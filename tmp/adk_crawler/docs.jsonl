{"doc_id": "10eae276fc8f2aedb3e6c06824b3d54c9cd8c6cdf2dd046b12e024d7c2338a6d", "url": "https://google.github.io/adk-docs/", "title": "Index - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agent Development Kit"], "text": "Agent Development Kit Agent Development Kit (ADK) is a flexible and modular framework for developing\nand deploying AI agents . While optimized for Gemini and the Google ecosystem,\nADK is model-agnostic , deployment-agnostic , and is built for compatibility with other frameworks . ADK was designed to make agent\ndevelopment feel more like software development, to make it easier for\ndevelopers to create, deploy, and orchestrate agentic architectures that range\nfrom simple tasks to complex workflows. Get started: Python Go Java pip install google-adk go get google.golang.org/adk pom.xml <dependency> <groupId> com.google.adk </groupId> <artifactId> google-adk </artifactId> <version> 0.3.0 </version> </dependency> build.gradle dependencies { implementation 'com.google.adk:google-adk:0.3.0' } Start with Python Start with Go Start with Java ", "code_blocks": [{"language": "text", "code": "<dependency>\n    <groupId>com.google.adk</groupId>\n    <artifactId>google-adk</artifactId>\n    <version>0.3.0</version>\n</dependency>"}, {"language": "text", "code": "dependencies {\n    implementation 'com.google.adk:google-adk:0.3.0'\n}"}]}, {"heading_path": ["Learn more\u00b6"], "text": "Learn more \u00b6 ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. Watch \"Introducing Agent Development Kit\"! Flexible Orchestration Define workflows using workflow agents ( Sequential , Parallel , Loop )\nfor predictable pipelines, or leverage LLM-driven dynamic routing\n( LlmAgent transfer) for adaptive behavior. Learn about agents Multi-Agent Architecture Build modular and scalable applications by composing multiple specialized\nagents in a hierarchy. Enable complex coordination and delegation. Explore multi-agent systems Rich Tool Ecosystem Equip agents with diverse capabilities: use pre-built tools (Search, Code\nExec), create custom functions, integrate 3rd-party libraries, or even use\nother agents as tools. Browse tools Deployment Ready Containerize and deploy your agents anywhere \u2013 run locally, scale with\nVertex AI Agent Engine, or integrate into custom infrastructure using Cloud\nRun or Docker. Deploy agents Built-in Evaluation Systematically assess agent performance by evaluating both the final\nresponse quality and the step-by-step execution trajectory against\npredefined test cases. Evaluate agents Building Safe and Secure Agents Learn how to building powerful and trustworthy agents by implementing\nsecurity and safety patterns and best practices into your agent's design. Safety and Security Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:37:57.698766", "source_type": "adk-docs"}
{"doc_id": "48d7b17ac6d27963d036225eb783cf15cfbb7e753056c42afbb21b40da4292fa", "url": "https://google.github.io/adk-docs/get-started", "title": "Get started - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Get started\u00b6"], "text": "Get started \u00b6 Agent Development Kit (ADK) is designed to empower developers to quickly build,\nmanage, evaluate and deploy AI-powered agents. These quick start guides get you\nset up and running a simple agent in less than 20 minutes. ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. Python Quickstart Create your first Python ADK agent in minutes. Start with Python ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. Go Quickstart Create your first Go ADK agent in minutes. Start with Go ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. Java Quickstart Create your first Java ADK agent in minutes. Start with Java Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:37:58.192099", "source_type": "adk-docs"}
{"doc_id": "822054370cdcaa2a598189e2a3b7d90cd52eee4cce0e4b46462755ca6ea4141d", "url": "https://google.github.io/adk-docs/get-started/python", "title": "Python - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Python Quickstart for ADK\u00b6"], "text": "Python Quickstart for ADK \u00b6 This guide shows you how to get up and running with Agent Development Kit\n(ADK) for Python. Before you start, make sure you have the following installed: Python 3.9 or later pip for installing packages ", "code_blocks": []}, {"heading_path": ["Installation\u00b6"], "text": "Installation \u00b6 Install ADK by running the following command: pip install google-adk Recommended: create and activate a Python virtual environment Create a Python virtual environment: python -m venv .venv Activate the Python virtual environment: Windows CMD Windows Powershell MacOS / Linux .venv\\Scripts\\activate.bat .venv\\Scripts\\Activate.ps1 source .venv/bin/activate ", "code_blocks": [{"language": "text", "code": "pip install google-adk"}, {"language": "text", "code": "python -m venv .venv"}, {"language": "text", "code": ".venv\\Scripts\\activate.bat"}, {"language": "text", "code": ".venv\\Scripts\\Activate.ps1"}, {"language": "text", "code": "source .venv/bin/activate"}]}, {"heading_path": ["Create an agent project\u00b6"], "text": "Create an agent project \u00b6 Run the adk create command to start a new agent project. adk create my_agent ", "code_blocks": [{"language": "text", "code": "adk create my_agent"}]}, {"heading_path": ["Explore the agent project\u00b6"], "text": "Explore the agent project \u00b6 The created agent project has the following structure, with the agent.py file containing the main control code for the agent. my_agent/ agent.py      # main agent code .env          # API keys or project IDs __init__.py ", "code_blocks": [{"language": "text", "code": "my_agent/\n    agent.py      # main agent code\n    .env          # API keys or project IDs\n    __init__.py"}]}, {"heading_path": ["Update your agent project\u00b6"], "text": "Update your agent project \u00b6 The agent.py file contains a root_agent definition which is the only\nrequired element of an ADK agent. You can also define tools for the agent to\nuse. Update the generated agent.py code to include a get_current_time tool\nfor use by the agent, as shown in the following code: from google.adk.agents.llm_agent import Agent # Mock tool implementation def get_current_time ( city : str ) -> dict : \"\"\"Returns the current time in a specified city.\"\"\" return { \"status\" : \"success\" , \"city\" : city , \"time\" : \"10:30 AM\" } root_agent = Agent ( model = 'gemini-3-pro-preview' , name = 'root_agent' , description = \"Tells the current time in a specified city.\" , instruction = \"You are a helpful assistant that tells the current time in cities. Use the 'get_current_time' tool for this purpose.\" , tools = [ get_current_time ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents.llm_agent import Agent\n\n# Mock tool implementation\ndef get_current_time(city: str) -> dict:\n    \"\"\"Returns the current time in a specified city.\"\"\"\n    return {\"status\": \"success\", \"city\": city, \"time\": \"10:30 AM\"}\n\nroot_agent = Agent(\n    model='gemini-3-pro-preview',\n    name='root_agent',\n    description=\"Tells the current time in a specified city.\",\n    instruction=\"You are a helpful assistant that tells the current time in cities. Use the 'get_current_time' tool for this purpose.\",\n    tools=[get_current_time],\n)"}]}, {"heading_path": ["Set your API key\u00b6"], "text": "Set your API key \u00b6 This project uses the Gemini API, which requires an API key. If you\ndon't already have Gemini API key, create a key in Google AI Studio on the API Keys page. In a terminal window, write your API key into an .env file as an environment variable: Update: my_agent/.env echo 'GOOGLE_API_KEY=\"YOUR_API_KEY\"' > .env Using other AI models with ADK ADK supports the use of many generative AI models. For more\ninformation on configuring other models in ADK agents, see Models & Authentication . ", "code_blocks": [{"language": "text", "code": "echo 'GOOGLE_API_KEY=\"YOUR_API_KEY\"' > .env"}]}, {"heading_path": ["Run your agent\u00b6"], "text": "Run your agent \u00b6 You can run your ADK agent with an interactive command-line interface using the adk run command or the ADK web user interface provided by the ADK using the adk web command. Both these options allow you to test and interact with your\nagent. ", "code_blocks": []}, {"heading_path": ["Run with command-line interface\u00b6"], "text": "Run with command-line interface \u00b6 Run your agent using the adk run command-line tool. adk run my_agent ", "code_blocks": [{"language": "text", "code": "adk run my_agent"}]}, {"heading_path": ["Run with web interface\u00b6"], "text": "Run with web interface \u00b6 The ADK framework provides web interface you can use to test and interact with\nyour agent. You can start the web interface using the following command: adk web --port 8000 Note Run this command from the parent directory that contains your my_agent/ folder. For example, if your agent is inside agents/my_agent/ ,\nrun adk web from the agents/ directory. This command starts a web server with a chat interface for your agent. You can\naccess the web interface at (http://localhost:8000). Select the agent at the\nupper left corner and type a request. ", "code_blocks": [{"language": "text", "code": "adk web --port 8000"}]}, {"heading_path": ["Next: Build your agent\u00b6"], "text": "Next: Build your agent \u00b6 Now that you have ADK installed and your first agent running, try building\nyour own agent with our build guides: Build your agent Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:37:58.703649", "source_type": "adk-docs"}
{"doc_id": "038b2cc576057bf2f6e3253e81eb80e1d178d2d22b57385a21a70f32082675a9", "url": "https://google.github.io/adk-docs/get-started/go", "title": "Go - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Go Quickstart for ADK\u00b6"], "text": "Go Quickstart for ADK \u00b6 This guide shows you how to get up and running with Agent Development Kit\nfor Go. Before you start, make sure you have the following installed: Go 1.24.4 or later ", "code_blocks": []}, {"heading_path": ["Create an agent project\u00b6"], "text": "Create an agent project \u00b6 Create an agent project with the following files and directory structure: my_agent/ agent.go    # main agent code .env        # API keys or project IDs Create this project structure using the command line Windows MacOS / Linux mkdir my_agent\\ type nul > my_agent\\agent.go type nul > my_agent\\env.bat mkdir -p my_agent/ && \\ touch my_agent/agent.go && \\ touch my_agent/.env ", "code_blocks": [{"language": "text", "code": "my_agent/\n    agent.go    # main agent code\n    .env        # API keys or project IDs"}, {"language": "text", "code": "mkdir my_agent\\\ntype nul > my_agent\\agent.go\ntype nul > my_agent\\env.bat"}, {"language": "text", "code": "mkdir -p my_agent/ && \\\n    touch my_agent/agent.go && \\\n    touch my_agent/.env"}]}, {"heading_path": ["Define the agent code\u00b6"], "text": "Define the agent code \u00b6 Create the code for a basic agent that uses the built-in Google Search tool . Add the\nfollowing code to the my_agent/agent.go file in your project directory: my_agent/agent.go package main import ( \"context\" \"log\" \"os\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/cmd/launcher/adk\" \"google.golang.org/adk/cmd/launcher/full\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/server/restapi/services\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/geminitool\" \"google.golang.org/genai\" ) func main () { ctx := context . Background () model , err := gemini . NewModel ( ctx , \"gemini-3-pro-preview\" , & genai . ClientConfig { APIKey : os . Getenv ( \"GOOGLE_API_KEY\" ), }) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } agent , err := llmagent . New ( llmagent . Config { Name : \"hello_time_agent\" , Model : model , Description : \"Tells the current time in a specified city.\" , Instruction : \"You are a helpful assistant that tells the current time in a city.\" , Tools : [] tool . Tool { geminitool . GoogleSearch {}, }, }) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } config := & adk . Config { AgentLoader : services . NewSingleAgentLoader ( agent ), } l := full . NewLauncher () if err = l . Execute ( ctx , config , os . Args [ 1 :]); err != nil { log . Fatalf ( \"Run failed: %v\\n\\n%s\" , err , l . CommandLineSyntax ()) } } ", "code_blocks": [{"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"log\"\n    \"os\"\n\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/cmd/launcher/adk\"\n    \"google.golang.org/adk/cmd/launcher/full\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/server/restapi/services\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/geminitool\"\n    \"google.golang.org/genai\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    model, err := gemini.NewModel(ctx, \"gemini-3-pro-preview\", &genai.ClientConfig{\n        APIKey: os.Getenv(\"GOOGLE_API_KEY\"),\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create model: %v\", err)\n    }\n\n    agent, err := llmagent.New(llmagent.Config{\n        Name:        \"hello_time_agent\",\n        Model:       model,\n        Description: \"Tells the current time in a specified city.\",\n        Instruction: \"You are a helpful assistant that tells the current time in a city.\",\n        Tools: []tool.Tool{\n            geminitool.GoogleSearch{},\n        },\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create agent: %v\", err)\n    }\n\n    config := &adk.Config{\n        AgentLoader: services.NewSingleAgentLoader(agent),\n    }\n\n    l := full.NewLauncher()\n    if err = l.Execute(ctx, config, os.Args[1:]); err != nil {\n        log.Fatalf(\"Run failed: %v\\n\\n%s\", err, l.CommandLineSyntax())\n    }\n}"}]}, {"heading_path": ["Configure project and dependencies\u00b6"], "text": "Configure project and dependencies \u00b6 Use the go mod command to initialize the project modules and install the\nrequired packages based on the import statement in your agent code file: go mod init my-agent/main go mod tidy ", "code_blocks": [{"language": "text", "code": "go mod init my-agent/main\ngo mod tidy"}]}, {"heading_path": ["Set your API key\u00b6"], "text": "Set your API key \u00b6 This project uses the Gemini API, which requires an API key. If you\ndon't already have Gemini API key, create a key in Google AI Studio on the API Keys page. In a terminal window, write your API key into the .env or env.bat file of\nyour project to set environment variables: MacOS / Linux Windows Update: my_agent/.env echo 'export GOOGLE_API_KEY=\"YOUR_API_KEY\"' > .env Update: my_agent/env.bat echo 'set GOOGLE_API_KEY=\"YOUR_API_KEY\"' > env.bat Using other AI models with ADK ADK supports the use of many generative AI models. For more\ninformation on configuring other models in ADK agents, see Models & Authentication . ", "code_blocks": [{"language": "text", "code": "echo 'export GOOGLE_API_KEY=\"YOUR_API_KEY\"' > .env"}, {"language": "text", "code": "echo 'set GOOGLE_API_KEY=\"YOUR_API_KEY\"' > env.bat"}]}, {"heading_path": ["Run your agent\u00b6"], "text": "Run your agent \u00b6 You can run your ADK agent using the interactive command-line interface\nyou defined or the ADK web user interface provided by\nthe ADK Go command line tool. Both these options allow you to test and\ninteract with your agent. ", "code_blocks": []}, {"heading_path": ["Run with command-line interface\u00b6"], "text": "Run with command-line interface \u00b6 Run your agent using the following Go command: Run from: my_agent/ directory # Remember to load keys and settings: source .env OR env.bat go run agent.go ", "code_blocks": [{"language": "text", "code": "# Remember to load keys and settings: source .env OR env.bat\ngo run agent.go"}]}, {"heading_path": ["Run with web interface\u00b6"], "text": "Run with web interface \u00b6 Run your agent with the ADK web interface using the following Go command: Run from: my_agent/ directory # Remember to load keys and settings: source .env OR env.bat go run agent.go web api webui This command starts a web server with a chat interface for your agent. You can\naccess the web interface at (http://localhost:8080). Select your agent at the\nupper left corner and type a request. ", "code_blocks": [{"language": "text", "code": "# Remember to load keys and settings: source .env OR env.bat\ngo run agent.go web api webui"}]}, {"heading_path": ["Next: Build your agent\u00b6"], "text": "Next: Build your agent \u00b6 Now that you have ADK installed and your first agent running, try building\nyour own agent with our build guides: Build your agent Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:37:59.204245", "source_type": "adk-docs"}
{"doc_id": "d892cceb8ff42bf67be8eb4660ae0c5db7d7f0cd6444e43cfe45e6fbe42bef02", "url": "https://google.github.io/adk-docs/get-started/java", "title": "Java - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Java Quickstart for ADK\u00b6"], "text": "Java Quickstart for ADK \u00b6 This guide shows you how to get up and running with Agent Development Kit\nfor Java. Before you start, make sure you have the following installed: Java 17 or later Maven 3.9 or later ", "code_blocks": []}, {"heading_path": ["Create an agent project\u00b6"], "text": "Create an agent project \u00b6 Create an agent project with the following files and directory structure: my_agent/ src/main/java/com/example/agent/ HelloTimeAgent.java # main agent code AgentCliRunner.java # command-line interface pom.xml                                 # project configuration .env                                    # API keys or project IDs Create this project structure using the command line Windows MacOS / Linux mkdir my_agent\\src\\main\\java\\com\\example\\agent type nul > my_agent\\src\\main\\java\\com\\example\\agent\\HelloTimeAgent.java type nul > my_agent\\src\\main\\java\\com\\example\\agent\\AgentCliRunner.java type nul > my_agent\\pom.xml type nul > my_agent\\.env mkdir -p my_agent/src/main/java/com/example/agent && \\ touch my_agent/src/main/java/com/example/agent/HelloTimeAgent.java && \\ touch my_agent/src/main/java/com/example/agent/AgentCliRunner.java && \\ touch my_agent/pom.xml my_agent/.env ", "code_blocks": [{"language": "text", "code": "my_agent/\n    src/main/java/com/example/agent/\n                        HelloTimeAgent.java # main agent code\n                        AgentCliRunner.java # command-line interface\n    pom.xml                                 # project configuration\n    .env                                    # API keys or project IDs"}, {"language": "text", "code": "mkdir my_agent\\src\\main\\java\\com\\example\\agent\ntype nul > my_agent\\src\\main\\java\\com\\example\\agent\\HelloTimeAgent.java\ntype nul > my_agent\\src\\main\\java\\com\\example\\agent\\AgentCliRunner.java\ntype nul > my_agent\\pom.xml\ntype nul > my_agent\\.env"}, {"language": "text", "code": "mkdir -p my_agent/src/main/java/com/example/agent && \\\n    touch my_agent/src/main/java/com/example/agent/HelloTimeAgent.java && \\\n    touch my_agent/src/main/java/com/example/agent/AgentCliRunner.java && \\\n    touch my_agent/pom.xml my_agent/.env"}]}, {"heading_path": ["Define the agent code\u00b6"], "text": "Define the agent code \u00b6 Create the code for a basic agent, including a simple implementation of an ADK Function Tool , called getCurrentTime() .\nAdd the following code to the HelloTimeAgent.java file in your project\ndirectory: my_agent/src/main/java/com/example/agent/HelloTimeAgent.java package com.example.agent ; import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.LlmAgent ; import com.google.adk.tools.Annotations.Schema ; import com.google.adk.tools.FunctionTool ; import java.util.Map ; public class HelloTimeAgent { public static BaseAgent ROOT_AGENT = initAgent (); private static BaseAgent initAgent () { return LlmAgent . builder () . name ( \"hello-time-agent\" ) . description ( \"Tells the current time in a specified city\" ) . instruction ( \"\"\" You are a helpful assistant that tells the current time in a city. Use the 'getCurrentTime' tool for this purpose. \"\"\" ) . model ( \"gemini-2.5-flash\" ) . tools ( FunctionTool . create ( HelloTimeAgent . class , \"getCurrentTime\" )) . build (); } /** Mock tool implementation */ @Schema ( description = \"Get the current time for a given city\" ) public static Map < String , String > getCurrentTime ( @Schema ( name = \"city\" , description = \"Name of the city to get the time for\" ) String city ) { return Map . of ( \"city\" , city , \"forecast\" , \"The time is 10:30am.\" ); } } Caution: Gemini 3 compatibility ADK Java v0.3.0 and lower is not compatible with Gemini 3 Pro Preview due to thought signature changes for function calling. Use Gemini 2.5\nor lower models instead. ", "code_blocks": [{"language": "text", "code": "package com.example.agent;\n\nimport com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.tools.Annotations.Schema;\nimport com.google.adk.tools.FunctionTool;\n\nimport java.util.Map;\n\npublic class HelloTimeAgent {\n\n    public static BaseAgent ROOT_AGENT = initAgent();\n\n    private static BaseAgent initAgent() {\n        return LlmAgent.builder()\n            .name(\"hello-time-agent\")\n            .description(\"Tells the current time in a specified city\")\n            .instruction(\"\"\"\n                You are a helpful assistant that tells the current time in a city.\n                Use the 'getCurrentTime' tool for this purpose.\n                \"\"\")\n            .model(\"gemini-2.5-flash\")\n            .tools(FunctionTool.create(HelloTimeAgent.class, \"getCurrentTime\"))\n            .build();\n    }\n\n    /** Mock tool implementation */\n    @Schema(description = \"Get the current time for a given city\")\n    public static Map<String, String> getCurrentTime(\n        @Schema(name = \"city\", description = \"Name of the city to get the time for\") String city) {\n        return Map.of(\n            \"city\", city,\n            \"forecast\", \"The time is 10:30am.\"\n        );\n    }\n}"}]}, {"heading_path": ["Configure project and dependencies\u00b6"], "text": "Configure project and dependencies \u00b6 An ADK agent project requires this dependency in your pom.xml project file: my_agent/pom.xml (partial) <dependencies> <dependency> <groupId> com.google.adk </groupId> <artifactId> adk-core </artifactId> <version> 0.3.0 </version> </dependency> </dependencies> Update the pom.xml project file to include this dependency and\naddtional settings with the following configuration code: Complete pom.xml configuration for project The following code shows a complete pom.xml configuration for\nthis project: my_agent/pom.xml <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <groupId> com.example.agent </groupId> <artifactId> adk-agents </artifactId> <version> 1.0-SNAPSHOT </version> <!-- Specify the version of Java you'll be using --> <properties> <maven.compiler.source> 17 </maven.compiler.source> <maven.compiler.target> 17 </maven.compiler.target> <project.build.sourceEncoding> UTF-8 </project.build.sourceEncoding> </properties> <dependencies> <!-- The ADK core dependency --> <dependency> <groupId> com.google.adk </groupId> <artifactId> google-adk </artifactId> <version> 0.3.0 </version> </dependency> <!-- The ADK dev web UI to debug your agent --> <dependency> <groupId> com.google.adk </groupId> <artifactId> google-adk-dev </artifactId> <version> 0.3.0 </version> </dependency> </dependencies> </project> ", "code_blocks": [{"language": "text", "code": "<dependencies>\n    <dependency>\n        <groupId>com.google.adk</groupId>\n        <artifactId>adk-core</artifactId>\n        <version>0.3.0</version>\n    </dependency>\n</dependencies>"}, {"language": "text", "code": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n        xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.example.agent</groupId>\n    <artifactId>adk-agents</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <!-- Specify the version of Java you'll be using -->\n    <properties>\n        <maven.compiler.source>17</maven.compiler.source>\n        <maven.compiler.target>17</maven.compiler.target>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    </properties>\n\n    <dependencies>\n        <!-- The ADK core dependency -->\n        <dependency>\n            <groupId>com.google.adk</groupId>\n            <artifactId>google-adk</artifactId>\n            <version>0.3.0</version>\n        </dependency>\n        <!-- The ADK dev web UI to debug your agent -->\n        <dependency>\n            <groupId>com.google.adk</groupId>\n            <artifactId>google-adk-dev</artifactId>\n            <version>0.3.0</version>\n        </dependency>\n    </dependencies>\n\n</project>"}]}, {"heading_path": ["Set your API key\u00b6"], "text": "Set your API key \u00b6 This project uses the Gemini API, which requires an API key. If you\ndon't already have Gemini API key, create a key in Google AI Studio on the API Keys page. In a terminal window, write your API key into your .env file of your project\nto set environment variables: MacOS / Linux Windows Update: my_agent/.env echo 'export GOOGLE_API_KEY=\"YOUR_API_KEY\"' > .env Update: my_agent/env.bat echo 'set GOOGLE_API_KEY=\"YOUR_API_KEY\"' > env.bat Using other AI models with ADK ADK supports the use of many generative AI models. For more\ninformation on configuring other models in ADK agents, see Models & Authentication . ", "code_blocks": [{"language": "text", "code": "echo 'export GOOGLE_API_KEY=\"YOUR_API_KEY\"' > .env"}, {"language": "text", "code": "echo 'set GOOGLE_API_KEY=\"YOUR_API_KEY\"' > env.bat"}]}, {"heading_path": ["Create an agent command-line interface\u00b6"], "text": "Create an agent command-line interface \u00b6 Create a AgentCliRunner.java class to allow you to run and interact with HelloTimeAgent from the command line. This code shows how to create a RunConfig object to run the agent and a Session object to interact with the\nrunning agent. my_agent/src/main/java/com/example/agent/AgentCliRunner.java package com.example.agent ; import com.google.adk.agents.RunConfig ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import java.util.Scanner ; import static java.nio.charset.StandardCharsets.UTF_8 ; public class AgentCliRunner { public static void main ( String [] args ) { RunConfig runConfig = RunConfig . builder (). build (); InMemoryRunner runner = new InMemoryRunner ( HelloTimeAgent . ROOT_AGENT ); Session session = runner . sessionService () . createSession ( runner . appName (), \"user1234\" ) . blockingGet (); try ( Scanner scanner = new Scanner ( System . in , UTF_8 )) { while ( true ) { System . out . print ( \"\\nYou > \" ); String userInput = scanner . nextLine (); if ( \"quit\" . equalsIgnoreCase ( userInput )) { break ; } Content userMsg = Content . fromParts ( Part . fromText ( userInput )); Flowable < Event > events = runner . runAsync ( session . userId (), session . id (), userMsg , runConfig ); System . out . print ( \"\\nAgent > \" ); events . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } } } } ", "code_blocks": [{"language": "text", "code": "package com.example.agent;\n\nimport com.google.adk.agents.RunConfig;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport java.util.Scanner;\n\nimport static java.nio.charset.StandardCharsets.UTF_8;\n\npublic class AgentCliRunner {\n\n    public static void main(String[] args) {\n        RunConfig runConfig = RunConfig.builder().build();\n        InMemoryRunner runner = new InMemoryRunner(HelloTimeAgent.ROOT_AGENT);\n\n        Session session = runner\n                .sessionService()\n                .createSession(runner.appName(), \"user1234\")\n                .blockingGet();\n\n        try (Scanner scanner = new Scanner(System.in, UTF_8)) {\n            while (true) {\n                System.out.print(\"\\nYou > \");\n                String userInput = scanner.nextLine();\n                if (\"quit\".equalsIgnoreCase(userInput)) {\n                    break;\n                }\n\n                Content userMsg = Content.fromParts(Part.fromText(userInput));\n                Flowable<Event> events = runner.runAsync(session.userId(), session.id(), userMsg, runConfig);\n\n                System.out.print(\"\\nAgent > \");\n                events.blockingForEach(event -> {\n                    if (event.finalResponse()) {\n                        System.out.println(event.stringifyContent());\n                    }\n                });\n            }\n        }\n    }\n}"}]}, {"heading_path": ["Run your agent\u00b6"], "text": "Run your agent \u00b6 You can run your ADK agent using the interactive command-line interface AgentCliRunner class you defined or the ADK web user interface provided by\nthe ADK using the AdkWebServer class. Both these options allow you to test and\ninteract with your agent. ", "code_blocks": []}, {"heading_path": ["Run with command-line interface\u00b6"], "text": "Run with command-line interface \u00b6 Run your agent with the command-line interface AgentCliRunner class\nusing the following Maven command: # Remember to load keys and settings: source .env OR env.bat mvn compile exec:java -Dexec.mainClass=\"com.example.agent.AgentCliRunner\" ", "code_blocks": [{"language": "text", "code": "# Remember to load keys and settings: source .env OR env.bat\nmvn compile exec:java -Dexec.mainClass=\"com.example.agent.AgentCliRunner\""}]}, {"heading_path": ["Run with web interface\u00b6"], "text": "Run with web interface \u00b6 Run your agent with the ADK web interface using the following Maven command: # Remember to load keys and settings: source .env OR env.bat mvn compile exec:java \\ -Dexec.mainClass=\"com.google.adk.web.AdkWebServer\" \\ -Dexec.args=\"--adk.agents.source-dir=target --server.port=8000\" This command starts a web server with a chat interface for your agent. You can\naccess the web interface at (http://localhost:8000). Select your agent at the\nupper left corner and type a request. ", "code_blocks": [{"language": "text", "code": "# Remember to load keys and settings: source .env OR env.bat\nmvn compile exec:java \\\n    -Dexec.mainClass=\"com.google.adk.web.AdkWebServer\" \\\n    -Dexec.args=\"--adk.agents.source-dir=target --server.port=8000\""}]}, {"heading_path": ["Next: Build your agent\u00b6"], "text": "Next: Build your agent \u00b6 Now that you have ADK installed and your first agent running, try building\nyour own agent with our build guides: Build your agent Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:37:59.739297", "source_type": "adk-docs"}
{"doc_id": "a87e9eaa19c3686b6b201c5d3b3bb5cab36ba0716d42b5d8f1ae43981ca94a35", "url": "https://google.github.io/adk-docs/tutorials", "title": "Build your agent with ADK - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Build your agent with ADK\u00b6"], "text": "Build your agent with ADK \u00b6 Get started with the Agent Development Kit (ADK) through our collection of\npractical guides. These tutorials are designed in a simple, progressive,\nstep-by-step fashion, introducing you to different ADK features and\ncapabilities. This approach allows you to learn and build incrementally \u2013 starting with\nfoundational concepts and gradually tackling more advanced agent development\ntechniques. You'll explore how to apply these features effectively across\nvarious use cases, equipping you to build your own sophisticated agentic\napplications with ADK. Explore our collection below and happy building: Multi-tool agent Create a workflow that uses multiple tools. Build a multi-tool agent Agent team Build an multi-agent workflow including agent delegation,\nsession management, and safety callbacks. Build an agent team Streaming agent Create an agent for handling streamed content. Build a streaming agent Discover sample agents Discover sample agents for retail, travel, customer service, and more! Discover adk-samples Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:00.219491", "source_type": "adk-docs"}
{"doc_id": "0fcdbfeedf7a7ecf3aef328060a4930ac74173df5e18d8b5235c3ad7748d6153", "url": "https://google.github.io/adk-docs/get-started/quickstart", "title": "Multi-tool agent - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Build a multi-tool agent\u00b6"], "text": "Build a multi-tool agent \u00b6 This quickstart guides you through installing the Agent Development Kit (ADK),\nsetting up a basic agent with multiple tools, and running it locally either in the terminal or in the interactive, browser-based dev UI. <img src=\"../../assets/quickstart.png\" alt=\"Quickstart setup\"> This quickstart assumes a local IDE (VS Code, PyCharm, IntelliJ IDEA, etc.)\nwith Python 3.9+ or Java 17+ and terminal access. This method runs the\napplication entirely on your machine and is recommended for internal development. ", "code_blocks": []}, {"heading_path": ["1. Set up Environment & Install ADK\u00b6"], "text": "1. Set up Environment & Install ADK \u00b6 Python Java Create & Activate Virtual Environment (Recommended): # Create python -m venv .venv # Activate (each new terminal) # macOS/Linux: source .venv/bin/activate # Windows CMD: .venv\\Scripts\\activate.bat # Windows PowerShell: .venv\\Scripts\\Activate.ps1 Install ADK: pip install google-adk To install ADK and setup the environment, proceed to the following steps. ", "code_blocks": [{"language": "text", "code": "# Create\npython -m venv .venv\n# Activate (each new terminal)\n# macOS/Linux: source .venv/bin/activate\n# Windows CMD: .venv\\Scripts\\activate.bat\n# Windows PowerShell: .venv\\Scripts\\Activate.ps1"}, {"language": "text", "code": "pip install google-adk"}]}, {"heading_path": ["2. Create Agent Project\u00b6"], "text": "2. Create Agent Project \u00b6 ", "code_blocks": []}, {"heading_path": ["Project structure\u00b6"], "text": "Project structure \u00b6 Python Java You will need to create the following project structure: parent_folder/ multi_tool_agent/ __init__.py agent.py .env Create the folder multi_tool_agent : mkdir multi_tool_agent/ Note for Windows users When using ADK on Windows for the next few steps, we recommend creating\nPython files using File Explorer or an IDE because the following commands\n( mkdir , echo ) typically generate files with null bytes and/or incorrect\nencoding. ", "code_blocks": [{"language": "text", "code": "parent_folder/\n    multi_tool_agent/\n        __init__.py\n        agent.py\n        .env"}, {"language": "text", "code": "mkdir multi_tool_agent/"}]}, {"heading_path": ["__init__.py\u00b6"], "text": "__init__.py \u00b6 Now create an __init__.py file in the folder: echo \"from . import agent\" > multi_tool_agent/__init__.py Your __init__.py should now look like this: multi_tool_agent/__init__.py from . import agent ", "code_blocks": [{"language": "text", "code": "echo \"from . import agent\" > multi_tool_agent/__init__.py"}, {"language": "text", "code": "from . import agent"}]}, {"heading_path": ["agent.py\u00b6"], "text": "agent.py \u00b6 Create an agent.py file in the same folder: OS X & Linux Windows touch multi_tool_agent/agent.py type nul > multi_tool_agent/agent.py Copy and paste the following code into agent.py : multi_tool_agent/agent.py import datetime from zoneinfo import ZoneInfo from google.adk.agents import Agent def get_weather ( city : str ) -> dict : \"\"\"Retrieves the current weather report for a specified city. Args: city (str): The name of the city for which to retrieve the weather report. Returns: dict: status and result or error msg. \"\"\" if city . lower () == \"new york\" : return { \"status\" : \"success\" , \"report\" : ( \"The weather in New York is sunny with a temperature of 25 degrees\" \" Celsius (77 degrees Fahrenheit).\" ), } else : return { \"status\" : \"error\" , \"error_message\" : f \"Weather information for ' { city } ' is not available.\" , } def get_current_time ( city : str ) -> dict : \"\"\"Returns the current time in a specified city. Args: city (str): The name of the city for which to retrieve the current time. Returns: dict: status and result or error msg. \"\"\" if city . lower () == \"new york\" : tz_identifier = \"America/New_York\" else : return { \"status\" : \"error\" , \"error_message\" : ( f \"Sorry, I don't have timezone information for { city } .\" ), } tz = ZoneInfo ( tz_identifier ) now = datetime . datetime . now ( tz ) report = ( f 'The current time in { city } is { now . strftime ( \"%Y-%m- %d %H:%M:%S %Z%z\" ) } ' ) return { \"status\" : \"success\" , \"report\" : report } root_agent = Agent ( name = \"weather_time_agent\" , model = \"gemini-2.0-flash\" , description = ( \"Agent to answer questions about the time and weather in a city.\" ), instruction = ( \"You are a helpful agent who can answer user questions about the time and weather in a city.\" ), tools = [ get_weather , get_current_time ], ) ", "code_blocks": [{"language": "text", "code": "touch multi_tool_agent/agent.py"}, {"language": "text", "code": "type nul > multi_tool_agent/agent.py"}, {"language": "text", "code": "import datetime\nfrom zoneinfo import ZoneInfo\nfrom google.adk.agents import Agent\n\ndef get_weather(city: str) -> dict:\n    \"\"\"Retrieves the current weather report for a specified city.\n\n    Args:\n        city (str): The name of the city for which to retrieve the weather report.\n\n    Returns:\n        dict: status and result or error msg.\n    \"\"\"\n    if city.lower() == \"new york\":\n        return {\n            \"status\": \"success\",\n            \"report\": (\n                \"The weather in New York is sunny with a temperature of 25 degrees\"\n                \" Celsius (77 degrees Fahrenheit).\"\n            ),\n        }\n    else:\n        return {\n            \"status\": \"error\",\n            \"error_message\": f\"Weather information for '{city}' is not available.\",\n        }\n\n\ndef get_current_time(city: str) -> dict:\n    \"\"\"Returns the current time in a specified city.\n\n    Args:\n        city (str): The name of the city for which to retrieve the current time.\n\n    Returns:\n        dict: status and result or error msg.\n    \"\"\"\n\n    if city.lower() == \"new york\":\n        tz_identifier = \"America/New_York\"\n    else:\n        return {\n            \"status\": \"error\",\n            \"error_message\": (\n                f\"Sorry, I don't have timezone information for {city}.\"\n            ),\n        }\n\n    tz = ZoneInfo(tz_identifier)\n    now = datetime.datetime.now(tz)\n    report = (\n        f'The current time in {city} is {now.strftime(\"%Y-%m-%d %H:%M:%S %Z%z\")}'\n    )\n    return {\"status\": \"success\", \"report\": report}\n\n\nroot_agent = Agent(\n    name=\"weather_time_agent\",\n    model=\"gemini-2.0-flash\",\n    description=(\n        \"Agent to answer questions about the time and weather in a city.\"\n    ),\n    instruction=(\n        \"You are a helpful agent who can answer user questions about the time and weather in a city.\"\n    ),\n    tools=[get_weather, get_current_time],\n)"}]}, {"heading_path": [".env\u00b6"], "text": ".env \u00b6 Create a .env file in the same folder: OS X & Linux Windows touch multi_tool_agent/.env type nul > multi_tool_agent \\. env More instructions about this file are described in the next section on Set up the model . Java projects generally feature the following project structure: project_folder/ \u251c\u2500\u2500 pom.xml (or build.gradle) \u251c\u2500\u2500 src/ \u251c\u2500\u2500 \u2514\u2500\u2500 main/ \u2502       \u2514\u2500\u2500 java/ \u2502           \u2514\u2500\u2500 agents/ \u2502               \u2514\u2500\u2500 multitool/ \u2514\u2500\u2500 test/ ", "code_blocks": [{"language": "text", "code": "touch multi_tool_agent/.env"}, {"language": "text", "code": "type nul > multi_tool_agent\\.env"}, {"language": "text", "code": "project_folder/\n\u251c\u2500\u2500 pom.xml (or build.gradle)\n\u251c\u2500\u2500 src/\n\u251c\u2500\u2500 \u2514\u2500\u2500 main/\n\u2502       \u2514\u2500\u2500 java/\n\u2502           \u2514\u2500\u2500 agents/\n\u2502               \u2514\u2500\u2500 multitool/\n\u2514\u2500\u2500 test/"}]}, {"heading_path": ["Create MultiToolAgent.java\u00b6"], "text": "Create MultiToolAgent.java \u00b6 Create a MultiToolAgent.java source file in the agents.multitool package\nin the src/main/java/agents/multitool/ directory. Copy and paste the following code into MultiToolAgent.java : agents/multitool/MultiToolAgent.java package agents.multitool ; import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.LlmAgent ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.adk.tools.Annotations.Schema ; import com.google.adk.tools.FunctionTool ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import java.nio.charset.StandardCharsets ; import java.text.Normalizer ; import java.time.ZoneId ; import java.time.ZonedDateTime ; import java.time.format.DateTimeFormatter ; import java.util.Map ; import java.util.Scanner ; public class MultiToolAgent { private static String USER_ID = \"student\" ; private static String NAME = \"multi_tool_agent\" ; // The run your agent with Dev UI, the ROOT_AGENT should be a global public static final variable. public static final BaseAgent ROOT_AGENT = initAgent (); public static BaseAgent initAgent () { return LlmAgent . builder () . name ( NAME ) . model ( \"gemini-2.0-flash\" ) . description ( \"Agent to answer questions about the time and weather in a city.\" ) . instruction ( \"You are a helpful agent who can answer user questions about the time and weather\" + \" in a city.\" ) . tools ( FunctionTool . create ( MultiToolAgent . class , \"getCurrentTime\" ), FunctionTool . create ( MultiToolAgent . class , \"getWeather\" )) . build (); } public static Map < String , String > getCurrentTime ( @Schema ( name = \"city\" , description = \"The name of the city for which to retrieve the current time\" ) String city ) { String normalizedCity = Normalizer . normalize ( city , Normalizer . Form . NFD ) . trim () . toLowerCase () . replaceAll ( \"(\\\\p{IsM}+|\\\\p{IsP}+)\" , \"\" ) . replaceAll ( \"\\\\s+\" , \"_\" ); return ZoneId . getAvailableZoneIds (). stream () . filter ( zid -> zid . toLowerCase (). endsWith ( \"/\" + normalizedCity )) . findFirst () . map ( zid -> Map . of ( \"status\" , \"success\" , \"report\" , \"The current time in \" + city + \" is \" + ZonedDateTime . now ( ZoneId . of ( zid )) . format ( DateTimeFormatter . ofPattern ( \"HH:mm\" )) + \".\" )) . orElse ( Map . of ( \"status\" , \"error\" , \"report\" , \"Sorry, I don't have timezone information for \" + city + \".\" )); } public static Map < String , String > getWeather ( @Schema ( name = \"city\" , description = \"The name of the city for which to retrieve the weather report\" ) String city ) { if ( city . toLowerCase (). equals ( \"new york\" )) { return Map . of ( \"status\" , \"success\" , \"report\" , \"The weather in New York is sunny with a temperature of 25 degrees Celsius (77 degrees\" + \" Fahrenheit).\" ); } else { return Map . of ( \"status\" , \"error\" , \"report\" , \"Weather information for \" + city + \" is not available.\" ); } } public static void main ( String [] args ) throws Exception { InMemoryRunner runner = new InMemoryRunner ( ROOT_AGENT ); Session session = runner . sessionService () . createSession ( NAME , USER_ID ) . blockingGet (); try ( Scanner scanner = new Scanner ( System . in , StandardCharsets . UTF_8 )) { while ( true ) { System . out . print ( \"\\nYou > \" ); String userInput = scanner . nextLine (); if ( \"quit\" . equalsIgnoreCase ( userInput )) { break ; } Content userMsg = Content . fromParts ( Part . fromText ( userInput )); Flowable < Event > events = runner . runAsync ( USER_ID , session . id (), userMsg ); System . out . print ( \"\\nAgent > \" ); events . blockingForEach ( event -> System . out . println ( event . stringifyContent ())); } } } } ", "code_blocks": [{"language": "text", "code": "package agents.multitool;\n\nimport com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.Annotations.Schema;\nimport com.google.adk.tools.FunctionTool;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport java.nio.charset.StandardCharsets;\nimport java.text.Normalizer;\nimport java.time.ZoneId;\nimport java.time.ZonedDateTime;\nimport java.time.format.DateTimeFormatter;\nimport java.util.Map;\nimport java.util.Scanner;\n\npublic class MultiToolAgent {\n\n    private static String USER_ID = \"student\";\n    private static String NAME = \"multi_tool_agent\";\n\n    // The run your agent with Dev UI, the ROOT_AGENT should be a global public static final variable.\n    public static final BaseAgent ROOT_AGENT = initAgent();\n\n    public static BaseAgent initAgent() {\n        return LlmAgent.builder()\n            .name(NAME)\n            .model(\"gemini-2.0-flash\")\n            .description(\"Agent to answer questions about the time and weather in a city.\")\n            .instruction(\n                \"You are a helpful agent who can answer user questions about the time and weather\"\n                    + \" in a city.\")\n            .tools(\n                FunctionTool.create(MultiToolAgent.class, \"getCurrentTime\"),\n                FunctionTool.create(MultiToolAgent.class, \"getWeather\"))\n            .build();\n    }\n\n    public static Map<String, String> getCurrentTime(\n        @Schema(name = \"city\",\n                description = \"The name of the city for which to retrieve the current time\")\n        String city) {\n        String normalizedCity =\n            Normalizer.normalize(city, Normalizer.Form.NFD)\n                .trim()\n                .toLowerCase()\n                .replaceAll(\"(\\\\p{IsM}+|\\\\p{IsP}+)\", \"\")\n                .replaceAll(\"\\\\s+\", \"_\");\n\n        return ZoneId.getAvailableZoneIds().stream()\n            .filter(zid -> zid.toLowerCase().endsWith(\"/\" + normalizedCity))\n            .findFirst()\n            .map(\n                zid ->\n                    Map.of(\n                        \"status\",\n                        \"success\",\n                        \"report\",\n                        \"The current time in \"\n                            + city\n                            + \" is \"\n                            + ZonedDateTime.now(ZoneId.of(zid))\n                            .format(DateTimeFormatter.ofPattern(\"HH:mm\"))\n                            + \".\"))\n            .orElse(\n                Map.of(\n                    \"status\",\n                    \"error\",\n                    \"report\",\n                    \"Sorry, I don't have timezone information for \" + city + \".\"));\n    }\n\n    public static Map<String, String> getWeather(\n        @Schema(name = \"city\",\n                description = \"The name of the city for which to retrieve the weather report\")\n        String city) {\n        if (city.toLowerCase().equals(\"new york\")) {\n            return Map.of(\n                \"status\",\n                \"success\",\n                \"report\",\n                \"The weather in New York is sunny with a temperature of 25 degrees Celsius (77 degrees\"\n                    + \" Fahrenheit).\");\n\n        } else {\n            return Map.of(\n                \"status\", \"error\", \"report\", \"Weather information for \" + city + \" is not available.\");\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        InMemoryRunner runner = new InMemoryRunner(ROOT_AGENT);\n\n        Session session =\n            runner\n                .sessionService()\n                .createSession(NAME, USER_ID)\n                .blockingGet();\n\n        try (Scanner scanner = new Scanner(System.in, StandardCharsets.UTF_8)) {\n            while (true) {\n                System.out.print(\"\\nYou > \");\n                String userInput = scanner.nextLine();\n\n                if (\"quit\".equalsIgnoreCase(userInput)) {\n                    break;\n                }\n\n                Content userMsg = Content.fromParts(Part.fromText(userInput));\n                Flowable<Event> events = runner.runAsync(USER_ID, session.id(), userMsg);\n\n                System.out.print(\"\\nAgent > \");\n                events.blockingForEach(event -> System.out.println(event.stringifyContent()));\n            }\n        }\n    }\n}"}]}, {"heading_path": ["3. Set up the model\u00b6"], "text": "3. Set up the model \u00b6 Your agent's ability to understand user requests and generate responses is\npowered by a Large Language Model (LLM). Your agent needs to make secure calls\nto this external LLM service, which requires authentication credentials . Without\nvalid authentication, the LLM service will deny the agent's requests, and the\nagent will be unable to function. Model Authentication guide For a detailed guide on authenticating to different models, see the Authentication guide .\nThis is a critical step to ensure your agent can make calls to the LLM service. Gemini - Google AI Studio Gemini - Google Cloud Vertex AI Gemini - Google Cloud Vertex AI with Express Mode Get an API key from Google AI Studio . When using Python, open the .env file located inside ( multi_tool_agent/ )\nand copy-paste the following code. multi_tool_agent/.env GOOGLE_GENAI_USE_VERTEXAI=FALSE GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE When using Java, define environment variables: terminal export GOOGLE_GENAI_USE_VERTEXAI=FALSE export GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE Replace PASTE_YOUR_ACTUAL_API_KEY_HERE with your actual API KEY . Set up a Google Cloud project and enable the Vertex AI API . Set up the gcloud CLI . Authenticate to Google Cloud from the terminal by running gcloud auth application-default login . When using Python, open the .env file located inside ( multi_tool_agent/ ). Copy-paste\nthe following code and update the project ID and location. multi_tool_agent/.env GOOGLE_GENAI_USE_VERTEXAI=TRUE GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID GOOGLE_CLOUD_LOCATION=LOCATION When using Java, define environment variables: terminal export GOOGLE_GENAI_USE_VERTEXAI=TRUE export GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID export GOOGLE_CLOUD_LOCATION=LOCATION You can sign up for a free Google Cloud project and use Gemini for free with an eligible account! Set up a Google Cloud project with Vertex AI Express Mode Get an API key from your Express mode project. This key can be used with ADK to use Gemini models for free, as well as access to Agent Engine services. When using Python, open the .env file located inside ( multi_tool_agent/ ). Copy-paste\nthe following code and update the project ID and location. multi_tool_agent/.env GOOGLE_GENAI_USE_VERTEXAI=TRUE GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE When using Java, define environment variables: terminal export GOOGLE_GENAI_USE_VERTEXAI=TRUE export GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE ", "code_blocks": [{"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=FALSE\nGOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE"}, {"language": "text", "code": "export GOOGLE_GENAI_USE_VERTEXAI=FALSE\nexport GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=TRUE\nGOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID\nGOOGLE_CLOUD_LOCATION=LOCATION"}, {"language": "text", "code": "export GOOGLE_GENAI_USE_VERTEXAI=TRUE\nexport GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID\nexport GOOGLE_CLOUD_LOCATION=LOCATION"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=TRUE\nGOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE"}, {"language": "text", "code": "export GOOGLE_GENAI_USE_VERTEXAI=TRUE\nexport GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE"}]}, {"heading_path": ["4. Run Your Agent\u00b6"], "text": "4. Run Your Agent \u00b6 Python Java Using the terminal, navigate to the parent directory of your agent project\n(e.g. using cd .. ): parent_folder/      <-- navigate to this directory multi_tool_agent/ __init__.py agent.py .env There are multiple ways to interact with your agent: Dev UI (adk web) Terminal (adk run) API Server (adk api_server) Authentication Setup for Vertex AI Users If you selected \"Gemini - Google Cloud Vertex AI\" in the previous step, you must authenticate with Google Cloud before launching the dev UI. Run this command and follow the prompts: gcloud auth application-default login Note: Skip this step if you're using \"Gemini - Google AI Studio\". Run the following command to launch the dev UI . adk web Note for Windows users When hitting the _make_subprocess_transport NotImplementedError , consider using adk web --no-reload instead. Step 1: Open the URL provided (usually http://localhost:8000 or http://127.0.0.1:8000 ) directly in your browser. Step 2. In the top-left corner of the UI, you can select your agent in\nthe dropdown. Select \"multi_tool_agent\". Troubleshooting If you do not see \"multi_tool_agent\" in the dropdown menu, make sure you\nare running adk web in the parent folder of your agent folder\n(i.e. the parent folder of multi_tool_agent). Step 3. Now you can chat with your agent using the textbox: Step 4. By using the Events tab at the left, you can inspect\nindividual function calls, responses and model responses by clicking on the\nactions: On the Events tab, you can also click the Trace button to see the trace logs for each event that shows the latency of each function calls: Step 5. You can also enable your microphone and talk to your agent: Model support for voice/video streaming In order to use voice/video streaming in ADK, you will need to use Gemini models that support the Live API. You can find the model ID(s) that supports the Gemini Live API in the documentation: Google AI Studio: Gemini Live API Vertex AI: Gemini Live API You can then replace the model string in root_agent in the agent.py file you created earlier ( jump to section ). Your code should look something like: root_agent = Agent ( name = \"weather_time_agent\" , model = \"replace-me-with-model-id\" , #e.g. gemini-2.0-flash-live-001 ... Tip When using adk run you can inject prompts into the agent to start by\npiping text to the command like so: echo \"Please start by listing files\" | adk run file_listing_agent Run the following command, to chat with your Weather agent. adk run multi_tool_agent To exit, use Cmd/Ctrl+C. adk api_server enables you to create a local FastAPI server in a single\ncommand, enabling you to test local cURL requests before you deploy your\nagent. To learn how to use adk api_server for testing, refer to the documentation on using the API server . Using the terminal, navigate to the parent directory of your agent project\n(e.g. using cd .. ): project_folder/                <-- navigate to this directory \u251c\u2500\u2500 pom.xml (or build.gradle) \u251c\u2500\u2500 src/ \u251c\u2500\u2500 \u2514\u2500\u2500 main/ \u2502       \u2514\u2500\u2500 java/ \u2502           \u2514\u2500\u2500 agents/ \u2502               \u2514\u2500\u2500 multitool/ \u2502                   \u2514\u2500\u2500 MultiToolAgent.java \u2514\u2500\u2500 test/ Dev UI Maven Gradle Run the following command from the terminal to launch the Dev UI. DO NOT change the main class name of the Dev UI server. terminal mvn exec:java \\ -Dexec.mainClass=\"com.google.adk.web.AdkWebServer\" \\ -Dexec.args=\"--adk.agents.source-dir=src/main/java\" \\ -Dexec.classpathScope=\"compile\" Step 1: Open the URL provided (usually http://localhost:8080 or http://127.0.0.1:8080 ) directly in your browser. Step 2. In the top-left corner of the UI, you can select your agent in\nthe dropdown. Select \"multi_tool_agent\". Troubleshooting If you do not see \"multi_tool_agent\" in the dropdown menu, make sure you\nare running the mvn command at the location where your Java source code\nis located (usually src/main/java ). Step 3. Now you can chat with your agent using the textbox: Step 4. You can also inspect individual function calls, responses and\nmodel responses by clicking on the actions: With Maven, run the main() method of your Java class\nwith the following command: terminal mvn compile exec:java -Dexec.mainClass=\"agents.multitool.MultiToolAgent\" With Gradle, the build.gradle or build.gradle.kts build file\nshould have the following Java plugin in its plugins section: plugins { id ( 'java' ) // other plugins } Then, elsewhere in the build file, at the top-level,\ncreate a new task to run the main() method of your agent: tasks . register ( 'runAgent' , JavaExec ) { classpath = sourceSets . main . runtimeClasspath mainClass = 'agents.multitool.MultiToolAgent' } Finally, on the command-line, run the following command: gradle runAgent ", "code_blocks": [{"language": "text", "code": "parent_folder/      <-- navigate to this directory\n    multi_tool_agent/\n        __init__.py\n        agent.py\n        .env"}, {"language": "text", "code": "gcloud auth application-default login"}, {"language": "text", "code": "adk web"}, {"language": "text", "code": "root_agent = Agent(\n    name=\"weather_time_agent\",\n    model=\"replace-me-with-model-id\", #e.g. gemini-2.0-flash-live-001\n    ..."}, {"language": "text", "code": "echo \"Please start by listing files\" | adk run file_listing_agent"}, {"language": "text", "code": "adk run multi_tool_agent"}, {"language": "text", "code": "project_folder/                <-- navigate to this directory\n\u251c\u2500\u2500 pom.xml (or build.gradle)\n\u251c\u2500\u2500 src/\n\u251c\u2500\u2500 \u2514\u2500\u2500 main/\n\u2502       \u2514\u2500\u2500 java/\n\u2502           \u2514\u2500\u2500 agents/\n\u2502               \u2514\u2500\u2500 multitool/\n\u2502                   \u2514\u2500\u2500 MultiToolAgent.java\n\u2514\u2500\u2500 test/"}, {"language": "text", "code": "mvn exec:java \\\n    -Dexec.mainClass=\"com.google.adk.web.AdkWebServer\" \\\n    -Dexec.args=\"--adk.agents.source-dir=src/main/java\" \\\n    -Dexec.classpathScope=\"compile\""}, {"language": "text", "code": "mvn compile exec:java -Dexec.mainClass=\"agents.multitool.MultiToolAgent\""}, {"language": "text", "code": "plugins {\n    id('java')\n    // other plugins\n}"}, {"language": "text", "code": "tasks.register('runAgent', JavaExec) {\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'agents.multitool.MultiToolAgent'\n}"}, {"language": "text", "code": "gradle runAgent"}]}, {"heading_path": ["\ud83d\udcdd Example prompts to try\u00b6"], "text": "\ud83d\udcdd Example prompts to try \u00b6 What is the weather in New York? What is the time in New York? What is the weather in Paris? What is the time in Paris? ", "code_blocks": []}, {"heading_path": ["\ud83c\udf89 Congratulations!\u00b6"], "text": "\ud83c\udf89 Congratulations! \u00b6 You've successfully created and interacted with your first agent using ADK! ", "code_blocks": []}, {"heading_path": ["\ud83d\udee3\ufe0f Next steps\u00b6"], "text": "\ud83d\udee3\ufe0f Next steps \u00b6 Go to the tutorial : Learn how to add memory, session, state to your agent: tutorial . Delve into advanced configuration: Explore the setup section for deeper dives into project structure, configuration, and other\n  interfaces. Understand Core Concepts: Learn about agents concepts . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:00.899489", "source_type": "adk-docs"}
{"doc_id": "62b0c9635661513d8eafadb01eae08f60ed10912cf49262c0713ca644ae04926", "url": "https://google.github.io/adk-docs/tutorials/agent-team", "title": "Agent team - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Build Your First Intelligent Agent Team: A Progressive Weather Bot with ADK\u00b6"], "text": "Build Your First Intelligent Agent Team: A Progressive Weather Bot with ADK \u00b6 Optional outer container for overall padding/spacing Line 1: Open in Colab This div ensures the link takes up its own line and adds space below Open in Colab Line 2: Share Links This div acts as a flex container for the \"Share to\" text and icons Share Text Share to: Social Media Links This tutorial extends from the Quickstart example for Agent Development Kit . Now, you're ready to dive deeper and construct a more sophisticated, multi-agent system . We'll embark on building a Weather Bot agent team , progressively layering advanced features onto a simple foundation. Starting with a single agent that can look up weather, we will incrementally add capabilities like: Leveraging different AI models (Gemini, GPT, Claude). Designing specialized sub-agents for distinct tasks (like greetings and farewells). Enabling intelligent delegation between agents. Giving agents memory using persistent session state. Implementing crucial safety guardrails using callbacks. Why a Weather Bot Team? This use case, while seemingly simple, provides a practical and relatable canvas to explore core ADK concepts essential for building complex, real-world agentic applications. You'll learn how to structure interactions, manage state, ensure safety, and orchestrate multiple AI \"brains\" working together. What is ADK Again? As a reminder, ADK is a Python framework designed to streamline the development of applications powered by Large Language Models (LLMs). It offers robust building blocks for creating agents that can reason, plan, utilize tools, interact dynamically with users, and collaborate effectively within a team. In this advanced tutorial, you will master: \u2705 Tool Definition & Usage: Crafting Python functions ( tools ) that grant agents specific abilities (like fetching data) and instructing agents on how to use them effectively. \u2705 Multi-LLM Flexibility: Configuring agents to utilize various leading LLMs (Gemini, GPT-4o, Claude Sonnet) via LiteLLM integration, allowing you to choose the best model for each task. \u2705 Agent Delegation & Collaboration: Designing specialized sub-agents and enabling automatic routing ( auto flow ) of user requests to the most appropriate agent within a team. \u2705 Session State for Memory: Utilizing Session State and ToolContext to enable agents to remember information across conversational turns, leading to more contextual interactions. \u2705 Safety Guardrails with Callbacks: Implementing before_model_callback and before_tool_callback to inspect, modify, or block requests/tool usage based on predefined rules, enhancing application safety and control. End State Expectation: By completing this tutorial, you will have built a functional multi-agent Weather Bot system. This system will not only provide weather information but also handle conversational niceties, remember the last city checked, and operate within defined safety boundaries, all orchestrated using ADK. Prerequisites: \u2705 Solid understanding of Python programming. \u2705 Familiarity with Large Language Models (LLMs), APIs, and the concept of agents. \u2757 Crucially: Completion of the ADK Quickstart tutorial(s) or equivalent foundational knowledge of ADK basics (Agent, Runner, SessionService, basic Tool usage). This tutorial builds directly upon those concepts. \u2705 API Keys for the LLMs you intend to use (e.g., Google AI Studio for Gemini, OpenAI Platform, Anthropic Console). Note on Execution Environment: This tutorial is structured for interactive notebook environments like Google Colab, Colab Enterprise, or Jupyter notebooks. Please keep the following in mind: Running Async Code: Notebook environments handle asynchronous code differently. You'll see examples using await (suitable when an event loop is already running, common in notebooks) or asyncio.run() (often needed when running as a standalone .py script or in specific notebook setups). The code blocks provide guidance for both scenarios. Manual Runner/Session Setup: The steps involve explicitly creating Runner and SessionService instances. This approach is shown because it gives you fine-grained control over the agent's execution lifecycle, session management, and state persistence. Alternative: Using ADK's Built-in Tools (Web UI / CLI / API Server) If you prefer a setup that handles the runner and session management automatically using ADK's standard tools, you can find the equivalent code structured for that purpose here . That version is designed to be run directly with commands like adk web (for a web UI), adk run (for CLI interaction), or adk api_server (to expose an API). Please follow the README.md instructions provided in that alternative resource. Ready to build your agent team? Let's dive in! Note: This tutorial works with adk version 1.0.0 and above # @title Step 0: Setup and Installation # Install ADK and LiteLLM for multi-model support ! pip install google - adk - q ! pip install litellm - q print ( \"Installation complete.\" ) # @title Import necessary libraries import os import asyncio from google.adk.agents import Agent from google.adk.models.lite_llm import LiteLlm # For multi-model support from google.adk.sessions import InMemorySessionService from google.adk.runners import Runner from google.genai import types # For creating message Content/Parts import warnings # Ignore all warnings warnings . filterwarnings ( \"ignore\" ) import logging logging . basicConfig ( level = logging . ERROR ) print ( \"Libraries imported.\" ) # @title Configure API Keys (Replace with your actual keys!) # --- IMPORTANT: Replace placeholders with your real API keys --- # Gemini API Key (Get from Google AI Studio: https://aistudio.google.com/app/apikey) os . environ [ \"GOOGLE_API_KEY\" ] = \"YOUR_GOOGLE_API_KEY\" # <--- REPLACE # [Optional] # OpenAI API Key (Get from OpenAI Platform: https://platform.openai.com/api-keys) os . environ [ 'OPENAI_API_KEY' ] = 'YOUR_OPENAI_API_KEY' # <--- REPLACE # [Optional] # Anthropic API Key (Get from Anthropic Console: https://console.anthropic.com/settings/keys) os . environ [ 'ANTHROPIC_API_KEY' ] = 'YOUR_ANTHROPIC_API_KEY' # <--- REPLACE # --- Verify Keys (Optional Check) --- print ( \"API Keys Set:\" ) print ( f \"Google API Key set: { 'Yes' if os . environ . get ( 'GOOGLE_API_KEY' ) and os . environ [ 'GOOGLE_API_KEY' ] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)' } \" ) print ( f \"OpenAI API Key set: { 'Yes' if os . environ . get ( 'OPENAI_API_KEY' ) and os . environ [ 'OPENAI_API_KEY' ] != 'YOUR_OPENAI_API_KEY' else 'No (REPLACE PLACEHOLDER!)' } \" ) print ( f \"Anthropic API Key set: { 'Yes' if os . environ . get ( 'ANTHROPIC_API_KEY' ) and os . environ [ 'ANTHROPIC_API_KEY' ] != 'YOUR_ANTHROPIC_API_KEY' else 'No (REPLACE PLACEHOLDER!)' } \" ) # Configure ADK to use API keys directly (not Vertex AI for this multi-model setup) os . environ [ \"GOOGLE_GENAI_USE_VERTEXAI\" ] = \"False\" # @markdown **Security Note:** It's best practice to manage API keys securely (e.g., using Colab Secrets or environment variables) rather than hardcoding them directly in the notebook. Replace the placeholder strings above. # --- Define Model Constants for easier use --- # More supported models can be referenced here: https://ai.google.dev/gemini-api/docs/models#model-variations MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\" # More supported models can be referenced here: https://docs.litellm.ai/docs/providers/openai#openai-chat-completion-models MODEL_GPT_4O = \"openai/gpt-4.1\" # You can also try: gpt-4.1-mini, gpt-4o etc. # More supported models can be referenced here: https://docs.litellm.ai/docs/providers/anthropic MODEL_CLAUDE_SONNET = \"anthropic/claude-sonnet-4-20250514\" # You can also try: claude-opus-4-20250514 , claude-3-7-sonnet-20250219 etc print ( \" \\n Environment configured.\" ) ", "code_blocks": [{"language": "text", "code": "# @title Step 0: Setup and Installation\n# Install ADK and LiteLLM for multi-model support\n\n!pip install google-adk -q\n!pip install litellm -q\n\nprint(\"Installation complete.\")"}, {"language": "text", "code": "# @title Import necessary libraries\nimport os\nimport asyncio\nfrom google.adk.agents import Agent\nfrom google.adk.models.lite_llm import LiteLlm # For multi-model support\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.runners import Runner\nfrom google.genai import types # For creating message Content/Parts\n\nimport warnings\n# Ignore all warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport logging\nlogging.basicConfig(level=logging.ERROR)\n\nprint(\"Libraries imported.\")"}, {"language": "text", "code": "# @title Configure API Keys (Replace with your actual keys!)\n\n# --- IMPORTANT: Replace placeholders with your real API keys ---\n\n# Gemini API Key (Get from Google AI Studio: https://aistudio.google.com/app/apikey)\nos.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GOOGLE_API_KEY\" # <--- REPLACE\n\n# [Optional]\n# OpenAI API Key (Get from OpenAI Platform: https://platform.openai.com/api-keys)\nos.environ['OPENAI_API_KEY'] = 'YOUR_OPENAI_API_KEY' # <--- REPLACE\n\n# [Optional]\n# Anthropic API Key (Get from Anthropic Console: https://console.anthropic.com/settings/keys)\nos.environ['ANTHROPIC_API_KEY'] = 'YOUR_ANTHROPIC_API_KEY' # <--- REPLACE\n\n# --- Verify Keys (Optional Check) ---\nprint(\"API Keys Set:\")\nprint(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\nprint(f\"OpenAI API Key set: {'Yes' if os.environ.get('OPENAI_API_KEY') and os.environ['OPENAI_API_KEY'] != 'YOUR_OPENAI_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\nprint(f\"Anthropic API Key set: {'Yes' if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'YOUR_ANTHROPIC_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n\n# Configure ADK to use API keys directly (not Vertex AI for this multi-model setup)\nos.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n\n\n# @markdown **Security Note:** It's best practice to manage API keys securely (e.g., using Colab Secrets or environment variables) rather than hardcoding them directly in the notebook. Replace the placeholder strings above."}, {"language": "text", "code": "# --- Define Model Constants for easier use ---\n\n# More supported models can be referenced here: https://ai.google.dev/gemini-api/docs/models#model-variations\nMODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\"\n\n# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/openai#openai-chat-completion-models\nMODEL_GPT_4O = \"openai/gpt-4.1\" # You can also try: gpt-4.1-mini, gpt-4o etc.\n\n# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/anthropic\nMODEL_CLAUDE_SONNET = \"anthropic/claude-sonnet-4-20250514\" # You can also try: claude-opus-4-20250514 , claude-3-7-sonnet-20250219 etc\n\nprint(\"\\nEnvironment configured.\")"}]}, {"heading_path": ["Step 1: Your First Agent - Basic Weather Lookup\u00b6"], "text": "Step 1: Your First Agent - Basic Weather Lookup \u00b6 Let's begin by building the fundamental component of our Weather Bot: a single agent capable of performing a specific task \u2013 looking up weather information. This involves creating two core pieces: A Tool: A Python function that equips the agent with the ability to fetch weather data. An Agent: The AI \"brain\" that understands the user's request, knows it has a weather tool, and decides when and how to use it. 1. Define the Tool ( get_weather ) In ADK, Tools are the building blocks that give agents concrete capabilities beyond just text generation. They are typically regular Python functions that perform specific actions, like calling an API, querying a database, or performing calculations. Our first tool will provide a mock weather report. This allows us to focus on the agent structure without needing external API keys yet. Later, you could easily swap this mock function with one that calls a real weather service. Key Concept: Docstrings are Crucial! The agent's LLM relies heavily on the function's docstring to understand: What the tool does. When to use it. What arguments it requires ( city: str ). What information it returns. Best Practice: Write clear, descriptive, and accurate docstrings for your tools. This is essential for the LLM to use the tool correctly. # @title Define the get_weather Tool def get_weather ( city : str ) -> dict : \"\"\"Retrieves the current weather report for a specified city. Args: city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\"). Returns: dict: A dictionary containing the weather information. Includes a 'status' key ('success' or 'error'). If 'success', includes a 'report' key with weather details. If 'error', includes an 'error_message' key. \"\"\" print ( f \"--- Tool: get_weather called for city: { city } ---\" ) # Log tool execution city_normalized = city . lower () . replace ( \" \" , \"\" ) # Basic normalization # Mock weather data mock_weather_db = { \"newyork\" : { \"status\" : \"success\" , \"report\" : \"The weather in New York is sunny with a temperature of 25\u00b0C.\" }, \"london\" : { \"status\" : \"success\" , \"report\" : \"It's cloudy in London with a temperature of 15\u00b0C.\" }, \"tokyo\" : { \"status\" : \"success\" , \"report\" : \"Tokyo is experiencing light rain and a temperature of 18\u00b0C.\" }, } if city_normalized in mock_weather_db : return mock_weather_db [ city_normalized ] else : return { \"status\" : \"error\" , \"error_message\" : f \"Sorry, I don't have weather information for ' { city } '.\" } # Example tool usage (optional test) print ( get_weather ( \"New York\" )) print ( get_weather ( \"Paris\" )) 2. Define the Agent ( weather_agent ) Now, let's create the Agent itself. An Agent in ADK orchestrates the interaction between the user, the LLM, and the available tools. We configure it with several key parameters: name : A unique identifier for this agent (e.g., \"weather_agent_v1\"). model : Specifies which LLM to use (e.g., MODEL_GEMINI_2_0_FLASH ). We'll start with a specific Gemini model. description : A concise summary of the agent's overall purpose. This becomes crucial later when other agents need to decide whether to delegate tasks to this agent. instruction : Detailed guidance for the LLM on how to behave, its persona, its goals, and specifically how and when to utilize its assigned tools . tools : A list containing the actual Python tool functions the agent is allowed to use (e.g., [get_weather] ). Best Practice: Provide clear and specific instruction prompts. The more detailed the instructions, the better the LLM can understand its role and how to use its tools effectively. Be explicit about error handling if needed. Best Practice: Choose descriptive name and description values. These are used internally by ADK and are vital for features like automatic delegation (covered later). # @title Define the Weather Agent # Use one of the model constants defined earlier AGENT_MODEL = MODEL_GEMINI_2_0_FLASH # Starting with Gemini weather_agent = Agent ( name = \"weather_agent_v1\" , model = AGENT_MODEL , # Can be a string for Gemini or a LiteLlm object description = \"Provides weather information for specific cities.\" , instruction = \"You are a helpful weather assistant. \" \"When the user asks for the weather in a specific city, \" \"use the 'get_weather' tool to find the information. \" \"If the tool returns an error, inform the user politely. \" \"If the tool is successful, present the weather report clearly.\" , tools = [ get_weather ], # Pass the function directly ) print ( f \"Agent ' { weather_agent . name } ' created using model ' { AGENT_MODEL } '.\" ) 3. Setup Runner and Session Service To manage conversations and execute the agent, we need two more components: SessionService : Responsible for managing conversation history and state for different users and sessions. The InMemorySessionService is a simple implementation that stores everything in memory, suitable for testing and simple applications. It keeps track of the messages exchanged. We'll explore state persistence more in Step 4. Runner : The engine that orchestrates the interaction flow. It takes user input, routes it to the appropriate agent, manages calls to the LLM and tools based on the agent's logic, handles session updates via the SessionService , and yields events representing the progress of the interaction. # @title Setup Session Service and Runner # --- Session Management --- # Key Concept: SessionService stores conversation history & state. # InMemorySessionService is simple, non-persistent storage for this tutorial. session_service = InMemorySessionService () # Define constants for identifying the interaction context APP_NAME = \"weather_tutorial_app\" USER_ID = \"user_1\" SESSION_ID = \"session_001\" # Using a fixed ID for simplicity # Create the specific session where the conversation will happen session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) print ( f \"Session created: App=' { APP_NAME } ', User=' { USER_ID } ', Session=' { SESSION_ID } '\" ) # --- Runner --- # Key Concept: Runner orchestrates the agent execution loop. runner = Runner ( agent = weather_agent , # The agent we want to run app_name = APP_NAME , # Associates runs with our app session_service = session_service # Uses our session manager ) print ( f \"Runner created for agent ' { runner . agent . name } '.\" ) 4. Interact with the Agent We need a way to send messages to our agent and receive its responses. Since LLM calls and tool executions can take time, ADK's Runner operates asynchronously. We'll define an async helper function ( call_agent_async ) that: Takes a user query string. Packages it into the ADK Content format. Calls runner.run_async , providing the user/session context and the new message. Iterates through the Events yielded by the runner. Events represent steps in the agent's execution (e.g., tool call requested, tool result received, intermediate LLM thought, final response). Identifies and prints the final response event using event.is_final_response() . Why async ? Interactions with LLMs and potentially tools (like external APIs) are I/O-bound operations. Using asyncio allows the program to handle these operations efficiently without blocking execution. # @title Define Agent Interaction Function from google.genai import types # For creating message Content/Parts async def call_agent_async ( query : str , runner , user_id , session_id ): \"\"\"Sends a query to the agent and prints the final response.\"\"\" print ( f \" \\n >>> User Query: { query } \" ) # Prepare the user's message in ADK format content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) final_response_text = \"Agent did not produce a final response.\" # Default # Key Concept: run_async executes the agent logic and yields Events. # We iterate through events to find the final answer. async for event in runner . run_async ( user_id = user_id , session_id = session_id , new_message = content ): # You can uncomment the line below to see *all* events during execution # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\") # Key Concept: is_final_response() marks the concluding message for the turn. if event . is_final_response (): if event . content and event . content . parts : # Assuming text response in the first part final_response_text = event . content . parts [ 0 ] . text elif event . actions and event . actions . escalate : # Handle potential errors/escalations final_response_text = f \"Agent escalated: { event . error_message or 'No specific message.' } \" # Add more checks here if needed (e.g., specific error codes) break # Stop processing events once the final response is found print ( f \"<<< Agent Response: { final_response_text } \" ) 5. Run the Conversation Finally, let's test our setup by sending a few queries to the agent. We wrap our async calls in a main async function and run it using await . Watch the output: See the user queries. Notice the --- Tool: get_weather called... --- logs when the agent uses the tool. Observe the agent's final responses, including how it handles the case where weather data isn't available (for Paris). # @title Run the Initial Conversation # We need an async function to await our interaction helper async def run_conversation (): await call_agent_async ( \"What is the weather like in London?\" , runner = runner , user_id = USER_ID , session_id = SESSION_ID ) await call_agent_async ( \"How about Paris?\" , runner = runner , user_id = USER_ID , session_id = SESSION_ID ) # Expecting the tool's error message await call_agent_async ( \"Tell me the weather in New York\" , runner = runner , user_id = USER_ID , session_id = SESSION_ID ) # Execute the conversation using await in an async context (like Colab/Jupyter) await run_conversation () # --- OR --- # Uncomment the following lines if running as a standard Python script (.py file): # import asyncio # if __name__ == \"__main__\": #     try: #         asyncio.run(run_conversation()) #     except Exception as e: #         print(f\"An error occurred: {e}\") Congratulations! You've successfully built and interacted with your first ADK agent. It understands the user's request, uses a tool to find information, and responds appropriately based on the tool's result. In the next step, we'll explore how to easily switch the underlying Language Model powering this agent. ", "code_blocks": [{"language": "text", "code": "# @title Define the get_weather Tool\ndef get_weather(city: str) -> dict:\n    \"\"\"Retrieves the current weather report for a specified city.\n\n    Args:\n        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n\n    Returns:\n        dict: A dictionary containing the weather information.\n              Includes a 'status' key ('success' or 'error').\n              If 'success', includes a 'report' key with weather details.\n              If 'error', includes an 'error_message' key.\n    \"\"\"\n    print(f\"--- Tool: get_weather called for city: {city} ---\") # Log tool execution\n    city_normalized = city.lower().replace(\" \", \"\") # Basic normalization\n\n    # Mock weather data\n    mock_weather_db = {\n        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25\u00b0C.\"},\n        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15\u00b0C.\"},\n        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18\u00b0C.\"},\n    }\n\n    if city_normalized in mock_weather_db:\n        return mock_weather_db[city_normalized]\n    else:\n        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n\n# Example tool usage (optional test)\nprint(get_weather(\"New York\"))\nprint(get_weather(\"Paris\"))"}, {"language": "text", "code": "# @title Define the Weather Agent\n# Use one of the model constants defined earlier\nAGENT_MODEL = MODEL_GEMINI_2_0_FLASH # Starting with Gemini\n\nweather_agent = Agent(\n    name=\"weather_agent_v1\",\n    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n    description=\"Provides weather information for specific cities.\",\n    instruction=\"You are a helpful weather assistant. \"\n                \"When the user asks for the weather in a specific city, \"\n                \"use the 'get_weather' tool to find the information. \"\n                \"If the tool returns an error, inform the user politely. \"\n                \"If the tool is successful, present the weather report clearly.\",\n    tools=[get_weather], # Pass the function directly\n)\n\nprint(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")"}, {"language": "text", "code": "# @title Setup Session Service and Runner\n\n# --- Session Management ---\n# Key Concept: SessionService stores conversation history & state.\n# InMemorySessionService is simple, non-persistent storage for this tutorial.\nsession_service = InMemorySessionService()\n\n# Define constants for identifying the interaction context\nAPP_NAME = \"weather_tutorial_app\"\nUSER_ID = \"user_1\"\nSESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n\n# Create the specific session where the conversation will happen\nsession = await session_service.create_session(\n    app_name=APP_NAME,\n    user_id=USER_ID,\n    session_id=SESSION_ID\n)\nprint(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n\n# --- Runner ---\n# Key Concept: Runner orchestrates the agent execution loop.\nrunner = Runner(\n    agent=weather_agent, # The agent we want to run\n    app_name=APP_NAME,   # Associates runs with our app\n    session_service=session_service # Uses our session manager\n)\nprint(f\"Runner created for agent '{runner.agent.name}'.\")"}, {"language": "text", "code": "# @title Define Agent Interaction Function\n\nfrom google.genai import types # For creating message Content/Parts\n\nasync def call_agent_async(query: str, runner, user_id, session_id):\n  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n  print(f\"\\n>>> User Query: {query}\")\n\n  # Prepare the user's message in ADK format\n  content = types.Content(role='user', parts=[types.Part(text=query)])\n\n  final_response_text = \"Agent did not produce a final response.\" # Default\n\n  # Key Concept: run_async executes the agent logic and yields Events.\n  # We iterate through events to find the final answer.\n  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n      # You can uncomment the line below to see *all* events during execution\n      # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n\n      # Key Concept: is_final_response() marks the concluding message for the turn.\n      if event.is_final_response():\n          if event.content and event.content.parts:\n             # Assuming text response in the first part\n             final_response_text = event.content.parts[0].text\n          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n          # Add more checks here if needed (e.g., specific error codes)\n          break # Stop processing events once the final response is found\n\n  print(f\"<<< Agent Response: {final_response_text}\")"}, {"language": "text", "code": "# @title Run the Initial Conversation\n\n# We need an async function to await our interaction helper\nasync def run_conversation():\n    await call_agent_async(\"What is the weather like in London?\",\n                                       runner=runner,\n                                       user_id=USER_ID,\n                                       session_id=SESSION_ID)\n\n    await call_agent_async(\"How about Paris?\",\n                                       runner=runner,\n                                       user_id=USER_ID,\n                                       session_id=SESSION_ID) # Expecting the tool's error message\n\n    await call_agent_async(\"Tell me the weather in New York\",\n                                       runner=runner,\n                                       user_id=USER_ID,\n                                       session_id=SESSION_ID)\n\n# Execute the conversation using await in an async context (like Colab/Jupyter)\nawait run_conversation()\n\n# --- OR ---\n\n# Uncomment the following lines if running as a standard Python script (.py file):\n# import asyncio\n# if __name__ == \"__main__\":\n#     try:\n#         asyncio.run(run_conversation())\n#     except Exception as e:\n#         print(f\"An error occurred: {e}\")"}]}, {"heading_path": ["Step 2: Going Multi-Model with LiteLLM [Optional]\u00b6"], "text": "Step 2: Going Multi-Model with LiteLLM [Optional] \u00b6 In Step 1, we built a functional Weather Agent powered by a specific Gemini model. While effective, real-world applications often benefit from the flexibility to use different Large Language Models (LLMs). Why? Performance: Some models excel at specific tasks (e.g., coding, reasoning, creative writing). Cost: Different models have varying price points. Capabilities: Models offer diverse features, context window sizes, and fine-tuning options. Availability/Redundancy: Having alternatives ensures your application remains functional even if one provider experiences issues. ADK makes switching between models seamless through its integration with the LiteLLM library. LiteLLM acts as a consistent interface to over 100 different LLMs. In this step, we will: Learn how to configure an ADK Agent to use models from providers like OpenAI (GPT) and Anthropic (Claude) using the LiteLlm wrapper. Define, configure (with their own sessions and runners), and immediately test instances of our Weather Agent, each backed by a different LLM. Interact with these different agents to observe potential variations in their responses, even when using the same underlying tool. 1. Import LiteLlm We imported this during the initial setup (Step 0), but it's the key component for multi-model support: # @title 1. Import LiteLlm from google.adk.models.lite_llm import LiteLlm 2. Define and Test Multi-Model Agents Instead of passing only a model name string (which defaults to Google's Gemini models), we wrap the desired model identifier string within the LiteLlm class. Key Concept: LiteLlm Wrapper: The LiteLlm(model=\"provider/model_name\") syntax tells ADK to route requests for this agent through the LiteLLM library to the specified model provider. Make sure you have configured the necessary API keys for OpenAI and Anthropic in Step 0. We'll use the call_agent_async function (defined earlier, which now accepts runner , user_id , and session_id ) to interact with each agent immediately after its setup. Each block below will: Define the agent using a specific LiteLLM model ( MODEL_GPT_4O or MODEL_CLAUDE_SONNET ). Create a new, separate InMemorySessionService and session specifically for that agent's test run. This keeps the conversation histories isolated for this demonstration. Create a Runner configured for the specific agent and its session service. Immediately call call_agent_async to send a query and test the agent. Best Practice: Use constants for model names (like MODEL_GPT_4O , MODEL_CLAUDE_SONNET defined in Step 0) to avoid typos and make code easier to manage. Error Handling: We wrap the agent definitions in try...except blocks. This prevents the entire code cell from failing if an API key for a specific provider is missing or invalid, allowing the tutorial to proceed with the models that are configured. First, let's create and test the agent using OpenAI's GPT-4o. # @title Define and Test GPT Agent # Make sure 'get_weather' function from Step 1 is defined in your environment. # Make sure 'call_agent_async' is defined from earlier. # --- Agent using GPT-4o --- weather_agent_gpt = None # Initialize to None runner_gpt = None # Initialize runner to None try : weather_agent_gpt = Agent ( name = \"weather_agent_gpt\" , # Key change: Wrap the LiteLLM model identifier model = LiteLlm ( model = MODEL_GPT_4O ), description = \"Provides weather information (using GPT-4o).\" , instruction = \"You are a helpful weather assistant powered by GPT-4o. \" \"Use the 'get_weather' tool for city weather requests. \" \"Clearly present successful reports or polite error messages based on the tool's output status.\" , tools = [ get_weather ], # Re-use the same tool ) print ( f \"Agent ' { weather_agent_gpt . name } ' created using model ' { MODEL_GPT_4O } '.\" ) # InMemorySessionService is simple, non-persistent storage for this tutorial. session_service_gpt = InMemorySessionService () # Create a dedicated service # Define constants for identifying the interaction context APP_NAME_GPT = \"weather_tutorial_app_gpt\" # Unique app name for this test USER_ID_GPT = \"user_1_gpt\" SESSION_ID_GPT = \"session_001_gpt\" # Using a fixed ID for simplicity # Create the specific session where the conversation will happen session_gpt = await session_service_gpt . create_session ( app_name = APP_NAME_GPT , user_id = USER_ID_GPT , session_id = SESSION_ID_GPT ) print ( f \"Session created: App=' { APP_NAME_GPT } ', User=' { USER_ID_GPT } ', Session=' { SESSION_ID_GPT } '\" ) # Create a runner specific to this agent and its session service runner_gpt = Runner ( agent = weather_agent_gpt , app_name = APP_NAME_GPT , # Use the specific app name session_service = session_service_gpt # Use the specific session service ) print ( f \"Runner created for agent ' { runner_gpt . agent . name } '.\" ) # --- Test the GPT Agent --- print ( \" \\n --- Testing GPT Agent ---\" ) # Ensure call_agent_async uses the correct runner, user_id, session_id await call_agent_async ( query = \"What's the weather in Tokyo?\" , runner = runner_gpt , user_id = USER_ID_GPT , session_id = SESSION_ID_GPT ) # --- OR --- # Uncomment the following lines if running as a standard Python script (.py file): # import asyncio # if __name__ == \"__main__\": #     try: #         asyncio.run(call_agent_async(query = \"What's the weather in Tokyo?\", #                      runner=runner_gpt, #                       user_id=USER_ID_GPT, #                       session_id=SESSION_ID_GPT) #     except Exception as e: #         print(f\"An error occurred: {e}\") except Exception as e : print ( f \"\u274c Could not create or run GPT agent ' { MODEL_GPT_4O } '. Check API Key and model name. Error: { e } \" ) Next, we'll do the same for Anthropic's Claude Sonnet. # @title Define and Test Claude Agent # Make sure 'get_weather' function from Step 1 is defined in your environment. # Make sure 'call_agent_async' is defined from earlier. # --- Agent using Claude Sonnet --- weather_agent_claude = None # Initialize to None runner_claude = None # Initialize runner to None try : weather_agent_claude = Agent ( name = \"weather_agent_claude\" , # Key change: Wrap the LiteLLM model identifier model = LiteLlm ( model = MODEL_CLAUDE_SONNET ), description = \"Provides weather information (using Claude Sonnet).\" , instruction = \"You are a helpful weather assistant powered by Claude Sonnet. \" \"Use the 'get_weather' tool for city weather requests. \" \"Analyze the tool's dictionary output ('status', 'report'/'error_message'). \" \"Clearly present successful reports or polite error messages.\" , tools = [ get_weather ], # Re-use the same tool ) print ( f \"Agent ' { weather_agent_claude . name } ' created using model ' { MODEL_CLAUDE_SONNET } '.\" ) # InMemorySessionService is simple, non-persistent storage for this tutorial. session_service_claude = InMemorySessionService () # Create a dedicated service # Define constants for identifying the interaction context APP_NAME_CLAUDE = \"weather_tutorial_app_claude\" # Unique app name USER_ID_CLAUDE = \"user_1_claude\" SESSION_ID_CLAUDE = \"session_001_claude\" # Using a fixed ID for simplicity # Create the specific session where the conversation will happen session_claude = await session_service_claude . create_session ( app_name = APP_NAME_CLAUDE , user_id = USER_ID_CLAUDE , session_id = SESSION_ID_CLAUDE ) print ( f \"Session created: App=' { APP_NAME_CLAUDE } ', User=' { USER_ID_CLAUDE } ', Session=' { SESSION_ID_CLAUDE } '\" ) # Create a runner specific to this agent and its session service runner_claude = Runner ( agent = weather_agent_claude , app_name = APP_NAME_CLAUDE , # Use the specific app name session_service = session_service_claude # Use the specific session service ) print ( f \"Runner created for agent ' { runner_claude . agent . name } '.\" ) # --- Test the Claude Agent --- print ( \" \\n --- Testing Claude Agent ---\" ) # Ensure call_agent_async uses the correct runner, user_id, session_id await call_agent_async ( query = \"Weather in London please.\" , runner = runner_claude , user_id = USER_ID_CLAUDE , session_id = SESSION_ID_CLAUDE ) # --- OR --- # Uncomment the following lines if running as a standard Python script (.py file): # import asyncio # if __name__ == \"__main__\": #     try: #         asyncio.run(call_agent_async(query = \"Weather in London please.\", #                      runner=runner_claude, #                       user_id=USER_ID_CLAUDE, #                       session_id=SESSION_ID_CLAUDE) #     except Exception as e: #         print(f\"An error occurred: {e}\") except Exception as e : print ( f \"\u274c Could not create or run Claude agent ' { MODEL_CLAUDE_SONNET } '. Check API Key and model name. Error: { e } \" ) Observe the output carefully from both code blocks. You should see: Each agent ( weather_agent_gpt , weather_agent_claude ) is created successfully (if API keys are valid). A dedicated session and runner are set up for each. Each agent correctly identifies the need to use the get_weather tool when processing the query (you'll see the --- Tool: get_weather called... --- log). The underlying tool logic remains identical, always returning our mock data. However, the final textual response generated by each agent might differ slightly in phrasing, tone, or formatting. This is because the instruction prompt is interpreted and executed by different LLMs (GPT-4o vs. Claude Sonnet). This step demonstrates the power and flexibility ADK + LiteLLM provide. You can easily experiment with and deploy agents using various LLMs while keeping your core application logic (tools, fundamental agent structure) consistent. In the next step, we'll move beyond a single agent and build a small team where agents can delegate tasks to each other! ", "code_blocks": [{"language": "text", "code": "# @title 1. Import LiteLlm\nfrom google.adk.models.lite_llm import LiteLlm"}, {"language": "text", "code": "# @title Define and Test GPT Agent\n\n# Make sure 'get_weather' function from Step 1 is defined in your environment.\n# Make sure 'call_agent_async' is defined from earlier.\n\n# --- Agent using GPT-4o ---\nweather_agent_gpt = None # Initialize to None\nrunner_gpt = None      # Initialize runner to None\n\ntry:\n    weather_agent_gpt = Agent(\n        name=\"weather_agent_gpt\",\n        # Key change: Wrap the LiteLLM model identifier\n        model=LiteLlm(model=MODEL_GPT_4O),\n        description=\"Provides weather information (using GPT-4o).\",\n        instruction=\"You are a helpful weather assistant powered by GPT-4o. \"\n                    \"Use the 'get_weather' tool for city weather requests. \"\n                    \"Clearly present successful reports or polite error messages based on the tool's output status.\",\n        tools=[get_weather], # Re-use the same tool\n    )\n    print(f\"Agent '{weather_agent_gpt.name}' created using model '{MODEL_GPT_4O}'.\")\n\n    # InMemorySessionService is simple, non-persistent storage for this tutorial.\n    session_service_gpt = InMemorySessionService() # Create a dedicated service\n\n    # Define constants for identifying the interaction context\n    APP_NAME_GPT = \"weather_tutorial_app_gpt\" # Unique app name for this test\n    USER_ID_GPT = \"user_1_gpt\"\n    SESSION_ID_GPT = \"session_001_gpt\" # Using a fixed ID for simplicity\n\n    # Create the specific session where the conversation will happen\n    session_gpt = await session_service_gpt.create_session(\n        app_name=APP_NAME_GPT,\n        user_id=USER_ID_GPT,\n        session_id=SESSION_ID_GPT\n    )\n    print(f\"Session created: App='{APP_NAME_GPT}', User='{USER_ID_GPT}', Session='{SESSION_ID_GPT}'\")\n\n    # Create a runner specific to this agent and its session service\n    runner_gpt = Runner(\n        agent=weather_agent_gpt,\n        app_name=APP_NAME_GPT,       # Use the specific app name\n        session_service=session_service_gpt # Use the specific session service\n        )\n    print(f\"Runner created for agent '{runner_gpt.agent.name}'.\")\n\n    # --- Test the GPT Agent ---\n    print(\"\\n--- Testing GPT Agent ---\")\n    # Ensure call_agent_async uses the correct runner, user_id, session_id\n    await call_agent_async(query = \"What's the weather in Tokyo?\",\n                           runner=runner_gpt,\n                           user_id=USER_ID_GPT,\n                           session_id=SESSION_ID_GPT)\n    # --- OR ---\n\n    # Uncomment the following lines if running as a standard Python script (.py file):\n    # import asyncio\n    # if __name__ == \"__main__\":\n    #     try:\n    #         asyncio.run(call_agent_async(query = \"What's the weather in Tokyo?\",\n    #                      runner=runner_gpt,\n    #                       user_id=USER_ID_GPT,\n    #                       session_id=SESSION_ID_GPT)\n    #     except Exception as e:\n    #         print(f\"An error occurred: {e}\")\n\nexcept Exception as e:\n    print(f\"\u274c Could not create or run GPT agent '{MODEL_GPT_4O}'. Check API Key and model name. Error: {e}\")"}, {"language": "text", "code": "# @title Define and Test Claude Agent\n\n# Make sure 'get_weather' function from Step 1 is defined in your environment.\n# Make sure 'call_agent_async' is defined from earlier.\n\n# --- Agent using Claude Sonnet ---\nweather_agent_claude = None # Initialize to None\nrunner_claude = None      # Initialize runner to None\n\ntry:\n    weather_agent_claude = Agent(\n        name=\"weather_agent_claude\",\n        # Key change: Wrap the LiteLLM model identifier\n        model=LiteLlm(model=MODEL_CLAUDE_SONNET),\n        description=\"Provides weather information (using Claude Sonnet).\",\n        instruction=\"You are a helpful weather assistant powered by Claude Sonnet. \"\n                    \"Use the 'get_weather' tool for city weather requests. \"\n                    \"Analyze the tool's dictionary output ('status', 'report'/'error_message'). \"\n                    \"Clearly present successful reports or polite error messages.\",\n        tools=[get_weather], # Re-use the same tool\n    )\n    print(f\"Agent '{weather_agent_claude.name}' created using model '{MODEL_CLAUDE_SONNET}'.\")\n\n    # InMemorySessionService is simple, non-persistent storage for this tutorial.\n    session_service_claude = InMemorySessionService() # Create a dedicated service\n\n    # Define constants for identifying the interaction context\n    APP_NAME_CLAUDE = \"weather_tutorial_app_claude\" # Unique app name\n    USER_ID_CLAUDE = \"user_1_claude\"\n    SESSION_ID_CLAUDE = \"session_001_claude\" # Using a fixed ID for simplicity\n\n    # Create the specific session where the conversation will happen\n    session_claude = await session_service_claude.create_session(\n        app_name=APP_NAME_CLAUDE,\n        user_id=USER_ID_CLAUDE,\n        session_id=SESSION_ID_CLAUDE\n    )\n    print(f\"Session created: App='{APP_NAME_CLAUDE}', User='{USER_ID_CLAUDE}', Session='{SESSION_ID_CLAUDE}'\")\n\n    # Create a runner specific to this agent and its session service\n    runner_claude = Runner(\n        agent=weather_agent_claude,\n        app_name=APP_NAME_CLAUDE,       # Use the specific app name\n        session_service=session_service_claude # Use the specific session service\n        )\n    print(f\"Runner created for agent '{runner_claude.agent.name}'.\")\n\n    # --- Test the Claude Agent ---\n    print(\"\\n--- Testing Claude Agent ---\")\n    # Ensure call_agent_async uses the correct runner, user_id, session_id\n    await call_agent_async(query = \"Weather in London please.\",\n                           runner=runner_claude,\n                           user_id=USER_ID_CLAUDE,\n                           session_id=SESSION_ID_CLAUDE)\n\n    # --- OR ---\n\n    # Uncomment the following lines if running as a standard Python script (.py file):\n    # import asyncio\n    # if __name__ == \"__main__\":\n    #     try:\n    #         asyncio.run(call_agent_async(query = \"Weather in London please.\",\n    #                      runner=runner_claude,\n    #                       user_id=USER_ID_CLAUDE,\n    #                       session_id=SESSION_ID_CLAUDE)\n    #     except Exception as e:\n    #         print(f\"An error occurred: {e}\")\n\n\nexcept Exception as e:\n    print(f\"\u274c Could not create or run Claude agent '{MODEL_CLAUDE_SONNET}'. Check API Key and model name. Error: {e}\")"}]}, {"heading_path": ["Step 3: Building an Agent Team - Delegation for Greetings & Farewells\u00b6"], "text": "Step 3: Building an Agent Team - Delegation for Greetings & Farewells \u00b6 In Steps 1 and 2, we built and experimented with a single agent focused solely on weather lookups. While effective for its specific task, real-world applications often involve handling a wider variety of user interactions. We could keep adding more tools and complex instructions to our single weather agent, but this can quickly become unmanageable and less efficient. A more robust approach is to build an Agent Team . This involves: Creating multiple, specialized agents , each designed for a specific capability (e.g., one for weather, one for greetings, one for calculations). Designating a root agent (or orchestrator) that receives the initial user request. Enabling the root agent to delegate the request to the most appropriate specialized sub-agent based on the user's intent. Why build an Agent Team? Modularity: Easier to develop, test, and maintain individual agents. Specialization: Each agent can be fine-tuned (instructions, model choice) for its specific task. Scalability: Simpler to add new capabilities by adding new agents. Efficiency: Allows using potentially simpler/cheaper models for simpler tasks (like greetings). In this step, we will: Define simple tools for handling greetings ( say_hello ) and farewells ( say_goodbye ). Create two new specialized sub-agents: greeting_agent and farewell_agent . Update our main weather agent ( weather_agent_v2 ) to act as the root agent . Configure the root agent with its sub-agents, enabling automatic delegation . Test the delegation flow by sending different types of requests to the root agent. 1. Define Tools for Sub-Agents First, let's create the simple Python functions that will serve as tools for our new specialist agents. Remember, clear docstrings are vital for the agents that will use them. # @title Define Tools for Greeting and Farewell Agents from typing import Optional # Make sure to import Optional # Ensure 'get_weather' from Step 1 is available if running this step independently. # def get_weather(city: str) -> dict: ... (from Step 1) def say_hello ( name : Optional [ str ] = None ) -> str : \"\"\"Provides a simple greeting. If a name is provided, it will be used. Args: name (str, optional): The name of the person to greet. Defaults to a generic greeting if not provided. Returns: str: A friendly greeting message. \"\"\" if name : greeting = f \"Hello, { name } !\" print ( f \"--- Tool: say_hello called with name: { name } ---\" ) else : greeting = \"Hello there!\" # Default greeting if name is None or not explicitly passed print ( f \"--- Tool: say_hello called without a specific name (name_arg_value: { name } ) ---\" ) return greeting def say_goodbye () -> str : \"\"\"Provides a simple farewell message to conclude the conversation.\"\"\" print ( f \"--- Tool: say_goodbye called ---\" ) return \"Goodbye! Have a great day.\" print ( \"Greeting and Farewell tools defined.\" ) # Optional self-test print ( say_hello ( \"Alice\" )) print ( say_hello ()) # Test with no argument (should use default \"Hello there!\") print ( say_hello ( name = None )) # Test with name explicitly as None (should use default \"Hello there!\") 2. Define the Sub-Agents (Greeting & Farewell) Now, create the Agent instances for our specialists. Notice their highly focused instruction and, critically, their clear description . The description is the primary information the root agent uses to decide when to delegate to these sub-agents. Best Practice: Sub-agent description fields should accurately and concisely summarize their specific capability. This is crucial for effective automatic delegation. Best Practice: Sub-agent instruction fields should be tailored to their limited scope, telling them exactly what to do and what not to do (e.g., \"Your only task is...\"). # @title Define Greeting and Farewell Sub-Agents # If you want to use models other than Gemini, Ensure LiteLlm is imported and API keys are set (from Step 0/2) # from google.adk.models.lite_llm import LiteLlm # MODEL_GPT_4O, MODEL_CLAUDE_SONNET etc. should be defined # Or else, continue to use: model = MODEL_GEMINI_2_0_FLASH # --- Greeting Agent --- greeting_agent = None try : greeting_agent = Agent ( # Using a potentially different/cheaper model for a simple task model = MODEL_GEMINI_2_0_FLASH , # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models name = \"greeting_agent\" , instruction = \"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting to the user. \" \"Use the 'say_hello' tool to generate the greeting. \" \"If the user provides their name, make sure to pass it to the tool. \" \"Do not engage in any other conversation or tasks.\" , description = \"Handles simple greetings and hellos using the 'say_hello' tool.\" , # Crucial for delegation tools = [ say_hello ], ) print ( f \"\u2705 Agent ' { greeting_agent . name } ' created using model ' { greeting_agent . model } '.\" ) except Exception as e : print ( f \"\u274c Could not create Greeting agent. Check API Key ( { greeting_agent . model } ). Error: { e } \" ) # --- Farewell Agent --- farewell_agent = None try : farewell_agent = Agent ( # Can use the same or a different model model = MODEL_GEMINI_2_0_FLASH , # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models name = \"farewell_agent\" , instruction = \"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message. \" \"Use the 'say_goodbye' tool when the user indicates they are leaving or ending the conversation \" \"(e.g., using words like 'bye', 'goodbye', 'thanks bye', 'see you'). \" \"Do not perform any other actions.\" , description = \"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\" , # Crucial for delegation tools = [ say_goodbye ], ) print ( f \"\u2705 Agent ' { farewell_agent . name } ' created using model ' { farewell_agent . model } '.\" ) except Exception as e : print ( f \"\u274c Could not create Farewell agent. Check API Key ( { farewell_agent . model } ). Error: { e } \" ) 3. Define the Root Agent (Weather Agent v2) with Sub-Agents Now, we upgrade our weather_agent . The key changes are: Adding the sub_agents parameter: We pass a list containing the greeting_agent and farewell_agent instances we just created. Updating the instruction : We explicitly tell the root agent about its sub-agents and when it should delegate tasks to them. Key Concept: Automatic Delegation (Auto Flow) By providing the sub_agents list, ADK enables automatic delegation. When the root agent receives a user query, its LLM considers not only its own instructions and tools but also the description of each sub-agent. If the LLM determines that a query aligns better with a sub-agent's described capability (e.g., \"Handles simple greetings\"), it will automatically generate a special internal action to transfer control to that sub-agent for that turn. The sub-agent then processes the query using its own model, instructions, and tools. Best Practice: Ensure the root agent's instructions clearly guide its delegation decisions. Mention the sub-agents by name and describe the conditions under which delegation should occur. # @title Define the Root Agent with Sub-Agents # Ensure sub-agents were created successfully before defining the root agent. # Also ensure the original 'get_weather' tool is defined. root_agent = None runner_root = None # Initialize runner if greeting_agent and farewell_agent and 'get_weather' in globals (): # Let's use a capable Gemini model for the root agent to handle orchestration root_agent_model = MODEL_GEMINI_2_0_FLASH weather_agent_team = Agent ( name = \"weather_agent_v2\" , # Give it a new version name model = root_agent_model , description = \"The main coordinator agent. Handles weather requests and delegates greetings/farewells to specialists.\" , instruction = \"You are the main Weather Agent coordinating a team. Your primary responsibility is to provide weather information. \" \"Use the 'get_weather' tool ONLY for specific weather requests (e.g., 'weather in London'). \" \"You have specialized sub-agents: \" \"1. 'greeting_agent': Handles simple greetings like 'Hi', 'Hello'. Delegate to it for these. \" \"2. 'farewell_agent': Handles simple farewells like 'Bye', 'See you'. Delegate to it for these. \" \"Analyze the user's query. If it's a greeting, delegate to 'greeting_agent'. If it's a farewell, delegate to 'farewell_agent'. \" \"If it's a weather request, handle it yourself using 'get_weather'. \" \"For anything else, respond appropriately or state you cannot handle it.\" , tools = [ get_weather ], # Root agent still needs the weather tool for its core task # Key change: Link the sub-agents here! sub_agents = [ greeting_agent , farewell_agent ] ) print ( f \"\u2705 Root Agent ' { weather_agent_team . name } ' created using model ' { root_agent_model } ' with sub-agents: { [ sa . name for sa in weather_agent_team . sub_agents ] } \" ) else : print ( \"\u274c Cannot create root agent because one or more sub-agents failed to initialize or 'get_weather' tool is missing.\" ) if not greeting_agent : print ( \" - Greeting Agent is missing.\" ) if not farewell_agent : print ( \" - Farewell Agent is missing.\" ) if 'get_weather' not in globals (): print ( \" - get_weather function is missing.\" ) 4. Interact with the Agent Team Now that we've defined our root agent ( weather_agent_team - Note: Ensure this variable name matches the one defined in the previous code block, likely # @title Define the Root Agent with Sub-Agents , which might have named it root_agent ) with its specialized sub-agents, let's test the delegation mechanism. The following code block will: Define an async function run_team_conversation . Inside this function, create a new, dedicated InMemorySessionService and a specific session ( session_001_agent_team ) just for this test run. This isolates the conversation history for testing the team dynamics. Create a Runner ( runner_agent_team ) configured to use our weather_agent_team (the root agent) and the dedicated session service. Use our updated call_agent_async function to send different types of queries (greeting, weather request, farewell) to the runner_agent_team . We explicitly pass the runner, user ID, and session ID for this specific test. Immediately execute the run_team_conversation function. We expect the following flow: The \"Hello there!\" query goes to runner_agent_team . The root agent ( weather_agent_team ) receives it and, based on its instructions and the greeting_agent 's description, delegates the task. greeting_agent handles the query, calls its say_hello tool, and generates the response. The \"What is the weather in New York?\" query is not delegated and is handled directly by the root agent using its get_weather tool. The \"Thanks, bye!\" query is delegated to the farewell_agent , which uses its say_goodbye tool. # @title Interact with the Agent Team import asyncio # Ensure asyncio is imported # Ensure the root agent (e.g., 'weather_agent_team' or 'root_agent' from the previous cell) is defined. # Ensure the call_agent_async function is defined. # Check if the root agent variable exists before defining the conversation function root_agent_var_name = 'root_agent' # Default name from Step 3 guide if 'weather_agent_team' in globals (): # Check if user used this name instead root_agent_var_name = 'weather_agent_team' elif 'root_agent' not in globals (): print ( \"\u26a0\ufe0f Root agent ('root_agent' or 'weather_agent_team') not found. Cannot define run_team_conversation.\" ) # Assign a dummy value to prevent NameError later if the code block runs anyway root_agent = None # Or set a flag to prevent execution # Only define and run if the root agent exists if root_agent_var_name in globals () and globals ()[ root_agent_var_name ]: # Define the main async function for the conversation logic. # The 'await' keywords INSIDE this function are necessary for async operations. async def run_team_conversation (): print ( \" \\n --- Testing Agent Team Delegation ---\" ) session_service = InMemorySessionService () APP_NAME = \"weather_tutorial_agent_team\" USER_ID = \"user_1_agent_team\" SESSION_ID = \"session_001_agent_team\" session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) print ( f \"Session created: App=' { APP_NAME } ', User=' { USER_ID } ', Session=' { SESSION_ID } '\" ) actual_root_agent = globals ()[ root_agent_var_name ] runner_agent_team = Runner ( # Or use InMemoryRunner agent = actual_root_agent , app_name = APP_NAME , session_service = session_service ) print ( f \"Runner created for agent ' { actual_root_agent . name } '.\" ) # --- Interactions using await (correct within async def) --- await call_agent_async ( query = \"Hello there!\" , runner = runner_agent_team , user_id = USER_ID , session_id = SESSION_ID ) await call_agent_async ( query = \"What is the weather in New York?\" , runner = runner_agent_team , user_id = USER_ID , session_id = SESSION_ID ) await call_agent_async ( query = \"Thanks, bye!\" , runner = runner_agent_team , user_id = USER_ID , session_id = SESSION_ID ) # --- Execute the `run_team_conversation` async function --- # Choose ONE of the methods below based on your environment. # Note: This may require API keys for the models used! # METHOD 1: Direct await (Default for Notebooks/Async REPLs) # If your environment supports top-level await (like Colab/Jupyter notebooks), # it means an event loop is already running, so you can directly await the function. print ( \"Attempting execution using 'await' (default for notebooks)...\" ) await run_team_conversation () # METHOD 2: asyncio.run (For Standard Python Scripts [.py]) # If running this code as a standard Python script from your terminal, # the script context is synchronous. `asyncio.run()` is needed to # create and manage an event loop to execute your async function. # To use this method: # 1. Comment out the `await run_team_conversation()` line above. # 2. Uncomment the following block: \"\"\" import asyncio if __name__ == \"__main__\": # Ensures this runs only when script is executed directly print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\") try: # This creates an event loop, runs your async function, and closes the loop. asyncio.run(run_team_conversation()) except Exception as e: print(f\"An error occurred: {e}\") \"\"\" else : # This message prints if the root agent variable wasn't found earlier print ( \" \\n \u26a0\ufe0f Skipping agent team conversation execution as the root agent was not successfully defined in a previous step.\" ) Look closely at the output logs, especially the --- Tool: ... called --- messages. You should observe: For \"Hello there!\", the say_hello tool was called (indicating greeting_agent handled it). For \"What is the weather in New York?\", the get_weather tool was called (indicating the root agent handled it). For \"Thanks, bye!\", the say_goodbye tool was called (indicating farewell_agent handled it). This confirms successful automatic delegation ! The root agent, guided by its instructions and the description s of its sub_agents , correctly routed user requests to the appropriate specialist agent within the team. You've now structured your application with multiple collaborating agents. This modular design is fundamental for building more complex and capable agent systems. In the next step, we'll give our agents the ability to remember information across turns using session state. ", "code_blocks": [{"language": "text", "code": "# @title Define Tools for Greeting and Farewell Agents\nfrom typing import Optional # Make sure to import Optional\n\n# Ensure 'get_weather' from Step 1 is available if running this step independently.\n# def get_weather(city: str) -> dict: ... (from Step 1)\n\ndef say_hello(name: Optional[str] = None) -> str:\n    \"\"\"Provides a simple greeting. If a name is provided, it will be used.\n\n    Args:\n        name (str, optional): The name of the person to greet. Defaults to a generic greeting if not provided.\n\n    Returns:\n        str: A friendly greeting message.\n    \"\"\"\n    if name:\n        greeting = f\"Hello, {name}!\"\n        print(f\"--- Tool: say_hello called with name: {name} ---\")\n    else:\n        greeting = \"Hello there!\" # Default greeting if name is None or not explicitly passed\n        print(f\"--- Tool: say_hello called without a specific name (name_arg_value: {name}) ---\")\n    return greeting\n\ndef say_goodbye() -> str:\n    \"\"\"Provides a simple farewell message to conclude the conversation.\"\"\"\n    print(f\"--- Tool: say_goodbye called ---\")\n    return \"Goodbye! Have a great day.\"\n\nprint(\"Greeting and Farewell tools defined.\")\n\n# Optional self-test\nprint(say_hello(\"Alice\"))\nprint(say_hello()) # Test with no argument (should use default \"Hello there!\")\nprint(say_hello(name=None)) # Test with name explicitly as None (should use default \"Hello there!\")"}, {"language": "text", "code": "# @title Define Greeting and Farewell Sub-Agents\n\n# If you want to use models other than Gemini, Ensure LiteLlm is imported and API keys are set (from Step 0/2)\n# from google.adk.models.lite_llm import LiteLlm\n# MODEL_GPT_4O, MODEL_CLAUDE_SONNET etc. should be defined\n# Or else, continue to use: model = MODEL_GEMINI_2_0_FLASH\n\n# --- Greeting Agent ---\ngreeting_agent = None\ntry:\n    greeting_agent = Agent(\n        # Using a potentially different/cheaper model for a simple task\n        model = MODEL_GEMINI_2_0_FLASH,\n        # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models\n        name=\"greeting_agent\",\n        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting to the user. \"\n                    \"Use the 'say_hello' tool to generate the greeting. \"\n                    \"If the user provides their name, make sure to pass it to the tool. \"\n                    \"Do not engage in any other conversation or tasks.\",\n        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\", # Crucial for delegation\n        tools=[say_hello],\n    )\n    print(f\"\u2705 Agent '{greeting_agent.name}' created using model '{greeting_agent.model}'.\")\nexcept Exception as e:\n    print(f\"\u274c Could not create Greeting agent. Check API Key ({greeting_agent.model}). Error: {e}\")\n\n# --- Farewell Agent ---\nfarewell_agent = None\ntry:\n    farewell_agent = Agent(\n        # Can use the same or a different model\n        model = MODEL_GEMINI_2_0_FLASH,\n        # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models\n        name=\"farewell_agent\",\n        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message. \"\n                    \"Use the 'say_goodbye' tool when the user indicates they are leaving or ending the conversation \"\n                    \"(e.g., using words like 'bye', 'goodbye', 'thanks bye', 'see you'). \"\n                    \"Do not perform any other actions.\",\n        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\", # Crucial for delegation\n        tools=[say_goodbye],\n    )\n    print(f\"\u2705 Agent '{farewell_agent.name}' created using model '{farewell_agent.model}'.\")\nexcept Exception as e:\n    print(f\"\u274c Could not create Farewell agent. Check API Key ({farewell_agent.model}). Error: {e}\")"}, {"language": "text", "code": "# @title Define the Root Agent with Sub-Agents\n\n# Ensure sub-agents were created successfully before defining the root agent.\n# Also ensure the original 'get_weather' tool is defined.\nroot_agent = None\nrunner_root = None # Initialize runner\n\nif greeting_agent and farewell_agent and 'get_weather' in globals():\n    # Let's use a capable Gemini model for the root agent to handle orchestration\n    root_agent_model = MODEL_GEMINI_2_0_FLASH\n\n    weather_agent_team = Agent(\n        name=\"weather_agent_v2\", # Give it a new version name\n        model=root_agent_model,\n        description=\"The main coordinator agent. Handles weather requests and delegates greetings/farewells to specialists.\",\n        instruction=\"You are the main Weather Agent coordinating a team. Your primary responsibility is to provide weather information. \"\n                    \"Use the 'get_weather' tool ONLY for specific weather requests (e.g., 'weather in London'). \"\n                    \"You have specialized sub-agents: \"\n                    \"1. 'greeting_agent': Handles simple greetings like 'Hi', 'Hello'. Delegate to it for these. \"\n                    \"2. 'farewell_agent': Handles simple farewells like 'Bye', 'See you'. Delegate to it for these. \"\n                    \"Analyze the user's query. If it's a greeting, delegate to 'greeting_agent'. If it's a farewell, delegate to 'farewell_agent'. \"\n                    \"If it's a weather request, handle it yourself using 'get_weather'. \"\n                    \"For anything else, respond appropriately or state you cannot handle it.\",\n        tools=[get_weather], # Root agent still needs the weather tool for its core task\n        # Key change: Link the sub-agents here!\n        sub_agents=[greeting_agent, farewell_agent]\n    )\n    print(f\"\u2705 Root Agent '{weather_agent_team.name}' created using model '{root_agent_model}' with sub-agents: {[sa.name for sa in weather_agent_team.sub_agents]}\")\n\nelse:\n    print(\"\u274c Cannot create root agent because one or more sub-agents failed to initialize or 'get_weather' tool is missing.\")\n    if not greeting_agent: print(\" - Greeting Agent is missing.\")\n    if not farewell_agent: print(\" - Farewell Agent is missing.\")\n    if 'get_weather' not in globals(): print(\" - get_weather function is missing.\")"}, {"language": "text", "code": "# @title Interact with the Agent Team\nimport asyncio # Ensure asyncio is imported\n\n# Ensure the root agent (e.g., 'weather_agent_team' or 'root_agent' from the previous cell) is defined.\n# Ensure the call_agent_async function is defined.\n\n# Check if the root agent variable exists before defining the conversation function\nroot_agent_var_name = 'root_agent' # Default name from Step 3 guide\nif 'weather_agent_team' in globals(): # Check if user used this name instead\n    root_agent_var_name = 'weather_agent_team'\nelif 'root_agent' not in globals():\n    print(\"\u26a0\ufe0f Root agent ('root_agent' or 'weather_agent_team') not found. Cannot define run_team_conversation.\")\n    # Assign a dummy value to prevent NameError later if the code block runs anyway\n    root_agent = None # Or set a flag to prevent execution\n\n# Only define and run if the root agent exists\nif root_agent_var_name in globals() and globals()[root_agent_var_name]:\n    # Define the main async function for the conversation logic.\n    # The 'await' keywords INSIDE this function are necessary for async operations.\n    async def run_team_conversation():\n        print(\"\\n--- Testing Agent Team Delegation ---\")\n        session_service = InMemorySessionService()\n        APP_NAME = \"weather_tutorial_agent_team\"\n        USER_ID = \"user_1_agent_team\"\n        SESSION_ID = \"session_001_agent_team\"\n        session = await session_service.create_session(\n            app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n        )\n        print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n\n        actual_root_agent = globals()[root_agent_var_name]\n        runner_agent_team = Runner( # Or use InMemoryRunner\n            agent=actual_root_agent,\n            app_name=APP_NAME,\n            session_service=session_service\n        )\n        print(f\"Runner created for agent '{actual_root_agent.name}'.\")\n\n        # --- Interactions using await (correct within async def) ---\n        await call_agent_async(query = \"Hello there!\",\n                               runner=runner_agent_team,\n                               user_id=USER_ID,\n                               session_id=SESSION_ID)\n        await call_agent_async(query = \"What is the weather in New York?\",\n                               runner=runner_agent_team,\n                               user_id=USER_ID,\n                               session_id=SESSION_ID)\n        await call_agent_async(query = \"Thanks, bye!\",\n                               runner=runner_agent_team,\n                               user_id=USER_ID,\n                               session_id=SESSION_ID)\n\n    # --- Execute the `run_team_conversation` async function ---\n    # Choose ONE of the methods below based on your environment.\n    # Note: This may require API keys for the models used!\n\n    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n    # it means an event loop is already running, so you can directly await the function.\n    print(\"Attempting execution using 'await' (default for notebooks)...\")\n    await run_team_conversation()\n\n    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n    # If running this code as a standard Python script from your terminal,\n    # the script context is synchronous. `asyncio.run()` is needed to\n    # create and manage an event loop to execute your async function.\n    # To use this method:\n    # 1. Comment out the `await run_team_conversation()` line above.\n    # 2. Uncomment the following block:\n    \"\"\"\n    import asyncio\n    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n        try:\n            # This creates an event loop, runs your async function, and closes the loop.\n            asyncio.run(run_team_conversation())\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n    \"\"\"\n\nelse:\n    # This message prints if the root agent variable wasn't found earlier\n    print(\"\\n\u26a0\ufe0f Skipping agent team conversation execution as the root agent was not successfully defined in a previous step.\")"}]}, {"heading_path": ["Step 4: Adding Memory and Personalization with Session State\u00b6"], "text": "Step 4: Adding Memory and Personalization with Session State \u00b6 So far, our agent team can handle different tasks through delegation, but each interaction starts fresh \u2013 the agents have no memory of past conversations or user preferences within a session. To create more sophisticated and context-aware experiences, agents need memory . ADK provides this through Session State . What is Session State? It's a Python dictionary ( session.state ) tied to a specific user session (identified by APP_NAME , USER_ID , SESSION_ID ). It persists information across multiple conversational turns within that session. Agents and Tools can read from and write to this state, allowing them to remember details, adapt behavior, and personalize responses. How Agents Interact with State: ToolContext (Primary Method): Tools can accept a ToolContext object (automatically provided by ADK if declared as the last argument). This object gives direct access to the session state via tool_context.state , allowing tools to read preferences or save results during execution. output_key (Auto-Save Agent Response): An Agent can be configured with an output_key=\"your_key\" . ADK will then automatically save the agent's final textual response for a turn into session.state[\"your_key\"] . In this step, we will enhance our Weather Bot team by: Using a new InMemorySessionService to demonstrate state in isolation. Initializing session state with a user preference for temperature_unit . Creating a state-aware version of the weather tool ( get_weather_stateful ) that reads this preference via ToolContext and adjusts its output format (Celsius/Fahrenheit). Updating the root agent to use this stateful tool and configuring it with an output_key to automatically save its final weather report to the session state. Running a conversation to observe how the initial state affects the tool, how manual state changes alter subsequent behavior, and how output_key persists the agent's response. 1. Initialize New Session Service and State To clearly demonstrate state management without interference from prior steps, we'll instantiate a new InMemorySessionService . We'll also create a session with an initial state defining the user's preferred temperature unit. # @title 1. Initialize New Session Service and State # Import necessary session components from google.adk.sessions import InMemorySessionService # Create a NEW session service instance for this state demonstration session_service_stateful = InMemorySessionService () print ( \"\u2705 New InMemorySessionService created for state demonstration.\" ) # Define a NEW session ID for this part of the tutorial SESSION_ID_STATEFUL = \"session_state_demo_001\" USER_ID_STATEFUL = \"user_state_demo\" # Define initial state data - user prefers Celsius initially initial_state = { \"user_preference_temperature_unit\" : \"Celsius\" } # Create the session, providing the initial state session_stateful = await session_service_stateful . create_session ( app_name = APP_NAME , # Use the consistent app name user_id = USER_ID_STATEFUL , session_id = SESSION_ID_STATEFUL , state = initial_state # <<< Initialize state during creation ) print ( f \"\u2705 Session ' { SESSION_ID_STATEFUL } ' created for user ' { USER_ID_STATEFUL } '.\" ) # Verify the initial state was set correctly retrieved_session = await session_service_stateful . get_session ( app_name = APP_NAME , user_id = USER_ID_STATEFUL , session_id = SESSION_ID_STATEFUL ) print ( \" \\n --- Initial Session State ---\" ) if retrieved_session : print ( retrieved_session . state ) else : print ( \"Error: Could not retrieve session.\" ) 2. Create State-Aware Weather Tool ( get_weather_stateful ) Now, we create a new version of the weather tool. Its key feature is accepting tool_context: ToolContext which allows it to access tool_context.state . It will read the user_preference_temperature_unit and format the temperature accordingly. Key Concept: ToolContext This object is the bridge allowing your tool logic to interact with the session's context, including reading and writing state variables. ADK injects it automatically if defined as the last parameter of your tool function. Best Practice: When reading from state, use dictionary.get('key', default_value) to handle cases where the key might not exist yet, ensuring your tool doesn't crash. from google.adk.tools.tool_context import ToolContext def get_weather_stateful ( city : str , tool_context : ToolContext ) -> dict : \"\"\"Retrieves weather, converts temp unit based on session state.\"\"\" print ( f \"--- Tool: get_weather_stateful called for { city } ---\" ) # --- Read preference from state --- preferred_unit = tool_context . state . get ( \"user_preference_temperature_unit\" , \"Celsius\" ) # Default to Celsius print ( f \"--- Tool: Reading state 'user_preference_temperature_unit': { preferred_unit } ---\" ) city_normalized = city . lower () . replace ( \" \" , \"\" ) # Mock weather data (always stored in Celsius internally) mock_weather_db = { \"newyork\" : { \"temp_c\" : 25 , \"condition\" : \"sunny\" }, \"london\" : { \"temp_c\" : 15 , \"condition\" : \"cloudy\" }, \"tokyo\" : { \"temp_c\" : 18 , \"condition\" : \"light rain\" }, } if city_normalized in mock_weather_db : data = mock_weather_db [ city_normalized ] temp_c = data [ \"temp_c\" ] condition = data [ \"condition\" ] # Format temperature based on state preference if preferred_unit == \"Fahrenheit\" : temp_value = ( temp_c * 9 / 5 ) + 32 # Calculate Fahrenheit temp_unit = \"\u00b0F\" else : # Default to Celsius temp_value = temp_c temp_unit = \"\u00b0C\" report = f \"The weather in { city . capitalize () } is { condition } with a temperature of { temp_value : .0f }{ temp_unit } .\" result = { \"status\" : \"success\" , \"report\" : report } print ( f \"--- Tool: Generated report in { preferred_unit } . Result: { result } ---\" ) # Example of writing back to state (optional for this tool) tool_context . state [ \"last_city_checked_stateful\" ] = city print ( f \"--- Tool: Updated state 'last_city_checked_stateful': { city } ---\" ) return result else : # Handle city not found error_msg = f \"Sorry, I don't have weather information for ' { city } '.\" print ( f \"--- Tool: City ' { city } ' not found. ---\" ) return { \"status\" : \"error\" , \"error_message\" : error_msg } print ( \"\u2705 State-aware 'get_weather_stateful' tool defined.\" ) 3. Redefine Sub-Agents and Update Root Agent To ensure this step is self-contained and builds correctly, we first redefine the greeting_agent and farewell_agent exactly as they were in Step 3. Then, we define our new root agent ( weather_agent_v4_stateful ): It uses the new get_weather_stateful tool. It includes the greeting and farewell sub-agents for delegation. Crucially , it sets output_key=\"last_weather_report\" which automatically saves its final weather response to the session state. # @title 3. Redefine Sub-Agents and Update Root Agent with output_key # Ensure necessary imports: Agent, LiteLlm, Runner from google.adk.agents import Agent from google.adk.models.lite_llm import LiteLlm from google.adk.runners import Runner # Ensure tools 'say_hello', 'say_goodbye' are defined (from Step 3) # Ensure model constants MODEL_GPT_4O, MODEL_GEMINI_2_0_FLASH etc. are defined # --- Redefine Greeting Agent (from Step 3) --- greeting_agent = None try : greeting_agent = Agent ( model = MODEL_GEMINI_2_0_FLASH , name = \"greeting_agent\" , instruction = \"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\" , description = \"Handles simple greetings and hellos using the 'say_hello' tool.\" , tools = [ say_hello ], ) print ( f \"\u2705 Agent ' { greeting_agent . name } ' redefined.\" ) except Exception as e : print ( f \"\u274c Could not redefine Greeting agent. Error: { e } \" ) # --- Redefine Farewell Agent (from Step 3) --- farewell_agent = None try : farewell_agent = Agent ( model = MODEL_GEMINI_2_0_FLASH , name = \"farewell_agent\" , instruction = \"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\" , description = \"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\" , tools = [ say_goodbye ], ) print ( f \"\u2705 Agent ' { farewell_agent . name } ' redefined.\" ) except Exception as e : print ( f \"\u274c Could not redefine Farewell agent. Error: { e } \" ) # --- Define the Updated Root Agent --- root_agent_stateful = None runner_root_stateful = None # Initialize runner # Check prerequisites before creating the root agent if greeting_agent and farewell_agent and 'get_weather_stateful' in globals (): root_agent_model = MODEL_GEMINI_2_0_FLASH # Choose orchestration model root_agent_stateful = Agent ( name = \"weather_agent_v4_stateful\" , # New version name model = root_agent_model , description = \"Main agent: Provides weather (state-aware unit), delegates greetings/farewells, saves report to state.\" , instruction = \"You are the main Weather Agent. Your job is to provide weather using 'get_weather_stateful'. \" \"The tool will format the temperature based on user preference stored in state. \" \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \" \"Handle only weather requests, greetings, and farewells.\" , tools = [ get_weather_stateful ], # Use the state-aware tool sub_agents = [ greeting_agent , farewell_agent ], # Include sub-agents output_key = \"last_weather_report\" # <<< Auto-save agent's final weather response ) print ( f \"\u2705 Root Agent ' { root_agent_stateful . name } ' created using stateful tool and output_key.\" ) # --- Create Runner for this Root Agent & NEW Session Service --- runner_root_stateful = Runner ( agent = root_agent_stateful , app_name = APP_NAME , session_service = session_service_stateful # Use the NEW stateful session service ) print ( f \"\u2705 Runner created for stateful root agent ' { runner_root_stateful . agent . name } ' using stateful session service.\" ) else : print ( \"\u274c Cannot create stateful root agent. Prerequisites missing.\" ) if not greeting_agent : print ( \" - greeting_agent definition missing.\" ) if not farewell_agent : print ( \" - farewell_agent definition missing.\" ) if 'get_weather_stateful' not in globals (): print ( \" - get_weather_stateful tool missing.\" ) 4. Interact and Test State Flow Now, let's execute a conversation designed to test the state interactions using the runner_root_stateful (associated with our stateful agent and the session_service_stateful ). We'll use the call_agent_async function defined earlier, ensuring we pass the correct runner, user ID ( USER_ID_STATEFUL ), and session ID ( SESSION_ID_STATEFUL ). The conversation flow will be: Check weather (London): The get_weather_stateful tool should read the initial \"Celsius\" preference from the session state initialized in Section 1. The root agent's final response (the weather report in Celsius) should get saved to state['last_weather_report'] via the output_key configuration. Manually update state: We will directly modify the state stored within the InMemorySessionService instance ( session_service_stateful ). Why direct modification? The session_service.get_session() method returns a copy of the session. Modifying that copy wouldn't affect the state used in subsequent agent runs. For this testing scenario with InMemorySessionService , we access the internal sessions dictionary to change the actual stored state value for user_preference_temperature_unit to \"Fahrenheit\". Note: In real applications, state changes are typically triggered by tools or agent logic returning EventActions(state_delta=...) , not direct manual updates. Check weather again (New York): The get_weather_stateful tool should now read the updated \"Fahrenheit\" preference from the state and convert the temperature accordingly. The root agent's new response (weather in Fahrenheit) will overwrite the previous value in state['last_weather_report'] due to the output_key . Greet the agent: Verify that delegation to the greeting_agent still works correctly alongside the stateful operations. This interaction will become the last response saved by output_key in this specific sequence. Inspect final state: After the conversation, we retrieve the session one last time (getting a copy) and print its state to confirm the user_preference_temperature_unit is indeed \"Fahrenheit\", observe the final value saved by output_key (which will be the greeting in this run), and see the last_city_checked_stateful value written by the tool. # @title 4. Interact to Test State Flow and output_key import asyncio # Ensure asyncio is imported # Ensure the stateful runner (runner_root_stateful) is available from the previous cell # Ensure call_agent_async, USER_ID_STATEFUL, SESSION_ID_STATEFUL, APP_NAME are defined if 'runner_root_stateful' in globals () and runner_root_stateful : # Define the main async function for the stateful conversation logic. # The 'await' keywords INSIDE this function are necessary for async operations. async def run_stateful_conversation (): print ( \" \\n --- Testing State: Temp Unit Conversion & output_key ---\" ) # 1. Check weather (Uses initial state: Celsius) print ( \"--- Turn 1: Requesting weather in London (expect Celsius) ---\" ) await call_agent_async ( query = \"What's the weather in London?\" , runner = runner_root_stateful , user_id = USER_ID_STATEFUL , session_id = SESSION_ID_STATEFUL ) # 2. Manually update state preference to Fahrenheit - DIRECTLY MODIFY STORAGE print ( \" \\n --- Manually Updating State: Setting unit to Fahrenheit ---\" ) try : # Access the internal storage directly - THIS IS SPECIFIC TO InMemorySessionService for testing # NOTE: In production with persistent services (Database, VertexAI), you would # typically update state via agent actions or specific service APIs if available, # not by direct manipulation of internal storage. stored_session = session_service_stateful . sessions [ APP_NAME ][ USER_ID_STATEFUL ][ SESSION_ID_STATEFUL ] stored_session . state [ \"user_preference_temperature_unit\" ] = \"Fahrenheit\" # Optional: You might want to update the timestamp as well if any logic depends on it # import time # stored_session.last_update_time = time.time() print ( f \"--- Stored session state updated. Current 'user_preference_temperature_unit': { stored_session . state . get ( 'user_preference_temperature_unit' , 'Not Set' ) } ---\" ) # Added .get for safety except KeyError : print ( f \"--- Error: Could not retrieve session ' { SESSION_ID_STATEFUL } ' from internal storage for user ' { USER_ID_STATEFUL } ' in app ' { APP_NAME } ' to update state. Check IDs and if session was created. ---\" ) except Exception as e : print ( f \"--- Error updating internal session state: { e } ---\" ) # 3. Check weather again (Tool should now use Fahrenheit) # This will also update 'last_weather_report' via output_key print ( \" \\n --- Turn 2: Requesting weather in New York (expect Fahrenheit) ---\" ) await call_agent_async ( query = \"Tell me the weather in New York.\" , runner = runner_root_stateful , user_id = USER_ID_STATEFUL , session_id = SESSION_ID_STATEFUL ) # 4. Test basic delegation (should still work) # This will update 'last_weather_report' again, overwriting the NY weather report print ( \" \\n --- Turn 3: Sending a greeting ---\" ) await call_agent_async ( query = \"Hi!\" , runner = runner_root_stateful , user_id = USER_ID_STATEFUL , session_id = SESSION_ID_STATEFUL ) # --- Execute the `run_stateful_conversation` async function --- # Choose ONE of the methods below based on your environment. # METHOD 1: Direct await (Default for Notebooks/Async REPLs) # If your environment supports top-level await (like Colab/Jupyter notebooks), # it means an event loop is already running, so you can directly await the function. print ( \"Attempting execution using 'await' (default for notebooks)...\" ) await run_stateful_conversation () # METHOD 2: asyncio.run (For Standard Python Scripts [.py]) # If running this code as a standard Python script from your terminal, # the script context is synchronous. `asyncio.run()` is needed to # create and manage an event loop to execute your async function. # To use this method: # 1. Comment out the `await run_stateful_conversation()` line above. # 2. Uncomment the following block: \"\"\" import asyncio if __name__ == \"__main__\": # Ensures this runs only when script is executed directly print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\") try: # This creates an event loop, runs your async function, and closes the loop. asyncio.run(run_stateful_conversation()) except Exception as e: print(f\"An error occurred: {e}\") \"\"\" # --- Inspect final session state after the conversation --- # This block runs after either execution method completes. print ( \" \\n --- Inspecting Final Session State ---\" ) final_session = await session_service_stateful . get_session ( app_name = APP_NAME , user_id = USER_ID_STATEFUL , session_id = SESSION_ID_STATEFUL ) if final_session : # Use .get() for safer access to potentially missing keys print ( f \"Final Preference: { final_session . state . get ( 'user_preference_temperature_unit' , 'Not Set' ) } \" ) print ( f \"Final Last Weather Report (from output_key): { final_session . state . get ( 'last_weather_report' , 'Not Set' ) } \" ) print ( f \"Final Last City Checked (by tool): { final_session . state . get ( 'last_city_checked_stateful' , 'Not Set' ) } \" ) # Print full state for detailed view # print(f\"Full State Dict: {final_session.state}\") # For detailed view else : print ( \" \\n \u274c Error: Could not retrieve final session state.\" ) else : print ( \" \\n \u26a0\ufe0f Skipping state test conversation. Stateful root agent runner ('runner_root_stateful') is not available.\" ) By reviewing the conversation flow and the final session state printout, you can confirm: State Read: The weather tool ( get_weather_stateful ) correctly read user_preference_temperature_unit from state, initially using \"Celsius\" for London. State Update: The direct modification successfully changed the stored preference to \"Fahrenheit\". State Read (Updated): The tool subsequently read \"Fahrenheit\" when asked for New York's weather and performed the conversion. Tool State Write: The tool successfully wrote the last_city_checked_stateful (\"New York\" after the second weather check) into the state via tool_context.state . Delegation: The delegation to the greeting_agent for \"Hi!\" functioned correctly even after state modifications. output_key : The output_key=\"last_weather_report\" successfully saved the root agent's final response for each turn where the root agent was the one ultimately responding. In this sequence, the last response was the greeting (\"Hello, there!\"), so that overwrote the weather report in the state key. Final State: The final check confirms the preference persisted as \"Fahrenheit\". You've now successfully integrated session state to personalize agent behavior using ToolContext , manually manipulated state for testing InMemorySessionService , and observed how output_key provides a simple mechanism for saving the agent's last response to state. This foundational understanding of state management is key as we proceed to implement safety guardrails using callbacks in the next steps. ", "code_blocks": [{"language": "text", "code": "# @title 1. Initialize New Session Service and State\n\n# Import necessary session components\nfrom google.adk.sessions import InMemorySessionService\n\n# Create a NEW session service instance for this state demonstration\nsession_service_stateful = InMemorySessionService()\nprint(\"\u2705 New InMemorySessionService created for state demonstration.\")\n\n# Define a NEW session ID for this part of the tutorial\nSESSION_ID_STATEFUL = \"session_state_demo_001\"\nUSER_ID_STATEFUL = \"user_state_demo\"\n\n# Define initial state data - user prefers Celsius initially\ninitial_state = {\n    \"user_preference_temperature_unit\": \"Celsius\"\n}\n\n# Create the session, providing the initial state\nsession_stateful = await session_service_stateful.create_session(\n    app_name=APP_NAME, # Use the consistent app name\n    user_id=USER_ID_STATEFUL,\n    session_id=SESSION_ID_STATEFUL,\n    state=initial_state # <<< Initialize state during creation\n)\nprint(f\"\u2705 Session '{SESSION_ID_STATEFUL}' created for user '{USER_ID_STATEFUL}'.\")\n\n# Verify the initial state was set correctly\nretrieved_session = await session_service_stateful.get_session(app_name=APP_NAME,\n                                                         user_id=USER_ID_STATEFUL,\n                                                         session_id = SESSION_ID_STATEFUL)\nprint(\"\\n--- Initial Session State ---\")\nif retrieved_session:\n    print(retrieved_session.state)\nelse:\n    print(\"Error: Could not retrieve session.\")"}, {"language": "text", "code": "from google.adk.tools.tool_context import ToolContext\n\ndef get_weather_stateful(city: str, tool_context: ToolContext) -> dict:\n    \"\"\"Retrieves weather, converts temp unit based on session state.\"\"\"\n    print(f\"--- Tool: get_weather_stateful called for {city} ---\")\n\n    # --- Read preference from state ---\n    preferred_unit = tool_context.state.get(\"user_preference_temperature_unit\", \"Celsius\") # Default to Celsius\n    print(f\"--- Tool: Reading state 'user_preference_temperature_unit': {preferred_unit} ---\")\n\n    city_normalized = city.lower().replace(\" \", \"\")\n\n    # Mock weather data (always stored in Celsius internally)\n    mock_weather_db = {\n        \"newyork\": {\"temp_c\": 25, \"condition\": \"sunny\"},\n        \"london\": {\"temp_c\": 15, \"condition\": \"cloudy\"},\n        \"tokyo\": {\"temp_c\": 18, \"condition\": \"light rain\"},\n    }\n\n    if city_normalized in mock_weather_db:\n        data = mock_weather_db[city_normalized]\n        temp_c = data[\"temp_c\"]\n        condition = data[\"condition\"]\n\n        # Format temperature based on state preference\n        if preferred_unit == \"Fahrenheit\":\n            temp_value = (temp_c * 9/5) + 32 # Calculate Fahrenheit\n            temp_unit = \"\u00b0F\"\n        else: # Default to Celsius\n            temp_value = temp_c\n            temp_unit = \"\u00b0C\"\n\n        report = f\"The weather in {city.capitalize()} is {condition} with a temperature of {temp_value:.0f}{temp_unit}.\"\n        result = {\"status\": \"success\", \"report\": report}\n        print(f\"--- Tool: Generated report in {preferred_unit}. Result: {result} ---\")\n\n        # Example of writing back to state (optional for this tool)\n        tool_context.state[\"last_city_checked_stateful\"] = city\n        print(f\"--- Tool: Updated state 'last_city_checked_stateful': {city} ---\")\n\n        return result\n    else:\n        # Handle city not found\n        error_msg = f\"Sorry, I don't have weather information for '{city}'.\"\n        print(f\"--- Tool: City '{city}' not found. ---\")\n        return {\"status\": \"error\", \"error_message\": error_msg}\n\nprint(\"\u2705 State-aware 'get_weather_stateful' tool defined.\")"}, {"language": "text", "code": "# @title 3. Redefine Sub-Agents and Update Root Agent with output_key\n\n# Ensure necessary imports: Agent, LiteLlm, Runner\nfrom google.adk.agents import Agent\nfrom google.adk.models.lite_llm import LiteLlm\nfrom google.adk.runners import Runner\n# Ensure tools 'say_hello', 'say_goodbye' are defined (from Step 3)\n# Ensure model constants MODEL_GPT_4O, MODEL_GEMINI_2_0_FLASH etc. are defined\n\n# --- Redefine Greeting Agent (from Step 3) ---\ngreeting_agent = None\ntry:\n    greeting_agent = Agent(\n        model=MODEL_GEMINI_2_0_FLASH,\n        name=\"greeting_agent\",\n        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n        tools=[say_hello],\n    )\n    print(f\"\u2705 Agent '{greeting_agent.name}' redefined.\")\nexcept Exception as e:\n    print(f\"\u274c Could not redefine Greeting agent. Error: {e}\")\n\n# --- Redefine Farewell Agent (from Step 3) ---\nfarewell_agent = None\ntry:\n    farewell_agent = Agent(\n        model=MODEL_GEMINI_2_0_FLASH,\n        name=\"farewell_agent\",\n        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n        tools=[say_goodbye],\n    )\n    print(f\"\u2705 Agent '{farewell_agent.name}' redefined.\")\nexcept Exception as e:\n    print(f\"\u274c Could not redefine Farewell agent. Error: {e}\")\n\n# --- Define the Updated Root Agent ---\nroot_agent_stateful = None\nrunner_root_stateful = None # Initialize runner\n\n# Check prerequisites before creating the root agent\nif greeting_agent and farewell_agent and 'get_weather_stateful' in globals():\n\n    root_agent_model = MODEL_GEMINI_2_0_FLASH # Choose orchestration model\n\n    root_agent_stateful = Agent(\n        name=\"weather_agent_v4_stateful\", # New version name\n        model=root_agent_model,\n        description=\"Main agent: Provides weather (state-aware unit), delegates greetings/farewells, saves report to state.\",\n        instruction=\"You are the main Weather Agent. Your job is to provide weather using 'get_weather_stateful'. \"\n                    \"The tool will format the temperature based on user preference stored in state. \"\n                    \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n                    \"Handle only weather requests, greetings, and farewells.\",\n        tools=[get_weather_stateful], # Use the state-aware tool\n        sub_agents=[greeting_agent, farewell_agent], # Include sub-agents\n        output_key=\"last_weather_report\" # <<< Auto-save agent's final weather response\n    )\n    print(f\"\u2705 Root Agent '{root_agent_stateful.name}' created using stateful tool and output_key.\")\n\n    # --- Create Runner for this Root Agent & NEW Session Service ---\n    runner_root_stateful = Runner(\n        agent=root_agent_stateful,\n        app_name=APP_NAME,\n        session_service=session_service_stateful # Use the NEW stateful session service\n    )\n    print(f\"\u2705 Runner created for stateful root agent '{runner_root_stateful.agent.name}' using stateful session service.\")\n\nelse:\n    print(\"\u274c Cannot create stateful root agent. Prerequisites missing.\")\n    if not greeting_agent: print(\" - greeting_agent definition missing.\")\n    if not farewell_agent: print(\" - farewell_agent definition missing.\")\n    if 'get_weather_stateful' not in globals(): print(\" - get_weather_stateful tool missing.\")"}, {"language": "text", "code": "# @title 4. Interact to Test State Flow and output_key\nimport asyncio # Ensure asyncio is imported\n\n# Ensure the stateful runner (runner_root_stateful) is available from the previous cell\n# Ensure call_agent_async, USER_ID_STATEFUL, SESSION_ID_STATEFUL, APP_NAME are defined\n\nif 'runner_root_stateful' in globals() and runner_root_stateful:\n    # Define the main async function for the stateful conversation logic.\n    # The 'await' keywords INSIDE this function are necessary for async operations.\n    async def run_stateful_conversation():\n        print(\"\\n--- Testing State: Temp Unit Conversion & output_key ---\")\n\n        # 1. Check weather (Uses initial state: Celsius)\n        print(\"--- Turn 1: Requesting weather in London (expect Celsius) ---\")\n        await call_agent_async(query= \"What's the weather in London?\",\n                               runner=runner_root_stateful,\n                               user_id=USER_ID_STATEFUL,\n                               session_id=SESSION_ID_STATEFUL\n                              )\n\n        # 2. Manually update state preference to Fahrenheit - DIRECTLY MODIFY STORAGE\n        print(\"\\n--- Manually Updating State: Setting unit to Fahrenheit ---\")\n        try:\n            # Access the internal storage directly - THIS IS SPECIFIC TO InMemorySessionService for testing\n            # NOTE: In production with persistent services (Database, VertexAI), you would\n            # typically update state via agent actions or specific service APIs if available,\n            # not by direct manipulation of internal storage.\n            stored_session = session_service_stateful.sessions[APP_NAME][USER_ID_STATEFUL][SESSION_ID_STATEFUL]\n            stored_session.state[\"user_preference_temperature_unit\"] = \"Fahrenheit\"\n            # Optional: You might want to update the timestamp as well if any logic depends on it\n            # import time\n            # stored_session.last_update_time = time.time()\n            print(f\"--- Stored session state updated. Current 'user_preference_temperature_unit': {stored_session.state.get('user_preference_temperature_unit', 'Not Set')} ---\") # Added .get for safety\n        except KeyError:\n            print(f\"--- Error: Could not retrieve session '{SESSION_ID_STATEFUL}' from internal storage for user '{USER_ID_STATEFUL}' in app '{APP_NAME}' to update state. Check IDs and if session was created. ---\")\n        except Exception as e:\n             print(f\"--- Error updating internal session state: {e} ---\")\n\n        # 3. Check weather again (Tool should now use Fahrenheit)\n        # This will also update 'last_weather_report' via output_key\n        print(\"\\n--- Turn 2: Requesting weather in New York (expect Fahrenheit) ---\")\n        await call_agent_async(query= \"Tell me the weather in New York.\",\n                               runner=runner_root_stateful,\n                               user_id=USER_ID_STATEFUL,\n                               session_id=SESSION_ID_STATEFUL\n                              )\n\n        # 4. Test basic delegation (should still work)\n        # This will update 'last_weather_report' again, overwriting the NY weather report\n        print(\"\\n--- Turn 3: Sending a greeting ---\")\n        await call_agent_async(query= \"Hi!\",\n                               runner=runner_root_stateful,\n                               user_id=USER_ID_STATEFUL,\n                               session_id=SESSION_ID_STATEFUL\n                              )\n\n    # --- Execute the `run_stateful_conversation` async function ---\n    # Choose ONE of the methods below based on your environment.\n\n    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n    # it means an event loop is already running, so you can directly await the function.\n    print(\"Attempting execution using 'await' (default for notebooks)...\")\n    await run_stateful_conversation()\n\n    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n    # If running this code as a standard Python script from your terminal,\n    # the script context is synchronous. `asyncio.run()` is needed to\n    # create and manage an event loop to execute your async function.\n    # To use this method:\n    # 1. Comment out the `await run_stateful_conversation()` line above.\n    # 2. Uncomment the following block:\n    \"\"\"\n    import asyncio\n    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n        try:\n            # This creates an event loop, runs your async function, and closes the loop.\n            asyncio.run(run_stateful_conversation())\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n    \"\"\"\n\n    # --- Inspect final session state after the conversation ---\n    # This block runs after either execution method completes.\n    print(\"\\n--- Inspecting Final Session State ---\")\n    final_session = await session_service_stateful.get_session(app_name=APP_NAME,\n                                                         user_id= USER_ID_STATEFUL,\n                                                         session_id=SESSION_ID_STATEFUL)\n    if final_session:\n        # Use .get() for safer access to potentially missing keys\n        print(f\"Final Preference: {final_session.state.get('user_preference_temperature_unit', 'Not Set')}\")\n        print(f\"Final Last Weather Report (from output_key): {final_session.state.get('last_weather_report', 'Not Set')}\")\n        print(f\"Final Last City Checked (by tool): {final_session.state.get('last_city_checked_stateful', 'Not Set')}\")\n        # Print full state for detailed view\n        # print(f\"Full State Dict: {final_session.state}\") # For detailed view\n    else:\n        print(\"\\n\u274c Error: Could not retrieve final session state.\")\n\nelse:\n    print(\"\\n\u26a0\ufe0f Skipping state test conversation. Stateful root agent runner ('runner_root_stateful') is not available.\")"}]}, {"heading_path": ["Step 5: Adding Safety - Input Guardrail with before_model_callback\u00b6"], "text": "Step 5: Adding Safety - Input Guardrail with before_model_callback \u00b6 Our agent team is becoming more capable, remembering preferences and using tools effectively. However, in real-world scenarios, we often need safety mechanisms to control the agent's behavior before potentially problematic requests even reach the core Large Language Model (LLM). ADK provides Callbacks \u2013 functions that allow you to hook into specific points in the agent's execution lifecycle. The before_model_callback is particularly useful for input safety. What is before_model_callback ? It's a Python function you define that ADK executes just before an agent sends its compiled request (including conversation history, instructions, and the latest user message) to the underlying LLM. Purpose: Inspect the request, modify it if necessary, or block it entirely based on predefined rules. Common Use Cases: Input Validation/Filtering: Check if user input meets criteria or contains disallowed content (like PII or keywords). Guardrails: Prevent harmful, off-topic, or policy-violating requests from being processed by the LLM. Dynamic Prompt Modification: Add timely information (e.g., from session state) to the LLM request context just before sending. How it Works: Define a function accepting callback_context: CallbackContext and llm_request: LlmRequest . callback_context : Provides access to agent info, session state ( callback_context.state ), etc. llm_request : Contains the full payload intended for the LLM ( contents , config ). Inside the function: Inspect: Examine llm_request.contents (especially the last user message). Modify (Use Caution): You can change parts of llm_request . Block (Guardrail): Return an LlmResponse object. ADK will send this response back immediately, skipping the LLM call for that turn. Allow: Return None . ADK proceeds to call the LLM with the (potentially modified) request. In this step, we will: Define a before_model_callback function ( block_keyword_guardrail ) that checks the user's input for a specific keyword (\"BLOCK\"). Update our stateful root agent ( weather_agent_v4_stateful from Step 4) to use this callback. Create a new runner associated with this updated agent but using the same stateful session service to maintain state continuity. Test the guardrail by sending both normal and keyword-containing requests. 1. Define the Guardrail Callback Function This function will inspect the last user message within the llm_request content. If it finds \"BLOCK\" (case-insensitive), it constructs and returns an LlmResponse to block the flow; otherwise, it returns None . # @title 1. Define the before_model_callback Guardrail # Ensure necessary imports are available from google.adk.agents.callback_context import CallbackContext from google.adk.models.llm_request import LlmRequest from google.adk.models.llm_response import LlmResponse from google.genai import types # For creating response content from typing import Optional def block_keyword_guardrail ( callback_context : CallbackContext , llm_request : LlmRequest ) -> Optional [ LlmResponse ]: \"\"\" Inspects the latest user message for 'BLOCK'. If found, blocks the LLM call and returns a predefined LlmResponse. Otherwise, returns None to proceed. \"\"\" agent_name = callback_context . agent_name # Get the name of the agent whose model call is being intercepted print ( f \"--- Callback: block_keyword_guardrail running for agent: { agent_name } ---\" ) # Extract the text from the latest user message in the request history last_user_message_text = \"\" if llm_request . contents : # Find the most recent message with role 'user' for content in reversed ( llm_request . contents ): if content . role == 'user' and content . parts : # Assuming text is in the first part for simplicity if content . parts [ 0 ] . text : last_user_message_text = content . parts [ 0 ] . text break # Found the last user message text print ( f \"--- Callback: Inspecting last user message: ' { last_user_message_text [: 100 ] } ...' ---\" ) # Log first 100 chars # --- Guardrail Logic --- keyword_to_block = \"BLOCK\" if keyword_to_block in last_user_message_text . upper (): # Case-insensitive check print ( f \"--- Callback: Found ' { keyword_to_block } '. Blocking LLM call! ---\" ) # Optionally, set a flag in state to record the block event callback_context . state [ \"guardrail_block_keyword_triggered\" ] = True print ( f \"--- Callback: Set state 'guardrail_block_keyword_triggered': True ---\" ) # Construct and return an LlmResponse to stop the flow and send this back instead return LlmResponse ( content = types . Content ( role = \"model\" , # Mimic a response from the agent's perspective parts = [ types . Part ( text = f \"I cannot process this request because it contains the blocked keyword ' { keyword_to_block } '.\" )], ) # Note: You could also set an error_message field here if needed ) else : # Keyword not found, allow the request to proceed to the LLM print ( f \"--- Callback: Keyword not found. Allowing LLM call for { agent_name } . ---\" ) return None # Returning None signals ADK to continue normally print ( \"\u2705 block_keyword_guardrail function defined.\" ) 2. Update Root Agent to Use the Callback We redefine the root agent, adding the before_model_callback parameter and pointing it to our new guardrail function. We'll give it a new version name for clarity. Important: We need to redefine the sub-agents ( greeting_agent , farewell_agent ) and the stateful tool ( get_weather_stateful ) within this context if they are not already available from previous steps, ensuring the root agent definition has access to all its components. # @title 2. Update Root Agent with before_model_callback # --- Redefine Sub-Agents (Ensures they exist in this context) --- greeting_agent = None try : # Use a defined model constant greeting_agent = Agent ( model = MODEL_GEMINI_2_0_FLASH , name = \"greeting_agent\" , # Keep original name for consistency instruction = \"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\" , description = \"Handles simple greetings and hellos using the 'say_hello' tool.\" , tools = [ say_hello ], ) print ( f \"\u2705 Sub-Agent ' { greeting_agent . name } ' redefined.\" ) except Exception as e : print ( f \"\u274c Could not redefine Greeting agent. Check Model/API Key ( { greeting_agent . model } ). Error: { e } \" ) farewell_agent = None try : # Use a defined model constant farewell_agent = Agent ( model = MODEL_GEMINI_2_0_FLASH , name = \"farewell_agent\" , # Keep original name instruction = \"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\" , description = \"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\" , tools = [ say_goodbye ], ) print ( f \"\u2705 Sub-Agent ' { farewell_agent . name } ' redefined.\" ) except Exception as e : print ( f \"\u274c Could not redefine Farewell agent. Check Model/API Key ( { farewell_agent . model } ). Error: { e } \" ) # --- Define the Root Agent with the Callback --- root_agent_model_guardrail = None runner_root_model_guardrail = None # Check all components before proceeding if greeting_agent and farewell_agent and 'get_weather_stateful' in globals () and 'block_keyword_guardrail' in globals (): # Use a defined model constant root_agent_model = MODEL_GEMINI_2_0_FLASH root_agent_model_guardrail = Agent ( name = \"weather_agent_v5_model_guardrail\" , # New version name for clarity model = root_agent_model , description = \"Main agent: Handles weather, delegates greetings/farewells, includes input keyword guardrail.\" , instruction = \"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \" \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \" \"Handle only weather requests, greetings, and farewells.\" , tools = [ get_weather_stateful ], sub_agents = [ greeting_agent , farewell_agent ], # Reference the redefined sub-agents output_key = \"last_weather_report\" , # Keep output_key from Step 4 before_model_callback = block_keyword_guardrail # <<< Assign the guardrail callback ) print ( f \"\u2705 Root Agent ' { root_agent_model_guardrail . name } ' created with before_model_callback.\" ) # --- Create Runner for this Agent, Using SAME Stateful Session Service --- # Ensure session_service_stateful exists from Step 4 if 'session_service_stateful' in globals (): runner_root_model_guardrail = Runner ( agent = root_agent_model_guardrail , app_name = APP_NAME , # Use consistent APP_NAME session_service = session_service_stateful # <<< Use the service from Step 4 ) print ( f \"\u2705 Runner created for guardrail agent ' { runner_root_model_guardrail . agent . name } ', using stateful session service.\" ) else : print ( \"\u274c Cannot create runner. 'session_service_stateful' from Step 4 is missing.\" ) else : print ( \"\u274c Cannot create root agent with model guardrail. One or more prerequisites are missing or failed initialization:\" ) if not greeting_agent : print ( \"   - Greeting Agent\" ) if not farewell_agent : print ( \"   - Farewell Agent\" ) if 'get_weather_stateful' not in globals (): print ( \"   - 'get_weather_stateful' tool\" ) if 'block_keyword_guardrail' not in globals (): print ( \"   - 'block_keyword_guardrail' callback\" ) 3. Interact to Test the Guardrail Let's test the guardrail's behavior. We'll use the same session ( SESSION_ID_STATEFUL ) as in Step 4 to show that state persists across these changes. Send a normal weather request (should pass the guardrail and execute). Send a request containing \"BLOCK\" (should be intercepted by the callback). Send a greeting (should pass the root agent's guardrail, be delegated, and execute normally). # @title 3. Interact to Test the Model Input Guardrail import asyncio # Ensure asyncio is imported # Ensure the runner for the guardrail agent is available if 'runner_root_model_guardrail' in globals () and runner_root_model_guardrail : # Define the main async function for the guardrail test conversation. # The 'await' keywords INSIDE this function are necessary for async operations. async def run_guardrail_test_conversation (): print ( \" \\n --- Testing Model Input Guardrail ---\" ) # Use the runner for the agent with the callback and the existing stateful session ID # Define a helper lambda for cleaner interaction calls interaction_func = lambda query : call_agent_async ( query , runner_root_model_guardrail , USER_ID_STATEFUL , # Use existing user ID SESSION_ID_STATEFUL # Use existing session ID ) # 1. Normal request (Callback allows, should use Fahrenheit from previous state change) print ( \"--- Turn 1: Requesting weather in London (expect allowed, Fahrenheit) ---\" ) await interaction_func ( \"What is the weather in London?\" ) # 2. Request containing the blocked keyword (Callback intercepts) print ( \" \\n --- Turn 2: Requesting with blocked keyword (expect blocked) ---\" ) await interaction_func ( \"BLOCK the request for weather in Tokyo\" ) # Callback should catch \"BLOCK\" # 3. Normal greeting (Callback allows root agent, delegation happens) print ( \" \\n --- Turn 3: Sending a greeting (expect allowed) ---\" ) await interaction_func ( \"Hello again\" ) # --- Execute the `run_guardrail_test_conversation` async function --- # Choose ONE of the methods below based on your environment. # METHOD 1: Direct await (Default for Notebooks/Async REPLs) # If your environment supports top-level await (like Colab/Jupyter notebooks), # it means an event loop is already running, so you can directly await the function. print ( \"Attempting execution using 'await' (default for notebooks)...\" ) await run_guardrail_test_conversation () # METHOD 2: asyncio.run (For Standard Python Scripts [.py]) # If running this code as a standard Python script from your terminal, # the script context is synchronous. `asyncio.run()` is needed to # create and manage an event loop to execute your async function. # To use this method: # 1. Comment out the `await run_guardrail_test_conversation()` line above. # 2. Uncomment the following block: \"\"\" import asyncio if __name__ == \"__main__\": # Ensures this runs only when script is executed directly print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\") try: # This creates an event loop, runs your async function, and closes the loop. asyncio.run(run_guardrail_test_conversation()) except Exception as e: print(f\"An error occurred: {e}\") \"\"\" # --- Inspect final session state after the conversation --- # This block runs after either execution method completes. # Optional: Check state for the trigger flag set by the callback print ( \" \\n --- Inspecting Final Session State (After Guardrail Test) ---\" ) # Use the session service instance associated with this stateful session final_session = await session_service_stateful . get_session ( app_name = APP_NAME , user_id = USER_ID_STATEFUL , session_id = SESSION_ID_STATEFUL ) if final_session : # Use .get() for safer access print ( f \"Guardrail Triggered Flag: { final_session . state . get ( 'guardrail_block_keyword_triggered' , 'Not Set (or False)' ) } \" ) print ( f \"Last Weather Report: { final_session . state . get ( 'last_weather_report' , 'Not Set' ) } \" ) # Should be London weather if successful print ( f \"Temperature Unit: { final_session . state . get ( 'user_preference_temperature_unit' , 'Not Set' ) } \" ) # Should be Fahrenheit # print(f\"Full State Dict: {final_session.state}\") # For detailed view else : print ( \" \\n \u274c Error: Could not retrieve final session state.\" ) else : print ( \" \\n \u26a0\ufe0f Skipping model guardrail test. Runner ('runner_root_model_guardrail') is not available.\" ) Observe the execution flow: London Weather: The callback runs for weather_agent_v5_model_guardrail , inspects the message, prints \"Keyword not found. Allowing LLM call.\", and returns None . The agent proceeds, calls the get_weather_stateful tool (which uses the \"Fahrenheit\" preference from Step 4's state change), and returns the weather. This response updates last_weather_report via output_key . BLOCK Request: The callback runs again for weather_agent_v5_model_guardrail , inspects the message, finds \"BLOCK\", prints \"Blocking LLM call!\", sets the state flag, and returns the predefined LlmResponse . The agent's underlying LLM is never called for this turn. The user sees the callback's blocking message. Hello Again: The callback runs for weather_agent_v5_model_guardrail , allows the request. The root agent then delegates to greeting_agent . Note: The before_model_callback defined on the root agent does NOT automatically apply to sub-agents. The greeting_agent proceeds normally, calls its say_hello tool, and returns the greeting. You have successfully implemented an input safety layer! The before_model_callback provides a powerful mechanism to enforce rules and control agent behavior before expensive or potentially risky LLM calls are made. Next, we'll apply a similar concept to add guardrails around tool usage itself. ", "code_blocks": [{"language": "text", "code": "# @title 1. Define the before_model_callback Guardrail\n\n# Ensure necessary imports are available\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.models.llm_request import LlmRequest\nfrom google.adk.models.llm_response import LlmResponse\nfrom google.genai import types # For creating response content\nfrom typing import Optional\n\ndef block_keyword_guardrail(\n    callback_context: CallbackContext, llm_request: LlmRequest\n) -> Optional[LlmResponse]:\n    \"\"\"\n    Inspects the latest user message for 'BLOCK'. If found, blocks the LLM call\n    and returns a predefined LlmResponse. Otherwise, returns None to proceed.\n    \"\"\"\n    agent_name = callback_context.agent_name # Get the name of the agent whose model call is being intercepted\n    print(f\"--- Callback: block_keyword_guardrail running for agent: {agent_name} ---\")\n\n    # Extract the text from the latest user message in the request history\n    last_user_message_text = \"\"\n    if llm_request.contents:\n        # Find the most recent message with role 'user'\n        for content in reversed(llm_request.contents):\n            if content.role == 'user' and content.parts:\n                # Assuming text is in the first part for simplicity\n                if content.parts[0].text:\n                    last_user_message_text = content.parts[0].text\n                    break # Found the last user message text\n\n    print(f\"--- Callback: Inspecting last user message: '{last_user_message_text[:100]}...' ---\") # Log first 100 chars\n\n    # --- Guardrail Logic ---\n    keyword_to_block = \"BLOCK\"\n    if keyword_to_block in last_user_message_text.upper(): # Case-insensitive check\n        print(f\"--- Callback: Found '{keyword_to_block}'. Blocking LLM call! ---\")\n        # Optionally, set a flag in state to record the block event\n        callback_context.state[\"guardrail_block_keyword_triggered\"] = True\n        print(f\"--- Callback: Set state 'guardrail_block_keyword_triggered': True ---\")\n\n        # Construct and return an LlmResponse to stop the flow and send this back instead\n        return LlmResponse(\n            content=types.Content(\n                role=\"model\", # Mimic a response from the agent's perspective\n                parts=[types.Part(text=f\"I cannot process this request because it contains the blocked keyword '{keyword_to_block}'.\")],\n            )\n            # Note: You could also set an error_message field here if needed\n        )\n    else:\n        # Keyword not found, allow the request to proceed to the LLM\n        print(f\"--- Callback: Keyword not found. Allowing LLM call for {agent_name}. ---\")\n        return None # Returning None signals ADK to continue normally\n\nprint(\"\u2705 block_keyword_guardrail function defined.\")"}, {"language": "text", "code": "# @title 2. Update Root Agent with before_model_callback\n\n\n# --- Redefine Sub-Agents (Ensures they exist in this context) ---\ngreeting_agent = None\ntry:\n    # Use a defined model constant\n    greeting_agent = Agent(\n        model=MODEL_GEMINI_2_0_FLASH,\n        name=\"greeting_agent\", # Keep original name for consistency\n        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n        tools=[say_hello],\n    )\n    print(f\"\u2705 Sub-Agent '{greeting_agent.name}' redefined.\")\nexcept Exception as e:\n    print(f\"\u274c Could not redefine Greeting agent. Check Model/API Key ({greeting_agent.model}). Error: {e}\")\n\nfarewell_agent = None\ntry:\n    # Use a defined model constant\n    farewell_agent = Agent(\n        model=MODEL_GEMINI_2_0_FLASH,\n        name=\"farewell_agent\", # Keep original name\n        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n        tools=[say_goodbye],\n    )\n    print(f\"\u2705 Sub-Agent '{farewell_agent.name}' redefined.\")\nexcept Exception as e:\n    print(f\"\u274c Could not redefine Farewell agent. Check Model/API Key ({farewell_agent.model}). Error: {e}\")\n\n\n# --- Define the Root Agent with the Callback ---\nroot_agent_model_guardrail = None\nrunner_root_model_guardrail = None\n\n# Check all components before proceeding\nif greeting_agent and farewell_agent and 'get_weather_stateful' in globals() and 'block_keyword_guardrail' in globals():\n\n    # Use a defined model constant\n    root_agent_model = MODEL_GEMINI_2_0_FLASH\n\n    root_agent_model_guardrail = Agent(\n        name=\"weather_agent_v5_model_guardrail\", # New version name for clarity\n        model=root_agent_model,\n        description=\"Main agent: Handles weather, delegates greetings/farewells, includes input keyword guardrail.\",\n        instruction=\"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \"\n                    \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n                    \"Handle only weather requests, greetings, and farewells.\",\n        tools=[get_weather_stateful],\n        sub_agents=[greeting_agent, farewell_agent], # Reference the redefined sub-agents\n        output_key=\"last_weather_report\", # Keep output_key from Step 4\n        before_model_callback=block_keyword_guardrail # <<< Assign the guardrail callback\n    )\n    print(f\"\u2705 Root Agent '{root_agent_model_guardrail.name}' created with before_model_callback.\")\n\n    # --- Create Runner for this Agent, Using SAME Stateful Session Service ---\n    # Ensure session_service_stateful exists from Step 4\n    if 'session_service_stateful' in globals():\n        runner_root_model_guardrail = Runner(\n            agent=root_agent_model_guardrail,\n            app_name=APP_NAME, # Use consistent APP_NAME\n            session_service=session_service_stateful # <<< Use the service from Step 4\n        )\n        print(f\"\u2705 Runner created for guardrail agent '{runner_root_model_guardrail.agent.name}', using stateful session service.\")\n    else:\n        print(\"\u274c Cannot create runner. 'session_service_stateful' from Step 4 is missing.\")\n\nelse:\n    print(\"\u274c Cannot create root agent with model guardrail. One or more prerequisites are missing or failed initialization:\")\n    if not greeting_agent: print(\"   - Greeting Agent\")\n    if not farewell_agent: print(\"   - Farewell Agent\")\n    if 'get_weather_stateful' not in globals(): print(\"   - 'get_weather_stateful' tool\")\n    if 'block_keyword_guardrail' not in globals(): print(\"   - 'block_keyword_guardrail' callback\")"}, {"language": "text", "code": "# @title 3. Interact to Test the Model Input Guardrail\nimport asyncio # Ensure asyncio is imported\n\n# Ensure the runner for the guardrail agent is available\nif 'runner_root_model_guardrail' in globals() and runner_root_model_guardrail:\n    # Define the main async function for the guardrail test conversation.\n    # The 'await' keywords INSIDE this function are necessary for async operations.\n    async def run_guardrail_test_conversation():\n        print(\"\\n--- Testing Model Input Guardrail ---\")\n\n        # Use the runner for the agent with the callback and the existing stateful session ID\n        # Define a helper lambda for cleaner interaction calls\n        interaction_func = lambda query: call_agent_async(query,\n                                                         runner_root_model_guardrail,\n                                                         USER_ID_STATEFUL, # Use existing user ID\n                                                         SESSION_ID_STATEFUL # Use existing session ID\n                                                        )\n        # 1. Normal request (Callback allows, should use Fahrenheit from previous state change)\n        print(\"--- Turn 1: Requesting weather in London (expect allowed, Fahrenheit) ---\")\n        await interaction_func(\"What is the weather in London?\")\n\n        # 2. Request containing the blocked keyword (Callback intercepts)\n        print(\"\\n--- Turn 2: Requesting with blocked keyword (expect blocked) ---\")\n        await interaction_func(\"BLOCK the request for weather in Tokyo\") # Callback should catch \"BLOCK\"\n\n        # 3. Normal greeting (Callback allows root agent, delegation happens)\n        print(\"\\n--- Turn 3: Sending a greeting (expect allowed) ---\")\n        await interaction_func(\"Hello again\")\n\n    # --- Execute the `run_guardrail_test_conversation` async function ---\n    # Choose ONE of the methods below based on your environment.\n\n    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n    # it means an event loop is already running, so you can directly await the function.\n    print(\"Attempting execution using 'await' (default for notebooks)...\")\n    await run_guardrail_test_conversation()\n\n    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n    # If running this code as a standard Python script from your terminal,\n    # the script context is synchronous. `asyncio.run()` is needed to\n    # create and manage an event loop to execute your async function.\n    # To use this method:\n    # 1. Comment out the `await run_guardrail_test_conversation()` line above.\n    # 2. Uncomment the following block:\n    \"\"\"\n    import asyncio\n    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n        try:\n            # This creates an event loop, runs your async function, and closes the loop.\n            asyncio.run(run_guardrail_test_conversation())\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n    \"\"\"\n\n    # --- Inspect final session state after the conversation ---\n    # This block runs after either execution method completes.\n    # Optional: Check state for the trigger flag set by the callback\n    print(\"\\n--- Inspecting Final Session State (After Guardrail Test) ---\")\n    # Use the session service instance associated with this stateful session\n    final_session = await session_service_stateful.get_session(app_name=APP_NAME,\n                                                         user_id=USER_ID_STATEFUL,\n                                                         session_id=SESSION_ID_STATEFUL)\n    if final_session:\n        # Use .get() for safer access\n        print(f\"Guardrail Triggered Flag: {final_session.state.get('guardrail_block_keyword_triggered', 'Not Set (or False)')}\")\n        print(f\"Last Weather Report: {final_session.state.get('last_weather_report', 'Not Set')}\") # Should be London weather if successful\n        print(f\"Temperature Unit: {final_session.state.get('user_preference_temperature_unit', 'Not Set')}\") # Should be Fahrenheit\n        # print(f\"Full State Dict: {final_session.state}\") # For detailed view\n    else:\n        print(\"\\n\u274c Error: Could not retrieve final session state.\")\n\nelse:\n    print(\"\\n\u26a0\ufe0f Skipping model guardrail test. Runner ('runner_root_model_guardrail') is not available.\")"}]}, {"heading_path": ["Step 6: Adding Safety - Tool Argument Guardrail (before_tool_callback)\u00b6"], "text": "Step 6: Adding Safety - Tool Argument Guardrail ( before_tool_callback ) \u00b6 In Step 5, we added a guardrail to inspect and potentially block user input before it reached the LLM. Now, we'll add another layer of control after the LLM has decided to use a tool but before that tool actually executes. This is useful for validating the arguments the LLM wants to pass to the tool. ADK provides the before_tool_callback for this precise purpose. What is before_tool_callback ? It's a Python function executed just before a specific tool function runs, after the LLM has requested its use and decided on the arguments. Purpose: Validate tool arguments, prevent tool execution based on specific inputs, modify arguments dynamically, or enforce resource usage policies. Common Use Cases: Argument Validation: Check if arguments provided by the LLM are valid, within allowed ranges, or conform to expected formats. Resource Protection: Prevent tools from being called with inputs that might be costly, access restricted data, or cause unwanted side effects (e.g., blocking API calls for certain parameters). Dynamic Argument Modification: Adjust arguments based on session state or other contextual information before the tool runs. How it Works: Define a function accepting tool: BaseTool , args: Dict[str, Any] , and tool_context: ToolContext . tool : The tool object about to be called (inspect tool.name ). args : The dictionary of arguments the LLM generated for the tool. tool_context : Provides access to session state ( tool_context.state ), agent info, etc. Inside the function: Inspect: Examine the tool.name and the args dictionary. Modify: Change values within the args dictionary directly . If you return None , the tool runs with these modified args. Block/Override (Guardrail): Return a dictionary . ADK treats this dictionary as the result of the tool call, completely skipping the execution of the original tool function. The dictionary should ideally match the expected return format of the tool it's blocking. Allow: Return None . ADK proceeds to execute the actual tool function with the (potentially modified) arguments. In this step, we will: Define a before_tool_callback function ( block_paris_tool_guardrail ) that specifically checks if the get_weather_stateful tool is called with the city \"Paris\". If \"Paris\" is detected, the callback will block the tool and return a custom error dictionary. Update our root agent ( weather_agent_v6_tool_guardrail ) to include both the before_model_callback and this new before_tool_callback . Create a new runner for this agent, using the same stateful session service. Test the flow by requesting weather for allowed cities and the blocked city (\"Paris\"). 1. Define the Tool Guardrail Callback Function This function targets the get_weather_stateful tool. It checks the city argument. If it's \"Paris\", it returns an error dictionary that looks like the tool's own error response. Otherwise, it allows the tool to run by returning None . # @title 1. Define the before_tool_callback Guardrail # Ensure necessary imports are available from google.adk.tools.base_tool import BaseTool from google.adk.tools.tool_context import ToolContext from typing import Optional , Dict , Any # For type hints def block_paris_tool_guardrail ( tool : BaseTool , args : Dict [ str , Any ], tool_context : ToolContext ) -> Optional [ Dict ]: \"\"\" Checks if 'get_weather_stateful' is called for 'Paris'. If so, blocks the tool execution and returns a specific error dictionary. Otherwise, allows the tool call to proceed by returning None. \"\"\" tool_name = tool . name agent_name = tool_context . agent_name # Agent attempting the tool call print ( f \"--- Callback: block_paris_tool_guardrail running for tool ' { tool_name } ' in agent ' { agent_name } ' ---\" ) print ( f \"--- Callback: Inspecting args: { args } ---\" ) # --- Guardrail Logic --- target_tool_name = \"get_weather_stateful\" # Match the function name used by FunctionTool blocked_city = \"paris\" # Check if it's the correct tool and the city argument matches the blocked city if tool_name == target_tool_name : city_argument = args . get ( \"city\" , \"\" ) # Safely get the 'city' argument if city_argument and city_argument . lower () == blocked_city : print ( f \"--- Callback: Detected blocked city ' { city_argument } '. Blocking tool execution! ---\" ) # Optionally update state tool_context . state [ \"guardrail_tool_block_triggered\" ] = True print ( f \"--- Callback: Set state 'guardrail_tool_block_triggered': True ---\" ) # Return a dictionary matching the tool's expected output format for errors # This dictionary becomes the tool's result, skipping the actual tool run. return { \"status\" : \"error\" , \"error_message\" : f \"Policy restriction: Weather checks for ' { city_argument . capitalize () } ' are currently disabled by a tool guardrail.\" } else : print ( f \"--- Callback: City ' { city_argument } ' is allowed for tool ' { tool_name } '. ---\" ) else : print ( f \"--- Callback: Tool ' { tool_name } ' is not the target tool. Allowing. ---\" ) # If the checks above didn't return a dictionary, allow the tool to execute print ( f \"--- Callback: Allowing tool ' { tool_name } ' to proceed. ---\" ) return None # Returning None allows the actual tool function to run print ( \"\u2705 block_paris_tool_guardrail function defined.\" ) 2. Update Root Agent to Use Both Callbacks We redefine the root agent again ( weather_agent_v6_tool_guardrail ), this time adding the before_tool_callback parameter alongside the before_model_callback from Step 5. Self-Contained Execution Note: Similar to Step 5, ensure all prerequisites (sub-agents, tools, before_model_callback ) are defined or available in the execution context before defining this agent. # @title 2. Update Root Agent with BOTH Callbacks (Self-Contained) # --- Ensure Prerequisites are Defined --- # (Include or ensure execution of definitions for: Agent, LiteLlm, Runner, ToolContext, #  MODEL constants, say_hello, say_goodbye, greeting_agent, farewell_agent, #  get_weather_stateful, block_keyword_guardrail, block_paris_tool_guardrail) # --- Redefine Sub-Agents (Ensures they exist in this context) --- greeting_agent = None try : # Use a defined model constant greeting_agent = Agent ( model = MODEL_GEMINI_2_0_FLASH , name = \"greeting_agent\" , # Keep original name for consistency instruction = \"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\" , description = \"Handles simple greetings and hellos using the 'say_hello' tool.\" , tools = [ say_hello ], ) print ( f \"\u2705 Sub-Agent ' { greeting_agent . name } ' redefined.\" ) except Exception as e : print ( f \"\u274c Could not redefine Greeting agent. Check Model/API Key ( { greeting_agent . model } ). Error: { e } \" ) farewell_agent = None try : # Use a defined model constant farewell_agent = Agent ( model = MODEL_GEMINI_2_0_FLASH , name = \"farewell_agent\" , # Keep original name instruction = \"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\" , description = \"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\" , tools = [ say_goodbye ], ) print ( f \"\u2705 Sub-Agent ' { farewell_agent . name } ' redefined.\" ) except Exception as e : print ( f \"\u274c Could not redefine Farewell agent. Check Model/API Key ( { farewell_agent . model } ). Error: { e } \" ) # --- Define the Root Agent with Both Callbacks --- root_agent_tool_guardrail = None runner_root_tool_guardrail = None if ( 'greeting_agent' in globals () and greeting_agent and 'farewell_agent' in globals () and farewell_agent and 'get_weather_stateful' in globals () and 'block_keyword_guardrail' in globals () and 'block_paris_tool_guardrail' in globals ()): root_agent_model = MODEL_GEMINI_2_0_FLASH root_agent_tool_guardrail = Agent ( name = \"weather_agent_v6_tool_guardrail\" , # New version name model = root_agent_model , description = \"Main agent: Handles weather, delegates, includes input AND tool guardrails.\" , instruction = \"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \" \"Delegate greetings to 'greeting_agent' and farewells to 'farewell_agent'. \" \"Handle only weather, greetings, and farewells.\" , tools = [ get_weather_stateful ], sub_agents = [ greeting_agent , farewell_agent ], output_key = \"last_weather_report\" , before_model_callback = block_keyword_guardrail , # Keep model guardrail before_tool_callback = block_paris_tool_guardrail # <<< Add tool guardrail ) print ( f \"\u2705 Root Agent ' { root_agent_tool_guardrail . name } ' created with BOTH callbacks.\" ) # --- Create Runner, Using SAME Stateful Session Service --- if 'session_service_stateful' in globals (): runner_root_tool_guardrail = Runner ( agent = root_agent_tool_guardrail , app_name = APP_NAME , session_service = session_service_stateful # <<< Use the service from Step 4/5 ) print ( f \"\u2705 Runner created for tool guardrail agent ' { runner_root_tool_guardrail . agent . name } ', using stateful session service.\" ) else : print ( \"\u274c Cannot create runner. 'session_service_stateful' from Step 4/5 is missing.\" ) else : print ( \"\u274c Cannot create root agent with tool guardrail. Prerequisites missing.\" ) 3. Interact to Test the Tool Guardrail Let's test the interaction flow, again using the same stateful session ( SESSION_ID_STATEFUL ) from the previous steps. Request weather for \"New York\": Passes both callbacks, tool executes (using Fahrenheit preference from state). Request weather for \"Paris\": Passes before_model_callback . LLM decides to call get_weather_stateful(city='Paris') . before_tool_callback intercepts, blocks the tool, and returns the error dictionary. Agent relays this error. Request weather for \"London\": Passes both callbacks, tool executes normally. # @title 3. Interact to Test the Tool Argument Guardrail import asyncio # Ensure asyncio is imported # Ensure the runner for the tool guardrail agent is available if 'runner_root_tool_guardrail' in globals () and runner_root_tool_guardrail : # Define the main async function for the tool guardrail test conversation. # The 'await' keywords INSIDE this function are necessary for async operations. async def run_tool_guardrail_test (): print ( \" \\n --- Testing Tool Argument Guardrail ('Paris' blocked) ---\" ) # Use the runner for the agent with both callbacks and the existing stateful session # Define a helper lambda for cleaner interaction calls interaction_func = lambda query : call_agent_async ( query , runner_root_tool_guardrail , USER_ID_STATEFUL , # Use existing user ID SESSION_ID_STATEFUL # Use existing session ID ) # 1. Allowed city (Should pass both callbacks, use Fahrenheit state) print ( \"--- Turn 1: Requesting weather in New York (expect allowed) ---\" ) await interaction_func ( \"What's the weather in New York?\" ) # 2. Blocked city (Should pass model callback, but be blocked by tool callback) print ( \" \\n --- Turn 2: Requesting weather in Paris (expect blocked by tool guardrail) ---\" ) await interaction_func ( \"How about Paris?\" ) # Tool callback should intercept this # 3. Another allowed city (Should work normally again) print ( \" \\n --- Turn 3: Requesting weather in London (expect allowed) ---\" ) await interaction_func ( \"Tell me the weather in London.\" ) # --- Execute the `run_tool_guardrail_test` async function --- # Choose ONE of the methods below based on your environment. # METHOD 1: Direct await (Default for Notebooks/Async REPLs) # If your environment supports top-level await (like Colab/Jupyter notebooks), # it means an event loop is already running, so you can directly await the function. print ( \"Attempting execution using 'await' (default for notebooks)...\" ) await run_tool_guardrail_test () # METHOD 2: asyncio.run (For Standard Python Scripts [.py]) # If running this code as a standard Python script from your terminal, # the script context is synchronous. `asyncio.run()` is needed to # create and manage an event loop to execute your async function. # To use this method: # 1. Comment out the `await run_tool_guardrail_test()` line above. # 2. Uncomment the following block: \"\"\" import asyncio if __name__ == \"__main__\": # Ensures this runs only when script is executed directly print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\") try: # This creates an event loop, runs your async function, and closes the loop. asyncio.run(run_tool_guardrail_test()) except Exception as e: print(f\"An error occurred: {e}\") \"\"\" # --- Inspect final session state after the conversation --- # This block runs after either execution method completes. # Optional: Check state for the tool block trigger flag print ( \" \\n --- Inspecting Final Session State (After Tool Guardrail Test) ---\" ) # Use the session service instance associated with this stateful session final_session = await session_service_stateful . get_session ( app_name = APP_NAME , user_id = USER_ID_STATEFUL , session_id = SESSION_ID_STATEFUL ) if final_session : # Use .get() for safer access print ( f \"Tool Guardrail Triggered Flag: { final_session . state . get ( 'guardrail_tool_block_triggered' , 'Not Set (or False)' ) } \" ) print ( f \"Last Weather Report: { final_session . state . get ( 'last_weather_report' , 'Not Set' ) } \" ) # Should be London weather if successful print ( f \"Temperature Unit: { final_session . state . get ( 'user_preference_temperature_unit' , 'Not Set' ) } \" ) # Should be Fahrenheit # print(f\"Full State Dict: {final_session.state}\") # For detailed view else : print ( \" \\n \u274c Error: Could not retrieve final session state.\" ) else : print ( \" \\n \u26a0\ufe0f Skipping tool guardrail test. Runner ('runner_root_tool_guardrail') is not available.\" ) Analyze the output: New York: The before_model_callback allows the request. The LLM requests get_weather_stateful . The before_tool_callback runs, inspects the args ( {'city': 'New York'} ), sees it's not \"Paris\", prints \"Allowing tool...\" and returns None . The actual get_weather_stateful function executes, reads \"Fahrenheit\" from state, and returns the weather report. The agent relays this, and it gets saved via output_key . Paris: The before_model_callback allows the request. The LLM requests get_weather_stateful(city='Paris') . The before_tool_callback runs, inspects the args, detects \"Paris\", prints \"Blocking tool execution!\", sets the state flag, and returns the error dictionary {'status': 'error', 'error_message': 'Policy restriction...'} . The actual get_weather_stateful function is never executed . The agent receives the error dictionary as if it were the tool's output and formulates a response based on that error message. London: Behaves like New York, passing both callbacks and executing the tool successfully. The new London weather report overwrites the last_weather_report in the state. You've now added a crucial safety layer controlling not just what reaches the LLM, but also how the agent's tools can be used based on the specific arguments generated by the LLM. Callbacks like before_model_callback and before_tool_callback are essential for building robust, safe, and policy-compliant agent applications. ", "code_blocks": [{"language": "text", "code": "# @title 1. Define the before_tool_callback Guardrail\n\n# Ensure necessary imports are available\nfrom google.adk.tools.base_tool import BaseTool\nfrom google.adk.tools.tool_context import ToolContext\nfrom typing import Optional, Dict, Any # For type hints\n\ndef block_paris_tool_guardrail(\n    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext\n) -> Optional[Dict]:\n    \"\"\"\n    Checks if 'get_weather_stateful' is called for 'Paris'.\n    If so, blocks the tool execution and returns a specific error dictionary.\n    Otherwise, allows the tool call to proceed by returning None.\n    \"\"\"\n    tool_name = tool.name\n    agent_name = tool_context.agent_name # Agent attempting the tool call\n    print(f\"--- Callback: block_paris_tool_guardrail running for tool '{tool_name}' in agent '{agent_name}' ---\")\n    print(f\"--- Callback: Inspecting args: {args} ---\")\n\n    # --- Guardrail Logic ---\n    target_tool_name = \"get_weather_stateful\" # Match the function name used by FunctionTool\n    blocked_city = \"paris\"\n\n    # Check if it's the correct tool and the city argument matches the blocked city\n    if tool_name == target_tool_name:\n        city_argument = args.get(\"city\", \"\") # Safely get the 'city' argument\n        if city_argument and city_argument.lower() == blocked_city:\n            print(f\"--- Callback: Detected blocked city '{city_argument}'. Blocking tool execution! ---\")\n            # Optionally update state\n            tool_context.state[\"guardrail_tool_block_triggered\"] = True\n            print(f\"--- Callback: Set state 'guardrail_tool_block_triggered': True ---\")\n\n            # Return a dictionary matching the tool's expected output format for errors\n            # This dictionary becomes the tool's result, skipping the actual tool run.\n            return {\n                \"status\": \"error\",\n                \"error_message\": f\"Policy restriction: Weather checks for '{city_argument.capitalize()}' are currently disabled by a tool guardrail.\"\n            }\n        else:\n             print(f\"--- Callback: City '{city_argument}' is allowed for tool '{tool_name}'. ---\")\n    else:\n        print(f\"--- Callback: Tool '{tool_name}' is not the target tool. Allowing. ---\")\n\n\n    # If the checks above didn't return a dictionary, allow the tool to execute\n    print(f\"--- Callback: Allowing tool '{tool_name}' to proceed. ---\")\n    return None # Returning None allows the actual tool function to run\n\nprint(\"\u2705 block_paris_tool_guardrail function defined.\")"}, {"language": "text", "code": "# @title 2. Update Root Agent with BOTH Callbacks (Self-Contained)\n\n# --- Ensure Prerequisites are Defined ---\n# (Include or ensure execution of definitions for: Agent, LiteLlm, Runner, ToolContext,\n#  MODEL constants, say_hello, say_goodbye, greeting_agent, farewell_agent,\n#  get_weather_stateful, block_keyword_guardrail, block_paris_tool_guardrail)\n\n# --- Redefine Sub-Agents (Ensures they exist in this context) ---\ngreeting_agent = None\ntry:\n    # Use a defined model constant\n    greeting_agent = Agent(\n        model=MODEL_GEMINI_2_0_FLASH,\n        name=\"greeting_agent\", # Keep original name for consistency\n        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n        tools=[say_hello],\n    )\n    print(f\"\u2705 Sub-Agent '{greeting_agent.name}' redefined.\")\nexcept Exception as e:\n    print(f\"\u274c Could not redefine Greeting agent. Check Model/API Key ({greeting_agent.model}). Error: {e}\")\n\nfarewell_agent = None\ntry:\n    # Use a defined model constant\n    farewell_agent = Agent(\n        model=MODEL_GEMINI_2_0_FLASH,\n        name=\"farewell_agent\", # Keep original name\n        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n        tools=[say_goodbye],\n    )\n    print(f\"\u2705 Sub-Agent '{farewell_agent.name}' redefined.\")\nexcept Exception as e:\n    print(f\"\u274c Could not redefine Farewell agent. Check Model/API Key ({farewell_agent.model}). Error: {e}\")\n\n# --- Define the Root Agent with Both Callbacks ---\nroot_agent_tool_guardrail = None\nrunner_root_tool_guardrail = None\n\nif ('greeting_agent' in globals() and greeting_agent and\n    'farewell_agent' in globals() and farewell_agent and\n    'get_weather_stateful' in globals() and\n    'block_keyword_guardrail' in globals() and\n    'block_paris_tool_guardrail' in globals()):\n\n    root_agent_model = MODEL_GEMINI_2_0_FLASH\n\n    root_agent_tool_guardrail = Agent(\n        name=\"weather_agent_v6_tool_guardrail\", # New version name\n        model=root_agent_model,\n        description=\"Main agent: Handles weather, delegates, includes input AND tool guardrails.\",\n        instruction=\"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \"\n                    \"Delegate greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n                    \"Handle only weather, greetings, and farewells.\",\n        tools=[get_weather_stateful],\n        sub_agents=[greeting_agent, farewell_agent],\n        output_key=\"last_weather_report\",\n        before_model_callback=block_keyword_guardrail, # Keep model guardrail\n        before_tool_callback=block_paris_tool_guardrail # <<< Add tool guardrail\n    )\n    print(f\"\u2705 Root Agent '{root_agent_tool_guardrail.name}' created with BOTH callbacks.\")\n\n    # --- Create Runner, Using SAME Stateful Session Service ---\n    if 'session_service_stateful' in globals():\n        runner_root_tool_guardrail = Runner(\n            agent=root_agent_tool_guardrail,\n            app_name=APP_NAME,\n            session_service=session_service_stateful # <<< Use the service from Step 4/5\n        )\n        print(f\"\u2705 Runner created for tool guardrail agent '{runner_root_tool_guardrail.agent.name}', using stateful session service.\")\n    else:\n        print(\"\u274c Cannot create runner. 'session_service_stateful' from Step 4/5 is missing.\")\n\nelse:\n    print(\"\u274c Cannot create root agent with tool guardrail. Prerequisites missing.\")"}, {"language": "text", "code": "# @title 3. Interact to Test the Tool Argument Guardrail\nimport asyncio # Ensure asyncio is imported\n\n# Ensure the runner for the tool guardrail agent is available\nif 'runner_root_tool_guardrail' in globals() and runner_root_tool_guardrail:\n    # Define the main async function for the tool guardrail test conversation.\n    # The 'await' keywords INSIDE this function are necessary for async operations.\n    async def run_tool_guardrail_test():\n        print(\"\\n--- Testing Tool Argument Guardrail ('Paris' blocked) ---\")\n\n        # Use the runner for the agent with both callbacks and the existing stateful session\n        # Define a helper lambda for cleaner interaction calls\n        interaction_func = lambda query: call_agent_async(query,\n                                                         runner_root_tool_guardrail,\n                                                         USER_ID_STATEFUL, # Use existing user ID\n                                                         SESSION_ID_STATEFUL # Use existing session ID\n                                                        )\n        # 1. Allowed city (Should pass both callbacks, use Fahrenheit state)\n        print(\"--- Turn 1: Requesting weather in New York (expect allowed) ---\")\n        await interaction_func(\"What's the weather in New York?\")\n\n        # 2. Blocked city (Should pass model callback, but be blocked by tool callback)\n        print(\"\\n--- Turn 2: Requesting weather in Paris (expect blocked by tool guardrail) ---\")\n        await interaction_func(\"How about Paris?\") # Tool callback should intercept this\n\n        # 3. Another allowed city (Should work normally again)\n        print(\"\\n--- Turn 3: Requesting weather in London (expect allowed) ---\")\n        await interaction_func(\"Tell me the weather in London.\")\n\n    # --- Execute the `run_tool_guardrail_test` async function ---\n    # Choose ONE of the methods below based on your environment.\n\n    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n    # it means an event loop is already running, so you can directly await the function.\n    print(\"Attempting execution using 'await' (default for notebooks)...\")\n    await run_tool_guardrail_test()\n\n    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n    # If running this code as a standard Python script from your terminal,\n    # the script context is synchronous. `asyncio.run()` is needed to\n    # create and manage an event loop to execute your async function.\n    # To use this method:\n    # 1. Comment out the `await run_tool_guardrail_test()` line above.\n    # 2. Uncomment the following block:\n    \"\"\"\n    import asyncio\n    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n        try:\n            # This creates an event loop, runs your async function, and closes the loop.\n            asyncio.run(run_tool_guardrail_test())\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n    \"\"\"\n\n    # --- Inspect final session state after the conversation ---\n    # This block runs after either execution method completes.\n    # Optional: Check state for the tool block trigger flag\n    print(\"\\n--- Inspecting Final Session State (After Tool Guardrail Test) ---\")\n    # Use the session service instance associated with this stateful session\n    final_session = await session_service_stateful.get_session(app_name=APP_NAME,\n                                                         user_id=USER_ID_STATEFUL,\n                                                         session_id= SESSION_ID_STATEFUL)\n    if final_session:\n        # Use .get() for safer access\n        print(f\"Tool Guardrail Triggered Flag: {final_session.state.get('guardrail_tool_block_triggered', 'Not Set (or False)')}\")\n        print(f\"Last Weather Report: {final_session.state.get('last_weather_report', 'Not Set')}\") # Should be London weather if successful\n        print(f\"Temperature Unit: {final_session.state.get('user_preference_temperature_unit', 'Not Set')}\") # Should be Fahrenheit\n        # print(f\"Full State Dict: {final_session.state}\") # For detailed view\n    else:\n        print(\"\\n\u274c Error: Could not retrieve final session state.\")\n\nelse:\n    print(\"\\n\u26a0\ufe0f Skipping tool guardrail test. Runner ('runner_root_tool_guardrail') is not available.\")"}]}, {"heading_path": ["Conclusion: Your Agent Team is Ready!\u00b6"], "text": "Conclusion: Your Agent Team is Ready! \u00b6 Congratulations! You've successfully journeyed from building a single, basic weather agent to constructing a sophisticated, multi-agent team using the Agent Development Kit (ADK). Let's recap what you've accomplished: You started with a fundamental agent equipped with a single tool ( get_weather ). You explored ADK's multi-model flexibility using LiteLLM, running the same core logic with different LLMs like Gemini, GPT-4o, and Claude. You embraced modularity by creating specialized sub-agents ( greeting_agent , farewell_agent ) and enabling automatic delegation from a root agent. You gave your agents memory using Session State , allowing them to remember user preferences ( temperature_unit ) and past interactions ( output_key ). You implemented crucial safety guardrails using both before_model_callback (blocking specific input keywords) and before_tool_callback (blocking tool execution based on arguments like the city \"Paris\"). Through building this progressive Weather Bot team, you've gained hands-on experience with core ADK concepts essential for developing complex, intelligent applications. Key Takeaways: Agents & Tools: The fundamental building blocks for defining capabilities and reasoning. Clear instructions and docstrings are paramount. Runners & Session Services: The engine and memory management system that orchestrate agent execution and maintain conversational context. Delegation: Designing multi-agent teams allows for specialization, modularity, and better management of complex tasks. Agent description is key for auto-flow. Session State ( ToolContext , output_key ): Essential for creating context-aware, personalized, and multi-turn conversational agents. Callbacks ( before_model , before_tool ): Powerful hooks for implementing safety, validation, policy enforcement, and dynamic modifications before critical operations (LLM calls or tool execution). Flexibility ( LiteLlm ): ADK empowers you to choose the best LLM for the job, balancing performance, cost, and features. Where to Go Next? Your Weather Bot team is a great starting point. Here are some ideas to further explore ADK and enhance your application: Real Weather API: Replace the mock_weather_db in your get_weather tool with a call to a real weather API (like OpenWeatherMap, WeatherAPI). More Complex State: Store more user preferences (e.g., preferred location, notification settings) or conversation summaries in the session state. Refine Delegation: Experiment with different root agent instructions or sub-agent descriptions to fine-tune the delegation logic. Could you add a \"forecast\" agent? Advanced Callbacks: Use after_model_callback to potentially reformat or sanitize the LLM's response after it's generated. Use after_tool_callback to process or log the results returned by a tool. Implement before_agent_callback or after_agent_callback for agent-level entry/exit logic. Error Handling: Improve how the agent handles tool errors or unexpected API responses. Maybe add retry logic within a tool. Persistent Session Storage: Explore alternatives to InMemorySessionService for storing session state persistently (e.g., using databases like Firestore or Cloud SQL \u2013 requires custom implementation or future ADK integrations). Streaming UI: Integrate your agent team with a web framework (like FastAPI, as shown in the ADK Streaming Quickstart) to create a real-time chat interface. The Agent Development Kit provides a robust foundation for building sophisticated LLM-powered applications. By mastering the concepts covered in this tutorial \u2013 tools, state, delegation, and callbacks \u2013 you are well-equipped to tackle increasingly complex agentic systems. Happy building! Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:01.681326", "source_type": "adk-docs"}
{"doc_id": "74706630905ae4821bc645940abcbc3e7fb1eb1b84ea930caf1ab8969e006770", "url": "https://google.github.io/adk-docs/get-started/streaming", "title": "Build a streaming agent - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Build a streaming agent\u00b6"], "text": "Build a streaming agent \u00b6 The Agent Development Kit (ADK) enables real-time, interactive experiences with your AI agents through streaming. This allows for features like live voice conversations, real-time tool use, and continuous updates from your agent. This page provides quickstart examples to get you up and running with streaming capabilities in both Python and Java ADK. ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. Python ADK: Streaming agent This example demonstrates how to set up a basic streaming interaction with an agent using Python ADK. It typically involves using the Runner.run_live() method and handling asynchronous events. View Python Streaming Quickstart <a href=\"python/quickstart-streaming.md\">\u0002klzzwxh:0005\u0003 View Python Streaming Quickstart</a> This comment forces a block separation ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. Java ADK: Streaming agent This example demonstrates how to set up a basic streaming interaction with an agent using Java ADK. It involves using the Runner.runLive() method, a LiveRequestQueue , and handling the Flowable<Event> stream. View Java Streaming Quickstart <a href=\"java/quickstart-streaming-java.md\">\u0002klzzwxh:0016\u0003 View Java Streaming Quickstart</a>) Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:01.831266", "source_type": "adk-docs"}
{"doc_id": "3d513aa73ed0e982199d4c8cd7952002fee0888acd5c0ab1b346151cd07a4970", "url": "https://google.github.io/adk-docs/get-started/streaming/quickstart-streaming", "title": "Python - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Build a streaming agent with Python\u00b6"], "text": "Build a streaming agent with Python \u00b6 With this quickstart, you'll learn to create a simple agent and use ADK Streaming to enable voice and video communication with it that is low-latency and bidirectional. We will install ADK, set up a basic \"Google Search\" agent, try running the agent with Streaming with adk web tool, and then explain how to build a simple asynchronous web app by yourself using ADK Streaming and FastAPI . Note: This guide assumes you have experience using a terminal in Windows, Mac, and Linux environments. ", "code_blocks": []}, {"heading_path": ["Supported models for voice/video streaming\u00b6"], "text": "Supported models for voice/video streaming \u00b6 In order to use voice/video streaming in ADK, you will need to use Gemini models that support the Live API. You can find the model ID(s) that supports the Gemini Live API in the documentation: Google AI Studio: Gemini Live API Vertex AI: Gemini Live API ", "code_blocks": []}, {"heading_path": ["1. Setup Environment & Install ADK\u00b6"], "text": "1. Setup Environment & Install ADK \u00b6 Create & Activate Virtual Environment (Recommended): # Create python -m venv .venv # Activate (each new terminal) # macOS/Linux: source .venv/bin/activate # Windows CMD: .venv\\Scripts\\activate.bat # Windows PowerShell: .venv\\Scripts\\Activate.ps1 Install ADK: pip install google-adk ", "code_blocks": [{"language": "text", "code": "# Create\npython -m venv .venv\n# Activate (each new terminal)\n# macOS/Linux: source .venv/bin/activate\n# Windows CMD: .venv\\Scripts\\activate.bat\n# Windows PowerShell: .venv\\Scripts\\Activate.ps1"}, {"language": "text", "code": "pip install google-adk"}]}, {"heading_path": ["2. Project Structure\u00b6"], "text": "2. Project Structure \u00b6 Create the following folder structure with empty files: adk-streaming/  # Project folder \u2514\u2500\u2500 app/ # the web app folder \u251c\u2500\u2500 .env # Gemini API key \u2514\u2500\u2500 google_search_agent/ # Agent folder \u251c\u2500\u2500 __init__.py # Python package \u2514\u2500\u2500 agent.py # Agent definition ", "code_blocks": [{"language": "text", "code": "adk-streaming/  # Project folder\n\u2514\u2500\u2500 app/ # the web app folder\n    \u251c\u2500\u2500 .env # Gemini API key\n    \u2514\u2500\u2500 google_search_agent/ # Agent folder\n        \u251c\u2500\u2500 __init__.py # Python package\n        \u2514\u2500\u2500 agent.py # Agent definition"}]}, {"heading_path": ["agent.py\u00b6"], "text": "agent.py \u00b6 Copy-paste the following code block into the agent.py file. For model , please double check the model ID as described earlier in the Models section . from google.adk.agents import Agent from google.adk.tools import google_search # Import the tool root_agent = Agent ( # A unique name for the agent. name = \"basic_search_agent\" , # The Large Language Model (LLM) that agent will use. # Please fill in the latest model id that supports live from # https://google.github.io/adk-docs/get-started/streaming/quickstart-streaming/#supported-models model = \"...\" , # for example: model=\"gemini-2.0-flash-live-001\" or model=\"gemini-2.0-flash-live-preview-04-09\" # A short description of the agent's purpose. description = \"Agent to answer questions using Google Search.\" , # Instructions to set the agent's behavior. instruction = \"You are an expert researcher. You always stick to the facts.\" , # Add google_search tool to perform grounding with Google search. tools = [ google_search ] ) agent.py is where all your agent(s)' logic will be stored, and you must have a root_agent defined. Notice how easily you integrated grounding with Google Search capabilities.  The Agent class and the google_search tool handle the complex interactions with the LLM and grounding with the search API, allowing you to focus on the agent's purpose and behavior . Copy-paste the following code block to __init__.py file. __init__.py from . import agent ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools import google_search  # Import the tool\n\nroot_agent = Agent(\n   # A unique name for the agent.\n   name=\"basic_search_agent\",\n   # The Large Language Model (LLM) that agent will use.\n   # Please fill in the latest model id that supports live from\n   # https://google.github.io/adk-docs/get-started/streaming/quickstart-streaming/#supported-models\n   model=\"...\",  # for example: model=\"gemini-2.0-flash-live-001\" or model=\"gemini-2.0-flash-live-preview-04-09\"\n   # A short description of the agent's purpose.\n   description=\"Agent to answer questions using Google Search.\",\n   # Instructions to set the agent's behavior.\n   instruction=\"You are an expert researcher. You always stick to the facts.\",\n   # Add google_search tool to perform grounding with Google search.\n   tools=[google_search]\n)"}, {"language": "text", "code": "from . import agent"}]}, {"heading_path": ["3. Set up the platform\u00b6"], "text": "3. Set up the platform \u00b6 To run the agent, choose a platform from either Google AI Studio or Google Cloud Vertex AI: Gemini - Google AI Studio Gemini - Google Cloud Vertex AI Get an API key from Google AI Studio . Open the .env file located inside ( app/ ) and copy-paste the following code. .env GOOGLE_GENAI_USE_VERTEXAI=FALSE GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE Replace PASTE_YOUR_ACTUAL_API_KEY_HERE with your actual API KEY . You need an existing Google Cloud account and a\n   project. Set up a Google Cloud project Set up the gcloud CLI Authenticate to Google Cloud, from the terminal by running gcloud auth login . Enable the Vertex AI API . Open the .env file located inside ( app/ ). Copy-paste\n   the following code and update the project ID and location. .env GOOGLE_GENAI_USE_VERTEXAI=TRUE GOOGLE_CLOUD_PROJECT=PASTE_YOUR_ACTUAL_PROJECT_ID GOOGLE_CLOUD_LOCATION=us-central1 ", "code_blocks": [{"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=FALSE\nGOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=TRUE\nGOOGLE_CLOUD_PROJECT=PASTE_YOUR_ACTUAL_PROJECT_ID\nGOOGLE_CLOUD_LOCATION=us-central1"}]}, {"heading_path": ["4. Try the agent with adk web\u00b6"], "text": "4. Try the agent with adk web \u00b6 Now it's ready to try the agent. Run the following command to launch the dev UI . First, make sure to set the current directory to app : cd app Also, set SSL_CERT_FILE variable with the following command. This is required for the voice and video tests later. OS X & Linux Windows export SSL_CERT_FILE = $( python -m certifi ) $env:SSL_CERT_FILE = ( python -m certifi ) Then, run the dev UI: adk web Note for Windows users When hitting the _make_subprocess_transport NotImplementedError , consider using adk web --no-reload instead. Open the URL provided (usually http://localhost:8000 or http://127.0.0.1:8000 ) directly in your browser . This connection stays\nentirely on your local machine. Select google_search_agent . ", "code_blocks": [{"language": "text", "code": "cd app"}, {"language": "text", "code": "export SSL_CERT_FILE=$(python -m certifi)"}, {"language": "text", "code": "$env:SSL_CERT_FILE = (python -m certifi)"}, {"language": "text", "code": "adk web"}]}, {"heading_path": ["Try with text\u00b6"], "text": "Try with text \u00b6 Try the following prompts by typing them in the UI. What is the weather in New York? What is the time in New York? What is the weather in Paris? What is the time in Paris? The agent will use the google_search tool to get the latest information to answer those questions. ", "code_blocks": []}, {"heading_path": ["Try with voice and video\u00b6"], "text": "Try with voice and video \u00b6 To try with voice, reload the web browser, click the microphone button to enable the voice input, and ask the same question in voice. You will hear the answer in voice in real-time. To try with video, reload the web browser, click the camera button to enable the video input, and ask questions like \"What do you see?\". The agent will answer what they see in the video input. (Just clicking the microphone or camera button once is enough. Your voice or video will be streamed to models and the model response will be streamed back continuously. Clicking on the microphone or camera button multiple times is not supported.) ", "code_blocks": []}, {"heading_path": ["Stop the tool\u00b6"], "text": "Stop the tool \u00b6 Stop adk web by pressing Ctrl-C on the console. ", "code_blocks": []}, {"heading_path": ["Note on ADK Streaming\u00b6"], "text": "Note on ADK Streaming \u00b6 The following features will be supported in the future versions of the ADK Streaming: Callback, LongRunningTool, ExampleTool, and Shell agent (e.g. SequentialAgent). Congratulations! You've successfully created and interacted with your first Streaming agent using ADK! ", "code_blocks": []}, {"heading_path": ["Next steps: build custom streaming app\u00b6"], "text": "Next steps: build custom streaming app \u00b6 In Custom Audio Streaming app tutorial, it overviews the server and client code for a custom asynchronous web app built with ADK Streaming and FastAPI , enabling real-time, bidirectional audio and text communication. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:02.421268", "source_type": "adk-docs"}
{"doc_id": "d9362ca7c6345611bb5825797df47b27cf5918181e845577cba481a9a9bb4f32", "url": "https://google.github.io/adk-docs/get-started/streaming/quickstart-streaming-java", "title": "Java - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Build a streaming agent with Java\u00b6"], "text": "Build a streaming agent with Java \u00b6 This quickstart guide will walk you through the process of creating a basic agent and leveraging ADK Streaming with Java to facilitate low-latency, bidirectional voice interactions. You'll begin by setting up your Java and Maven environment, structuring your project, and defining the necessary dependencies. Following this, you'll create a simple ScienceTeacherAgent , test its text-based streaming capabilities using the Dev UI, and then progress to enabling live audio communication, transforming your agent into an interactive voice-driven application. ", "code_blocks": []}, {"heading_path": ["Create your first agent\u00b6"], "text": "Create your first agent \u00b6 ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 In this getting started guide, you will be programming in Java. Check if Java is installed on your machine. Ideally, you should be using Java 17 or more (you can check that by typing java -version ) You\u2019ll also be using the Maven build tool for Java. So be sure to have Maven installed on your machine before going further (this is the case for Cloud Top or Cloud Shell, but not necessarily for your laptop). ", "code_blocks": []}, {"heading_path": ["Prepare the project structure\u00b6"], "text": "Prepare the project structure \u00b6 To get started with ADK Java, let\u2019s create a Maven project with the following directory structure: adk-agents/ \u251c\u2500\u2500 pom.xml \u2514\u2500\u2500 src/ \u2514\u2500\u2500 main/ \u2514\u2500\u2500 java/ \u2514\u2500\u2500 agents/ \u2514\u2500\u2500 ScienceTeacherAgent.java Follow the instructions in Installation page to add pom.xml for using the ADK package. Note Feel free to use whichever name you like for the root directory of your project (instead of adk-agents) ", "code_blocks": [{"language": "text", "code": "adk-agents/\n\u251c\u2500\u2500 pom.xml\n\u2514\u2500\u2500 src/\n    \u2514\u2500\u2500 main/\n        \u2514\u2500\u2500 java/\n            \u2514\u2500\u2500 agents/\n                \u2514\u2500\u2500 ScienceTeacherAgent.java"}]}, {"heading_path": ["Running a compilation\u00b6"], "text": "Running a compilation \u00b6 Let\u2019s see if Maven is happy with this build, by running a compilation ( mvn compile command): $ mvn compile [ INFO ] Scanning for projects... [ INFO ] [ INFO ] --------------------< adk-agents:adk-agents >-------------------- [ INFO ] Building adk-agents 1 .0-SNAPSHOT [ INFO ] from pom.xml [ INFO ] -------------------------------- [ jar ] --------------------------------- [ INFO ] [ INFO ] --- resources:3.3.1:resources ( default-resources ) @ adk-demo --- [ INFO ] skip non existing resourceDirectory /home/user/adk-demo/src/main/resources [ INFO ] [ INFO ] --- compiler:3.13.0:compile ( default-compile ) @ adk-demo --- [ INFO ] Nothing to compile - all classes are up to date. [ INFO ] ------------------------------------------------------------------------ [ INFO ] BUILD SUCCESS [ INFO ] ------------------------------------------------------------------------ [ INFO ] Total time: 1 .347 s [ INFO ] Finished at: 2025 -05-06T15:38:08Z [ INFO ] ------------------------------------------------------------------------ Looks like the project is set up properly for compilation! ", "code_blocks": [{"language": "text", "code": "$ mvn compile\n[INFO] Scanning for projects...\n[INFO]\n[INFO] --------------------< adk-agents:adk-agents >--------------------\n[INFO] Building adk-agents 1.0-SNAPSHOT\n[INFO]   from pom.xml\n[INFO] --------------------------------[ jar ]---------------------------------\n[INFO]\n[INFO] --- resources:3.3.1:resources (default-resources) @ adk-demo ---\n[INFO] skip non existing resourceDirectory /home/user/adk-demo/src/main/resources\n[INFO]\n[INFO] --- compiler:3.13.0:compile (default-compile) @ adk-demo ---\n[INFO] Nothing to compile - all classes are up to date.\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  1.347 s\n[INFO] Finished at: 2025-05-06T15:38:08Z\n[INFO] ------------------------------------------------------------------------"}]}, {"heading_path": ["Creating an agent\u00b6"], "text": "Creating an agent \u00b6 Create the ScienceTeacherAgent.java file under the src/main/java/agents/ directory with the following content: package samples.liveaudio ; import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.LlmAgent ; /** Science teacher agent. */ public class ScienceTeacherAgent { // Field expected by the Dev UI to load the agent dynamically // (the agent must be initialized at declaration time) public static final BaseAgent ROOT_AGENT = initAgent (); public static BaseAgent initAgent () { return LlmAgent . builder () . name ( \"science-app\" ) . description ( \"Science teacher agent\" ) . model ( \"gemini-2.0-flash-exp\" ) . instruction ( \"\"\" You are a helpful science teacher that explains science concepts to kids and teenagers. \"\"\" ) . build (); } } Troubleshooting The model gemini-2.0-flash-exp will be deprecated in the future. If you see any issues on using it, try using gemini-2.0-flash-live-001 instead We will use Dev UI to run this agent later. For the tool to automatically recognize the agent, its Java class has to comply with the following two rules: The agent should be stored in a global public static variable named ROOT_AGENT of type BaseAgent and initialized at declaration time. The agent definition has to be a static method so it can be loaded during the class initialization by the dynamic compiling classloader. ", "code_blocks": [{"language": "text", "code": "package samples.liveaudio;\n\nimport com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.LlmAgent;\n\n/** Science teacher agent. */\npublic class ScienceTeacherAgent {\n\n  // Field expected by the Dev UI to load the agent dynamically\n  // (the agent must be initialized at declaration time)\n  public static final BaseAgent ROOT_AGENT = initAgent();\n\n  public static BaseAgent initAgent() {\n    return LlmAgent.builder()\n        .name(\"science-app\")\n        .description(\"Science teacher agent\")\n        .model(\"gemini-2.0-flash-exp\")\n        .instruction(\"\"\"\n            You are a helpful science teacher that explains\n            science concepts to kids and teenagers.\n            \"\"\")\n        .build();\n  }\n}"}]}, {"heading_path": ["Run agent with Dev UI\u00b6"], "text": "Run agent with Dev UI \u00b6 Dev UI is a web server where you can quickly run and test your agents for development purpose, without building your own UI application for the agents. ", "code_blocks": []}, {"heading_path": ["Define environment variables\u00b6"], "text": "Define environment variables \u00b6 To run the server, you\u2019ll need to export two environment variables: a Gemini key that you can get from AI Studio , a variable to specify we\u2019re not using Vertex AI this time. export GOOGLE_GENAI_USE_VERTEXAI = FALSE export GOOGLE_API_KEY = YOUR_API_KEY ", "code_blocks": [{"language": "text", "code": "export GOOGLE_GENAI_USE_VERTEXAI=FALSE\nexport GOOGLE_API_KEY=YOUR_API_KEY"}]}, {"heading_path": ["Run Dev UI\u00b6"], "text": "Run Dev UI \u00b6 Run the following command from the terminal to launch the Dev UI. terminal mvn exec:java \\ -Dexec.mainClass=\"com.google.adk.web.AdkWebServer\" \\ -Dexec.args=\"--adk.agents.source-dir=.\" \\ -Dexec.classpathScope=\"compile\" Step 1: Open the URL provided (usually http://localhost:8080 or http://127.0.0.1:8080 ) directly in your browser. Step 2. In the top-left corner of the UI, you can select your agent in\nthe dropdown. Select \"science-app\". Troubleshooting If you do not see \"science-app\" in the dropdown menu, make sure you\nare running the mvn command from the root of your maven project. ", "code_blocks": [{"language": "text", "code": "mvn exec:java \\\n    -Dexec.mainClass=\"com.google.adk.web.AdkWebServer\" \\\n    -Dexec.args=\"--adk.agents.source-dir=.\" \\\n    -Dexec.classpathScope=\"compile\""}]}, {"heading_path": ["Try Dev UI with text\u00b6"], "text": "Try Dev UI with text \u00b6 With your favorite browser, navigate to: http://127.0.0.1:8080/ You should see the following interface: Click the Token Streaming switch at the top right, and ask any questions for the science teacher such as What's the electron? . Then you should see the output text in streaming on the UI. As we saw, you do not have to write any specific code in the agent itself for the text streaming capability. It is provided as an ADK Agent feature by default. ", "code_blocks": []}, {"heading_path": ["Try with voice and video\u00b6"], "text": "Try with voice and video \u00b6 To try with voice, reload the web browser, click the microphone button to enable the voice input, and ask the same question in voice. You will hear the answer in voice in real-time. To try with video, reload the web browser, click the camera button to enable the video input, and ask questions like \"What do you see?\". The agent will answer what they see in the video input. ", "code_blocks": []}, {"heading_path": ["Stop the tool\u00b6"], "text": "Stop the tool \u00b6 Stop the tool by pressing Ctrl-C on the console. ", "code_blocks": []}, {"heading_path": ["Run agent with a custom live audio app\u00b6"], "text": "Run agent with a custom live audio app \u00b6 Now, let's try audio streaming with the agent and a custom live audio application. ", "code_blocks": []}, {"heading_path": ["A Maven pom.xml build file for Live Audio\u00b6"], "text": "A Maven pom.xml build file for Live Audio \u00b6 Replace your existing pom.xml with the following. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <groupId> com.google.adk.samples </groupId> <artifactId> google-adk-sample-live-audio </artifactId> <version> 0.1.0 </version> <name> Google ADK - Sample - Live Audio </name> <description> A sample application demonstrating a live audio conversation using ADK, runnable via samples.liveaudio.LiveAudioRun. </description> <packaging> jar </packaging> <properties> <project.build.sourceEncoding> UTF-8 </project.build.sourceEncoding> <java.version> 17 </java.version> <auto-value.version> 1.11.0 </auto-value.version> <!-- Main class for exec-maven-plugin --> <exec.mainClass> samples.liveaudio.LiveAudioRun </exec.mainClass> <google-adk.version> 0.1.0 </google-adk.version> </properties> <dependencyManagement> <dependencies> <dependency> <groupId> com.google.cloud </groupId> <artifactId> libraries-bom </artifactId> <version> 26.53.0 </version> <type> pom </type> <scope> import </scope> </dependency> </dependencies> </dependencyManagement> <dependencies> <dependency> <groupId> com.google.adk </groupId> <artifactId> google-adk </artifactId> <version> ${google-adk.version} </version> </dependency> <dependency> <groupId> commons-logging </groupId> <artifactId> commons-logging </artifactId> <version> 1.2 </version> <!-- Or use a property if defined in a parent POM --> </dependency> </dependencies> <build> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-compiler-plugin </artifactId> <version> 3.13.0 </version> <configuration> <source> ${java.version} </source> <target> ${java.version} </target> <parameters> true </parameters> <annotationProcessorPaths> <path> <groupId> com.google.auto.value </groupId> <artifactId> auto-value </artifactId> <version> ${auto-value.version} </version> </path> </annotationProcessorPaths> </configuration> </plugin> <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> build-helper-maven-plugin </artifactId> <version> 3.6.0 </version> <executions> <execution> <id> add-source </id> <phase> generate-sources </phase> <goals> <goal> add-source </goal> </goals> <configuration> <sources> <source> . </source> </sources> </configuration> </execution> </executions> </plugin> <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> exec-maven-plugin </artifactId> <version> 3.2.0 </version> <configuration> <mainClass> ${exec.mainClass} </mainClass> <classpathScope> runtime </classpathScope> </configuration> </plugin> </plugins> </build> </project> ", "code_blocks": [{"language": "text", "code": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>com.google.adk.samples</groupId>\n  <artifactId>google-adk-sample-live-audio</artifactId>\n  <version>0.1.0</version>\n  <name>Google ADK - Sample - Live Audio</name>\n  <description>\n    A sample application demonstrating a live audio conversation using ADK,\n    runnable via samples.liveaudio.LiveAudioRun.\n  </description>\n  <packaging>jar</packaging>\n\n  <properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <java.version>17</java.version>\n    <auto-value.version>1.11.0</auto-value.version>\n    <!-- Main class for exec-maven-plugin -->\n    <exec.mainClass>samples.liveaudio.LiveAudioRun</exec.mainClass>\n    <google-adk.version>0.1.0</google-adk.version>\n  </properties>\n\n  <dependencyManagement>\n    <dependencies>\n      <dependency>\n        <groupId>com.google.cloud</groupId>\n        <artifactId>libraries-bom</artifactId>\n        <version>26.53.0</version>\n        <type>pom</type>\n        <scope>import</scope>\n      </dependency>\n    </dependencies>\n  </dependencyManagement>\n\n  <dependencies>\n    <dependency>\n      <groupId>com.google.adk</groupId>\n      <artifactId>google-adk</artifactId>\n      <version>${google-adk.version}</version>\n    </dependency>\n    <dependency>\n      <groupId>commons-logging</groupId>\n      <artifactId>commons-logging</artifactId>\n      <version>1.2</version> <!-- Or use a property if defined in a parent POM -->\n    </dependency>\n  </dependencies>\n\n  <build>\n    <plugins>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-compiler-plugin</artifactId>\n        <version>3.13.0</version>\n        <configuration>\n          <source>${java.version}</source>\n          <target>${java.version}</target>\n          <parameters>true</parameters>\n          <annotationProcessorPaths>\n            <path>\n              <groupId>com.google.auto.value</groupId>\n              <artifactId>auto-value</artifactId>\n              <version>${auto-value.version}</version>\n            </path>\n          </annotationProcessorPaths>\n        </configuration>\n      </plugin>\n      <plugin>\n        <groupId>org.codehaus.mojo</groupId>\n        <artifactId>build-helper-maven-plugin</artifactId>\n        <version>3.6.0</version>\n        <executions>\n          <execution>\n            <id>add-source</id>\n            <phase>generate-sources</phase>\n            <goals>\n              <goal>add-source</goal>\n            </goals>\n            <configuration>\n              <sources>\n                <source>.</source>\n              </sources>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.codehaus.mojo</groupId>\n        <artifactId>exec-maven-plugin</artifactId>\n        <version>3.2.0</version>\n        <configuration>\n          <mainClass>${exec.mainClass}</mainClass>\n          <classpathScope>runtime</classpathScope>\n        </configuration>\n      </plugin>\n    </plugins>\n  </build>\n</project>"}]}, {"heading_path": ["Creating Live Audio Run tool\u00b6"], "text": "Creating Live Audio Run tool \u00b6 Create the LiveAudioRun.java file under the src/main/java/ directory with the following content. This tool runs the agent on it with live audio input and output. package samples.liveaudio ; import com.google.adk.agents.LiveRequestQueue ; import com.google.adk.agents.RunConfig ; import com.google.adk.events.Event ; import com.google.adk.runner.Runner ; import com.google.adk.sessions.InMemorySessionService ; import com.google.common.collect.ImmutableList ; import com.google.genai.types.Blob ; import com.google.genai.types.Modality ; import com.google.genai.types.PrebuiltVoiceConfig ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import com.google.genai.types.SpeechConfig ; import com.google.genai.types.VoiceConfig ; import io.reactivex.rxjava3.core.Flowable ; import java.io.ByteArrayOutputStream ; import java.io.InputStream ; import java.net.URL ; import javax.sound.sampled.AudioFormat ; import javax.sound.sampled.AudioInputStream ; import javax.sound.sampled.AudioSystem ; import javax.sound.sampled.DataLine ; import javax.sound.sampled.LineUnavailableException ; import javax.sound.sampled.Mixer ; import javax.sound.sampled.SourceDataLine ; import javax.sound.sampled.TargetDataLine ; import java.util.UUID ; import java.util.concurrent.ExecutorService ; import java.util.concurrent.ConcurrentHashMap ; import java.util.concurrent.ConcurrentMap ; import java.util.concurrent.Executors ; import java.util.concurrent.Future ; import java.util.concurrent.TimeUnit ; import java.util.concurrent.atomic.AtomicBoolean ; import agents.ScienceTeacherAgent ; /** Main class to demonstrate running the {@link LiveAudioAgent} for a voice conversation. */ public final class LiveAudioRun { private final String userId ; private final String sessionId ; private final Runner runner ; private static final javax . sound . sampled . AudioFormat MIC_AUDIO_FORMAT = new javax . sound . sampled . AudioFormat ( 16000.0f , 16 , 1 , true , false ); private static final javax . sound . sampled . AudioFormat SPEAKER_AUDIO_FORMAT = new javax . sound . sampled . AudioFormat ( 24000.0f , 16 , 1 , true , false ); private static final int BUFFER_SIZE = 4096 ; public LiveAudioRun () { this . userId = \"test_user\" ; String appName = \"LiveAudioApp\" ; this . sessionId = UUID . randomUUID (). toString (); InMemorySessionService sessionService = new InMemorySessionService (); this . runner = new Runner ( ScienceTeacherAgent . ROOT_AGENT , appName , null , sessionService ); ConcurrentMap < String , Object > initialState = new ConcurrentHashMap <> (); var unused = sessionService . createSession ( appName , userId , initialState , sessionId ). blockingGet (); } private void runConversation () throws Exception { System . out . println ( \"Initializing microphone input and speaker output...\" ); RunConfig runConfig = RunConfig . builder () . setStreamingMode ( RunConfig . StreamingMode . BIDI ) . setResponseModalities ( ImmutableList . of ( new Modality ( \"AUDIO\" ))) . setSpeechConfig ( SpeechConfig . builder () . voiceConfig ( VoiceConfig . builder () . prebuiltVoiceConfig ( PrebuiltVoiceConfig . builder (). voiceName ( \"Aoede\" ). build ()) . build ()) . languageCode ( \"en-US\" ) . build ()) . build (); LiveRequestQueue liveRequestQueue = new LiveRequestQueue (); Flowable < Event > eventStream = this . runner . runLive ( runner . sessionService (). createSession ( userId , sessionId ). blockingGet (), liveRequestQueue , runConfig ); AtomicBoolean isRunning = new AtomicBoolean ( true ); AtomicBoolean conversationEnded = new AtomicBoolean ( false ); ExecutorService executorService = Executors . newFixedThreadPool ( 2 ); // Task for capturing microphone input Future <?> microphoneTask = executorService . submit (() -> captureAndSendMicrophoneAudio ( liveRequestQueue , isRunning )); // Task for processing agent responses and playing audio Future <?> outputTask = executorService . submit ( () -> { try { processAudioOutput ( eventStream , isRunning , conversationEnded ); } catch ( Exception e ) { System . err . println ( \"Error processing audio output: \" + e . getMessage ()); e . printStackTrace (); isRunning . set ( false ); } }); // Wait for user to press Enter to stop the conversation System . out . println ( \"Conversation started. Press Enter to stop...\" ); System . in . read (); System . out . println ( \"Ending conversation...\" ); isRunning . set ( false ); try { // Give some time for ongoing processing to complete microphoneTask . get ( 2 , TimeUnit . SECONDS ); outputTask . get ( 2 , TimeUnit . SECONDS ); } catch ( Exception e ) { System . out . println ( \"Stopping tasks...\" ); } liveRequestQueue . close (); executorService . shutdownNow (); System . out . println ( \"Conversation ended.\" ); } private void captureAndSendMicrophoneAudio ( LiveRequestQueue liveRequestQueue , AtomicBoolean isRunning ) { TargetDataLine micLine = null ; try { DataLine . Info info = new DataLine . Info ( TargetDataLine . class , MIC_AUDIO_FORMAT ); if ( ! AudioSystem . isLineSupported ( info )) { System . err . println ( \"Microphone line not supported!\" ); return ; } micLine = ( TargetDataLine ) AudioSystem . getLine ( info ); micLine . open ( MIC_AUDIO_FORMAT ); micLine . start (); System . out . println ( \"Microphone initialized. Start speaking...\" ); byte [] buffer = new byte [ BUFFER_SIZE ] ; int bytesRead ; while ( isRunning . get ()) { bytesRead = micLine . read ( buffer , 0 , buffer . length ); if ( bytesRead > 0 ) { byte [] audioChunk = new byte [ bytesRead ] ; System . arraycopy ( buffer , 0 , audioChunk , 0 , bytesRead ); Blob audioBlob = Blob . builder (). data ( audioChunk ). mimeType ( \"audio/pcm\" ). build (); liveRequestQueue . realtime ( audioBlob ); } } } catch ( LineUnavailableException e ) { System . err . println ( \"Error accessing microphone: \" + e . getMessage ()); e . printStackTrace (); } finally { if ( micLine != null ) { micLine . stop (); micLine . close (); } } } private void processAudioOutput ( Flowable < Event > eventStream , AtomicBoolean isRunning , AtomicBoolean conversationEnded ) { SourceDataLine speakerLine = null ; try { DataLine . Info info = new DataLine . Info ( SourceDataLine . class , SPEAKER_AUDIO_FORMAT ); if ( ! AudioSystem . isLineSupported ( info )) { System . err . println ( \"Speaker line not supported!\" ); return ; } final SourceDataLine finalSpeakerLine = ( SourceDataLine ) AudioSystem . getLine ( info ); finalSpeakerLine . open ( SPEAKER_AUDIO_FORMAT ); finalSpeakerLine . start (); System . out . println ( \"Speaker initialized.\" ); for ( Event event : eventStream . blockingIterable ()) { if ( ! isRunning . get ()) { break ; } AtomicBoolean audioReceived = new AtomicBoolean ( false ); processEvent ( event , audioReceived ); event . content (). ifPresent ( content -> content . parts (). ifPresent ( parts -> parts . forEach ( part -> playAudioData ( part , finalSpeakerLine )))); } speakerLine = finalSpeakerLine ; // Assign to outer variable for cleanup in finally block } catch ( LineUnavailableException e ) { System . err . println ( \"Error accessing speaker: \" + e . getMessage ()); e . printStackTrace (); } finally { if ( speakerLine != null ) { speakerLine . drain (); speakerLine . stop (); speakerLine . close (); } conversationEnded . set ( true ); } } private void playAudioData ( Part part , SourceDataLine speakerLine ) { part . inlineData () . ifPresent ( inlineBlob -> inlineBlob . data () . ifPresent ( audioBytes -> { if ( audioBytes . length > 0 ) { System . out . printf ( \"Playing audio (%s): %d bytes%n\" , inlineBlob . mimeType (), audioBytes . length ); speakerLine . write ( audioBytes , 0 , audioBytes . length ); } })); } private void processEvent ( Event event , java . util . concurrent . atomic . AtomicBoolean audioReceived ) { event . content () . ifPresent ( content -> content . parts () . ifPresent ( parts -> parts . forEach ( part -> logReceivedAudioData ( part , audioReceived )))); } private void logReceivedAudioData ( Part part , AtomicBoolean audioReceived ) { part . inlineData () . ifPresent ( inlineBlob -> inlineBlob . data () . ifPresent ( audioBytes -> { if ( audioBytes . length > 0 ) { System . out . printf ( \"    Audio (%s): received %d bytes.%n\" , inlineBlob . mimeType (), audioBytes . length ); audioReceived . set ( true ); } else { System . out . printf ( \"    Audio (%s): received empty audio data.%n\" , inlineBlob . mimeType ()); } })); } public static void main ( String [] args ) throws Exception { LiveAudioRun liveAudioRun = new LiveAudioRun (); liveAudioRun . runConversation (); System . out . println ( \"Exiting Live Audio Run.\" ); } } ", "code_blocks": [{"language": "text", "code": "package samples.liveaudio;\n\nimport com.google.adk.agents.LiveRequestQueue;\nimport com.google.adk.agents.RunConfig;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.InMemorySessionService;\nimport com.google.common.collect.ImmutableList;\nimport com.google.genai.types.Blob;\nimport com.google.genai.types.Modality;\nimport com.google.genai.types.PrebuiltVoiceConfig;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport com.google.genai.types.SpeechConfig;\nimport com.google.genai.types.VoiceConfig;\nimport io.reactivex.rxjava3.core.Flowable;\nimport java.io.ByteArrayOutputStream;\nimport java.io.InputStream;\nimport java.net.URL;\nimport javax.sound.sampled.AudioFormat;\nimport javax.sound.sampled.AudioInputStream;\nimport javax.sound.sampled.AudioSystem;\nimport javax.sound.sampled.DataLine;\nimport javax.sound.sampled.LineUnavailableException;\nimport javax.sound.sampled.Mixer;\nimport javax.sound.sampled.SourceDataLine;\nimport javax.sound.sampled.TargetDataLine;\nimport java.util.UUID;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.ConcurrentMap;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.Future;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicBoolean;\nimport agents.ScienceTeacherAgent;\n\n/** Main class to demonstrate running the {@link LiveAudioAgent} for a voice conversation. */\npublic final class LiveAudioRun {\n  private final String userId;\n  private final String sessionId;\n  private final Runner runner;\n\n  private static final javax.sound.sampled.AudioFormat MIC_AUDIO_FORMAT =\n      new javax.sound.sampled.AudioFormat(16000.0f, 16, 1, true, false);\n\n  private static final javax.sound.sampled.AudioFormat SPEAKER_AUDIO_FORMAT =\n      new javax.sound.sampled.AudioFormat(24000.0f, 16, 1, true, false);\n\n  private static final int BUFFER_SIZE = 4096;\n\n  public LiveAudioRun() {\n    this.userId = \"test_user\";\n    String appName = \"LiveAudioApp\";\n    this.sessionId = UUID.randomUUID().toString();\n\n    InMemorySessionService sessionService = new InMemorySessionService();\n    this.runner = new Runner(ScienceTeacherAgent.ROOT_AGENT, appName, null, sessionService);\n\n    ConcurrentMap<String, Object> initialState = new ConcurrentHashMap<>();\n    var unused =\n        sessionService.createSession(appName, userId, initialState, sessionId).blockingGet();\n  }\n\n  private void runConversation() throws Exception {\n    System.out.println(\"Initializing microphone input and speaker output...\");\n\n    RunConfig runConfig =\n        RunConfig.builder()\n            .setStreamingMode(RunConfig.StreamingMode.BIDI)\n            .setResponseModalities(ImmutableList.of(new Modality(\"AUDIO\")))\n            .setSpeechConfig(\n                SpeechConfig.builder()\n                    .voiceConfig(\n                        VoiceConfig.builder()\n                            .prebuiltVoiceConfig(\n                                PrebuiltVoiceConfig.builder().voiceName(\"Aoede\").build())\n                            .build())\n                    .languageCode(\"en-US\")\n                    .build())\n            .build();\n\n    LiveRequestQueue liveRequestQueue = new LiveRequestQueue();\n\n    Flowable<Event> eventStream =\n        this.runner.runLive(\n            runner.sessionService().createSession(userId, sessionId).blockingGet(),\n            liveRequestQueue,\n            runConfig);\n\n    AtomicBoolean isRunning = new AtomicBoolean(true);\n    AtomicBoolean conversationEnded = new AtomicBoolean(false);\n    ExecutorService executorService = Executors.newFixedThreadPool(2);\n\n    // Task for capturing microphone input\n    Future<?> microphoneTask =\n        executorService.submit(() -> captureAndSendMicrophoneAudio(liveRequestQueue, isRunning));\n\n    // Task for processing agent responses and playing audio\n    Future<?> outputTask =\n        executorService.submit(\n            () -> {\n              try {\n                processAudioOutput(eventStream, isRunning, conversationEnded);\n              } catch (Exception e) {\n                System.err.println(\"Error processing audio output: \" + e.getMessage());\n                e.printStackTrace();\n                isRunning.set(false);\n              }\n            });\n\n    // Wait for user to press Enter to stop the conversation\n    System.out.println(\"Conversation started. Press Enter to stop...\");\n    System.in.read();\n\n    System.out.println(\"Ending conversation...\");\n    isRunning.set(false);\n\n    try {\n      // Give some time for ongoing processing to complete\n      microphoneTask.get(2, TimeUnit.SECONDS);\n      outputTask.get(2, TimeUnit.SECONDS);\n    } catch (Exception e) {\n      System.out.println(\"Stopping tasks...\");\n    }\n\n    liveRequestQueue.close();\n    executorService.shutdownNow();\n    System.out.println(\"Conversation ended.\");\n  }\n\n  private void captureAndSendMicrophoneAudio(\n      LiveRequestQueue liveRequestQueue, AtomicBoolean isRunning) {\n    TargetDataLine micLine = null;\n    try {\n      DataLine.Info info = new DataLine.Info(TargetDataLine.class, MIC_AUDIO_FORMAT);\n      if (!AudioSystem.isLineSupported(info)) {\n        System.err.println(\"Microphone line not supported!\");\n        return;\n      }\n\n      micLine = (TargetDataLine) AudioSystem.getLine(info);\n      micLine.open(MIC_AUDIO_FORMAT);\n      micLine.start();\n\n      System.out.println(\"Microphone initialized. Start speaking...\");\n\n      byte[] buffer = new byte[BUFFER_SIZE];\n      int bytesRead;\n\n      while (isRunning.get()) {\n        bytesRead = micLine.read(buffer, 0, buffer.length);\n\n        if (bytesRead > 0) {\n          byte[] audioChunk = new byte[bytesRead];\n          System.arraycopy(buffer, 0, audioChunk, 0, bytesRead);\n\n          Blob audioBlob = Blob.builder().data(audioChunk).mimeType(\"audio/pcm\").build();\n\n          liveRequestQueue.realtime(audioBlob);\n        }\n      }\n    } catch (LineUnavailableException e) {\n      System.err.println(\"Error accessing microphone: \" + e.getMessage());\n      e.printStackTrace();\n    } finally {\n      if (micLine != null) {\n        micLine.stop();\n        micLine.close();\n      }\n    }\n  }\n\n  private void processAudioOutput(\n      Flowable<Event> eventStream, AtomicBoolean isRunning, AtomicBoolean conversationEnded) {\n    SourceDataLine speakerLine = null;\n    try {\n      DataLine.Info info = new DataLine.Info(SourceDataLine.class, SPEAKER_AUDIO_FORMAT);\n      if (!AudioSystem.isLineSupported(info)) {\n        System.err.println(\"Speaker line not supported!\");\n        return;\n      }\n\n      final SourceDataLine finalSpeakerLine = (SourceDataLine) AudioSystem.getLine(info);\n      finalSpeakerLine.open(SPEAKER_AUDIO_FORMAT);\n      finalSpeakerLine.start();\n\n      System.out.println(\"Speaker initialized.\");\n\n      for (Event event : eventStream.blockingIterable()) {\n        if (!isRunning.get()) {\n          break;\n        }\n\n        AtomicBoolean audioReceived = new AtomicBoolean(false);\n        processEvent(event, audioReceived);\n\n        event.content().ifPresent(content -> content.parts().ifPresent(parts -> parts.forEach(part -> playAudioData(part, finalSpeakerLine))));\n      }\n\n      speakerLine = finalSpeakerLine; // Assign to outer variable for cleanup in finally block\n    } catch (LineUnavailableException e) {\n      System.err.println(\"Error accessing speaker: \" + e.getMessage());\n      e.printStackTrace();\n    } finally {\n      if (speakerLine != null) {\n        speakerLine.drain();\n        speakerLine.stop();\n        speakerLine.close();\n      }\n      conversationEnded.set(true);\n    }\n  }\n\n  private void playAudioData(Part part, SourceDataLine speakerLine) {\n    part.inlineData()\n        .ifPresent(\n            inlineBlob ->\n                inlineBlob\n                    .data()\n                    .ifPresent(\n                        audioBytes -> {\n                          if (audioBytes.length > 0) {\n                            System.out.printf(\n                                \"Playing audio (%s): %d bytes%n\",\n                                inlineBlob.mimeType(),\n                                audioBytes.length);\n                            speakerLine.write(audioBytes, 0, audioBytes.length);\n                          }\n                        }));\n  }\n\n  private void processEvent(Event event, java.util.concurrent.atomic.AtomicBoolean audioReceived) {\n    event\n        .content()\n        .ifPresent(\n            content ->\n                content\n                    .parts()\n                    .ifPresent(parts -> parts.forEach(part -> logReceivedAudioData(part, audioReceived))));\n  }\n\n  private void logReceivedAudioData(Part part, AtomicBoolean audioReceived) {\n    part.inlineData()\n        .ifPresent(\n            inlineBlob ->\n                inlineBlob\n                    .data()\n                    .ifPresent(\n                        audioBytes -> {\n                          if (audioBytes.length > 0) {\n                            System.out.printf(\n                                \"    Audio (%s): received %d bytes.%n\",\n                                inlineBlob.mimeType(),\n                                audioBytes.length);\n                            audioReceived.set(true);\n                          } else {\n                            System.out.printf(\n                                \"    Audio (%s): received empty audio data.%n\",\n                                inlineBlob.mimeType());\n                          }\n                        }));\n  }\n\n  public static void main(String[] args) throws Exception {\n    LiveAudioRun liveAudioRun = new LiveAudioRun();\n    liveAudioRun.runConversation();\n    System.out.println(\"Exiting Live Audio Run.\");\n  }\n}"}]}, {"heading_path": ["Run the Live Audio Run tool\u00b6"], "text": "Run the Live Audio Run tool \u00b6 To run Live Audio Run tool, use the following command on the adk-agents directory: mvn compile exec:java Then you should see: $ mvn compile exec:java ... Initializing microphone input and speaker output... Conversation started. Press Enter to stop... Speaker initialized. Microphone initialized. Start speaking... With this message, the tool is ready to take voice input. Talk to the agent with a question like What's the electron? . Caution When you observe the agent keep speaking by itself and doesn't stop, try using earphones to suppress the echoing. ", "code_blocks": [{"language": "text", "code": "mvn compile exec:java"}, {"language": "text", "code": "$ mvn compile exec:java\n...\nInitializing microphone input and speaker output...\nConversation started. Press Enter to stop...\nSpeaker initialized.\nMicrophone initialized. Start speaking..."}]}, {"heading_path": ["Summary\u00b6"], "text": "Summary \u00b6 Streaming for ADK enables developers to create agents capable of low-latency, bidirectional voice and video communication, enhancing interactive experiences. The article demonstrates that text streaming is a built-in feature of ADK Agents, requiring no additional specific code, while also showcasing how to implement live audio conversations for real-time voice interaction with an agent. This allows for more natural and dynamic communication, as users can speak to and hear from the agent seamlessly. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:03.020325", "source_type": "adk-docs"}
{"doc_id": "3b61bc607a92669e1572b9a0435917cf47df564a718cad1999462921661663d2", "url": "https://google.github.io/adk-docs/visual-builder", "title": "Visual Builder - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Visual Builder for agents\u00b6"], "text": "Visual Builder for agents \u00b6 Supported in ADK Python v1.18.0 Experimental The ADK Visual Builder is a web-based tool that provides a visual workflow\ndesign environment for creating and managing ADK agents. It allows you to\ndesign, build, and test your agents in a beginner-friendly graphical interface,\nand includes an AI-powered assistant to help you build agents. Experimental The Visual Builder feature is an experimental release. We welcome your feedback ! ", "code_blocks": []}, {"heading_path": ["Get started\u00b6"], "text": "Get started \u00b6 The Visual Builder interface is part of the ADK Web tool user interface.\nMake sure you have ADK library installed and then run the ADK Web user interface. adk web --port 8000 Tip: Run from a code development directory The Visual Builder tool writes project files to new subdirectories located\nin the directory where you run the ADK Web tool. Make sure you run this\ncommand from a developer directory location where you have write access. Figure 1: ADK Web controls to start the Visual Builder tool. To create an agent with Visual Builder: In top left of the page, select the + (plus sign), as shown in Figure 1 , to start creating an agent. Type a name for your agent application and select Create . Edit your agent by doing any of the following: In the left panel, edit agent component values. In the central panel, add new agent components . In the right panel, use prompts to modify the agent or get help. In bottom left corner, select Save to save your agent. Interact with your new agent to test it. In top left of the page, select the pencil icon, as shown in Figure 1 , to continue editing your agent. Here are few things to note when using Visual Builder: Create agent and save: When creating an agent, make sure you select Save before exiting the editing interface, otherwise your new agent may\n    not be editable. Agent editing: Edit (pencil icon) for agents is only available for\n    agents created with Visual Builder Add tools: When adding existing custom Tools to a Visual Builder\n    agent, specify a fully-qualified Python function name. ", "code_blocks": [{"language": "text", "code": "adk web --port 8000"}]}, {"heading_path": ["Workflow component support\u00b6"], "text": "Workflow component support \u00b6 The Visual Builder tool provides a drag-and-drop user interface for constructing agents, as\nwell as an AI-powered development Assistant that can answer questions and edit your agent workflow.\nThe tool supports all the essential components for building an ADK agent workflow, including: Agents Root Agent : The primary controlling agent for a workflow. All other agents in\n    an ADK agent workflow are considered Sub Agents. LLM Agent: An agent powered by a generative AI model. Sequential Agent: A workflow agent that executes a series of sub-agents in a sequence. Loop Agent: A workflow agent that repeatedly executes a sub-agent until a certain condition is met. Parallel Agent: A workflow agent that executes multiple sub-agents concurrently. Tools Prebuilt tools: A limited set of ADK-provided tools can be added to agents. Custom tools: You can build and add custom tools to your workflow. Components Callbacks A flow control component that lets you modify the behavior of agents at the start\n    and end of agent workflow events. Some advanced ADK features are not supported by Visual Builder due to\nlimitations of the Agent Config feature. For more information, see the\nAgent Config Known limitations . ", "code_blocks": []}, {"heading_path": ["Project code output\u00b6"], "text": "Project code output \u00b6 The Visual Builder tool generates code in the Agent Config format, using .yaml configuration files for agents and Python code for custom\ntools. These files are generated in a subfolder of the directory where you ran\nthe ADK Web interface. The following listing shows an example layout for a\nDiceAgent project: DiceAgent/ root_agent.yaml    # main agent code sub_agent_1.yaml   # sub agents (if any) tools/             # tools directory __init__.py dice_tool.py   # tool code Editing generated agents You can edit the generated files in your development environment. However,\nsome changes may not be compatible with Visual Builder. ", "code_blocks": [{"language": "text", "code": "DiceAgent/\n    root_agent.yaml    # main agent code\n    sub_agent_1.yaml   # sub agents (if any)\n    tools/             # tools directory\n        __init__.py\n        dice_tool.py   # tool code"}]}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 Using the Visual Builder development Assistant, try building a new agent using\nthis prompt: Help me add a dice roll tool to my current agent. Use the default model if you need to configure that. Check out more information on the Agent Config code format used by Visual Builder\nand the available options: Agent Config Agent Config YAML schema Back to top ", "code_blocks": [{"language": "text", "code": "Help me add a dice roll tool to my current agent.\nUse the default model if you need to configure that."}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:03.549745", "source_type": "adk-docs"}
{"doc_id": "f1695f54a6db70498be29df27bbab0172b9fc7f4f97c94f8fb170f01bcb6fd16", "url": "https://google.github.io/adk-docs/get-started/installation", "title": "Advanced setup - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Installing ADK\u00b6"], "text": "Installing ADK \u00b6 Python Go Java ", "code_blocks": []}, {"heading_path": ["Create & activate virtual environment\u00b6"], "text": "Create & activate virtual environment \u00b6 We recommend creating a virtual Python environment using venv : python -m venv .venv Now, you can activate the virtual environment using the appropriate command for\nyour operating system and environment: # Mac / Linux source .venv/bin/activate # Windows CMD: .venv\\Scripts\\activate.bat # Windows PowerShell: .venv\\Scripts\\Activate.ps1 ", "code_blocks": [{"language": "text", "code": "python -m venv .venv"}, {"language": "text", "code": "# Mac / Linux\nsource .venv/bin/activate\n\n# Windows CMD:\n.venv\\Scripts\\activate.bat\n\n# Windows PowerShell:\n.venv\\Scripts\\Activate.ps1"}]}, {"heading_path": ["Install ADK\u00b6"], "text": "Install ADK \u00b6 pip install google-adk (Optional) Verify your installation: pip show google-adk ", "code_blocks": [{"language": "text", "code": "pip install google-adk"}, {"language": "text", "code": "pip show google-adk"}]}, {"heading_path": ["Create a new Go module\u00b6"], "text": "Create a new Go module \u00b6 If you are starting a new project, you can create a new Go module: go mod init example.com/my-agent ", "code_blocks": [{"language": "text", "code": "go mod init example.com/my-agent"}]}, {"heading_path": ["Install ADK\u00b6"], "text": "Install ADK \u00b6 To add the ADK to your project, run the following command: go get google.golang.org/adk This will add the ADK as a dependency to your go.mod file. (Optional) Verify your installation by checking your go.mod file for the google.golang.org/adk entry. You can either use maven or gradle to add the google-adk and google-adk-dev package. google-adk is the core Java ADK library. Java ADK also comes with a pluggable example SpringBoot server to run your agents seamlessly. This optional\npackage is present as part of google-adk-dev . If you are using maven, add the following to your pom.xml : pom.xml <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <groupId> com.example.agent </groupId> <artifactId> adk-agents </artifactId> <version> 1.0-SNAPSHOT </version> <!-- Specify the version of Java you'll be using --> <properties> <maven.compiler.source> 17 </maven.compiler.source> <maven.compiler.target> 17 </maven.compiler.target> <project.build.sourceEncoding> UTF-8 </project.build.sourceEncoding> </properties> <dependencies> <!-- The ADK core dependency --> <dependency> <groupId> com.google.adk </groupId> <artifactId> google-adk </artifactId> <version> 0.3.0 </version> </dependency> <!-- The ADK dev web UI to debug your agent --> <dependency> <groupId> com.google.adk </groupId> <artifactId> google-adk-dev </artifactId> <version> 0.3.0 </version> </dependency> </dependencies> </project> Here's a complete pom.xml file for reference. If you are using gradle, add the dependency to your build.gradle: build.gradle dependencies { implementation 'com.google.adk:google-adk:0.2.0' implementation 'com.google.adk:google-adk-dev:0.2.0' } You should also configure Gradle to pass -parameters to javac . (Alternatively, use @Schema(name = \"...\") ). ", "code_blocks": [{"language": "text", "code": "go get google.golang.org/adk"}, {"language": "text", "code": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n        xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.example.agent</groupId>\n    <artifactId>adk-agents</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <!-- Specify the version of Java you'll be using -->\n    <properties>\n        <maven.compiler.source>17</maven.compiler.source>\n        <maven.compiler.target>17</maven.compiler.target>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    </properties>\n\n    <dependencies>\n        <!-- The ADK core dependency -->\n        <dependency>\n            <groupId>com.google.adk</groupId>\n            <artifactId>google-adk</artifactId>\n            <version>0.3.0</version>\n        </dependency>\n        <!-- The ADK dev web UI to debug your agent -->\n        <dependency>\n            <groupId>com.google.adk</groupId>\n            <artifactId>google-adk-dev</artifactId>\n            <version>0.3.0</version>\n        </dependency>\n    </dependencies>\n\n</project>"}, {"language": "text", "code": "dependencies {\n    implementation 'com.google.adk:google-adk:0.2.0'\n    implementation 'com.google.adk:google-adk-dev:0.2.0'\n}"}]}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 Try creating your first agent with the Quickstart Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:03.902168", "source_type": "adk-docs"}
{"doc_id": "a393e03b92578c69d51a3b6447bd4f45225c9edda559605eff2ac7cf66ea2b4c", "url": "https://google.github.io/adk-docs/agents", "title": "Agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agents\u00b6"], "text": "Agents \u00b6 Supported in ADK Python Go Java In the Agent Development Kit (ADK), an Agent is a self-contained execution unit designed to act autonomously to achieve specific goals. Agents can perform tasks, interact with users, utilize external tools, and coordinate with other agents. The foundation for all agents in ADK is the BaseAgent class. It serves as the fundamental blueprint. To create functional agents, you typically extend BaseAgent in one of three main ways, catering to different needs \u2013 from intelligent reasoning to structured process control. ", "code_blocks": []}, {"heading_path": ["Core Agent Categories\u00b6"], "text": "Core Agent Categories \u00b6 ADK provides distinct agent categories to build sophisticated applications: LLM Agents ( LlmAgent , Agent ) : These agents utilize Large Language Models (LLMs) as their core engine to understand natural language, reason, plan, generate responses, and dynamically decide how to proceed or which tools to use, making them ideal for flexible, language-centric tasks. Learn more about LLM Agents... Workflow Agents ( SequentialAgent , ParallelAgent , LoopAgent ) : These specialized agents control the execution flow of other agents in predefined, deterministic patterns (sequence, parallel, or loop) without using an LLM for the flow control itself, perfect for structured processes needing predictable execution. Explore Workflow Agents... Custom Agents : Created by extending BaseAgent directly, these agents allow you to implement unique operational logic, specific control flows, or specialized integrations not covered by the standard types, catering to highly tailored application requirements. Discover how to build Custom Agents... ", "code_blocks": []}, {"heading_path": ["Choosing the Right Agent Type\u00b6"], "text": "Choosing the Right Agent Type \u00b6 The following table provides a high-level comparison to help distinguish between the agent types. As you explore each type in more detail in the subsequent sections, these distinctions will become clearer. Feature LLM Agent ( LlmAgent ) Workflow Agent Custom Agent ( BaseAgent subclass) Primary Function Reasoning, Generation, Tool Use Controlling Agent Execution Flow Implementing Unique Logic/Integrations Core Engine Large Language Model (LLM) Predefined Logic (Sequence, Parallel, Loop) Custom Code Determinism Non-deterministic (Flexible) Deterministic (Predictable) Can be either, based on implementation Primary Use Language tasks, Dynamic decisions Structured processes, Orchestration Tailored requirements, Specific workflows ", "code_blocks": []}, {"heading_path": ["Agents Working Together: Multi-Agent Systems\u00b6"], "text": "Agents Working Together: Multi-Agent Systems \u00b6 While each agent type serves a distinct purpose, the true power often comes from combining them. Complex applications frequently employ multi-agent architectures where: LLM Agents handle intelligent, language-based task execution. Workflow Agents manage the overall process flow using standard patterns. Custom Agents provide specialized capabilities or rules needed for unique integrations. Understanding these core types is the first step toward building sophisticated, capable AI applications with ADK. ", "code_blocks": []}, {"heading_path": ["What's Next?\u00b6"], "text": "What's Next? \u00b6 Now that you have an overview of the different agent types available in ADK, dive deeper into how they work and how to use them effectively: LLM Agents: Explore how to configure agents powered by large language models, including setting instructions, providing tools, and enabling advanced features like planning and code execution. Workflow Agents: Learn how to orchestrate tasks using SequentialAgent , ParallelAgent , and LoopAgent for structured and predictable processes. Custom Agents: Discover the principles of extending BaseAgent to build agents with unique logic and integrations tailored to your specific needs. Multi-Agents: Understand how to combine different agent types to create sophisticated, collaborative systems capable of tackling complex problems. Models: Learn about the different LLM integrations available and how to select the right model for your agents. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:04.383676", "source_type": "adk-docs"}
{"doc_id": "65a6276e14de303594976b77e2e632816a964070a12fb87736cf89839c1368a8", "url": "https://google.github.io/adk-docs/agents/llm-agents", "title": "LLM agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["LLM Agent\u00b6"], "text": "LLM Agent \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 The LlmAgent (often aliased simply as Agent ) is a core component in ADK,\nacting as the \"thinking\" part of your application. It leverages the power of a\nLarge Language Model (LLM) for reasoning, understanding natural language, making\ndecisions, generating responses, and interacting with tools. Unlike deterministic Workflow Agents that follow\npredefined execution paths, LlmAgent behavior is non-deterministic. It uses\nthe LLM to interpret instructions and context, deciding dynamically how to\nproceed, which tools to use (if any), or whether to transfer control to another\nagent. Building an effective LlmAgent involves defining its identity, clearly guiding\nits behavior through instructions, and equipping it with the necessary tools and\ncapabilities. ", "code_blocks": []}, {"heading_path": ["Defining the Agent's Identity and Purpose\u00b6"], "text": "Defining the Agent's Identity and Purpose \u00b6 First, you need to establish what the agent is and what it's for . name (Required): Every agent needs a unique string identifier. This name is crucial for internal operations, especially in multi-agent systems\n  where agents need to refer to or delegate tasks to each other. Choose a\n  descriptive name that reflects the agent's function (e.g., customer_support_router , billing_inquiry_agent ). Avoid reserved names like user . description (Optional, Recommended for Multi-Agent): Provide a concise\n  summary of the agent's capabilities. This description is primarily used by other LLM agents to determine if they should route a task to this agent.\n  Make it specific enough to differentiate it from peers (e.g., \"Handles\n  inquiries about current billing statements,\" not just \"Billing agent\"). model (Required): Specify the underlying LLM that will power this\n  agent's reasoning. This is a string identifier like \"gemini-2.0-flash\" . The\n  choice of model impacts the agent's capabilities, cost, and performance. See\n  the Models page for available options and considerations. Python Go Java # Example: Defining the basic identity capital_agent = LlmAgent ( model = \"gemini-2.0-flash\" , name = \"capital_agent\" , description = \"Answers user questions about the capital city of a given country.\" # instruction and tools will be added next ) // Example: Defining the basic identity agent , err := llmagent . New ( llmagent . Config { Name : \"capital_agent\" , Model : model , Description : \"Answers user questions about the capital city of a given country.\" , // instruction and tools will be added next }) // Example: Defining the basic identity LlmAgent capitalAgent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"capital_agent\" ) . description ( \"Answers user questions about the capital city of a given country.\" ) // instruction and tools will be added next . build (); ", "code_blocks": [{"language": "text", "code": "# Example: Defining the basic identity\ncapital_agent = LlmAgent(\n    model=\"gemini-2.0-flash\",\n    name=\"capital_agent\",\n    description=\"Answers user questions about the capital city of a given country.\"\n    # instruction and tools will be added next\n)"}, {"language": "text", "code": "// Example: Defining the basic identity\nagent, err := llmagent.New(llmagent.Config{\n    Name:        \"capital_agent\",\n    Model:       model,\n    Description: \"Answers user questions about the capital city of a given country.\",\n    // instruction and tools will be added next\n})"}, {"language": "text", "code": "// Example: Defining the basic identity\nLlmAgent capitalAgent =\n    LlmAgent.builder()\n        .model(\"gemini-2.0-flash\")\n        .name(\"capital_agent\")\n        .description(\"Answers user questions about the capital city of a given country.\")\n        // instruction and tools will be added next\n        .build();"}]}, {"heading_path": ["Guiding the Agent: Instructions (instruction)\u00b6"], "text": "Guiding the Agent: Instructions ( instruction ) \u00b6 The instruction parameter is arguably the most critical for shaping an LlmAgent 's behavior. It's a string (or a function returning a string) that\ntells the agent: Its core task or goal. Its personality or persona (e.g., \"You are a helpful assistant,\" \"You are a witty pirate\"). Constraints on its behavior (e.g., \"Only answer questions about X,\" \"Never reveal Y\"). How and when to use its tools . You should explain the purpose of each tool and the circumstances under which it should be called, supplementing any descriptions within the tool itself. The desired format for its output (e.g., \"Respond in JSON,\" \"Provide a bulleted list\"). Tips for Effective Instructions: Be Clear and Specific: Avoid ambiguity. Clearly state the desired actions and outcomes. Use Markdown: Improve readability for complex instructions using headings, lists, etc. Provide Examples (Few-Shot): For complex tasks or specific output formats, include examples directly in the instruction. Guide Tool Use: Don't just list tools; explain when and why the agent should use them. State: The instruction is a string template, you can use the {var} syntax to insert dynamic values into the instruction. {var} is used to insert the value of the state variable named var. {artifact.var} is used to insert the text content of the artifact named var. If the state variable or artifact does not exist, the agent will raise an error. If you want to ignore the error, you can append a ? to the variable name as in {var?} . Python Go Java # Example: Adding instructions capital_agent = LlmAgent ( model = \"gemini-2.0-flash\" , name = \"capital_agent\" , description = \"Answers user questions about the capital city of a given country.\" , instruction = \"\"\"You are an agent that provides the capital city of a country. When a user asks for the capital of a country: 1. Identify the country name from the user's query. 2. Use the `get_capital_city` tool to find the capital. 3. Respond clearly to the user, stating the capital city. Example Query: \"What's the capital of {country} ?\" Example Response: \"The capital of France is Paris.\" \"\"\" , # tools will be added next ) // Example: Adding instructions agent , err := llmagent . New ( llmagent . Config { Name : \"capital_agent\" , Model : model , Description : \"Answers user questions about the capital city of a given country.\" , Instruction : `You are an agent that provides the capital city of a country. When a user asks for the capital of a country: 1. Identify the country name from the user's query. 2. Use the 'get_capital_city' tool to find the capital. 3. Respond clearly to the user, stating the capital city. Example Query: \"What's the capital of {country}?\" Example Response: \"The capital of France is Paris.\"` , // tools will be added next }) // Example: Adding instructions LlmAgent capitalAgent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"capital_agent\" ) . description ( \"Answers user questions about the capital city of a given country.\" ) . instruction ( \"\"\" You are an agent that provides the capital city of a country. When a user asks for the capital of a country: 1. Identify the country name from the user's query. 2. Use the `get_capital_city` tool to find the capital. 3. Respond clearly to the user, stating the capital city. Example Query: \"What's the capital of {country}?\" Example Response: \"The capital of France is Paris.\" \"\"\" ) // tools will be added next . build (); (Note: For instructions that apply to all agents in a system, consider using global_instruction on the root agent, detailed further in the Multi-Agents section.) ", "code_blocks": [{"language": "text", "code": "# Example: Adding instructions\ncapital_agent = LlmAgent(\n    model=\"gemini-2.0-flash\",\n    name=\"capital_agent\",\n    description=\"Answers user questions about the capital city of a given country.\",\n    instruction=\"\"\"You are an agent that provides the capital city of a country.\nWhen a user asks for the capital of a country:\n1. Identify the country name from the user's query.\n2. Use the `get_capital_city` tool to find the capital.\n3. Respond clearly to the user, stating the capital city.\nExample Query: \"What's the capital of {country}?\"\nExample Response: \"The capital of France is Paris.\"\n\"\"\",\n    # tools will be added next\n)"}, {"language": "text", "code": "// Example: Adding instructions\n    agent, err := llmagent.New(llmagent.Config{\n        Name:        \"capital_agent\",\n        Model:       model,\n        Description: \"Answers user questions about the capital city of a given country.\",\n        Instruction: `You are an agent that provides the capital city of a country.\nWhen a user asks for the capital of a country:\n1. Identify the country name from the user's query.\n2. Use the 'get_capital_city' tool to find the capital.\n3. Respond clearly to the user, stating the capital city.\nExample Query: \"What's the capital of {country}?\"\nExample Response: \"The capital of France is Paris.\"`,\n        // tools will be added next\n    })"}, {"language": "text", "code": "// Example: Adding instructions\nLlmAgent capitalAgent =\n    LlmAgent.builder()\n        .model(\"gemini-2.0-flash\")\n        .name(\"capital_agent\")\n        .description(\"Answers user questions about the capital city of a given country.\")\n        .instruction(\n            \"\"\"\n            You are an agent that provides the capital city of a country.\n            When a user asks for the capital of a country:\n            1. Identify the country name from the user's query.\n            2. Use the `get_capital_city` tool to find the capital.\n            3. Respond clearly to the user, stating the capital city.\n            Example Query: \"What's the capital of {country}?\"\n            Example Response: \"The capital of France is Paris.\"\n            \"\"\")\n        // tools will be added next\n        .build();"}]}, {"heading_path": ["Equipping the Agent: Tools (tools)\u00b6"], "text": "Equipping the Agent: Tools ( tools ) \u00b6 Tools give your LlmAgent capabilities beyond the LLM's built-in knowledge or\nreasoning. They allow the agent to interact with the outside world, perform\ncalculations, fetch real-time data, or execute specific actions. tools (Optional): Provide a list of tools the agent can use. Each item in the list can be: A native function or method (wrapped as a FunctionTool ). Python ADK automatically wraps the native function into a FuntionTool whereas, you must explicitly wrap your Java methods using FunctionTool.create(...) An instance of a class inheriting from BaseTool . An instance of another agent ( AgentTool , enabling agent-to-agent delegation - see Multi-Agents ). The LLM uses the function/tool names, descriptions (from docstrings or the description field), and parameter schemas to decide which tool to call based\non the conversation and its instructions. Python Go Java # Define a tool function def get_capital_city ( country : str ) -> str : \"\"\"Retrieves the capital city for a given country.\"\"\" # Replace with actual logic (e.g., API call, database lookup) capitals = { \"france\" : \"Paris\" , \"japan\" : \"Tokyo\" , \"canada\" : \"Ottawa\" } return capitals . get ( country . lower (), f \"Sorry, I don't know the capital of { country } .\" ) # Add the tool to the agent capital_agent = LlmAgent ( model = \"gemini-2.0-flash\" , name = \"capital_agent\" , description = \"Answers user questions about the capital city of a given country.\" , instruction = \"\"\"You are an agent that provides the capital city of a country... (previous instruction text)\"\"\" , tools = [ get_capital_city ] # Provide the function directly ) // Define a tool function type getCapitalCityArgs struct { Country string `json:\"country\" jsonschema:\"The country to get the capital of.\"` } getCapitalCity := func ( ctx tool . Context , args getCapitalCityArgs ) map [ string ] any { // Replace with actual logic (e.g., API call, database lookup) capitals := map [ string ] string { \"france\" : \"Paris\" , \"japan\" : \"Tokyo\" , \"canada\" : \"Ottawa\" } capital , ok := capitals [ strings . ToLower ( args . Country )] if ! ok { return map [ string ] any { \"result\" : fmt . Sprintf ( \"Sorry, I don't know the capital of %s.\" , args . Country )} } return map [ string ] any { \"result\" : capital } } // Add the tool to the agent capitalTool , err := functiontool . New ( functiontool . Config { Name : \"get_capital_city\" , Description : \"Retrieves the capital city for a given country.\" , }, getCapitalCity , ) if err != nil { log . Fatal ( err ) } agent , err := llmagent . New ( llmagent . Config { Name : \"capital_agent\" , Model : model , Description : \"Answers user questions about the capital city of a given country.\" , Instruction : \"You are an agent that provides the capital city of a country... (previous instruction text)\" , Tools : [] tool . Tool { capitalTool }, }) // Define a tool function // Retrieves the capital city of a given country. public static Map < String , Object > getCapitalCity ( @Schema ( name = \"country\" , description = \"The country to get capital for\" ) String country ) { // Replace with actual logic (e.g., API call, database lookup) Map < String , String > countryCapitals = new HashMap <> (); countryCapitals . put ( \"canada\" , \"Ottawa\" ); countryCapitals . put ( \"france\" , \"Paris\" ); countryCapitals . put ( \"japan\" , \"Tokyo\" ); String result = countryCapitals . getOrDefault ( country . toLowerCase (), \"Sorry, I couldn't find the capital for \" + country + \".\" ); return Map . of ( \"result\" , result ); // Tools must return a Map } // Add the tool to the agent FunctionTool capitalTool = FunctionTool . create ( experiment . getClass (), \"getCapitalCity\" ); LlmAgent capitalAgent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"capital_agent\" ) . description ( \"Answers user questions about the capital city of a given country.\" ) . instruction ( \"You are an agent that provides the capital city of a country... (previous instruction text)\" ) . tools ( capitalTool ) // Provide the function wrapped as a FunctionTool . build (); Learn more about Tools in the Tools section. ", "code_blocks": [{"language": "text", "code": "# Define a tool function\ndef get_capital_city(country: str) -> str:\n  \"\"\"Retrieves the capital city for a given country.\"\"\"\n  # Replace with actual logic (e.g., API call, database lookup)\n  capitals = {\"france\": \"Paris\", \"japan\": \"Tokyo\", \"canada\": \"Ottawa\"}\n  return capitals.get(country.lower(), f\"Sorry, I don't know the capital of {country}.\")\n\n# Add the tool to the agent\ncapital_agent = LlmAgent(\n    model=\"gemini-2.0-flash\",\n    name=\"capital_agent\",\n    description=\"Answers user questions about the capital city of a given country.\",\n    instruction=\"\"\"You are an agent that provides the capital city of a country... (previous instruction text)\"\"\",\n    tools=[get_capital_city] # Provide the function directly\n)"}, {"language": "text", "code": "// Define a tool function\ntype getCapitalCityArgs struct {\n    Country string `json:\"country\" jsonschema:\"The country to get the capital of.\"`\n}\ngetCapitalCity := func(ctx tool.Context, args getCapitalCityArgs) map[string]any {\n    // Replace with actual logic (e.g., API call, database lookup)\n    capitals := map[string]string{\"france\": \"Paris\", \"japan\": \"Tokyo\", \"canada\": \"Ottawa\"}\n    capital, ok := capitals[strings.ToLower(args.Country)]\n    if !ok {\n        return map[string]any{\"result\": fmt.Sprintf(\"Sorry, I don't know the capital of %s.\", args.Country)}\n    }\n    return map[string]any{\"result\": capital}\n}\n\n// Add the tool to the agent\ncapitalTool, err := functiontool.New(\n    functiontool.Config{\n        Name:        \"get_capital_city\",\n        Description: \"Retrieves the capital city for a given country.\",\n    },\n    getCapitalCity,\n)\nif err != nil {\n    log.Fatal(err)\n}\nagent, err := llmagent.New(llmagent.Config{\n    Name:        \"capital_agent\",\n    Model:       model,\n    Description: \"Answers user questions about the capital city of a given country.\",\n    Instruction: \"You are an agent that provides the capital city of a country... (previous instruction text)\",\n    Tools:       []tool.Tool{capitalTool},\n})"}, {"language": "text", "code": "// Define a tool function\n// Retrieves the capital city of a given country.\npublic static Map<String, Object> getCapitalCity(\n        @Schema(name = \"country\", description = \"The country to get capital for\")\n        String country) {\n  // Replace with actual logic (e.g., API call, database lookup)\n  Map<String, String> countryCapitals = new HashMap<>();\n  countryCapitals.put(\"canada\", \"Ottawa\");\n  countryCapitals.put(\"france\", \"Paris\");\n  countryCapitals.put(\"japan\", \"Tokyo\");\n\n  String result =\n          countryCapitals.getOrDefault(\n                  country.toLowerCase(), \"Sorry, I couldn't find the capital for \" + country + \".\");\n  return Map.of(\"result\", result); // Tools must return a Map\n}\n\n// Add the tool to the agent\nFunctionTool capitalTool = FunctionTool.create(experiment.getClass(), \"getCapitalCity\");\nLlmAgent capitalAgent =\n    LlmAgent.builder()\n        .model(\"gemini-2.0-flash\")\n        .name(\"capital_agent\")\n        .description(\"Answers user questions about the capital city of a given country.\")\n        .instruction(\"You are an agent that provides the capital city of a country... (previous instruction text)\")\n        .tools(capitalTool) // Provide the function wrapped as a FunctionTool\n        .build();"}]}, {"heading_path": ["Advanced Configuration & Control\u00b6"], "text": "Advanced Configuration & Control \u00b6 Beyond the core parameters, LlmAgent offers several options for finer control: ", "code_blocks": []}, {"heading_path": ["Configuring LLM Generation (generate_content_config)\u00b6"], "text": "Configuring LLM Generation ( generate_content_config ) \u00b6 You can adjust how the underlying LLM generates responses using generate_content_config . generate_content_config (Optional): Pass an instance of google.genai.types.GenerateContentConfig to control parameters like temperature (randomness), max_output_tokens (response length), top_p , top_k , and safety settings. Python Go Java from google.genai import types agent = LlmAgent ( # ... other params generate_content_config = types . GenerateContentConfig ( temperature = 0.2 , # More deterministic output max_output_tokens = 250 , safety_settings = [ types . SafetySetting ( category = types . HarmCategory . HARM_CATEGORY_DANGEROUS_CONTENT , threshold = types . HarmBlockThreshold . BLOCK_LOW_AND_ABOVE , ) ] ) ) import \"google.golang.org/genai\" temperature := float32 ( 0.2 ) agent , err := llmagent . New ( llmagent . Config { Name : \"gen_config_agent\" , Model : model , GenerateContentConfig : & genai . GenerateContentConfig { Temperature : & temperature , MaxOutputTokens : 250 , }, }) import com.google.genai.types.GenerateContentConfig ; LlmAgent agent = LlmAgent . builder () // ... other params . generateContentConfig ( GenerateContentConfig . builder () . temperature ( 0.2F ) // More deterministic output . maxOutputTokens ( 250 ) . build ()) . build (); ", "code_blocks": [{"language": "text", "code": "from google.genai import types\n\nagent = LlmAgent(\n    # ... other params\n    generate_content_config=types.GenerateContentConfig(\n        temperature=0.2, # More deterministic output\n        max_output_tokens=250,\n        safety_settings=[\n            types.SafetySetting(\n                category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n                threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n            )\n        ]\n    )\n)"}, {"language": "text", "code": "import \"google.golang.org/genai\"\n\ntemperature := float32(0.2)\nagent, err := llmagent.New(llmagent.Config{\n    Name:  \"gen_config_agent\",\n    Model: model,\n    GenerateContentConfig: &genai.GenerateContentConfig{\n        Temperature:     &temperature,\n        MaxOutputTokens: 250,\n    },\n})"}, {"language": "text", "code": "import com.google.genai.types.GenerateContentConfig;\n\nLlmAgent agent =\n    LlmAgent.builder()\n        // ... other params\n        .generateContentConfig(GenerateContentConfig.builder()\n            .temperature(0.2F) // More deterministic output\n            .maxOutputTokens(250)\n            .build())\n        .build();"}]}, {"heading_path": ["Structuring Data (input_schema, output_schema, output_key)\u00b6"], "text": "Structuring Data ( input_schema , output_schema , output_key ) \u00b6 For scenarios requiring structured data exchange with an LLM Agent , the ADK provides mechanisms to define expected input and desired output formats using schema definitions. input_schema (Optional): Define a schema representing the expected input structure. If set, the user message content passed to this agent must be a JSON string conforming to this schema. Your instructions should guide the user or preceding agent accordingly. output_schema (Optional): Define a schema representing the desired output structure. If set, the agent's final response must be a JSON string conforming to this schema. output_key (Optional): Provide a string key. If set, the text content of the agent's final response will be automatically saved to the session's state dictionary under this key. This is useful for passing results between agents or steps in a workflow. In Python, this might look like: session.state[output_key] = agent_response_text In Java: session.state().put(outputKey, agentResponseText) In Golang, within a callback handler: ctx.State().Set(output_key, agentResponseText) Python Go Java The input and output schema is typically a Pydantic BaseModel. from pydantic import BaseModel , Field class CapitalOutput ( BaseModel ): capital : str = Field ( description = \"The capital of the country.\" ) structured_capital_agent = LlmAgent ( # ... name, model, description instruction = \"\"\"You are a Capital Information Agent. Given a country, respond ONLY with a JSON object containing the capital. Format: {\"capital\": \"capital_name\"}\"\"\" , output_schema = CapitalOutput , # Enforce JSON output output_key = \"found_capital\" # Store result in state['found_capital'] # Cannot use tools=[get_capital_city] effectively here ) The input and output schema is a google.genai.types.Schema object. capitalOutput := & genai . Schema { Type : genai . TypeObject , Description : \"Schema for capital city information.\" , Properties : map [ string ] * genai . Schema { \"capital\" : { Type : genai . TypeString , Description : \"The capital city of the country.\" , }, }, } agent , err := llmagent . New ( llmagent . Config { Name : \"structured_capital_agent\" , Model : model , Description : \"Provides capital information in a structured format.\" , Instruction : `You are a Capital Information Agent. Given a country, respond ONLY with a JSON object containing the capital. Format: {\"capital\": \"capital_name\"}` , OutputSchema : capitalOutput , OutputKey : \"found_capital\" , // Cannot use the capitalTool tool effectively here }) The input and output schema is a google.genai.types.Schema object. private static final Schema CAPITAL_OUTPUT = Schema . builder () . type ( \"OBJECT\" ) . description ( \"Schema for capital city information.\" ) . properties ( Map . of ( \"capital\" , Schema . builder () . type ( \"STRING\" ) . description ( \"The capital city of the country.\" ) . build ())) . build (); LlmAgent structuredCapitalAgent = LlmAgent . builder () // ... name, model, description . instruction ( \"You are a Capital Information Agent. Given a country, respond ONLY with a JSON object containing the capital. Format: {\\\"capital\\\": \\\"capital_name\\\"}\" ) . outputSchema ( capitalOutput ) // Enforce JSON output . outputKey ( \"found_capital\" ) // Store result in state.get(\"found_capital\") // Cannot use tools(getCapitalCity) effectively here . build (); ", "code_blocks": [{"language": "text", "code": "from pydantic import BaseModel, Field\n\nclass CapitalOutput(BaseModel):\n    capital: str = Field(description=\"The capital of the country.\")\n\nstructured_capital_agent = LlmAgent(\n    # ... name, model, description\n    instruction=\"\"\"You are a Capital Information Agent. Given a country, respond ONLY with a JSON object containing the capital. Format: {\"capital\": \"capital_name\"}\"\"\",\n    output_schema=CapitalOutput, # Enforce JSON output\n    output_key=\"found_capital\"  # Store result in state['found_capital']\n    # Cannot use tools=[get_capital_city] effectively here\n)"}, {"language": "text", "code": "capitalOutput := &genai.Schema{\n    Type:        genai.TypeObject,\n    Description: \"Schema for capital city information.\",\n    Properties: map[string]*genai.Schema{\n        \"capital\": {\n            Type:        genai.TypeString,\n            Description: \"The capital city of the country.\",\n        },\n    },\n}\n\nagent, err := llmagent.New(llmagent.Config{\n    Name:         \"structured_capital_agent\",\n    Model:        model,\n    Description:  \"Provides capital information in a structured format.\",\n    Instruction:  `You are a Capital Information Agent. Given a country, respond ONLY with a JSON object containing the capital. Format: {\"capital\": \"capital_name\"}`,\n    OutputSchema: capitalOutput,\n    OutputKey:    \"found_capital\",\n    // Cannot use the capitalTool tool effectively here\n})"}, {"language": "text", "code": "private static final Schema CAPITAL_OUTPUT =\n    Schema.builder()\n        .type(\"OBJECT\")\n        .description(\"Schema for capital city information.\")\n        .properties(\n            Map.of(\n                \"capital\",\n                Schema.builder()\n                    .type(\"STRING\")\n                    .description(\"The capital city of the country.\")\n                    .build()))\n        .build();\n\nLlmAgent structuredCapitalAgent =\n    LlmAgent.builder()\n        // ... name, model, description\n        .instruction(\n                \"You are a Capital Information Agent. Given a country, respond ONLY with a JSON object containing the capital. Format: {\\\"capital\\\": \\\"capital_name\\\"}\")\n        .outputSchema(capitalOutput) // Enforce JSON output\n        .outputKey(\"found_capital\") // Store result in state.get(\"found_capital\")\n        // Cannot use tools(getCapitalCity) effectively here\n        .build();"}]}, {"heading_path": ["Managing Context (include_contents)\u00b6"], "text": "Managing Context ( include_contents ) \u00b6 Control whether the agent receives the prior conversation history. include_contents (Optional, Default: 'default' ): Determines if the contents (history) are sent to the LLM. 'default' : The agent receives the relevant conversation history. 'none' : The agent receives no prior contents . It operates based solely on its current instruction and any input provided in the current turn (useful for stateless tasks or enforcing specific contexts). Python Go Java stateless_agent = LlmAgent ( # ... other params include_contents = 'none' ) import \"google.golang.org/adk/agent/llmagent\" agent , err := llmagent . New ( llmagent . Config { Name : \"stateless_agent\" , Model : model , IncludeContents : llmagent . IncludeContentsNone , }) import com.google.adk.agents.LlmAgent.IncludeContents ; LlmAgent statelessAgent = LlmAgent . builder () // ... other params . includeContents ( IncludeContents . NONE ) . build (); ", "code_blocks": [{"language": "text", "code": "stateless_agent = LlmAgent(\n    # ... other params\n    include_contents='none'\n)"}, {"language": "text", "code": "import \"google.golang.org/adk/agent/llmagent\"\n\nagent, err := llmagent.New(llmagent.Config{\n    Name:            \"stateless_agent\",\n    Model:           model,\n    IncludeContents: llmagent.IncludeContentsNone,\n})"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent.IncludeContents;\n\nLlmAgent statelessAgent =\n    LlmAgent.builder()\n        // ... other params\n        .includeContents(IncludeContents.NONE)\n        .build();"}]}, {"heading_path": ["Planner\u00b6"], "text": "Planner \u00b6 Supported in ADK Python v0.1.0 planner (Optional): Assign a BasePlanner instance to enable multi-step reasoning and planning before execution. There are two main planners: BuiltInPlanner : Leverages the model's built-in planning capabilities (e.g., Gemini's thinking feature). See Gemini Thinking for details and examples. Here, the thinking_budget parameter guides the model on the number of thinking tokens to use when generating a response. The include_thoughts parameter controls whether the model should include its raw thoughts and internal reasoning process in the response. from google.adk import Agent from google.adk.planners import BuiltInPlanner from google.genai import types my_agent = Agent ( model = \"gemini-2.5-flash\" , planner = BuiltInPlanner ( thinking_config = types . ThinkingConfig ( include_thoughts = True , thinking_budget = 1024 , ) ), # ... your tools here ) PlanReActPlanner : This planner instructs the model to follow a specific structure in its output: first create a plan, then execute actions (like calling tools), and provide reasoning for its steps. It's particularly useful for models that don't have a built-in \"thinking\" feature . from google.adk import Agent from google.adk.planners import PlanReActPlanner my_agent = Agent ( model = \"gemini-2.0-flash\" , planner = PlanReActPlanner (), # ... your tools here ) The agent's response will follow a structured format: [user]: ai news [google_search_agent]: /*PLANNING*/ 1. Perform a Google search for \"latest AI news\" to get current updates and headlines related to artificial intelligence. 2. Synthesize the information from the search results to provide a summary of recent AI news. /*ACTION*/ /*REASONING*/ The search results provide a comprehensive overview of recent AI news, covering various aspects like company developments, research breakthroughs, and applications. I have enough information to answer the user's request. /*FINAL_ANSWER*/ Here's a summary of recent AI news: .... ", "code_blocks": [{"language": "text", "code": "from google.adk import Agent\nfrom google.adk.planners import BuiltInPlanner\nfrom google.genai import types\n\nmy_agent = Agent(\n    model=\"gemini-2.5-flash\",\n    planner=BuiltInPlanner(\n        thinking_config=types.ThinkingConfig(\n            include_thoughts=True,\n            thinking_budget=1024,\n        )\n    ),\n    # ... your tools here\n)"}, {"language": "text", "code": "from google.adk import Agent\nfrom google.adk.planners import PlanReActPlanner\n\nmy_agent = Agent(\n    model=\"gemini-2.0-flash\",\n    planner=PlanReActPlanner(),\n    # ... your tools here\n)"}, {"language": "text", "code": "[user]: ai news\n[google_search_agent]: /*PLANNING*/\n1. Perform a Google search for \"latest AI news\" to get current updates and headlines related to artificial intelligence.\n2. Synthesize the information from the search results to provide a summary of recent AI news.\n\n/*ACTION*/\n/*REASONING*/\nThe search results provide a comprehensive overview of recent AI news, covering various aspects like company developments, research breakthroughs, and applications. I have enough information to answer the user's request.\n\n/*FINAL_ANSWER*/\nHere's a summary of recent AI news:\n...."}]}, {"heading_path": ["Code Execution\u00b6"], "text": "Code Execution \u00b6 Supported in ADK Python v0.1.0 code_executor (Optional): Provide a BaseCodeExecutor instance to allow the agent to execute code blocks found in the LLM's response. ( See Tools/Built-in tools ). Example for using built-in-planner: from dotenv import load_dotenv import asyncio import os from google.genai import types from google.adk.agents.llm_agent import LlmAgent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService # Optional from google.adk.planners import BasePlanner , BuiltInPlanner , PlanReActPlanner from google.adk.models import LlmRequest from google.genai.types import ThinkingConfig from google.genai.types import GenerateContentConfig import datetime from zoneinfo import ZoneInfo APP_NAME = \"weather_app\" USER_ID = \"1234\" SESSION_ID = \"session1234\" def get_weather ( city : str ) -> dict : \"\"\"Retrieves the current weather report for a specified city. Args: city (str): The name of the city for which to retrieve the weather report. Returns: dict: status and result or error msg. \"\"\" if city . lower () == \"new york\" : return { \"status\" : \"success\" , \"report\" : ( \"The weather in New York is sunny with a temperature of 25 degrees\" \" Celsius (77 degrees Fahrenheit).\" ), } else : return { \"status\" : \"error\" , \"error_message\" : f \"Weather information for ' { city } ' is not available.\" , } def get_current_time ( city : str ) -> dict : \"\"\"Returns the current time in a specified city. Args: city (str): The name of the city for which to retrieve the current time. Returns: dict: status and result or error msg. \"\"\" if city . lower () == \"new york\" : tz_identifier = \"America/New_York\" else : return { \"status\" : \"error\" , \"error_message\" : ( f \"Sorry, I don't have timezone information for { city } .\" ), } tz = ZoneInfo ( tz_identifier ) now = datetime . datetime . now ( tz ) report = ( f 'The current time in { city } is { now . strftime ( \"%Y-%m- %d %H:%M:%S %Z%z\" ) } ' ) return { \"status\" : \"success\" , \"report\" : report } # Step 1: Create a ThinkingConfig thinking_config = ThinkingConfig ( include_thoughts = True , # Ask the model to include its thoughts in the response thinking_budget = 256 # Limit the 'thinking' to 256 tokens (adjust as needed) ) print ( \"ThinkingConfig:\" , thinking_config ) # Step 2: Instantiate BuiltInPlanner planner = BuiltInPlanner ( thinking_config = thinking_config ) print ( \"BuiltInPlanner created.\" ) # Step 3: Wrap the planner in an LlmAgent agent = LlmAgent ( model = \"gemini-2.5-pro-preview-03-25\" , # Set your model name name = \"weather_and_time_agent\" , instruction = \"You are an agent that returns time and weather\" , planner = planner , tools = [ get_weather , get_current_time ] ) # Session and Runner session_service = InMemorySessionService () session = session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = agent , app_name = APP_NAME , session_service = session_service ) # Agent Interaction def call_agent ( query ): content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) events = runner . run ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) for event in events : print ( f \" \\n DEBUG EVENT: { event } \\n \" ) if event . is_final_response () and event . content : final_answer = event . content . parts [ 0 ] . text . strip () print ( \" \\n \ud83d\udfe2 FINAL ANSWER \\n \" , final_answer , \" \\n \" ) call_agent ( \"If it's raining in New York right now, what is the current temperature?\" ) ", "code_blocks": [{"language": "text", "code": "from dotenv import load_dotenv\n\n\nimport asyncio\nimport os\n\nfrom google.genai import types\nfrom google.adk.agents.llm_agent import LlmAgent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService # Optional\nfrom google.adk.planners import BasePlanner, BuiltInPlanner, PlanReActPlanner\nfrom google.adk.models import LlmRequest\n\nfrom google.genai.types import ThinkingConfig\nfrom google.genai.types import GenerateContentConfig\n\nimport datetime\nfrom zoneinfo import ZoneInfo\n\nAPP_NAME = \"weather_app\"\nUSER_ID = \"1234\"\nSESSION_ID = \"session1234\"\n\ndef get_weather(city: str) -> dict:\n    \"\"\"Retrieves the current weather report for a specified city.\n\n    Args:\n        city (str): The name of the city for which to retrieve the weather report.\n\n    Returns:\n        dict: status and result or error msg.\n    \"\"\"\n    if city.lower() == \"new york\":\n        return {\n            \"status\": \"success\",\n            \"report\": (\n                \"The weather in New York is sunny with a temperature of 25 degrees\"\n                \" Celsius (77 degrees Fahrenheit).\"\n            ),\n        }\n    else:\n        return {\n            \"status\": \"error\",\n            \"error_message\": f\"Weather information for '{city}' is not available.\",\n        }\n\n\ndef get_current_time(city: str) -> dict:\n    \"\"\"Returns the current time in a specified city.\n\n    Args:\n        city (str): The name of the city for which to retrieve the current time.\n\n    Returns:\n        dict: status and result or error msg.\n    \"\"\"\n\n    if city.lower() == \"new york\":\n        tz_identifier = \"America/New_York\"\n    else:\n        return {\n            \"status\": \"error\",\n            \"error_message\": (\n                f\"Sorry, I don't have timezone information for {city}.\"\n            ),\n        }\n\n    tz = ZoneInfo(tz_identifier)\n    now = datetime.datetime.now(tz)\n    report = (\n        f'The current time in {city} is {now.strftime(\"%Y-%m-%d %H:%M:%S %Z%z\")}'\n    )\n    return {\"status\": \"success\", \"report\": report}\n\n# Step 1: Create a ThinkingConfig\nthinking_config = ThinkingConfig(\n    include_thoughts=True,   # Ask the model to include its thoughts in the response\n    thinking_budget=256      # Limit the 'thinking' to 256 tokens (adjust as needed)\n)\nprint(\"ThinkingConfig:\", thinking_config)\n\n# Step 2: Instantiate BuiltInPlanner\nplanner = BuiltInPlanner(\n    thinking_config=thinking_config\n)\nprint(\"BuiltInPlanner created.\")\n\n# Step 3: Wrap the planner in an LlmAgent\nagent = LlmAgent(\n    model=\"gemini-2.5-pro-preview-03-25\",  # Set your model name\n    name=\"weather_and_time_agent\",\n    instruction=\"You are an agent that returns time and weather\",\n    planner=planner,\n    tools=[get_weather, get_current_time]\n)\n\n# Session and Runner\nsession_service = InMemorySessionService()\nsession = session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\nrunner = Runner(agent=agent, app_name=APP_NAME, session_service=session_service)\n\n# Agent Interaction\ndef call_agent(query):\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    for event in events:\n        print(f\"\\nDEBUG EVENT: {event}\\n\")\n        if event.is_final_response() and event.content:\n            final_answer = event.content.parts[0].text.strip()\n            print(\"\\n\ud83d\udfe2 FINAL ANSWER\\n\", final_answer, \"\\n\")\n\ncall_agent(\"If it's raining in New York right now, what is the current temperature?\")"}]}, {"heading_path": ["Putting It Together: Example\u00b6"], "text": "Putting It Together: Example \u00b6 Code Here's the complete basic capital_agent : Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # --- Full example code demonstrating LlmAgent with Tools vs. Output Schema --- import json # Needed for pretty printing dicts import asyncio from google.adk.agents import LlmAgent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.genai import types from pydantic import BaseModel , Field # --- 1. Define Constants --- APP_NAME = \"agent_comparison_app\" USER_ID = \"test_user_456\" SESSION_ID_TOOL_AGENT = \"session_tool_agent_xyz\" SESSION_ID_SCHEMA_AGENT = \"session_schema_agent_xyz\" MODEL_NAME = \"gemini-2.0-flash\" # --- 2. Define Schemas --- # Input schema used by both agents class CountryInput ( BaseModel ): country : str = Field ( description = \"The country to get information about.\" ) # Output schema ONLY for the second agent class CapitalInfoOutput ( BaseModel ): capital : str = Field ( description = \"The capital city of the country.\" ) # Note: Population is illustrative; the LLM will infer or estimate this # as it cannot use tools when output_schema is set. population_estimate : str = Field ( description = \"An estimated population of the capital city.\" ) # --- 3. Define the Tool (Only for the first agent) --- def get_capital_city ( country : str ) -> str : \"\"\"Retrieves the capital city of a given country.\"\"\" print ( f \" \\n -- Tool Call: get_capital_city(country=' { country } ') --\" ) country_capitals = { \"united states\" : \"Washington, D.C.\" , \"canada\" : \"Ottawa\" , \"france\" : \"Paris\" , \"japan\" : \"Tokyo\" , } result = country_capitals . get ( country . lower (), f \"Sorry, I couldn't find the capital for { country } .\" ) print ( f \"-- Tool Result: ' { result } ' --\" ) return result # --- 4. Configure Agents --- # Agent 1: Uses a tool and output_key capital_agent_with_tool = LlmAgent ( model = MODEL_NAME , name = \"capital_agent_tool\" , description = \"Retrieves the capital city using a specific tool.\" , instruction = \"\"\"You are a helpful agent that provides the capital city of a country using a tool. The user will provide the country name in a JSON format like {\"country\": \"country_name\"}. 1. Extract the country name. 2. Use the `get_capital_city` tool to find the capital. 3. Respond clearly to the user, stating the capital city found by the tool. \"\"\" , tools = [ get_capital_city ], input_schema = CountryInput , output_key = \"capital_tool_result\" , # Store final text response ) # Agent 2: Uses output_schema (NO tools possible) structured_info_agent_schema = LlmAgent ( model = MODEL_NAME , name = \"structured_info_agent_schema\" , description = \"Provides capital and estimated population in a specific JSON format.\" , instruction = f \"\"\"You are an agent that provides country information. The user will provide the country name in a JSON format like {{ \"country\": \"country_name\" }} . Respond ONLY with a JSON object matching this exact schema: { json . dumps ( CapitalInfoOutput . model_json_schema (), indent = 2 ) } Use your knowledge to determine the capital and estimate the population. Do not use any tools. \"\"\" , # *** NO tools parameter here - using output_schema prevents tool use *** input_schema = CountryInput , output_schema = CapitalInfoOutput , # Enforce JSON output structure output_key = \"structured_info_result\" , # Store final JSON response ) # --- 5. Set up Session Management and Runners --- session_service = InMemorySessionService () # Create a runner for EACH agent capital_runner = Runner ( agent = capital_agent_with_tool , app_name = APP_NAME , session_service = session_service ) structured_runner = Runner ( agent = structured_info_agent_schema , app_name = APP_NAME , session_service = session_service ) # --- 6. Define Agent Interaction Logic --- async def call_agent_and_print ( runner_instance : Runner , agent_instance : LlmAgent , session_id : str , query_json : str ): \"\"\"Sends a query to the specified agent/runner and prints results.\"\"\" print ( f \" \\n >>> Calling Agent: ' { agent_instance . name } ' | Query: { query_json } \" ) user_content = types . Content ( role = 'user' , parts = [ types . Part ( text = query_json )]) final_response_content = \"No final response received.\" async for event in runner_instance . run_async ( user_id = USER_ID , session_id = session_id , new_message = user_content ): # print(f\"Event: {event.type}, Author: {event.author}\") # Uncomment for detailed logging if event . is_final_response () and event . content and event . content . parts : # For output_schema, the content is the JSON string itself final_response_content = event . content . parts [ 0 ] . text print ( f \"<<< Agent ' { agent_instance . name } ' Response: { final_response_content } \" ) current_session = await session_service . get_session ( app_name = APP_NAME , user_id = USER_ID , session_id = session_id ) stored_output = current_session . state . get ( agent_instance . output_key ) # Pretty print if the stored output looks like JSON (likely from output_schema) print ( f \"--- Session State [' { agent_instance . output_key } ']: \" , end = \"\" ) try : # Attempt to parse and pretty print if it's JSON parsed_output = json . loads ( stored_output ) print ( json . dumps ( parsed_output , indent = 2 )) except ( json . JSONDecodeError , TypeError ): # Otherwise, print as string print ( stored_output ) print ( \"-\" * 30 ) # --- 7. Run Interactions --- async def main (): # Create separate sessions for clarity, though not strictly necessary if context is managed print ( \"--- Creating Sessions ---\" ) await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID_TOOL_AGENT ) await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID_SCHEMA_AGENT ) print ( \"--- Testing Agent with Tool ---\" ) await call_agent_and_print ( capital_runner , capital_agent_with_tool , SESSION_ID_TOOL_AGENT , '{\"country\": \"France\"}' ) await call_agent_and_print ( capital_runner , capital_agent_with_tool , SESSION_ID_TOOL_AGENT , '{\"country\": \"Canada\"}' ) print ( \" \\n\\n --- Testing Agent with Output Schema (No Tool Use) ---\" ) await call_agent_and_print ( structured_runner , structured_info_agent_schema , SESSION_ID_SCHEMA_AGENT , '{\"country\": \"France\"}' ) await call_agent_and_print ( structured_runner , structured_info_agent_schema , SESSION_ID_SCHEMA_AGENT , '{\"country\": \"Japan\"}' ) # --- Run the Agent --- # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. if __name__ == \"__main__\" : asyncio . run ( main ()) package main import ( \"context\" \"encoding/json\" \"fmt\" \"log\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) // --- Main Runnable Example --- const ( modelName = \"gemini-2.0-flash\" appName = \"agent_comparison_app\" userID = \"test_user_456\" ) type getCapitalCityArgs struct { Country string `json:\"country\" jsonschema:\"The country to get the capital of.\"` } // getCapitalCity retrieves the capital city of a given country. func getCapitalCity ( ctx tool . Context , args getCapitalCityArgs ) map [ string ] any { fmt . Printf ( \"\\n-- Tool Call: getCapitalCity(country='%s') --\\n\" , args . Country ) capitals := map [ string ] string { \"united states\" : \"Washington, D.C.\" , \"canada\" : \"Ottawa\" , \"france\" : \"Paris\" , \"japan\" : \"Tokyo\" , } capital , ok := capitals [ strings . ToLower ( args . Country )] if ! ok { result := fmt . Sprintf ( \"Sorry, I couldn't find the capital for %s.\" , args . Country ) fmt . Printf ( \"-- Tool Result: '%s' --\\n\" , result ) return map [ string ] any { \"result\" : result } } fmt . Printf ( \"-- Tool Result: '%s' --\\n\" , capital ) return map [ string ] any { \"result\" : capital } } // callAgent is a helper function to execute an agent with a given prompt and handle its output. func callAgent ( ctx context . Context , a agent . Agent , outputKey string , prompt string ) { fmt . Printf ( \"\\n>>> Calling Agent: '%s' | Query: %s\\n\" , a . Name (), prompt ) // Create an in-memory session service to manage agent state. sessionService := session . InMemoryService () // Create a new session for the agent interaction. sessionCreateResponse , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , }) if err != nil { log . Fatalf ( \"Failed to create the session service: %v\" , err ) } session := sessionCreateResponse . Session // Configure the runner with the application name, agent, and session service. config := runner . Config { AppName : appName , Agent : a , SessionService : sessionService , } // Create a new runner instance. r , err := runner . New ( config ) if err != nil { log . Fatalf ( \"Failed to create the runner: %v\" , err ) } // Prepare the user's message to send to the agent. sessionID := session . ID () userMsg := & genai . Content { Parts : [] * genai . Part { genai . NewPartFromText ( prompt ), }, Role : string ( genai . RoleUser ), } // Run the agent and process the streaming events. for event , err := range r . Run ( ctx , userID , sessionID , userMsg , agent . RunConfig { StreamingMode : agent . StreamingModeSSE , }) { if err != nil { fmt . Printf ( \"\\nAGENT_ERROR: %v\\n\" , err ) } else if event . Partial { // Print partial responses as they are received. for _ , p := range event . Content . Parts { fmt . Print ( p . Text ) } } } // After the run, check if there's an expected output key in the session state. if outputKey != \"\" { storedOutput , error := session . State (). Get ( outputKey ) if error == nil { // Pretty-print the stored output if it's a JSON string. fmt . Printf ( \"\\n--- Session State ['%s']: \" , outputKey ) storedString , isString := storedOutput .( string ) if isString { var prettyJSON map [ string ] interface {} if err := json . Unmarshal ([] byte ( storedString ), & prettyJSON ); err == nil { indentedJSON , err := json . MarshalIndent ( prettyJSON , \"\" , \"  \" ) if err == nil { fmt . Println ( string ( indentedJSON )) } else { fmt . Println ( storedString ) } } else { fmt . Println ( storedString ) } } else { fmt . Println ( storedOutput ) } fmt . Println ( strings . Repeat ( \"-\" , 30 )) } } } func main () { ctx := context . Background () model , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } capitalTool , err := functiontool . New ( functiontool . Config { Name : \"get_capital_city\" , Description : \"Retrieves the capital city for a given country.\" , }, getCapitalCity , ) if err != nil { log . Fatalf ( \"Failed to create function tool: %v\" , err ) } countryInputSchema := & genai . Schema { Type : genai . TypeObject , Description : \"Input for specifying a country.\" , Properties : map [ string ] * genai . Schema { \"country\" : { Type : genai . TypeString , Description : \"The country to get information about.\" , }, }, Required : [] string { \"country\" }, } capitalAgentWithTool , err := llmagent . New ( llmagent . Config { Name : \"capital_agent_tool\" , Model : model , Description : \"Retrieves the capital city using a specific tool.\" , Instruction : `You are a helpful agent that provides the capital city of a country using a tool. The user will provide the country name in a JSON format like {\"country\": \"country_name\"}. 1. Extract the country name. 2. Use the 'get_capital_city' tool to find the capital. 3. Respond clearly to the user, stating the capital city found by the tool.` , Tools : [] tool . Tool { capitalTool }, InputSchema : countryInputSchema , OutputKey : \"capital_tool_result\" , }) if err != nil { log . Fatalf ( \"Failed to create capital agent with tool: %v\" , err ) } capitalInfoOutputSchema := & genai . Schema { Type : genai . TypeObject , Description : \"Schema for capital city information.\" , Properties : map [ string ] * genai . Schema { \"capital\" : { Type : genai . TypeString , Description : \"The capital city of the country.\" , }, \"population_estimate\" : { Type : genai . TypeString , Description : \"An estimated population of the capital city.\" , }, }, Required : [] string { \"capital\" , \"population_estimate\" }, } schemaJSON , _ := json . Marshal ( capitalInfoOutputSchema ) structuredInfoAgentSchema , err := llmagent . New ( llmagent . Config { Name : \"structured_info_agent_schema\" , Model : model , Description : \"Provides capital and estimated population in a specific JSON format.\" , Instruction : fmt . Sprintf ( `You are an agent that provides country information. The user will provide the country name in a JSON format like {\"country\": \"country_name\"}. Respond ONLY with a JSON object matching this exact schema: %s Use your knowledge to determine the capital and estimate the population. Do not use any tools.` , string ( schemaJSON )), InputSchema : countryInputSchema , OutputSchema : capitalInfoOutputSchema , OutputKey : \"structured_info_result\" , }) if err != nil { log . Fatalf ( \"Failed to create structured info agent: %v\" , err ) } fmt . Println ( \"--- Testing Agent with Tool ---\" ) callAgent ( ctx , capitalAgentWithTool , \"capital_tool_result\" , `{\"country\": \"France\"}` ) callAgent ( ctx , capitalAgentWithTool , \"capital_tool_result\" , `{\"country\": \"Canada\"}` ) fmt . Println ( \"\\n\\n--- Testing Agent with Output Schema (No Tool Use) ---\" ) callAgent ( ctx , structuredInfoAgentSchema , \"structured_info_result\" , `{\"country\": \"France\"}` ) callAgent ( ctx , structuredInfoAgentSchema , \"structured_info_result\" , `{\"country\": \"Japan\"}` ) } // --- Full example code demonstrating LlmAgent with Tools vs. Output Schema --- import com.google.adk.agents.LlmAgent ; import com.google.adk.events.Event ; import com.google.adk.runner.Runner ; import com.google.adk.sessions.InMemorySessionService ; import com.google.adk.sessions.Session ; import com.google.adk.tools.Annotations ; import com.google.adk.tools.FunctionTool ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import com.google.genai.types.Schema ; import io.reactivex.rxjava3.core.Flowable ; import java.util.HashMap ; import java.util.List ; import java.util.Map ; import java.util.Optional ; public class LlmAgentExample { // --- 1. Define Constants --- private static final String MODEL_NAME = \"gemini-2.0-flash\" ; private static final String APP_NAME = \"capital_agent_tool\" ; private static final String USER_ID = \"test_user_456\" ; private static final String SESSION_ID_TOOL_AGENT = \"session_tool_agent_xyz\" ; private static final String SESSION_ID_SCHEMA_AGENT = \"session_schema_agent_xyz\" ; // --- 2. Define Schemas --- // Input schema used by both agents private static final Schema COUNTRY_INPUT_SCHEMA = Schema . builder () . type ( \"OBJECT\" ) . description ( \"Input for specifying a country.\" ) . properties ( Map . of ( \"country\" , Schema . builder () . type ( \"STRING\" ) . description ( \"The country to get information about.\" ) . build ())) . required ( List . of ( \"country\" )) . build (); // Output schema ONLY for the second agent private static final Schema CAPITAL_INFO_OUTPUT_SCHEMA = Schema . builder () . type ( \"OBJECT\" ) . description ( \"Schema for capital city information.\" ) . properties ( Map . of ( \"capital\" , Schema . builder () . type ( \"STRING\" ) . description ( \"The capital city of the country.\" ) . build (), \"population_estimate\" , Schema . builder () . type ( \"STRING\" ) . description ( \"An estimated population of the capital city.\" ) . build ())) . required ( List . of ( \"capital\" , \"population_estimate\" )) . build (); // --- 3. Define the Tool (Only for the first agent) --- // Retrieves the capital city of a given country. public static Map < String , Object > getCapitalCity ( @Annotations.Schema ( name = \"country\" , description = \"The country to get capital for\" ) String country ) { System . out . printf ( \"%n-- Tool Call: getCapitalCity(country='%s') --%n\" , country ); Map < String , String > countryCapitals = new HashMap <> (); countryCapitals . put ( \"united states\" , \"Washington, D.C.\" ); countryCapitals . put ( \"canada\" , \"Ottawa\" ); countryCapitals . put ( \"france\" , \"Paris\" ); countryCapitals . put ( \"japan\" , \"Tokyo\" ); String result = countryCapitals . getOrDefault ( country . toLowerCase (), \"Sorry, I couldn't find the capital for \" + country + \".\" ); System . out . printf ( \"-- Tool Result: '%s' --%n\" , result ); return Map . of ( \"result\" , result ); // Tools must return a Map } public static void main ( String [] args ){ LlmAgentExample agentExample = new LlmAgentExample (); FunctionTool capitalTool = FunctionTool . create ( agentExample . getClass (), \"getCapitalCity\" ); // --- 4. Configure Agents --- // Agent 1: Uses a tool and output_key LlmAgent capitalAgentWithTool = LlmAgent . builder () . model ( MODEL_NAME ) . name ( \"capital_agent_tool\" ) . description ( \"Retrieves the capital city using a specific tool.\" ) . instruction ( \"\"\" You are a helpful agent that provides the capital city of a country using a tool. 1. Extract the country name. 2. Use the `get_capital_city` tool to find the capital. 3. Respond clearly to the user, stating the capital city found by the tool. \"\"\" ) . tools ( capitalTool ) . inputSchema ( COUNTRY_INPUT_SCHEMA ) . outputKey ( \"capital_tool_result\" ) // Store final text response . build (); // Agent 2: Uses an output schema LlmAgent structuredInfoAgentSchema = LlmAgent . builder () . model ( MODEL_NAME ) . name ( \"structured_info_agent_schema\" ) . description ( \"Provides capital and estimated population in a specific JSON format.\" ) . instruction ( String . format ( \"\"\" You are an agent that provides country information. Respond ONLY with a JSON object matching this exact schema: %s Use your knowledge to determine the capital and estimate the population. Do not use any tools. \"\"\" , CAPITAL_INFO_OUTPUT_SCHEMA . toJson ())) // *** NO tools parameter here - using output_schema prevents tool use *** . inputSchema ( COUNTRY_INPUT_SCHEMA ) . outputSchema ( CAPITAL_INFO_OUTPUT_SCHEMA ) // Enforce JSON output structure . outputKey ( \"structured_info_result\" ) // Store final JSON response . build (); // --- 5. Set up Session Management and Runners --- InMemorySessionService sessionService = new InMemorySessionService (); sessionService . createSession ( APP_NAME , USER_ID , null , SESSION_ID_TOOL_AGENT ). blockingGet (); sessionService . createSession ( APP_NAME , USER_ID , null , SESSION_ID_SCHEMA_AGENT ). blockingGet (); Runner capitalRunner = new Runner ( capitalAgentWithTool , APP_NAME , null , sessionService ); Runner structuredRunner = new Runner ( structuredInfoAgentSchema , APP_NAME , null , sessionService ); // --- 6. Run Interactions --- System . out . println ( \"--- Testing Agent with Tool ---\" ); agentExample . callAgentAndPrint ( capitalRunner , capitalAgentWithTool , SESSION_ID_TOOL_AGENT , \"{\\\"country\\\": \\\"France\\\"}\" ); agentExample . callAgentAndPrint ( capitalRunner , capitalAgentWithTool , SESSION_ID_TOOL_AGENT , \"{\\\"country\\\": \\\"Canada\\\"}\" ); System . out . println ( \"\\n\\n--- Testing Agent with Output Schema (No Tool Use) ---\" ); agentExample . callAgentAndPrint ( structuredRunner , structuredInfoAgentSchema , SESSION_ID_SCHEMA_AGENT , \"{\\\"country\\\": \\\"France\\\"}\" ); agentExample . callAgentAndPrint ( structuredRunner , structuredInfoAgentSchema , SESSION_ID_SCHEMA_AGENT , \"{\\\"country\\\": \\\"Japan\\\"}\" ); } // --- 7. Define Agent Interaction Logic --- public void callAgentAndPrint ( Runner runner , LlmAgent agent , String sessionId , String queryJson ) { System . out . printf ( \"%n>>> Calling Agent: '%s' | Session: '%s' | Query: %s%n\" , agent . name (), sessionId , queryJson ); Content userContent = Content . fromParts ( Part . fromText ( queryJson )); final String [] finalResponseContent = { \"No final response received.\" }; Flowable < Event > eventStream = runner . runAsync ( USER_ID , sessionId , userContent ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse () && event . content (). isPresent ()) { event . content () . get () . parts () . flatMap ( parts -> parts . isEmpty () ? Optional . empty () : Optional . of ( parts . get ( 0 ))) . flatMap ( Part :: text ) . ifPresent ( text -> finalResponseContent [ 0 ] = text ); } }); System . out . printf ( \"<<< Agent '%s' Response: %s%n\" , agent . name (), finalResponseContent [ 0 ] ); // Retrieve the session again to get the updated state Session updatedSession = runner . sessionService () . getSession ( APP_NAME , USER_ID , sessionId , Optional . empty ()) . blockingGet (); if ( updatedSession != null && agent . outputKey (). isPresent ()) { // Print to verify if the stored output looks like JSON (likely from output_schema) System . out . printf ( \"--- Session State ['%s']: \" , agent . outputKey (). get ()); } } } (This example demonstrates the core concepts. More complex agents might incorporate schemas, context control, planning, etc.) ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# --- Full example code demonstrating LlmAgent with Tools vs. Output Schema ---\nimport json # Needed for pretty printing dicts\nimport asyncio \n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\nfrom pydantic import BaseModel, Field\n\n# --- 1. Define Constants ---\nAPP_NAME = \"agent_comparison_app\"\nUSER_ID = \"test_user_456\"\nSESSION_ID_TOOL_AGENT = \"session_tool_agent_xyz\"\nSESSION_ID_SCHEMA_AGENT = \"session_schema_agent_xyz\"\nMODEL_NAME = \"gemini-2.0-flash\"\n\n# --- 2. Define Schemas ---\n\n# Input schema used by both agents\nclass CountryInput(BaseModel):\n    country: str = Field(description=\"The country to get information about.\")\n\n# Output schema ONLY for the second agent\nclass CapitalInfoOutput(BaseModel):\n    capital: str = Field(description=\"The capital city of the country.\")\n    # Note: Population is illustrative; the LLM will infer or estimate this\n    # as it cannot use tools when output_schema is set.\n    population_estimate: str = Field(description=\"An estimated population of the capital city.\")\n\n# --- 3. Define the Tool (Only for the first agent) ---\ndef get_capital_city(country: str) -> str:\n    \"\"\"Retrieves the capital city of a given country.\"\"\"\n    print(f\"\\n-- Tool Call: get_capital_city(country='{country}') --\")\n    country_capitals = {\n        \"united states\": \"Washington, D.C.\",\n        \"canada\": \"Ottawa\",\n        \"france\": \"Paris\",\n        \"japan\": \"Tokyo\",\n    }\n    result = country_capitals.get(country.lower(), f\"Sorry, I couldn't find the capital for {country}.\")\n    print(f\"-- Tool Result: '{result}' --\")\n    return result\n\n# --- 4. Configure Agents ---\n\n# Agent 1: Uses a tool and output_key\ncapital_agent_with_tool = LlmAgent(\n    model=MODEL_NAME,\n    name=\"capital_agent_tool\",\n    description=\"Retrieves the capital city using a specific tool.\",\n    instruction=\"\"\"You are a helpful agent that provides the capital city of a country using a tool.\nThe user will provide the country name in a JSON format like {\"country\": \"country_name\"}.\n1. Extract the country name.\n2. Use the `get_capital_city` tool to find the capital.\n3. Respond clearly to the user, stating the capital city found by the tool.\n\"\"\",\n    tools=[get_capital_city],\n    input_schema=CountryInput,\n    output_key=\"capital_tool_result\", # Store final text response\n)\n\n# Agent 2: Uses output_schema (NO tools possible)\nstructured_info_agent_schema = LlmAgent(\n    model=MODEL_NAME,\n    name=\"structured_info_agent_schema\",\n    description=\"Provides capital and estimated population in a specific JSON format.\",\n    instruction=f\"\"\"You are an agent that provides country information.\nThe user will provide the country name in a JSON format like {{\"country\": \"country_name\"}}.\nRespond ONLY with a JSON object matching this exact schema:\n{json.dumps(CapitalInfoOutput.model_json_schema(), indent=2)}\nUse your knowledge to determine the capital and estimate the population. Do not use any tools.\n\"\"\",\n    # *** NO tools parameter here - using output_schema prevents tool use ***\n    input_schema=CountryInput,\n    output_schema=CapitalInfoOutput, # Enforce JSON output structure\n    output_key=\"structured_info_result\", # Store final JSON response\n)\n\n# --- 5. Set up Session Management and Runners ---\nsession_service = InMemorySessionService()\n\n# Create a runner for EACH agent\ncapital_runner = Runner(\n    agent=capital_agent_with_tool,\n    app_name=APP_NAME,\n    session_service=session_service\n)\nstructured_runner = Runner(\n    agent=structured_info_agent_schema,\n    app_name=APP_NAME,\n    session_service=session_service\n)\n\n# --- 6. Define Agent Interaction Logic ---\nasync def call_agent_and_print(\n    runner_instance: Runner,\n    agent_instance: LlmAgent,\n    session_id: str,\n    query_json: str\n):\n    \"\"\"Sends a query to the specified agent/runner and prints results.\"\"\"\n    print(f\"\\n>>> Calling Agent: '{agent_instance.name}' | Query: {query_json}\")\n\n    user_content = types.Content(role='user', parts=[types.Part(text=query_json)])\n\n    final_response_content = \"No final response received.\"\n    async for event in runner_instance.run_async(user_id=USER_ID, session_id=session_id, new_message=user_content):\n        # print(f\"Event: {event.type}, Author: {event.author}\") # Uncomment for detailed logging\n        if event.is_final_response() and event.content and event.content.parts:\n            # For output_schema, the content is the JSON string itself\n            final_response_content = event.content.parts[0].text\n\n    print(f\"<<< Agent '{agent_instance.name}' Response: {final_response_content}\")\n\n    current_session = await session_service.get_session(app_name=APP_NAME,\n                                                  user_id=USER_ID,\n                                                  session_id=session_id)\n    stored_output = current_session.state.get(agent_instance.output_key)\n\n    # Pretty print if the stored output looks like JSON (likely from output_schema)\n    print(f\"--- Session State ['{agent_instance.output_key}']: \", end=\"\")\n    try:\n        # Attempt to parse and pretty print if it's JSON\n        parsed_output = json.loads(stored_output)\n        print(json.dumps(parsed_output, indent=2))\n    except (json.JSONDecodeError, TypeError):\n         # Otherwise, print as string\n        print(stored_output)\n    print(\"-\" * 30)\n\n\n# --- 7. Run Interactions ---\nasync def main():\n    # Create separate sessions for clarity, though not strictly necessary if context is managed\n    print(\"--- Creating Sessions ---\")\n    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID_TOOL_AGENT)\n    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID_SCHEMA_AGENT)\n\n    print(\"--- Testing Agent with Tool ---\")\n    await call_agent_and_print(capital_runner, capital_agent_with_tool, SESSION_ID_TOOL_AGENT, '{\"country\": \"France\"}')\n    await call_agent_and_print(capital_runner, capital_agent_with_tool, SESSION_ID_TOOL_AGENT, '{\"country\": \"Canada\"}')\n\n    print(\"\\n\\n--- Testing Agent with Output Schema (No Tool Use) ---\")\n    await call_agent_and_print(structured_runner, structured_info_agent_schema, SESSION_ID_SCHEMA_AGENT, '{\"country\": \"France\"}')\n    await call_agent_and_print(structured_runner, structured_info_agent_schema, SESSION_ID_SCHEMA_AGENT, '{\"country\": \"Japan\"}')\n\n# --- Run the Agent ---\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nif __name__ == \"__main__\":\n    asyncio.run(main())"}, {"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"log\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n\n    \"google.golang.org/genai\"\n)\n\n// --- Main Runnable Example ---\n\nconst (\n    modelName = \"gemini-2.0-flash\"\n    appName   = \"agent_comparison_app\"\n    userID    = \"test_user_456\"\n)\n\ntype getCapitalCityArgs struct {\n    Country string `json:\"country\" jsonschema:\"The country to get the capital of.\"`\n}\n\n// getCapitalCity retrieves the capital city of a given country.\nfunc getCapitalCity(ctx tool.Context, args getCapitalCityArgs) map[string]any {\n    fmt.Printf(\"\\n-- Tool Call: getCapitalCity(country='%s') --\\n\", args.Country)\n    capitals := map[string]string{\n        \"united states\": \"Washington, D.C.\",\n        \"canada\":        \"Ottawa\",\n        \"france\":        \"Paris\",\n        \"japan\":         \"Tokyo\",\n    }\n    capital, ok := capitals[strings.ToLower(args.Country)]\n    if !ok {\n        result := fmt.Sprintf(\"Sorry, I couldn't find the capital for %s.\", args.Country)\n        fmt.Printf(\"-- Tool Result: '%s' --\\n\", result)\n        return map[string]any{\"result\": result}\n    }\n    fmt.Printf(\"-- Tool Result: '%s' --\\n\", capital)\n    return map[string]any{\"result\": capital}\n}\n\n// callAgent is a helper function to execute an agent with a given prompt and handle its output.\nfunc callAgent(ctx context.Context, a agent.Agent, outputKey string, prompt string) {\n    fmt.Printf(\"\\n>>> Calling Agent: '%s' | Query: %s\\n\", a.Name(), prompt)\n    // Create an in-memory session service to manage agent state.\n    sessionService := session.InMemoryService()\n\n    // Create a new session for the agent interaction.\n    sessionCreateResponse, err := sessionService.Create(ctx, &session.CreateRequest{\n        AppName: appName,\n        UserID:  userID,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create the session service: %v\", err)\n    }\n\n    session := sessionCreateResponse.Session\n\n    // Configure the runner with the application name, agent, and session service.\n    config := runner.Config{\n        AppName:        appName,\n        Agent:          a,\n        SessionService: sessionService,\n    }\n\n    // Create a new runner instance.\n    r, err := runner.New(config)\n    if err != nil {\n        log.Fatalf(\"Failed to create the runner: %v\", err)\n    }\n\n    // Prepare the user's message to send to the agent.\n    sessionID := session.ID()\n    userMsg := &genai.Content{\n        Parts: []*genai.Part{\n            genai.NewPartFromText(prompt),\n        },\n        Role: string(genai.RoleUser),\n    }\n\n    // Run the agent and process the streaming events.\n    for event, err := range r.Run(ctx, userID, sessionID, userMsg, agent.RunConfig{\n        StreamingMode: agent.StreamingModeSSE,\n    }) {\n        if err != nil {\n            fmt.Printf(\"\\nAGENT_ERROR: %v\\n\", err)\n        } else if event.Partial {\n            // Print partial responses as they are received.\n            for _, p := range event.Content.Parts {\n                fmt.Print(p.Text)\n            }\n        }\n    }\n\n    // After the run, check if there's an expected output key in the session state.\n    if outputKey != \"\" {\n        storedOutput, error := session.State().Get(outputKey)\n        if error == nil {\n            // Pretty-print the stored output if it's a JSON string.\n            fmt.Printf(\"\\n--- Session State ['%s']: \", outputKey)\n            storedString, isString := storedOutput.(string)\n            if isString {\n                var prettyJSON map[string]interface{}\n                if err := json.Unmarshal([]byte(storedString), &prettyJSON); err == nil {\n                    indentedJSON, err := json.MarshalIndent(prettyJSON, \"\", \"  \")\n                    if err == nil {\n                        fmt.Println(string(indentedJSON))\n                    } else {\n                        fmt.Println(storedString)\n                    }\n                } else {\n                    fmt.Println(storedString)\n                }\n            } else {\n                fmt.Println(storedOutput)\n            }\n            fmt.Println(strings.Repeat(\"-\", 30))\n        }\n    }\n}\n\nfunc main() {\n    ctx := context.Background()\n\n    model, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"Failed to create model: %v\", err)\n    }\n\n    capitalTool, err := functiontool.New(\n        functiontool.Config{\n            Name:        \"get_capital_city\",\n            Description: \"Retrieves the capital city for a given country.\",\n        },\n        getCapitalCity,\n    )\n    if err != nil {\n        log.Fatalf(\"Failed to create function tool: %v\", err)\n    }\n\n    countryInputSchema := &genai.Schema{\n        Type:        genai.TypeObject,\n        Description: \"Input for specifying a country.\",\n        Properties: map[string]*genai.Schema{\n            \"country\": {\n                Type:        genai.TypeString,\n                Description: \"The country to get information about.\",\n            },\n        },\n        Required: []string{\"country\"},\n    }\n\n    capitalAgentWithTool, err := llmagent.New(llmagent.Config{\n        Name:        \"capital_agent_tool\",\n        Model:       model,\n        Description: \"Retrieves the capital city using a specific tool.\",\n        Instruction: `You are a helpful agent that provides the capital city of a country using a tool.\nThe user will provide the country name in a JSON format like {\"country\": \"country_name\"}.\n1. Extract the country name.\n2. Use the 'get_capital_city' tool to find the capital.\n3. Respond clearly to the user, stating the capital city found by the tool.`,\n        Tools:       []tool.Tool{capitalTool},\n        InputSchema: countryInputSchema,\n        OutputKey:   \"capital_tool_result\",\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create capital agent with tool: %v\", err)\n    }\n\n    capitalInfoOutputSchema := &genai.Schema{\n        Type:        genai.TypeObject,\n        Description: \"Schema for capital city information.\",\n        Properties: map[string]*genai.Schema{\n            \"capital\": {\n                Type:        genai.TypeString,\n                Description: \"The capital city of the country.\",\n            },\n            \"population_estimate\": {\n                Type:        genai.TypeString,\n                Description: \"An estimated population of the capital city.\",\n            },\n        },\n        Required: []string{\"capital\", \"population_estimate\"},\n    }\n    schemaJSON, _ := json.Marshal(capitalInfoOutputSchema)\n    structuredInfoAgentSchema, err := llmagent.New(llmagent.Config{\n        Name:        \"structured_info_agent_schema\",\n        Model:       model,\n        Description: \"Provides capital and estimated population in a specific JSON format.\",\n        Instruction: fmt.Sprintf(`You are an agent that provides country information.\nThe user will provide the country name in a JSON format like {\"country\": \"country_name\"}.\nRespond ONLY with a JSON object matching this exact schema:\n%s\nUse your knowledge to determine the capital and estimate the population. Do not use any tools.`, string(schemaJSON)),\n        InputSchema:  countryInputSchema,\n        OutputSchema: capitalInfoOutputSchema,\n        OutputKey:    \"structured_info_result\",\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create structured info agent: %v\", err)\n    }\n\n    fmt.Println(\"--- Testing Agent with Tool ---\")\n    callAgent(ctx, capitalAgentWithTool, \"capital_tool_result\", `{\"country\": \"France\"}`)\n    callAgent(ctx, capitalAgentWithTool, \"capital_tool_result\", `{\"country\": \"Canada\"}`)\n\n    fmt.Println(\"\\n\\n--- Testing Agent with Output Schema (No Tool Use) ---\")\n    callAgent(ctx, structuredInfoAgentSchema, \"structured_info_result\", `{\"country\": \"France\"}`)\n    callAgent(ctx, structuredInfoAgentSchema, \"structured_info_result\", `{\"country\": \"Japan\"}`)\n}"}, {"language": "text", "code": "// --- Full example code demonstrating LlmAgent with Tools vs. Output Schema ---\n\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.InMemorySessionService;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.Annotations;\nimport com.google.adk.tools.FunctionTool;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport com.google.genai.types.Schema;\nimport io.reactivex.rxjava3.core.Flowable;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Optional;\n\npublic class LlmAgentExample {\n\n  // --- 1. Define Constants ---\n  private static final String MODEL_NAME = \"gemini-2.0-flash\";\n  private static final String APP_NAME = \"capital_agent_tool\";\n  private static final String USER_ID = \"test_user_456\";\n  private static final String SESSION_ID_TOOL_AGENT = \"session_tool_agent_xyz\";\n  private static final String SESSION_ID_SCHEMA_AGENT = \"session_schema_agent_xyz\";\n\n  // --- 2. Define Schemas ---\n\n  // Input schema used by both agents\n  private static final Schema COUNTRY_INPUT_SCHEMA =\n      Schema.builder()\n          .type(\"OBJECT\")\n          .description(\"Input for specifying a country.\")\n          .properties(\n              Map.of(\n                  \"country\",\n                  Schema.builder()\n                      .type(\"STRING\")\n                      .description(\"The country to get information about.\")\n                      .build()))\n          .required(List.of(\"country\"))\n          .build();\n\n  // Output schema ONLY for the second agent\n  private static final Schema CAPITAL_INFO_OUTPUT_SCHEMA =\n      Schema.builder()\n          .type(\"OBJECT\")\n          .description(\"Schema for capital city information.\")\n          .properties(\n              Map.of(\n                  \"capital\",\n                  Schema.builder()\n                      .type(\"STRING\")\n                      .description(\"The capital city of the country.\")\n                      .build(),\n                  \"population_estimate\",\n                  Schema.builder()\n                      .type(\"STRING\")\n                      .description(\"An estimated population of the capital city.\")\n                      .build()))\n          .required(List.of(\"capital\", \"population_estimate\"))\n          .build();\n\n  // --- 3. Define the Tool (Only for the first agent) ---\n  // Retrieves the capital city of a given country.\n  public static Map<String, Object> getCapitalCity(\n      @Annotations.Schema(name = \"country\", description = \"The country to get capital for\")\n      String country) {\n    System.out.printf(\"%n-- Tool Call: getCapitalCity(country='%s') --%n\", country);\n    Map<String, String> countryCapitals = new HashMap<>();\n    countryCapitals.put(\"united states\", \"Washington, D.C.\");\n    countryCapitals.put(\"canada\", \"Ottawa\");\n    countryCapitals.put(\"france\", \"Paris\");\n    countryCapitals.put(\"japan\", \"Tokyo\");\n\n    String result =\n        countryCapitals.getOrDefault(\n            country.toLowerCase(), \"Sorry, I couldn't find the capital for \" + country + \".\");\n    System.out.printf(\"-- Tool Result: '%s' --%n\", result);\n    return Map.of(\"result\", result); // Tools must return a Map\n  }\n\n  public static void main(String[] args){\n    LlmAgentExample agentExample = new LlmAgentExample();\n    FunctionTool capitalTool = FunctionTool.create(agentExample.getClass(), \"getCapitalCity\");\n\n    // --- 4. Configure Agents ---\n\n    // Agent 1: Uses a tool and output_key\n    LlmAgent capitalAgentWithTool =\n        LlmAgent.builder()\n            .model(MODEL_NAME)\n            .name(\"capital_agent_tool\")\n            .description(\"Retrieves the capital city using a specific tool.\")\n            .instruction(\n              \"\"\"\n              You are a helpful agent that provides the capital city of a country using a tool.\n              1. Extract the country name.\n              2. Use the `get_capital_city` tool to find the capital.\n              3. Respond clearly to the user, stating the capital city found by the tool.\n              \"\"\")\n            .tools(capitalTool)\n            .inputSchema(COUNTRY_INPUT_SCHEMA)\n            .outputKey(\"capital_tool_result\") // Store final text response\n            .build();\n\n    // Agent 2: Uses an output schema\n    LlmAgent structuredInfoAgentSchema =\n        LlmAgent.builder()\n            .model(MODEL_NAME)\n            .name(\"structured_info_agent_schema\")\n            .description(\"Provides capital and estimated population in a specific JSON format.\")\n            .instruction(\n                String.format(\"\"\"\n                You are an agent that provides country information.\n                Respond ONLY with a JSON object matching this exact schema: %s\n                Use your knowledge to determine the capital and estimate the population. Do not use any tools.\n                \"\"\", CAPITAL_INFO_OUTPUT_SCHEMA.toJson()))\n            // *** NO tools parameter here - using output_schema prevents tool use ***\n            .inputSchema(COUNTRY_INPUT_SCHEMA)\n            .outputSchema(CAPITAL_INFO_OUTPUT_SCHEMA) // Enforce JSON output structure\n            .outputKey(\"structured_info_result\") // Store final JSON response\n            .build();\n\n    // --- 5. Set up Session Management and Runners ---\n    InMemorySessionService sessionService = new InMemorySessionService();\n\n    sessionService.createSession(APP_NAME, USER_ID, null, SESSION_ID_TOOL_AGENT).blockingGet();\n    sessionService.createSession(APP_NAME, USER_ID, null, SESSION_ID_SCHEMA_AGENT).blockingGet();\n\n    Runner capitalRunner = new Runner(capitalAgentWithTool, APP_NAME, null, sessionService);\n    Runner structuredRunner = new Runner(structuredInfoAgentSchema, APP_NAME, null, sessionService);\n\n    // --- 6. Run Interactions ---\n    System.out.println(\"--- Testing Agent with Tool ---\");\n    agentExample.callAgentAndPrint(\n        capitalRunner, capitalAgentWithTool, SESSION_ID_TOOL_AGENT, \"{\\\"country\\\": \\\"France\\\"}\");\n    agentExample.callAgentAndPrint(\n        capitalRunner, capitalAgentWithTool, SESSION_ID_TOOL_AGENT, \"{\\\"country\\\": \\\"Canada\\\"}\");\n\n    System.out.println(\"\\n\\n--- Testing Agent with Output Schema (No Tool Use) ---\");\n    agentExample.callAgentAndPrint(\n        structuredRunner,\n        structuredInfoAgentSchema,\n        SESSION_ID_SCHEMA_AGENT,\n        \"{\\\"country\\\": \\\"France\\\"}\");\n    agentExample.callAgentAndPrint(\n        structuredRunner,\n        structuredInfoAgentSchema,\n        SESSION_ID_SCHEMA_AGENT,\n        \"{\\\"country\\\": \\\"Japan\\\"}\");\n  }\n\n  // --- 7. Define Agent Interaction Logic ---\n  public void callAgentAndPrint(Runner runner, LlmAgent agent, String sessionId, String queryJson) {\n    System.out.printf(\n        \"%n>>> Calling Agent: '%s' | Session: '%s' | Query: %s%n\",\n        agent.name(), sessionId, queryJson);\n\n    Content userContent = Content.fromParts(Part.fromText(queryJson));\n    final String[] finalResponseContent = {\"No final response received.\"};\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, sessionId, userContent);\n\n    // Stream event response\n    eventStream.blockingForEach(event -> {\n          if (event.finalResponse() && event.content().isPresent()) {\n            event\n                .content()\n                .get()\n                .parts()\n                .flatMap(parts -> parts.isEmpty() ? Optional.empty() : Optional.of(parts.get(0)))\n                .flatMap(Part::text)\n                .ifPresent(text -> finalResponseContent[0] = text);\n          }\n        });\n\n    System.out.printf(\"<<< Agent '%s' Response: %s%n\", agent.name(), finalResponseContent[0]);\n\n    // Retrieve the session again to get the updated state\n    Session updatedSession =\n        runner\n            .sessionService()\n            .getSession(APP_NAME, USER_ID, sessionId, Optional.empty())\n            .blockingGet();\n\n    if (updatedSession != null && agent.outputKey().isPresent()) {\n      // Print to verify if the stored output looks like JSON (likely from output_schema)\n      System.out.printf(\"--- Session State ['%s']: \", agent.outputKey().get());\n      }\n  }\n}"}]}, {"heading_path": ["Related Concepts (Deferred Topics)\u00b6"], "text": "Related Concepts (Deferred Topics) \u00b6 While this page covers the core configuration of LlmAgent , several related concepts provide more advanced control and are detailed elsewhere: Callbacks: Intercepting execution points (before/after model calls, before/after tool calls) using before_model_callback , after_model_callback , etc. See Callbacks . Multi-Agent Control: Advanced strategies for agent interaction, including planning ( planner ), controlling agent transfer ( disallow_transfer_to_parent , disallow_transfer_to_peers ), and system-wide instructions ( global_instruction ). See Multi-Agents . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:05.106158", "source_type": "adk-docs"}
{"doc_id": "96db29bb8b4e59fd397e54962239381de40c5b5c99cf81c558cbfc8fd8d2012d", "url": "https://google.github.io/adk-docs/agents/workflow-agents", "title": "Workflow Agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Workflow Agents\u00b6"], "text": "Workflow Agents \u00b6 Supported in ADK Python Go Java This section introduces \" workflow agents \" - specialized agents that control the execution flow of its sub-agents . Workflow agents are specialized components in ADK designed purely for orchestrating the execution flow of sub-agents . Their primary role is to manage how and when other agents run, defining the control flow of a process. Unlike LLM Agents , which use Large Language Models for dynamic reasoning and decision-making, Workflow Agents operate based on predefined logic . They determine the execution sequence according to their type (e.g., sequential, parallel, loop) without consulting an LLM for the orchestration itself. This results in deterministic and predictable execution patterns . ADK provides three core workflow agent types, each implementing a distinct execution pattern: Sequential Agents Executes sub-agents one after another, in sequence . Learn more Loop Agents Repeatedly executes its sub-agents until a specific termination condition is met. Learn more Parallel Agents Executes multiple sub-agents in parallel . Learn more ", "code_blocks": []}, {"heading_path": ["Why Use Workflow Agents?\u00b6"], "text": "Why Use Workflow Agents? \u00b6 Workflow agents are essential when you need explicit control over how a series of tasks or agents are executed. They provide: Predictability: The flow of execution is guaranteed based on the agent type and configuration. Reliability: Ensures tasks run in the required order or pattern consistently. Structure: Allows you to build complex processes by composing agents within clear control structures. While the workflow agent manages the control flow deterministically, the sub-agents it orchestrates can themselves be any type of agent, including intelligent LLM Agent instances. This allows you to combine structured process control with flexible, LLM-powered task execution. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:05.452554", "source_type": "adk-docs"}
{"doc_id": "68dd684959fbecbd384b464b0934e0a2b378129e675ff11ece2d2d4b3ee90296", "url": "https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents", "title": "Sequential agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Sequential agents\u00b6"], "text": "Sequential agents \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.2.0 The SequentialAgent is a workflow agent that executes its sub-agents in the order they are specified in the list.\nUse the SequentialAgent when you want the execution to occur in a fixed, strict order. ", "code_blocks": []}, {"heading_path": ["Example\u00b6"], "text": "Example \u00b6 You want to build an agent that can summarize any webpage, using two tools: Get Page Contents and Summarize Page . Because the agent must always call Get Page Contents before calling Summarize Page (you can't summarize from nothing!), you should build your agent using a SequentialAgent . As with other workflow agents , the SequentialAgent is not powered by an LLM, and is thus deterministic in how it executes. That being said, workflow agents are concerned only with their execution (i.e. in sequence), and not their internal logic; the tools or sub-agents of a workflow agent may or may not utilize LLMs. ", "code_blocks": []}, {"heading_path": ["How it works\u00b6"], "text": "How it works \u00b6 When the SequentialAgent 's Run Async method is called, it performs the following actions: Iteration: It iterates through the sub agents list in the order they were provided. Sub-Agent Execution: For each sub-agent in the list, it calls the sub-agent's Run Async method. ", "code_blocks": []}, {"heading_path": ["Full Example: Code Development Pipeline\u00b6"], "text": "Full Example: Code Development Pipeline \u00b6 Consider a simplified code development pipeline: Code Writer Agent: An LLM Agent that generates initial code based on a specification. Code Reviewer Agent: An LLM Agent that reviews the generated code for errors, style issues, and adherence to best practices.  It receives the output of the Code Writer Agent. Code Refactorer Agent: An LLM Agent that takes the reviewed code (and the reviewer's comments) and refactors it to improve quality and address issues. A SequentialAgent is perfect for this: SequentialAgent ( sub_agents = [ CodeWriterAgent , CodeReviewerAgent , CodeRefactorerAgent ]) This ensures the code is written, then reviewed, and finally refactored, in a strict, dependable order. The output from each sub-agent is passed to the next by storing them in state via Output Key . Shared Invocation Context The SequentialAgent passes the same InvocationContext to each of its sub-agents. This means they all share the same session state, including the temporary ( temp: ) namespace, making it easy to pass data between steps within a single turn. Code Python Go Java # Part of agent.py --> Follow https://google.github.io/adk-docs/get-started/quickstart/ to learn the setup # --- 1. Define Sub-Agents for Each Pipeline Stage --- # Code Writer Agent # Takes the initial specification (from user query) and writes code. code_writer_agent = LlmAgent ( name = \"CodeWriterAgent\" , model = GEMINI_MODEL , # Change 3: Improved instruction instruction = \"\"\"You are a Python Code Generator. Based *only* on the user's request, write Python code that fulfills the requirement. Output *only* the complete Python code block, enclosed in triple backticks (```python ... ```). Do not add any other text before or after the code block. \"\"\" , description = \"Writes initial Python code based on a specification.\" , output_key = \"generated_code\" # Stores output in state['generated_code'] ) # Code Reviewer Agent # Takes the code generated by the previous agent (read from state) and provides feedback. code_reviewer_agent = LlmAgent ( name = \"CodeReviewerAgent\" , model = GEMINI_MODEL , # Change 3: Improved instruction, correctly using state key injection instruction = \"\"\"You are an expert Python Code Reviewer. Your task is to provide constructive feedback on the provided code. **Code to Review:** ```python {generated_code} ``` **Review Criteria:** 1.  **Correctness:** Does the code work as intended? Are there logic errors? 2.  **Readability:** Is the code clear and easy to understand? Follows PEP 8 style guidelines? 3.  **Efficiency:** Is the code reasonably efficient? Any obvious performance bottlenecks? 4.  **Edge Cases:** Does the code handle potential edge cases or invalid inputs gracefully? 5.  **Best Practices:** Does the code follow common Python best practices? **Output:** Provide your feedback as a concise, bulleted list. Focus on the most important points for improvement. If the code is excellent and requires no changes, simply state: \"No major issues found.\" Output *only* the review comments or the \"No major issues\" statement. \"\"\" , description = \"Reviews code and provides feedback.\" , output_key = \"review_comments\" , # Stores output in state['review_comments'] ) # Code Refactorer Agent # Takes the original code and the review comments (read from state) and refactors the code. code_refactorer_agent = LlmAgent ( name = \"CodeRefactorerAgent\" , model = GEMINI_MODEL , # Change 3: Improved instruction, correctly using state key injection instruction = \"\"\"You are a Python Code Refactoring AI. Your goal is to improve the given Python code based on the provided review comments. **Original Code:** ```python {generated_code} ``` **Review Comments:** {review_comments} **Task:** Carefully apply the suggestions from the review comments to refactor the original code. If the review comments state \"No major issues found,\" return the original code unchanged. Ensure the final code is complete, functional, and includes necessary imports and docstrings. **Output:** Output *only* the final, refactored Python code block, enclosed in triple backticks (```python ... ```). Do not add any other text before or after the code block. \"\"\" , description = \"Refactors code based on review comments.\" , output_key = \"refactored_code\" , # Stores output in state['refactored_code'] ) # --- 2. Create the SequentialAgent --- # This agent orchestrates the pipeline by running the sub_agents in order. code_pipeline_agent = SequentialAgent ( name = \"CodePipelineAgent\" , sub_agents = [ code_writer_agent , code_reviewer_agent , code_refactorer_agent ], description = \"Executes a sequence of code writing, reviewing, and refactoring.\" , # The agents will run in the order provided: Writer -> Reviewer -> Refactorer ) # For ADK tools compatibility, the root agent must be named `root_agent` root_agent = code_pipeline_agent model , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { return fmt . Errorf ( \"failed to create model: %v\" , err ) } codeWriterAgent , err := llmagent . New ( llmagent . Config { Name : \"CodeWriterAgent\" , Model : model , Description : \"Writes initial Go code based on a specification.\" , Instruction : `You are a Go Code Generator. Based *only* on the user's request, write Go code that fulfills the requirement. Output *only* the complete Go code block, enclosed in triple backticks ('''go ... '''). Do not add any other text before or after the code block.` , OutputKey : \"generated_code\" , }) if err != nil { return fmt . Errorf ( \"failed to create code writer agent: %v\" , err ) } codeReviewerAgent , err := llmagent . New ( llmagent . Config { Name : \"CodeReviewerAgent\" , Model : model , Description : \"Reviews code and provides feedback.\" , Instruction : `You are an expert Go Code Reviewer. Your task is to provide constructive feedback on the provided code. **Code to Review:** '''go {generated_code} ''' **Review Criteria:** 1.  **Correctness:** Does the code work as intended? Are there logic errors? 2.  **Readability:** Is the code clear and easy to understand? Follows Go style guidelines? 3.  **Idiomatic Go:** Does the code use Go's features in a natural and standard way? 4.  **Edge Cases:** Does the code handle potential edge cases or invalid inputs gracefully? 5.  **Best Practices:** Does the code follow common Go best practices? **Output:** Provide your feedback as a concise, bulleted list. Focus on the most important points for improvement. If the code is excellent and requires no changes, simply state: \"No major issues found.\" Output *only* the review comments or the \"No major issues\" statement.` , OutputKey : \"review_comments\" , }) if err != nil { return fmt . Errorf ( \"failed to create code reviewer agent: %v\" , err ) } codeRefactorerAgent , err := llmagent . New ( llmagent . Config { Name : \"CodeRefactorerAgent\" , Model : model , Description : \"Refactors code based on review comments.\" , Instruction : `You are a Go Code Refactoring AI. Your goal is to improve the given Go code based on the provided review comments. **Original Code:** '''go {generated_code} ''' **Review Comments:** {review_comments} **Task:** Carefully apply the suggestions from the review comments to refactor the original code. If the review comments state \"No major issues found,\" return the original code unchanged. Ensure the final code is complete, functional, and includes necessary imports. **Output:** Output *only* the final, refactored Go code block, enclosed in triple backticks ('''go ... '''). Do not add any other text before or after the code block.` , OutputKey : \"refactored_code\" , }) if err != nil { return fmt . Errorf ( \"failed to create code refactorer agent: %v\" , err ) } codePipelineAgent , err := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : appName , Description : \"Executes a sequence of code writing, reviewing, and refactoring.\" , SubAgents : [] agent . Agent { codeWriterAgent , codeReviewerAgent , codeRefactorerAgent , }, }, }) if err != nil { return fmt . Errorf ( \"failed to create sequential agent: %v\" , err ) } import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.SequentialAgent ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; public class SequentialAgentExample { private static final String APP_NAME = \"CodePipelineAgent\" ; private static final String USER_ID = \"test_user_456\" ; private static final String MODEL_NAME = \"gemini-2.0-flash\" ; public static void main ( String [] args ) { SequentialAgentExample sequentialAgentExample = new SequentialAgentExample (); sequentialAgentExample . runAgent ( \"Write a Java function to calculate the factorial of a number.\" ); } public void runAgent ( String prompt ) { LlmAgent codeWriterAgent = LlmAgent . builder () . model ( MODEL_NAME ) . name ( \"CodeWriterAgent\" ) . description ( \"Writes initial Java code based on a specification.\" ) . instruction ( \"\"\" You are a Java Code Generator. Based *only* on the user's request, write Java code that fulfills the requirement. Output *only* the complete Java code block, enclosed in triple backticks (```java ... ```). Do not add any other text before or after the code block. \"\"\" ) . outputKey ( \"generated_code\" ) . build (); LlmAgent codeReviewerAgent = LlmAgent . builder () . model ( MODEL_NAME ) . name ( \"CodeReviewerAgent\" ) . description ( \"Reviews code and provides feedback.\" ) . instruction ( \"\"\" You are an expert Java Code Reviewer. Your task is to provide constructive feedback on the provided code. **Code to Review:** ```java {generated_code} ``` **Review Criteria:** 1.  **Correctness:** Does the code work as intended? Are there logic errors? 2.  **Readability:** Is the code clear and easy to understand? Follows Java style guidelines? 3.  **Efficiency:** Is the code reasonably efficient? Any obvious performance bottlenecks? 4.  **Edge Cases:** Does the code handle potential edge cases or invalid inputs gracefully? 5.  **Best Practices:** Does the code follow common Java best practices? **Output:** Provide your feedback as a concise, bulleted list. Focus on the most important points for improvement. If the code is excellent and requires no changes, simply state: \"No major issues found.\" Output *only* the review comments or the \"No major issues\" statement. \"\"\" ) . outputKey ( \"review_comments\" ) . build (); LlmAgent codeRefactorerAgent = LlmAgent . builder () . model ( MODEL_NAME ) . name ( \"CodeRefactorerAgent\" ) . description ( \"Refactors code based on review comments.\" ) . instruction ( \"\"\" You are a Java Code Refactoring AI. Your goal is to improve the given Java code based on the provided review comments. **Original Code:** ```java {generated_code} ``` **Review Comments:** {review_comments} **Task:** Carefully apply the suggestions from the review comments to refactor the original code. If the review comments state \"No major issues found,\" return the original code unchanged. Ensure the final code is complete, functional, and includes necessary imports and docstrings. **Output:** Output *only* the final, refactored Java code block, enclosed in triple backticks (```java ... ```). Do not add any other text before or after the code block. \"\"\" ) . outputKey ( \"refactored_code\" ) . build (); SequentialAgent codePipelineAgent = SequentialAgent . builder () . name ( APP_NAME ) . description ( \"Executes a sequence of code writing, reviewing, and refactoring.\" ) // The agents will run in the order provided: Writer -> Reviewer -> Refactorer . subAgents ( codeWriterAgent , codeReviewerAgent , codeRefactorerAgent ) . build (); // Create an InMemoryRunner InMemoryRunner runner = new InMemoryRunner ( codePipelineAgent , APP_NAME ); // InMemoryRunner automatically creates a session service. Create a session using the service Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( prompt )); // Run the agent Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } } Back to top ", "code_blocks": [{"language": "text", "code": "SequentialAgent(sub_agents=[CodeWriterAgent, CodeReviewerAgent, CodeRefactorerAgent])"}, {"language": "text", "code": "# Part of agent.py --> Follow https://google.github.io/adk-docs/get-started/quickstart/ to learn the setup\n\n# --- 1. Define Sub-Agents for Each Pipeline Stage ---\n\n# Code Writer Agent\n# Takes the initial specification (from user query) and writes code.\ncode_writer_agent = LlmAgent(\n    name=\"CodeWriterAgent\",\n    model=GEMINI_MODEL,\n    # Change 3: Improved instruction\n    instruction=\"\"\"You are a Python Code Generator.\nBased *only* on the user's request, write Python code that fulfills the requirement.\nOutput *only* the complete Python code block, enclosed in triple backticks (```python ... ```). \nDo not add any other text before or after the code block.\n\"\"\",\n    description=\"Writes initial Python code based on a specification.\",\n    output_key=\"generated_code\" # Stores output in state['generated_code']\n)\n\n# Code Reviewer Agent\n# Takes the code generated by the previous agent (read from state) and provides feedback.\ncode_reviewer_agent = LlmAgent(\n    name=\"CodeReviewerAgent\",\n    model=GEMINI_MODEL,\n    # Change 3: Improved instruction, correctly using state key injection\n    instruction=\"\"\"You are an expert Python Code Reviewer. \n    Your task is to provide constructive feedback on the provided code.\n\n    **Code to Review:**\n    ```python\n    {generated_code}\n    ```\n\n**Review Criteria:**\n1.  **Correctness:** Does the code work as intended? Are there logic errors?\n2.  **Readability:** Is the code clear and easy to understand? Follows PEP 8 style guidelines?\n3.  **Efficiency:** Is the code reasonably efficient? Any obvious performance bottlenecks?\n4.  **Edge Cases:** Does the code handle potential edge cases or invalid inputs gracefully?\n5.  **Best Practices:** Does the code follow common Python best practices?\n\n**Output:**\nProvide your feedback as a concise, bulleted list. Focus on the most important points for improvement.\nIf the code is excellent and requires no changes, simply state: \"No major issues found.\"\nOutput *only* the review comments or the \"No major issues\" statement.\n\"\"\",\n    description=\"Reviews code and provides feedback.\",\n    output_key=\"review_comments\", # Stores output in state['review_comments']\n)\n\n\n# Code Refactorer Agent\n# Takes the original code and the review comments (read from state) and refactors the code.\ncode_refactorer_agent = LlmAgent(\n    name=\"CodeRefactorerAgent\",\n    model=GEMINI_MODEL,\n    # Change 3: Improved instruction, correctly using state key injection\n    instruction=\"\"\"You are a Python Code Refactoring AI.\nYour goal is to improve the given Python code based on the provided review comments.\n\n  **Original Code:**\n  ```python\n  {generated_code}\n  ```\n\n  **Review Comments:**\n  {review_comments}\n\n**Task:**\nCarefully apply the suggestions from the review comments to refactor the original code.\nIf the review comments state \"No major issues found,\" return the original code unchanged.\nEnsure the final code is complete, functional, and includes necessary imports and docstrings.\n\n**Output:**\nOutput *only* the final, refactored Python code block, enclosed in triple backticks (```python ... ```). \nDo not add any other text before or after the code block.\n\"\"\",\n    description=\"Refactors code based on review comments.\",\n    output_key=\"refactored_code\", # Stores output in state['refactored_code']\n)\n\n\n# --- 2. Create the SequentialAgent ---\n# This agent orchestrates the pipeline by running the sub_agents in order.\ncode_pipeline_agent = SequentialAgent(\n    name=\"CodePipelineAgent\",\n    sub_agents=[code_writer_agent, code_reviewer_agent, code_refactorer_agent],\n    description=\"Executes a sequence of code writing, reviewing, and refactoring.\",\n    # The agents will run in the order provided: Writer -> Reviewer -> Refactorer\n)\n\n# For ADK tools compatibility, the root agent must be named `root_agent`\nroot_agent = code_pipeline_agent"}, {"language": "text", "code": "model, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        return fmt.Errorf(\"failed to create model: %v\", err)\n    }\n\n    codeWriterAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"CodeWriterAgent\",\n        Model:       model,\n        Description: \"Writes initial Go code based on a specification.\",\n        Instruction: `You are a Go Code Generator.\nBased *only* on the user's request, write Go code that fulfills the requirement.\nOutput *only* the complete Go code block, enclosed in triple backticks ('''go ... ''').\nDo not add any other text before or after the code block.`,\n        OutputKey: \"generated_code\",\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create code writer agent: %v\", err)\n    }\n\n    codeReviewerAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"CodeReviewerAgent\",\n        Model:       model,\n        Description: \"Reviews code and provides feedback.\",\n        Instruction: `You are an expert Go Code Reviewer.\nYour task is to provide constructive feedback on the provided code.\n\n**Code to Review:**\n'''go\n{generated_code}\n'''\n\n**Review Criteria:**\n1.  **Correctness:** Does the code work as intended? Are there logic errors?\n2.  **Readability:** Is the code clear and easy to understand? Follows Go style guidelines?\n3.  **Idiomatic Go:** Does the code use Go's features in a natural and standard way?\n4.  **Edge Cases:** Does the code handle potential edge cases or invalid inputs gracefully?\n5.  **Best Practices:** Does the code follow common Go best practices?\n\n**Output:**\nProvide your feedback as a concise, bulleted list. Focus on the most important points for improvement.\nIf the code is excellent and requires no changes, simply state: \"No major issues found.\"\nOutput *only* the review comments or the \"No major issues\" statement.`,\n        OutputKey: \"review_comments\",\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create code reviewer agent: %v\", err)\n    }\n\n    codeRefactorerAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"CodeRefactorerAgent\",\n        Model:       model,\n        Description: \"Refactors code based on review comments.\",\n        Instruction: `You are a Go Code Refactoring AI.\nYour goal is to improve the given Go code based on the provided review comments.\n\n**Original Code:**\n'''go\n{generated_code}\n'''\n\n**Review Comments:**\n{review_comments}\n\n**Task:**\nCarefully apply the suggestions from the review comments to refactor the original code.\nIf the review comments state \"No major issues found,\" return the original code unchanged.\nEnsure the final code is complete, functional, and includes necessary imports.\n\n**Output:**\nOutput *only* the final, refactored Go code block, enclosed in triple backticks ('''go ... ''').\nDo not add any other text before or after the code block.`,\n        OutputKey: \"refactored_code\",\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create code refactorer agent: %v\", err)\n    }\n\n    codePipelineAgent, err := sequentialagent.New(sequentialagent.Config{\n        AgentConfig: agent.Config{\n            Name:        appName,\n            Description: \"Executes a sequence of code writing, reviewing, and refactoring.\",\n            SubAgents: []agent.Agent{\n                codeWriterAgent,\n                codeReviewerAgent,\n                codeRefactorerAgent,\n            },\n        },\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create sequential agent: %v\", err)\n    }"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.SequentialAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\n\npublic class SequentialAgentExample {\n\n  private static final String APP_NAME = \"CodePipelineAgent\";\n  private static final String USER_ID = \"test_user_456\";\n  private static final String MODEL_NAME = \"gemini-2.0-flash\";\n\n  public static void main(String[] args) {\n    SequentialAgentExample sequentialAgentExample = new SequentialAgentExample();\n    sequentialAgentExample.runAgent(\n        \"Write a Java function to calculate the factorial of a number.\");\n  }\n\n  public void runAgent(String prompt) {\n\n    LlmAgent codeWriterAgent =\n        LlmAgent.builder()\n            .model(MODEL_NAME)\n            .name(\"CodeWriterAgent\")\n            .description(\"Writes initial Java code based on a specification.\")\n            .instruction(\n                \"\"\"\n                You are a Java Code Generator.\n                Based *only* on the user's request, write Java code that fulfills the requirement.\n                Output *only* the complete Java code block, enclosed in triple backticks (```java ... ```).\n                Do not add any other text before or after the code block.\n                \"\"\")\n            .outputKey(\"generated_code\")\n            .build();\n\n    LlmAgent codeReviewerAgent =\n        LlmAgent.builder()\n            .model(MODEL_NAME)\n            .name(\"CodeReviewerAgent\")\n            .description(\"Reviews code and provides feedback.\")\n            .instruction(\n                \"\"\"\n                    You are an expert Java Code Reviewer.\n                    Your task is to provide constructive feedback on the provided code.\n\n                    **Code to Review:**\n                    ```java\n                    {generated_code}\n                    ```\n\n                    **Review Criteria:**\n                    1.  **Correctness:** Does the code work as intended? Are there logic errors?\n                    2.  **Readability:** Is the code clear and easy to understand? Follows Java style guidelines?\n                    3.  **Efficiency:** Is the code reasonably efficient? Any obvious performance bottlenecks?\n                    4.  **Edge Cases:** Does the code handle potential edge cases or invalid inputs gracefully?\n                    5.  **Best Practices:** Does the code follow common Java best practices?\n\n                    **Output:**\n                    Provide your feedback as a concise, bulleted list. Focus on the most important points for improvement.\n                    If the code is excellent and requires no changes, simply state: \"No major issues found.\"\n                    Output *only* the review comments or the \"No major issues\" statement.\n                \"\"\")\n            .outputKey(\"review_comments\")\n            .build();\n\n    LlmAgent codeRefactorerAgent =\n        LlmAgent.builder()\n            .model(MODEL_NAME)\n            .name(\"CodeRefactorerAgent\")\n            .description(\"Refactors code based on review comments.\")\n            .instruction(\n                \"\"\"\n                You are a Java Code Refactoring AI.\n                Your goal is to improve the given Java code based on the provided review comments.\n\n                  **Original Code:**\n                  ```java\n                  {generated_code}\n                  ```\n\n                  **Review Comments:**\n                  {review_comments}\n\n                **Task:**\n                Carefully apply the suggestions from the review comments to refactor the original code.\n                If the review comments state \"No major issues found,\" return the original code unchanged.\n                Ensure the final code is complete, functional, and includes necessary imports and docstrings.\n\n                **Output:**\n                Output *only* the final, refactored Java code block, enclosed in triple backticks (```java ... ```).\n                Do not add any other text before or after the code block.\n                \"\"\")\n            .outputKey(\"refactored_code\")\n            .build();\n\n    SequentialAgent codePipelineAgent =\n        SequentialAgent.builder()\n            .name(APP_NAME)\n            .description(\"Executes a sequence of code writing, reviewing, and refactoring.\")\n            // The agents will run in the order provided: Writer -> Reviewer -> Refactorer\n            .subAgents(codeWriterAgent, codeReviewerAgent, codeRefactorerAgent)\n            .build();\n\n    // Create an InMemoryRunner\n    InMemoryRunner runner = new InMemoryRunner(codePipelineAgent, APP_NAME);\n    // InMemoryRunner automatically creates a session service. Create a session using the service\n    Session session = runner.sessionService().createSession(APP_NAME, USER_ID).blockingGet();\n    Content userMessage = Content.fromParts(Part.fromText(prompt));\n\n    // Run the agent\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n    // Stream event response\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n}"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:06.029383", "source_type": "adk-docs"}
{"doc_id": "6f7423ab8554d74d1fd0a71c122d5bf9e41dac50541b2fcf85e67370c1c42659", "url": "https://google.github.io/adk-docs/agents/workflow-agents/loop-agents", "title": "Loop agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Loop agents\u00b6"], "text": "Loop agents \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.2.0 The LoopAgent is a workflow agent that executes its sub-agents in a loop (i.e. iteratively). It repeatedly runs a sequence of agents for a specified number of iterations or until a termination condition is met. Use the LoopAgent when your workflow involves repetition or iterative refinement, such as revising code. ", "code_blocks": []}, {"heading_path": ["Example\u00b6"], "text": "Example \u00b6 You want to build an agent that can generate images of food, but sometimes when you want to generate a specific number of items (e.g. 5 bananas), it generates a different number of those items in the image (e.g. an image of 7 bananas). You have two tools: Generate Image , Count Food Items . Because you want to keep generating images until it either correctly generates the specified number of items, or after a certain number of iterations, you should build your agent using a LoopAgent . As with other workflow agents , the LoopAgent is not powered by an LLM, and is thus deterministic in how it executes. That being said, workflow agents are only concerned only with their execution (i.e. in a loop), and not their internal logic; the tools or sub-agents of a workflow agent may or may not utilize LLMs. ", "code_blocks": []}, {"heading_path": ["How it Works\u00b6"], "text": "How it Works \u00b6 When the LoopAgent 's Run Async method is called, it performs the following actions: Sub-Agent Execution: It iterates through the Sub Agents list in order . For each sub-agent, it calls the agent's Run Async method. Termination Check: Crucially , the LoopAgent itself does not inherently decide when to stop looping. You must implement a termination mechanism to prevent infinite loops.  Common strategies include: Max Iterations : Set a maximum number of iterations in the LoopAgent . The loop will terminate after that many iterations . Escalation from sub-agent : Design one or more sub-agents to evaluate a condition (e.g., \"Is the document quality good enough?\", \"Has a consensus been reached?\").  If the condition is met, the sub-agent can signal termination (e.g., by raising a custom event, setting a flag in a shared context, or returning a specific value). ", "code_blocks": []}, {"heading_path": ["Full Example: Iterative Document Improvement\u00b6"], "text": "Full Example: Iterative Document Improvement \u00b6 Imagine a scenario where you want to iteratively improve a document: Writer Agent: An LlmAgent that generates or refines a draft on a topic. Critic Agent: An LlmAgent that critiques the draft, identifying areas for improvement. LoopAgent ( sub_agents = [ WriterAgent , CriticAgent ], max_iterations = 5 ) In this setup, the LoopAgent would manage the iterative process.  The CriticAgent could be designed to return a \"STOP\" signal when the document reaches a satisfactory quality level , preventing further iterations. Alternatively, the max iterations parameter could be used to limit the process to a fixed number of cycles, or external logic could be implemented to make stop decisions. The loop would run at most five times , ensuring the iterative refinement doesn't continue indefinitely. Full Code Python Go Java # Part of agent.py --> Follow https://google.github.io/adk-docs/get-started/quickstart/ to learn the setup import asyncio import os from google.adk.agents import LoopAgent , LlmAgent , BaseAgent , SequentialAgent from google.genai import types from google.adk.runners import InMemoryRunner from google.adk.agents.invocation_context import InvocationContext from google.adk.tools.tool_context import ToolContext from typing import AsyncGenerator , Optional from google.adk.events import Event , EventActions # --- Constants --- APP_NAME = \"doc_writing_app_v3\" # New App Name USER_ID = \"dev_user_01\" SESSION_ID_BASE = \"loop_exit_tool_session\" # New Base Session ID GEMINI_MODEL = \"gemini-2.0-flash\" STATE_INITIAL_TOPIC = \"initial_topic\" # --- State Keys --- STATE_CURRENT_DOC = \"current_document\" STATE_CRITICISM = \"criticism\" # Define the exact phrase the Critic should use to signal completion COMPLETION_PHRASE = \"No major issues found.\" # --- Tool Definition --- def exit_loop ( tool_context : ToolContext ): \"\"\"Call this function ONLY when the critique indicates no further changes are needed, signaling the iterative process should end.\"\"\" print ( f \"  [Tool Call] exit_loop triggered by { tool_context . agent_name } \" ) tool_context . actions . escalate = True # Return empty dict as tools should typically return JSON-serializable output return {} # --- Agent Definitions --- # STEP 1: Initial Writer Agent (Runs ONCE at the beginning) initial_writer_agent = LlmAgent ( name = \"InitialWriterAgent\" , model = GEMINI_MODEL , include_contents = 'none' , # MODIFIED Instruction: Ask for a slightly more developed start instruction = f \"\"\"You are a Creative Writing Assistant tasked with starting a story. Write the *first draft* of a short story (aim for 2-4 sentences). Base the content *only* on the topic provided below. Try to introduce a specific element (like a character, a setting detail, or a starting action) to make it engaging. Topic: {{ initial_topic }} Output *only* the story/document text. Do not add introductions or explanations. \"\"\" , description = \"Writes the initial document draft based on the topic, aiming for some initial substance.\" , output_key = STATE_CURRENT_DOC ) # STEP 2a: Critic Agent (Inside the Refinement Loop) critic_agent_in_loop = LlmAgent ( name = \"CriticAgent\" , model = GEMINI_MODEL , include_contents = 'none' , # MODIFIED Instruction: More nuanced completion criteria, look for clear improvement paths. instruction = f \"\"\"You are a Constructive Critic AI reviewing a short document draft (typically 2-6 sentences). Your goal is balanced feedback. **Document to Review:** ``` {{ current_document }} ``` **Task:** Review the document for clarity, engagement, and basic coherence according to the initial topic (if known). IF you identify 1-2 *clear and actionable* ways the document could be improved to better capture the topic or enhance reader engagement (e.g., \"Needs a stronger opening sentence\", \"Clarify the character's goal\"): Provide these specific suggestions concisely. Output *only* the critique text. ELSE IF the document is coherent, addresses the topic adequately for its length, and has no glaring errors or obvious omissions: Respond *exactly* with the phrase \" { COMPLETION_PHRASE } \" and nothing else. It doesn't need to be perfect, just functionally complete for this stage. Avoid suggesting purely subjective stylistic preferences if the core is sound. Do not add explanations. Output only the critique OR the exact completion phrase. \"\"\" , description = \"Reviews the current draft, providing critique if clear improvements are needed, otherwise signals completion.\" , output_key = STATE_CRITICISM ) # STEP 2b: Refiner/Exiter Agent (Inside the Refinement Loop) refiner_agent_in_loop = LlmAgent ( name = \"RefinerAgent\" , model = GEMINI_MODEL , # Relies solely on state via placeholders include_contents = 'none' , instruction = f \"\"\"You are a Creative Writing Assistant refining a document based on feedback OR exiting the process. **Current Document:** ``` {{ current_document }} ``` **Critique/Suggestions:** {{ criticism }} **Task:** Analyze the 'Critique/Suggestions'. IF the critique is *exactly* \" { COMPLETION_PHRASE } \": You MUST call the 'exit_loop' function. Do not output any text. ELSE (the critique contains actionable feedback): Carefully apply the suggestions to improve the 'Current Document'. Output *only* the refined document text. Do not add explanations. Either output the refined document OR call the exit_loop function. \"\"\" , description = \"Refines the document based on critique, or calls exit_loop if critique indicates completion.\" , tools = [ exit_loop ], # Provide the exit_loop tool output_key = STATE_CURRENT_DOC # Overwrites state['current_document'] with the refined version ) # STEP 2: Refinement Loop Agent refinement_loop = LoopAgent ( name = \"RefinementLoop\" , # Agent order is crucial: Critique first, then Refine/Exit sub_agents = [ critic_agent_in_loop , refiner_agent_in_loop , ], max_iterations = 5 # Limit loops ) # STEP 3: Overall Sequential Pipeline # For ADK tools compatibility, the root agent must be named `root_agent` root_agent = SequentialAgent ( name = \"IterativeWritingPipeline\" , sub_agents = [ initial_writer_agent , # Run first to create initial doc refinement_loop # Then run the critique/refine loop ], description = \"Writes an initial document and then iteratively refines it with critique using an exit tool.\" ) // ExitLoopArgs defines the (empty) arguments for the ExitLoop tool. type ExitLoopArgs struct {} // ExitLoopResults defines the output of the ExitLoop tool. type ExitLoopResults struct {} // ExitLoop is a tool that signals the loop to terminate by setting Escalate to true. func ExitLoop ( ctx tool . Context , input ExitLoopArgs ) ExitLoopResults { fmt . Printf ( \"[Tool Call] exitLoop triggered by %s \\n\" , ctx . AgentName ()) ctx . Actions (). Escalate = true return ExitLoopResults {} } func main () { ctx := context . Background () if err := runAgent ( ctx , \"Write a document about a cat\" ); err != nil { log . Fatalf ( \"Agent execution failed: %v\" , err ) } } func runAgent ( ctx context . Context , prompt string ) error { model , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { return fmt . Errorf ( \"failed to create model: %v\" , err ) } // STEP 1: Initial Writer Agent (Runs ONCE at the beginning) initialWriterAgent , err := llmagent . New ( llmagent . Config { Name : \"InitialWriterAgent\" , Model : model , Description : \"Writes the initial document draft based on the topic.\" , Instruction : `You are a Creative Writing Assistant tasked with starting a story. Write the *first draft* of a short story (aim for 2-4 sentences). Base the content *only* on the topic provided in the user's prompt. Output *only* the story/document text. Do not add introductions or explanations.` , OutputKey : stateDoc , }) if err != nil { return fmt . Errorf ( \"failed to create initial writer agent: %v\" , err ) } // STEP 2a: Critic Agent (Inside the Refinement Loop) criticAgentInLoop , err := llmagent . New ( llmagent . Config { Name : \"CriticAgent\" , Model : model , Description : \"Reviews the current draft, providing critique or signaling completion.\" , Instruction : fmt . Sprintf ( `You are a Constructive Critic AI reviewing a short document draft. **Document to Review:** \"\"\" {%s} \"\"\" **Task:** Review the document. IF you identify 1-2 *clear and actionable* ways it could be improved: Provide these specific suggestions concisely. Output *only* the critique text. ELSE IF the document is coherent and addresses the topic adequately: Respond *exactly* with the phrase \"%s\" and nothing else.` , stateDoc , donePhrase ), OutputKey : stateCrit , }) if err != nil { return fmt . Errorf ( \"failed to create critic agent: %v\" , err ) } exitLoopTool , err := functiontool . New ( functiontool . Config { Name : \"exitLoop\" , Description : \"Call this function ONLY when the critique indicates no further changes are needed.\" , }, ExitLoop , ) if err != nil { return fmt . Errorf ( \"failed to create exit loop tool: %v\" , err ) } // STEP 2b: Refiner/Exiter Agent (Inside the Refinement Loop) refinerAgentInLoop , err := llmagent . New ( llmagent . Config { Name : \"RefinerAgent\" , Model : model , Instruction : fmt . Sprintf ( `You are a Creative Writing Assistant refining a document based on feedback OR exiting the process. **Current Document:** \"\"\" {%s} \"\"\" **Critique/Suggestions:** {%s} **Task:** Analyze the 'Critique/Suggestions'. IF the critique is *exactly* \"%s\": You MUST call the 'exitLoop' function. Do not output any text. ELSE (the critique contains actionable feedback): Carefully apply the suggestions to improve the 'Current Document'. Output *only* the refined document text.` , stateDoc , stateCrit , donePhrase ), Description : \"Refines the document based on critique, or calls exitLoop if critique indicates completion.\" , Tools : [] tool . Tool { exitLoopTool }, OutputKey : stateDoc , }) if err != nil { return fmt . Errorf ( \"failed to create refiner agent: %v\" , err ) } // STEP 2: Refinement Loop Agent refinementLoop , err := loopagent . New ( loopagent . Config { AgentConfig : agent . Config { Name : \"RefinementLoop\" , SubAgents : [] agent . Agent { criticAgentInLoop , refinerAgentInLoop }, }, MaxIterations : 5 , }) if err != nil { return fmt . Errorf ( \"failed to create loop agent: %v\" , err ) } // STEP 3: Overall Sequential Pipeline iterativeWriterAgent , err := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : appName , SubAgents : [] agent . Agent { initialWriterAgent , refinementLoop }, }, }) if err != nil { return fmt . Errorf ( \"failed to create sequential agent pipeline: %v\" , err ) } import static com.google.adk.agents.LlmAgent.IncludeContents.NONE ; import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.LoopAgent ; import com.google.adk.agents.SequentialAgent ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.adk.tools.Annotations.Schema ; import com.google.adk.tools.FunctionTool ; import com.google.adk.tools.ToolContext ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import java.util.Map ; public class LoopAgentExample { // --- Constants --- private static final String APP_NAME = \"IterativeWritingPipeline\" ; private static final String USER_ID = \"test_user_456\" ; private static final String MODEL_NAME = \"gemini-2.0-flash\" ; // --- State Keys --- private static final String STATE_CURRENT_DOC = \"current_document\" ; private static final String STATE_CRITICISM = \"criticism\" ; public static void main ( String [] args ) { LoopAgentExample loopAgentExample = new LoopAgentExample (); loopAgentExample . runAgent ( \"Write a document about a cat\" ); } // --- Tool Definition --- @Schema ( description = \"Call this function ONLY when the critique indicates no further changes are needed,\" + \" signaling the iterative process should end.\" ) public static Map < String , Object > exitLoop ( @Schema ( name = \"toolContext\" ) ToolContext toolContext ) { System . out . printf ( \"[Tool Call] exitLoop triggered by %s \\n\" , toolContext . agentName ()); toolContext . actions (). setEscalate ( true ); //  Return empty dict as tools should typically return JSON-serializable output return Map . of (); } // --- Agent Definitions --- public void runAgent ( String prompt ) { // STEP 1: Initial Writer Agent (Runs ONCE at the beginning) LlmAgent initialWriterAgent = LlmAgent . builder () . model ( MODEL_NAME ) . name ( \"InitialWriterAgent\" ) . description ( \"Writes the initial document draft based on the topic, aiming for some initial\" + \" substance.\" ) . instruction ( \"\"\" You are a Creative Writing Assistant tasked with starting a story. Write the *first draft* of a short story (aim for 2-4 sentences). Base the content *only* on the topic provided below. Try to introduce a specific element (like a character, a setting detail, or a starting action) to make it engaging. Output *only* the story/document text. Do not add introductions or explanations. \"\"\" ) . outputKey ( STATE_CURRENT_DOC ) . includeContents ( NONE ) . build (); // STEP 2a: Critic Agent (Inside the Refinement Loop) LlmAgent criticAgentInLoop = LlmAgent . builder () . model ( MODEL_NAME ) . name ( \"CriticAgent\" ) . description ( \"Reviews the current draft, providing critique if clear improvements are needed,\" + \" otherwise signals completion.\" ) . instruction ( \"\"\" You are a Constructive Critic AI reviewing a short document draft (typically 2-6 sentences). Your goal is balanced feedback. **Document to Review:** ``` {{current_document}} ``` **Task:** Review the document for clarity, engagement, and basic coherence according to the initial topic (if known). IF you identify 1-2 *clear and actionable* ways the document could be improved to better capture the topic or enhance reader engagement (e.g., \"Needs a stronger opening sentence\", \"Clarify the character's goal\"): Provide these specific suggestions concisely. Output *only* the critique text. ELSE IF the document is coherent, addresses the topic adequately for its length, and has no glaring errors or obvious omissions: Respond *exactly* with the phrase \"No major issues found.\" and nothing else. It doesn't need to be perfect, just functionally complete for this stage. Avoid suggesting purely subjective stylistic preferences if the core is sound. Do not add explanations. Output only the critique OR the exact completion phrase. \"\"\" ) . outputKey ( STATE_CRITICISM ) . includeContents ( NONE ) . build (); // STEP 2b: Refiner/Exiter Agent (Inside the Refinement Loop) LlmAgent refinerAgentInLoop = LlmAgent . builder () . model ( MODEL_NAME ) . name ( \"RefinerAgent\" ) . description ( \"Refines the document based on critique, or calls exitLoop if critique indicates\" + \" completion.\" ) . instruction ( \"\"\" You are a Creative Writing Assistant refining a document based on feedback OR exiting the process. **Current Document:** ``` {{current_document}} ``` **Critique/Suggestions:** {{criticism}} **Task:** Analyze the 'Critique/Suggestions'. IF the critique is *exactly* \"No major issues found.\": You MUST call the 'exitLoop' function. Do not output any text. ELSE (the critique contains actionable feedback): Carefully apply the suggestions to improve the 'Current Document'. Output *only* the refined document text. Do not add explanations. Either output the refined document OR call the exitLoop function. \"\"\" ) . outputKey ( STATE_CURRENT_DOC ) . includeContents ( NONE ) . tools ( FunctionTool . create ( LoopAgentExample . class , \"exitLoop\" )) . build (); // STEP 2: Refinement Loop Agent LoopAgent refinementLoop = LoopAgent . builder () . name ( \"RefinementLoop\" ) . description ( \"Repeatedly refines the document with critique and then exits.\" ) . subAgents ( criticAgentInLoop , refinerAgentInLoop ) . maxIterations ( 5 ) . build (); // STEP 3: Overall Sequential Pipeline SequentialAgent iterativeWriterAgent = SequentialAgent . builder () . name ( APP_NAME ) . description ( \"Writes an initial document and then iteratively refines it with critique using an\" + \" exit tool.\" ) . subAgents ( initialWriterAgent , refinementLoop ) . build (); // Create an InMemoryRunner InMemoryRunner runner = new InMemoryRunner ( iterativeWriterAgent , APP_NAME ); // InMemoryRunner automatically creates a session service. Create a session using the service Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( prompt )); // Run the agent Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } } Back to top ", "code_blocks": [{"language": "text", "code": "LoopAgent(sub_agents=[WriterAgent, CriticAgent], max_iterations=5)"}, {"language": "text", "code": "# Part of agent.py --> Follow https://google.github.io/adk-docs/get-started/quickstart/ to learn the setup\n\nimport asyncio\nimport os\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent, SequentialAgent\nfrom google.genai import types\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.agents.invocation_context import InvocationContext\nfrom google.adk.tools.tool_context import ToolContext\nfrom typing import AsyncGenerator, Optional\nfrom google.adk.events import Event, EventActions\n\n# --- Constants ---\nAPP_NAME = \"doc_writing_app_v3\" # New App Name\nUSER_ID = \"dev_user_01\"\nSESSION_ID_BASE = \"loop_exit_tool_session\" # New Base Session ID\nGEMINI_MODEL = \"gemini-2.0-flash\"\nSTATE_INITIAL_TOPIC = \"initial_topic\"\n\n# --- State Keys ---\nSTATE_CURRENT_DOC = \"current_document\"\nSTATE_CRITICISM = \"criticism\"\n# Define the exact phrase the Critic should use to signal completion\nCOMPLETION_PHRASE = \"No major issues found.\"\n\n# --- Tool Definition ---\ndef exit_loop(tool_context: ToolContext):\n  \"\"\"Call this function ONLY when the critique indicates no further changes are needed, signaling the iterative process should end.\"\"\"\n  print(f\"  [Tool Call] exit_loop triggered by {tool_context.agent_name}\")\n  tool_context.actions.escalate = True\n  # Return empty dict as tools should typically return JSON-serializable output\n  return {}\n\n# --- Agent Definitions ---\n\n# STEP 1: Initial Writer Agent (Runs ONCE at the beginning)\ninitial_writer_agent = LlmAgent(\n    name=\"InitialWriterAgent\",\n    model=GEMINI_MODEL,\n    include_contents='none',\n    # MODIFIED Instruction: Ask for a slightly more developed start\n    instruction=f\"\"\"You are a Creative Writing Assistant tasked with starting a story.\n    Write the *first draft* of a short story (aim for 2-4 sentences).\n    Base the content *only* on the topic provided below. Try to introduce a specific element (like a character, a setting detail, or a starting action) to make it engaging.\n    Topic: {{initial_topic}}\n\n    Output *only* the story/document text. Do not add introductions or explanations.\n\"\"\",\n    description=\"Writes the initial document draft based on the topic, aiming for some initial substance.\",\n    output_key=STATE_CURRENT_DOC\n)\n\n# STEP 2a: Critic Agent (Inside the Refinement Loop)\ncritic_agent_in_loop = LlmAgent(\n    name=\"CriticAgent\",\n    model=GEMINI_MODEL,\n    include_contents='none',\n    # MODIFIED Instruction: More nuanced completion criteria, look for clear improvement paths.\n    instruction=f\"\"\"You are a Constructive Critic AI reviewing a short document draft (typically 2-6 sentences). Your goal is balanced feedback.\n\n    **Document to Review:**\n    ```\n    {{current_document}}\n    ```\n\n    **Task:**\n    Review the document for clarity, engagement, and basic coherence according to the initial topic (if known).\n\n    IF you identify 1-2 *clear and actionable* ways the document could be improved to better capture the topic or enhance reader engagement (e.g., \"Needs a stronger opening sentence\", \"Clarify the character's goal\"):\n    Provide these specific suggestions concisely. Output *only* the critique text.\n\n    ELSE IF the document is coherent, addresses the topic adequately for its length, and has no glaring errors or obvious omissions:\n    Respond *exactly* with the phrase \"{COMPLETION_PHRASE}\" and nothing else. It doesn't need to be perfect, just functionally complete for this stage. Avoid suggesting purely subjective stylistic preferences if the core is sound.\n\n    Do not add explanations. Output only the critique OR the exact completion phrase.\n\"\"\",\n    description=\"Reviews the current draft, providing critique if clear improvements are needed, otherwise signals completion.\",\n    output_key=STATE_CRITICISM\n)\n\n\n# STEP 2b: Refiner/Exiter Agent (Inside the Refinement Loop)\nrefiner_agent_in_loop = LlmAgent(\n    name=\"RefinerAgent\",\n    model=GEMINI_MODEL,\n    # Relies solely on state via placeholders\n    include_contents='none',\n    instruction=f\"\"\"You are a Creative Writing Assistant refining a document based on feedback OR exiting the process.\n    **Current Document:**\n    ```\n    {{current_document}}\n    ```\n    **Critique/Suggestions:**\n    {{criticism}}\n\n    **Task:**\n    Analyze the 'Critique/Suggestions'.\n    IF the critique is *exactly* \"{COMPLETION_PHRASE}\":\n    You MUST call the 'exit_loop' function. Do not output any text.\n    ELSE (the critique contains actionable feedback):\n    Carefully apply the suggestions to improve the 'Current Document'. Output *only* the refined document text.\n\n    Do not add explanations. Either output the refined document OR call the exit_loop function.\n\"\"\",\n    description=\"Refines the document based on critique, or calls exit_loop if critique indicates completion.\",\n    tools=[exit_loop], # Provide the exit_loop tool\n    output_key=STATE_CURRENT_DOC # Overwrites state['current_document'] with the refined version\n)\n\n\n# STEP 2: Refinement Loop Agent\nrefinement_loop = LoopAgent(\n    name=\"RefinementLoop\",\n    # Agent order is crucial: Critique first, then Refine/Exit\n    sub_agents=[\n        critic_agent_in_loop,\n        refiner_agent_in_loop,\n    ],\n    max_iterations=5 # Limit loops\n)\n\n# STEP 3: Overall Sequential Pipeline\n# For ADK tools compatibility, the root agent must be named `root_agent`\nroot_agent = SequentialAgent(\n    name=\"IterativeWritingPipeline\",\n    sub_agents=[\n        initial_writer_agent, # Run first to create initial doc\n        refinement_loop       # Then run the critique/refine loop\n    ],\n    description=\"Writes an initial document and then iteratively refines it with critique using an exit tool.\"\n)"}, {"language": "text", "code": "// ExitLoopArgs defines the (empty) arguments for the ExitLoop tool.\ntype ExitLoopArgs struct{}\n\n// ExitLoopResults defines the output of the ExitLoop tool.\ntype ExitLoopResults struct{}\n\n// ExitLoop is a tool that signals the loop to terminate by setting Escalate to true.\nfunc ExitLoop(ctx tool.Context, input ExitLoopArgs) ExitLoopResults {\n    fmt.Printf(\"[Tool Call] exitLoop triggered by %s \\n\", ctx.AgentName())\n    ctx.Actions().Escalate = true\n    return ExitLoopResults{}\n}\n\nfunc main() {\n    ctx := context.Background()\n\n    if err := runAgent(ctx, \"Write a document about a cat\"); err != nil {\n        log.Fatalf(\"Agent execution failed: %v\", err)\n    }\n}\n\nfunc runAgent(ctx context.Context, prompt string) error {\n    model, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        return fmt.Errorf(\"failed to create model: %v\", err)\n    }\n\n    // STEP 1: Initial Writer Agent (Runs ONCE at the beginning)\n    initialWriterAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"InitialWriterAgent\",\n        Model:       model,\n        Description: \"Writes the initial document draft based on the topic.\",\n        Instruction: `You are a Creative Writing Assistant tasked with starting a story.\nWrite the *first draft* of a short story (aim for 2-4 sentences).\nBase the content *only* on the topic provided in the user's prompt.\nOutput *only* the story/document text. Do not add introductions or explanations.`,\n        OutputKey: stateDoc,\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create initial writer agent: %v\", err)\n    }\n\n    // STEP 2a: Critic Agent (Inside the Refinement Loop)\n    criticAgentInLoop, err := llmagent.New(llmagent.Config{\n        Name:        \"CriticAgent\",\n        Model:       model,\n        Description: \"Reviews the current draft, providing critique or signaling completion.\",\n        Instruction: fmt.Sprintf(`You are a Constructive Critic AI reviewing a short document draft.\n**Document to Review:**\n\"\"\"\n{%s}\n\"\"\"\n**Task:**\nReview the document.\nIF you identify 1-2 *clear and actionable* ways it could be improved:\nProvide these specific suggestions concisely. Output *only* the critique text.\nELSE IF the document is coherent and addresses the topic adequately:\nRespond *exactly* with the phrase \"%s\" and nothing else.`, stateDoc, donePhrase),\n        OutputKey: stateCrit,\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create critic agent: %v\", err)\n    }\n\n    exitLoopTool, err := functiontool.New(\n        functiontool.Config{\n            Name:        \"exitLoop\",\n            Description: \"Call this function ONLY when the critique indicates no further changes are needed.\",\n        },\n        ExitLoop,\n    )\n    if err != nil {\n        return fmt.Errorf(\"failed to create exit loop tool: %v\", err)\n    }\n\n    // STEP 2b: Refiner/Exiter Agent (Inside the Refinement Loop)\n    refinerAgentInLoop, err := llmagent.New(llmagent.Config{\n        Name:  \"RefinerAgent\",\n        Model: model,\n        Instruction: fmt.Sprintf(`You are a Creative Writing Assistant refining a document based on feedback OR exiting the process.\n**Current Document:**\n\n\"\"\"\n{%s}\n\"\"\"\n\n**Critique/Suggestions:**\n{%s}\n**Task:**\nAnalyze the 'Critique/Suggestions'.\nIF the critique is *exactly* \"%s\":\nYou MUST call the 'exitLoop' function. Do not output any text.\nELSE (the critique contains actionable feedback):\nCarefully apply the suggestions to improve the 'Current Document'. Output *only* the refined document text.`, stateDoc, stateCrit, donePhrase),\n        Description: \"Refines the document based on critique, or calls exitLoop if critique indicates completion.\",\n        Tools:       []tool.Tool{exitLoopTool},\n        OutputKey:   stateDoc,\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create refiner agent: %v\", err)\n    }\n\n    // STEP 2: Refinement Loop Agent\n    refinementLoop, err := loopagent.New(loopagent.Config{\n        AgentConfig: agent.Config{\n            Name:      \"RefinementLoop\",\n            SubAgents: []agent.Agent{criticAgentInLoop, refinerAgentInLoop},\n        },\n        MaxIterations: 5,\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create loop agent: %v\", err)\n    }\n\n    // STEP 3: Overall Sequential Pipeline\n    iterativeWriterAgent, err := sequentialagent.New(sequentialagent.Config{\n        AgentConfig: agent.Config{\n            Name:      appName,\n            SubAgents: []agent.Agent{initialWriterAgent, refinementLoop},\n        },\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create sequential agent pipeline: %v\", err)\n    }"}, {"language": "text", "code": "import static com.google.adk.agents.LlmAgent.IncludeContents.NONE;\n\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.LoopAgent;\nimport com.google.adk.agents.SequentialAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.Annotations.Schema;\nimport com.google.adk.tools.FunctionTool;\nimport com.google.adk.tools.ToolContext;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport java.util.Map;\n\npublic class LoopAgentExample {\n\n  // --- Constants ---\n  private static final String APP_NAME = \"IterativeWritingPipeline\";\n  private static final String USER_ID = \"test_user_456\";\n  private static final String MODEL_NAME = \"gemini-2.0-flash\";\n\n  // --- State Keys ---\n  private static final String STATE_CURRENT_DOC = \"current_document\";\n  private static final String STATE_CRITICISM = \"criticism\";\n\n  public static void main(String[] args) {\n    LoopAgentExample loopAgentExample = new LoopAgentExample();\n    loopAgentExample.runAgent(\"Write a document about a cat\");\n  }\n\n  // --- Tool Definition ---\n  @Schema(\n      description =\n          \"Call this function ONLY when the critique indicates no further changes are needed,\"\n              + \" signaling the iterative process should end.\")\n  public static Map<String, Object> exitLoop(@Schema(name = \"toolContext\") ToolContext toolContext) {\n    System.out.printf(\"[Tool Call] exitLoop triggered by %s \\n\", toolContext.agentName());\n    toolContext.actions().setEscalate(true);\n    //  Return empty dict as tools should typically return JSON-serializable output\n    return Map.of();\n  }\n\n  // --- Agent Definitions ---\n  public void runAgent(String prompt) {\n    // STEP 1: Initial Writer Agent (Runs ONCE at the beginning)\n    LlmAgent initialWriterAgent =\n        LlmAgent.builder()\n            .model(MODEL_NAME)\n            .name(\"InitialWriterAgent\")\n            .description(\n                \"Writes the initial document draft based on the topic, aiming for some initial\"\n                    + \" substance.\")\n            .instruction(\n                \"\"\"\n                    You are a Creative Writing Assistant tasked with starting a story.\n                    Write the *first draft* of a short story (aim for 2-4 sentences).\n                    Base the content *only* on the topic provided below. Try to introduce a specific element (like a character, a setting detail, or a starting action) to make it engaging.\n\n                    Output *only* the story/document text. Do not add introductions or explanations.\n                \"\"\")\n            .outputKey(STATE_CURRENT_DOC)\n            .includeContents(NONE)\n            .build();\n\n    // STEP 2a: Critic Agent (Inside the Refinement Loop)\n    LlmAgent criticAgentInLoop =\n        LlmAgent.builder()\n            .model(MODEL_NAME)\n            .name(\"CriticAgent\")\n            .description(\n                \"Reviews the current draft, providing critique if clear improvements are needed,\"\n                    + \" otherwise signals completion.\")\n            .instruction(\n                \"\"\"\n                    You are a Constructive Critic AI reviewing a short document draft (typically 2-6 sentences). Your goal is balanced feedback.\n\n                    **Document to Review:**\n                    ```\n                    {{current_document}}\n                    ```\n\n                    **Task:**\n                    Review the document for clarity, engagement, and basic coherence according to the initial topic (if known).\n\n                    IF you identify 1-2 *clear and actionable* ways the document could be improved to better capture the topic or enhance reader engagement (e.g., \"Needs a stronger opening sentence\", \"Clarify the character's goal\"):\n                    Provide these specific suggestions concisely. Output *only* the critique text.\n\n                    ELSE IF the document is coherent, addresses the topic adequately for its length, and has no glaring errors or obvious omissions:\n                    Respond *exactly* with the phrase \"No major issues found.\" and nothing else. It doesn't need to be perfect, just functionally complete for this stage. Avoid suggesting purely subjective stylistic preferences if the core is sound.\n\n                    Do not add explanations. Output only the critique OR the exact completion phrase.\n                    \"\"\")\n            .outputKey(STATE_CRITICISM)\n            .includeContents(NONE)\n            .build();\n\n    // STEP 2b: Refiner/Exiter Agent (Inside the Refinement Loop)\n    LlmAgent refinerAgentInLoop =\n        LlmAgent.builder()\n            .model(MODEL_NAME)\n            .name(\"RefinerAgent\")\n            .description(\n                \"Refines the document based on critique, or calls exitLoop if critique indicates\"\n                    + \" completion.\")\n            .instruction(\n                \"\"\"\n                    You are a Creative Writing Assistant refining a document based on feedback OR exiting the process.\n                    **Current Document:**\n                    ```\n                    {{current_document}}\n                    ```\n                    **Critique/Suggestions:**\n                    {{criticism}}\n\n                    **Task:**\n                    Analyze the 'Critique/Suggestions'.\n                    IF the critique is *exactly* \"No major issues found.\":\n                    You MUST call the 'exitLoop' function. Do not output any text.\n                    ELSE (the critique contains actionable feedback):\n                    Carefully apply the suggestions to improve the 'Current Document'. Output *only* the refined document text.\n\n                    Do not add explanations. Either output the refined document OR call the exitLoop function.\n                \"\"\")\n            .outputKey(STATE_CURRENT_DOC)\n            .includeContents(NONE)\n            .tools(FunctionTool.create(LoopAgentExample.class, \"exitLoop\"))\n            .build();\n\n    // STEP 2: Refinement Loop Agent\n    LoopAgent refinementLoop =\n        LoopAgent.builder()\n            .name(\"RefinementLoop\")\n            .description(\"Repeatedly refines the document with critique and then exits.\")\n            .subAgents(criticAgentInLoop, refinerAgentInLoop)\n            .maxIterations(5)\n            .build();\n\n    // STEP 3: Overall Sequential Pipeline\n    SequentialAgent iterativeWriterAgent =\n        SequentialAgent.builder()\n            .name(APP_NAME)\n            .description(\n                \"Writes an initial document and then iteratively refines it with critique using an\"\n                    + \" exit tool.\")\n            .subAgents(initialWriterAgent, refinementLoop)\n            .build();\n\n    // Create an InMemoryRunner\n    InMemoryRunner runner = new InMemoryRunner(iterativeWriterAgent, APP_NAME);\n    // InMemoryRunner automatically creates a session service. Create a session using the service\n    Session session = runner.sessionService().createSession(APP_NAME, USER_ID).blockingGet();\n    Content userMessage = Content.fromParts(Part.fromText(prompt));\n\n    // Run the agent\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n    // Stream event response\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n}"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:06.505935", "source_type": "adk-docs"}
{"doc_id": "06d314f92d47691150df654db596088ffdbed85e7b1fc56c5717de92561a8829", "url": "https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents", "title": "Parallel agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Parallel agents\u00b6"], "text": "Parallel agents \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.2.0 The ParallelAgent is a workflow agent that executes its sub-agents concurrently . This dramatically speeds up workflows where tasks can be performed independently. Use ParallelAgent when: For scenarios prioritizing speed and involving independent, resource-intensive tasks, a ParallelAgent facilitates efficient parallel execution. When sub-agents operate without dependencies, their tasks can be performed concurrently , significantly reducing overall processing time. As with other workflow agents , the ParallelAgent is not powered by an LLM, and is thus deterministic in how it executes. That being said, workflow agents are only concerned with their execution (i.e. executing sub-agents in parallel), and not their internal logic; the tools or sub-agents of a workflow agent may or may not utilize LLMs. ", "code_blocks": []}, {"heading_path": ["Example\u00b6"], "text": "Example \u00b6 This approach is particularly beneficial for operations like multi-source data retrieval or heavy computations, where parallelization yields substantial performance gains. Importantly, this strategy assumes no inherent need for shared state or direct information exchange between the concurrently executing agents. ", "code_blocks": []}, {"heading_path": ["How it works\u00b6"], "text": "How it works \u00b6 When the ParallelAgent 's run_async() method is called: Concurrent Execution: It initiates the run_async() method of each sub-agent present in the sub_agents list concurrently .  This means all the agents start running at (approximately) the same time. Independent Branches: Each sub-agent operates in its own execution branch.  There is no automatic sharing of conversation history or state between these branches during execution. Result Collection: The ParallelAgent manages the parallel execution and, typically, provides a way to access the results from each sub-agent after they have completed (e.g., through a list of results or events). The order of results may not be deterministic. ", "code_blocks": []}, {"heading_path": ["Independent Execution and State Management\u00b6"], "text": "Independent Execution and State Management \u00b6 It's crucial to understand that sub-agents within a ParallelAgent run independently.  If you need communication or data sharing between these agents, you must implement it explicitly.  Possible approaches include: Shared InvocationContext : You could pass a shared InvocationContext object to each sub-agent.  This object could act as a shared data store.  However, you'd need to manage concurrent access to this shared context carefully (e.g., using locks) to avoid race conditions. External State Management: Use an external database, message queue, or other mechanism to manage shared state and facilitate communication between agents. Post-Processing: Collect results from each branch, and then implement logic to coordinate data afterwards. ", "code_blocks": []}, {"heading_path": ["Full Example: Parallel Web Research\u00b6"], "text": "Full Example: Parallel Web Research \u00b6 Imagine researching multiple topics simultaneously: Researcher Agent 1: An LlmAgent that researches \"renewable energy sources.\" Researcher Agent 2: An LlmAgent that researches \"electric vehicle technology.\" Researcher Agent 3: An LlmAgent that researches \"carbon capture methods.\" ParallelAgent ( sub_agents = [ ResearcherAgent1 , ResearcherAgent2 , ResearcherAgent3 ]) These research tasks are independent.  Using a ParallelAgent allows them to run concurrently, potentially reducing the total research time significantly compared to running them sequentially. The results from each agent would be collected separately after they finish. Full Code Python Go Java # Part of agent.py --> Follow https://google.github.io/adk-docs/get-started/quickstart/ to learn the setup # --- 1. Define Researcher Sub-Agents (to run in parallel) --- # Researcher 1: Renewable Energy researcher_agent_1 = LlmAgent ( name = \"RenewableEnergyResearcher\" , model = GEMINI_MODEL , instruction = \"\"\"You are an AI Research Assistant specializing in energy. Research the latest advancements in 'renewable energy sources'. Use the Google Search tool provided. Summarize your key findings concisely (1-2 sentences). Output *only* the summary. \"\"\" , description = \"Researches renewable energy sources.\" , tools = [ google_search ], # Store result in state for the merger agent output_key = \"renewable_energy_result\" ) # Researcher 2: Electric Vehicles researcher_agent_2 = LlmAgent ( name = \"EVResearcher\" , model = GEMINI_MODEL , instruction = \"\"\"You are an AI Research Assistant specializing in transportation. Research the latest developments in 'electric vehicle technology'. Use the Google Search tool provided. Summarize your key findings concisely (1-2 sentences). Output *only* the summary. \"\"\" , description = \"Researches electric vehicle technology.\" , tools = [ google_search ], # Store result in state for the merger agent output_key = \"ev_technology_result\" ) # Researcher 3: Carbon Capture researcher_agent_3 = LlmAgent ( name = \"CarbonCaptureResearcher\" , model = GEMINI_MODEL , instruction = \"\"\"You are an AI Research Assistant specializing in climate solutions. Research the current state of 'carbon capture methods'. Use the Google Search tool provided. Summarize your key findings concisely (1-2 sentences). Output *only* the summary. \"\"\" , description = \"Researches carbon capture methods.\" , tools = [ google_search ], # Store result in state for the merger agent output_key = \"carbon_capture_result\" ) # --- 2. Create the ParallelAgent (Runs researchers concurrently) --- # This agent orchestrates the concurrent execution of the researchers. # It finishes once all researchers have completed and stored their results in state. parallel_research_agent = ParallelAgent ( name = \"ParallelWebResearchAgent\" , sub_agents = [ researcher_agent_1 , researcher_agent_2 , researcher_agent_3 ], description = \"Runs multiple research agents in parallel to gather information.\" ) # --- 3. Define the Merger Agent (Runs *after* the parallel agents) --- # This agent takes the results stored in the session state by the parallel agents # and synthesizes them into a single, structured response with attributions. merger_agent = LlmAgent ( name = \"SynthesisAgent\" , model = GEMINI_MODEL , # Or potentially a more powerful model if needed for synthesis instruction = \"\"\"You are an AI Assistant responsible for combining research findings into a structured report. Your primary task is to synthesize the following research summaries, clearly attributing findings to their source areas. Structure your response using headings for each topic. Ensure the report is coherent and integrates the key points smoothly. **Crucially: Your entire response MUST be grounded *exclusively* on the information provided in the 'Input Summaries' below. Do NOT add any external knowledge, facts, or details not present in these specific summaries.** **Input Summaries:** *   **Renewable Energy:** {renewable_energy_result} *   **Electric Vehicles:** {ev_technology_result} *   **Carbon Capture:** {carbon_capture_result} **Output Format:** ## Summary of Recent Sustainable Technology Advancements ### Renewable Energy Findings (Based on RenewableEnergyResearcher's findings) [Synthesize and elaborate *only* on the renewable energy input summary provided above.] ### Electric Vehicle Findings (Based on EVResearcher's findings) [Synthesize and elaborate *only* on the EV input summary provided above.] ### Carbon Capture Findings (Based on CarbonCaptureResearcher's findings) [Synthesize and elaborate *only* on the carbon capture input summary provided above.] ### Overall Conclusion [Provide a brief (1-2 sentence) concluding statement that connects *only* the findings presented above.] Output *only* the structured report following this format. Do not include introductory or concluding phrases outside this structure, and strictly adhere to using only the provided input summary content. \"\"\" , description = \"Combines research findings from parallel agents into a structured, cited report, strictly grounded on provided inputs.\" , # No tools needed for merging # No output_key needed here, as its direct response is the final output of the sequence ) # --- 4. Create the SequentialAgent (Orchestrates the overall flow) --- # This is the main agent that will be run. It first executes the ParallelAgent # to populate the state, and then executes the MergerAgent to produce the final output. sequential_pipeline_agent = SequentialAgent ( name = \"ResearchAndSynthesisPipeline\" , # Run parallel research first, then merge sub_agents = [ parallel_research_agent , merger_agent ], description = \"Coordinates parallel research and synthesizes the results.\" ) root_agent = sequential_pipeline_agent model , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { return fmt . Errorf ( \"failed to create model: %v\" , err ) } // --- 1. Define Researcher Sub-Agents (to run in parallel) --- researcher1 , err := llmagent . New ( llmagent . Config { Name : \"RenewableEnergyResearcher\" , Model : model , Instruction : `You are an AI Research Assistant specializing in energy. Research the latest advancements in 'renewable energy sources'. Use the Google Search tool provided. Summarize your key findings concisely (1-2 sentences). Output *only* the summary.` , Description : \"Researches renewable energy sources.\" , OutputKey : \"renewable_energy_result\" , }) if err != nil { return err } researcher2 , err := llmagent . New ( llmagent . Config { Name : \"EVResearcher\" , Model : model , Instruction : `You are an AI Research Assistant specializing in transportation. Research the latest developments in 'electric vehicle technology'. Use the Google Search tool provided. Summarize your key findings concisely (1-2 sentences). Output *only* the summary.` , Description : \"Researches electric vehicle technology.\" , OutputKey : \"ev_technology_result\" , }) if err != nil { return err } researcher3 , err := llmagent . New ( llmagent . Config { Name : \"CarbonCaptureResearcher\" , Model : model , Instruction : `You are an AI Research Assistant specializing in climate solutions. Research the current state of 'carbon capture methods'. Use the Google Search tool provided. Summarize your key findings concisely (1-2 sentences). Output *only* the summary.` , Description : \"Researches carbon capture methods.\" , OutputKey : \"carbon_capture_result\" , }) if err != nil { return err } // --- 2. Create the ParallelAgent (Runs researchers concurrently) --- parallelResearchAgent , err := parallelagent . New ( parallelagent . Config { AgentConfig : agent . Config { Name : \"ParallelWebResearchAgent\" , Description : \"Runs multiple research agents in parallel to gather information.\" , SubAgents : [] agent . Agent { researcher1 , researcher2 , researcher3 }, }, }) if err != nil { return fmt . Errorf ( \"failed to create parallel agent: %v\" , err ) } // --- 3. Define the Merger Agent (Runs *after* the parallel agents) --- synthesisAgent , err := llmagent . New ( llmagent . Config { Name : \"SynthesisAgent\" , Model : model , Instruction : `You are an AI Assistant responsible for combining research findings into a structured report. Your primary task is to synthesize the following research summaries, clearly attributing findings to their source areas. Structure your response using headings for each topic. Ensure the report is coherent and integrates the key points smoothly. **Crucially: Your entire response MUST be grounded *exclusively* on the information provided in the 'Input Summaries' below. Do NOT add any external knowledge, facts, or details not present in these specific summaries.** **Input Summaries:** *   **Renewable Energy:** {renewable_energy_result} *   **Electric Vehicles:** {ev_technology_result} *   **Carbon Capture:** {carbon_capture_result} **Output Format:** ## Summary of Recent Sustainable Technology Advancements ### Renewable Energy Findings (Based on RenewableEnergyResearcher's findings) [Synthesize and elaborate *only* on the renewable energy input summary provided above.] ### Electric Vehicle Findings (Based on EVResearcher's findings) [Synthesize and elaborate *only* on the EV input summary provided above.] ### Carbon Capture Findings (Based on CarbonCaptureResearcher's findings) [Synthesize and elaborate *only* on the carbon capture input summary provided above.] ### Overall Conclusion [Provide a brief (1-2 sentence) concluding statement that connects *only* the findings presented above.] Output *only* the structured report following this format. Do not include introductory or concluding phrases outside this structure, and strictly adhere to using only the provided input summary content.` , Description : \"Combines research findings from parallel agents into a structured, cited report, strictly grounded on provided inputs.\" , }) if err != nil { return fmt . Errorf ( \"failed to create synthesis agent: %v\" , err ) } // --- 4. Create the SequentialAgent (Orchestrates the overall flow) --- pipeline , err := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : \"ResearchAndSynthesisPipeline\" , Description : \"Coordinates parallel research and synthesizes the results.\" , SubAgents : [] agent . Agent { parallelResearchAgent , synthesisAgent }, }, }) if err != nil { return fmt . Errorf ( \"failed to create sequential agent pipeline: %v\" , err ) } import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.ParallelAgent ; import com.google.adk.agents.SequentialAgent ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.adk.tools.GoogleSearchTool ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; public class ParallelResearchPipeline { private static final String APP_NAME = \"parallel_research_app\" ; private static final String USER_ID = \"research_user_01\" ; private static final String GEMINI_MODEL = \"gemini-2.0-flash\" ; // Assume google_search is an instance of the GoogleSearchTool private static final GoogleSearchTool googleSearchTool = new GoogleSearchTool (); public static void main ( String [] args ) { String query = \"Summarize recent sustainable tech advancements.\" ; SequentialAgent sequentialPipelineAgent = initAgent (); runAgent ( sequentialPipelineAgent , query ); } public static SequentialAgent initAgent () { // --- 1. Define Researcher Sub-Agents (to run in parallel) --- // Researcher 1: Renewable Energy LlmAgent researcherAgent1 = LlmAgent . builder () . name ( \"RenewableEnergyResearcher\" ) . model ( GEMINI_MODEL ) . instruction ( \"\"\" You are an AI Research Assistant specializing in energy. Research the latest advancements in 'renewable energy sources'. Use the Google Search tool provided. Summarize your key findings concisely (1-2 sentences). Output *only* the summary. \"\"\" ) . description ( \"Researches renewable energy sources.\" ) . tools ( googleSearchTool ) . outputKey ( \"renewable_energy_result\" ) // Store result in state . build (); // Researcher 2: Electric Vehicles LlmAgent researcherAgent2 = LlmAgent . builder () . name ( \"EVResearcher\" ) . model ( GEMINI_MODEL ) . instruction ( \"\"\" You are an AI Research Assistant specializing in transportation. Research the latest developments in 'electric vehicle technology'. Use the Google Search tool provided. Summarize your key findings concisely (1-2 sentences). Output *only* the summary. \"\"\" ) . description ( \"Researches electric vehicle technology.\" ) . tools ( googleSearchTool ) . outputKey ( \"ev_technology_result\" ) // Store result in state . build (); // Researcher 3: Carbon Capture LlmAgent researcherAgent3 = LlmAgent . builder () . name ( \"CarbonCaptureResearcher\" ) . model ( GEMINI_MODEL ) . instruction ( \"\"\" You are an AI Research Assistant specializing in climate solutions. Research the current state of 'carbon capture methods'. Use the Google Search tool provided. Summarize your key findings concisely (1-2 sentences). Output *only* the summary. \"\"\" ) . description ( \"Researches carbon capture methods.\" ) . tools ( googleSearchTool ) . outputKey ( \"carbon_capture_result\" ) // Store result in state . build (); // --- 2. Create the ParallelAgent (Runs researchers concurrently) --- // This agent orchestrates the concurrent execution of the researchers. // It finishes once all researchers have completed and stored their results in state. ParallelAgent parallelResearchAgent = ParallelAgent . builder () . name ( \"ParallelWebResearchAgent\" ) . subAgents ( researcherAgent1 , researcherAgent2 , researcherAgent3 ) . description ( \"Runs multiple research agents in parallel to gather information.\" ) . build (); // --- 3. Define the Merger Agent (Runs *after* the parallel agents) --- // This agent takes the results stored in the session state by the parallel agents // and synthesizes them into a single, structured response with attributions. LlmAgent mergerAgent = LlmAgent . builder () . name ( \"SynthesisAgent\" ) . model ( GEMINI_MODEL ) . instruction ( \"\"\" You are an AI Assistant responsible for combining research findings into a structured report. Your primary task is to synthesize the following research summaries, clearly attributing findings to their source areas. Structure your response using headings for each topic. Ensure the report is coherent and integrates the key points smoothly. **Crucially: Your entire response MUST be grounded *exclusively* on the information provided in the 'Input Summaries' below. Do NOT add any external knowledge, facts, or details not present in these specific summaries.** **Input Summaries:** *   **Renewable Energy:** {renewable_energy_result} *   **Electric Vehicles:** {ev_technology_result} *   **Carbon Capture:** {carbon_capture_result} **Output Format:** ## Summary of Recent Sustainable Technology Advancements ### Renewable Energy Findings (Based on RenewableEnergyResearcher's findings) [Synthesize and elaborate *only* on the renewable energy input summary provided above.] ### Electric Vehicle Findings (Based on EVResearcher's findings) [Synthesize and elaborate *only* on the EV input summary provided above.] ### Carbon Capture Findings (Based on CarbonCaptureResearcher's findings) [Synthesize and elaborate *only* on the carbon capture input summary provided above.] ### Overall Conclusion [Provide a brief (1-2 sentence) concluding statement that connects *only* the findings presented above.] Output *only* the structured report following this format. Do not include introductory or concluding phrases outside this structure, and strictly adhere to using only the provided input summary content. \"\"\" ) . description ( \"Combines research findings from parallel agents into a structured, cited report, strictly grounded on provided inputs.\" ) // No tools needed for merging // No output_key needed here, as its direct response is the final output of the sequence . build (); // --- 4. Create the SequentialAgent (Orchestrates the overall flow) --- // This is the main agent that will be run. It first executes the ParallelAgent // to populate the state, and then executes the MergerAgent to produce the final output. SequentialAgent sequentialPipelineAgent = SequentialAgent . builder () . name ( \"ResearchAndSynthesisPipeline\" ) // Run parallel research first, then merge . subAgents ( parallelResearchAgent , mergerAgent ) . description ( \"Coordinates parallel research and synthesizes the results.\" ) . build (); return sequentialPipelineAgent ; } public static void runAgent ( SequentialAgent sequentialPipelineAgent , String query ) { // Create an InMemoryRunner InMemoryRunner runner = new InMemoryRunner ( sequentialPipelineAgent , APP_NAME ); // InMemoryRunner automatically creates a session service. Create a session using the service Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( query )); // Run the agent Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . printf ( \"Event Author: %s \\n Event Response: %s \\n\\n\\n\" , event . author (), event . stringifyContent ()); } }); } } Back to top ", "code_blocks": [{"language": "text", "code": "ParallelAgent(sub_agents=[ResearcherAgent1, ResearcherAgent2, ResearcherAgent3])"}, {"language": "text", "code": "# Part of agent.py --> Follow https://google.github.io/adk-docs/get-started/quickstart/ to learn the setup\n # --- 1. Define Researcher Sub-Agents (to run in parallel) ---\n\n # Researcher 1: Renewable Energy\n researcher_agent_1 = LlmAgent(\n     name=\"RenewableEnergyResearcher\",\n     model=GEMINI_MODEL,\n     instruction=\"\"\"You are an AI Research Assistant specializing in energy.\n Research the latest advancements in 'renewable energy sources'.\n Use the Google Search tool provided.\n Summarize your key findings concisely (1-2 sentences).\n Output *only* the summary.\n \"\"\",\n     description=\"Researches renewable energy sources.\",\n     tools=[google_search],\n     # Store result in state for the merger agent\n     output_key=\"renewable_energy_result\"\n )\n\n # Researcher 2: Electric Vehicles\n researcher_agent_2 = LlmAgent(\n     name=\"EVResearcher\",\n     model=GEMINI_MODEL,\n     instruction=\"\"\"You are an AI Research Assistant specializing in transportation.\n Research the latest developments in 'electric vehicle technology'.\n Use the Google Search tool provided.\n Summarize your key findings concisely (1-2 sentences).\n Output *only* the summary.\n \"\"\",\n     description=\"Researches electric vehicle technology.\",\n     tools=[google_search],\n     # Store result in state for the merger agent\n     output_key=\"ev_technology_result\"\n )\n\n # Researcher 3: Carbon Capture\n researcher_agent_3 = LlmAgent(\n     name=\"CarbonCaptureResearcher\",\n     model=GEMINI_MODEL,\n     instruction=\"\"\"You are an AI Research Assistant specializing in climate solutions.\n Research the current state of 'carbon capture methods'.\n Use the Google Search tool provided.\n Summarize your key findings concisely (1-2 sentences).\n Output *only* the summary.\n \"\"\",\n     description=\"Researches carbon capture methods.\",\n     tools=[google_search],\n     # Store result in state for the merger agent\n     output_key=\"carbon_capture_result\"\n )\n\n # --- 2. Create the ParallelAgent (Runs researchers concurrently) ---\n # This agent orchestrates the concurrent execution of the researchers.\n # It finishes once all researchers have completed and stored their results in state.\n parallel_research_agent = ParallelAgent(\n     name=\"ParallelWebResearchAgent\",\n     sub_agents=[researcher_agent_1, researcher_agent_2, researcher_agent_3],\n     description=\"Runs multiple research agents in parallel to gather information.\"\n )\n\n # --- 3. Define the Merger Agent (Runs *after* the parallel agents) ---\n # This agent takes the results stored in the session state by the parallel agents\n # and synthesizes them into a single, structured response with attributions.\n merger_agent = LlmAgent(\n     name=\"SynthesisAgent\",\n     model=GEMINI_MODEL,  # Or potentially a more powerful model if needed for synthesis\n     instruction=\"\"\"You are an AI Assistant responsible for combining research findings into a structured report.\n\n Your primary task is to synthesize the following research summaries, clearly attributing findings to their source areas. Structure your response using headings for each topic. Ensure the report is coherent and integrates the key points smoothly.\n\n **Crucially: Your entire response MUST be grounded *exclusively* on the information provided in the 'Input Summaries' below. Do NOT add any external knowledge, facts, or details not present in these specific summaries.**\n\n **Input Summaries:**\n\n *   **Renewable Energy:**\n     {renewable_energy_result}\n\n *   **Electric Vehicles:**\n     {ev_technology_result}\n\n *   **Carbon Capture:**\n     {carbon_capture_result}\n\n **Output Format:**\n\n ## Summary of Recent Sustainable Technology Advancements\n\n ### Renewable Energy Findings\n (Based on RenewableEnergyResearcher's findings)\n [Synthesize and elaborate *only* on the renewable energy input summary provided above.]\n\n ### Electric Vehicle Findings\n (Based on EVResearcher's findings)\n [Synthesize and elaborate *only* on the EV input summary provided above.]\n\n ### Carbon Capture Findings\n (Based on CarbonCaptureResearcher's findings)\n [Synthesize and elaborate *only* on the carbon capture input summary provided above.]\n\n ### Overall Conclusion\n [Provide a brief (1-2 sentence) concluding statement that connects *only* the findings presented above.]\n\n Output *only* the structured report following this format. Do not include introductory or concluding phrases outside this structure, and strictly adhere to using only the provided input summary content.\n \"\"\",\n     description=\"Combines research findings from parallel agents into a structured, cited report, strictly grounded on provided inputs.\",\n     # No tools needed for merging\n     # No output_key needed here, as its direct response is the final output of the sequence\n )\n\n\n # --- 4. Create the SequentialAgent (Orchestrates the overall flow) ---\n # This is the main agent that will be run. It first executes the ParallelAgent\n # to populate the state, and then executes the MergerAgent to produce the final output.\n sequential_pipeline_agent = SequentialAgent(\n     name=\"ResearchAndSynthesisPipeline\",\n     # Run parallel research first, then merge\n     sub_agents=[parallel_research_agent, merger_agent],\n     description=\"Coordinates parallel research and synthesizes the results.\"\n )\n\n root_agent = sequential_pipeline_agent"}, {"language": "text", "code": "model, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        return fmt.Errorf(\"failed to create model: %v\", err)\n    }\n\n    // --- 1. Define Researcher Sub-Agents (to run in parallel) ---\n    researcher1, err := llmagent.New(llmagent.Config{\n        Name:  \"RenewableEnergyResearcher\",\n        Model: model,\n        Instruction: `You are an AI Research Assistant specializing in energy.\n Research the latest advancements in 'renewable energy sources'.\n Use the Google Search tool provided.\n Summarize your key findings concisely (1-2 sentences).\n Output *only* the summary.`,\n        Description: \"Researches renewable energy sources.\",\n        OutputKey:   \"renewable_energy_result\",\n    })\n    if err != nil {\n        return err\n    }\n    researcher2, err := llmagent.New(llmagent.Config{\n        Name:  \"EVResearcher\",\n        Model: model,\n        Instruction: `You are an AI Research Assistant specializing in transportation.\n Research the latest developments in 'electric vehicle technology'.\n Use the Google Search tool provided.\n Summarize your key findings concisely (1-2 sentences).\n Output *only* the summary.`,\n        Description: \"Researches electric vehicle technology.\",\n        OutputKey:   \"ev_technology_result\",\n    })\n    if err != nil {\n        return err\n    }\n    researcher3, err := llmagent.New(llmagent.Config{\n        Name:  \"CarbonCaptureResearcher\",\n        Model: model,\n        Instruction: `You are an AI Research Assistant specializing in climate solutions.\n Research the current state of 'carbon capture methods'.\n Use the Google Search tool provided.\n Summarize your key findings concisely (1-2 sentences).\n Output *only* the summary.`,\n        Description: \"Researches carbon capture methods.\",\n        OutputKey:   \"carbon_capture_result\",\n    })\n    if err != nil {\n        return err\n    }\n\n    // --- 2. Create the ParallelAgent (Runs researchers concurrently) ---\n    parallelResearchAgent, err := parallelagent.New(parallelagent.Config{\n        AgentConfig: agent.Config{\n            Name:        \"ParallelWebResearchAgent\",\n            Description: \"Runs multiple research agents in parallel to gather information.\",\n            SubAgents:   []agent.Agent{researcher1, researcher2, researcher3},\n        },\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create parallel agent: %v\", err)\n    }\n\n    // --- 3. Define the Merger Agent (Runs *after* the parallel agents) ---\n    synthesisAgent, err := llmagent.New(llmagent.Config{\n        Name:  \"SynthesisAgent\",\n        Model: model,\n        Instruction: `You are an AI Assistant responsible for combining research findings into a structured report.\n Your primary task is to synthesize the following research summaries, clearly attributing findings to their source areas. Structure your response using headings for each topic. Ensure the report is coherent and integrates the key points smoothly.\n **Crucially: Your entire response MUST be grounded *exclusively* on the information provided in the 'Input Summaries' below. Do NOT add any external knowledge, facts, or details not present in these specific summaries.**\n **Input Summaries:**\n\n *   **Renewable Energy:**\n     {renewable_energy_result}\n\n *   **Electric Vehicles:**\n     {ev_technology_result}\n\n *   **Carbon Capture:**\n     {carbon_capture_result}\n\n **Output Format:**\n\n ## Summary of Recent Sustainable Technology Advancements\n\n ### Renewable Energy Findings\n (Based on RenewableEnergyResearcher's findings)\n [Synthesize and elaborate *only* on the renewable energy input summary provided above.]\n\n ### Electric Vehicle Findings\n (Based on EVResearcher's findings)\n [Synthesize and elaborate *only* on the EV input summary provided above.]\n\n ### Carbon Capture Findings\n (Based on CarbonCaptureResearcher's findings)\n [Synthesize and elaborate *only* on the carbon capture input summary provided above.]\n\n ### Overall Conclusion\n [Provide a brief (1-2 sentence) concluding statement that connects *only* the findings presented above.]\n\n Output *only* the structured report following this format. Do not include introductory or concluding phrases outside this structure, and strictly adhere to using only the provided input summary content.`,\n        Description: \"Combines research findings from parallel agents into a structured, cited report, strictly grounded on provided inputs.\",\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create synthesis agent: %v\", err)\n    }\n\n    // --- 4. Create the SequentialAgent (Orchestrates the overall flow) ---\n    pipeline, err := sequentialagent.New(sequentialagent.Config{\n        AgentConfig: agent.Config{\n            Name:        \"ResearchAndSynthesisPipeline\",\n            Description: \"Coordinates parallel research and synthesizes the results.\",\n            SubAgents:   []agent.Agent{parallelResearchAgent, synthesisAgent},\n        },\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create sequential agent pipeline: %v\", err)\n    }"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\n import com.google.adk.agents.ParallelAgent;\n import com.google.adk.agents.SequentialAgent;\n import com.google.adk.events.Event;\n import com.google.adk.runner.InMemoryRunner;\n import com.google.adk.sessions.Session;\n import com.google.adk.tools.GoogleSearchTool;\n import com.google.genai.types.Content;\n import com.google.genai.types.Part;\n import io.reactivex.rxjava3.core.Flowable;\n\n public class ParallelResearchPipeline {\n\n   private static final String APP_NAME = \"parallel_research_app\";\n   private static final String USER_ID = \"research_user_01\";\n   private static final String GEMINI_MODEL = \"gemini-2.0-flash\";\n\n   // Assume google_search is an instance of the GoogleSearchTool\n   private static final GoogleSearchTool googleSearchTool = new GoogleSearchTool();\n\n   public static void main(String[] args) {\n     String query = \"Summarize recent sustainable tech advancements.\";\n     SequentialAgent sequentialPipelineAgent = initAgent();\n     runAgent(sequentialPipelineAgent, query);\n   }\n\n   public static SequentialAgent initAgent() {\n     // --- 1. Define Researcher Sub-Agents (to run in parallel) ---\n     // Researcher 1: Renewable Energy\n     LlmAgent researcherAgent1 = LlmAgent.builder()\n         .name(\"RenewableEnergyResearcher\")\n         .model(GEMINI_MODEL)\n         .instruction(\"\"\"\n                     You are an AI Research Assistant specializing in energy.\n                     Research the latest advancements in 'renewable energy sources'.\n                     Use the Google Search tool provided.\n                     Summarize your key findings concisely (1-2 sentences).\n                     Output *only* the summary.\n                     \"\"\")\n         .description(\"Researches renewable energy sources.\")\n         .tools(googleSearchTool)\n         .outputKey(\"renewable_energy_result\") // Store result in state\n         .build();\n\n     // Researcher 2: Electric Vehicles\n     LlmAgent researcherAgent2 = LlmAgent.builder()\n         .name(\"EVResearcher\")\n         .model(GEMINI_MODEL)\n         .instruction(\"\"\"\n                     You are an AI Research Assistant specializing in transportation.\n                     Research the latest developments in 'electric vehicle technology'.\n                     Use the Google Search tool provided.\n                     Summarize your key findings concisely (1-2 sentences).\n                     Output *only* the summary.\n                     \"\"\")\n         .description(\"Researches electric vehicle technology.\")\n         .tools(googleSearchTool)\n         .outputKey(\"ev_technology_result\") // Store result in state\n         .build();\n\n     // Researcher 3: Carbon Capture\n     LlmAgent researcherAgent3 = LlmAgent.builder()\n         .name(\"CarbonCaptureResearcher\")\n         .model(GEMINI_MODEL)\n         .instruction(\"\"\"\n                     You are an AI Research Assistant specializing in climate solutions.\n                     Research the current state of 'carbon capture methods'.\n                     Use the Google Search tool provided.\n                     Summarize your key findings concisely (1-2 sentences).\n                     Output *only* the summary.\n                     \"\"\")\n         .description(\"Researches carbon capture methods.\")\n         .tools(googleSearchTool)\n         .outputKey(\"carbon_capture_result\") // Store result in state\n         .build();\n\n     // --- 2. Create the ParallelAgent (Runs researchers concurrently) ---\n     // This agent orchestrates the concurrent execution of the researchers.\n     // It finishes once all researchers have completed and stored their results in state.\n     ParallelAgent parallelResearchAgent =\n         ParallelAgent.builder()\n             .name(\"ParallelWebResearchAgent\")\n             .subAgents(researcherAgent1, researcherAgent2, researcherAgent3)\n             .description(\"Runs multiple research agents in parallel to gather information.\")\n             .build();\n\n     // --- 3. Define the Merger Agent (Runs *after* the parallel agents) ---\n     // This agent takes the results stored in the session state by the parallel agents\n     // and synthesizes them into a single, structured response with attributions.\n     LlmAgent mergerAgent =\n         LlmAgent.builder()\n             .name(\"SynthesisAgent\")\n             .model(GEMINI_MODEL)\n             .instruction(\n                 \"\"\"\n                       You are an AI Assistant responsible for combining research findings into a structured report.\n                       Your primary task is to synthesize the following research summaries, clearly attributing findings to their source areas. Structure your response using headings for each topic. Ensure the report is coherent and integrates the key points smoothly.\n                       **Crucially: Your entire response MUST be grounded *exclusively* on the information provided in the 'Input Summaries' below. Do NOT add any external knowledge, facts, or details not present in these specific summaries.**\n                       **Input Summaries:**\n\n                       *   **Renewable Energy:**\n                           {renewable_energy_result}\n\n                       *   **Electric Vehicles:**\n                           {ev_technology_result}\n\n                       *   **Carbon Capture:**\n                           {carbon_capture_result}\n\n                       **Output Format:**\n\n                       ## Summary of Recent Sustainable Technology Advancements\n\n                       ### Renewable Energy Findings\n                       (Based on RenewableEnergyResearcher's findings)\n                       [Synthesize and elaborate *only* on the renewable energy input summary provided above.]\n\n                       ### Electric Vehicle Findings\n                       (Based on EVResearcher's findings)\n                       [Synthesize and elaborate *only* on the EV input summary provided above.]\n\n                       ### Carbon Capture Findings\n                       (Based on CarbonCaptureResearcher's findings)\n                       [Synthesize and elaborate *only* on the carbon capture input summary provided above.]\n\n                       ### Overall Conclusion\n                       [Provide a brief (1-2 sentence) concluding statement that connects *only* the findings presented above.]\n\n                       Output *only* the structured report following this format. Do not include introductory or concluding phrases outside this structure, and strictly adhere to using only the provided input summary content.\n                       \"\"\")\n             .description(\n                 \"Combines research findings from parallel agents into a structured, cited report, strictly grounded on provided inputs.\")\n             // No tools needed for merging\n             // No output_key needed here, as its direct response is the final output of the sequence\n             .build();\n\n     // --- 4. Create the SequentialAgent (Orchestrates the overall flow) ---\n     // This is the main agent that will be run. It first executes the ParallelAgent\n     // to populate the state, and then executes the MergerAgent to produce the final output.\n     SequentialAgent sequentialPipelineAgent =\n         SequentialAgent.builder()\n             .name(\"ResearchAndSynthesisPipeline\")\n             // Run parallel research first, then merge\n             .subAgents(parallelResearchAgent, mergerAgent)\n             .description(\"Coordinates parallel research and synthesizes the results.\")\n             .build();\n\n     return sequentialPipelineAgent;\n   }\n\n   public static void runAgent(SequentialAgent sequentialPipelineAgent, String query) {\n     // Create an InMemoryRunner\n     InMemoryRunner runner = new InMemoryRunner(sequentialPipelineAgent, APP_NAME);\n     // InMemoryRunner automatically creates a session service. Create a session using the service\n     Session session = runner.sessionService().createSession(APP_NAME, USER_ID).blockingGet();\n     Content userMessage = Content.fromParts(Part.fromText(query));\n\n     // Run the agent\n     Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n     // Stream event response\n     eventStream.blockingForEach(\n         event -> {\n           if (event.finalResponse()) {\n             System.out.printf(\"Event Author: %s \\n Event Response: %s \\n\\n\\n\", event.author(), event.stringifyContent());\n           }\n         });\n   }\n }"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:06.967456", "source_type": "adk-docs"}
{"doc_id": "334799b83d9843b17c82c7d61fa0519b1913c9de7e72eb0ccba7a5f38f084a08", "url": "https://google.github.io/adk-docs/agents/custom-agents", "title": "Custom agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Custom agents\u00b6"], "text": "Custom agents \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.2.0 Custom agents provide the ultimate flexibility in ADK, allowing you to define arbitrary orchestration logic by inheriting directly from BaseAgent and implementing your own control flow. This goes beyond the predefined patterns of SequentialAgent , LoopAgent , and ParallelAgent , enabling you to build highly specific and complex agentic workflows. Advanced Concept Building custom agents by directly implementing _run_async_impl (or its equivalent in other languages) provides powerful control but is more complex than using the predefined LlmAgent or standard WorkflowAgent types. We recommend understanding those foundational agent types first before tackling custom orchestration logic. ", "code_blocks": []}, {"heading_path": ["Introduction: Beyond Predefined Workflows\u00b6"], "text": "Introduction: Beyond Predefined Workflows \u00b6 ", "code_blocks": []}, {"heading_path": ["What is a Custom Agent?\u00b6"], "text": "What is a Custom Agent? \u00b6 A Custom Agent is essentially any class you create that inherits from google.adk.agents.BaseAgent and implements its core execution logic within the _run_async_impl asynchronous method. You have complete control over how this method calls other agents (sub-agents), manages state, and handles events. Note The specific method name for implementing an agent's core asynchronous logic may vary slightly by SDK language (e.g., runAsyncImpl in Java, _run_async_impl in Python). Refer to the language-specific API documentation for details. ", "code_blocks": []}, {"heading_path": ["Why Use Them?\u00b6"], "text": "Why Use Them? \u00b6 While the standard Workflow Agents ( SequentialAgent , LoopAgent , ParallelAgent ) cover common orchestration patterns, you'll need a Custom agent when your requirements include: Conditional Logic: Executing different sub-agents or taking different paths based on runtime conditions or the results of previous steps. Complex State Management: Implementing intricate logic for maintaining and updating state throughout the workflow beyond simple sequential passing. External Integrations: Incorporating calls to external APIs, databases, or custom libraries directly within the orchestration flow control. Dynamic Agent Selection: Choosing which sub-agent(s) to run next based on dynamic evaluation of the situation or input. Unique Workflow Patterns: Implementing orchestration logic that doesn't fit the standard sequential, parallel, or loop structures. ", "code_blocks": []}, {"heading_path": ["Implementing Custom Logic:\u00b6"], "text": "Implementing Custom Logic: \u00b6 The core of any custom agent is the method where you define its unique asynchronous behavior. This method allows you to orchestrate sub-agents and manage the flow of execution. Python Go Java The heart of any custom agent is the _run_async_impl method. This is where you define its unique behavior. Signature: async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]: Asynchronous Generator: It must be an async def function and return an AsyncGenerator . This allows it to yield events produced by sub-agents or its own logic back to the runner. ctx (InvocationContext): Provides access to crucial runtime information, most importantly ctx.session.state , which is the primary way to share data between steps orchestrated by your custom agent. In Go, you implement the Run method as part of a struct that satisfies the agent.Agent interface. The actual logic is typically a method on your custom agent struct. Signature: Run(ctx agent.InvocationContext) iter.Seq2[*session.Event, error] Iterator: The Run method returns an iterator ( iter.Seq2 ) that yields events and errors. This is the standard way to handle streaming results from an agent's execution. ctx (InvocationContext): The agent.InvocationContext provides access to the session, including state, and other crucial runtime information. Session State: You can access the session state through ctx.Session().State() . The heart of any custom agent is the runAsyncImpl method, which you override from BaseAgent . Signature: protected Flowable<Event> runAsyncImpl(InvocationContext ctx) Reactive Stream ( Flowable ): It must return an io.reactivex.rxjava3.core.Flowable<Event> . This Flowable represents a stream of events that will be produced by the custom agent's logic, often by combining or transforming multiple Flowable from sub-agents. ctx (InvocationContext): Provides access to crucial runtime information, most importantly ctx.session().state() , which is a java.util.concurrent.ConcurrentMap<String, Object> . This is the primary way to share data between steps orchestrated by your custom agent. Key Capabilities within the Core Asynchronous Method: Python Go Java Calling Sub-Agents: You invoke sub-agents (which are typically stored as instance attributes like self.my_llm_agent ) using their run_async method and yield their events: async for event in self . some_sub_agent . run_async ( ctx ): # Optionally inspect or log the event yield event # Pass the event up Managing State: Read from and write to the session state dictionary ( ctx.session.state ) to pass data between sub-agent calls or make decisions: # Read data set by a previous agent previous_result = ctx . session . state . get ( \"some_key\" ) # Make a decision based on state if previous_result == \"some_value\" : # ... call a specific sub-agent ... else : # ... call another sub-agent ... # Store a result for a later step (often done via a sub-agent's output_key) # ctx.session.state[\"my_custom_result\"] = \"calculated_value\" Implementing Control Flow: Use standard Python constructs ( if / elif / else , for / while loops, try / except ) to create sophisticated, conditional, or iterative workflows involving your sub-agents. Calling Sub-Agents: You invoke sub-agents by calling their Run method. // Example: Running one sub-agent and yielding its events for event , err := range someSubAgent . Run ( ctx ) { if err != nil { // Handle or propagate the error return } // Yield the event up to the caller if ! yield ( event , nil ) { return } } Managing State: Read from and write to the session state to pass data between sub-agent calls or make decisions. // The `ctx` (`agent.InvocationContext`) is passed directly to your agent's `Run` function. // Read data set by a previous agent previousResult , err := ctx . Session (). State (). Get ( \"some_key\" ) if err != nil { // Handle cases where the key might not exist yet } // Make a decision based on state if val , ok := previousResult .( string ); ok && val == \"some_value\" { // ... call a specific sub-agent ... } else { // ... call another sub-agent ... } // Store a result for a later step if err := ctx . Session (). State (). Set ( \"my_custom_result\" , \"calculated_value\" ); err != nil { // Handle error } Implementing Control Flow: Use standard Go constructs ( if / else , for / switch loops, goroutines, channels) to create sophisticated, conditional, or iterative workflows involving your sub-agents. Calling Sub-Agents: You invoke sub-agents (which are typically stored as instance attributes or objects) using their asynchronous run method and return their event streams: You typically chain Flowable s from sub-agents using RxJava operators like concatWith , flatMapPublisher , or concatArray . // Example: Running one sub-agent // return someSubAgent.runAsync(ctx); // Example: Running sub-agents sequentially Flowable < Event > firstAgentEvents = someSubAgent1 . runAsync ( ctx ) . doOnNext ( event -> System . out . println ( \"Event from agent 1: \" + event . id ())); Flowable < Event > secondAgentEvents = Flowable . defer (() -> someSubAgent2 . runAsync ( ctx ) . doOnNext ( event -> System . out . println ( \"Event from agent 2: \" + event . id ())) ); return firstAgentEvents . concatWith ( secondAgentEvents ); The Flowable.defer() is often used for subsequent stages if their execution depends on the completion or state after prior stages. Managing State: Read from and write to the session state to pass data between sub-agent calls or make decisions. The session state is a java.util.concurrent.ConcurrentMap<String, Object> obtained via ctx.session().state() . // Read data set by a previous agent Object previousResult = ctx . session (). state (). get ( \"some_key\" ); // Make a decision based on state if ( \"some_value\" . equals ( previousResult )) { // ... logic to include a specific sub-agent's Flowable ... } else { // ... logic to include another sub-agent's Flowable ... } // Store a result for a later step (often done via a sub-agent's output_key) // ctx.session().state().put(\"my_custom_result\", \"calculated_value\"); Implementing Control Flow: Use standard language constructs ( if / else , loops, try / catch ) combined with reactive operators (RxJava) to create sophisticated workflows. Conditional: Flowable.defer() to choose which Flowable to subscribe to based on a condition, or filter() if you're filtering events within a stream. Iterative: Operators like repeat() , retry() , or by structuring your Flowable chain to recursively call parts of itself based on conditions (often managed with flatMapPublisher or concatMap ). ", "code_blocks": [{"language": "text", "code": "async for event in self.some_sub_agent.run_async(ctx):\n    # Optionally inspect or log the event\n    yield event # Pass the event up"}, {"language": "text", "code": "# Read data set by a previous agent\nprevious_result = ctx.session.state.get(\"some_key\")\n\n# Make a decision based on state\nif previous_result == \"some_value\":\n    # ... call a specific sub-agent ...\nelse:\n    # ... call another sub-agent ...\n\n# Store a result for a later step (often done via a sub-agent's output_key)\n# ctx.session.state[\"my_custom_result\"] = \"calculated_value\""}, {"language": "text", "code": "// Example: Running one sub-agent and yielding its events\nfor event, err := range someSubAgent.Run(ctx) {\n    if err != nil {\n        // Handle or propagate the error\n        return\n    }\n    // Yield the event up to the caller\n    if !yield(event, nil) {\n      return\n    }\n}"}, {"language": "text", "code": "// The `ctx` (`agent.InvocationContext`) is passed directly to your agent's `Run` function.\n// Read data set by a previous agent\npreviousResult, err := ctx.Session().State().Get(\"some_key\")\nif err != nil {\n    // Handle cases where the key might not exist yet\n}\n\n// Make a decision based on state\nif val, ok := previousResult.(string); ok && val == \"some_value\" {\n    // ... call a specific sub-agent ...\n} else {\n    // ... call another sub-agent ...\n}\n\n// Store a result for a later step\nif err := ctx.Session().State().Set(\"my_custom_result\", \"calculated_value\"); err != nil {\n    // Handle error\n}"}, {"language": "text", "code": "// Example: Running one sub-agent\n// return someSubAgent.runAsync(ctx);\n\n// Example: Running sub-agents sequentially\nFlowable<Event> firstAgentEvents = someSubAgent1.runAsync(ctx)\n    .doOnNext(event -> System.out.println(\"Event from agent 1: \" + event.id()));\n\nFlowable<Event> secondAgentEvents = Flowable.defer(() ->\n    someSubAgent2.runAsync(ctx)\n        .doOnNext(event -> System.out.println(\"Event from agent 2: \" + event.id()))\n);\n\nreturn firstAgentEvents.concatWith(secondAgentEvents);"}, {"language": "text", "code": "// Read data set by a previous agent\nObject previousResult = ctx.session().state().get(\"some_key\");\n\n// Make a decision based on state\nif (\"some_value\".equals(previousResult)) {\n    // ... logic to include a specific sub-agent's Flowable ...\n} else {\n    // ... logic to include another sub-agent's Flowable ...\n}\n\n// Store a result for a later step (often done via a sub-agent's output_key)\n// ctx.session().state().put(\"my_custom_result\", \"calculated_value\");"}]}, {"heading_path": ["Managing Sub-Agents and State\u00b6"], "text": "Managing Sub-Agents and State \u00b6 Typically, a custom agent orchestrates other agents (like LlmAgent , LoopAgent , etc.). Initialization: You usually pass instances of these sub-agents into your custom agent's constructor and store them as instance fields/attributes (e.g., this.story_generator = story_generator_instance or self.story_generator = story_generator_instance ). This makes them accessible within the custom agent's core asynchronous execution logic (such as: _run_async_impl method). Sub Agents List: When initializing the BaseAgent using it's super() constructor, you should pass a sub agents list. This list tells the ADK framework about the agents that are part of this custom agent's immediate hierarchy. It's important for framework features like lifecycle management, introspection, and potentially future routing capabilities, even if your core execution logic ( _run_async_impl ) calls the agents directly via self.xxx_agent . Include the agents that your custom logic directly invokes at the top level. State: As mentioned, ctx.session.state is the standard way sub-agents (especially LlmAgent s using output key ) communicate results back to the orchestrator and how the orchestrator passes necessary inputs down. ", "code_blocks": []}, {"heading_path": ["Design Pattern Example: StoryFlowAgent\u00b6"], "text": "Design Pattern Example: StoryFlowAgent \u00b6 Let's illustrate the power of custom agents with an example pattern: a multi-stage content generation workflow with conditional logic. Goal: Create a system that generates a story, iteratively refines it through critique and revision, performs final checks, and crucially, regenerates the story if the final tone check fails . Why Custom? The core requirement driving the need for a custom agent here is the conditional regeneration based on the tone check . Standard workflow agents don't have built-in conditional branching based on the outcome of a sub-agent's task. We need custom logic ( if tone == \"negative\": ... ) within the orchestrator. ", "code_blocks": []}, {"heading_path": ["Part 1: Simplified custom agent Initialization\u00b6"], "text": "Part 1: Simplified custom agent Initialization \u00b6 Python Go Java We define the StoryFlowAgent inheriting from BaseAgent . In __init__ , we store the necessary sub-agents (passed in) as instance attributes and tell the BaseAgent framework about the top-level agents this custom agent will directly orchestrate. class StoryFlowAgent ( BaseAgent ): \"\"\" Custom agent for a story generation and refinement workflow. This agent orchestrates a sequence of LLM agents to generate a story, critique it, revise it, check grammar and tone, and potentially regenerate the story if the tone is negative. \"\"\" # --- Field Declarations for Pydantic --- # Declare the agents passed during initialization as class attributes with type hints story_generator : LlmAgent critic : LlmAgent reviser : LlmAgent grammar_check : LlmAgent tone_check : LlmAgent loop_agent : LoopAgent sequential_agent : SequentialAgent # model_config allows setting Pydantic configurations if needed, e.g., arbitrary_types_allowed model_config = { \"arbitrary_types_allowed\" : True } def __init__ ( self , name : str , story_generator : LlmAgent , critic : LlmAgent , reviser : LlmAgent , grammar_check : LlmAgent , tone_check : LlmAgent , ): \"\"\" Initializes the StoryFlowAgent. Args: name: The name of the agent. story_generator: An LlmAgent to generate the initial story. critic: An LlmAgent to critique the story. reviser: An LlmAgent to revise the story based on criticism. grammar_check: An LlmAgent to check the grammar. tone_check: An LlmAgent to analyze the tone. \"\"\" # Create internal agents *before* calling super().__init__ loop_agent = LoopAgent ( name = \"CriticReviserLoop\" , sub_agents = [ critic , reviser ], max_iterations = 2 ) sequential_agent = SequentialAgent ( name = \"PostProcessing\" , sub_agents = [ grammar_check , tone_check ] ) # Define the sub_agents list for the framework sub_agents_list = [ story_generator , loop_agent , sequential_agent , ] # Pydantic will validate and assign them based on the class annotations. super () . __init__ ( name = name , story_generator = story_generator , critic = critic , reviser = reviser , grammar_check = grammar_check , tone_check = tone_check , loop_agent = loop_agent , sequential_agent = sequential_agent , sub_agents = sub_agents_list , # Pass the sub_agents list directly ) We define the StoryFlowAgent struct and a constructor. In the constructor, we store the necessary sub-agents and tell the BaseAgent framework about the top-level agents this custom agent will directly orchestrate. // StoryFlowAgent is a custom agent that orchestrates a story generation workflow. // It encapsulates the logic of running sub-agents in a specific sequence. type StoryFlowAgent struct { storyGenerator agent . Agent revisionLoopAgent agent . Agent postProcessorAgent agent . Agent } // NewStoryFlowAgent creates and configures the entire custom agent workflow. // It takes individual LLM agents as input and internally creates the necessary // workflow agents (loop, sequential), returning the final orchestrator agent. func NewStoryFlowAgent ( storyGenerator , critic , reviser , grammarCheck , toneCheck agent . Agent , ) ( agent . Agent , error ) { loopAgent , err := loopagent . New ( loopagent . Config { MaxIterations : 2 , AgentConfig : agent . Config { Name : \"CriticReviserLoop\" , SubAgents : [] agent . Agent { critic , reviser }, }, }) if err != nil { return nil , fmt . Errorf ( \"failed to create loop agent: %w\" , err ) } sequentialAgent , err := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : \"PostProcessing\" , SubAgents : [] agent . Agent { grammarCheck , toneCheck }, }, }) if err != nil { return nil , fmt . Errorf ( \"failed to create sequential agent: %w\" , err ) } // The StoryFlowAgent struct holds the agents needed for the Run method. orchestrator := & StoryFlowAgent { storyGenerator : storyGenerator , revisionLoopAgent : loopAgent , postProcessorAgent : sequentialAgent , } // agent.New creates the final agent, wiring up the Run method. return agent . New ( agent . Config { Name : \"StoryFlowAgent\" , Description : \"Orchestrates story generation, critique, revision, and checks.\" , SubAgents : [] agent . Agent { storyGenerator , loopAgent , sequentialAgent }, Run : orchestrator . Run , }) } We define the StoryFlowAgentExample by extending BaseAgent . In its constructor , we store the necessary sub-agent instances (passed as parameters) as instance fields. These top-level sub-agents, which this custom agent will directly orchestrate, are also passed to the super constructor of BaseAgent as a list. private final LlmAgent storyGenerator ; private final LoopAgent loopAgent ; private final SequentialAgent sequentialAgent ; public StoryFlowAgentExample ( String name , LlmAgent storyGenerator , LoopAgent loopAgent , SequentialAgent sequentialAgent ) { super ( name , \"Orchestrates story generation, critique, revision, and checks.\" , List . of ( storyGenerator , loopAgent , sequentialAgent ), null , null ); this . storyGenerator = storyGenerator ; this . loopAgent = loopAgent ; this . sequentialAgent = sequentialAgent ; } ", "code_blocks": [{"language": "text", "code": "class StoryFlowAgent(BaseAgent):\n    \"\"\"\n    Custom agent for a story generation and refinement workflow.\n\n    This agent orchestrates a sequence of LLM agents to generate a story,\n    critique it, revise it, check grammar and tone, and potentially\n    regenerate the story if the tone is negative.\n    \"\"\"\n\n    # --- Field Declarations for Pydantic ---\n    # Declare the agents passed during initialization as class attributes with type hints\n    story_generator: LlmAgent\n    critic: LlmAgent\n    reviser: LlmAgent\n    grammar_check: LlmAgent\n    tone_check: LlmAgent\n\n    loop_agent: LoopAgent\n    sequential_agent: SequentialAgent\n\n    # model_config allows setting Pydantic configurations if needed, e.g., arbitrary_types_allowed\n    model_config = {\"arbitrary_types_allowed\": True}\n\n    def __init__(\n        self,\n        name: str,\n        story_generator: LlmAgent,\n        critic: LlmAgent,\n        reviser: LlmAgent,\n        grammar_check: LlmAgent,\n        tone_check: LlmAgent,\n    ):\n        \"\"\"\n        Initializes the StoryFlowAgent.\n\n        Args:\n            name: The name of the agent.\n            story_generator: An LlmAgent to generate the initial story.\n            critic: An LlmAgent to critique the story.\n            reviser: An LlmAgent to revise the story based on criticism.\n            grammar_check: An LlmAgent to check the grammar.\n            tone_check: An LlmAgent to analyze the tone.\n        \"\"\"\n        # Create internal agents *before* calling super().__init__\n        loop_agent = LoopAgent(\n            name=\"CriticReviserLoop\", sub_agents=[critic, reviser], max_iterations=2\n        )\n        sequential_agent = SequentialAgent(\n            name=\"PostProcessing\", sub_agents=[grammar_check, tone_check]\n        )\n\n        # Define the sub_agents list for the framework\n        sub_agents_list = [\n            story_generator,\n            loop_agent,\n            sequential_agent,\n        ]\n\n        # Pydantic will validate and assign them based on the class annotations.\n        super().__init__(\n            name=name,\n            story_generator=story_generator,\n            critic=critic,\n            reviser=reviser,\n            grammar_check=grammar_check,\n            tone_check=tone_check,\n            loop_agent=loop_agent,\n            sequential_agent=sequential_agent,\n            sub_agents=sub_agents_list, # Pass the sub_agents list directly\n        )"}, {"language": "text", "code": "// StoryFlowAgent is a custom agent that orchestrates a story generation workflow.\n// It encapsulates the logic of running sub-agents in a specific sequence.\ntype StoryFlowAgent struct {\n    storyGenerator     agent.Agent\n    revisionLoopAgent  agent.Agent\n    postProcessorAgent agent.Agent\n}\n\n// NewStoryFlowAgent creates and configures the entire custom agent workflow.\n// It takes individual LLM agents as input and internally creates the necessary\n// workflow agents (loop, sequential), returning the final orchestrator agent.\nfunc NewStoryFlowAgent(\n    storyGenerator,\n    critic,\n    reviser,\n    grammarCheck,\n    toneCheck agent.Agent,\n) (agent.Agent, error) {\n    loopAgent, err := loopagent.New(loopagent.Config{\n        MaxIterations: 2,\n        AgentConfig: agent.Config{\n            Name:      \"CriticReviserLoop\",\n            SubAgents: []agent.Agent{critic, reviser},\n        },\n    })\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create loop agent: %w\", err)\n    }\n\n    sequentialAgent, err := sequentialagent.New(sequentialagent.Config{\n        AgentConfig: agent.Config{\n            Name:      \"PostProcessing\",\n            SubAgents: []agent.Agent{grammarCheck, toneCheck},\n        },\n    })\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create sequential agent: %w\", err)\n    }\n\n    // The StoryFlowAgent struct holds the agents needed for the Run method.\n    orchestrator := &StoryFlowAgent{\n        storyGenerator:     storyGenerator,\n        revisionLoopAgent:  loopAgent,\n        postProcessorAgent: sequentialAgent,\n    }\n\n    // agent.New creates the final agent, wiring up the Run method.\n    return agent.New(agent.Config{\n        Name:        \"StoryFlowAgent\",\n        Description: \"Orchestrates story generation, critique, revision, and checks.\",\n        SubAgents:   []agent.Agent{storyGenerator, loopAgent, sequentialAgent},\n        Run:         orchestrator.Run,\n    })\n}"}, {"language": "text", "code": "private final LlmAgent storyGenerator;\nprivate final LoopAgent loopAgent;\nprivate final SequentialAgent sequentialAgent;\n\npublic StoryFlowAgentExample(\n    String name, LlmAgent storyGenerator, LoopAgent loopAgent, SequentialAgent sequentialAgent) {\n  super(\n      name,\n      \"Orchestrates story generation, critique, revision, and checks.\",\n      List.of(storyGenerator, loopAgent, sequentialAgent),\n      null,\n      null);\n\n  this.storyGenerator = storyGenerator;\n  this.loopAgent = loopAgent;\n  this.sequentialAgent = sequentialAgent;\n}"}]}, {"heading_path": ["Part 2: Defining the Custom Execution Logic\u00b6"], "text": "Part 2: Defining the Custom Execution Logic \u00b6 Python Go Java This method orchestrates the sub-agents using standard Python async/await and control flow. @override async def _run_async_impl ( self , ctx : InvocationContext ) -> AsyncGenerator [ Event , None ]: \"\"\" Implements the custom orchestration logic for the story workflow. Uses the instance attributes assigned by Pydantic (e.g., self.story_generator). \"\"\" logger . info ( f \"[ { self . name } ] Starting story generation workflow.\" ) # 1. Initial Story Generation logger . info ( f \"[ { self . name } ] Running StoryGenerator...\" ) async for event in self . story_generator . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from StoryGenerator: { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event # Check if story was generated before proceeding if \"current_story\" not in ctx . session . state or not ctx . session . state [ \"current_story\" ]: logger . error ( f \"[ { self . name } ] Failed to generate initial story. Aborting workflow.\" ) return # Stop processing if initial story failed logger . info ( f \"[ { self . name } ] Story state after generator: { ctx . session . state . get ( 'current_story' ) } \" ) # 2. Critic-Reviser Loop logger . info ( f \"[ { self . name } ] Running CriticReviserLoop...\" ) # Use the loop_agent instance attribute assigned during init async for event in self . loop_agent . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from CriticReviserLoop: { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event logger . info ( f \"[ { self . name } ] Story state after loop: { ctx . session . state . get ( 'current_story' ) } \" ) # 3. Sequential Post-Processing (Grammar and Tone Check) logger . info ( f \"[ { self . name } ] Running PostProcessing...\" ) # Use the sequential_agent instance attribute assigned during init async for event in self . sequential_agent . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from PostProcessing: { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event # 4. Tone-Based Conditional Logic tone_check_result = ctx . session . state . get ( \"tone_check_result\" ) logger . info ( f \"[ { self . name } ] Tone check result: { tone_check_result } \" ) if tone_check_result == \"negative\" : logger . info ( f \"[ { self . name } ] Tone is negative. Regenerating story...\" ) async for event in self . story_generator . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from StoryGenerator (Regen): { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event else : logger . info ( f \"[ { self . name } ] Tone is not negative. Keeping current story.\" ) pass logger . info ( f \"[ { self . name } ] Workflow finished.\" ) Explanation of Logic: The initial story_generator runs. Its output is expected to be in ctx.session.state[\"current_story\"] . The loop_agent runs, which internally calls the critic and reviser sequentially for max_iterations times. They read/write current_story and criticism from/to the state. The sequential_agent runs, calling grammar_check then tone_check , reading current_story and writing grammar_suggestions and tone_check_result to the state. Custom Part: The if statement checks the tone_check_result from the state. If it's \"negative\", the story_generator is called again , overwriting the current_story in the state. Otherwise, the flow ends. The Run method orchestrates the sub-agents by calling their respective Run methods in a loop and yielding their events. // Run defines the custom execution logic for the StoryFlowAgent. func ( s * StoryFlowAgent ) Run ( ctx agent . InvocationContext ) iter . Seq2 [ * session . Event , error ] { return func ( yield func ( * session . Event , error ) bool ) { // Stage 1: Initial Story Generation for event , err := range s . storyGenerator . Run ( ctx ) { if err != nil { yield ( nil , fmt . Errorf ( \"story generator failed: %w\" , err )) return } if ! yield ( event , nil ) { return } } // Check if story was generated before proceeding currentStory , err := ctx . Session (). State (). Get ( \"current_story\" ) if err != nil || currentStory == \"\" { log . Println ( \"Failed to generate initial story. Aborting workflow.\" ) return } // Stage 2: Critic-Reviser Loop for event , err := range s . revisionLoopAgent . Run ( ctx ) { if err != nil { yield ( nil , fmt . Errorf ( \"loop agent failed: %w\" , err )) return } if ! yield ( event , nil ) { return } } // Stage 3: Post-Processing for event , err := range s . postProcessorAgent . Run ( ctx ) { if err != nil { yield ( nil , fmt . Errorf ( \"sequential agent failed: %w\" , err )) return } if ! yield ( event , nil ) { return } } // Stage 4: Conditional Regeneration toneResult , err := ctx . Session (). State (). Get ( \"tone_check_result\" ) if err != nil { log . Printf ( \"Could not read tone_check_result from state: %v. Assuming tone is not negative.\" , err ) return } if tone , ok := toneResult .( string ); ok && tone == \"negative\" { log . Println ( \"Tone is negative. Regenerating story...\" ) for event , err := range s . storyGenerator . Run ( ctx ) { if err != nil { yield ( nil , fmt . Errorf ( \"story regeneration failed: %w\" , err )) return } if ! yield ( event , nil ) { return } } } else { log . Println ( \"Tone is not negative. Keeping current story.\" ) } } } Explanation of Logic: The initial storyGenerator runs. Its output is expected to be in the session state under the key \"current_story\" . The revisionLoopAgent runs, which internally calls the critic and reviser sequentially for max_iterations times. They read/write current_story and criticism from/to the state. The postProcessorAgent runs, calling grammar_check then tone_check , reading current_story and writing grammar_suggestions and tone_check_result to the state. Custom Part: The code checks the tone_check_result from the state. If it's \"negative\", the story_generator is called again , overwriting the current_story in the state. Otherwise, the flow ends. The runAsyncImpl method orchestrates the sub-agents using RxJava's Flowable streams and operators for asynchronous control flow. @Override protected Flowable < Event > runAsyncImpl ( InvocationContext invocationContext ) { // Implements the custom orchestration logic for the story workflow. // Uses the instance attributes assigned by Pydantic (e.g., self.story_generator). logger . log ( Level . INFO , () -> String . format ( \"[%s] Starting story generation workflow.\" , name ())); // Stage 1. Initial Story Generation Flowable < Event > storyGenFlow = runStage ( storyGenerator , invocationContext , \"StoryGenerator\" ); // Stage 2: Critic-Reviser Loop (runs after story generation completes) Flowable < Event > criticReviserFlow = Flowable . defer (() -> { if ( ! isStoryGenerated ( invocationContext )) { logger . log ( Level . SEVERE ,() -> String . format ( \"[%s] Failed to generate initial story. Aborting after StoryGenerator.\" , name ())); return Flowable . empty (); // Stop further processing if no story } logger . log ( Level . INFO , () -> String . format ( \"[%s] Story state after generator: %s\" , name (), invocationContext . session (). state (). get ( \"current_story\" ))); return runStage ( loopAgent , invocationContext , \"CriticReviserLoop\" ); }); // Stage 3: Post-Processing (runs after critic-reviser loop completes) Flowable < Event > postProcessingFlow = Flowable . defer (() -> { logger . log ( Level . INFO , () -> String . format ( \"[%s] Story state after loop: %s\" , name (), invocationContext . session (). state (). get ( \"current_story\" ))); return runStage ( sequentialAgent , invocationContext , \"PostProcessing\" ); }); // Stage 4: Conditional Regeneration (runs after post-processing completes) Flowable < Event > conditionalRegenFlow = Flowable . defer (() -> { String toneCheckResult = ( String ) invocationContext . session (). state (). get ( \"tone_check_result\" ); logger . log ( Level . INFO , () -> String . format ( \"[%s] Tone check result: %s\" , name (), toneCheckResult )); if ( \"negative\" . equalsIgnoreCase ( toneCheckResult )) { logger . log ( Level . INFO , () -> String . format ( \"[%s] Tone is negative. Regenerating story...\" , name ())); return runStage ( storyGenerator , invocationContext , \"StoryGenerator (Regen)\" ); } else { logger . log ( Level . INFO , () -> String . format ( \"[%s] Tone is not negative. Keeping current story.\" , name ())); return Flowable . empty (); // No regeneration needed } }); return Flowable . concatArray ( storyGenFlow , criticReviserFlow , postProcessingFlow , conditionalRegenFlow ) . doOnComplete (() -> logger . log ( Level . INFO , () -> String . format ( \"[%s] Workflow finished.\" , name ()))); } // Helper method for a single agent run stage with logging private Flowable < Event > runStage ( BaseAgent agentToRun , InvocationContext ctx , String stageName ) { logger . log ( Level . INFO , () -> String . format ( \"[%s] Running %s...\" , name (), stageName )); return agentToRun . runAsync ( ctx ) . doOnNext ( event -> logger . log ( Level . INFO ,() -> String . format ( \"[%s] Event from %s: %s\" , name (), stageName , event . toJson ()))) . doOnError ( err -> logger . log ( Level . SEVERE , String . format ( \"[%s] Error in %s\" , name (), stageName ), err )) . doOnComplete (() -> logger . log ( Level . INFO , () -> String . format ( \"[%s] %s finished.\" , name (), stageName ))); } Explanation of Logic: The initial storyGenerator.runAsync(invocationContext) Flowable is executed. Its output is expected to be in invocationContext.session().state().get(\"current_story\") . The loopAgent's Flowable runs next (due to Flowable.concatArray and Flowable.defer ). The LoopAgent internally calls the critic and reviser sub-agents sequentially for up to maxIterations . They read/write current_story and criticism from/to the state. Then, the sequentialAgent's Flowable executes. It calls the grammar_check then tone_check , reading current_story and writing grammar_suggestions and tone_check_result to the state. Custom Part: After the sequentialAgent completes, logic within a Flowable.defer checks the \"tone_check_result\" from invocationContext.session().state() . If it's \"negative\", the storyGenerator Flowable is conditionally concatenated and executed again, overwriting \"current_story\". Otherwise, an empty Flowable is used, and the overall workflow proceeds to completion. ", "code_blocks": [{"language": "text", "code": "@override\nasync def _run_async_impl(\n    self, ctx: InvocationContext\n) -> AsyncGenerator[Event, None]:\n    \"\"\"\n    Implements the custom orchestration logic for the story workflow.\n    Uses the instance attributes assigned by Pydantic (e.g., self.story_generator).\n    \"\"\"\n    logger.info(f\"[{self.name}] Starting story generation workflow.\")\n\n    # 1. Initial Story Generation\n    logger.info(f\"[{self.name}] Running StoryGenerator...\")\n    async for event in self.story_generator.run_async(ctx):\n        logger.info(f\"[{self.name}] Event from StoryGenerator: {event.model_dump_json(indent=2, exclude_none=True)}\")\n        yield event\n\n    # Check if story was generated before proceeding\n    if \"current_story\" not in ctx.session.state or not ctx.session.state[\"current_story\"]:\n         logger.error(f\"[{self.name}] Failed to generate initial story. Aborting workflow.\")\n         return # Stop processing if initial story failed\n\n    logger.info(f\"[{self.name}] Story state after generator: {ctx.session.state.get('current_story')}\")\n\n\n    # 2. Critic-Reviser Loop\n    logger.info(f\"[{self.name}] Running CriticReviserLoop...\")\n    # Use the loop_agent instance attribute assigned during init\n    async for event in self.loop_agent.run_async(ctx):\n        logger.info(f\"[{self.name}] Event from CriticReviserLoop: {event.model_dump_json(indent=2, exclude_none=True)}\")\n        yield event\n\n    logger.info(f\"[{self.name}] Story state after loop: {ctx.session.state.get('current_story')}\")\n\n    # 3. Sequential Post-Processing (Grammar and Tone Check)\n    logger.info(f\"[{self.name}] Running PostProcessing...\")\n    # Use the sequential_agent instance attribute assigned during init\n    async for event in self.sequential_agent.run_async(ctx):\n        logger.info(f\"[{self.name}] Event from PostProcessing: {event.model_dump_json(indent=2, exclude_none=True)}\")\n        yield event\n\n    # 4. Tone-Based Conditional Logic\n    tone_check_result = ctx.session.state.get(\"tone_check_result\")\n    logger.info(f\"[{self.name}] Tone check result: {tone_check_result}\")\n\n    if tone_check_result == \"negative\":\n        logger.info(f\"[{self.name}] Tone is negative. Regenerating story...\")\n        async for event in self.story_generator.run_async(ctx):\n            logger.info(f\"[{self.name}] Event from StoryGenerator (Regen): {event.model_dump_json(indent=2, exclude_none=True)}\")\n            yield event\n    else:\n        logger.info(f\"[{self.name}] Tone is not negative. Keeping current story.\")\n        pass\n\n    logger.info(f\"[{self.name}] Workflow finished.\")"}, {"language": "text", "code": "// Run defines the custom execution logic for the StoryFlowAgent.\nfunc (s *StoryFlowAgent) Run(ctx agent.InvocationContext) iter.Seq2[*session.Event, error] {\n    return func(yield func(*session.Event, error) bool) {\n        // Stage 1: Initial Story Generation\n        for event, err := range s.storyGenerator.Run(ctx) {\n            if err != nil {\n                yield(nil, fmt.Errorf(\"story generator failed: %w\", err))\n                return\n            }\n            if !yield(event, nil) {\n                return\n            }\n        }\n\n        // Check if story was generated before proceeding\n        currentStory, err := ctx.Session().State().Get(\"current_story\")\n        if err != nil || currentStory == \"\" {\n            log.Println(\"Failed to generate initial story. Aborting workflow.\")\n            return\n        }\n\n        // Stage 2: Critic-Reviser Loop\n        for event, err := range s.revisionLoopAgent.Run(ctx) {\n            if err != nil {\n                yield(nil, fmt.Errorf(\"loop agent failed: %w\", err))\n                return\n            }\n            if !yield(event, nil) {\n                return\n            }\n        }\n\n        // Stage 3: Post-Processing\n        for event, err := range s.postProcessorAgent.Run(ctx) {\n            if err != nil {\n                yield(nil, fmt.Errorf(\"sequential agent failed: %w\", err))\n                return\n            }\n            if !yield(event, nil) {\n                return\n            }\n        }\n\n        // Stage 4: Conditional Regeneration\n        toneResult, err := ctx.Session().State().Get(\"tone_check_result\")\n        if err != nil {\n            log.Printf(\"Could not read tone_check_result from state: %v. Assuming tone is not negative.\", err)\n            return\n        }\n\n        if tone, ok := toneResult.(string); ok && tone == \"negative\" {\n            log.Println(\"Tone is negative. Regenerating story...\")\n            for event, err := range s.storyGenerator.Run(ctx) {\n                if err != nil {\n                    yield(nil, fmt.Errorf(\"story regeneration failed: %w\", err))\n                    return\n                }\n                if !yield(event, nil) {\n                    return\n                }\n            }\n        } else {\n            log.Println(\"Tone is not negative. Keeping current story.\")\n        }\n    }\n}"}, {"language": "text", "code": "@Override\nprotected Flowable<Event> runAsyncImpl(InvocationContext invocationContext) {\n  // Implements the custom orchestration logic for the story workflow.\n  // Uses the instance attributes assigned by Pydantic (e.g., self.story_generator).\n  logger.log(Level.INFO, () -> String.format(\"[%s] Starting story generation workflow.\", name()));\n\n  // Stage 1. Initial Story Generation\n  Flowable<Event> storyGenFlow = runStage(storyGenerator, invocationContext, \"StoryGenerator\");\n\n  // Stage 2: Critic-Reviser Loop (runs after story generation completes)\n  Flowable<Event> criticReviserFlow = Flowable.defer(() -> {\n    if (!isStoryGenerated(invocationContext)) {\n      logger.log(Level.SEVERE,() ->\n          String.format(\"[%s] Failed to generate initial story. Aborting after StoryGenerator.\",\n              name()));\n      return Flowable.empty(); // Stop further processing if no story\n    }\n      logger.log(Level.INFO, () ->\n          String.format(\"[%s] Story state after generator: %s\",\n              name(), invocationContext.session().state().get(\"current_story\")));\n      return runStage(loopAgent, invocationContext, \"CriticReviserLoop\");\n  });\n\n  // Stage 3: Post-Processing (runs after critic-reviser loop completes)\n  Flowable<Event> postProcessingFlow = Flowable.defer(() -> {\n    logger.log(Level.INFO, () ->\n        String.format(\"[%s] Story state after loop: %s\",\n            name(), invocationContext.session().state().get(\"current_story\")));\n    return runStage(sequentialAgent, invocationContext, \"PostProcessing\");\n  });\n\n  // Stage 4: Conditional Regeneration (runs after post-processing completes)\n  Flowable<Event> conditionalRegenFlow = Flowable.defer(() -> {\n    String toneCheckResult = (String) invocationContext.session().state().get(\"tone_check_result\");\n    logger.log(Level.INFO, () -> String.format(\"[%s] Tone check result: %s\", name(), toneCheckResult));\n\n    if (\"negative\".equalsIgnoreCase(toneCheckResult)) {\n      logger.log(Level.INFO, () ->\n          String.format(\"[%s] Tone is negative. Regenerating story...\", name()));\n      return runStage(storyGenerator, invocationContext, \"StoryGenerator (Regen)\");\n    } else {\n      logger.log(Level.INFO, () ->\n          String.format(\"[%s] Tone is not negative. Keeping current story.\", name()));\n      return Flowable.empty(); // No regeneration needed\n    }\n  });\n\n  return Flowable.concatArray(storyGenFlow, criticReviserFlow, postProcessingFlow, conditionalRegenFlow)\n      .doOnComplete(() -> logger.log(Level.INFO, () -> String.format(\"[%s] Workflow finished.\", name())));\n}\n\n// Helper method for a single agent run stage with logging\nprivate Flowable<Event> runStage(BaseAgent agentToRun, InvocationContext ctx, String stageName) {\n  logger.log(Level.INFO, () -> String.format(\"[%s] Running %s...\", name(), stageName));\n  return agentToRun\n      .runAsync(ctx)\n      .doOnNext(event ->\n          logger.log(Level.INFO,() ->\n              String.format(\"[%s] Event from %s: %s\", name(), stageName, event.toJson())))\n      .doOnError(err ->\n          logger.log(Level.SEVERE,\n              String.format(\"[%s] Error in %s\", name(), stageName), err))\n      .doOnComplete(() ->\n          logger.log(Level.INFO, () ->\n              String.format(\"[%s] %s finished.\", name(), stageName)));\n}"}]}, {"heading_path": ["Part 3: Defining the LLM Sub-Agents\u00b6"], "text": "Part 3: Defining the LLM Sub-Agents \u00b6 These are standard LlmAgent definitions, responsible for specific tasks. Their output key parameter is crucial for placing results into the session.state where other agents or the custom orchestrator can access them. Direct State Injection in Instructions Notice the story_generator 's instruction. The {var} syntax is a placeholder. Before the instruction is sent to the LLM, the ADK framework automatically replaces (Example: {topic} ) with the value of session.state['topic'] . This is the recommended way to provide context to an agent, using templating in the instructions. For more details, see the State documentation . Python Java Go GEMINI_2_FLASH = \"gemini-2.0-flash\" # Define model constant # --- Define the individual LLM agents --- story_generator = LlmAgent ( name = \"StoryGenerator\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a story writer. Write a short story (around 100 words), on the following topic: {topic} \"\"\" , input_schema = None , output_key = \"current_story\" , # Key for storing output in session state ) critic = LlmAgent ( name = \"Critic\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a story critic. Review the story provided: {{current_story}}. Provide 1-2 sentences of constructive criticism on how to improve it. Focus on plot or character.\"\"\" , input_schema = None , output_key = \"criticism\" , # Key for storing criticism in session state ) reviser = LlmAgent ( name = \"Reviser\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a story reviser. Revise the story provided: {{current_story}}, based on the criticism in {{criticism}}. Output only the revised story.\"\"\" , input_schema = None , output_key = \"current_story\" , # Overwrites the original story ) grammar_check = LlmAgent ( name = \"GrammarCheck\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a grammar checker. Check the grammar of the story provided: {current_story} . Output only the suggested corrections as a list, or output 'Grammar is good!' if there are no errors.\"\"\" , input_schema = None , output_key = \"grammar_suggestions\" , ) tone_check = LlmAgent ( name = \"ToneCheck\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a tone analyzer. Analyze the tone of the story provided: {current_story} . Output only one word: 'positive' if the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral' otherwise.\"\"\" , input_schema = None , output_key = \"tone_check_result\" , # This agent's output determines the conditional flow ) // --- Define the individual LLM agents --- LlmAgent storyGenerator = LlmAgent . builder () . name ( \"StoryGenerator\" ) . model ( MODEL_NAME ) . description ( \"Generates the initial story.\" ) . instruction ( \"\"\" You are a story writer. Write a short story (around 100 words) about a cat, based on the topic: {topic} \"\"\" ) . inputSchema ( null ) . outputKey ( \"current_story\" ) // Key for storing output in session state . build (); LlmAgent critic = LlmAgent . builder () . name ( \"Critic\" ) . model ( MODEL_NAME ) . description ( \"Critiques the story.\" ) . instruction ( \"\"\" You are a story critic. Review the story: {current_story}. Provide 1-2 sentences of constructive criticism on how to improve it. Focus on plot or character. \"\"\" ) . inputSchema ( null ) . outputKey ( \"criticism\" ) // Key for storing criticism in session state . build (); LlmAgent reviser = LlmAgent . builder () . name ( \"Reviser\" ) . model ( MODEL_NAME ) . description ( \"Revises the story based on criticism.\" ) . instruction ( \"\"\" You are a story reviser. Revise the story: {current_story}, based on the criticism: {criticism}. Output only the revised story. \"\"\" ) . inputSchema ( null ) . outputKey ( \"current_story\" ) // Overwrites the original story . build (); LlmAgent grammarCheck = LlmAgent . builder () . name ( \"GrammarCheck\" ) . model ( MODEL_NAME ) . description ( \"Checks grammar and suggests corrections.\" ) . instruction ( \"\"\" You are a grammar checker. Check the grammar of the story: {current_story}. Output only the suggested corrections as a list, or output 'Grammar is good!' if there are no errors. \"\"\" ) . outputKey ( \"grammar_suggestions\" ) . build (); LlmAgent toneCheck = LlmAgent . builder () . name ( \"ToneCheck\" ) . model ( MODEL_NAME ) . description ( \"Analyzes the tone of the story.\" ) . instruction ( \"\"\" You are a tone analyzer. Analyze the tone of the story: {current_story}. Output only one word: 'positive' if the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral' otherwise. \"\"\" ) . outputKey ( \"tone_check_result\" ) // This agent's output determines the conditional flow . build (); LoopAgent loopAgent = LoopAgent . builder () . name ( \"CriticReviserLoop\" ) . description ( \"Iteratively critiques and revises the story.\" ) . subAgents ( critic , reviser ) . maxIterations ( 2 ) . build (); SequentialAgent sequentialAgent = SequentialAgent . builder () . name ( \"PostProcessing\" ) . description ( \"Performs grammar and tone checks sequentially.\" ) . subAgents ( grammarCheck , toneCheck ) . build (); // --- Define the individual LLM agents --- storyGenerator , err := llmagent . New ( llmagent . Config { Name : \"StoryGenerator\" , Model : model , Description : \"Generates the initial story.\" , Instruction : \"You are a story writer. Write a short story (around 100 words) about a cat, based on the topic: {topic}\" , OutputKey : \"current_story\" , }) if err != nil { log . Fatalf ( \"Failed to create StoryGenerator agent: %v\" , err ) } critic , err := llmagent . New ( llmagent . Config { Name : \"Critic\" , Model : model , Description : \"Critiques the story.\" , Instruction : \"You are a story critic. Review the story: {current_story}. Provide 1-2 sentences of constructive criticism on how to improve it. Focus on plot or character.\" , OutputKey : \"criticism\" , }) if err != nil { log . Fatalf ( \"Failed to create Critic agent: %v\" , err ) } reviser , err := llmagent . New ( llmagent . Config { Name : \"Reviser\" , Model : model , Description : \"Revises the story based on criticism.\" , Instruction : \"You are a story reviser. Revise the story: {current_story}, based on the criticism: {criticism}. Output only the revised story.\" , OutputKey : \"current_story\" , }) if err != nil { log . Fatalf ( \"Failed to create Reviser agent: %v\" , err ) } grammarCheck , err := llmagent . New ( llmagent . Config { Name : \"GrammarCheck\" , Model : model , Description : \"Checks grammar and suggests corrections.\" , Instruction : \"You are a grammar checker. Check the grammar of the story: {current_story}. Output only the suggested corrections as a list, or output 'Grammar is good!' if there are no errors.\" , OutputKey : \"grammar_suggestions\" , }) if err != nil { log . Fatalf ( \"Failed to create GrammarCheck agent: %v\" , err ) } toneCheck , err := llmagent . New ( llmagent . Config { Name : \"ToneCheck\" , Model : model , Description : \"Analyzes the tone of the story.\" , Instruction : \"You are a tone analyzer. Analyze the tone of the story: {current_story}. Output only one word: 'positive' if the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral' otherwise.\" , OutputKey : \"tone_check_result\" , }) if err != nil { log . Fatalf ( \"Failed to create ToneCheck agent: %v\" , err ) } ", "code_blocks": [{"language": "text", "code": "GEMINI_2_FLASH = \"gemini-2.0-flash\" # Define model constant\n# --- Define the individual LLM agents ---\nstory_generator = LlmAgent(\n    name=\"StoryGenerator\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a story writer. Write a short story (around 100 words), on the following topic: {topic}\"\"\",\n    input_schema=None,\n    output_key=\"current_story\",  # Key for storing output in session state\n)\n\ncritic = LlmAgent(\n    name=\"Critic\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a story critic. Review the story provided: {{current_story}}. Provide 1-2 sentences of constructive criticism\non how to improve it. Focus on plot or character.\"\"\",\n    input_schema=None,\n    output_key=\"criticism\",  # Key for storing criticism in session state\n)\n\nreviser = LlmAgent(\n    name=\"Reviser\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a story reviser. Revise the story provided: {{current_story}}, based on the criticism in\n{{criticism}}. Output only the revised story.\"\"\",\n    input_schema=None,\n    output_key=\"current_story\",  # Overwrites the original story\n)\n\ngrammar_check = LlmAgent(\n    name=\"GrammarCheck\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a grammar checker. Check the grammar of the story provided: {current_story}. Output only the suggested\ncorrections as a list, or output 'Grammar is good!' if there are no errors.\"\"\",\n    input_schema=None,\n    output_key=\"grammar_suggestions\",\n)\n\ntone_check = LlmAgent(\n    name=\"ToneCheck\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a tone analyzer. Analyze the tone of the story provided: {current_story}. Output only one word: 'positive' if\nthe tone is generally positive, 'negative' if the tone is generally negative, or 'neutral'\notherwise.\"\"\",\n    input_schema=None,\n    output_key=\"tone_check_result\", # This agent's output determines the conditional flow\n)"}, {"language": "text", "code": "// --- Define the individual LLM agents ---\nLlmAgent storyGenerator =\n    LlmAgent.builder()\n        .name(\"StoryGenerator\")\n        .model(MODEL_NAME)\n        .description(\"Generates the initial story.\")\n        .instruction(\n            \"\"\"\n          You are a story writer. Write a short story (around 100 words) about a cat,\n          based on the topic: {topic}\n          \"\"\")\n        .inputSchema(null)\n        .outputKey(\"current_story\") // Key for storing output in session state\n        .build();\n\nLlmAgent critic =\n    LlmAgent.builder()\n        .name(\"Critic\")\n        .model(MODEL_NAME)\n        .description(\"Critiques the story.\")\n        .instruction(\n            \"\"\"\n          You are a story critic. Review the story: {current_story}. Provide 1-2 sentences of constructive criticism\n          on how to improve it. Focus on plot or character.\n          \"\"\")\n        .inputSchema(null)\n        .outputKey(\"criticism\") // Key for storing criticism in session state\n        .build();\n\nLlmAgent reviser =\n    LlmAgent.builder()\n        .name(\"Reviser\")\n        .model(MODEL_NAME)\n        .description(\"Revises the story based on criticism.\")\n        .instruction(\n            \"\"\"\n          You are a story reviser. Revise the story: {current_story}, based on the criticism: {criticism}. Output only the revised story.\n          \"\"\")\n        .inputSchema(null)\n        .outputKey(\"current_story\") // Overwrites the original story\n        .build();\n\nLlmAgent grammarCheck =\n    LlmAgent.builder()\n        .name(\"GrammarCheck\")\n        .model(MODEL_NAME)\n        .description(\"Checks grammar and suggests corrections.\")\n        .instruction(\n            \"\"\"\n           You are a grammar checker. Check the grammar of the story: {current_story}. Output only the suggested\n           corrections as a list, or output 'Grammar is good!' if there are no errors.\n           \"\"\")\n        .outputKey(\"grammar_suggestions\")\n        .build();\n\nLlmAgent toneCheck =\n    LlmAgent.builder()\n        .name(\"ToneCheck\")\n        .model(MODEL_NAME)\n        .description(\"Analyzes the tone of the story.\")\n        .instruction(\n            \"\"\"\n          You are a tone analyzer. Analyze the tone of the story: {current_story}. Output only one word: 'positive' if\n          the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral'\n          otherwise.\n          \"\"\")\n        .outputKey(\"tone_check_result\") // This agent's output determines the conditional flow\n        .build();\n\nLoopAgent loopAgent =\n    LoopAgent.builder()\n        .name(\"CriticReviserLoop\")\n        .description(\"Iteratively critiques and revises the story.\")\n        .subAgents(critic, reviser)\n        .maxIterations(2)\n        .build();\n\nSequentialAgent sequentialAgent =\n    SequentialAgent.builder()\n        .name(\"PostProcessing\")\n        .description(\"Performs grammar and tone checks sequentially.\")\n        .subAgents(grammarCheck, toneCheck)\n        .build();"}, {"language": "text", "code": "// --- Define the individual LLM agents ---\nstoryGenerator, err := llmagent.New(llmagent.Config{\n    Name:        \"StoryGenerator\",\n    Model:       model,\n    Description: \"Generates the initial story.\",\n    Instruction: \"You are a story writer. Write a short story (around 100 words) about a cat, based on the topic: {topic}\",\n    OutputKey:   \"current_story\",\n})\nif err != nil {\n    log.Fatalf(\"Failed to create StoryGenerator agent: %v\", err)\n}\n\ncritic, err := llmagent.New(llmagent.Config{\n    Name:        \"Critic\",\n    Model:       model,\n    Description: \"Critiques the story.\",\n    Instruction: \"You are a story critic. Review the story: {current_story}. Provide 1-2 sentences of constructive criticism on how to improve it. Focus on plot or character.\",\n    OutputKey:   \"criticism\",\n})\nif err != nil {\n    log.Fatalf(\"Failed to create Critic agent: %v\", err)\n}\n\nreviser, err := llmagent.New(llmagent.Config{\n    Name:        \"Reviser\",\n    Model:       model,\n    Description: \"Revises the story based on criticism.\",\n    Instruction: \"You are a story reviser. Revise the story: {current_story}, based on the criticism: {criticism}. Output only the revised story.\",\n    OutputKey:   \"current_story\",\n})\nif err != nil {\n    log.Fatalf(\"Failed to create Reviser agent: %v\", err)\n}\n\ngrammarCheck, err := llmagent.New(llmagent.Config{\n    Name:        \"GrammarCheck\",\n    Model:       model,\n    Description: \"Checks grammar and suggests corrections.\",\n    Instruction: \"You are a grammar checker. Check the grammar of the story: {current_story}. Output only the suggested corrections as a list, or output 'Grammar is good!' if there are no errors.\",\n    OutputKey:   \"grammar_suggestions\",\n})\nif err != nil {\n    log.Fatalf(\"Failed to create GrammarCheck agent: %v\", err)\n}\n\ntoneCheck, err := llmagent.New(llmagent.Config{\n    Name:        \"ToneCheck\",\n    Model:       model,\n    Description: \"Analyzes the tone of the story.\",\n    Instruction: \"You are a tone analyzer. Analyze the tone of the story: {current_story}. Output only one word: 'positive' if the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral' otherwise.\",\n    OutputKey:   \"tone_check_result\",\n})\nif err != nil {\n    log.Fatalf(\"Failed to create ToneCheck agent: %v\", err)\n}"}]}, {"heading_path": ["Part 4: Instantiating and Running the custom agent\u00b6"], "text": "Part 4: Instantiating and Running the custom agent \u00b6 Finally, you instantiate your StoryFlowAgent and use the Runner as usual. Python Go Java # --- Create the custom agent instance --- story_flow_agent = StoryFlowAgent ( name = \"StoryFlowAgent\" , story_generator = story_generator , critic = critic , reviser = reviser , grammar_check = grammar_check , tone_check = tone_check , ) INITIAL_STATE = { \"topic\" : \"a brave kitten exploring a haunted house\" } # --- Setup Runner and Session --- async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID , state = INITIAL_STATE ) logger . info ( f \"Initial session state: { session . state } \" ) runner = Runner ( agent = story_flow_agent , # Pass the custom orchestrator agent app_name = APP_NAME , session_service = session_service ) return session_service , runner # --- Function to Interact with the Agent --- async def call_agent_async ( user_input_topic : str ): \"\"\" Sends a new topic to the agent (overwriting the initial one if needed) and runs the workflow. \"\"\" session_service , runner = await setup_session_and_runner () current_session = await session_service . get_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) if not current_session : logger . error ( \"Session not found!\" ) return current_session . state [ \"topic\" ] = user_input_topic logger . info ( f \"Updated session state topic to: { user_input_topic } \" ) content = types . Content ( role = 'user' , parts = [ types . Part ( text = f \"Generate a story about: { user_input_topic } \" )]) events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) final_response = \"No final response captured.\" async for event in events : if event . is_final_response () and event . content and event . content . parts : logger . info ( f \"Potential final response from [ { event . author } ]: { event . content . parts [ 0 ] . text } \" ) final_response = event . content . parts [ 0 ] . text print ( \" \\n --- Agent Interaction Result ---\" ) print ( \"Agent Final Response: \" , final_response ) final_session = await session_service . get_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) print ( \"Final Session State:\" ) import json print ( json . dumps ( final_session . state , indent = 2 )) print ( \"------------------------------- \\n \" ) # --- Run the Agent --- # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"a lonely robot finding a friend in a junkyard\" ) // Instantiate the custom agent, which encapsulates the workflow agents. storyFlowAgent , err := NewStoryFlowAgent ( storyGenerator , critic , reviser , grammarCheck , toneCheck , ) if err != nil { log . Fatalf ( \"Failed to create story flow agent: %v\" , err ) } // --- Run the Agent --- sessionService := session . InMemoryService () initialState := map [ string ] any { \"topic\" : \"a brave kitten exploring a haunted house\" , } sessionInstance , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , State : initialState , }) if err != nil { log . Fatalf ( \"Failed to create session: %v\" , err ) } userTopic := \"a lonely robot finding a friend in a junkyard\" r , err := runner . New ( runner . Config { AppName : appName , Agent : storyFlowAgent , SessionService : sessionService , }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } input := genai . NewContentFromText ( \"Generate a story about: \" + userTopic , genai . RoleUser ) events := r . Run ( ctx , userID , sessionInstance . Session . ID (), input , agent . RunConfig { StreamingMode : agent . StreamingModeSSE , }) var finalResponse string for event , err := range events { if err != nil { log . Fatalf ( \"An error occurred during agent execution: %v\" , err ) } for _ , part := range event . Content . Parts { // Accumulate text from all parts of the final response. finalResponse += part . Text } } fmt . Println ( \"\\n--- Agent Interaction Result ---\" ) fmt . Println ( \"Agent Final Response: \" + finalResponse ) finalSession , err := sessionService . Get ( ctx , & session . GetRequest { UserID : userID , AppName : appName , SessionID : sessionInstance . Session . ID (), }) if err != nil { log . Fatalf ( \"Failed to retrieve final session: %v\" , err ) } fmt . Println ( \"Final Session State:\" , finalSession . Session . State ()) } // --- Function to Interact with the Agent --- // Sends a new topic to the agent (overwriting the initial one if needed) // and runs the workflow. public static void runAgent ( StoryFlowAgentExample agent , String userTopic ) { // --- Setup Runner and Session --- InMemoryRunner runner = new InMemoryRunner ( agent ); Map < String , Object > initialState = new HashMap <> (); initialState . put ( \"topic\" , \"a brave kitten exploring a haunted house\" ); Session session = runner . sessionService () . createSession ( APP_NAME , USER_ID , new ConcurrentHashMap <> ( initialState ), SESSION_ID ) . blockingGet (); logger . log ( Level . INFO , () -> String . format ( \"Initial session state: %s\" , session . state ())); session . state (). put ( \"topic\" , userTopic ); // Update the state in the retrieved session logger . log ( Level . INFO , () -> String . format ( \"Updated session state topic to: %s\" , userTopic )); Content userMessage = Content . fromParts ( Part . fromText ( \"Generate a story about: \" + userTopic )); // Use the modified session object for the run Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); final String [] finalResponse = { \"No final response captured.\" }; eventStream . blockingForEach ( event -> { if ( event . finalResponse () && event . content (). isPresent ()) { String author = event . author () != null ? event . author () : \"UNKNOWN_AUTHOR\" ; Optional < String > textOpt = event . content () . flatMap ( Content :: parts ) . filter ( parts -> ! parts . isEmpty ()) . map ( parts -> parts . get ( 0 ). text (). orElse ( \"\" )); logger . log ( Level . INFO , () -> String . format ( \"Potential final response from [%s]: %s\" , author , textOpt . orElse ( \"N/A\" ))); textOpt . ifPresent ( text -> finalResponse [ 0 ] = text ); } }); System . out . println ( \"\\n--- Agent Interaction Result ---\" ); System . out . println ( \"Agent Final Response: \" + finalResponse [ 0 ] ); // Retrieve session again to see the final state after the run Session finalSession = runner . sessionService () . getSession ( APP_NAME , USER_ID , SESSION_ID , Optional . empty ()) . blockingGet (); assert finalSession != null ; System . out . println ( \"Final Session State:\" + finalSession . state ()); System . out . println ( \"-------------------------------\\n\" ); } (Note: The full runnable code, including imports and execution logic, can be found linked below.) ", "code_blocks": [{"language": "text", "code": "# --- Create the custom agent instance ---\nstory_flow_agent = StoryFlowAgent(\n    name=\"StoryFlowAgent\",\n    story_generator=story_generator,\n    critic=critic,\n    reviser=reviser,\n    grammar_check=grammar_check,\n    tone_check=tone_check,\n)\n\nINITIAL_STATE = {\"topic\": \"a brave kitten exploring a haunted house\"}\n\n# --- Setup Runner and Session ---\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID, state=INITIAL_STATE)\n    logger.info(f\"Initial session state: {session.state}\")\n    runner = Runner(\n        agent=story_flow_agent, # Pass the custom orchestrator agent\n        app_name=APP_NAME,\n        session_service=session_service\n    )\n    return session_service, runner\n\n# --- Function to Interact with the Agent ---\nasync def call_agent_async(user_input_topic: str):\n    \"\"\"\n    Sends a new topic to the agent (overwriting the initial one if needed)\n    and runs the workflow.\n    \"\"\"\n\n    session_service, runner = await setup_session_and_runner()\n\n    current_session = await session_service.get_session(app_name=APP_NAME, \n                                                  user_id=USER_ID, \n                                                  session_id=SESSION_ID)\n    if not current_session:\n        logger.error(\"Session not found!\")\n        return\n\n    current_session.state[\"topic\"] = user_input_topic\n    logger.info(f\"Updated session state topic to: {user_input_topic}\")\n\n    content = types.Content(role='user', parts=[types.Part(text=f\"Generate a story about: {user_input_topic}\")])\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    final_response = \"No final response captured.\"\n    async for event in events:\n        if event.is_final_response() and event.content and event.content.parts:\n            logger.info(f\"Potential final response from [{event.author}]: {event.content.parts[0].text}\")\n            final_response = event.content.parts[0].text\n\n    print(\"\\n--- Agent Interaction Result ---\")\n    print(\"Agent Final Response: \", final_response)\n\n    final_session = await session_service.get_session(app_name=APP_NAME, \n                                                user_id=USER_ID, \n                                                session_id=SESSION_ID)\n    print(\"Final Session State:\")\n    import json\n    print(json.dumps(final_session.state, indent=2))\n    print(\"-------------------------------\\n\")\n\n# --- Run the Agent ---\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"a lonely robot finding a friend in a junkyard\")"}, {"language": "text", "code": "// Instantiate the custom agent, which encapsulates the workflow agents.\n    storyFlowAgent, err := NewStoryFlowAgent(\n        storyGenerator,\n        critic,\n        reviser,\n        grammarCheck,\n        toneCheck,\n    )\n    if err != nil {\n        log.Fatalf(\"Failed to create story flow agent: %v\", err)\n    }\n\n    // --- Run the Agent ---\n    sessionService := session.InMemoryService()\n    initialState := map[string]any{\n        \"topic\": \"a brave kitten exploring a haunted house\",\n    }\n    sessionInstance, err := sessionService.Create(ctx, &session.CreateRequest{\n        AppName: appName,\n        UserID:  userID,\n        State:   initialState,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create session: %v\", err)\n    }\n\n    userTopic := \"a lonely robot finding a friend in a junkyard\"\n\n    r, err := runner.New(runner.Config{\n        AppName:        appName,\n        Agent:          storyFlowAgent,\n        SessionService: sessionService,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create runner: %v\", err)\n    }\n\n    input := genai.NewContentFromText(\"Generate a story about: \"+userTopic, genai.RoleUser)\n    events := r.Run(ctx, userID, sessionInstance.Session.ID(), input, agent.RunConfig{\n        StreamingMode: agent.StreamingModeSSE,\n    })\n\n    var finalResponse string\n    for event, err := range events {\n        if err != nil {\n            log.Fatalf(\"An error occurred during agent execution: %v\", err)\n        }\n\n        for _, part := range event.Content.Parts {\n            // Accumulate text from all parts of the final response.\n            finalResponse += part.Text\n        }\n    }\n\n    fmt.Println(\"\\n--- Agent Interaction Result ---\")\n    fmt.Println(\"Agent Final Response: \" + finalResponse)\n\n    finalSession, err := sessionService.Get(ctx, &session.GetRequest{\n        UserID:    userID,\n        AppName:   appName,\n        SessionID: sessionInstance.Session.ID(),\n    })\n\n    if err != nil {\n        log.Fatalf(\"Failed to retrieve final session: %v\", err)\n    }\n\n    fmt.Println(\"Final Session State:\", finalSession.Session.State())\n}"}, {"language": "text", "code": "// --- Function to Interact with the Agent ---\n// Sends a new topic to the agent (overwriting the initial one if needed)\n// and runs the workflow.\npublic static void runAgent(StoryFlowAgentExample agent, String userTopic) {\n  // --- Setup Runner and Session ---\n  InMemoryRunner runner = new InMemoryRunner(agent);\n\n  Map<String, Object> initialState = new HashMap<>();\n  initialState.put(\"topic\", \"a brave kitten exploring a haunted house\");\n\n  Session session =\n      runner\n          .sessionService()\n          .createSession(APP_NAME, USER_ID, new ConcurrentHashMap<>(initialState), SESSION_ID)\n          .blockingGet();\n  logger.log(Level.INFO, () -> String.format(\"Initial session state: %s\", session.state()));\n\n  session.state().put(\"topic\", userTopic); // Update the state in the retrieved session\n  logger.log(Level.INFO, () -> String.format(\"Updated session state topic to: %s\", userTopic));\n\n  Content userMessage = Content.fromParts(Part.fromText(\"Generate a story about: \" + userTopic));\n  // Use the modified session object for the run\n  Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n  final String[] finalResponse = {\"No final response captured.\"};\n  eventStream.blockingForEach(\n      event -> {\n        if (event.finalResponse() && event.content().isPresent()) {\n          String author = event.author() != null ? event.author() : \"UNKNOWN_AUTHOR\";\n          Optional<String> textOpt =\n              event\n                  .content()\n                  .flatMap(Content::parts)\n                  .filter(parts -> !parts.isEmpty())\n                  .map(parts -> parts.get(0).text().orElse(\"\"));\n\n          logger.log(Level.INFO, () ->\n              String.format(\"Potential final response from [%s]: %s\", author, textOpt.orElse(\"N/A\")));\n          textOpt.ifPresent(text -> finalResponse[0] = text);\n        }\n      });\n\n  System.out.println(\"\\n--- Agent Interaction Result ---\");\n  System.out.println(\"Agent Final Response: \" + finalResponse[0]);\n\n  // Retrieve session again to see the final state after the run\n  Session finalSession =\n      runner\n          .sessionService()\n          .getSession(APP_NAME, USER_ID, SESSION_ID, Optional.empty())\n          .blockingGet();\n\n  assert finalSession != null;\n  System.out.println(\"Final Session State:\" + finalSession.state());\n  System.out.println(\"-------------------------------\\n\");\n}"}]}, {"heading_path": ["Full Code Example\u00b6"], "text": "Full Code Example \u00b6 Storyflow Agent Python Go Java # Full runnable code for the StoryFlowAgent example # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import logging from typing import AsyncGenerator from typing_extensions import override from google.adk.agents import LlmAgent , BaseAgent , LoopAgent , SequentialAgent from google.adk.agents.invocation_context import InvocationContext from google.genai import types from google.adk.sessions import InMemorySessionService from google.adk.runners import Runner from google.adk.events import Event from pydantic import BaseModel , Field # --- Constants --- APP_NAME = \"story_app\" USER_ID = \"12345\" SESSION_ID = \"123344\" GEMINI_2_FLASH = \"gemini-2.0-flash\" # --- Configure Logging --- logging . basicConfig ( level = logging . INFO ) logger = logging . getLogger ( __name__ ) # --- Custom Orchestrator Agent --- class StoryFlowAgent ( BaseAgent ): \"\"\" Custom agent for a story generation and refinement workflow. This agent orchestrates a sequence of LLM agents to generate a story, critique it, revise it, check grammar and tone, and potentially regenerate the story if the tone is negative. \"\"\" # --- Field Declarations for Pydantic --- # Declare the agents passed during initialization as class attributes with type hints story_generator : LlmAgent critic : LlmAgent reviser : LlmAgent grammar_check : LlmAgent tone_check : LlmAgent loop_agent : LoopAgent sequential_agent : SequentialAgent # model_config allows setting Pydantic configurations if needed, e.g., arbitrary_types_allowed model_config = { \"arbitrary_types_allowed\" : True } def __init__ ( self , name : str , story_generator : LlmAgent , critic : LlmAgent , reviser : LlmAgent , grammar_check : LlmAgent , tone_check : LlmAgent , ): \"\"\" Initializes the StoryFlowAgent. Args: name: The name of the agent. story_generator: An LlmAgent to generate the initial story. critic: An LlmAgent to critique the story. reviser: An LlmAgent to revise the story based on criticism. grammar_check: An LlmAgent to check the grammar. tone_check: An LlmAgent to analyze the tone. \"\"\" # Create internal agents *before* calling super().__init__ loop_agent = LoopAgent ( name = \"CriticReviserLoop\" , sub_agents = [ critic , reviser ], max_iterations = 2 ) sequential_agent = SequentialAgent ( name = \"PostProcessing\" , sub_agents = [ grammar_check , tone_check ] ) # Define the sub_agents list for the framework sub_agents_list = [ story_generator , loop_agent , sequential_agent , ] # Pydantic will validate and assign them based on the class annotations. super () . __init__ ( name = name , story_generator = story_generator , critic = critic , reviser = reviser , grammar_check = grammar_check , tone_check = tone_check , loop_agent = loop_agent , sequential_agent = sequential_agent , sub_agents = sub_agents_list , # Pass the sub_agents list directly ) @override async def _run_async_impl ( self , ctx : InvocationContext ) -> AsyncGenerator [ Event , None ]: \"\"\" Implements the custom orchestration logic for the story workflow. Uses the instance attributes assigned by Pydantic (e.g., self.story_generator). \"\"\" logger . info ( f \"[ { self . name } ] Starting story generation workflow.\" ) # 1. Initial Story Generation logger . info ( f \"[ { self . name } ] Running StoryGenerator...\" ) async for event in self . story_generator . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from StoryGenerator: { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event # Check if story was generated before proceeding if \"current_story\" not in ctx . session . state or not ctx . session . state [ \"current_story\" ]: logger . error ( f \"[ { self . name } ] Failed to generate initial story. Aborting workflow.\" ) return # Stop processing if initial story failed logger . info ( f \"[ { self . name } ] Story state after generator: { ctx . session . state . get ( 'current_story' ) } \" ) # 2. Critic-Reviser Loop logger . info ( f \"[ { self . name } ] Running CriticReviserLoop...\" ) # Use the loop_agent instance attribute assigned during init async for event in self . loop_agent . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from CriticReviserLoop: { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event logger . info ( f \"[ { self . name } ] Story state after loop: { ctx . session . state . get ( 'current_story' ) } \" ) # 3. Sequential Post-Processing (Grammar and Tone Check) logger . info ( f \"[ { self . name } ] Running PostProcessing...\" ) # Use the sequential_agent instance attribute assigned during init async for event in self . sequential_agent . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from PostProcessing: { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event # 4. Tone-Based Conditional Logic tone_check_result = ctx . session . state . get ( \"tone_check_result\" ) logger . info ( f \"[ { self . name } ] Tone check result: { tone_check_result } \" ) if tone_check_result == \"negative\" : logger . info ( f \"[ { self . name } ] Tone is negative. Regenerating story...\" ) async for event in self . story_generator . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from StoryGenerator (Regen): { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event else : logger . info ( f \"[ { self . name } ] Tone is not negative. Keeping current story.\" ) pass logger . info ( f \"[ { self . name } ] Workflow finished.\" ) # --- Define the individual LLM agents --- story_generator = LlmAgent ( name = \"StoryGenerator\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a story writer. Write a short story (around 100 words), on the following topic: {topic} \"\"\" , input_schema = None , output_key = \"current_story\" , # Key for storing output in session state ) critic = LlmAgent ( name = \"Critic\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a story critic. Review the story provided: {{current_story}}. Provide 1-2 sentences of constructive criticism on how to improve it. Focus on plot or character.\"\"\" , input_schema = None , output_key = \"criticism\" , # Key for storing criticism in session state ) reviser = LlmAgent ( name = \"Reviser\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a story reviser. Revise the story provided: {{current_story}}, based on the criticism in {{criticism}}. Output only the revised story.\"\"\" , input_schema = None , output_key = \"current_story\" , # Overwrites the original story ) grammar_check = LlmAgent ( name = \"GrammarCheck\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a grammar checker. Check the grammar of the story provided: {current_story} . Output only the suggested corrections as a list, or output 'Grammar is good!' if there are no errors.\"\"\" , input_schema = None , output_key = \"grammar_suggestions\" , ) tone_check = LlmAgent ( name = \"ToneCheck\" , model = GEMINI_2_FLASH , instruction = \"\"\"You are a tone analyzer. Analyze the tone of the story provided: {current_story} . Output only one word: 'positive' if the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral' otherwise.\"\"\" , input_schema = None , output_key = \"tone_check_result\" , # This agent's output determines the conditional flow ) # --- Create the custom agent instance --- story_flow_agent = StoryFlowAgent ( name = \"StoryFlowAgent\" , story_generator = story_generator , critic = critic , reviser = reviser , grammar_check = grammar_check , tone_check = tone_check , ) INITIAL_STATE = { \"topic\" : \"a brave kitten exploring a haunted house\" } # --- Setup Runner and Session --- async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID , state = INITIAL_STATE ) logger . info ( f \"Initial session state: { session . state } \" ) runner = Runner ( agent = story_flow_agent , # Pass the custom orchestrator agent app_name = APP_NAME , session_service = session_service ) return session_service , runner # --- Function to Interact with the Agent --- async def call_agent_async ( user_input_topic : str ): \"\"\" Sends a new topic to the agent (overwriting the initial one if needed) and runs the workflow. \"\"\" session_service , runner = await setup_session_and_runner () current_session = await session_service . get_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) if not current_session : logger . error ( \"Session not found!\" ) return current_session . state [ \"topic\" ] = user_input_topic logger . info ( f \"Updated session state topic to: { user_input_topic } \" ) content = types . Content ( role = 'user' , parts = [ types . Part ( text = f \"Generate a story about: { user_input_topic } \" )]) events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) final_response = \"No final response captured.\" async for event in events : if event . is_final_response () and event . content and event . content . parts : logger . info ( f \"Potential final response from [ { event . author } ]: { event . content . parts [ 0 ] . text } \" ) final_response = event . content . parts [ 0 ] . text print ( \" \\n --- Agent Interaction Result ---\" ) print ( \"Agent Final Response: \" , final_response ) final_session = await session_service . get_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) print ( \"Final Session State:\" ) import json print ( json . dumps ( final_session . state , indent = 2 )) print ( \"------------------------------- \\n \" ) # --- Run the Agent --- # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"a lonely robot finding a friend in a junkyard\" ) # Full runnable code for the StoryFlowAgent example package main import ( \"context\" \"fmt\" \"iter\" \"log\" \"google.golang.org/adk/agent/workflowagents/loopagent\" \"google.golang.org/adk/agent/workflowagents/sequentialagent\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/genai\" ) // StoryFlowAgent is a custom agent that orchestrates a story generation workflow. // It encapsulates the logic of running sub-agents in a specific sequence. type StoryFlowAgent struct { storyGenerator agent . Agent revisionLoopAgent agent . Agent postProcessorAgent agent . Agent } // NewStoryFlowAgent creates and configures the entire custom agent workflow. // It takes individual LLM agents as input and internally creates the necessary // workflow agents (loop, sequential), returning the final orchestrator agent. func NewStoryFlowAgent ( storyGenerator , critic , reviser , grammarCheck , toneCheck agent . Agent , ) ( agent . Agent , error ) { loopAgent , err := loopagent . New ( loopagent . Config { MaxIterations : 2 , AgentConfig : agent . Config { Name : \"CriticReviserLoop\" , SubAgents : [] agent . Agent { critic , reviser }, }, }) if err != nil { return nil , fmt . Errorf ( \"failed to create loop agent: %w\" , err ) } sequentialAgent , err := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : \"PostProcessing\" , SubAgents : [] agent . Agent { grammarCheck , toneCheck }, }, }) if err != nil { return nil , fmt . Errorf ( \"failed to create sequential agent: %w\" , err ) } // The StoryFlowAgent struct holds the agents needed for the Run method. orchestrator := & StoryFlowAgent { storyGenerator : storyGenerator , revisionLoopAgent : loopAgent , postProcessorAgent : sequentialAgent , } // agent.New creates the final agent, wiring up the Run method. return agent . New ( agent . Config { Name : \"StoryFlowAgent\" , Description : \"Orchestrates story generation, critique, revision, and checks.\" , SubAgents : [] agent . Agent { storyGenerator , loopAgent , sequentialAgent }, Run : orchestrator . Run , }) } // Run defines the custom execution logic for the StoryFlowAgent. func ( s * StoryFlowAgent ) Run ( ctx agent . InvocationContext ) iter . Seq2 [ * session . Event , error ] { return func ( yield func ( * session . Event , error ) bool ) { // Stage 1: Initial Story Generation for event , err := range s . storyGenerator . Run ( ctx ) { if err != nil { yield ( nil , fmt . Errorf ( \"story generator failed: %w\" , err )) return } if ! yield ( event , nil ) { return } } // Check if story was generated before proceeding currentStory , err := ctx . Session (). State (). Get ( \"current_story\" ) if err != nil || currentStory == \"\" { log . Println ( \"Failed to generate initial story. Aborting workflow.\" ) return } // Stage 2: Critic-Reviser Loop for event , err := range s . revisionLoopAgent . Run ( ctx ) { if err != nil { yield ( nil , fmt . Errorf ( \"loop agent failed: %w\" , err )) return } if ! yield ( event , nil ) { return } } // Stage 3: Post-Processing for event , err := range s . postProcessorAgent . Run ( ctx ) { if err != nil { yield ( nil , fmt . Errorf ( \"sequential agent failed: %w\" , err )) return } if ! yield ( event , nil ) { return } } // Stage 4: Conditional Regeneration toneResult , err := ctx . Session (). State (). Get ( \"tone_check_result\" ) if err != nil { log . Printf ( \"Could not read tone_check_result from state: %v. Assuming tone is not negative.\" , err ) return } if tone , ok := toneResult .( string ); ok && tone == \"negative\" { log . Println ( \"Tone is negative. Regenerating story...\" ) for event , err := range s . storyGenerator . Run ( ctx ) { if err != nil { yield ( nil , fmt . Errorf ( \"story regeneration failed: %w\" , err )) return } if ! yield ( event , nil ) { return } } } else { log . Println ( \"Tone is not negative. Keeping current story.\" ) } } } const ( modelName = \"gemini-2.0-flash\" appName = \"story_app\" userID = \"user_12345\" ) func main () { ctx := context . Background () model , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } // --- Define the individual LLM agents --- storyGenerator , err := llmagent . New ( llmagent . Config { Name : \"StoryGenerator\" , Model : model , Description : \"Generates the initial story.\" , Instruction : \"You are a story writer. Write a short story (around 100 words) about a cat, based on the topic: {topic}\" , OutputKey : \"current_story\" , }) if err != nil { log . Fatalf ( \"Failed to create StoryGenerator agent: %v\" , err ) } critic , err := llmagent . New ( llmagent . Config { Name : \"Critic\" , Model : model , Description : \"Critiques the story.\" , Instruction : \"You are a story critic. Review the story: {current_story}. Provide 1-2 sentences of constructive criticism on how to improve it. Focus on plot or character.\" , OutputKey : \"criticism\" , }) if err != nil { log . Fatalf ( \"Failed to create Critic agent: %v\" , err ) } reviser , err := llmagent . New ( llmagent . Config { Name : \"Reviser\" , Model : model , Description : \"Revises the story based on criticism.\" , Instruction : \"You are a story reviser. Revise the story: {current_story}, based on the criticism: {criticism}. Output only the revised story.\" , OutputKey : \"current_story\" , }) if err != nil { log . Fatalf ( \"Failed to create Reviser agent: %v\" , err ) } grammarCheck , err := llmagent . New ( llmagent . Config { Name : \"GrammarCheck\" , Model : model , Description : \"Checks grammar and suggests corrections.\" , Instruction : \"You are a grammar checker. Check the grammar of the story: {current_story}. Output only the suggested corrections as a list, or output 'Grammar is good!' if there are no errors.\" , OutputKey : \"grammar_suggestions\" , }) if err != nil { log . Fatalf ( \"Failed to create GrammarCheck agent: %v\" , err ) } toneCheck , err := llmagent . New ( llmagent . Config { Name : \"ToneCheck\" , Model : model , Description : \"Analyzes the tone of the story.\" , Instruction : \"You are a tone analyzer. Analyze the tone of the story: {current_story}. Output only one word: 'positive' if the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral' otherwise.\" , OutputKey : \"tone_check_result\" , }) if err != nil { log . Fatalf ( \"Failed to create ToneCheck agent: %v\" , err ) } // Instantiate the custom agent, which encapsulates the workflow agents. storyFlowAgent , err := NewStoryFlowAgent ( storyGenerator , critic , reviser , grammarCheck , toneCheck , ) if err != nil { log . Fatalf ( \"Failed to create story flow agent: %v\" , err ) } // --- Run the Agent --- sessionService := session . InMemoryService () initialState := map [ string ] any { \"topic\" : \"a brave kitten exploring a haunted house\" , } sessionInstance , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , State : initialState , }) if err != nil { log . Fatalf ( \"Failed to create session: %v\" , err ) } userTopic := \"a lonely robot finding a friend in a junkyard\" r , err := runner . New ( runner . Config { AppName : appName , Agent : storyFlowAgent , SessionService : sessionService , }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } input := genai . NewContentFromText ( \"Generate a story about: \" + userTopic , genai . RoleUser ) events := r . Run ( ctx , userID , sessionInstance . Session . ID (), input , agent . RunConfig { StreamingMode : agent . StreamingModeSSE , }) var finalResponse string for event , err := range events { if err != nil { log . Fatalf ( \"An error occurred during agent execution: %v\" , err ) } for _ , part := range event . Content . Parts { // Accumulate text from all parts of the final response. finalResponse += part . Text } } fmt . Println ( \"\\n--- Agent Interaction Result ---\" ) fmt . Println ( \"Agent Final Response: \" + finalResponse ) finalSession , err := sessionService . Get ( ctx , & session . GetRequest { UserID : userID , AppName : appName , SessionID : sessionInstance . Session . ID (), }) if err != nil { log . Fatalf ( \"Failed to retrieve final session: %v\" , err ) } fmt . Println ( \"Final Session State:\" , finalSession . Session . State ()) } # Full runnable code for the StoryFlowAgent example import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.InvocationContext ; import com.google.adk.agents.LoopAgent ; import com.google.adk.agents.SequentialAgent ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import java.util.HashMap ; import java.util.List ; import java.util.Map ; import java.util.Optional ; import java.util.concurrent.ConcurrentHashMap ; import java.util.logging.Level ; import java.util.logging.Logger ; public class StoryFlowAgentExample extends BaseAgent { // --- Constants --- private static final String APP_NAME = \"story_app\" ; private static final String USER_ID = \"user_12345\" ; private static final String SESSION_ID = \"session_123344\" ; private static final String MODEL_NAME = \"gemini-2.0-flash\" ; // Ensure this model is available private static final Logger logger = Logger . getLogger ( StoryFlowAgentExample . class . getName ()); private final LlmAgent storyGenerator ; private final LoopAgent loopAgent ; private final SequentialAgent sequentialAgent ; public StoryFlowAgentExample ( String name , LlmAgent storyGenerator , LoopAgent loopAgent , SequentialAgent sequentialAgent ) { super ( name , \"Orchestrates story generation, critique, revision, and checks.\" , List . of ( storyGenerator , loopAgent , sequentialAgent ), null , null ); this . storyGenerator = storyGenerator ; this . loopAgent = loopAgent ; this . sequentialAgent = sequentialAgent ; } public static void main ( String [] args ) { // --- Define the individual LLM agents --- LlmAgent storyGenerator = LlmAgent . builder () . name ( \"StoryGenerator\" ) . model ( MODEL_NAME ) . description ( \"Generates the initial story.\" ) . instruction ( \"\"\" You are a story writer. Write a short story (around 100 words) about a cat, based on the topic: {topic} \"\"\" ) . inputSchema ( null ) . outputKey ( \"current_story\" ) // Key for storing output in session state . build (); LlmAgent critic = LlmAgent . builder () . name ( \"Critic\" ) . model ( MODEL_NAME ) . description ( \"Critiques the story.\" ) . instruction ( \"\"\" You are a story critic. Review the story: {current_story}. Provide 1-2 sentences of constructive criticism on how to improve it. Focus on plot or character. \"\"\" ) . inputSchema ( null ) . outputKey ( \"criticism\" ) // Key for storing criticism in session state . build (); LlmAgent reviser = LlmAgent . builder () . name ( \"Reviser\" ) . model ( MODEL_NAME ) . description ( \"Revises the story based on criticism.\" ) . instruction ( \"\"\" You are a story reviser. Revise the story: {current_story}, based on the criticism: {criticism}. Output only the revised story. \"\"\" ) . inputSchema ( null ) . outputKey ( \"current_story\" ) // Overwrites the original story . build (); LlmAgent grammarCheck = LlmAgent . builder () . name ( \"GrammarCheck\" ) . model ( MODEL_NAME ) . description ( \"Checks grammar and suggests corrections.\" ) . instruction ( \"\"\" You are a grammar checker. Check the grammar of the story: {current_story}. Output only the suggested corrections as a list, or output 'Grammar is good!' if there are no errors. \"\"\" ) . outputKey ( \"grammar_suggestions\" ) . build (); LlmAgent toneCheck = LlmAgent . builder () . name ( \"ToneCheck\" ) . model ( MODEL_NAME ) . description ( \"Analyzes the tone of the story.\" ) . instruction ( \"\"\" You are a tone analyzer. Analyze the tone of the story: {current_story}. Output only one word: 'positive' if the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral' otherwise. \"\"\" ) . outputKey ( \"tone_check_result\" ) // This agent's output determines the conditional flow . build (); LoopAgent loopAgent = LoopAgent . builder () . name ( \"CriticReviserLoop\" ) . description ( \"Iteratively critiques and revises the story.\" ) . subAgents ( critic , reviser ) . maxIterations ( 2 ) . build (); SequentialAgent sequentialAgent = SequentialAgent . builder () . name ( \"PostProcessing\" ) . description ( \"Performs grammar and tone checks sequentially.\" ) . subAgents ( grammarCheck , toneCheck ) . build (); StoryFlowAgentExample storyFlowAgentExample = new StoryFlowAgentExample ( APP_NAME , storyGenerator , loopAgent , sequentialAgent ); // --- Run the Agent --- runAgent ( storyFlowAgentExample , \"a lonely robot finding a friend in a junkyard\" ); } // --- Function to Interact with the Agent --- // Sends a new topic to the agent (overwriting the initial one if needed) // and runs the workflow. public static void runAgent ( StoryFlowAgentExample agent , String userTopic ) { // --- Setup Runner and Session --- InMemoryRunner runner = new InMemoryRunner ( agent ); Map < String , Object > initialState = new HashMap <> (); initialState . put ( \"topic\" , \"a brave kitten exploring a haunted house\" ); Session session = runner . sessionService () . createSession ( APP_NAME , USER_ID , new ConcurrentHashMap <> ( initialState ), SESSION_ID ) . blockingGet (); logger . log ( Level . INFO , () -> String . format ( \"Initial session state: %s\" , session . state ())); session . state (). put ( \"topic\" , userTopic ); // Update the state in the retrieved session logger . log ( Level . INFO , () -> String . format ( \"Updated session state topic to: %s\" , userTopic )); Content userMessage = Content . fromParts ( Part . fromText ( \"Generate a story about: \" + userTopic )); // Use the modified session object for the run Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); final String [] finalResponse = { \"No final response captured.\" }; eventStream . blockingForEach ( event -> { if ( event . finalResponse () && event . content (). isPresent ()) { String author = event . author () != null ? event . author () : \"UNKNOWN_AUTHOR\" ; Optional < String > textOpt = event . content () . flatMap ( Content :: parts ) . filter ( parts -> ! parts . isEmpty ()) . map ( parts -> parts . get ( 0 ). text (). orElse ( \"\" )); logger . log ( Level . INFO , () -> String . format ( \"Potential final response from [%s]: %s\" , author , textOpt . orElse ( \"N/A\" ))); textOpt . ifPresent ( text -> finalResponse [ 0 ] = text ); } }); System . out . println ( \"\\n--- Agent Interaction Result ---\" ); System . out . println ( \"Agent Final Response: \" + finalResponse [ 0 ] ); // Retrieve session again to see the final state after the run Session finalSession = runner . sessionService () . getSession ( APP_NAME , USER_ID , SESSION_ID , Optional . empty ()) . blockingGet (); assert finalSession != null ; System . out . println ( \"Final Session State:\" + finalSession . state ()); System . out . println ( \"-------------------------------\\n\" ); } private boolean isStoryGenerated ( InvocationContext ctx ) { Object currentStoryObj = ctx . session (). state (). get ( \"current_story\" ); return currentStoryObj != null && ! String . valueOf ( currentStoryObj ). isEmpty (); } @Override protected Flowable < Event > runAsyncImpl ( InvocationContext invocationContext ) { // Implements the custom orchestration logic for the story workflow. // Uses the instance attributes assigned by Pydantic (e.g., self.story_generator). logger . log ( Level . INFO , () -> String . format ( \"[%s] Starting story generation workflow.\" , name ())); // Stage 1. Initial Story Generation Flowable < Event > storyGenFlow = runStage ( storyGenerator , invocationContext , \"StoryGenerator\" ); // Stage 2: Critic-Reviser Loop (runs after story generation completes) Flowable < Event > criticReviserFlow = Flowable . defer (() -> { if ( ! isStoryGenerated ( invocationContext )) { logger . log ( Level . SEVERE ,() -> String . format ( \"[%s] Failed to generate initial story. Aborting after StoryGenerator.\" , name ())); return Flowable . empty (); // Stop further processing if no story } logger . log ( Level . INFO , () -> String . format ( \"[%s] Story state after generator: %s\" , name (), invocationContext . session (). state (). get ( \"current_story\" ))); return runStage ( loopAgent , invocationContext , \"CriticReviserLoop\" ); }); // Stage 3: Post-Processing (runs after critic-reviser loop completes) Flowable < Event > postProcessingFlow = Flowable . defer (() -> { logger . log ( Level . INFO , () -> String . format ( \"[%s] Story state after loop: %s\" , name (), invocationContext . session (). state (). get ( \"current_story\" ))); return runStage ( sequentialAgent , invocationContext , \"PostProcessing\" ); }); // Stage 4: Conditional Regeneration (runs after post-processing completes) Flowable < Event > conditionalRegenFlow = Flowable . defer (() -> { String toneCheckResult = ( String ) invocationContext . session (). state (). get ( \"tone_check_result\" ); logger . log ( Level . INFO , () -> String . format ( \"[%s] Tone check result: %s\" , name (), toneCheckResult )); if ( \"negative\" . equalsIgnoreCase ( toneCheckResult )) { logger . log ( Level . INFO , () -> String . format ( \"[%s] Tone is negative. Regenerating story...\" , name ())); return runStage ( storyGenerator , invocationContext , \"StoryGenerator (Regen)\" ); } else { logger . log ( Level . INFO , () -> String . format ( \"[%s] Tone is not negative. Keeping current story.\" , name ())); return Flowable . empty (); // No regeneration needed } }); return Flowable . concatArray ( storyGenFlow , criticReviserFlow , postProcessingFlow , conditionalRegenFlow ) . doOnComplete (() -> logger . log ( Level . INFO , () -> String . format ( \"[%s] Workflow finished.\" , name ()))); } // Helper method for a single agent run stage with logging private Flowable < Event > runStage ( BaseAgent agentToRun , InvocationContext ctx , String stageName ) { logger . log ( Level . INFO , () -> String . format ( \"[%s] Running %s...\" , name (), stageName )); return agentToRun . runAsync ( ctx ) . doOnNext ( event -> logger . log ( Level . INFO ,() -> String . format ( \"[%s] Event from %s: %s\" , name (), stageName , event . toJson ()))) . doOnError ( err -> logger . log ( Level . SEVERE , String . format ( \"[%s] Error in %s\" , name (), stageName ), err )) . doOnComplete (() -> logger . log ( Level . INFO , () -> String . format ( \"[%s] %s finished.\" , name (), stageName ))); } @Override protected Flowable < Event > runLiveImpl ( InvocationContext invocationContext ) { return Flowable . error ( new UnsupportedOperationException ( \"runLive not implemented.\" )); } } Back to top ", "code_blocks": [{"language": "text", "code": "# Full runnable code for the StoryFlowAgent example\n# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport logging\nfrom typing import AsyncGenerator\nfrom typing_extensions import override\n\nfrom google.adk.agents import LlmAgent, BaseAgent, LoopAgent, SequentialAgent\nfrom google.adk.agents.invocation_context import InvocationContext\nfrom google.genai import types\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.runners import Runner\nfrom google.adk.events import Event\nfrom pydantic import BaseModel, Field\n\n# --- Constants ---\nAPP_NAME = \"story_app\"\nUSER_ID = \"12345\"\nSESSION_ID = \"123344\"\nGEMINI_2_FLASH = \"gemini-2.0-flash\"\n\n# --- Configure Logging ---\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\n# --- Custom Orchestrator Agent ---\nclass StoryFlowAgent(BaseAgent):\n    \"\"\"\n    Custom agent for a story generation and refinement workflow.\n\n    This agent orchestrates a sequence of LLM agents to generate a story,\n    critique it, revise it, check grammar and tone, and potentially\n    regenerate the story if the tone is negative.\n    \"\"\"\n\n    # --- Field Declarations for Pydantic ---\n    # Declare the agents passed during initialization as class attributes with type hints\n    story_generator: LlmAgent\n    critic: LlmAgent\n    reviser: LlmAgent\n    grammar_check: LlmAgent\n    tone_check: LlmAgent\n\n    loop_agent: LoopAgent\n    sequential_agent: SequentialAgent\n\n    # model_config allows setting Pydantic configurations if needed, e.g., arbitrary_types_allowed\n    model_config = {\"arbitrary_types_allowed\": True}\n\n    def __init__(\n        self,\n        name: str,\n        story_generator: LlmAgent,\n        critic: LlmAgent,\n        reviser: LlmAgent,\n        grammar_check: LlmAgent,\n        tone_check: LlmAgent,\n    ):\n        \"\"\"\n        Initializes the StoryFlowAgent.\n\n        Args:\n            name: The name of the agent.\n            story_generator: An LlmAgent to generate the initial story.\n            critic: An LlmAgent to critique the story.\n            reviser: An LlmAgent to revise the story based on criticism.\n            grammar_check: An LlmAgent to check the grammar.\n            tone_check: An LlmAgent to analyze the tone.\n        \"\"\"\n        # Create internal agents *before* calling super().__init__\n        loop_agent = LoopAgent(\n            name=\"CriticReviserLoop\", sub_agents=[critic, reviser], max_iterations=2\n        )\n        sequential_agent = SequentialAgent(\n            name=\"PostProcessing\", sub_agents=[grammar_check, tone_check]\n        )\n\n        # Define the sub_agents list for the framework\n        sub_agents_list = [\n            story_generator,\n            loop_agent,\n            sequential_agent,\n        ]\n\n        # Pydantic will validate and assign them based on the class annotations.\n        super().__init__(\n            name=name,\n            story_generator=story_generator,\n            critic=critic,\n            reviser=reviser,\n            grammar_check=grammar_check,\n            tone_check=tone_check,\n            loop_agent=loop_agent,\n            sequential_agent=sequential_agent,\n            sub_agents=sub_agents_list, # Pass the sub_agents list directly\n        )\n\n    @override\n    async def _run_async_impl(\n        self, ctx: InvocationContext\n    ) -> AsyncGenerator[Event, None]:\n        \"\"\"\n        Implements the custom orchestration logic for the story workflow.\n        Uses the instance attributes assigned by Pydantic (e.g., self.story_generator).\n        \"\"\"\n        logger.info(f\"[{self.name}] Starting story generation workflow.\")\n\n        # 1. Initial Story Generation\n        logger.info(f\"[{self.name}] Running StoryGenerator...\")\n        async for event in self.story_generator.run_async(ctx):\n            logger.info(f\"[{self.name}] Event from StoryGenerator: {event.model_dump_json(indent=2, exclude_none=True)}\")\n            yield event\n\n        # Check if story was generated before proceeding\n        if \"current_story\" not in ctx.session.state or not ctx.session.state[\"current_story\"]:\n             logger.error(f\"[{self.name}] Failed to generate initial story. Aborting workflow.\")\n             return # Stop processing if initial story failed\n\n        logger.info(f\"[{self.name}] Story state after generator: {ctx.session.state.get('current_story')}\")\n\n\n        # 2. Critic-Reviser Loop\n        logger.info(f\"[{self.name}] Running CriticReviserLoop...\")\n        # Use the loop_agent instance attribute assigned during init\n        async for event in self.loop_agent.run_async(ctx):\n            logger.info(f\"[{self.name}] Event from CriticReviserLoop: {event.model_dump_json(indent=2, exclude_none=True)}\")\n            yield event\n\n        logger.info(f\"[{self.name}] Story state after loop: {ctx.session.state.get('current_story')}\")\n\n        # 3. Sequential Post-Processing (Grammar and Tone Check)\n        logger.info(f\"[{self.name}] Running PostProcessing...\")\n        # Use the sequential_agent instance attribute assigned during init\n        async for event in self.sequential_agent.run_async(ctx):\n            logger.info(f\"[{self.name}] Event from PostProcessing: {event.model_dump_json(indent=2, exclude_none=True)}\")\n            yield event\n\n        # 4. Tone-Based Conditional Logic\n        tone_check_result = ctx.session.state.get(\"tone_check_result\")\n        logger.info(f\"[{self.name}] Tone check result: {tone_check_result}\")\n\n        if tone_check_result == \"negative\":\n            logger.info(f\"[{self.name}] Tone is negative. Regenerating story...\")\n            async for event in self.story_generator.run_async(ctx):\n                logger.info(f\"[{self.name}] Event from StoryGenerator (Regen): {event.model_dump_json(indent=2, exclude_none=True)}\")\n                yield event\n        else:\n            logger.info(f\"[{self.name}] Tone is not negative. Keeping current story.\")\n            pass\n\n        logger.info(f\"[{self.name}] Workflow finished.\")\n\n# --- Define the individual LLM agents ---\nstory_generator = LlmAgent(\n    name=\"StoryGenerator\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a story writer. Write a short story (around 100 words), on the following topic: {topic}\"\"\",\n    input_schema=None,\n    output_key=\"current_story\",  # Key for storing output in session state\n)\n\ncritic = LlmAgent(\n    name=\"Critic\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a story critic. Review the story provided: {{current_story}}. Provide 1-2 sentences of constructive criticism\non how to improve it. Focus on plot or character.\"\"\",\n    input_schema=None,\n    output_key=\"criticism\",  # Key for storing criticism in session state\n)\n\nreviser = LlmAgent(\n    name=\"Reviser\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a story reviser. Revise the story provided: {{current_story}}, based on the criticism in\n{{criticism}}. Output only the revised story.\"\"\",\n    input_schema=None,\n    output_key=\"current_story\",  # Overwrites the original story\n)\n\ngrammar_check = LlmAgent(\n    name=\"GrammarCheck\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a grammar checker. Check the grammar of the story provided: {current_story}. Output only the suggested\ncorrections as a list, or output 'Grammar is good!' if there are no errors.\"\"\",\n    input_schema=None,\n    output_key=\"grammar_suggestions\",\n)\n\ntone_check = LlmAgent(\n    name=\"ToneCheck\",\n    model=GEMINI_2_FLASH,\n    instruction=\"\"\"You are a tone analyzer. Analyze the tone of the story provided: {current_story}. Output only one word: 'positive' if\nthe tone is generally positive, 'negative' if the tone is generally negative, or 'neutral'\notherwise.\"\"\",\n    input_schema=None,\n    output_key=\"tone_check_result\", # This agent's output determines the conditional flow\n)\n\n# --- Create the custom agent instance ---\nstory_flow_agent = StoryFlowAgent(\n    name=\"StoryFlowAgent\",\n    story_generator=story_generator,\n    critic=critic,\n    reviser=reviser,\n    grammar_check=grammar_check,\n    tone_check=tone_check,\n)\n\nINITIAL_STATE = {\"topic\": \"a brave kitten exploring a haunted house\"}\n\n# --- Setup Runner and Session ---\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID, state=INITIAL_STATE)\n    logger.info(f\"Initial session state: {session.state}\")\n    runner = Runner(\n        agent=story_flow_agent, # Pass the custom orchestrator agent\n        app_name=APP_NAME,\n        session_service=session_service\n    )\n    return session_service, runner\n\n# --- Function to Interact with the Agent ---\nasync def call_agent_async(user_input_topic: str):\n    \"\"\"\n    Sends a new topic to the agent (overwriting the initial one if needed)\n    and runs the workflow.\n    \"\"\"\n\n    session_service, runner = await setup_session_and_runner()\n\n    current_session = await session_service.get_session(app_name=APP_NAME, \n                                                  user_id=USER_ID, \n                                                  session_id=SESSION_ID)\n    if not current_session:\n        logger.error(\"Session not found!\")\n        return\n\n    current_session.state[\"topic\"] = user_input_topic\n    logger.info(f\"Updated session state topic to: {user_input_topic}\")\n\n    content = types.Content(role='user', parts=[types.Part(text=f\"Generate a story about: {user_input_topic}\")])\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    final_response = \"No final response captured.\"\n    async for event in events:\n        if event.is_final_response() and event.content and event.content.parts:\n            logger.info(f\"Potential final response from [{event.author}]: {event.content.parts[0].text}\")\n            final_response = event.content.parts[0].text\n\n    print(\"\\n--- Agent Interaction Result ---\")\n    print(\"Agent Final Response: \", final_response)\n\n    final_session = await session_service.get_session(app_name=APP_NAME, \n                                                user_id=USER_ID, \n                                                session_id=SESSION_ID)\n    print(\"Final Session State:\")\n    import json\n    print(json.dumps(final_session.state, indent=2))\n    print(\"-------------------------------\\n\")\n\n# --- Run the Agent ---\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"a lonely robot finding a friend in a junkyard\")"}, {"language": "text", "code": "# Full runnable code for the StoryFlowAgent example\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"iter\"\n    \"log\"\n\n    \"google.golang.org/adk/agent/workflowagents/loopagent\"\n    \"google.golang.org/adk/agent/workflowagents/sequentialagent\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/genai\"\n)\n\n// StoryFlowAgent is a custom agent that orchestrates a story generation workflow.\n// It encapsulates the logic of running sub-agents in a specific sequence.\ntype StoryFlowAgent struct {\n    storyGenerator     agent.Agent\n    revisionLoopAgent  agent.Agent\n    postProcessorAgent agent.Agent\n}\n\n// NewStoryFlowAgent creates and configures the entire custom agent workflow.\n// It takes individual LLM agents as input and internally creates the necessary\n// workflow agents (loop, sequential), returning the final orchestrator agent.\nfunc NewStoryFlowAgent(\n    storyGenerator,\n    critic,\n    reviser,\n    grammarCheck,\n    toneCheck agent.Agent,\n) (agent.Agent, error) {\n    loopAgent, err := loopagent.New(loopagent.Config{\n        MaxIterations: 2,\n        AgentConfig: agent.Config{\n            Name:      \"CriticReviserLoop\",\n            SubAgents: []agent.Agent{critic, reviser},\n        },\n    })\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create loop agent: %w\", err)\n    }\n\n    sequentialAgent, err := sequentialagent.New(sequentialagent.Config{\n        AgentConfig: agent.Config{\n            Name:      \"PostProcessing\",\n            SubAgents: []agent.Agent{grammarCheck, toneCheck},\n        },\n    })\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create sequential agent: %w\", err)\n    }\n\n    // The StoryFlowAgent struct holds the agents needed for the Run method.\n    orchestrator := &StoryFlowAgent{\n        storyGenerator:     storyGenerator,\n        revisionLoopAgent:  loopAgent,\n        postProcessorAgent: sequentialAgent,\n    }\n\n    // agent.New creates the final agent, wiring up the Run method.\n    return agent.New(agent.Config{\n        Name:        \"StoryFlowAgent\",\n        Description: \"Orchestrates story generation, critique, revision, and checks.\",\n        SubAgents:   []agent.Agent{storyGenerator, loopAgent, sequentialAgent},\n        Run:         orchestrator.Run,\n    })\n}\n\n\n// Run defines the custom execution logic for the StoryFlowAgent.\nfunc (s *StoryFlowAgent) Run(ctx agent.InvocationContext) iter.Seq2[*session.Event, error] {\n    return func(yield func(*session.Event, error) bool) {\n        // Stage 1: Initial Story Generation\n        for event, err := range s.storyGenerator.Run(ctx) {\n            if err != nil {\n                yield(nil, fmt.Errorf(\"story generator failed: %w\", err))\n                return\n            }\n            if !yield(event, nil) {\n                return\n            }\n        }\n\n        // Check if story was generated before proceeding\n        currentStory, err := ctx.Session().State().Get(\"current_story\")\n        if err != nil || currentStory == \"\" {\n            log.Println(\"Failed to generate initial story. Aborting workflow.\")\n            return\n        }\n\n        // Stage 2: Critic-Reviser Loop\n        for event, err := range s.revisionLoopAgent.Run(ctx) {\n            if err != nil {\n                yield(nil, fmt.Errorf(\"loop agent failed: %w\", err))\n                return\n            }\n            if !yield(event, nil) {\n                return\n            }\n        }\n\n        // Stage 3: Post-Processing\n        for event, err := range s.postProcessorAgent.Run(ctx) {\n            if err != nil {\n                yield(nil, fmt.Errorf(\"sequential agent failed: %w\", err))\n                return\n            }\n            if !yield(event, nil) {\n                return\n            }\n        }\n\n        // Stage 4: Conditional Regeneration\n        toneResult, err := ctx.Session().State().Get(\"tone_check_result\")\n        if err != nil {\n            log.Printf(\"Could not read tone_check_result from state: %v. Assuming tone is not negative.\", err)\n            return\n        }\n\n        if tone, ok := toneResult.(string); ok && tone == \"negative\" {\n            log.Println(\"Tone is negative. Regenerating story...\")\n            for event, err := range s.storyGenerator.Run(ctx) {\n                if err != nil {\n                    yield(nil, fmt.Errorf(\"story regeneration failed: %w\", err))\n                    return\n                }\n                if !yield(event, nil) {\n                    return\n                }\n            }\n        } else {\n            log.Println(\"Tone is not negative. Keeping current story.\")\n        }\n    }\n}\n\n\nconst (\n    modelName = \"gemini-2.0-flash\"\n    appName   = \"story_app\"\n    userID    = \"user_12345\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    model, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"Failed to create model: %v\", err)\n    }\n\n    // --- Define the individual LLM agents ---\n    storyGenerator, err := llmagent.New(llmagent.Config{\n        Name:        \"StoryGenerator\",\n        Model:       model,\n        Description: \"Generates the initial story.\",\n        Instruction: \"You are a story writer. Write a short story (around 100 words) about a cat, based on the topic: {topic}\",\n        OutputKey:   \"current_story\",\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create StoryGenerator agent: %v\", err)\n    }\n\n    critic, err := llmagent.New(llmagent.Config{\n        Name:        \"Critic\",\n        Model:       model,\n        Description: \"Critiques the story.\",\n        Instruction: \"You are a story critic. Review the story: {current_story}. Provide 1-2 sentences of constructive criticism on how to improve it. Focus on plot or character.\",\n        OutputKey:   \"criticism\",\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create Critic agent: %v\", err)\n    }\n\n    reviser, err := llmagent.New(llmagent.Config{\n        Name:        \"Reviser\",\n        Model:       model,\n        Description: \"Revises the story based on criticism.\",\n        Instruction: \"You are a story reviser. Revise the story: {current_story}, based on the criticism: {criticism}. Output only the revised story.\",\n        OutputKey:   \"current_story\",\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create Reviser agent: %v\", err)\n    }\n\n    grammarCheck, err := llmagent.New(llmagent.Config{\n        Name:        \"GrammarCheck\",\n        Model:       model,\n        Description: \"Checks grammar and suggests corrections.\",\n        Instruction: \"You are a grammar checker. Check the grammar of the story: {current_story}. Output only the suggested corrections as a list, or output 'Grammar is good!' if there are no errors.\",\n        OutputKey:   \"grammar_suggestions\",\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create GrammarCheck agent: %v\", err)\n    }\n\n    toneCheck, err := llmagent.New(llmagent.Config{\n        Name:        \"ToneCheck\",\n        Model:       model,\n        Description: \"Analyzes the tone of the story.\",\n        Instruction: \"You are a tone analyzer. Analyze the tone of the story: {current_story}. Output only one word: 'positive' if the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral' otherwise.\",\n        OutputKey:   \"tone_check_result\",\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create ToneCheck agent: %v\", err)\n    }\n\n    // Instantiate the custom agent, which encapsulates the workflow agents.\n    storyFlowAgent, err := NewStoryFlowAgent(\n        storyGenerator,\n        critic,\n        reviser,\n        grammarCheck,\n        toneCheck,\n    )\n    if err != nil {\n        log.Fatalf(\"Failed to create story flow agent: %v\", err)\n    }\n\n    // --- Run the Agent ---\n    sessionService := session.InMemoryService()\n    initialState := map[string]any{\n        \"topic\": \"a brave kitten exploring a haunted house\",\n    }\n    sessionInstance, err := sessionService.Create(ctx, &session.CreateRequest{\n        AppName: appName,\n        UserID:  userID,\n        State:   initialState,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create session: %v\", err)\n    }\n\n    userTopic := \"a lonely robot finding a friend in a junkyard\"\n\n    r, err := runner.New(runner.Config{\n        AppName:        appName,\n        Agent:          storyFlowAgent,\n        SessionService: sessionService,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create runner: %v\", err)\n    }\n\n    input := genai.NewContentFromText(\"Generate a story about: \"+userTopic, genai.RoleUser)\n    events := r.Run(ctx, userID, sessionInstance.Session.ID(), input, agent.RunConfig{\n        StreamingMode: agent.StreamingModeSSE,\n    })\n\n    var finalResponse string\n    for event, err := range events {\n        if err != nil {\n            log.Fatalf(\"An error occurred during agent execution: %v\", err)\n        }\n\n        for _, part := range event.Content.Parts {\n            // Accumulate text from all parts of the final response.\n            finalResponse += part.Text\n        }\n    }\n\n    fmt.Println(\"\\n--- Agent Interaction Result ---\")\n    fmt.Println(\"Agent Final Response: \" + finalResponse)\n\n    finalSession, err := sessionService.Get(ctx, &session.GetRequest{\n        UserID:    userID,\n        AppName:   appName,\n        SessionID: sessionInstance.Session.ID(),\n    })\n\n    if err != nil {\n        log.Fatalf(\"Failed to retrieve final session: %v\", err)\n    }\n\n    fmt.Println(\"Final Session State:\", finalSession.Session.State())\n}"}, {"language": "text", "code": "# Full runnable code for the StoryFlowAgent example\n\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.InvocationContext;\nimport com.google.adk.agents.LoopAgent;\nimport com.google.adk.agents.SequentialAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Optional;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.logging.Level;\nimport java.util.logging.Logger;\n\npublic class StoryFlowAgentExample extends BaseAgent {\n\n  // --- Constants ---\n  private static final String APP_NAME = \"story_app\";\n  private static final String USER_ID = \"user_12345\";\n  private static final String SESSION_ID = \"session_123344\";\n  private static final String MODEL_NAME = \"gemini-2.0-flash\"; // Ensure this model is available\n\n  private static final Logger logger = Logger.getLogger(StoryFlowAgentExample.class.getName());\n\n  private final LlmAgent storyGenerator;\n  private final LoopAgent loopAgent;\n  private final SequentialAgent sequentialAgent;\n\n  public StoryFlowAgentExample(\n      String name, LlmAgent storyGenerator, LoopAgent loopAgent, SequentialAgent sequentialAgent) {\n    super(\n        name,\n        \"Orchestrates story generation, critique, revision, and checks.\",\n        List.of(storyGenerator, loopAgent, sequentialAgent),\n        null,\n        null);\n\n    this.storyGenerator = storyGenerator;\n    this.loopAgent = loopAgent;\n    this.sequentialAgent = sequentialAgent;\n  }\n\n  public static void main(String[] args) {\n\n    // --- Define the individual LLM agents ---\n    LlmAgent storyGenerator =\n        LlmAgent.builder()\n            .name(\"StoryGenerator\")\n            .model(MODEL_NAME)\n            .description(\"Generates the initial story.\")\n            .instruction(\n                \"\"\"\n              You are a story writer. Write a short story (around 100 words) about a cat,\n              based on the topic: {topic}\n              \"\"\")\n            .inputSchema(null)\n            .outputKey(\"current_story\") // Key for storing output in session state\n            .build();\n\n    LlmAgent critic =\n        LlmAgent.builder()\n            .name(\"Critic\")\n            .model(MODEL_NAME)\n            .description(\"Critiques the story.\")\n            .instruction(\n                \"\"\"\n              You are a story critic. Review the story: {current_story}. Provide 1-2 sentences of constructive criticism\n              on how to improve it. Focus on plot or character.\n              \"\"\")\n            .inputSchema(null)\n            .outputKey(\"criticism\") // Key for storing criticism in session state\n            .build();\n\n    LlmAgent reviser =\n        LlmAgent.builder()\n            .name(\"Reviser\")\n            .model(MODEL_NAME)\n            .description(\"Revises the story based on criticism.\")\n            .instruction(\n                \"\"\"\n              You are a story reviser. Revise the story: {current_story}, based on the criticism: {criticism}. Output only the revised story.\n              \"\"\")\n            .inputSchema(null)\n            .outputKey(\"current_story\") // Overwrites the original story\n            .build();\n\n    LlmAgent grammarCheck =\n        LlmAgent.builder()\n            .name(\"GrammarCheck\")\n            .model(MODEL_NAME)\n            .description(\"Checks grammar and suggests corrections.\")\n            .instruction(\n                \"\"\"\n               You are a grammar checker. Check the grammar of the story: {current_story}. Output only the suggested\n               corrections as a list, or output 'Grammar is good!' if there are no errors.\n               \"\"\")\n            .outputKey(\"grammar_suggestions\")\n            .build();\n\n    LlmAgent toneCheck =\n        LlmAgent.builder()\n            .name(\"ToneCheck\")\n            .model(MODEL_NAME)\n            .description(\"Analyzes the tone of the story.\")\n            .instruction(\n                \"\"\"\n              You are a tone analyzer. Analyze the tone of the story: {current_story}. Output only one word: 'positive' if\n              the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral'\n              otherwise.\n              \"\"\")\n            .outputKey(\"tone_check_result\") // This agent's output determines the conditional flow\n            .build();\n\n    LoopAgent loopAgent =\n        LoopAgent.builder()\n            .name(\"CriticReviserLoop\")\n            .description(\"Iteratively critiques and revises the story.\")\n            .subAgents(critic, reviser)\n            .maxIterations(2)\n            .build();\n\n    SequentialAgent sequentialAgent =\n        SequentialAgent.builder()\n            .name(\"PostProcessing\")\n            .description(\"Performs grammar and tone checks sequentially.\")\n            .subAgents(grammarCheck, toneCheck)\n            .build();\n\n\n    StoryFlowAgentExample storyFlowAgentExample =\n        new StoryFlowAgentExample(APP_NAME, storyGenerator, loopAgent, sequentialAgent);\n\n    // --- Run the Agent ---\n    runAgent(storyFlowAgentExample, \"a lonely robot finding a friend in a junkyard\");\n  }\n\n  // --- Function to Interact with the Agent ---\n  // Sends a new topic to the agent (overwriting the initial one if needed)\n  // and runs the workflow.\n  public static void runAgent(StoryFlowAgentExample agent, String userTopic) {\n    // --- Setup Runner and Session ---\n    InMemoryRunner runner = new InMemoryRunner(agent);\n\n    Map<String, Object> initialState = new HashMap<>();\n    initialState.put(\"topic\", \"a brave kitten exploring a haunted house\");\n\n    Session session =\n        runner\n            .sessionService()\n            .createSession(APP_NAME, USER_ID, new ConcurrentHashMap<>(initialState), SESSION_ID)\n            .blockingGet();\n    logger.log(Level.INFO, () -> String.format(\"Initial session state: %s\", session.state()));\n\n    session.state().put(\"topic\", userTopic); // Update the state in the retrieved session\n    logger.log(Level.INFO, () -> String.format(\"Updated session state topic to: %s\", userTopic));\n\n    Content userMessage = Content.fromParts(Part.fromText(\"Generate a story about: \" + userTopic));\n    // Use the modified session object for the run\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n    final String[] finalResponse = {\"No final response captured.\"};\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse() && event.content().isPresent()) {\n            String author = event.author() != null ? event.author() : \"UNKNOWN_AUTHOR\";\n            Optional<String> textOpt =\n                event\n                    .content()\n                    .flatMap(Content::parts)\n                    .filter(parts -> !parts.isEmpty())\n                    .map(parts -> parts.get(0).text().orElse(\"\"));\n\n            logger.log(Level.INFO, () ->\n                String.format(\"Potential final response from [%s]: %s\", author, textOpt.orElse(\"N/A\")));\n            textOpt.ifPresent(text -> finalResponse[0] = text);\n          }\n        });\n\n    System.out.println(\"\\n--- Agent Interaction Result ---\");\n    System.out.println(\"Agent Final Response: \" + finalResponse[0]);\n\n    // Retrieve session again to see the final state after the run\n    Session finalSession =\n        runner\n            .sessionService()\n            .getSession(APP_NAME, USER_ID, SESSION_ID, Optional.empty())\n            .blockingGet();\n\n    assert finalSession != null;\n    System.out.println(\"Final Session State:\" + finalSession.state());\n    System.out.println(\"-------------------------------\\n\");\n  }\n\n  private boolean isStoryGenerated(InvocationContext ctx) {\n    Object currentStoryObj = ctx.session().state().get(\"current_story\");\n    return currentStoryObj != null && !String.valueOf(currentStoryObj).isEmpty();\n  }\n\n  @Override\n  protected Flowable<Event> runAsyncImpl(InvocationContext invocationContext) {\n    // Implements the custom orchestration logic for the story workflow.\n    // Uses the instance attributes assigned by Pydantic (e.g., self.story_generator).\n    logger.log(Level.INFO, () -> String.format(\"[%s] Starting story generation workflow.\", name()));\n\n    // Stage 1. Initial Story Generation\n    Flowable<Event> storyGenFlow = runStage(storyGenerator, invocationContext, \"StoryGenerator\");\n\n    // Stage 2: Critic-Reviser Loop (runs after story generation completes)\n    Flowable<Event> criticReviserFlow = Flowable.defer(() -> {\n      if (!isStoryGenerated(invocationContext)) {\n        logger.log(Level.SEVERE,() ->\n            String.format(\"[%s] Failed to generate initial story. Aborting after StoryGenerator.\",\n                name()));\n        return Flowable.empty(); // Stop further processing if no story\n      }\n        logger.log(Level.INFO, () ->\n            String.format(\"[%s] Story state after generator: %s\",\n                name(), invocationContext.session().state().get(\"current_story\")));\n        return runStage(loopAgent, invocationContext, \"CriticReviserLoop\");\n    });\n\n    // Stage 3: Post-Processing (runs after critic-reviser loop completes)\n    Flowable<Event> postProcessingFlow = Flowable.defer(() -> {\n      logger.log(Level.INFO, () ->\n          String.format(\"[%s] Story state after loop: %s\",\n              name(), invocationContext.session().state().get(\"current_story\")));\n      return runStage(sequentialAgent, invocationContext, \"PostProcessing\");\n    });\n\n    // Stage 4: Conditional Regeneration (runs after post-processing completes)\n    Flowable<Event> conditionalRegenFlow = Flowable.defer(() -> {\n      String toneCheckResult = (String) invocationContext.session().state().get(\"tone_check_result\");\n      logger.log(Level.INFO, () -> String.format(\"[%s] Tone check result: %s\", name(), toneCheckResult));\n\n      if (\"negative\".equalsIgnoreCase(toneCheckResult)) {\n        logger.log(Level.INFO, () ->\n            String.format(\"[%s] Tone is negative. Regenerating story...\", name()));\n        return runStage(storyGenerator, invocationContext, \"StoryGenerator (Regen)\");\n      } else {\n        logger.log(Level.INFO, () ->\n            String.format(\"[%s] Tone is not negative. Keeping current story.\", name()));\n        return Flowable.empty(); // No regeneration needed\n      }\n    });\n\n    return Flowable.concatArray(storyGenFlow, criticReviserFlow, postProcessingFlow, conditionalRegenFlow)\n        .doOnComplete(() -> logger.log(Level.INFO, () -> String.format(\"[%s] Workflow finished.\", name())));\n  }\n\n  // Helper method for a single agent run stage with logging\n  private Flowable<Event> runStage(BaseAgent agentToRun, InvocationContext ctx, String stageName) {\n    logger.log(Level.INFO, () -> String.format(\"[%s] Running %s...\", name(), stageName));\n    return agentToRun\n        .runAsync(ctx)\n        .doOnNext(event ->\n            logger.log(Level.INFO,() ->\n                String.format(\"[%s] Event from %s: %s\", name(), stageName, event.toJson())))\n        .doOnError(err ->\n            logger.log(Level.SEVERE,\n                String.format(\"[%s] Error in %s\", name(), stageName), err))\n        .doOnComplete(() ->\n            logger.log(Level.INFO, () ->\n                String.format(\"[%s] %s finished.\", name(), stageName)));\n  }\n\n  @Override\n  protected Flowable<Event> runLiveImpl(InvocationContext invocationContext) {\n    return Flowable.error(new UnsupportedOperationException(\"runLive not implemented.\"));\n  }\n}"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:08.017198", "source_type": "adk-docs"}
{"doc_id": "18efd37c387ce62a796bb95f435db0a22484b941a887c4ab43c05623dafb5d89", "url": "https://google.github.io/adk-docs/agents/multi-agents", "title": "Multi-agent systems - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Multi-Agent Systems in ADK\u00b6"], "text": "Multi-Agent Systems in ADK \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.2.0 As agentic applications grow in complexity, structuring them as a single, monolithic agent can become challenging to develop, maintain, and reason about. The Agent Development Kit (ADK) supports building sophisticated applications by composing multiple, distinct BaseAgent instances into a Multi-Agent System (MAS) . In ADK, a multi-agent system is an application where different agents, often forming a hierarchy, collaborate or coordinate to achieve a larger goal. Structuring your application this way offers significant advantages, including enhanced modularity, specialization, reusability, maintainability, and the ability to define structured control flows using dedicated workflow agents. You can compose various types of agents derived from BaseAgent to build these systems: LLM Agents: Agents powered by large language models. (See LLM Agents ) Workflow Agents: Specialized agents ( SequentialAgent , ParallelAgent , LoopAgent ) designed to manage the execution flow of their sub-agents. (See Workflow Agents ) Custom agents: Your own agents inheriting from BaseAgent with specialized, non-LLM logic. (See Custom Agents ) The following sections detail the core ADK primitives\u2014such as agent hierarchy, workflow agents, and interaction mechanisms\u2014that enable you to construct and manage these multi-agent systems effectively. ", "code_blocks": []}, {"heading_path": ["1. ADK Primitives for Agent Composition\u00b6"], "text": "1. ADK Primitives for Agent Composition \u00b6 ADK provides core building blocks\u2014primitives\u2014that enable you to structure and manage interactions within your multi-agent system. Note The specific parameters or method names for the primitives may vary slightly by SDK language (e.g., sub_agents in Python, subAgents in Java). Refer to the language-specific API documentation for details. ", "code_blocks": []}, {"heading_path": ["1.1. Agent Hierarchy (Parent agent, Sub Agents)\u00b6"], "text": "1.1. Agent Hierarchy (Parent agent, Sub Agents) \u00b6 The foundation for structuring multi-agent systems is the parent-child relationship defined in BaseAgent . Establishing Hierarchy: You create a tree structure by passing a list of agent instances to the sub_agents argument when initializing a parent agent. ADK automatically sets the parent_agent attribute on each child agent during initialization. Single Parent Rule: An agent instance can only be added as a sub-agent once. Attempting to assign a second parent will result in a ValueError . Importance: This hierarchy defines the scope for Workflow Agents and influences the potential targets for LLM-Driven Delegation. You can navigate the hierarchy using agent.parent_agent or find descendants using agent.find_agent(name) . Python Java Go # Conceptual Example: Defining Hierarchy from google.adk.agents import LlmAgent , BaseAgent # Define individual agents greeter = LlmAgent ( name = \"Greeter\" , model = \"gemini-2.0-flash\" ) task_doer = BaseAgent ( name = \"TaskExecutor\" ) # Custom non-LLM agent # Create parent agent and assign children via sub_agents coordinator = LlmAgent ( name = \"Coordinator\" , model = \"gemini-2.0-flash\" , description = \"I coordinate greetings and tasks.\" , sub_agents = [ # Assign sub_agents here greeter , task_doer ] ) # Framework automatically sets: # assert greeter.parent_agent == coordinator # assert task_doer.parent_agent == coordinator // Conceptual Example: Defining Hierarchy import com.google.adk.agents.SequentialAgent ; import com.google.adk.agents.LlmAgent ; // Define individual agents LlmAgent greeter = LlmAgent . builder (). name ( \"Greeter\" ). model ( \"gemini-2.0-flash\" ). build (); SequentialAgent taskDoer = SequentialAgent . builder (). name ( \"TaskExecutor\" ). subAgents (...). build (); // Sequential Agent // Create parent agent and assign sub_agents LlmAgent coordinator = LlmAgent . builder () . name ( \"Coordinator\" ) . model ( \"gemini-2.0-flash\" ) . description ( \"I coordinate greetings and tasks\" ) . subAgents ( greeter , taskDoer ) // Assign sub_agents here . build (); // Framework automatically sets: // assert greeter.parentAgent().equals(coordinator); // assert taskDoer.parentAgent().equals(coordinator); import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" ) // Conceptual Example: Defining Hierarchy // Define individual agents greeter , _ := llmagent . New ( llmagent . Config { Name : \"Greeter\" , Model : m }) taskDoer , _ := agent . New ( agent . Config { Name : \"TaskExecutor\" }) // Custom non-LLM agent // Create parent agent and assign children via sub_agents coordinator , _ := llmagent . New ( llmagent . Config { Name : \"Coordinator\" , Model : m , Description : \"I coordinate greetings and tasks.\" , SubAgents : [] agent . Agent { greeter , taskDoer }, // Assign sub_agents here }) ", "code_blocks": [{"language": "text", "code": "# Conceptual Example: Defining Hierarchy\nfrom google.adk.agents import LlmAgent, BaseAgent\n\n# Define individual agents\ngreeter = LlmAgent(name=\"Greeter\", model=\"gemini-2.0-flash\")\ntask_doer = BaseAgent(name=\"TaskExecutor\") # Custom non-LLM agent\n\n# Create parent agent and assign children via sub_agents\ncoordinator = LlmAgent(\n    name=\"Coordinator\",\n    model=\"gemini-2.0-flash\",\n    description=\"I coordinate greetings and tasks.\",\n    sub_agents=[ # Assign sub_agents here\n        greeter,\n        task_doer\n    ]\n)\n\n# Framework automatically sets:\n# assert greeter.parent_agent == coordinator\n# assert task_doer.parent_agent == coordinator"}, {"language": "text", "code": "// Conceptual Example: Defining Hierarchy\nimport com.google.adk.agents.SequentialAgent;\nimport com.google.adk.agents.LlmAgent;\n\n// Define individual agents\nLlmAgent greeter = LlmAgent.builder().name(\"Greeter\").model(\"gemini-2.0-flash\").build();\nSequentialAgent taskDoer = SequentialAgent.builder().name(\"TaskExecutor\").subAgents(...).build(); // Sequential Agent\n\n// Create parent agent and assign sub_agents\nLlmAgent coordinator = LlmAgent.builder()\n    .name(\"Coordinator\")\n    .model(\"gemini-2.0-flash\")\n    .description(\"I coordinate greetings and tasks\")\n    .subAgents(greeter, taskDoer) // Assign sub_agents here\n    .build();\n\n// Framework automatically sets:\n// assert greeter.parentAgent().equals(coordinator);\n// assert taskDoer.parentAgent().equals(coordinator);"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n)\n\n// Conceptual Example: Defining Hierarchy\n// Define individual agents\ngreeter, _ := llmagent.New(llmagent.Config{Name: \"Greeter\", Model: m})\ntaskDoer, _ := agent.New(agent.Config{Name: \"TaskExecutor\"}) // Custom non-LLM agent\n\n// Create parent agent and assign children via sub_agents\ncoordinator, _ := llmagent.New(llmagent.Config{\n    Name:        \"Coordinator\",\n    Model:       m,\n    Description: \"I coordinate greetings and tasks.\",\n    SubAgents:   []agent.Agent{greeter, taskDoer}, // Assign sub_agents here\n})"}]}, {"heading_path": ["1.2. Workflow Agents as Orchestrators\u00b6"], "text": "1.2. Workflow Agents as Orchestrators \u00b6 ADK includes specialized agents derived from BaseAgent that don't perform tasks themselves but orchestrate the execution flow of their sub_agents . SequentialAgent : Executes its sub_agents one after another in the order they are listed. Context: Passes the same InvocationContext sequentially, allowing agents to easily pass results via shared state. Python Java Go # Conceptual Example: Sequential Pipeline from google.adk.agents import SequentialAgent , LlmAgent step1 = LlmAgent ( name = \"Step1_Fetch\" , output_key = \"data\" ) # Saves output to state['data'] step2 = LlmAgent ( name = \"Step2_Process\" , instruction = \"Process data from {data} .\" ) pipeline = SequentialAgent ( name = \"MyPipeline\" , sub_agents = [ step1 , step2 ]) # When pipeline runs, Step2 can access the state['data'] set by Step1. // Conceptual Example: Sequential Pipeline import com.google.adk.agents.SequentialAgent ; import com.google.adk.agents.LlmAgent ; LlmAgent step1 = LlmAgent . builder (). name ( \"Step1_Fetch\" ). outputKey ( \"data\" ). build (); // Saves output to state.get(\"data\") LlmAgent step2 = LlmAgent . builder (). name ( \"Step2_Process\" ). instruction ( \"Process data from {data}.\" ). build (); SequentialAgent pipeline = SequentialAgent . builder (). name ( \"MyPipeline\" ). subAgents ( step1 , step2 ). build (); // When pipeline runs, Step2 can access the state.get(\"data\") set by Step1. import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/agent/workflowagents/sequentialagent\" ) // Conceptual Example: Sequential Pipeline step1 , _ := llmagent . New ( llmagent . Config { Name : \"Step1_Fetch\" , OutputKey : \"data\" , Model : m }) // Saves output to state[\"data\"] step2 , _ := llmagent . New ( llmagent . Config { Name : \"Step2_Process\" , Instruction : \"Process data from {data}.\" , Model : m }) pipeline , _ := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : \"MyPipeline\" , SubAgents : [] agent . Agent { step1 , step2 }}, }) // When pipeline runs, Step2 can access the state[\"data\"] set by Step1. ParallelAgent : Executes its sub_agents in parallel. Events from sub-agents may be interleaved. Context: Modifies the InvocationContext.branch for each child agent (e.g., ParentBranch.ChildName ), providing a distinct contextual path which can be useful for isolating history in some memory implementations. State: Despite different branches, all parallel children access the same shared session.state , enabling them to read initial state and write results (use distinct keys to avoid race conditions). Python Java Go # Conceptual Example: Parallel Execution from google.adk.agents import ParallelAgent , LlmAgent fetch_weather = LlmAgent ( name = \"WeatherFetcher\" , output_key = \"weather\" ) fetch_news = LlmAgent ( name = \"NewsFetcher\" , output_key = \"news\" ) gatherer = ParallelAgent ( name = \"InfoGatherer\" , sub_agents = [ fetch_weather , fetch_news ]) # When gatherer runs, WeatherFetcher and NewsFetcher run concurrently. # A subsequent agent could read state['weather'] and state['news']. // Conceptual Example: Parallel Execution import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.ParallelAgent ; LlmAgent fetchWeather = LlmAgent . builder () . name ( \"WeatherFetcher\" ) . outputKey ( \"weather\" ) . build (); LlmAgent fetchNews = LlmAgent . builder () . name ( \"NewsFetcher\" ) . instruction ( \"news\" ) . build (); ParallelAgent gatherer = ParallelAgent . builder () . name ( \"InfoGatherer\" ) . subAgents ( fetchWeather , fetchNews ) . build (); // When gatherer runs, WeatherFetcher and NewsFetcher run concurrently. // A subsequent agent could read state['weather'] and state['news']. import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/agent/workflowagents/parallelagent\" ) // Conceptual Example: Parallel Execution fetchWeather , _ := llmagent . New ( llmagent . Config { Name : \"WeatherFetcher\" , OutputKey : \"weather\" , Model : m }) fetchNews , _ := llmagent . New ( llmagent . Config { Name : \"NewsFetcher\" , OutputKey : \"news\" , Model : m }) gatherer , _ := parallelagent . New ( parallelagent . Config { AgentConfig : agent . Config { Name : \"InfoGatherer\" , SubAgents : [] agent . Agent { fetchWeather , fetchNews }}, }) // When gatherer runs, WeatherFetcher and NewsFetcher run concurrently. // A subsequent agent could read state[\"weather\"] and state[\"news\"]. LoopAgent : Executes its sub_agents sequentially in a loop. Termination: The loop stops if the optional max_iterations is reached, or if any sub-agent returns an Event with escalate=True in it's Event Actions. Context & State: Passes the same InvocationContext in each iteration, allowing state changes (e.g., counters, flags) to persist across loops. Python Java Go # Conceptual Example: Loop with Condition from google.adk.agents import LoopAgent , LlmAgent , BaseAgent from google.adk.events import Event , EventActions from google.adk.agents.invocation_context import InvocationContext from typing import AsyncGenerator class CheckCondition ( BaseAgent ): # Custom agent to check state async def _run_async_impl ( self , ctx : InvocationContext ) -> AsyncGenerator [ Event , None ]: status = ctx . session . state . get ( \"status\" , \"pending\" ) is_done = ( status == \"completed\" ) yield Event ( author = self . name , actions = EventActions ( escalate = is_done )) # Escalate if done process_step = LlmAgent ( name = \"ProcessingStep\" ) # Agent that might update state['status'] poller = LoopAgent ( name = \"StatusPoller\" , max_iterations = 10 , sub_agents = [ process_step , CheckCondition ( name = \"Checker\" )] ) # When poller runs, it executes process_step then Checker repeatedly # until Checker escalates (state['status'] == 'completed') or 10 iterations pass. // Conceptual Example: Loop with Condition // Custom agent to check state and potentially escalate public static class CheckConditionAgent extends BaseAgent { public CheckConditionAgent ( String name , String description ) { super ( name , description , List . of (), null , null ); } @Override protected Flowable < Event > runAsyncImpl ( InvocationContext ctx ) { String status = ( String ) ctx . session (). state (). getOrDefault ( \"status\" , \"pending\" ); boolean isDone = \"completed\" . equalsIgnoreCase ( status ); // Emit an event that signals to escalate (exit the loop) if the condition is met. // If not done, the escalate flag will be false or absent, and the loop continues. Event checkEvent = Event . builder () . author ( name ()) . id ( Event . generateEventId ()) // Important to give events unique IDs . actions ( EventActions . builder (). escalate ( isDone ). build ()) // Escalate if done . build (); return Flowable . just ( checkEvent ); } } // Agent that might update state.put(\"status\") LlmAgent processingStepAgent = LlmAgent . builder (). name ( \"ProcessingStep\" ). build (); // Custom agent instance for checking the condition CheckConditionAgent conditionCheckerAgent = new CheckConditionAgent ( \"ConditionChecker\" , \"Checks if the status is 'completed'.\" ); LoopAgent poller = LoopAgent . builder (). name ( \"StatusPoller\" ). maxIterations ( 10 ). subAgents ( processingStepAgent , conditionCheckerAgent ). build (); // When poller runs, it executes processingStepAgent then conditionCheckerAgent repeatedly // until Checker escalates (state.get(\"status\") == \"completed\") or 10 iterations pass. import ( \"iter\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/agent/workflowagents/loopagent\" \"google.golang.org/adk/session\" ) // Conceptual Example: Loop with Condition // Custom agent to check state checkCondition , _ := agent . New ( agent . Config { Name : \"Checker\" , Run : func ( ctx agent . InvocationContext ) iter . Seq2 [ * session . Event , error ] { return func ( yield func ( * session . Event , error ) bool ) { status , err := ctx . Session (). State (). Get ( \"status\" ) // If \"status\" is not in the state, default to \"pending\". // This is idiomatic Go for handling a potential error on lookup. if err != nil { status = \"pending\" } isDone := status == \"completed\" yield ( & session . Event { Author : \"Checker\" , Actions : session . EventActions { Escalate : isDone }}, nil ) } }, }) processStep , _ := llmagent . New ( llmagent . Config { Name : \"ProcessingStep\" , Model : m }) // Agent that might update state[\"status\"] poller , _ := loopagent . New ( loopagent . Config { MaxIterations : 10 , AgentConfig : agent . Config { Name : \"StatusPoller\" , SubAgents : [] agent . Agent { processStep , checkCondition }}, }) // When poller runs, it executes processStep then Checker repeatedly // until Checker escalates (state[\"status\"] == \"completed\") or 10 iterations pass. ", "code_blocks": [{"language": "text", "code": "# Conceptual Example: Sequential Pipeline\nfrom google.adk.agents import SequentialAgent, LlmAgent\n\nstep1 = LlmAgent(name=\"Step1_Fetch\", output_key=\"data\") # Saves output to state['data']\nstep2 = LlmAgent(name=\"Step2_Process\", instruction=\"Process data from {data}.\")\n\npipeline = SequentialAgent(name=\"MyPipeline\", sub_agents=[step1, step2])\n# When pipeline runs, Step2 can access the state['data'] set by Step1."}, {"language": "text", "code": "// Conceptual Example: Sequential Pipeline\nimport com.google.adk.agents.SequentialAgent;\nimport com.google.adk.agents.LlmAgent;\n\nLlmAgent step1 = LlmAgent.builder().name(\"Step1_Fetch\").outputKey(\"data\").build(); // Saves output to state.get(\"data\")\nLlmAgent step2 = LlmAgent.builder().name(\"Step2_Process\").instruction(\"Process data from {data}.\").build();\n\nSequentialAgent pipeline = SequentialAgent.builder().name(\"MyPipeline\").subAgents(step1, step2).build();\n// When pipeline runs, Step2 can access the state.get(\"data\") set by Step1."}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/agent/workflowagents/sequentialagent\"\n)\n\n// Conceptual Example: Sequential Pipeline\nstep1, _ := llmagent.New(llmagent.Config{Name: \"Step1_Fetch\", OutputKey: \"data\", Model: m}) // Saves output to state[\"data\"]\nstep2, _ := llmagent.New(llmagent.Config{Name: \"Step2_Process\", Instruction: \"Process data from {data}.\", Model: m})\n\npipeline, _ := sequentialagent.New(sequentialagent.Config{\n    AgentConfig: agent.Config{Name: \"MyPipeline\", SubAgents: []agent.Agent{step1, step2}},\n})\n// When pipeline runs, Step2 can access the state[\"data\"] set by Step1."}, {"language": "text", "code": "# Conceptual Example: Parallel Execution\nfrom google.adk.agents import ParallelAgent, LlmAgent\n\nfetch_weather = LlmAgent(name=\"WeatherFetcher\", output_key=\"weather\")\nfetch_news = LlmAgent(name=\"NewsFetcher\", output_key=\"news\")\n\ngatherer = ParallelAgent(name=\"InfoGatherer\", sub_agents=[fetch_weather, fetch_news])\n# When gatherer runs, WeatherFetcher and NewsFetcher run concurrently.\n# A subsequent agent could read state['weather'] and state['news']."}, {"language": "text", "code": "// Conceptual Example: Parallel Execution\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.ParallelAgent;\n\nLlmAgent fetchWeather = LlmAgent.builder()\n    .name(\"WeatherFetcher\")\n    .outputKey(\"weather\")\n    .build();\n\nLlmAgent fetchNews = LlmAgent.builder()\n    .name(\"NewsFetcher\")\n    .instruction(\"news\")\n    .build();\n\nParallelAgent gatherer = ParallelAgent.builder()\n    .name(\"InfoGatherer\")\n    .subAgents(fetchWeather, fetchNews)\n    .build();\n\n// When gatherer runs, WeatherFetcher and NewsFetcher run concurrently.\n// A subsequent agent could read state['weather'] and state['news']."}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/agent/workflowagents/parallelagent\"\n)\n\n// Conceptual Example: Parallel Execution\nfetchWeather, _ := llmagent.New(llmagent.Config{Name: \"WeatherFetcher\", OutputKey: \"weather\", Model: m})\nfetchNews, _ := llmagent.New(llmagent.Config{Name: \"NewsFetcher\", OutputKey: \"news\", Model: m})\n\ngatherer, _ := parallelagent.New(parallelagent.Config{\n    AgentConfig: agent.Config{Name: \"InfoGatherer\", SubAgents: []agent.Agent{fetchWeather, fetchNews}},\n})\n// When gatherer runs, WeatherFetcher and NewsFetcher run concurrently.\n// A subsequent agent could read state[\"weather\"] and state[\"news\"]."}, {"language": "text", "code": "# Conceptual Example: Loop with Condition\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\nfrom google.adk.events import Event, EventActions\nfrom google.adk.agents.invocation_context import InvocationContext\nfrom typing import AsyncGenerator\n\nclass CheckCondition(BaseAgent): # Custom agent to check state\n    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n        status = ctx.session.state.get(\"status\", \"pending\")\n        is_done = (status == \"completed\")\n        yield Event(author=self.name, actions=EventActions(escalate=is_done)) # Escalate if done\n\nprocess_step = LlmAgent(name=\"ProcessingStep\") # Agent that might update state['status']\n\npoller = LoopAgent(\n    name=\"StatusPoller\",\n    max_iterations=10,\n    sub_agents=[process_step, CheckCondition(name=\"Checker\")]\n)\n# When poller runs, it executes process_step then Checker repeatedly\n# until Checker escalates (state['status'] == 'completed') or 10 iterations pass."}, {"language": "text", "code": "// Conceptual Example: Loop with Condition\n// Custom agent to check state and potentially escalate\npublic static class CheckConditionAgent extends BaseAgent {\n  public CheckConditionAgent(String name, String description) {\n    super(name, description, List.of(), null, null);\n  }\n\n  @Override\n  protected Flowable<Event> runAsyncImpl(InvocationContext ctx) {\n    String status = (String) ctx.session().state().getOrDefault(\"status\", \"pending\");\n    boolean isDone = \"completed\".equalsIgnoreCase(status);\n\n    // Emit an event that signals to escalate (exit the loop) if the condition is met.\n    // If not done, the escalate flag will be false or absent, and the loop continues.\n    Event checkEvent = Event.builder()\n            .author(name())\n            .id(Event.generateEventId()) // Important to give events unique IDs\n            .actions(EventActions.builder().escalate(isDone).build()) // Escalate if done\n            .build();\n    return Flowable.just(checkEvent);\n  }\n}\n\n// Agent that might update state.put(\"status\")\nLlmAgent processingStepAgent = LlmAgent.builder().name(\"ProcessingStep\").build();\n// Custom agent instance for checking the condition\nCheckConditionAgent conditionCheckerAgent = new CheckConditionAgent(\n    \"ConditionChecker\",\n    \"Checks if the status is 'completed'.\"\n);\nLoopAgent poller = LoopAgent.builder().name(\"StatusPoller\").maxIterations(10).subAgents(processingStepAgent, conditionCheckerAgent).build();\n// When poller runs, it executes processingStepAgent then conditionCheckerAgent repeatedly\n// until Checker escalates (state.get(\"status\") == \"completed\") or 10 iterations pass."}, {"language": "text", "code": "import (\n    \"iter\"\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/agent/workflowagents/loopagent\"\n    \"google.golang.org/adk/session\"\n)\n\n// Conceptual Example: Loop with Condition\n// Custom agent to check state\ncheckCondition, _ := agent.New(agent.Config{\n    Name: \"Checker\",\n    Run: func(ctx agent.InvocationContext) iter.Seq2[*session.Event, error] {\n        return func(yield func(*session.Event, error) bool) {\n            status, err := ctx.Session().State().Get(\"status\")\n            // If \"status\" is not in the state, default to \"pending\".\n            // This is idiomatic Go for handling a potential error on lookup.\n            if err != nil {\n                status = \"pending\"\n            }\n            isDone := status == \"completed\"\n            yield(&session.Event{Author: \"Checker\", Actions: session.EventActions{Escalate: isDone}}, nil)\n        }\n    },\n})\n\nprocessStep, _ := llmagent.New(llmagent.Config{Name: \"ProcessingStep\", Model: m}) // Agent that might update state[\"status\"]\n\npoller, _ := loopagent.New(loopagent.Config{\n    MaxIterations: 10,\n    AgentConfig:   agent.Config{Name: \"StatusPoller\", SubAgents: []agent.Agent{processStep, checkCondition}},\n})\n// When poller runs, it executes processStep then Checker repeatedly\n// until Checker escalates (state[\"status\"] == \"completed\") or 10 iterations pass."}]}, {"heading_path": ["1.3. Interaction & Communication Mechanisms\u00b6"], "text": "1.3. Interaction & Communication Mechanisms \u00b6 Agents within a system often need to exchange data or trigger actions in one another. ADK facilitates this through: ", "code_blocks": []}, {"heading_path": ["a) Shared Session State (session.state)\u00b6"], "text": "a) Shared Session State ( session.state ) \u00b6 The most fundamental way for agents operating within the same invocation (and thus sharing the same Session object via the InvocationContext ) to communicate passively. Mechanism: One agent (or its tool/callback) writes a value ( context.state['data_key'] = processed_data ), and a subsequent agent reads it ( data = context.state.get('data_key') ). State changes are tracked via CallbackContext . Convenience: The output_key property on LlmAgent automatically saves the agent's final response text (or structured output) to the specified state key. Nature: Asynchronous, passive communication. Ideal for pipelines orchestrated by SequentialAgent or passing data across LoopAgent iterations. See Also: State Management Invocation Context and temp: State When a parent agent invokes a sub-agent, it passes the same InvocationContext . This means they share the same temporary ( temp: ) state, which is ideal for passing data that is only relevant for the current turn. Python Java Go # Conceptual Example: Using output_key and reading state from google.adk.agents import LlmAgent , SequentialAgent agent_A = LlmAgent ( name = \"AgentA\" , instruction = \"Find the capital of France.\" , output_key = \"capital_city\" ) agent_B = LlmAgent ( name = \"AgentB\" , instruction = \"Tell me about the city stored in {capital_city} .\" ) pipeline = SequentialAgent ( name = \"CityInfo\" , sub_agents = [ agent_A , agent_B ]) # AgentA runs, saves \"Paris\" to state['capital_city']. # AgentB runs, its instruction processor reads state['capital_city'] to get \"Paris\". // Conceptual Example: Using outputKey and reading state import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.SequentialAgent ; LlmAgent agentA = LlmAgent . builder () . name ( \"AgentA\" ) . instruction ( \"Find the capital of France.\" ) . outputKey ( \"capital_city\" ) . build (); LlmAgent agentB = LlmAgent . builder () . name ( \"AgentB\" ) . instruction ( \"Tell me about the city stored in {capital_city}.\" ) . outputKey ( \"capital_city\" ) . build (); SequentialAgent pipeline = SequentialAgent . builder (). name ( \"CityInfo\" ). subAgents ( agentA , agentB ). build (); // AgentA runs, saves \"Paris\" to state('capital_city'). // AgentB runs, its instruction processor reads state.get(\"capital_city\") to get \"Paris\". import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/agent/workflowagents/sequentialagent\" ) // Conceptual Example: Using output_key and reading state agentA , _ := llmagent . New ( llmagent . Config { Name : \"AgentA\" , Instruction : \"Find the capital of France.\" , OutputKey : \"capital_city\" , Model : m }) agentB , _ := llmagent . New ( llmagent . Config { Name : \"AgentB\" , Instruction : \"Tell me about the city stored in {capital_city}.\" , Model : m }) pipeline2 , _ := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : \"CityInfo\" , SubAgents : [] agent . Agent { agentA , agentB }}, }) // AgentA runs, saves \"Paris\" to state[\"capital_city\"]. // AgentB runs, its instruction processor reads state[\"capital_city\"] to get \"Paris\". ", "code_blocks": [{"language": "text", "code": "# Conceptual Example: Using output_key and reading state\nfrom google.adk.agents import LlmAgent, SequentialAgent\n\nagent_A = LlmAgent(name=\"AgentA\", instruction=\"Find the capital of France.\", output_key=\"capital_city\")\nagent_B = LlmAgent(name=\"AgentB\", instruction=\"Tell me about the city stored in {capital_city}.\")\n\npipeline = SequentialAgent(name=\"CityInfo\", sub_agents=[agent_A, agent_B])\n# AgentA runs, saves \"Paris\" to state['capital_city'].\n# AgentB runs, its instruction processor reads state['capital_city'] to get \"Paris\"."}, {"language": "text", "code": "// Conceptual Example: Using outputKey and reading state\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.SequentialAgent;\n\nLlmAgent agentA = LlmAgent.builder()\n    .name(\"AgentA\")\n    .instruction(\"Find the capital of France.\")\n    .outputKey(\"capital_city\")\n    .build();\n\nLlmAgent agentB = LlmAgent.builder()\n    .name(\"AgentB\")\n    .instruction(\"Tell me about the city stored in {capital_city}.\")\n    .outputKey(\"capital_city\")\n    .build();\n\nSequentialAgent pipeline = SequentialAgent.builder().name(\"CityInfo\").subAgents(agentA, agentB).build();\n// AgentA runs, saves \"Paris\" to state('capital_city').\n// AgentB runs, its instruction processor reads state.get(\"capital_city\") to get \"Paris\"."}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/agent/workflowagents/sequentialagent\"\n)\n\n// Conceptual Example: Using output_key and reading state\nagentA, _ := llmagent.New(llmagent.Config{Name: \"AgentA\", Instruction: \"Find the capital of France.\", OutputKey: \"capital_city\", Model: m})\nagentB, _ := llmagent.New(llmagent.Config{Name: \"AgentB\", Instruction: \"Tell me about the city stored in {capital_city}.\", Model: m})\n\npipeline2, _ := sequentialagent.New(sequentialagent.Config{\n    AgentConfig: agent.Config{Name: \"CityInfo\", SubAgents: []agent.Agent{agentA, agentB}},\n})\n// AgentA runs, saves \"Paris\" to state[\"capital_city\"].\n// AgentB runs, its instruction processor reads state[\"capital_city\"] to get \"Paris\"."}]}, {"heading_path": ["b) LLM-Driven Delegation (Agent Transfer)\u00b6"], "text": "b) LLM-Driven Delegation (Agent Transfer) \u00b6 Leverages an LlmAgent 's understanding to dynamically route tasks to other suitable agents within the hierarchy. Mechanism: The agent's LLM generates a specific function call: transfer_to_agent(agent_name='target_agent_name') . Handling: The AutoFlow , used by default when sub-agents are present or transfer isn't disallowed, intercepts this call. It identifies the target agent using root_agent.find_agent() and updates the InvocationContext to switch execution focus. Requires: The calling LlmAgent needs clear instructions on when to transfer, and potential target agents need distinct description s for the LLM to make informed decisions. Transfer scope (parent, sub-agent, siblings) can be configured on the LlmAgent . Nature: Dynamic, flexible routing based on LLM interpretation. Python Java Go # Conceptual Setup: LLM Transfer from google.adk.agents import LlmAgent booking_agent = LlmAgent ( name = \"Booker\" , description = \"Handles flight and hotel bookings.\" ) info_agent = LlmAgent ( name = \"Info\" , description = \"Provides general information and answers questions.\" ) coordinator = LlmAgent ( name = \"Coordinator\" , model = \"gemini-2.0-flash\" , instruction = \"You are an assistant. Delegate booking tasks to Booker and info requests to Info.\" , description = \"Main coordinator.\" , # AutoFlow is typically used implicitly here sub_agents = [ booking_agent , info_agent ] ) # If coordinator receives \"Book a flight\", its LLM should generate: # FunctionCall(name='transfer_to_agent', args={'agent_name': 'Booker'}) # ADK framework then routes execution to booking_agent. // Conceptual Setup: LLM Transfer import com.google.adk.agents.LlmAgent ; LlmAgent bookingAgent = LlmAgent . builder () . name ( \"Booker\" ) . description ( \"Handles flight and hotel bookings.\" ) . build (); LlmAgent infoAgent = LlmAgent . builder () . name ( \"Info\" ) . description ( \"Provides general information and answers questions.\" ) . build (); // Define the coordinator agent LlmAgent coordinator = LlmAgent . builder () . name ( \"Coordinator\" ) . model ( \"gemini-2.0-flash\" ) // Or your desired model . instruction ( \"You are an assistant. Delegate booking tasks to Booker and info requests to Info.\" ) . description ( \"Main coordinator.\" ) // AutoFlow will be used by default (implicitly) because subAgents are present // and transfer is not disallowed. . subAgents ( bookingAgent , infoAgent ) . build (); // If coordinator receives \"Book a flight\", its LLM should generate: // FunctionCall.builder.name(\"transferToAgent\").args(ImmutableMap.of(\"agent_name\", \"Booker\")).build() // ADK framework then routes execution to bookingAgent. import ( \"google.golang.org/adk/agent/llmagent\" ) // Conceptual Setup: LLM Transfer bookingAgent , _ := llmagent . New ( llmagent . Config { Name : \"Booker\" , Description : \"Handles flight and hotel bookings.\" , Model : m }) infoAgent , _ := llmagent . New ( llmagent . Config { Name : \"Info\" , Description : \"Provides general information and answers questions.\" , Model : m }) coordinator , _ = llmagent . New ( llmagent . Config { Name : \"Coordinator\" , Model : m , Instruction : \"You are an assistant. Delegate booking tasks to Booker and info requests to Info.\" , Description : \"Main coordinator.\" , SubAgents : [] agent . Agent { bookingAgent , infoAgent }, }) // If coordinator receives \"Book a flight\", its LLM should generate: // FunctionCall{Name: \"transfer_to_agent\", Args: map[string]any{\"agent_name\": \"Booker\"}} // ADK framework then routes execution to bookingAgent. ", "code_blocks": [{"language": "text", "code": "# Conceptual Setup: LLM Transfer\nfrom google.adk.agents import LlmAgent\n\nbooking_agent = LlmAgent(name=\"Booker\", description=\"Handles flight and hotel bookings.\")\ninfo_agent = LlmAgent(name=\"Info\", description=\"Provides general information and answers questions.\")\n\ncoordinator = LlmAgent(\n    name=\"Coordinator\",\n    model=\"gemini-2.0-flash\",\n    instruction=\"You are an assistant. Delegate booking tasks to Booker and info requests to Info.\",\n    description=\"Main coordinator.\",\n    # AutoFlow is typically used implicitly here\n    sub_agents=[booking_agent, info_agent]\n)\n# If coordinator receives \"Book a flight\", its LLM should generate:\n# FunctionCall(name='transfer_to_agent', args={'agent_name': 'Booker'})\n# ADK framework then routes execution to booking_agent."}, {"language": "text", "code": "// Conceptual Setup: LLM Transfer\nimport com.google.adk.agents.LlmAgent;\n\nLlmAgent bookingAgent = LlmAgent.builder()\n    .name(\"Booker\")\n    .description(\"Handles flight and hotel bookings.\")\n    .build();\n\nLlmAgent infoAgent = LlmAgent.builder()\n    .name(\"Info\")\n    .description(\"Provides general information and answers questions.\")\n    .build();\n\n// Define the coordinator agent\nLlmAgent coordinator = LlmAgent.builder()\n    .name(\"Coordinator\")\n    .model(\"gemini-2.0-flash\") // Or your desired model\n    .instruction(\"You are an assistant. Delegate booking tasks to Booker and info requests to Info.\")\n    .description(\"Main coordinator.\")\n    // AutoFlow will be used by default (implicitly) because subAgents are present\n    // and transfer is not disallowed.\n    .subAgents(bookingAgent, infoAgent)\n    .build();\n\n// If coordinator receives \"Book a flight\", its LLM should generate:\n// FunctionCall.builder.name(\"transferToAgent\").args(ImmutableMap.of(\"agent_name\", \"Booker\")).build()\n// ADK framework then routes execution to bookingAgent."}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent/llmagent\"\n)\n\n// Conceptual Setup: LLM Transfer\nbookingAgent, _ := llmagent.New(llmagent.Config{Name: \"Booker\", Description: \"Handles flight and hotel bookings.\", Model: m})\ninfoAgent, _ := llmagent.New(llmagent.Config{Name: \"Info\", Description: \"Provides general information and answers questions.\", Model: m})\n\ncoordinator, _ = llmagent.New(llmagent.Config{\n    Name:        \"Coordinator\",\n    Model:       m,\n    Instruction: \"You are an assistant. Delegate booking tasks to Booker and info requests to Info.\",\n    Description: \"Main coordinator.\",\n    SubAgents:   []agent.Agent{bookingAgent, infoAgent},\n})\n\n// If coordinator receives \"Book a flight\", its LLM should generate:\n// FunctionCall{Name: \"transfer_to_agent\", Args: map[string]any{\"agent_name\": \"Booker\"}}\n// ADK framework then routes execution to bookingAgent."}]}, {"heading_path": ["c) Explicit Invocation (AgentTool)\u00b6"], "text": "c) Explicit Invocation ( AgentTool ) \u00b6 Allows an LlmAgent to treat another BaseAgent instance as a callable function or Tool . Mechanism: Wrap the target agent instance in AgentTool and include it in the parent LlmAgent 's tools list. AgentTool generates a corresponding function declaration for the LLM. Handling: When the parent LLM generates a function call targeting the AgentTool , the framework executes AgentTool.run_async . This method runs the target agent, captures its final response, forwards any state/artifact changes back to the parent's context, and returns the response as the tool's result. Nature: Synchronous (within the parent's flow), explicit, controlled invocation like any other tool. (Note: AgentTool needs to be imported and used explicitly). Python Java Go # Conceptual Setup: Agent as a Tool from google.adk.agents import LlmAgent , BaseAgent from google.adk.tools import agent_tool from pydantic import BaseModel # Define a target agent (could be LlmAgent or custom BaseAgent) class ImageGeneratorAgent ( BaseAgent ): # Example custom agent name : str = \"ImageGen\" description : str = \"Generates an image based on a prompt.\" # ... internal logic ... async def _run_async_impl ( self , ctx ): # Simplified run logic prompt = ctx . session . state . get ( \"image_prompt\" , \"default prompt\" ) # ... generate image bytes ... image_bytes = b \"...\" yield Event ( author = self . name , content = types . Content ( parts = [ types . Part . from_bytes ( image_bytes , \"image/png\" )])) image_agent = ImageGeneratorAgent () image_tool = agent_tool . AgentTool ( agent = image_agent ) # Wrap the agent # Parent agent uses the AgentTool artist_agent = LlmAgent ( name = \"Artist\" , model = \"gemini-2.0-flash\" , instruction = \"Create a prompt and use the ImageGen tool to generate the image.\" , tools = [ image_tool ] # Include the AgentTool ) # Artist LLM generates a prompt, then calls: # FunctionCall(name='ImageGen', args={'image_prompt': 'a cat wearing a hat'}) # Framework calls image_tool.run_async(...), which runs ImageGeneratorAgent. # The resulting image Part is returned to the Artist agent as the tool result. // Conceptual Setup: Agent as a Tool import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.LlmAgent ; import com.google.adk.tools.AgentTool ; // Example custom agent (could be LlmAgent or custom BaseAgent) public class ImageGeneratorAgent extends BaseAgent { public ImageGeneratorAgent ( String name , String description ) { super ( name , description , List . of (), null , null ); } // ... internal logic ... @Override protected Flowable < Event > runAsyncImpl ( InvocationContext invocationContext ) { // Simplified run logic invocationContext . session (). state (). get ( \"image_prompt\" ); // Generate image bytes // ... Event responseEvent = Event . builder () . author ( this . name ()) . content ( Content . fromParts ( Part . fromText ( \"\\b...\" ))) . build (); return Flowable . just ( responseEvent ); } @Override protected Flowable < Event > runLiveImpl ( InvocationContext invocationContext ) { return null ; } } // Wrap the agent using AgentTool ImageGeneratorAgent imageAgent = new ImageGeneratorAgent ( \"image_agent\" , \"generates images\" ); AgentTool imageTool = AgentTool . create ( imageAgent ); // Parent agent uses the AgentTool LlmAgent artistAgent = LlmAgent . builder () . name ( \"Artist\" ) . model ( \"gemini-2.0-flash\" ) . instruction ( \"You are an artist. Create a detailed prompt for an image and then \" + \"use the 'ImageGen' tool to generate the image. \" + \"The 'ImageGen' tool expects a single string argument named 'request' \" + \"containing the image prompt. The tool will return a JSON string in its \" + \"'result' field, containing 'image_base64', 'mime_type', and 'status'.\" ) . description ( \"An agent that can create images using a generation tool.\" ) . tools ( imageTool ) // Include the AgentTool . build (); // Artist LLM generates a prompt, then calls: // FunctionCall(name='ImageGen', args={'imagePrompt': 'a cat wearing a hat'}) // Framework calls imageTool.runAsync(...), which runs ImageGeneratorAgent. // The resulting image Part is returned to the Artist agent as the tool result. import ( \"fmt\" \"iter\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/agenttool\" \"google.golang.org/genai\" ) // Conceptual Setup: Agent as a Tool // Define a target agent (could be LlmAgent or custom BaseAgent) imageAgent , _ := agent . New ( agent . Config { Name : \"ImageGen\" , Description : \"Generates an image based on a prompt.\" , Run : func ( ctx agent . InvocationContext ) iter . Seq2 [ * session . Event , error ] { return func ( yield func ( * session . Event , error ) bool ) { prompt , _ := ctx . Session (). State (). Get ( \"image_prompt\" ) fmt . Printf ( \"Generating image for prompt: %v\\n\" , prompt ) imageBytes := [] byte ( \"...\" ) // Simulate image bytes yield ( & session . Event { Author : \"ImageGen\" , LLMResponse : model . LLMResponse { Content : & genai . Content { Parts : [] * genai . Part { genai . NewPartFromBytes ( imageBytes , \"image/png\" )}, }, }, }, nil ) } }, }) // Wrap the agent imageTool := agenttool . New ( imageAgent , nil ) // Now imageTool can be used as a tool by other agents. // Parent agent uses the AgentTool artistAgent , _ := llmagent . New ( llmagent . Config { Name : \"Artist\" , Model : m , Instruction : \"Create a prompt and use the ImageGen tool to generate the image.\" , Tools : [] tool . Tool { imageTool }, // Include the AgentTool }) // Artist LLM generates a prompt, then calls: // FunctionCall{Name: \"ImageGen\", Args: map[string]any{\"image_prompt\": \"a cat wearing a hat\"}} // Framework calls imageTool.Run(...), which runs ImageGeneratorAgent. // The resulting image Part is returned to the Artist agent as the tool result. These primitives provide the flexibility to design multi-agent interactions ranging from tightly coupled sequential workflows to dynamic, LLM-driven delegation networks. ", "code_blocks": [{"language": "text", "code": "# Conceptual Setup: Agent as a Tool\nfrom google.adk.agents import LlmAgent, BaseAgent\nfrom google.adk.tools import agent_tool\nfrom pydantic import BaseModel\n\n# Define a target agent (could be LlmAgent or custom BaseAgent)\nclass ImageGeneratorAgent(BaseAgent): # Example custom agent\n    name: str = \"ImageGen\"\n    description: str = \"Generates an image based on a prompt.\"\n    # ... internal logic ...\n    async def _run_async_impl(self, ctx): # Simplified run logic\n        prompt = ctx.session.state.get(\"image_prompt\", \"default prompt\")\n        # ... generate image bytes ...\n        image_bytes = b\"...\"\n        yield Event(author=self.name, content=types.Content(parts=[types.Part.from_bytes(image_bytes, \"image/png\")]))\n\nimage_agent = ImageGeneratorAgent()\nimage_tool = agent_tool.AgentTool(agent=image_agent) # Wrap the agent\n\n# Parent agent uses the AgentTool\nartist_agent = LlmAgent(\n    name=\"Artist\",\n    model=\"gemini-2.0-flash\",\n    instruction=\"Create a prompt and use the ImageGen tool to generate the image.\",\n    tools=[image_tool] # Include the AgentTool\n)\n# Artist LLM generates a prompt, then calls:\n# FunctionCall(name='ImageGen', args={'image_prompt': 'a cat wearing a hat'})\n# Framework calls image_tool.run_async(...), which runs ImageGeneratorAgent.\n# The resulting image Part is returned to the Artist agent as the tool result."}, {"language": "text", "code": "// Conceptual Setup: Agent as a Tool\nimport com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.tools.AgentTool;\n\n// Example custom agent (could be LlmAgent or custom BaseAgent)\npublic class ImageGeneratorAgent extends BaseAgent  {\n\n  public ImageGeneratorAgent(String name, String description) {\n    super(name, description, List.of(), null, null);\n  }\n\n  // ... internal logic ...\n  @Override\n  protected Flowable<Event> runAsyncImpl(InvocationContext invocationContext) { // Simplified run logic\n    invocationContext.session().state().get(\"image_prompt\");\n    // Generate image bytes\n    // ...\n\n    Event responseEvent = Event.builder()\n        .author(this.name())\n        .content(Content.fromParts(Part.fromText(\"\\b...\")))\n        .build();\n\n    return Flowable.just(responseEvent);\n  }\n\n  @Override\n  protected Flowable<Event> runLiveImpl(InvocationContext invocationContext) {\n    return null;\n  }\n}\n\n// Wrap the agent using AgentTool\nImageGeneratorAgent imageAgent = new ImageGeneratorAgent(\"image_agent\", \"generates images\");\nAgentTool imageTool = AgentTool.create(imageAgent);\n\n// Parent agent uses the AgentTool\nLlmAgent artistAgent = LlmAgent.builder()\n        .name(\"Artist\")\n        .model(\"gemini-2.0-flash\")\n        .instruction(\n                \"You are an artist. Create a detailed prompt for an image and then \" +\n                        \"use the 'ImageGen' tool to generate the image. \" +\n                        \"The 'ImageGen' tool expects a single string argument named 'request' \" +\n                        \"containing the image prompt. The tool will return a JSON string in its \" +\n                        \"'result' field, containing 'image_base64', 'mime_type', and 'status'.\"\n        )\n        .description(\"An agent that can create images using a generation tool.\")\n        .tools(imageTool) // Include the AgentTool\n        .build();\n\n// Artist LLM generates a prompt, then calls:\n// FunctionCall(name='ImageGen', args={'imagePrompt': 'a cat wearing a hat'})\n// Framework calls imageTool.runAsync(...), which runs ImageGeneratorAgent.\n// The resulting image Part is returned to the Artist agent as the tool result."}, {"language": "text", "code": "import (\n    \"fmt\"\n    \"iter\"\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/agenttool\"\n    \"google.golang.org/genai\"\n)\n\n// Conceptual Setup: Agent as a Tool\n// Define a target agent (could be LlmAgent or custom BaseAgent)\nimageAgent, _ := agent.New(agent.Config{\n    Name:        \"ImageGen\",\n    Description: \"Generates an image based on a prompt.\",\n    Run: func(ctx agent.InvocationContext) iter.Seq2[*session.Event, error] {\n        return func(yield func(*session.Event, error) bool) {\n            prompt, _ := ctx.Session().State().Get(\"image_prompt\")\n            fmt.Printf(\"Generating image for prompt: %v\\n\", prompt)\n            imageBytes := []byte(\"...\") // Simulate image bytes\n            yield(&session.Event{\n                Author: \"ImageGen\",\n                LLMResponse: model.LLMResponse{\n                    Content: &genai.Content{\n                        Parts: []*genai.Part{genai.NewPartFromBytes(imageBytes, \"image/png\")},\n                    },\n                },\n            }, nil)\n        }\n    },\n})\n\n// Wrap the agent\nimageTool := agenttool.New(imageAgent, nil)\n\n// Now imageTool can be used as a tool by other agents.\n\n// Parent agent uses the AgentTool\nartistAgent, _ := llmagent.New(llmagent.Config{\n    Name:        \"Artist\",\n    Model:       m,\n    Instruction: \"Create a prompt and use the ImageGen tool to generate the image.\",\n    Tools:       []tool.Tool{imageTool}, // Include the AgentTool\n})\n// Artist LLM generates a prompt, then calls:\n// FunctionCall{Name: \"ImageGen\", Args: map[string]any{\"image_prompt\": \"a cat wearing a hat\"}}\n// Framework calls imageTool.Run(...), which runs ImageGeneratorAgent.\n// The resulting image Part is returned to the Artist agent as the tool result."}]}, {"heading_path": ["2. Common Multi-Agent Patterns using ADK Primitives\u00b6"], "text": "2. Common Multi-Agent Patterns using ADK Primitives \u00b6 By combining ADK's composition primitives, you can implement various established patterns for multi-agent collaboration. ", "code_blocks": []}, {"heading_path": ["Coordinator/Dispatcher Pattern\u00b6"], "text": "Coordinator/Dispatcher Pattern \u00b6 Structure: A central LlmAgent (Coordinator) manages several specialized sub_agents . Goal: Route incoming requests to the appropriate specialist agent. ADK Primitives Used: Hierarchy: Coordinator has specialists listed in sub_agents . Interaction: Primarily uses LLM-Driven Delegation (requires clear description s on sub-agents and appropriate instruction on Coordinator) or Explicit Invocation ( AgentTool ) (Coordinator includes AgentTool -wrapped specialists in its tools ). Python Java Go # Conceptual Code: Coordinator using LLM Transfer from google.adk.agents import LlmAgent billing_agent = LlmAgent ( name = \"Billing\" , description = \"Handles billing inquiries.\" ) support_agent = LlmAgent ( name = \"Support\" , description = \"Handles technical support requests.\" ) coordinator = LlmAgent ( name = \"HelpDeskCoordinator\" , model = \"gemini-2.0-flash\" , instruction = \"Route user requests: Use Billing agent for payment issues, Support agent for technical problems.\" , description = \"Main help desk router.\" , # allow_transfer=True is often implicit with sub_agents in AutoFlow sub_agents = [ billing_agent , support_agent ] ) # User asks \"My payment failed\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Billing') # User asks \"I can't log in\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Support') // Conceptual Code: Coordinator using LLM Transfer import com.google.adk.agents.LlmAgent ; LlmAgent billingAgent = LlmAgent . builder () . name ( \"Billing\" ) . description ( \"Handles billing inquiries and payment issues.\" ) . build (); LlmAgent supportAgent = LlmAgent . builder () . name ( \"Support\" ) . description ( \"Handles technical support requests and login problems.\" ) . build (); LlmAgent coordinator = LlmAgent . builder () . name ( \"HelpDeskCoordinator\" ) . model ( \"gemini-2.0-flash\" ) . instruction ( \"Route user requests: Use Billing agent for payment issues, Support agent for technical problems.\" ) . description ( \"Main help desk router.\" ) . subAgents ( billingAgent , supportAgent ) // Agent transfer is implicit with sub agents in the Autoflow, unless specified // using .disallowTransferToParent or disallowTransferToPeers . build (); // User asks \"My payment failed\" -> Coordinator's LLM should call // transferToAgent(agentName='Billing') // User asks \"I can't log in\" -> Coordinator's LLM should call // transferToAgent(agentName='Support') import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" ) // Conceptual Code: Coordinator using LLM Transfer billingAgent , _ := llmagent . New ( llmagent . Config { Name : \"Billing\" , Description : \"Handles billing inquiries.\" , Model : m }) supportAgent , _ := llmagent . New ( llmagent . Config { Name : \"Support\" , Description : \"Handles technical support requests.\" , Model : m }) coordinator , _ := llmagent . New ( llmagent . Config { Name : \"HelpDeskCoordinator\" , Model : m , Instruction : \"Route user requests: Use Billing agent for payment issues, Support agent for technical problems.\" , Description : \"Main help desk router.\" , SubAgents : [] agent . Agent { billingAgent , supportAgent }, }) // User asks \"My payment failed\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Billing') // User asks \"I can't log in\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Support') ", "code_blocks": [{"language": "text", "code": "# Conceptual Code: Coordinator using LLM Transfer\nfrom google.adk.agents import LlmAgent\n\nbilling_agent = LlmAgent(name=\"Billing\", description=\"Handles billing inquiries.\")\nsupport_agent = LlmAgent(name=\"Support\", description=\"Handles technical support requests.\")\n\ncoordinator = LlmAgent(\n    name=\"HelpDeskCoordinator\",\n    model=\"gemini-2.0-flash\",\n    instruction=\"Route user requests: Use Billing agent for payment issues, Support agent for technical problems.\",\n    description=\"Main help desk router.\",\n    # allow_transfer=True is often implicit with sub_agents in AutoFlow\n    sub_agents=[billing_agent, support_agent]\n)\n# User asks \"My payment failed\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Billing')\n# User asks \"I can't log in\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Support')"}, {"language": "text", "code": "// Conceptual Code: Coordinator using LLM Transfer\nimport com.google.adk.agents.LlmAgent;\n\nLlmAgent billingAgent = LlmAgent.builder()\n    .name(\"Billing\")\n    .description(\"Handles billing inquiries and payment issues.\")\n    .build();\n\nLlmAgent supportAgent = LlmAgent.builder()\n    .name(\"Support\")\n    .description(\"Handles technical support requests and login problems.\")\n    .build();\n\nLlmAgent coordinator = LlmAgent.builder()\n    .name(\"HelpDeskCoordinator\")\n    .model(\"gemini-2.0-flash\")\n    .instruction(\"Route user requests: Use Billing agent for payment issues, Support agent for technical problems.\")\n    .description(\"Main help desk router.\")\n    .subAgents(billingAgent, supportAgent)\n    // Agent transfer is implicit with sub agents in the Autoflow, unless specified\n    // using .disallowTransferToParent or disallowTransferToPeers\n    .build();\n\n// User asks \"My payment failed\" -> Coordinator's LLM should call\n// transferToAgent(agentName='Billing')\n// User asks \"I can't log in\" -> Coordinator's LLM should call\n// transferToAgent(agentName='Support')"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n)\n\n// Conceptual Code: Coordinator using LLM Transfer\nbillingAgent, _ := llmagent.New(llmagent.Config{Name: \"Billing\", Description: \"Handles billing inquiries.\", Model: m})\nsupportAgent, _ := llmagent.New(llmagent.Config{Name: \"Support\", Description: \"Handles technical support requests.\", Model: m})\n\ncoordinator, _ := llmagent.New(llmagent.Config{\n    Name:        \"HelpDeskCoordinator\",\n    Model:       m,\n    Instruction: \"Route user requests: Use Billing agent for payment issues, Support agent for technical problems.\",\n    Description: \"Main help desk router.\",\n    SubAgents:   []agent.Agent{billingAgent, supportAgent},\n})\n// User asks \"My payment failed\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Billing')\n// User asks \"I can't log in\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Support')"}]}, {"heading_path": ["Sequential Pipeline Pattern\u00b6"], "text": "Sequential Pipeline Pattern \u00b6 Structure: A SequentialAgent contains sub_agents executed in a fixed order. Goal: Implement a multi-step process where the output of one step feeds into the next. ADK Primitives Used: Workflow: SequentialAgent defines the order. Communication: Primarily uses Shared Session State . Earlier agents write results (often via output_key ), later agents read those results from context.state . Python Java Go # Conceptual Code: Sequential Data Pipeline from google.adk.agents import SequentialAgent , LlmAgent validator = LlmAgent ( name = \"ValidateInput\" , instruction = \"Validate the input.\" , output_key = \"validation_status\" ) processor = LlmAgent ( name = \"ProcessData\" , instruction = \"Process data if {validation_status} is 'valid'.\" , output_key = \"result\" ) reporter = LlmAgent ( name = \"ReportResult\" , instruction = \"Report the result from {result} .\" ) data_pipeline = SequentialAgent ( name = \"DataPipeline\" , sub_agents = [ validator , processor , reporter ] ) # validator runs -> saves to state['validation_status'] # processor runs -> reads state['validation_status'], saves to state['result'] # reporter runs -> reads state['result'] // Conceptual Code: Sequential Data Pipeline import com.google.adk.agents.SequentialAgent ; LlmAgent validator = LlmAgent . builder () . name ( \"ValidateInput\" ) . instruction ( \"Validate the input\" ) . outputKey ( \"validation_status\" ) // Saves its main text output to session.state[\"validation_status\"] . build (); LlmAgent processor = LlmAgent . builder () . name ( \"ProcessData\" ) . instruction ( \"Process data if {validation_status} is 'valid'\" ) . outputKey ( \"result\" ) // Saves its main text output to session.state[\"result\"] . build (); LlmAgent reporter = LlmAgent . builder () . name ( \"ReportResult\" ) . instruction ( \"Report the result from {result}\" ) . build (); SequentialAgent dataPipeline = SequentialAgent . builder () . name ( \"DataPipeline\" ) . subAgents ( validator , processor , reporter ) . build (); // validator runs -> saves to state['validation_status'] // processor runs -> reads state['validation_status'], saves to state['result'] // reporter runs -> reads state['result'] import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/agent/workflowagents/sequentialagent\" ) // Conceptual Code: Sequential Data Pipeline validator , _ := llmagent . New ( llmagent . Config { Name : \"ValidateInput\" , Instruction : \"Validate the input.\" , OutputKey : \"validation_status\" , Model : m }) processor , _ := llmagent . New ( llmagent . Config { Name : \"ProcessData\" , Instruction : \"Process data if {validation_status} is 'valid'.\" , OutputKey : \"result\" , Model : m }) reporter , _ := llmagent . New ( llmagent . Config { Name : \"ReportResult\" , Instruction : \"Report the result from {result}.\" , Model : m }) dataPipeline , _ := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : \"DataPipeline\" , SubAgents : [] agent . Agent { validator , processor , reporter }}, }) // validator runs -> saves to state[\"validation_status\"] // processor runs -> reads state[\"validation_status\"], saves to state[\"result\"] // reporter runs -> reads state[\"result\"] ", "code_blocks": [{"language": "text", "code": "# Conceptual Code: Sequential Data Pipeline\nfrom google.adk.agents import SequentialAgent, LlmAgent\n\nvalidator = LlmAgent(name=\"ValidateInput\", instruction=\"Validate the input.\", output_key=\"validation_status\")\nprocessor = LlmAgent(name=\"ProcessData\", instruction=\"Process data if {validation_status} is 'valid'.\", output_key=\"result\")\nreporter = LlmAgent(name=\"ReportResult\", instruction=\"Report the result from {result}.\")\n\ndata_pipeline = SequentialAgent(\n    name=\"DataPipeline\",\n    sub_agents=[validator, processor, reporter]\n)\n# validator runs -> saves to state['validation_status']\n# processor runs -> reads state['validation_status'], saves to state['result']\n# reporter runs -> reads state['result']"}, {"language": "text", "code": "// Conceptual Code: Sequential Data Pipeline\nimport com.google.adk.agents.SequentialAgent;\n\nLlmAgent validator = LlmAgent.builder()\n    .name(\"ValidateInput\")\n    .instruction(\"Validate the input\")\n    .outputKey(\"validation_status\") // Saves its main text output to session.state[\"validation_status\"]\n    .build();\n\nLlmAgent processor = LlmAgent.builder()\n    .name(\"ProcessData\")\n    .instruction(\"Process data if {validation_status} is 'valid'\")\n    .outputKey(\"result\") // Saves its main text output to session.state[\"result\"]\n    .build();\n\nLlmAgent reporter = LlmAgent.builder()\n    .name(\"ReportResult\")\n    .instruction(\"Report the result from {result}\")\n    .build();\n\nSequentialAgent dataPipeline = SequentialAgent.builder()\n    .name(\"DataPipeline\")\n    .subAgents(validator, processor, reporter)\n    .build();\n\n// validator runs -> saves to state['validation_status']\n// processor runs -> reads state['validation_status'], saves to state['result']\n// reporter runs -> reads state['result']"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/agent/workflowagents/sequentialagent\"\n)\n\n// Conceptual Code: Sequential Data Pipeline\nvalidator, _ := llmagent.New(llmagent.Config{Name: \"ValidateInput\", Instruction: \"Validate the input.\", OutputKey: \"validation_status\", Model: m})\nprocessor, _ := llmagent.New(llmagent.Config{Name: \"ProcessData\", Instruction: \"Process data if {validation_status} is 'valid'.\", OutputKey: \"result\", Model: m})\nreporter, _ := llmagent.New(llmagent.Config{Name: \"ReportResult\", Instruction: \"Report the result from {result}.\", Model: m})\n\ndataPipeline, _ := sequentialagent.New(sequentialagent.Config{\n    AgentConfig: agent.Config{Name: \"DataPipeline\", SubAgents: []agent.Agent{validator, processor, reporter}},\n})\n// validator runs -> saves to state[\"validation_status\"]\n// processor runs -> reads state[\"validation_status\"], saves to state[\"result\"]\n// reporter runs -> reads state[\"result\"]"}]}, {"heading_path": ["Parallel Fan-Out/Gather Pattern\u00b6"], "text": "Parallel Fan-Out/Gather Pattern \u00b6 Structure: A ParallelAgent runs multiple sub_agents concurrently, often followed by a later agent (in a SequentialAgent ) that aggregates results. Goal: Execute independent tasks simultaneously to reduce latency, then combine their outputs. ADK Primitives Used: Workflow: ParallelAgent for concurrent execution (Fan-Out). Often nested within a SequentialAgent to handle the subsequent aggregation step (Gather). Communication: Sub-agents write results to distinct keys in Shared Session State . The subsequent \"Gather\" agent reads multiple state keys. Python Java Go # Conceptual Code: Parallel Information Gathering from google.adk.agents import SequentialAgent , ParallelAgent , LlmAgent fetch_api1 = LlmAgent ( name = \"API1Fetcher\" , instruction = \"Fetch data from API 1.\" , output_key = \"api1_data\" ) fetch_api2 = LlmAgent ( name = \"API2Fetcher\" , instruction = \"Fetch data from API 2.\" , output_key = \"api2_data\" ) gather_concurrently = ParallelAgent ( name = \"ConcurrentFetch\" , sub_agents = [ fetch_api1 , fetch_api2 ] ) synthesizer = LlmAgent ( name = \"Synthesizer\" , instruction = \"Combine results from {api1_data} and {api2_data} .\" ) overall_workflow = SequentialAgent ( name = \"FetchAndSynthesize\" , sub_agents = [ gather_concurrently , synthesizer ] # Run parallel fetch, then synthesize ) # fetch_api1 and fetch_api2 run concurrently, saving to state. # synthesizer runs afterwards, reading state['api1_data'] and state['api2_data']. // Conceptual Code: Parallel Information Gathering import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.ParallelAgent ; import com.google.adk.agents.SequentialAgent ; LlmAgent fetchApi1 = LlmAgent . builder () . name ( \"API1Fetcher\" ) . instruction ( \"Fetch data from API 1.\" ) . outputKey ( \"api1_data\" ) . build (); LlmAgent fetchApi2 = LlmAgent . builder () . name ( \"API2Fetcher\" ) . instruction ( \"Fetch data from API 2.\" ) . outputKey ( \"api2_data\" ) . build (); ParallelAgent gatherConcurrently = ParallelAgent . builder () . name ( \"ConcurrentFetcher\" ) . subAgents ( fetchApi2 , fetchApi1 ) . build (); LlmAgent synthesizer = LlmAgent . builder () . name ( \"Synthesizer\" ) . instruction ( \"Combine results from {api1_data} and {api2_data}.\" ) . build (); SequentialAgent overallWorfklow = SequentialAgent . builder () . name ( \"FetchAndSynthesize\" ) // Run parallel fetch, then synthesize . subAgents ( gatherConcurrently , synthesizer ) . build (); // fetch_api1 and fetch_api2 run concurrently, saving to state. // synthesizer runs afterwards, reading state['api1_data'] and state['api2_data']. import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/agent/workflowagents/parallelagent\" \"google.golang.org/adk/agent/workflowagents/sequentialagent\" ) // Conceptual Code: Parallel Information Gathering fetchAPI1 , _ := llmagent . New ( llmagent . Config { Name : \"API1Fetcher\" , Instruction : \"Fetch data from API 1.\" , OutputKey : \"api1_data\" , Model : m }) fetchAPI2 , _ := llmagent . New ( llmagent . Config { Name : \"API2Fetcher\" , Instruction : \"Fetch data from API 2.\" , OutputKey : \"api2_data\" , Model : m }) gatherConcurrently , _ := parallelagent . New ( parallelagent . Config { AgentConfig : agent . Config { Name : \"ConcurrentFetch\" , SubAgents : [] agent . Agent { fetchAPI1 , fetchAPI2 }}, }) synthesizer , _ := llmagent . New ( llmagent . Config { Name : \"Synthesizer\" , Instruction : \"Combine results from {api1_data} and {api2_data}.\" , Model : m }) overallWorkflow , _ := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : \"FetchAndSynthesize\" , SubAgents : [] agent . Agent { gatherConcurrently , synthesizer }}, }) // fetch_api1 and fetch_api2 run concurrently, saving to state. // synthesizer runs afterwards, reading state[\"api1_data\"] and state[\"api2_data\"]. ", "code_blocks": [{"language": "text", "code": "# Conceptual Code: Parallel Information Gathering\nfrom google.adk.agents import SequentialAgent, ParallelAgent, LlmAgent\n\nfetch_api1 = LlmAgent(name=\"API1Fetcher\", instruction=\"Fetch data from API 1.\", output_key=\"api1_data\")\nfetch_api2 = LlmAgent(name=\"API2Fetcher\", instruction=\"Fetch data from API 2.\", output_key=\"api2_data\")\n\ngather_concurrently = ParallelAgent(\n    name=\"ConcurrentFetch\",\n    sub_agents=[fetch_api1, fetch_api2]\n)\n\nsynthesizer = LlmAgent(\n    name=\"Synthesizer\",\n    instruction=\"Combine results from {api1_data} and {api2_data}.\"\n)\n\noverall_workflow = SequentialAgent(\n    name=\"FetchAndSynthesize\",\n    sub_agents=[gather_concurrently, synthesizer] # Run parallel fetch, then synthesize\n)\n# fetch_api1 and fetch_api2 run concurrently, saving to state.\n# synthesizer runs afterwards, reading state['api1_data'] and state['api2_data']."}, {"language": "text", "code": "// Conceptual Code: Parallel Information Gathering\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.ParallelAgent;\nimport com.google.adk.agents.SequentialAgent;\n\nLlmAgent fetchApi1 = LlmAgent.builder()\n    .name(\"API1Fetcher\")\n    .instruction(\"Fetch data from API 1.\")\n    .outputKey(\"api1_data\")\n    .build();\n\nLlmAgent fetchApi2 = LlmAgent.builder()\n    .name(\"API2Fetcher\")\n    .instruction(\"Fetch data from API 2.\")\n    .outputKey(\"api2_data\")\n    .build();\n\nParallelAgent gatherConcurrently = ParallelAgent.builder()\n    .name(\"ConcurrentFetcher\")\n    .subAgents(fetchApi2, fetchApi1)\n    .build();\n\nLlmAgent synthesizer = LlmAgent.builder()\n    .name(\"Synthesizer\")\n    .instruction(\"Combine results from {api1_data} and {api2_data}.\")\n    .build();\n\nSequentialAgent overallWorfklow = SequentialAgent.builder()\n    .name(\"FetchAndSynthesize\") // Run parallel fetch, then synthesize\n    .subAgents(gatherConcurrently, synthesizer)\n    .build();\n\n// fetch_api1 and fetch_api2 run concurrently, saving to state.\n// synthesizer runs afterwards, reading state['api1_data'] and state['api2_data']."}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/agent/workflowagents/parallelagent\"\n    \"google.golang.org/adk/agent/workflowagents/sequentialagent\"\n)\n\n// Conceptual Code: Parallel Information Gathering\nfetchAPI1, _ := llmagent.New(llmagent.Config{Name: \"API1Fetcher\", Instruction: \"Fetch data from API 1.\", OutputKey: \"api1_data\", Model: m})\nfetchAPI2, _ := llmagent.New(llmagent.Config{Name: \"API2Fetcher\", Instruction: \"Fetch data from API 2.\", OutputKey: \"api2_data\", Model: m})\n\ngatherConcurrently, _ := parallelagent.New(parallelagent.Config{\n    AgentConfig: agent.Config{Name: \"ConcurrentFetch\", SubAgents: []agent.Agent{fetchAPI1, fetchAPI2}},\n})\n\nsynthesizer, _ := llmagent.New(llmagent.Config{Name: \"Synthesizer\", Instruction: \"Combine results from {api1_data} and {api2_data}.\", Model: m})\n\noverallWorkflow, _ := sequentialagent.New(sequentialagent.Config{\n    AgentConfig: agent.Config{Name: \"FetchAndSynthesize\", SubAgents: []agent.Agent{gatherConcurrently, synthesizer}},\n})\n// fetch_api1 and fetch_api2 run concurrently, saving to state.\n// synthesizer runs afterwards, reading state[\"api1_data\"] and state[\"api2_data\"]."}]}, {"heading_path": ["Hierarchical Task Decomposition\u00b6"], "text": "Hierarchical Task Decomposition \u00b6 Structure: A multi-level tree of agents where higher-level agents break down complex goals and delegate sub-tasks to lower-level agents. Goal: Solve complex problems by recursively breaking them down into simpler, executable steps. ADK Primitives Used: Hierarchy: Multi-level parent_agent / sub_agents structure. Interaction: Primarily LLM-Driven Delegation or Explicit Invocation ( AgentTool ) used by parent agents to assign tasks to subagents. Results are returned up the hierarchy (via tool responses or state). Python Java Go # Conceptual Code: Hierarchical Research Task from google.adk.agents import LlmAgent from google.adk.tools import agent_tool # Low-level tool-like agents web_searcher = LlmAgent ( name = \"WebSearch\" , description = \"Performs web searches for facts.\" ) summarizer = LlmAgent ( name = \"Summarizer\" , description = \"Summarizes text.\" ) # Mid-level agent combining tools research_assistant = LlmAgent ( name = \"ResearchAssistant\" , model = \"gemini-2.0-flash\" , description = \"Finds and summarizes information on a topic.\" , tools = [ agent_tool . AgentTool ( agent = web_searcher ), agent_tool . AgentTool ( agent = summarizer )] ) # High-level agent delegating research report_writer = LlmAgent ( name = \"ReportWriter\" , model = \"gemini-2.0-flash\" , instruction = \"Write a report on topic X. Use the ResearchAssistant to gather information.\" , tools = [ agent_tool . AgentTool ( agent = research_assistant )] # Alternatively, could use LLM Transfer if research_assistant is a sub_agent ) # User interacts with ReportWriter. # ReportWriter calls ResearchAssistant tool. # ResearchAssistant calls WebSearch and Summarizer tools. # Results flow back up. // Conceptual Code: Hierarchical Research Task import com.google.adk.agents.LlmAgent ; import com.google.adk.tools.AgentTool ; // Low-level tool-like agents LlmAgent webSearcher = LlmAgent . builder () . name ( \"WebSearch\" ) . description ( \"Performs web searches for facts.\" ) . build (); LlmAgent summarizer = LlmAgent . builder () . name ( \"Summarizer\" ) . description ( \"Summarizes text.\" ) . build (); // Mid-level agent combining tools LlmAgent researchAssistant = LlmAgent . builder () . name ( \"ResearchAssistant\" ) . model ( \"gemini-2.0-flash\" ) . description ( \"Finds and summarizes information on a topic.\" ) . tools ( AgentTool . create ( webSearcher ), AgentTool . create ( summarizer )) . build (); // High-level agent delegating research LlmAgent reportWriter = LlmAgent . builder () . name ( \"ReportWriter\" ) . model ( \"gemini-2.0-flash\" ) . instruction ( \"Write a report on topic X. Use the ResearchAssistant to gather information.\" ) . tools ( AgentTool . create ( researchAssistant )) // Alternatively, could use LLM Transfer if research_assistant is a subAgent . build (); // User interacts with ReportWriter. // ReportWriter calls ResearchAssistant tool. // ResearchAssistant calls WebSearch and Summarizer tools. // Results flow back up. import ( \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/agenttool\" ) // Conceptual Code: Hierarchical Research Task // Low-level tool-like agents webSearcher , _ := llmagent . New ( llmagent . Config { Name : \"WebSearch\" , Description : \"Performs web searches for facts.\" , Model : m }) summarizer , _ := llmagent . New ( llmagent . Config { Name : \"Summarizer\" , Description : \"Summarizes text.\" , Model : m }) // Mid-level agent combining tools webSearcherTool := agenttool . New ( webSearcher , nil ) summarizerTool := agenttool . New ( summarizer , nil ) researchAssistant , _ := llmagent . New ( llmagent . Config { Name : \"ResearchAssistant\" , Model : m , Description : \"Finds and summarizes information on a topic.\" , Tools : [] tool . Tool { webSearcherTool , summarizerTool }, }) // High-level agent delegating research researchAssistantTool := agenttool . New ( researchAssistant , nil ) reportWriter , _ := llmagent . New ( llmagent . Config { Name : \"ReportWriter\" , Model : m , Instruction : \"Write a report on topic X. Use the ResearchAssistant to gather information.\" , Tools : [] tool . Tool { researchAssistantTool }, }) // User interacts with ReportWriter. // ReportWriter calls ResearchAssistant tool. // ResearchAssistant calls WebSearch and Summarizer tools. // Results flow back up. ", "code_blocks": [{"language": "text", "code": "# Conceptual Code: Hierarchical Research Task\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools import agent_tool\n\n# Low-level tool-like agents\nweb_searcher = LlmAgent(name=\"WebSearch\", description=\"Performs web searches for facts.\")\nsummarizer = LlmAgent(name=\"Summarizer\", description=\"Summarizes text.\")\n\n# Mid-level agent combining tools\nresearch_assistant = LlmAgent(\n    name=\"ResearchAssistant\",\n    model=\"gemini-2.0-flash\",\n    description=\"Finds and summarizes information on a topic.\",\n    tools=[agent_tool.AgentTool(agent=web_searcher), agent_tool.AgentTool(agent=summarizer)]\n)\n\n# High-level agent delegating research\nreport_writer = LlmAgent(\n    name=\"ReportWriter\",\n    model=\"gemini-2.0-flash\",\n    instruction=\"Write a report on topic X. Use the ResearchAssistant to gather information.\",\n    tools=[agent_tool.AgentTool(agent=research_assistant)]\n    # Alternatively, could use LLM Transfer if research_assistant is a sub_agent\n)\n# User interacts with ReportWriter.\n# ReportWriter calls ResearchAssistant tool.\n# ResearchAssistant calls WebSearch and Summarizer tools.\n# Results flow back up."}, {"language": "text", "code": "// Conceptual Code: Hierarchical Research Task\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.tools.AgentTool;\n\n// Low-level tool-like agents\nLlmAgent webSearcher = LlmAgent.builder()\n    .name(\"WebSearch\")\n    .description(\"Performs web searches for facts.\")\n    .build();\n\nLlmAgent summarizer = LlmAgent.builder()\n    .name(\"Summarizer\")\n    .description(\"Summarizes text.\")\n    .build();\n\n// Mid-level agent combining tools\nLlmAgent researchAssistant = LlmAgent.builder()\n    .name(\"ResearchAssistant\")\n    .model(\"gemini-2.0-flash\")\n    .description(\"Finds and summarizes information on a topic.\")\n    .tools(AgentTool.create(webSearcher), AgentTool.create(summarizer))\n    .build();\n\n// High-level agent delegating research\nLlmAgent reportWriter = LlmAgent.builder()\n    .name(\"ReportWriter\")\n    .model(\"gemini-2.0-flash\")\n    .instruction(\"Write a report on topic X. Use the ResearchAssistant to gather information.\")\n    .tools(AgentTool.create(researchAssistant))\n    // Alternatively, could use LLM Transfer if research_assistant is a subAgent\n    .build();\n\n// User interacts with ReportWriter.\n// ReportWriter calls ResearchAssistant tool.\n// ResearchAssistant calls WebSearch and Summarizer tools.\n// Results flow back up."}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/agenttool\"\n)\n\n// Conceptual Code: Hierarchical Research Task\n// Low-level tool-like agents\nwebSearcher, _ := llmagent.New(llmagent.Config{Name: \"WebSearch\", Description: \"Performs web searches for facts.\", Model: m})\nsummarizer, _ := llmagent.New(llmagent.Config{Name: \"Summarizer\", Description: \"Summarizes text.\", Model: m})\n\n// Mid-level agent combining tools\nwebSearcherTool := agenttool.New(webSearcher, nil)\nsummarizerTool := agenttool.New(summarizer, nil)\nresearchAssistant, _ := llmagent.New(llmagent.Config{\n    Name:        \"ResearchAssistant\",\n    Model:       m,\n    Description: \"Finds and summarizes information on a topic.\",\n    Tools:       []tool.Tool{webSearcherTool, summarizerTool},\n})\n\n// High-level agent delegating research\nresearchAssistantTool := agenttool.New(researchAssistant, nil)\nreportWriter, _ := llmagent.New(llmagent.Config{\n    Name:        \"ReportWriter\",\n    Model:       m,\n    Instruction: \"Write a report on topic X. Use the ResearchAssistant to gather information.\",\n    Tools:       []tool.Tool{researchAssistantTool},\n})\n// User interacts with ReportWriter.\n// ReportWriter calls ResearchAssistant tool.\n// ResearchAssistant calls WebSearch and Summarizer tools.\n// Results flow back up."}]}, {"heading_path": ["Review/Critique Pattern (Generator-Critic)\u00b6"], "text": "Review/Critique Pattern (Generator-Critic) \u00b6 Structure: Typically involves two agents within a SequentialAgent : a Generator and a Critic/Reviewer. Goal: Improve the quality or validity of generated output by having a dedicated agent review it. ADK Primitives Used: Workflow: SequentialAgent ensures generation happens before review. Communication: Shared Session State (Generator uses output_key to save output; Reviewer reads that state key). The Reviewer might save its feedback to another state key for subsequent steps. Python Java Go # Conceptual Code: Generator-Critic from google.adk.agents import SequentialAgent , LlmAgent generator = LlmAgent ( name = \"DraftWriter\" , instruction = \"Write a short paragraph about subject X.\" , output_key = \"draft_text\" ) reviewer = LlmAgent ( name = \"FactChecker\" , instruction = \"Review the text in {draft_text} for factual accuracy. Output 'valid' or 'invalid' with reasons.\" , output_key = \"review_status\" ) # Optional: Further steps based on review_status review_pipeline = SequentialAgent ( name = \"WriteAndReview\" , sub_agents = [ generator , reviewer ] ) # generator runs -> saves draft to state['draft_text'] # reviewer runs -> reads state['draft_text'], saves status to state['review_status'] // Conceptual Code: Generator-Critic import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.SequentialAgent ; LlmAgent generator = LlmAgent . builder () . name ( \"DraftWriter\" ) . instruction ( \"Write a short paragraph about subject X.\" ) . outputKey ( \"draft_text\" ) . build (); LlmAgent reviewer = LlmAgent . builder () . name ( \"FactChecker\" ) . instruction ( \"Review the text in {draft_text} for factual accuracy. Output 'valid' or 'invalid' with reasons.\" ) . outputKey ( \"review_status\" ) . build (); // Optional: Further steps based on review_status SequentialAgent reviewPipeline = SequentialAgent . builder () . name ( \"WriteAndReview\" ) . subAgents ( generator , reviewer ) . build (); // generator runs -> saves draft to state['draft_text'] // reviewer runs -> reads state['draft_text'], saves status to state['review_status'] import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/agent/workflowagents/sequentialagent\" ) // Conceptual Code: Generator-Critic generator , _ := llmagent . New ( llmagent . Config { Name : \"DraftWriter\" , Instruction : \"Write a short paragraph about subject X.\" , OutputKey : \"draft_text\" , Model : m , }) reviewer , _ := llmagent . New ( llmagent . Config { Name : \"FactChecker\" , Instruction : \"Review the text in {draft_text} for factual accuracy. Output 'valid' or 'invalid' with reasons.\" , OutputKey : \"review_status\" , Model : m , }) reviewPipeline , _ := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : \"WriteAndReview\" , SubAgents : [] agent . Agent { generator , reviewer }}, }) // generator runs -> saves draft to state[\"draft_text\"] // reviewer runs -> reads state[\"draft_text\"], saves status to state[\"review_status\"] ", "code_blocks": [{"language": "text", "code": "# Conceptual Code: Generator-Critic\nfrom google.adk.agents import SequentialAgent, LlmAgent\n\ngenerator = LlmAgent(\n    name=\"DraftWriter\",\n    instruction=\"Write a short paragraph about subject X.\",\n    output_key=\"draft_text\"\n)\n\nreviewer = LlmAgent(\n    name=\"FactChecker\",\n    instruction=\"Review the text in {draft_text} for factual accuracy. Output 'valid' or 'invalid' with reasons.\",\n    output_key=\"review_status\"\n)\n\n# Optional: Further steps based on review_status\n\nreview_pipeline = SequentialAgent(\n    name=\"WriteAndReview\",\n    sub_agents=[generator, reviewer]\n)\n# generator runs -> saves draft to state['draft_text']\n# reviewer runs -> reads state['draft_text'], saves status to state['review_status']"}, {"language": "text", "code": "// Conceptual Code: Generator-Critic\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.SequentialAgent;\n\nLlmAgent generator = LlmAgent.builder()\n    .name(\"DraftWriter\")\n    .instruction(\"Write a short paragraph about subject X.\")\n    .outputKey(\"draft_text\")\n    .build();\n\nLlmAgent reviewer = LlmAgent.builder()\n    .name(\"FactChecker\")\n    .instruction(\"Review the text in {draft_text} for factual accuracy. Output 'valid' or 'invalid' with reasons.\")\n    .outputKey(\"review_status\")\n    .build();\n\n// Optional: Further steps based on review_status\n\nSequentialAgent reviewPipeline = SequentialAgent.builder()\n    .name(\"WriteAndReview\")\n    .subAgents(generator, reviewer)\n    .build();\n\n// generator runs -> saves draft to state['draft_text']\n// reviewer runs -> reads state['draft_text'], saves status to state['review_status']"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/agent/workflowagents/sequentialagent\"\n)\n\n// Conceptual Code: Generator-Critic\ngenerator, _ := llmagent.New(llmagent.Config{\n    Name:        \"DraftWriter\",\n    Instruction: \"Write a short paragraph about subject X.\",\n    OutputKey:   \"draft_text\",\n    Model:       m,\n})\n\nreviewer, _ := llmagent.New(llmagent.Config{\n    Name:        \"FactChecker\",\n    Instruction: \"Review the text in {draft_text} for factual accuracy. Output 'valid' or 'invalid' with reasons.\",\n    OutputKey:   \"review_status\",\n    Model:       m,\n})\n\nreviewPipeline, _ := sequentialagent.New(sequentialagent.Config{\n    AgentConfig: agent.Config{Name: \"WriteAndReview\", SubAgents: []agent.Agent{generator, reviewer}},\n})\n// generator runs -> saves draft to state[\"draft_text\"]\n// reviewer runs -> reads state[\"draft_text\"], saves status to state[\"review_status\"]"}]}, {"heading_path": ["Iterative Refinement Pattern\u00b6"], "text": "Iterative Refinement Pattern \u00b6 Structure: Uses a LoopAgent containing one or more agents that work on a task over multiple iterations. Goal: Progressively improve a result (e.g., code, text, plan) stored in the session state until a quality threshold is met or a maximum number of iterations is reached. ADK Primitives Used: Workflow: LoopAgent manages the repetition. Communication: Shared Session State is essential for agents to read the previous iteration's output and save the refined version. Termination: The loop typically ends based on max_iterations or a dedicated checking agent setting escalate=True in the Event Actions when the result is satisfactory. Python Java Go # Conceptual Code: Iterative Code Refinement from google.adk.agents import LoopAgent , LlmAgent , BaseAgent from google.adk.events import Event , EventActions from google.adk.agents.invocation_context import InvocationContext from typing import AsyncGenerator # Agent to generate/refine code based on state['current_code'] and state['requirements'] code_refiner = LlmAgent ( name = \"CodeRefiner\" , instruction = \"Read state['current_code'] (if exists) and state['requirements']. Generate/refine Python code to meet requirements. Save to state['current_code'].\" , output_key = \"current_code\" # Overwrites previous code in state ) # Agent to check if the code meets quality standards quality_checker = LlmAgent ( name = \"QualityChecker\" , instruction = \"Evaluate the code in state['current_code'] against state['requirements']. Output 'pass' or 'fail'.\" , output_key = \"quality_status\" ) # Custom agent to check the status and escalate if 'pass' class CheckStatusAndEscalate ( BaseAgent ): async def _run_async_impl ( self , ctx : InvocationContext ) -> AsyncGenerator [ Event , None ]: status = ctx . session . state . get ( \"quality_status\" , \"fail\" ) should_stop = ( status == \"pass\" ) yield Event ( author = self . name , actions = EventActions ( escalate = should_stop )) refinement_loop = LoopAgent ( name = \"CodeRefinementLoop\" , max_iterations = 5 , sub_agents = [ code_refiner , quality_checker , CheckStatusAndEscalate ( name = \"StopChecker\" )] ) # Loop runs: Refiner -> Checker -> StopChecker # State['current_code'] is updated each iteration. # Loop stops if QualityChecker outputs 'pass' (leading to StopChecker escalating) or after 5 iterations. // Conceptual Code: Iterative Code Refinement import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.LoopAgent ; import com.google.adk.events.Event ; import com.google.adk.events.EventActions ; import com.google.adk.agents.InvocationContext ; import io.reactivex.rxjava3.core.Flowable ; import java.util.List ; // Agent to generate/refine code based on state['current_code'] and state['requirements'] LlmAgent codeRefiner = LlmAgent . builder () . name ( \"CodeRefiner\" ) . instruction ( \"Read state['current_code'] (if exists) and state['requirements']. Generate/refine Java code to meet requirements. Save to state['current_code'].\" ) . outputKey ( \"current_code\" ) // Overwrites previous code in state . build (); // Agent to check if the code meets quality standards LlmAgent qualityChecker = LlmAgent . builder () . name ( \"QualityChecker\" ) . instruction ( \"Evaluate the code in state['current_code'] against state['requirements']. Output 'pass' or 'fail'.\" ) . outputKey ( \"quality_status\" ) . build (); BaseAgent checkStatusAndEscalate = new BaseAgent ( \"StopChecker\" , \"Checks quality_status and escalates if 'pass'.\" , List . of (), null , null ) { @Override protected Flowable < Event > runAsyncImpl ( InvocationContext invocationContext ) { String status = ( String ) invocationContext . session (). state (). getOrDefault ( \"quality_status\" , \"fail\" ); boolean shouldStop = \"pass\" . equals ( status ); EventActions actions = EventActions . builder (). escalate ( shouldStop ). build (); Event event = Event . builder () . author ( this . name ()) . actions ( actions ) . build (); return Flowable . just ( event ); } }; LoopAgent refinementLoop = LoopAgent . builder () . name ( \"CodeRefinementLoop\" ) . maxIterations ( 5 ) . subAgents ( codeRefiner , qualityChecker , checkStatusAndEscalate ) . build (); // Loop runs: Refiner -> Checker -> StopChecker // State['current_code'] is updated each iteration. // Loop stops if QualityChecker outputs 'pass' (leading to StopChecker escalating) or after 5 // iterations. import ( \"iter\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/agent/workflowagents/loopagent\" \"google.golang.org/adk/session\" ) // Conceptual Code: Iterative Code Refinement codeRefiner , _ := llmagent . New ( llmagent . Config { Name : \"CodeRefiner\" , Instruction : \"Read state['current_code'] (if exists) and state['requirements']. Generate/refine Python code to meet requirements. Save to state['current_code'].\" , OutputKey : \"current_code\" , Model : m , }) qualityChecker , _ := llmagent . New ( llmagent . Config { Name : \"QualityChecker\" , Instruction : \"Evaluate the code in state['current_code'] against state['requirements']. Output 'pass' or 'fail'.\" , OutputKey : \"quality_status\" , Model : m , }) checkStatusAndEscalate , _ := agent . New ( agent . Config { Name : \"StopChecker\" , Run : func ( ctx agent . InvocationContext ) iter . Seq2 [ * session . Event , error ] { return func ( yield func ( * session . Event , error ) bool ) { status , _ := ctx . Session (). State (). Get ( \"quality_status\" ) shouldStop := status == \"pass\" yield ( & session . Event { Author : \"StopChecker\" , Actions : session . EventActions { Escalate : shouldStop }}, nil ) } }, }) refinementLoop , _ := loopagent . New ( loopagent . Config { MaxIterations : 5 , AgentConfig : agent . Config { Name : \"CodeRefinementLoop\" , SubAgents : [] agent . Agent { codeRefiner , qualityChecker , checkStatusAndEscalate }}, }) // Loop runs: Refiner -> Checker -> StopChecker // State[\"current_code\"] is updated each iteration. // Loop stops if QualityChecker outputs 'pass' (leading to StopChecker escalating) or after 5 iterations. ", "code_blocks": [{"language": "text", "code": "# Conceptual Code: Iterative Code Refinement\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\nfrom google.adk.events import Event, EventActions\nfrom google.adk.agents.invocation_context import InvocationContext\nfrom typing import AsyncGenerator\n\n# Agent to generate/refine code based on state['current_code'] and state['requirements']\ncode_refiner = LlmAgent(\n    name=\"CodeRefiner\",\n    instruction=\"Read state['current_code'] (if exists) and state['requirements']. Generate/refine Python code to meet requirements. Save to state['current_code'].\",\n    output_key=\"current_code\" # Overwrites previous code in state\n)\n\n# Agent to check if the code meets quality standards\nquality_checker = LlmAgent(\n    name=\"QualityChecker\",\n    instruction=\"Evaluate the code in state['current_code'] against state['requirements']. Output 'pass' or 'fail'.\",\n    output_key=\"quality_status\"\n)\n\n# Custom agent to check the status and escalate if 'pass'\nclass CheckStatusAndEscalate(BaseAgent):\n    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n        status = ctx.session.state.get(\"quality_status\", \"fail\")\n        should_stop = (status == \"pass\")\n        yield Event(author=self.name, actions=EventActions(escalate=should_stop))\n\nrefinement_loop = LoopAgent(\n    name=\"CodeRefinementLoop\",\n    max_iterations=5,\n    sub_agents=[code_refiner, quality_checker, CheckStatusAndEscalate(name=\"StopChecker\")]\n)\n# Loop runs: Refiner -> Checker -> StopChecker\n# State['current_code'] is updated each iteration.\n# Loop stops if QualityChecker outputs 'pass' (leading to StopChecker escalating) or after 5 iterations."}, {"language": "text", "code": "// Conceptual Code: Iterative Code Refinement\nimport com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.LoopAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.events.EventActions;\nimport com.google.adk.agents.InvocationContext;\nimport io.reactivex.rxjava3.core.Flowable;\nimport java.util.List;\n\n// Agent to generate/refine code based on state['current_code'] and state['requirements']\nLlmAgent codeRefiner = LlmAgent.builder()\n    .name(\"CodeRefiner\")\n    .instruction(\"Read state['current_code'] (if exists) and state['requirements']. Generate/refine Java code to meet requirements. Save to state['current_code'].\")\n    .outputKey(\"current_code\") // Overwrites previous code in state\n    .build();\n\n// Agent to check if the code meets quality standards\nLlmAgent qualityChecker = LlmAgent.builder()\n    .name(\"QualityChecker\")\n    .instruction(\"Evaluate the code in state['current_code'] against state['requirements']. Output 'pass' or 'fail'.\")\n    .outputKey(\"quality_status\")\n    .build();\n\nBaseAgent checkStatusAndEscalate = new BaseAgent(\n    \"StopChecker\",\"Checks quality_status and escalates if 'pass'.\", List.of(), null, null) {\n\n  @Override\n  protected Flowable<Event> runAsyncImpl(InvocationContext invocationContext) {\n    String status = (String) invocationContext.session().state().getOrDefault(\"quality_status\", \"fail\");\n    boolean shouldStop = \"pass\".equals(status);\n\n    EventActions actions = EventActions.builder().escalate(shouldStop).build();\n    Event event = Event.builder()\n        .author(this.name())\n        .actions(actions)\n        .build();\n    return Flowable.just(event);\n  }\n};\n\nLoopAgent refinementLoop = LoopAgent.builder()\n    .name(\"CodeRefinementLoop\")\n    .maxIterations(5)\n    .subAgents(codeRefiner, qualityChecker, checkStatusAndEscalate)\n    .build();\n\n// Loop runs: Refiner -> Checker -> StopChecker\n// State['current_code'] is updated each iteration.\n// Loop stops if QualityChecker outputs 'pass' (leading to StopChecker escalating) or after 5\n// iterations."}, {"language": "text", "code": "import (\n    \"iter\"\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/agent/workflowagents/loopagent\"\n    \"google.golang.org/adk/session\"\n)\n\n// Conceptual Code: Iterative Code Refinement\ncodeRefiner, _ := llmagent.New(llmagent.Config{\n    Name:        \"CodeRefiner\",\n    Instruction: \"Read state['current_code'] (if exists) and state['requirements']. Generate/refine Python code to meet requirements. Save to state['current_code'].\",\n    OutputKey:   \"current_code\",\n    Model:       m,\n})\n\nqualityChecker, _ := llmagent.New(llmagent.Config{\n    Name:        \"QualityChecker\",\n    Instruction: \"Evaluate the code in state['current_code'] against state['requirements']. Output 'pass' or 'fail'.\",\n    OutputKey:   \"quality_status\",\n    Model:       m,\n})\n\ncheckStatusAndEscalate, _ := agent.New(agent.Config{\n    Name: \"StopChecker\",\n    Run: func(ctx agent.InvocationContext) iter.Seq2[*session.Event, error] {\n        return func(yield func(*session.Event, error) bool) {\n            status, _ := ctx.Session().State().Get(\"quality_status\")\n            shouldStop := status == \"pass\"\n            yield(&session.Event{Author: \"StopChecker\", Actions: session.EventActions{Escalate: shouldStop}}, nil)\n        }\n    },\n})\n\nrefinementLoop, _ := loopagent.New(loopagent.Config{\n    MaxIterations: 5,\n    AgentConfig:   agent.Config{Name: \"CodeRefinementLoop\", SubAgents: []agent.Agent{codeRefiner, qualityChecker, checkStatusAndEscalate}},\n})\n// Loop runs: Refiner -> Checker -> StopChecker\n// State[\"current_code\"] is updated each iteration.\n// Loop stops if QualityChecker outputs 'pass' (leading to StopChecker escalating) or after 5 iterations."}]}, {"heading_path": ["Human-in-the-Loop Pattern\u00b6"], "text": "Human-in-the-Loop Pattern \u00b6 Structure: Integrates human intervention points within an agent workflow. Goal: Allow for human oversight, approval, correction, or tasks that AI cannot perform. ADK Primitives Used (Conceptual): Interaction: Can be implemented using a custom Tool that pauses execution and sends a request to an external system (e.g., a UI, ticketing system) waiting for human input. The tool then returns the human's response to the agent. Workflow: Could use LLM-Driven Delegation ( transfer_to_agent ) targeting a conceptual \"Human Agent\" that triggers the external workflow, or use the custom tool within an LlmAgent . State/Callbacks: State can hold task details for the human; callbacks can manage the interaction flow. Note: ADK doesn't have a built-in \"Human Agent\" type, so this requires custom integration. Python Java Go # Conceptual Code: Using a Tool for Human Approval from google.adk.agents import LlmAgent , SequentialAgent from google.adk.tools import FunctionTool # --- Assume external_approval_tool exists --- # This tool would: # 1. Take details (e.g., request_id, amount, reason). # 2. Send these details to a human review system (e.g., via API). # 3. Poll or wait for the human response (approved/rejected). # 4. Return the human's decision. # async def external_approval_tool(amount: float, reason: str) -> str: ... approval_tool = FunctionTool ( func = external_approval_tool ) # Agent that prepares the request prepare_request = LlmAgent ( name = \"PrepareApproval\" , instruction = \"Prepare the approval request details based on user input. Store amount and reason in state.\" , # ... likely sets state['approval_amount'] and state['approval_reason'] ... ) # Agent that calls the human approval tool request_approval = LlmAgent ( name = \"RequestHumanApproval\" , instruction = \"Use the external_approval_tool with amount from state['approval_amount'] and reason from state['approval_reason'].\" , tools = [ approval_tool ], output_key = \"human_decision\" ) # Agent that proceeds based on human decision process_decision = LlmAgent ( name = \"ProcessDecision\" , instruction = \"Check {human_decision} . If 'approved', proceed. If 'rejected', inform user.\" ) approval_workflow = SequentialAgent ( name = \"HumanApprovalWorkflow\" , sub_agents = [ prepare_request , request_approval , process_decision ] ) // Conceptual Code: Using a Tool for Human Approval import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.SequentialAgent ; import com.google.adk.tools.FunctionTool ; // --- Assume external_approval_tool exists --- // This tool would: // 1. Take details (e.g., request_id, amount, reason). // 2. Send these details to a human review system (e.g., via API). // 3. Poll or wait for the human response (approved/rejected). // 4. Return the human's decision. // public boolean externalApprovalTool(float amount, String reason) { ... } FunctionTool approvalTool = FunctionTool . create ( externalApprovalTool ); // Agent that prepares the request LlmAgent prepareRequest = LlmAgent . builder () . name ( \"PrepareApproval\" ) . instruction ( \"Prepare the approval request details based on user input. Store amount and reason in state.\" ) // ... likely sets state['approval_amount'] and state['approval_reason'] ... . build (); // Agent that calls the human approval tool LlmAgent requestApproval = LlmAgent . builder () . name ( \"RequestHumanApproval\" ) . instruction ( \"Use the external_approval_tool with amount from state['approval_amount'] and reason from state['approval_reason'].\" ) . tools ( approvalTool ) . outputKey ( \"human_decision\" ) . build (); // Agent that proceeds based on human decision LlmAgent processDecision = LlmAgent . builder () . name ( \"ProcessDecision\" ) . instruction ( \"Check {human_decision}. If 'approved', proceed. If 'rejected', inform user.\" ) . build (); SequentialAgent approvalWorkflow = SequentialAgent . builder () . name ( \"HumanApprovalWorkflow\" ) . subAgents ( prepareRequest , requestApproval , processDecision ) . build (); import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/agent/workflowagents/sequentialagent\" \"google.golang.org/adk/tool\" ) // Conceptual Code: Using a Tool for Human Approval // --- Assume externalApprovalTool exists --- // func externalApprovalTool(amount float64, reason string) string { ... } type externalApprovalToolArgs struct { Amount float64 `json:\"amount\" jsonschema:\"The amount for which approval is requested.\"` Reason string `json:\"reason\" jsonschema:\"The reason for the approval request.\"` } var externalApprovalTool func ( tool . Context , externalApprovalToolArgs ) string approvalTool , _ := functiontool . New ( functiontool . Config { Name : \"external_approval_tool\" , Description : \"Sends a request for human approval.\" , }, externalApprovalTool , ) prepareRequest , _ := llmagent . New ( llmagent . Config { Name : \"PrepareApproval\" , Instruction : \"Prepare the approval request details based on user input. Store amount and reason in state.\" , Model : m , }) requestApproval , _ := llmagent . New ( llmagent . Config { Name : \"RequestHumanApproval\" , Instruction : \"Use the external_approval_tool with amount from state['approval_amount'] and reason from state['approval_reason'].\" , Tools : [] tool . Tool { approvalTool }, OutputKey : \"human_decision\" , Model : m , }) processDecision , _ := llmagent . New ( llmagent . Config { Name : \"ProcessDecision\" , Instruction : \"Check {human_decision}. If 'approved', proceed. If 'rejected', inform user.\" , Model : m , }) approvalWorkflow , _ := sequentialagent . New ( sequentialagent . Config { AgentConfig : agent . Config { Name : \"HumanApprovalWorkflow\" , SubAgents : [] agent . Agent { prepareRequest , requestApproval , processDecision }}, }) These patterns provide starting points for structuring your multi-agent systems. You can mix and match them as needed to create the most effective architecture for your specific application. Back to top ", "code_blocks": [{"language": "text", "code": "# Conceptual Code: Using a Tool for Human Approval\nfrom google.adk.agents import LlmAgent, SequentialAgent\nfrom google.adk.tools import FunctionTool\n\n# --- Assume external_approval_tool exists ---\n# This tool would:\n# 1. Take details (e.g., request_id, amount, reason).\n# 2. Send these details to a human review system (e.g., via API).\n# 3. Poll or wait for the human response (approved/rejected).\n# 4. Return the human's decision.\n# async def external_approval_tool(amount: float, reason: str) -> str: ...\napproval_tool = FunctionTool(func=external_approval_tool)\n\n# Agent that prepares the request\nprepare_request = LlmAgent(\n    name=\"PrepareApproval\",\n    instruction=\"Prepare the approval request details based on user input. Store amount and reason in state.\",\n    # ... likely sets state['approval_amount'] and state['approval_reason'] ...\n)\n\n# Agent that calls the human approval tool\nrequest_approval = LlmAgent(\n    name=\"RequestHumanApproval\",\n    instruction=\"Use the external_approval_tool with amount from state['approval_amount'] and reason from state['approval_reason'].\",\n    tools=[approval_tool],\n    output_key=\"human_decision\"\n)\n\n# Agent that proceeds based on human decision\nprocess_decision = LlmAgent(\n    name=\"ProcessDecision\",\n    instruction=\"Check {human_decision}. If 'approved', proceed. If 'rejected', inform user.\"\n)\n\napproval_workflow = SequentialAgent(\n    name=\"HumanApprovalWorkflow\",\n    sub_agents=[prepare_request, request_approval, process_decision]\n)"}, {"language": "text", "code": "// Conceptual Code: Using a Tool for Human Approval\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.SequentialAgent;\nimport com.google.adk.tools.FunctionTool;\n\n// --- Assume external_approval_tool exists ---\n// This tool would:\n// 1. Take details (e.g., request_id, amount, reason).\n// 2. Send these details to a human review system (e.g., via API).\n// 3. Poll or wait for the human response (approved/rejected).\n// 4. Return the human's decision.\n// public boolean externalApprovalTool(float amount, String reason) { ... }\nFunctionTool approvalTool = FunctionTool.create(externalApprovalTool);\n\n// Agent that prepares the request\nLlmAgent prepareRequest = LlmAgent.builder()\n    .name(\"PrepareApproval\")\n    .instruction(\"Prepare the approval request details based on user input. Store amount and reason in state.\")\n    // ... likely sets state['approval_amount'] and state['approval_reason'] ...\n    .build();\n\n// Agent that calls the human approval tool\nLlmAgent requestApproval = LlmAgent.builder()\n    .name(\"RequestHumanApproval\")\n    .instruction(\"Use the external_approval_tool with amount from state['approval_amount'] and reason from state['approval_reason'].\")\n    .tools(approvalTool)\n    .outputKey(\"human_decision\")\n    .build();\n\n// Agent that proceeds based on human decision\nLlmAgent processDecision = LlmAgent.builder()\n    .name(\"ProcessDecision\")\n    .instruction(\"Check {human_decision}. If 'approved', proceed. If 'rejected', inform user.\")\n    .build();\n\nSequentialAgent approvalWorkflow = SequentialAgent.builder()\n    .name(\"HumanApprovalWorkflow\")\n    .subAgents(prepareRequest, requestApproval, processDecision)\n    .build();"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/agent/workflowagents/sequentialagent\"\n    \"google.golang.org/adk/tool\"\n)\n\n// Conceptual Code: Using a Tool for Human Approval\n// --- Assume externalApprovalTool exists ---\n// func externalApprovalTool(amount float64, reason string) string { ... }\ntype externalApprovalToolArgs struct {\n    Amount float64 `json:\"amount\" jsonschema:\"The amount for which approval is requested.\"`\n    Reason string  `json:\"reason\" jsonschema:\"The reason for the approval request.\"`\n}\nvar externalApprovalTool func(tool.Context, externalApprovalToolArgs) string\napprovalTool, _ := functiontool.New(\n    functiontool.Config{\n        Name:        \"external_approval_tool\",\n        Description: \"Sends a request for human approval.\",\n    },\n    externalApprovalTool,\n)\n\nprepareRequest, _ := llmagent.New(llmagent.Config{\n    Name:        \"PrepareApproval\",\n    Instruction: \"Prepare the approval request details based on user input. Store amount and reason in state.\",\n    Model:       m,\n})\n\nrequestApproval, _ := llmagent.New(llmagent.Config{\n    Name:        \"RequestHumanApproval\",\n    Instruction: \"Use the external_approval_tool with amount from state['approval_amount'] and reason from state['approval_reason'].\",\n    Tools:       []tool.Tool{approvalTool},\n    OutputKey:   \"human_decision\",\n    Model:       m,\n})\n\nprocessDecision, _ := llmagent.New(llmagent.Config{\n    Name:        \"ProcessDecision\",\n    Instruction: \"Check {human_decision}. If 'approved', proceed. If 'rejected', inform user.\",\n    Model:       m,\n})\n\napprovalWorkflow, _ := sequentialagent.New(sequentialagent.Config{\n    AgentConfig: agent.Config{Name: \"HumanApprovalWorkflow\", SubAgents: []agent.Agent{prepareRequest, requestApproval, processDecision}},\n})"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:08.546045", "source_type": "adk-docs"}
{"doc_id": "59aef09206f25c07aedda7e991d5606ac9ce40c7cb8b1126a70241d7fcf36691", "url": "https://google.github.io/adk-docs/agents/config", "title": "Agent Config - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Build agents with Agent Config\u00b6"], "text": "Build agents with Agent Config \u00b6 Supported in ADK Python v1.11.0 Experimental The ADK Agent Config feature lets you build an ADK workflow without writing\ncode. An Agent Config uses a YAML format text file with a brief description of\nthe agent, allowing just about anyone to assemble and run an ADK agent. The\nfollowing is a simple example of an basic Agent Config definition: name: assistant_agent model: gemini-2.5-flash description: A helper agent that can answer users' questions. instruction: You are an agent to help answer users' various questions. You can use Agent Config files to build more complex agents which can\nincorporate Functions, Tools, Sub-Agents, and more. This page describes how to\nbuild and run ADK workflows with the Agent Config feature. For detailed\ninformation on the syntax and settings supported by the Agent Config format,\nsee the Agent Config syntax reference . Experimental The Agent Config feature is experimental and has some known limitations . We welcome your feedback ! ", "code_blocks": [{"language": "text", "code": "name: assistant_agent\nmodel: gemini-2.5-flash\ndescription: A helper agent that can answer users' questions.\ninstruction: You are an agent to help answer users' various questions."}]}, {"heading_path": ["Get started\u00b6"], "text": "Get started \u00b6 This section describes how to set up and start building agents with the ADK and\nthe Agent Config feature, including installation setup, building an agent, and\nrunning your agent. ", "code_blocks": []}, {"heading_path": ["Setup\u00b6"], "text": "Setup \u00b6 You need to install the Google Agent Development Kit libraries, and provide an\naccess key for a generative AI model such as Gemini API. This section provides\ndetails on what you must install and configure before you can run agents with\nthe Agent Config files. Note The Agent Config feature currently only supports Gemini models. For more\ninformation about additional; functional restrictions, see Known limitations . To setup ADK for use with Agent Config: Install the ADK Python libraries by following the Installation instructions. Python is currently required. For more information, see the Known limitations . Verify that ADK is installed by running the following command in your\n    terminal: adk --version This command should show the ADK version you have installed. Tip If the adk command fails to run and the version is not listed in step 2, make\nsure your Python environment is active. Execute source .venv/bin/activate in\nyour terminal on Mac and Linux. For other platform commands, see the Installation page. ", "code_blocks": [{"language": "text", "code": "adk --version"}]}, {"heading_path": ["Build an agent\u00b6"], "text": "Build an agent \u00b6 You build an agent with Agent Config using the adk create command to create\nthe project files for an agent, and then editing the root_agent.yaml file it\ngenerates for you. To create an ADK project for use with Agent Config: In your terminal window, run the following command to create a\n    config-based agent: adk create --type=config my_agent This command generates a my_agent/ folder, containing a root_agent.yaml file and an .env file. In the my_agent/.env file, set environment variables for your agent to\n    access generative AI models and other services: For Gemini model access through Google API, add a line to the\n    file with your API key: GOOGLE_GENAI_USE_VERTEXAI=0\nGOOGLE_API_KEY=<your-Google-Gemini-API-key> You can get an API key from the Google AI Studio API Keys page. For Gemini model access through Google Cloud, add these lines to the file: GOOGLE_GENAI_USE_VERTEXAI=1\nGOOGLE_CLOUD_PROJECT=<your_gcp_project>\nGOOGLE_CLOUD_LOCATION=us-central1 For information on creating a Cloud Project, see the Google Cloud docs\nfor Creating and managing projects . Using text editor, edit the Agent Config file my_agent/root_agent.yaml , as shown below: # yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json name: assistant_agent model: gemini-2.5-flash description: A helper agent that can answer users' questions. instruction: You are an agent to help answer users' various questions. You can discover more configuration options for your root_agent.yaml agent\nconfiguration file by referring to the ADK samples repository or the Agent Config syntax reference. ", "code_blocks": [{"language": "text", "code": "adk create --type=config my_agent"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=0\nGOOGLE_API_KEY=<your-Google-Gemini-API-key>"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=1\nGOOGLE_CLOUD_PROJECT=<your_gcp_project>\nGOOGLE_CLOUD_LOCATION=us-central1"}, {"language": "text", "code": "# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json\nname: assistant_agent\nmodel: gemini-2.5-flash\ndescription: A helper agent that can answer users' questions.\ninstruction: You are an agent to help answer users' various questions."}]}, {"heading_path": ["Run the agent\u00b6"], "text": "Run the agent \u00b6 Once you have completed editing your Agent Config, you can run your agent using\nthe web interface, command line terminal execution, or API server mode. To run your Agent Config-defined agent: In your terminal, navigate to the my_agent/ directory containing the root_agent.yaml file. Type one of the following commands to run your agent: adk web - Run web UI interface for your agent. adk run - Run your agent in the terminal without a user\n    interface. adk api_server - Run your agent as a service that can be\n    used by other applications. For more information on the ways to run your agent, see the Run Your Agent topic in the Quickstart .\nFor more information about the ADK command line options, see the ADK CLI reference . ", "code_blocks": []}, {"heading_path": ["Example configs\u00b6"], "text": "Example configs \u00b6 This section shows examples of Agent Config files to get you started building\nagents. For additional and more complete examples, see the ADK samples repository . ", "code_blocks": []}, {"heading_path": ["Built-in tool example\u00b6"], "text": "Built-in tool example \u00b6 The following example uses a built-in ADK tool function for using google search\nto provide functionality to the agent. This agent automatically uses the search\ntool to reply to user requests. # yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json name: search_agent model: gemini-2.0-flash description: 'an agent whose job it is to perform Google search queries and answer questions about the results.' instruction: You are an agent whose job is to perform Google search queries and answer questions about the results. tools: - name: google_search For more details, see the full code for this sample in the ADK sample repository . ", "code_blocks": [{"language": "text", "code": "# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json\nname: search_agent\nmodel: gemini-2.0-flash\ndescription: 'an agent whose job it is to perform Google search queries and answer questions about the results.'\ninstruction: You are an agent whose job is to perform Google search queries and answer questions about the results.\ntools:\n  - name: google_search"}]}, {"heading_path": ["Custom tool example\u00b6"], "text": "Custom tool example \u00b6 The following example uses a custom tool built with Python code and listed in\nthe tools: section of the config file. The agent uses this tool to check if a\nlist of numbers provided by the user are prime numbers. # yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json agent_class: LlmAgent model: gemini-2.5-flash name: prime_agent description: Handles checking if numbers are prime. instruction: | You are responsible for checking whether numbers are prime. When asked to check primes, you must call the check_prime tool with a list of integers. Never attempt to determine prime numbers manually. Return the prime number results to the root agent. tools: - name: ma_llm.check_prime For more details, see the full code for this sample in the ADK sample repository . ", "code_blocks": [{"language": "text", "code": "# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json\nagent_class: LlmAgent\nmodel: gemini-2.5-flash\nname: prime_agent\ndescription: Handles checking if numbers are prime.\ninstruction: |\n  You are responsible for checking whether numbers are prime.\n  When asked to check primes, you must call the check_prime tool with a list of integers.\n  Never attempt to determine prime numbers manually.\n  Return the prime number results to the root agent.\ntools:\n  - name: ma_llm.check_prime"}]}, {"heading_path": ["Sub-agents example\u00b6"], "text": "Sub-agents example \u00b6 The following example shows an agent defined with two sub-agents in the sub_agents: section, and an example tool in the tools: section of the config\nfile. This agent determines what the user wants, and delegates to one of the\nsub-agents to resolve the request. The sub-agents are defined using Agent Config\nYAML files. # yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json agent_class: LlmAgent model: gemini-2.5-flash name: root_agent description: Learning assistant that provides tutoring in code and math. instruction: | You are a learning assistant that helps students with coding and math questions. You delegate coding questions to the code_tutor_agent and math questions to the math_tutor_agent. Follow these steps: 1. If the user asks about programming or coding, delegate to the code_tutor_agent. 2. If the user asks about math concepts or problems, delegate to the math_tutor_agent. 3. Always provide clear explanations and encourage learning. sub_agents: - config_path: code_tutor_agent.yaml - config_path: math_tutor_agent.yaml For more details, see the full code for this sample in the ADK sample repository . ", "code_blocks": [{"language": "text", "code": "# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json\nagent_class: LlmAgent\nmodel: gemini-2.5-flash\nname: root_agent\ndescription: Learning assistant that provides tutoring in code and math.\ninstruction: |\n  You are a learning assistant that helps students with coding and math questions.\n\n  You delegate coding questions to the code_tutor_agent and math questions to the math_tutor_agent.\n\n  Follow these steps:\n  1. If the user asks about programming or coding, delegate to the code_tutor_agent.\n  2. If the user asks about math concepts or problems, delegate to the math_tutor_agent.\n  3. Always provide clear explanations and encourage learning.\nsub_agents:\n  - config_path: code_tutor_agent.yaml\n  - config_path: math_tutor_agent.yaml"}]}, {"heading_path": ["Deploy agent configs\u00b6"], "text": "Deploy agent configs \u00b6 You can deploy Agent Config agents with Cloud Run and Agent Engine ,\nusing the same procedure as code-based agents. For more information on how\nto prepare and deploy Agent Config-based agents, see the Cloud Run and Agent Engine deployment guides. ", "code_blocks": []}, {"heading_path": ["Known limitations\u00b6"], "text": "Known limitations \u00b6 The Agent Config feature is experimental and includes the following\nlimitations: Model support: Only Gemini models are currently supported.\n    Integration with third-party models is in progress. Programming language: The Agent Config feature currently supports\n    only Python code for tools and other functionality requiring programming code. ADK Tool support: The following ADK tools are supported by the Agent\n    Config feature, but not all tools are fully supported : google_search load_artifacts url_context exit_loop preload_memory get_user_choice enterprise_web_search load_web_page : Requires a fully-qualified path to access web\n    pages. Agent Type Support: The LangGraphAgent and A2aAgent types are\n    not yet supported. AgentTool LongRunningFunctionTool VertexAiSearchTool MCPToolset ExampleTool ", "code_blocks": []}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 For ideas on how and what to build with ADK Agent Configs, see the yaml-based\nagent definitions in the ADK adk-samples repository. For detailed information on the syntax and settings supported by\nthe Agent Config format, see the Agent Config syntax reference . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:08.686297", "source_type": "adk-docs"}
{"doc_id": "e173aa5bdad5441f769e995aef92e123c349076c7ea8eea0af1172ea47fffd7f", "url": "https://google.github.io/adk-docs/agents/models", "title": "Models & Authentication - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Using Different Models with ADK\u00b6"], "text": "Using Different Models with ADK \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 The Agent Development Kit (ADK) is designed for flexibility, allowing you to\nintegrate various Large Language Models (LLMs) into your agents. While the setup\nfor Google Gemini models is covered in the Setup Foundation Models guide, this page\ndetails how to leverage Gemini effectively and integrate other popular models,\nincluding those hosted externally or running locally. ADK primarily uses two mechanisms for model integration: Direct String / Registry: For models tightly integrated with Google Cloud\n   (like Gemini models accessed via Google AI Studio or Vertex AI) or models\n   hosted on Vertex AI endpoints. You typically provide the model name or\n   endpoint resource string directly to the LlmAgent . ADK's internal registry\n   resolves this string to the appropriate backend client, often utilizing the google-genai library. Wrapper Classes: For broader compatibility, especially with models\n   outside the Google ecosystem or those requiring specific client\n   configurations (like models accessed via Apigee or LiteLLM). You instantiate a specific\n   wrapper class (e.g., ApigeeLlm or LiteLlm ) and pass this object as the model parameter\n   to your LlmAgent . The following sections guide you through using these methods based on your needs. ", "code_blocks": []}, {"heading_path": ["Using Google Gemini Models\u00b6"], "text": "Using Google Gemini Models \u00b6 This section covers authenticating with Google's Gemini models, either through Google AI Studio for rapid development or Google Cloud Vertex AI for enterprise applications. This is the most direct way to use Google's flagship models within ADK. Integration Method: Once you are authenticated using one of the below methods, you can pass the model's identifier string directly to the model parameter of LlmAgent . Tip The google-genai library, used internally by ADK for Gemini models, can connect\nthrough either Google AI Studio or Vertex AI. Model support for voice/video streaming In order to use voice/video streaming in ADK, you will need to use Gemini\nmodels that support the Live API. You can find the model ID(s) that\nsupport the Gemini Live API in the documentation: Google AI Studio: Gemini Live API Vertex AI: Gemini Live API ", "code_blocks": []}, {"heading_path": ["Google AI Studio\u00b6"], "text": "Google AI Studio \u00b6 This is the simplest method and is recommended for getting started quickly. Authentication Method: API Key Setup: Get an API key: Obtain your key from Google AI Studio . Set environment variables: Create a .env file (Python) or .properties (Java) in your project's root directory and add the following lines. ADK will automatically load this file. export GOOGLE_API_KEY = \"YOUR_GOOGLE_API_KEY\" export GOOGLE_GENAI_USE_VERTEXAI = FALSE (or) Pass these variables during the model initialization via the Client (see example below). Models: Find all available models on the Google AI for Developers site . ", "code_blocks": [{"language": "text", "code": "export GOOGLE_API_KEY=\"YOUR_GOOGLE_API_KEY\"\nexport GOOGLE_GENAI_USE_VERTEXAI=FALSE"}]}, {"heading_path": ["Google Cloud Vertex AI\u00b6"], "text": "Google Cloud Vertex AI \u00b6 For scalable and production-oriented use cases, Vertex AI is the recommended platform. Gemini on Vertex AI supports enterprise-grade features, security, and compliance controls. Based on your development environment and usecase, choose one of the below methods to authenticate . Pre-requisites: A Google Cloud Project with Vertex AI enabled . ", "code_blocks": []}, {"heading_path": ["Method A: User Credentials (for Local Development)\u00b6"], "text": "Method A: User Credentials (for Local Development) \u00b6 Install the gcloud CLI: Follow the official installation instructions . Log in using ADC: This command opens a browser to authenticate your user account for local development. gcloud auth application-default login Set environment variables: export GOOGLE_CLOUD_PROJECT = \"YOUR_PROJECT_ID\" export GOOGLE_CLOUD_LOCATION = \"YOUR_VERTEX_AI_LOCATION\" # e.g., us-central1 Explicitly tell the library to use Vertex AI: export GOOGLE_GENAI_USE_VERTEXAI = TRUE Models: Find available model IDs in the Vertex AI documentation . ", "code_blocks": [{"language": "text", "code": "gcloud auth application-default login"}, {"language": "text", "code": "export GOOGLE_CLOUD_PROJECT=\"YOUR_PROJECT_ID\"\nexport GOOGLE_CLOUD_LOCATION=\"YOUR_VERTEX_AI_LOCATION\" # e.g., us-central1"}, {"language": "text", "code": "export GOOGLE_GENAI_USE_VERTEXAI=TRUE"}]}, {"heading_path": ["Method B: Vertex AI Express Mode\u00b6"], "text": "Method B: Vertex AI Express Mode \u00b6 Vertex AI Express Mode offers a simplified, API-key-based setup for rapid prototyping. Sign up for Express Mode to get your API key. Set environment variables: export GOOGLE_API_KEY = \"PASTE_YOUR_EXPRESS_MODE_API_KEY_HERE\" export GOOGLE_GENAI_USE_VERTEXAI = TRUE ", "code_blocks": [{"language": "text", "code": "export GOOGLE_API_KEY=\"PASTE_YOUR_EXPRESS_MODE_API_KEY_HERE\"\nexport GOOGLE_GENAI_USE_VERTEXAI=TRUE"}]}, {"heading_path": ["Method C: Service Account (for Production & Automation)\u00b6"], "text": "Method C: Service Account (for Production & Automation) \u00b6 For deployed applications, a service account is the standard method. Create a Service Account and grant it the Vertex AI User role. Provide credentials to your application: On Google Cloud: If you are running the agent in Cloud Run, GKE, VM or other Google Cloud services, the environment can automatically provide the service account credentials. You don't have to create a key file. Elsewhere: Create a service account key file and point to it with an environment variable: export GOOGLE_APPLICATION_CREDENTIALS = \"/path/to/your/keyfile.json\" Instead of the key file, you can also authenticate the service account using Workload Identity. But this is outside the scope of this guide. Example: Python Go Java from google.adk.agents import LlmAgent # --- Example using a stable Gemini Flash model --- agent_gemini_flash = LlmAgent ( # Use the latest stable Flash model identifier model = \"gemini-2.0-flash\" , name = \"gemini_flash_agent\" , instruction = \"You are a fast and helpful Gemini assistant.\" , # ... other agent parameters ) # --- Example using a powerful Gemini Pro model --- # Note: Always check the official Gemini documentation for the latest model names, # including specific preview versions if needed. Preview models might have # different availability or quota limitations. agent_gemini_pro = LlmAgent ( # Use the latest generally available Pro model identifier model = \"gemini-2.5-pro-preview-03-25\" , name = \"gemini_pro_agent\" , instruction = \"You are a powerful and knowledgeable Gemini assistant.\" , # ... other agent parameters ) import ( \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/genai\" ) // --- Example using a stable Gemini Flash model --- modelFlash , err := gemini . NewModel ( ctx , \"gemini-2.0-flash\" , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"failed to create model: %v\" , err ) } agentGeminiFlash , err := llmagent . New ( llmagent . Config { // Use the latest stable Flash model identifier Model : modelFlash , Name : \"gemini_flash_agent\" , Instruction : \"You are a fast and helpful Gemini assistant.\" , // ... other agent parameters }) if err != nil { log . Fatalf ( \"failed to create agent: %v\" , err ) } // --- Example using a powerful Gemini Pro model --- // Note: Always check the official Gemini documentation for the latest model names, // including specific preview versions if needed. Preview models might have // different availability or quota limitations. modelPro , err := gemini . NewModel ( ctx , \"gemini-2.5-pro-preview-03-25\" , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"failed to create model: %v\" , err ) } agentGeminiPro , err := llmagent . New ( llmagent . Config { // Use the latest generally available Pro model identifier Model : modelPro , Name : \"gemini_pro_agent\" , Instruction : \"You are a powerful and knowledgeable Gemini assistant.\" , // ... other agent parameters }) if err != nil { log . Fatalf ( \"failed to create agent: %v\" , err ) } // --- Example #1: using a stable Gemini Flash model with ENV variables--- LlmAgent agentGeminiFlash = LlmAgent . builder () // Use the latest stable Flash model identifier . model ( \"gemini-2.0-flash\" ) // Set ENV variables to use this model . name ( \"gemini_flash_agent\" ) . instruction ( \"You are a fast and helpful Gemini assistant.\" ) // ... other agent parameters . build (); // --- Example #2: using a powerful Gemini Pro model with API Key in model --- LlmAgent agentGeminiPro = LlmAgent . builder () // Use the latest generally available Pro model identifier . model ( new Gemini ( \"gemini-2.5-pro-preview-03-25\" , Client . builder () . vertexAI ( false ) . apiKey ( \"API_KEY\" ) // Set the API Key (or) project/ location . build ())) // Or, you can also directly pass the API_KEY // .model(new Gemini(\"gemini-2.5-pro-preview-03-25\", \"API_KEY\")) . name ( \"gemini_pro_agent\" ) . instruction ( \"You are a powerful and knowledgeable Gemini assistant.\" ) // ... other agent parameters . build (); // Note: Always check the official Gemini documentation for the latest model names, // including specific preview versions if needed. Preview models might have // different availability or quota limitations. Secure Your Credentials Service account credentials or API keys are powerful credentials. Never\nexpose them publicly. Use a secret manager such as Google Cloud Secret\nManager to store\nand access them securely in production. ", "code_blocks": [{"language": "text", "code": "export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/keyfile.json\""}, {"language": "text", "code": "from google.adk.agents import LlmAgent\n\n# --- Example using a stable Gemini Flash model ---\nagent_gemini_flash = LlmAgent(\n    # Use the latest stable Flash model identifier\n    model=\"gemini-2.0-flash\",\n    name=\"gemini_flash_agent\",\n    instruction=\"You are a fast and helpful Gemini assistant.\",\n    # ... other agent parameters\n)\n\n# --- Example using a powerful Gemini Pro model ---\n# Note: Always check the official Gemini documentation for the latest model names,\n# including specific preview versions if needed. Preview models might have\n# different availability or quota limitations.\nagent_gemini_pro = LlmAgent(\n    # Use the latest generally available Pro model identifier\n    model=\"gemini-2.5-pro-preview-03-25\",\n    name=\"gemini_pro_agent\",\n    instruction=\"You are a powerful and knowledgeable Gemini assistant.\",\n    # ... other agent parameters\n)"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/genai\"\n)\n\n// --- Example using a stable Gemini Flash model ---\nmodelFlash, err := gemini.NewModel(ctx, \"gemini-2.0-flash\", &genai.ClientConfig{})\nif err != nil {\n    log.Fatalf(\"failed to create model: %v\", err)\n}\nagentGeminiFlash, err := llmagent.New(llmagent.Config{\n    // Use the latest stable Flash model identifier\n    Model:       modelFlash,\n    Name:        \"gemini_flash_agent\",\n    Instruction: \"You are a fast and helpful Gemini assistant.\",\n    // ... other agent parameters\n})\nif err != nil {\n    log.Fatalf(\"failed to create agent: %v\", err)\n}\n\n// --- Example using a powerful Gemini Pro model ---\n// Note: Always check the official Gemini documentation for the latest model names,\n// including specific preview versions if needed. Preview models might have\n// different availability or quota limitations.\nmodelPro, err := gemini.NewModel(ctx, \"gemini-2.5-pro-preview-03-25\", &genai.ClientConfig{})\nif err != nil {\n    log.Fatalf(\"failed to create model: %v\", err)\n}\nagentGeminiPro, err := llmagent.New(llmagent.Config{\n    // Use the latest generally available Pro model identifier\n    Model:       modelPro,\n    Name:        \"gemini_pro_agent\",\n    Instruction: \"You are a powerful and knowledgeable Gemini assistant.\",\n    // ... other agent parameters\n})\nif err != nil {\n    log.Fatalf(\"failed to create agent: %v\", err)\n}"}, {"language": "text", "code": "// --- Example #1: using a stable Gemini Flash model with ENV variables---\nLlmAgent agentGeminiFlash =\n    LlmAgent.builder()\n        // Use the latest stable Flash model identifier\n        .model(\"gemini-2.0-flash\") // Set ENV variables to use this model\n        .name(\"gemini_flash_agent\")\n        .instruction(\"You are a fast and helpful Gemini assistant.\")\n        // ... other agent parameters\n        .build();\n\n// --- Example #2: using a powerful Gemini Pro model with API Key in model ---\nLlmAgent agentGeminiPro =\n    LlmAgent.builder()\n        // Use the latest generally available Pro model identifier\n        .model(new Gemini(\"gemini-2.5-pro-preview-03-25\",\n            Client.builder()\n                .vertexAI(false)\n                .apiKey(\"API_KEY\") // Set the API Key (or) project/ location\n                .build()))\n        // Or, you can also directly pass the API_KEY\n        // .model(new Gemini(\"gemini-2.5-pro-preview-03-25\", \"API_KEY\"))\n        .name(\"gemini_pro_agent\")\n        .instruction(\"You are a powerful and knowledgeable Gemini assistant.\")\n        // ... other agent parameters\n        .build();\n\n// Note: Always check the official Gemini documentation for the latest model names,\n// including specific preview versions if needed. Preview models might have\n// different availability or quota limitations."}]}, {"heading_path": ["Troubleshooting\u00b6"], "text": "Troubleshooting \u00b6 ", "code_blocks": []}, {"heading_path": ["Error Code 429 - RESOURCE_EXHAUSTED\u00b6"], "text": "Error Code 429 - RESOURCE_EXHAUSTED \u00b6 This error usually happens if the number of your requests exceeds the capacity allocated to process requests. To mitigate this, you can do one of the following: Request higher quota limits for the model you are trying to use. Enable client-side retries. Retries allow the client to automatically retry the request after a delay, which can help if the quota issue is temporary. There are two ways you can set retry options: Option 1: Set retry options on the Agent as a part of generate_content_config. You would use this option if you are instantiating this model adapter by\nyourself. root_agent = Agent ( model = 'gemini-2.0-flash' , ... generate_content_config = types . GenerateContentConfig ( ... http_options = types . HttpOptions ( ... retry_options = types . HttpRetryOptions ( initial_delay = 1 , attempts = 2 ), ... ), ... ) Option 2: Retry options on this model adapter. You would use this option if you were instantiating the instance of adapter\nby yourself. from google.genai import types # ... agent = Agent ( model = Gemini ( retry_options = types . HttpRetryOptions ( initial_delay = 1 , attempts = 2 ), ) ) ", "code_blocks": [{"language": "text", "code": "root_agent = Agent(\n    model='gemini-2.0-flash',\n    ...\n    generate_content_config=types.GenerateContentConfig(\n        ...\n        http_options=types.HttpOptions(\n            ...\n            retry_options=types.HttpRetryOptions(initial_delay=1, attempts=2),\n            ...\n        ),\n        ...\n    )"}, {"language": "text", "code": "from google.genai import types\n\n# ...\n\nagent = Agent(\n    model=Gemini(\n    retry_options=types.HttpRetryOptions(initial_delay=1, attempts=2),\n    )\n)"}]}, {"heading_path": ["Using Anthropic models\u00b6"], "text": "Using Anthropic models \u00b6 Supported in ADK Java v0.2.0 You can integrate Anthropic's Claude models directly using their API key or from a Vertex AI backend into your Java ADK applications by using the ADK's Claude wrapper class. For Vertex AI backend, see the Third-Party Models on Vertex AI section. Prerequisites: Dependencies: Anthropic SDK Classes (Transitive): The Java ADK's com.google.adk.models.Claude wrapper relies on classes from Anthropic's official Java SDK. These are typically included as transitive dependencies . Anthropic API Key: Obtain an API key from Anthropic. Securely manage this key using a secret manager. Integration: Instantiate com.google.adk.models.Claude , providing the desired Claude model name and an AnthropicOkHttpClient configured with your API key. Then, pass this Claude instance to your LlmAgent . Example: import com.anthropic.client.AnthropicClient ; import com.google.adk.agents.LlmAgent ; import com.google.adk.models.Claude ; import com.anthropic.client.okhttp.AnthropicOkHttpClient ; // From Anthropic's SDK public class DirectAnthropicAgent { private static final String CLAUDE_MODEL_ID = \"claude-3-7-sonnet-latest\" ; // Or your preferred Claude model public static LlmAgent createAgent () { // It's recommended to load sensitive keys from a secure config AnthropicClient anthropicClient = AnthropicOkHttpClient . builder () . apiKey ( \"ANTHROPIC_API_KEY\" ) . build (); Claude claudeModel = new Claude ( CLAUDE_MODEL_ID , anthropicClient ); return LlmAgent . builder () . name ( \"claude_direct_agent\" ) . model ( claudeModel ) . instruction ( \"You are a helpful AI assistant powered by Anthropic Claude.\" ) // ... other LlmAgent configurations . build (); } public static void main ( String [] args ) { try { LlmAgent agent = createAgent (); System . out . println ( \"Successfully created direct Anthropic agent: \" + agent . name ()); } catch ( IllegalStateException e ) { System . err . println ( \"Error creating agent: \" + e . getMessage ()); } } } ", "code_blocks": [{"language": "text", "code": "import com.anthropic.client.AnthropicClient;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.models.Claude;\nimport com.anthropic.client.okhttp.AnthropicOkHttpClient; // From Anthropic's SDK\n\npublic class DirectAnthropicAgent {\n\n  private static final String CLAUDE_MODEL_ID = \"claude-3-7-sonnet-latest\"; // Or your preferred Claude model\n\n  public static LlmAgent createAgent() {\n\n    // It's recommended to load sensitive keys from a secure config\n    AnthropicClient anthropicClient = AnthropicOkHttpClient.builder()\n        .apiKey(\"ANTHROPIC_API_KEY\")\n        .build();\n\n    Claude claudeModel = new Claude(\n        CLAUDE_MODEL_ID,\n        anthropicClient\n    );\n\n    return LlmAgent.builder()\n        .name(\"claude_direct_agent\")\n        .model(claudeModel)\n        .instruction(\"You are a helpful AI assistant powered by Anthropic Claude.\")\n        // ... other LlmAgent configurations\n        .build();\n  }\n\n  public static void main(String[] args) {\n    try {\n      LlmAgent agent = createAgent();\n      System.out.println(\"Successfully created direct Anthropic agent: \" + agent.name());\n    } catch (IllegalStateException e) {\n      System.err.println(\"Error creating agent: \" + e.getMessage());\n    }\n  }\n}"}]}, {"heading_path": ["Using Apigee gateway for AI models\u00b6"], "text": "Using Apigee gateway for AI models \u00b6 Supported in ADK Python v1.18.0 Apigee acts as a powerful AI Gateway , transforming how you manage and govern your generative AI model traffic. By exposing your AI model endpoint (like Vertex AI or the Gemini API) through an Apigee proxy, you immediately gain enterprise-grade capabilities: Model Safety: Implement security policies like Model Armor for threat protection. Traffic Governance: Enforce Rate Limiting and Token Limiting to manage costs and prevent abuse. Performance: Improve response times and efficiency using Semantic Caching and advanced model routing. Monitoring & Visibility: Get granular monitoring, analysis, and auditing of all your AI requests. NOTE: The ApigeeLLM wrapper is currently designed for use with Vertex AI and the Gemini API (generateContent). We are continually expanding support for other models and interfaces. Integration Method: To integrate Apigee's governance into your agent's workflow, simply instantiate the ApigeeLlm wrapper and pass it to an LlmAgent or other agent type. Example: from google.adk.agents import LlmAgent from google.adk.models.apigee_llm import ApigeeLlm # Instantiate the ApigeeLlm wrapper model = ApigeeLlm ( # Specify the Apigee route to your model. For more info, check out the ApigeeLlm documentation (https://github.com/google/adk-python/tree/main/contributing/samples/hello_world_apigeellm). model = \"apigee/gemini-2.5-flash\" , # The proxy URL of your deployed Apigee proxy including the base path proxy_url = f \"https:// { APIGEE_PROXY_URL } \" , # Pass necessary authentication/authorization headers (like an API key) custom_headers = { \"foo\" : \"bar\" } ) # Pass the configured model wrapper to your LlmAgent agent = LlmAgent ( model = model , name = \"my_governed_agent\" , instruction = \"You are a helpful assistant powered by Gemini and governed by Apigee.\" , # ... other agent parameters ) With this configuration, every API call from your agent will be routed through Apigee first, where all necessary policies (security, rate limiting, logging) are executed before the request is securely forwarded to the underlying AI model endpoint. For a full code example using the Apigee proxy, see Hello World Apigee LLM ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import LlmAgent\nfrom google.adk.models.apigee_llm import ApigeeLlm\n\n# Instantiate the ApigeeLlm wrapper\nmodel = ApigeeLlm(\n    # Specify the Apigee route to your model. For more info, check out the ApigeeLlm documentation (https://github.com/google/adk-python/tree/main/contributing/samples/hello_world_apigeellm).\n    model=\"apigee/gemini-2.5-flash\",\n    # The proxy URL of your deployed Apigee proxy including the base path\n    proxy_url=f\"https://{APIGEE_PROXY_URL}\",\n    # Pass necessary authentication/authorization headers (like an API key)\n    custom_headers={\"foo\": \"bar\"}\n)\n\n# Pass the configured model wrapper to your LlmAgent\nagent = LlmAgent(\n    model=model,\n    name=\"my_governed_agent\",\n    instruction=\"You are a helpful assistant powered by Gemini and governed by Apigee.\",\n    # ... other agent parameters\n)"}]}, {"heading_path": ["Using Cloud & Proprietary Models via LiteLLM\u00b6"], "text": "Using Cloud & Proprietary Models via LiteLLM \u00b6 Supported in ADK Python v0.1.0 To access a vast range of LLMs from providers like OpenAI, Anthropic (non-Vertex\nAI), Cohere, and many others, ADK offers integration through the LiteLLM\nlibrary. Integration Method: Instantiate the LiteLlm wrapper class and pass it to\nthe model parameter of LlmAgent . LiteLLM Overview: LiteLLM acts as a translation\nlayer, providing a standardized, OpenAI-compatible interface to over 100+ LLMs. Setup: Install LiteLLM: pip install litellm Set Provider API Keys: Configure API keys as environment variables for\n   the specific providers you intend to use. Example for OpenAI: export OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\" Example for Anthropic (non-Vertex AI): export ANTHROPIC_API_KEY = \"YOUR_ANTHROPIC_API_KEY\" Consult the LiteLLM Providers Documentation for the correct environment variable names for other providers. Example: from google.adk.agents import LlmAgent from google.adk.models.lite_llm import LiteLlm # --- Example Agent using OpenAI's GPT-4o --- # (Requires OPENAI_API_KEY) agent_openai = LlmAgent ( model = LiteLlm ( model = \"openai/gpt-4o\" ), # LiteLLM model string format name = \"openai_agent\" , instruction = \"You are a helpful assistant powered by GPT-4o.\" , # ... other agent parameters ) # --- Example Agent using Anthropic's Claude Haiku (non-Vertex) --- # (Requires ANTHROPIC_API_KEY) agent_claude_direct = LlmAgent ( model = LiteLlm ( model = \"anthropic/claude-3-haiku-20240307\" ), name = \"claude_direct_agent\" , instruction = \"You are an assistant powered by Claude Haiku.\" , # ... other agent parameters ) Windows Encoding Note for LiteLLM When using ADK agents with LiteLLM on Windows, you might encounter a UnicodeDecodeError . This error occurs because LiteLLM may attempt to read cached files using the default Windows encoding ( cp1252 ) instead of UTF-8. To prevent this, we recommend setting the PYTHONUTF8 environment variable to 1 . This forces Python to use UTF-8 for all file I/O. Example (PowerShell): # Set for the current session $env:PYTHONUTF8 = \"1\" # Set persistently for the user [System.Environment] :: SetEnvironmentVariable ( 'PYTHONUTF8' , '1' , [System.EnvironmentVariableTarget] :: User ) ", "code_blocks": [{"language": "text", "code": "pip install litellm"}, {"language": "text", "code": "export OPENAI_API_KEY=\"YOUR_OPENAI_API_KEY\""}, {"language": "text", "code": "export ANTHROPIC_API_KEY=\"YOUR_ANTHROPIC_API_KEY\""}, {"language": "text", "code": "from google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\n\n# --- Example Agent using OpenAI's GPT-4o ---\n# (Requires OPENAI_API_KEY)\nagent_openai = LlmAgent(\n    model=LiteLlm(model=\"openai/gpt-4o\"), # LiteLLM model string format\n    name=\"openai_agent\",\n    instruction=\"You are a helpful assistant powered by GPT-4o.\",\n    # ... other agent parameters\n)\n\n# --- Example Agent using Anthropic's Claude Haiku (non-Vertex) ---\n# (Requires ANTHROPIC_API_KEY)\nagent_claude_direct = LlmAgent(\n    model=LiteLlm(model=\"anthropic/claude-3-haiku-20240307\"),\n    name=\"claude_direct_agent\",\n    instruction=\"You are an assistant powered by Claude Haiku.\",\n    # ... other agent parameters\n)"}, {"language": "text", "code": "# Set for the current session\n$env:PYTHONUTF8 = \"1\"\n\n# Set persistently for the user\n[System.Environment]::SetEnvironmentVariable('PYTHONUTF8', '1', [System.EnvironmentVariableTarget]::User)"}]}, {"heading_path": ["Using Open & Local Models via LiteLLM\u00b6"], "text": "Using Open & Local Models via LiteLLM \u00b6 Supported in ADK Python v0.1.0 For maximum control, cost savings, privacy, or offline use cases, you can run\nopen-source models locally or self-host them and integrate them using LiteLLM. Integration Method: Instantiate the LiteLlm wrapper class, configured to\npoint to your local model server. ", "code_blocks": []}, {"heading_path": ["Ollama Integration\u00b6"], "text": "Ollama Integration \u00b6 Ollama allows you to easily run open-source models\nlocally. ", "code_blocks": []}, {"heading_path": ["Model choice\u00b6"], "text": "Model choice \u00b6 If your agent is relying on tools, please make sure that you select a model with\ntool support from Ollama website . For reliable results, we recommend using a decent-sized model with tool support. The tool support for the model can be checked with the following command: ollama show mistral-small3.1 Model architecture mistral3 parameters 24 .0B context length 131072 embedding length 5120 quantization Q4_K_M Capabilities completion vision tools You are supposed to see tools listed under capabilities. You can also look at the template the model is using and tweak it based on your\nneeds. ollama show --modelfile llama3.2 > model_file_to_modify For instance, the default template for the above model inherently suggests that\nthe model shall call a function all the time. This may result in an infinite\nloop of function calls. Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt. Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}. Do not use variables. You can swap such prompts with a more descriptive one to prevent infinite tool\ncall loops. For instance: Review the user's prompt and the available functions listed below. First, determine if calling one of these functions is the most appropriate way to respond. A function call is likely needed if the prompt asks for a specific action, requires external data lookup, or involves calculations handled by the functions. If the prompt is a general question or can be answered directly, a function call is likely NOT needed. If you determine a function call IS required: Respond ONLY with a JSON object in the format {\"name\": \"function_name\", \"parameters\": {\"argument_name\": \"value\"}}. Ensure parameter values are concrete, not variables. If you determine a function call IS NOT required: Respond directly to the user's prompt in plain text, providing the answer or information requested. Do not output any JSON. Then you can create a new model with the following command: ollama create llama3.2-modified -f model_file_to_modify ", "code_blocks": [{"language": "text", "code": "ollama show mistral-small3.1\n  Model\n    architecture        mistral3\n    parameters          24.0B\n    context length      131072\n    embedding length    5120\n    quantization        Q4_K_M\n\n  Capabilities\n    completion\n    vision\n    tools"}, {"language": "text", "code": "ollama show --modelfile llama3.2 > model_file_to_modify"}, {"language": "text", "code": "Given the following functions, please respond with a JSON for a function call\nwith its proper arguments that best answers the given prompt.\n\nRespond in the format {\"name\": function name, \"parameters\": dictionary of\nargument name and its value}. Do not use variables."}, {"language": "text", "code": "Review the user's prompt and the available functions listed below.\nFirst, determine if calling one of these functions is the most appropriate way to respond. A function call is likely needed if the prompt asks for a specific action, requires external data lookup, or involves calculations handled by the functions. If the prompt is a general question or can be answered directly, a function call is likely NOT needed.\n\nIf you determine a function call IS required: Respond ONLY with a JSON object in the format {\"name\": \"function_name\", \"parameters\": {\"argument_name\": \"value\"}}. Ensure parameter values are concrete, not variables.\n\nIf you determine a function call IS NOT required: Respond directly to the user's prompt in plain text, providing the answer or information requested. Do not output any JSON."}, {"language": "text", "code": "ollama create llama3.2-modified -f model_file_to_modify"}]}, {"heading_path": ["Using ollama_chat provider\u00b6"], "text": "Using ollama_chat provider \u00b6 Our LiteLLM wrapper can be used to create agents with Ollama models. root_agent = Agent ( model = LiteLlm ( model = \"ollama_chat/mistral-small3.1\" ), name = \"dice_agent\" , description = ( \"hello world agent that can roll a dice of 8 sides and check prime\" \" numbers.\" ), instruction = \"\"\" You roll dice and answer questions about the outcome of the dice rolls. \"\"\" , tools = [ roll_die , check_prime , ], ) It is important to set the provider ollama_chat instead of ollama . Using ollama will result in unexpected behaviors such as infinite tool call loops\nand ignoring previous context. While api_base can be provided inside LiteLLM for generation, LiteLLM library\nis calling other APIs relying on the env variable instead as of v1.65.5 after\ncompletion. So at this time, we recommend setting the env variable OLLAMA_API_BASE to point to the ollama server. export OLLAMA_API_BASE = \"http://localhost:11434\" adk web ", "code_blocks": [{"language": "text", "code": "root_agent = Agent(\n    model=LiteLlm(model=\"ollama_chat/mistral-small3.1\"),\n    name=\"dice_agent\",\n    description=(\n        \"hello world agent that can roll a dice of 8 sides and check prime\"\n        \" numbers.\"\n    ),\n    instruction=\"\"\"\n      You roll dice and answer questions about the outcome of the dice rolls.\n    \"\"\",\n    tools=[\n        roll_die,\n        check_prime,\n    ],\n)"}, {"language": "text", "code": "export OLLAMA_API_BASE=\"http://localhost:11434\"\nadk web"}]}, {"heading_path": ["Using openai provider\u00b6"], "text": "Using openai provider \u00b6 Alternatively, openai can be used as the provider name. But this will also\nrequire setting the OPENAI_API_BASE=http://localhost:11434/v1 and OPENAI_API_KEY=anything env variables instead of OLLAMA_API_BASE . Please\nnote that api base now has /v1 at the end. root_agent = Agent ( model = LiteLlm ( model = \"openai/mistral-small3.1\" ), name = \"dice_agent\" , description = ( \"hello world agent that can roll a dice of 8 sides and check prime\" \" numbers.\" ), instruction = \"\"\" You roll dice and answer questions about the outcome of the dice rolls. \"\"\" , tools = [ roll_die , check_prime , ], ) export OPENAI_API_BASE = http://localhost:11434/v1 export OPENAI_API_KEY = anything adk web ", "code_blocks": [{"language": "text", "code": "root_agent = Agent(\n    model=LiteLlm(model=\"openai/mistral-small3.1\"),\n    name=\"dice_agent\",\n    description=(\n        \"hello world agent that can roll a dice of 8 sides and check prime\"\n        \" numbers.\"\n    ),\n    instruction=\"\"\"\n      You roll dice and answer questions about the outcome of the dice rolls.\n    \"\"\",\n    tools=[\n        roll_die,\n        check_prime,\n    ],\n)"}, {"language": "text", "code": "export OPENAI_API_BASE=http://localhost:11434/v1\nexport OPENAI_API_KEY=anything\nadk web"}]}, {"heading_path": ["Debugging\u00b6"], "text": "Debugging \u00b6 You can see the request sent to the Ollama server by adding the following in\nyour agent code just after imports. import litellm litellm . _turn_on_debug () Look for a line like the following: Request Sent from LiteLLM: curl -X POST \\ http://localhost:11434/api/chat \\ -d '{' model ': ' mistral-small3.1 ', ' messages ': [{' role ': ' system ', ' content ' : ... ", "code_blocks": [{"language": "text", "code": "import litellm\nlitellm._turn_on_debug()"}, {"language": "text", "code": "Request Sent from LiteLLM:\ncurl -X POST \\\nhttp://localhost:11434/api/chat \\\n-d '{'model': 'mistral-small3.1', 'messages': [{'role': 'system', 'content': ..."}]}, {"heading_path": ["Self-Hosted Endpoint (e.g., vLLM)\u00b6"], "text": "Self-Hosted Endpoint (e.g., vLLM) \u00b6 Supported in ADK Python Tools such as vLLM allow you to host\nmodels efficiently and often expose an OpenAI-compatible API endpoint. Setup: Deploy Model: Deploy your chosen model using vLLM (or a similar tool).\n   Note the API base URL (e.g., https://your-vllm-endpoint.run.app/v1 ). Important for ADK Tools: When deploying, ensure the serving tool\n  supports and enables OpenAI-compatible tool/function calling. For vLLM,\n  this might involve flags like --enable-auto-tool-choice and potentially\n  a specific --tool-call-parser , depending on the model. Refer to the vLLM\n  documentation on Tool Use. Authentication: Determine how your endpoint handles authentication (e.g.,\n   API key, bearer token). Integration Example: import subprocess from google.adk.agents import LlmAgent from google.adk.models.lite_llm import LiteLlm # --- Example Agent using a model hosted on a vLLM endpoint --- # Endpoint URL provided by your vLLM deployment api_base_url = \"https://your-vllm-endpoint.run.app/v1\" # Model name as recognized by *your* vLLM endpoint configuration model_name_at_endpoint = \"hosted_vllm/google/gemma-3-4b-it\" # Example from vllm_test.py # Authentication (Example: using gcloud identity token for a Cloud Run deployment) # Adapt this based on your endpoint's security try : gcloud_token = subprocess . check_output ( [ \"gcloud\" , \"auth\" , \"print-identity-token\" , \"-q\" ] ) . decode () . strip () auth_headers = { \"Authorization\" : f \"Bearer { gcloud_token } \" } except Exception as e : print ( f \"Warning: Could not get gcloud token - { e } . Endpoint might be unsecured or require different auth.\" ) auth_headers = None # Or handle error appropriately agent_vllm = LlmAgent ( model = LiteLlm ( model = model_name_at_endpoint , api_base = api_base_url , # Pass authentication headers if needed extra_headers = auth_headers # Alternatively, if endpoint uses an API key: # api_key=\"YOUR_ENDPOINT_API_KEY\" ), name = \"vllm_agent\" , instruction = \"You are a helpful assistant running on a self-hosted vLLM endpoint.\" , # ... other agent parameters ) ", "code_blocks": [{"language": "text", "code": "import subprocess\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.lite_llm import LiteLlm\n\n# --- Example Agent using a model hosted on a vLLM endpoint ---\n\n# Endpoint URL provided by your vLLM deployment\napi_base_url = \"https://your-vllm-endpoint.run.app/v1\"\n\n# Model name as recognized by *your* vLLM endpoint configuration\nmodel_name_at_endpoint = \"hosted_vllm/google/gemma-3-4b-it\" # Example from vllm_test.py\n\n# Authentication (Example: using gcloud identity token for a Cloud Run deployment)\n# Adapt this based on your endpoint's security\ntry:\n    gcloud_token = subprocess.check_output(\n        [\"gcloud\", \"auth\", \"print-identity-token\", \"-q\"]\n    ).decode().strip()\n    auth_headers = {\"Authorization\": f\"Bearer {gcloud_token}\"}\nexcept Exception as e:\n    print(f\"Warning: Could not get gcloud token - {e}. Endpoint might be unsecured or require different auth.\")\n    auth_headers = None # Or handle error appropriately\n\nagent_vllm = LlmAgent(\n    model=LiteLlm(\n        model=model_name_at_endpoint,\n        api_base=api_base_url,\n        # Pass authentication headers if needed\n        extra_headers=auth_headers\n        # Alternatively, if endpoint uses an API key:\n        # api_key=\"YOUR_ENDPOINT_API_KEY\"\n    ),\n    name=\"vllm_agent\",\n    instruction=\"You are a helpful assistant running on a self-hosted vLLM endpoint.\",\n    # ... other agent parameters\n)"}]}, {"heading_path": ["Using Hosted & Tuned Models on Vertex AI\u00b6"], "text": "Using Hosted & Tuned Models on Vertex AI \u00b6 For enterprise-grade scalability, reliability, and integration with Google\nCloud's MLOps ecosystem, you can use models deployed to Vertex AI Endpoints.\nThis includes models from Model Garden or your own fine-tuned models. Integration Method: Pass the full Vertex AI Endpoint resource string\n( projects/PROJECT_ID/locations/LOCATION/endpoints/ENDPOINT_ID ) directly to the model parameter of LlmAgent . Vertex AI Setup (Consolidated): Ensure your environment is configured for Vertex AI: Authentication: Use Application Default Credentials (ADC): gcloud auth application-default login Environment Variables: Set your project and location: export GOOGLE_CLOUD_PROJECT = \"YOUR_PROJECT_ID\" export GOOGLE_CLOUD_LOCATION = \"YOUR_VERTEX_AI_LOCATION\" # e.g., us-central1 Enable Vertex Backend: Crucially, ensure the google-genai library\n   targets Vertex AI: export GOOGLE_GENAI_USE_VERTEXAI = TRUE ", "code_blocks": [{"language": "text", "code": "gcloud auth application-default login"}, {"language": "text", "code": "export GOOGLE_CLOUD_PROJECT=\"YOUR_PROJECT_ID\"\nexport GOOGLE_CLOUD_LOCATION=\"YOUR_VERTEX_AI_LOCATION\" # e.g., us-central1"}, {"language": "text", "code": "export GOOGLE_GENAI_USE_VERTEXAI=TRUE"}]}, {"heading_path": ["Model Garden Deployments\u00b6"], "text": "Model Garden Deployments \u00b6 Supported in ADK Python v0.2.0 You can deploy various open and proprietary models from the Vertex AI Model Garden to an endpoint. Example: from google.adk.agents import LlmAgent from google.genai import types # For config objects # --- Example Agent using a Llama 3 model deployed from Model Garden --- # Replace with your actual Vertex AI Endpoint resource name llama3_endpoint = \"projects/YOUR_PROJECT_ID/locations/us-central1/endpoints/YOUR_LLAMA3_ENDPOINT_ID\" agent_llama3_vertex = LlmAgent ( model = llama3_endpoint , name = \"llama3_vertex_agent\" , instruction = \"You are a helpful assistant based on Llama 3, hosted on Vertex AI.\" , generate_content_config = types . GenerateContentConfig ( max_output_tokens = 2048 ), # ... other agent parameters ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import LlmAgent\nfrom google.genai import types # For config objects\n\n# --- Example Agent using a Llama 3 model deployed from Model Garden ---\n\n# Replace with your actual Vertex AI Endpoint resource name\nllama3_endpoint = \"projects/YOUR_PROJECT_ID/locations/us-central1/endpoints/YOUR_LLAMA3_ENDPOINT_ID\"\n\nagent_llama3_vertex = LlmAgent(\n    model=llama3_endpoint,\n    name=\"llama3_vertex_agent\",\n    instruction=\"You are a helpful assistant based on Llama 3, hosted on Vertex AI.\",\n    generate_content_config=types.GenerateContentConfig(max_output_tokens=2048),\n    # ... other agent parameters\n)"}]}, {"heading_path": ["Fine-tuned Model Endpoints\u00b6"], "text": "Fine-tuned Model Endpoints \u00b6 Supported in ADK Python v0.2.0 Deploying your fine-tuned models (whether based on Gemini or other architectures\nsupported by Vertex AI) results in an endpoint that can be used directly. Example: from google.adk.agents import LlmAgent # --- Example Agent using a fine-tuned Gemini model endpoint --- # Replace with your fine-tuned model's endpoint resource name finetuned_gemini_endpoint = \"projects/YOUR_PROJECT_ID/locations/us-central1/endpoints/YOUR_FINETUNED_ENDPOINT_ID\" agent_finetuned_gemini = LlmAgent ( model = finetuned_gemini_endpoint , name = \"finetuned_gemini_agent\" , instruction = \"You are a specialized assistant trained on specific data.\" , # ... other agent parameters ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import LlmAgent\n\n# --- Example Agent using a fine-tuned Gemini model endpoint ---\n\n# Replace with your fine-tuned model's endpoint resource name\nfinetuned_gemini_endpoint = \"projects/YOUR_PROJECT_ID/locations/us-central1/endpoints/YOUR_FINETUNED_ENDPOINT_ID\"\n\nagent_finetuned_gemini = LlmAgent(\n    model=finetuned_gemini_endpoint,\n    name=\"finetuned_gemini_agent\",\n    instruction=\"You are a specialized assistant trained on specific data.\",\n    # ... other agent parameters\n)"}]}, {"heading_path": ["Third-Party Models on Vertex AI (e.g., Anthropic Claude)\u00b6"], "text": "Third-Party Models on Vertex AI (e.g., Anthropic Claude) \u00b6 Some providers, like Anthropic, make their models available directly through\nVertex AI. Python Java Integration Method: Uses the direct model string (e.g., \"claude-3-sonnet@20240229\" ), but requires manual registration within ADK. Why Registration? ADK's registry automatically recognizes gemini-* strings\nand standard Vertex AI endpoint strings ( projects/.../endpoints/... ) and\nroutes them via the google-genai library. For other model types used directly\nvia Vertex AI (like Claude), you must explicitly tell the ADK registry which\nspecific wrapper class ( Claude in this case) knows how to handle that model\nidentifier string with the Vertex AI backend. Setup: Vertex AI Environment: Ensure the consolidated Vertex AI setup (ADC, Env\n   Vars, GOOGLE_GENAI_USE_VERTEXAI=TRUE ) is complete. Install Provider Library: Install the necessary client library configured\n   for Vertex AI. pip install \"anthropic[vertex]\" Register Model Class: Add this code near the start of your application, before creating an agent using the Claude model string: # Required for using Claude model strings directly via Vertex AI with LlmAgent from google.adk.models.anthropic_llm import Claude from google.adk.models.registry import LLMRegistry LLMRegistry . register ( Claude ) Example: from google.adk.agents import LlmAgent from google.adk.models.anthropic_llm import Claude # Import needed for registration from google.adk.models.registry import LLMRegistry # Import needed for registration from google.genai import types # --- Register Claude class (do this once at startup) --- LLMRegistry . register ( Claude ) # --- Example Agent using Claude 3 Sonnet on Vertex AI --- # Standard model name for Claude 3 Sonnet on Vertex AI claude_model_vertexai = \"claude-3-sonnet@20240229\" agent_claude_vertexai = LlmAgent ( model = claude_model_vertexai , # Pass the direct string after registration name = \"claude_vertexai_agent\" , instruction = \"You are an assistant powered by Claude 3 Sonnet on Vertex AI.\" , generate_content_config = types . GenerateContentConfig ( max_output_tokens = 4096 ), # ... other agent parameters ) Integration Method: Directly instantiate the provider-specific model class (e.g., com.google.adk.models.Claude ) and configure it with a Vertex AI backend. Why Direct Instantiation? The Java ADK's LlmRegistry primarily handles Gemini models by default. For third-party models like Claude on Vertex AI, you directly provide an instance of the ADK's wrapper class (e.g., Claude ) to the LlmAgent . This wrapper class is responsible for interacting with the model via its specific client library, configured for Vertex AI. Setup: Vertex AI Environment: Ensure your Google Cloud project and region are correctly set up. Application Default Credentials (ADC): Make sure ADC is configured correctly in your environment. This is typically done by running gcloud auth application-default login . The Java client libraries will use these credentials to authenticate with Vertex AI. Follow the Google Cloud Java documentation on ADC for detailed setup. Provider Library Dependencies: Third-Party Client Libraries (Often Transitive): The ADK core library often includes the necessary client libraries for common third-party models on Vertex AI (like Anthropic's required classes) as transitive dependencies . This means you might not need to explicitly add a separate dependency for the Anthropic Vertex SDK in your pom.xml or build.gradle . Instantiate and Configure the Model: When creating your LlmAgent , instantiate the Claude class (or the equivalent for another provider) and configure its VertexBackend . Example: import com.anthropic.client.AnthropicClient ; import com.anthropic.client.okhttp.AnthropicOkHttpClient ; import com.anthropic.vertex.backends.VertexBackend ; import com.google.adk.agents.LlmAgent ; import com.google.adk.models.Claude ; // ADK's wrapper for Claude import com.google.auth.oauth2.GoogleCredentials ; import java.io.IOException ; // ... other imports public class ClaudeVertexAiAgent { public static LlmAgent createAgent () throws IOException { // Model name for Claude 3 Sonnet on Vertex AI (or other versions) String claudeModelVertexAi = \"claude-3-7-sonnet\" ; // Or any other Claude model // Configure the AnthropicOkHttpClient with the VertexBackend AnthropicClient anthropicClient = AnthropicOkHttpClient . builder () . backend ( VertexBackend . builder () . region ( \"us-east5\" ) // Specify your Vertex AI region . project ( \"your-gcp-project-id\" ) // Specify your GCP Project ID . googleCredentials ( GoogleCredentials . getApplicationDefault ()) . build ()) . build (); // Instantiate LlmAgent with the ADK Claude wrapper LlmAgent agentClaudeVertexAi = LlmAgent . builder () . model ( new Claude ( claudeModelVertexAi , anthropicClient )) // Pass the Claude instance . name ( \"claude_vertexai_agent\" ) . instruction ( \"You are an assistant powered by Claude 3 Sonnet on Vertex AI.\" ) // .generateContentConfig(...) // Optional: Add generation config if needed // ... other agent parameters . build (); return agentClaudeVertexAi ; } public static void main ( String [] args ) { try { LlmAgent agent = createAgent (); System . out . println ( \"Successfully created agent: \" + agent . name ()); // Here you would typically set up a Runner and Session to interact with the agent } catch ( IOException e ) { System . err . println ( \"Failed to create agent: \" + e . getMessage ()); e . printStackTrace (); } } } Back to top ", "code_blocks": [{"language": "text", "code": "pip install \"anthropic[vertex]\""}, {"language": "text", "code": "# Required for using Claude model strings directly via Vertex AI with LlmAgent\nfrom google.adk.models.anthropic_llm import Claude\nfrom google.adk.models.registry import LLMRegistry\n\nLLMRegistry.register(Claude)"}, {"language": "text", "code": "from google.adk.agents import LlmAgent\nfrom google.adk.models.anthropic_llm import Claude # Import needed for registration\nfrom google.adk.models.registry import LLMRegistry # Import needed for registration\nfrom google.genai import types\n\n# --- Register Claude class (do this once at startup) ---\nLLMRegistry.register(Claude)\n\n# --- Example Agent using Claude 3 Sonnet on Vertex AI ---\n\n# Standard model name for Claude 3 Sonnet on Vertex AI\nclaude_model_vertexai = \"claude-3-sonnet@20240229\"\n\nagent_claude_vertexai = LlmAgent(\n    model=claude_model_vertexai, # Pass the direct string after registration\n    name=\"claude_vertexai_agent\",\n    instruction=\"You are an assistant powered by Claude 3 Sonnet on Vertex AI.\",\n    generate_content_config=types.GenerateContentConfig(max_output_tokens=4096),\n    # ... other agent parameters\n)"}, {"language": "text", "code": "import com.anthropic.client.AnthropicClient;\nimport com.anthropic.client.okhttp.AnthropicOkHttpClient;\nimport com.anthropic.vertex.backends.VertexBackend;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.models.Claude; // ADK's wrapper for Claude\nimport com.google.auth.oauth2.GoogleCredentials;\nimport java.io.IOException;\n\n// ... other imports\n\npublic class ClaudeVertexAiAgent {\n\n    public static LlmAgent createAgent() throws IOException {\n        // Model name for Claude 3 Sonnet on Vertex AI (or other versions)\n        String claudeModelVertexAi = \"claude-3-7-sonnet\"; // Or any other Claude model\n\n        // Configure the AnthropicOkHttpClient with the VertexBackend\n        AnthropicClient anthropicClient = AnthropicOkHttpClient.builder()\n            .backend(\n                VertexBackend.builder()\n                    .region(\"us-east5\") // Specify your Vertex AI region\n                    .project(\"your-gcp-project-id\") // Specify your GCP Project ID\n                    .googleCredentials(GoogleCredentials.getApplicationDefault())\n                    .build())\n            .build();\n\n        // Instantiate LlmAgent with the ADK Claude wrapper\n        LlmAgent agentClaudeVertexAi = LlmAgent.builder()\n            .model(new Claude(claudeModelVertexAi, anthropicClient)) // Pass the Claude instance\n            .name(\"claude_vertexai_agent\")\n            .instruction(\"You are an assistant powered by Claude 3 Sonnet on Vertex AI.\")\n            // .generateContentConfig(...) // Optional: Add generation config if needed\n            // ... other agent parameters\n            .build();\n\n        return agentClaudeVertexAi;\n    }\n\n    public static void main(String[] args) {\n        try {\n            LlmAgent agent = createAgent();\n            System.out.println(\"Successfully created agent: \" + agent.name());\n            // Here you would typically set up a Runner and Session to interact with the agent\n        } catch (IOException e) {\n            System.err.println(\"Failed to create agent: \" + e.getMessage());\n            e.printStackTrace();\n        }\n    }\n}"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:09.288073", "source_type": "adk-docs"}
{"doc_id": "588dcd5668251c9c9faef8dbd721e3e2dc686866bf81553d1a67317cd59b55d1", "url": "https://google.github.io/adk-docs/tools", "title": "Tools for Agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Tools for Agents\u00b6"], "text": "Tools for Agents \u00b6 Check out the following pre-built tools that you can use with ADK agents: ", "code_blocks": []}, {"heading_path": ["Gemini tools\u00b6"], "text": "Gemini tools \u00b6 ", "code_blocks": []}, {"heading_path": ["Google Search"], "text": "Google Search Perform web searches using Google Search with Gemini ", "code_blocks": []}, {"heading_path": ["Code Execution"], "text": "Code Execution Execute code using Gemini models ", "code_blocks": []}, {"heading_path": ["Google Cloud tools\u00b6"], "text": "Google Cloud tools \u00b6 ", "code_blocks": []}, {"heading_path": ["Apigee API Hub"], "text": "Apigee API Hub Turn any documented API from Apigee API hub into a tool ", "code_blocks": []}, {"heading_path": ["Application Integration"], "text": "Application Integration Link your agents to enterprise apps using Integration Connectors ", "code_blocks": []}, {"heading_path": ["BigQuery Agent Analytics"], "text": "BigQuery Agent Analytics Analyze and debug agent behavior at scale. ", "code_blocks": []}, {"heading_path": ["BigQuery Tools"], "text": "BigQuery Tools Connect with BigQuery to retrieve data and perform analysis ", "code_blocks": []}, {"heading_path": ["Bigtable Tools"], "text": "Bigtable Tools Interact with Bigtable to retrieve data and and execute SQL ", "code_blocks": []}, {"heading_path": ["GKE Code Executor"], "text": "GKE Code Executor Run AI-generated code in a secure and scalable GKE environment ", "code_blocks": []}, {"heading_path": ["Spanner Tools"], "text": "Spanner Tools Interact with Spanner to retrieve data, search, and execute SQL ", "code_blocks": []}, {"heading_path": ["MCP Toolbox for Databases"], "text": "MCP Toolbox for Databases Connect over 30 different data sources to your agents ", "code_blocks": []}, {"heading_path": ["Vertex AI RAG Engine"], "text": "Vertex AI RAG Engine Perform private data retrieval using Vertex AI RAG Engine ", "code_blocks": []}, {"heading_path": ["Vertex AI Search"], "text": "Vertex AI Search Search across your private, configured data stores in Vertex AI Search ", "code_blocks": []}, {"heading_path": ["Third-party tools\u00b6"], "text": "Third-party tools \u00b6 ", "code_blocks": []}, {"heading_path": ["AgentQL"], "text": "AgentQL Extract resilient, structured web data using natural language ", "code_blocks": []}, {"heading_path": ["Bright Data"], "text": "Bright Data One MCP for the web - connect your AI to real web data ", "code_blocks": []}, {"heading_path": ["Browserbase"], "text": "Browserbase Powers web browsing capabilities for AI agents ", "code_blocks": []}, {"heading_path": ["Exa"], "text": "Exa Search and extract structured content from websites and live data ", "code_blocks": []}, {"heading_path": ["Firecrawl"], "text": "Firecrawl Empower your AI apps with clean data from any website ", "code_blocks": []}, {"heading_path": ["GitHub"], "text": "GitHub Analyze code, manage issues and PRs, and automate workflows ", "code_blocks": []}, {"heading_path": ["Hugging Face"], "text": "Hugging Face Access models, datasets, research papers, and AI tools ", "code_blocks": []}, {"heading_path": ["Notion"], "text": "Notion Search workspaces, create pages, and manage tasks and databases ", "code_blocks": []}, {"heading_path": ["Tavily"], "text": "Tavily Provides real-time web search, extraction, and crawling tools ", "code_blocks": []}, {"heading_path": ["Build your tools\u00b6"], "text": "Build your tools \u00b6 If the above tools don't meet your needs, you can build tools for your ADK\nworkflows using the following guides: Function Tools : Build custom tools for\n    your specific ADK agent needs. MCP Tools : Connect MCP servers as tools\n    for your ADK agents. OpenAPI Integration :\n    Generate callable tools directly from an OpenAPI Specification. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:09.704659", "source_type": "adk-docs"}
{"doc_id": "aa08f6dfc109ecf4d6e7fc73d3d1cd385aa02f2dce5be446f7520024607403a1", "url": "https://google.github.io/adk-docs/tools/built-in-tools", "title": "Built-in tools - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Built-in tools\u00b6"], "text": "Built-in tools \u00b6 These built-in tools provide ready-to-use functionality such as Google Search or\ncode executors that provide agents with common capabilities. For instance, an\nagent that needs to retrieve information from the web can directly use the google_search tool without any additional setup. ", "code_blocks": []}, {"heading_path": ["How to Use\u00b6"], "text": "How to Use \u00b6 Import: Import the desired tool from the tools module. This is agents.tools in Python, google.golang.org/adk/tool/geminitool in Go, or com.google.adk.tools in Java. Configure: Initialize the tool, providing required parameters if any. Register: Add the initialized tool to the tools list of your Agent. Once added to an agent, the agent can decide to use the tool based on the user\nprompt and its instructions . The framework handles the execution of the\ntool when the agent calls it. Important: check the Limitations section of this page. ", "code_blocks": []}, {"heading_path": ["Available Built-in tools\u00b6"], "text": "Available Built-in tools \u00b6 Note: Go supports the Google Search tool and other built-in tools via the geminitool package.\nNote: Java only supports Google Search and Code Execution tools currently. ", "code_blocks": []}, {"heading_path": ["Google Search\u00b6"], "text": "Google Search \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.2.0 The google_search tool allows the agent to perform web searches using Google Search. The google_search tool is only compatible with Gemini 2 models. For further details of the tool, see Understanding Google Search grounding . Additional requirements when using the google_search tool When you use grounding with Google Search, and you receive Search suggestions in your response, you must display the Search suggestions in production and in your applications.\nFor more information on grounding with Google Search, see Grounding with Google Search documentation for Google AI Studio or Vertex AI . The UI code (HTML) is returned in the Gemini response as renderedContent , and you will need to show the HTML in your app, in accordance with the policy. Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.agents import Agent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.tools import google_search from google.genai import types APP_NAME = \"google_search_agent\" USER_ID = \"user1234\" SESSION_ID = \"1234\" root_agent = Agent ( name = \"basic_search_agent\" , model = \"gemini-2.0-flash\" , description = \"Agent to answer questions using Google Search.\" , instruction = \"I can answer your questions by searching the internet. Just ask me anything!\" , # google_search is a pre-built tool which allows the agent to perform Google searches. tools = [ google_search ] ) # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = root_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) async for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response: \" , final_response ) # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"what's the latest ai news?\" ) // Copyright 2025 Google LLC // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // //     http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package main import ( \"context\" \"fmt\" \"log\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/geminitool\" \"google.golang.org/genai\" ) func createSearchAgent ( ctx context . Context ) ( agent . Agent , error ) { model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig {}) if err != nil { return nil , fmt . Errorf ( \"failed to create model: %v\" , err ) } return llmagent . New ( llmagent . Config { Name : \"basic_search_agent\" , Model : model , Description : \"Agent to answer questions using Google Search.\" , Instruction : \"I can answer your questions by searching the web. Just ask me anything!\" , Tools : [] tool . Tool { geminitool . GoogleSearch {}}, }) } const ( userID = \"user1234\" appName = \"Google Search_agent\" ) func callAgent ( ctx context . Context , a agent . Agent , prompt string ) error { sessionService := session . InMemoryService () session , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , }) if err != nil { return fmt . Errorf ( \"failed to create the session service: %v\" , err ) } config := runner . Config { AppName : appName , Agent : a , SessionService : sessionService , } r , err := runner . New ( config ) if err != nil { return fmt . Errorf ( \"failed to create the runner: %v\" , err ) } sessionID := session . Session . ID () userMsg := & genai . Content { Parts : [] * genai . Part {{ Text : prompt }}, Role : string ( genai . RoleUser ), } // The r.Run method streams events and errors. // The loop iterates over the results, handling them as they arrive. for event , err := range r . Run ( ctx , userID , sessionID , userMsg , agent . RunConfig { StreamingMode : agent . StreamingModeSSE , }) { if err != nil { fmt . Printf ( \"\\nAGENT_ERROR: %v\\n\" , err ) } else if event . Partial { for _ , p := range event . LLMResponse . Content . Parts { fmt . Print ( p . Text ) } } } return nil } func main () { agent , err := createSearchAgent ( context . Background ()) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } fmt . Println ( \"Agent created:\" , agent . Name ()) prompt := \"what's the latest ai news?\" fmt . Printf ( \"\\nPrompt: %s\\nResponse: \" , prompt ) if err := callAgent ( context . Background (), agent , prompt ); err != nil { log . Fatalf ( \"Error calling agent: %v\" , err ) } fmt . Println ( \"\\n---\" ) } import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.LlmAgent ; import com.google.adk.runner.Runner ; import com.google.adk.sessions.InMemorySessionService ; import com.google.adk.sessions.Session ; import com.google.adk.tools.GoogleSearchTool ; import com.google.common.collect.ImmutableList ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; public class GoogleSearchAgentApp { private static final String APP_NAME = \"Google Search_agent\" ; private static final String USER_ID = \"user1234\" ; private static final String SESSION_ID = \"1234\" ; /** * Calls the agent with the given query and prints the final response. * * @param runner The runner to use. * @param query The query to send to the agent. */ public static void callAgent ( Runner runner , String query ) { Content content = Content . fromParts ( Part . fromText ( query )); InMemorySessionService sessionService = ( InMemorySessionService ) runner . sessionService (); Session session = sessionService . createSession ( APP_NAME , USER_ID , /* state= */ null , SESSION_ID ) . blockingGet (); runner . runAsync ( session . userId (), session . id (), content ) . forEach ( event -> { if ( event . finalResponse () && event . content (). isPresent () && event . content (). get (). parts (). isPresent () && ! event . content (). get (). parts (). get (). isEmpty () && event . content (). get (). parts (). get (). get ( 0 ). text (). isPresent ()) { String finalResponse = event . content (). get (). parts (). get (). get ( 0 ). text (). get (); System . out . println ( \"Agent Response: \" + finalResponse ); } }); } public static void main ( String [] args ) { // Google Search is a pre-built tool which allows the agent to perform Google searches. GoogleSearchTool googleSearchTool = new GoogleSearchTool (); BaseAgent rootAgent = LlmAgent . builder () . name ( \"basic_search_agent\" ) . model ( \"gemini-2.0-flash\" ) // Ensure to use a Gemini 2.0 model for Google Search Tool . description ( \"Agent to answer questions using Google Search.\" ) . instruction ( \"I can answer your questions by searching the internet. Just ask me anything!\" ) . tools ( ImmutableList . of ( googleSearchTool )) . build (); // Session and Runner InMemorySessionService sessionService = new InMemorySessionService (); Runner runner = new Runner ( rootAgent , APP_NAME , null , sessionService ); // Agent Interaction callAgent ( runner , \"what's the latest ai news?\" ); } } ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.agents import Agent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import google_search\nfrom google.genai import types\n\nAPP_NAME=\"google_search_agent\"\nUSER_ID=\"user1234\"\nSESSION_ID=\"1234\"\n\n\nroot_agent = Agent(\n    name=\"basic_search_agent\",\n    model=\"gemini-2.0-flash\",\n    description=\"Agent to answer questions using Google Search.\",\n    instruction=\"I can answer your questions by searching the internet. Just ask me anything!\",\n    # google_search is a pre-built tool which allows the agent to perform Google searches.\n    tools=[google_search]\n)\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n# Agent Interaction\nasync def call_agent_async(query):\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    async for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"Agent Response: \", final_response)\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"what's the latest ai news?\")"}, {"language": "text", "code": "// Copyright 2025 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/geminitool\"\n    \"google.golang.org/genai\"\n)\n\nfunc createSearchAgent(ctx context.Context) (agent.Agent, error) {\n    model, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{})\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create model: %v\", err)\n    }\n\n    return llmagent.New(llmagent.Config{\n        Name:        \"basic_search_agent\",\n        Model:       model,\n        Description: \"Agent to answer questions using Google Search.\",\n        Instruction: \"I can answer your questions by searching the web. Just ask me anything!\",\n        Tools:       []tool.Tool{geminitool.GoogleSearch{}},\n    })\n}\n\nconst (\n    userID  = \"user1234\"\n    appName = \"Google Search_agent\"\n)\n\nfunc callAgent(ctx context.Context, a agent.Agent, prompt string) error {\n    sessionService := session.InMemoryService()\n    session, err := sessionService.Create(ctx, &session.CreateRequest{\n        AppName: appName,\n        UserID:  userID,\n    })\n    if err != nil {\n        return fmt.Errorf(\"failed to create the session service: %v\", err)\n    }\n\n    config := runner.Config{\n        AppName:        appName,\n        Agent:          a,\n        SessionService: sessionService,\n    }\n    r, err := runner.New(config)\n    if err != nil {\n        return fmt.Errorf(\"failed to create the runner: %v\", err)\n    }\n\n    sessionID := session.Session.ID()\n    userMsg := &genai.Content{\n        Parts: []*genai.Part{{Text: prompt}},\n        Role:  string(genai.RoleUser),\n    }\n\n    // The r.Run method streams events and errors.\n    // The loop iterates over the results, handling them as they arrive.\n    for event, err := range r.Run(ctx, userID, sessionID, userMsg, agent.RunConfig{\n        StreamingMode: agent.StreamingModeSSE,\n    }) {\n        if err != nil {\n            fmt.Printf(\"\\nAGENT_ERROR: %v\\n\", err)\n        } else if event.Partial {\n            for _, p := range event.LLMResponse.Content.Parts {\n                fmt.Print(p.Text)\n            }\n        }\n    }\n    return nil\n}\n\nfunc main() {\n    agent, err := createSearchAgent(context.Background())\n    if err != nil {\n        log.Fatalf(\"Failed to create agent: %v\", err)\n    }\n    fmt.Println(\"Agent created:\", agent.Name())\n    prompt := \"what's the latest ai news?\"\n    fmt.Printf(\"\\nPrompt: %s\\nResponse: \", prompt)\n    if err := callAgent(context.Background(), agent, prompt); err != nil {\n        log.Fatalf(\"Error calling agent: %v\", err)\n    }\n    fmt.Println(\"\\n---\")\n}"}, {"language": "text", "code": "import com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.InMemorySessionService;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.GoogleSearchTool;\nimport com.google.common.collect.ImmutableList;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\n\npublic class GoogleSearchAgentApp {\n\n  private static final String APP_NAME = \"Google Search_agent\";\n  private static final String USER_ID = \"user1234\";\n  private static final String SESSION_ID = \"1234\";\n\n  /**\n   * Calls the agent with the given query and prints the final response.\n   *\n   * @param runner The runner to use.\n   * @param query The query to send to the agent.\n   */\n  public static void callAgent(Runner runner, String query) {\n    Content content =\n        Content.fromParts(Part.fromText(query));\n\n    InMemorySessionService sessionService = (InMemorySessionService) runner.sessionService();\n    Session session =\n        sessionService\n            .createSession(APP_NAME, USER_ID, /* state= */ null, SESSION_ID)\n            .blockingGet();\n\n    runner\n        .runAsync(session.userId(), session.id(), content)\n        .forEach(\n            event -> {\n              if (event.finalResponse()\n                  && event.content().isPresent()\n                  && event.content().get().parts().isPresent()\n                  && !event.content().get().parts().get().isEmpty()\n                  && event.content().get().parts().get().get(0).text().isPresent()) {\n                String finalResponse = event.content().get().parts().get().get(0).text().get();\n                System.out.println(\"Agent Response: \" + finalResponse);\n              }\n            });\n  }\n\n  public static void main(String[] args) {\n    // Google Search is a pre-built tool which allows the agent to perform Google searches.\n    GoogleSearchTool googleSearchTool = new GoogleSearchTool();\n\n    BaseAgent rootAgent =\n        LlmAgent.builder()\n            .name(\"basic_search_agent\")\n            .model(\"gemini-2.0-flash\") // Ensure to use a Gemini 2.0 model for Google Search Tool\n            .description(\"Agent to answer questions using Google Search.\")\n            .instruction(\n                \"I can answer your questions by searching the internet. Just ask me anything!\")\n            .tools(ImmutableList.of(googleSearchTool))\n            .build();\n\n    // Session and Runner\n    InMemorySessionService sessionService = new InMemorySessionService();\n    Runner runner = new Runner(rootAgent, APP_NAME, null, sessionService);\n\n    // Agent Interaction\n    callAgent(runner, \"what's the latest ai news?\");\n  }\n}"}]}, {"heading_path": ["Code Execution\u00b6"], "text": "Code Execution \u00b6 Supported in ADK Python v0.1.0 Java v0.2.0 The built_in_code_execution tool enables the agent to execute code,\nspecifically when using Gemini 2 models. This allows the model to perform tasks\nlike calculations, data manipulation, or running small scripts. Python Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import asyncio from google.adk.agents import LlmAgent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.code_executors import BuiltInCodeExecutor from google.genai import types AGENT_NAME = \"calculator_agent\" APP_NAME = \"calculator\" USER_ID = \"user1234\" SESSION_ID = \"session_code_exec_async\" GEMINI_MODEL = \"gemini-2.0-flash\" # Agent Definition code_agent = LlmAgent ( name = AGENT_NAME , model = GEMINI_MODEL , code_executor = BuiltInCodeExecutor (), instruction = \"\"\"You are a calculator agent. When given a mathematical expression, write and execute Python code to calculate the result. Return only the final numerical result as plain text, without markdown or code blocks. \"\"\" , description = \"Executes Python code to perform calculations.\" , ) # Session and Runner session_service = InMemorySessionService () session = asyncio . run ( session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID )) runner = Runner ( agent = code_agent , app_name = APP_NAME , session_service = session_service ) # Agent Interaction (Async) async def call_agent_async ( query ): content = types . Content ( role = \"user\" , parts = [ types . Part ( text = query )]) print ( f \" \\n --- Running Query: { query } ---\" ) final_response_text = \"No final text response captured.\" try : # Use run_async async for event in runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ): print ( f \"Event ID: { event . id } , Author: { event . author } \" ) # --- Check for specific parts FIRST --- has_specific_part = False if event . content and event . content . parts : for part in event . content . parts : # Iterate through all parts if part . executable_code : # Access the actual code string via .code print ( f \"  Debug: Agent generated code: \\n ```python \\n { part . executable_code . code } \\n ```\" ) has_specific_part = True elif part . code_execution_result : # Access outcome and output correctly print ( f \"  Debug: Code Execution Result: { part . code_execution_result . outcome } - Output: \\n { part . code_execution_result . output } \" ) has_specific_part = True # Also print any text parts found in any event for debugging elif part . text and not part . text . isspace (): print ( f \"  Text: ' { part . text . strip () } '\" ) # Do not set has_specific_part=True here, as we want the final response logic below # --- Check for final response AFTER specific parts --- # Only consider it final if it doesn't have the specific code parts we just handled if not has_specific_part and event . is_final_response (): if ( event . content and event . content . parts and event . content . parts [ 0 ] . text ): final_response_text = event . content . parts [ 0 ] . text . strip () print ( f \"==> Final Agent Response: { final_response_text } \" ) else : print ( \"==> Final Agent Response: [No text content in final event]\" ) except Exception as e : print ( f \"ERROR during agent run: { e } \" ) print ( \"-\" * 30 ) # Main async function to run the examples async def main (): await call_agent_async ( \"Calculate the value of (5 + 7) * 3\" ) await call_agent_async ( \"What is 10 factorial?\" ) # Execute the main async function try : asyncio . run ( main ()) except RuntimeError as e : # Handle specific error when running asyncio.run in an already running loop (like Jupyter/Colab) if \"cannot be called from a running event loop\" in str ( e ): print ( \" \\n Running in an existing event loop (like Colab/Jupyter).\" ) print ( \"Please run `await main()` in a notebook cell instead.\" ) # If in an interactive environment like a notebook, you might need to run: # await main() else : raise e # Re-raise other runtime errors import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.LlmAgent ; import com.google.adk.runner.Runner ; import com.google.adk.sessions.InMemorySessionService ; import com.google.adk.sessions.Session ; import com.google.adk.tools.BuiltInCodeExecutionTool ; import com.google.common.collect.ImmutableList ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; public class CodeExecutionAgentApp { private static final String AGENT_NAME = \"calculator_agent\" ; private static final String APP_NAME = \"calculator\" ; private static final String USER_ID = \"user1234\" ; private static final String SESSION_ID = \"session_code_exec_sync\" ; private static final String GEMINI_MODEL = \"gemini-2.0-flash\" ; /** * Calls the agent with a query and prints the interaction events and final response. * * @param runner The runner instance for the agent. * @param query The query to send to the agent. */ public static void callAgent ( Runner runner , String query ) { Content content = Content . builder (). role ( \"user\" ). parts ( ImmutableList . of ( Part . fromText ( query ))). build (); InMemorySessionService sessionService = ( InMemorySessionService ) runner . sessionService (); Session session = sessionService . createSession ( APP_NAME , USER_ID , /* state= */ null , SESSION_ID ) . blockingGet (); System . out . println ( \"\\n--- Running Query: \" + query + \" ---\" ); final String [] finalResponseText = { \"No final text response captured.\" }; try { runner . runAsync ( session . userId (), session . id (), content ) . forEach ( event -> { System . out . println ( \"Event ID: \" + event . id () + \", Author: \" + event . author ()); boolean hasSpecificPart = false ; if ( event . content (). isPresent () && event . content (). get (). parts (). isPresent ()) { for ( Part part : event . content (). get (). parts (). get ()) { if ( part . executableCode (). isPresent ()) { System . out . println ( \"  Debug: Agent generated code:\\n```python\\n\" + part . executableCode (). get (). code () + \"\\n```\" ); hasSpecificPart = true ; } else if ( part . codeExecutionResult (). isPresent ()) { System . out . println ( \"  Debug: Code Execution Result: \" + part . codeExecutionResult (). get (). outcome () + \" - Output:\\n\" + part . codeExecutionResult (). get (). output ()); hasSpecificPart = true ; } else if ( part . text (). isPresent () && ! part . text (). get (). trim (). isEmpty ()) { System . out . println ( \"  Text: '\" + part . text (). get (). trim () + \"'\" ); } } } if ( ! hasSpecificPart && event . finalResponse ()) { if ( event . content (). isPresent () && event . content (). get (). parts (). isPresent () && ! event . content (). get (). parts (). get (). isEmpty () && event . content (). get (). parts (). get (). get ( 0 ). text (). isPresent ()) { finalResponseText [ 0 ] = event . content (). get (). parts (). get (). get ( 0 ). text (). get (). trim (); System . out . println ( \"==> Final Agent Response: \" + finalResponseText [ 0 ] ); } else { System . out . println ( \"==> Final Agent Response: [No text content in final event]\" ); } } }); } catch ( Exception e ) { System . err . println ( \"ERROR during agent run: \" + e . getMessage ()); e . printStackTrace (); } System . out . println ( \"------------------------------\" ); } public static void main ( String [] args ) { BuiltInCodeExecutionTool codeExecutionTool = new BuiltInCodeExecutionTool (); BaseAgent codeAgent = LlmAgent . builder () . name ( AGENT_NAME ) . model ( GEMINI_MODEL ) . tools ( ImmutableList . of ( codeExecutionTool )) . instruction ( \"\"\" You are a calculator agent. When given a mathematical expression, write and execute Python code to calculate the result. Return only the final numerical result as plain text, without markdown or code blocks. \"\"\" ) . description ( \"Executes Python code to perform calculations.\" ) . build (); InMemorySessionService sessionService = new InMemorySessionService (); Runner runner = new Runner ( codeAgent , APP_NAME , null , sessionService ); callAgent ( runner , \"Calculate the value of (5 + 7) * 3\" ); callAgent ( runner , \"What is 10 factorial?\" ); } } ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\nfrom google.adk.agents import LlmAgent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.code_executors import BuiltInCodeExecutor\nfrom google.genai import types\n\nAGENT_NAME = \"calculator_agent\"\nAPP_NAME = \"calculator\"\nUSER_ID = \"user1234\"\nSESSION_ID = \"session_code_exec_async\"\nGEMINI_MODEL = \"gemini-2.0-flash\"\n\n# Agent Definition\ncode_agent = LlmAgent(\n    name=AGENT_NAME,\n    model=GEMINI_MODEL,\n    code_executor=BuiltInCodeExecutor(),\n    instruction=\"\"\"You are a calculator agent.\n    When given a mathematical expression, write and execute Python code to calculate the result.\n    Return only the final numerical result as plain text, without markdown or code blocks.\n    \"\"\",\n    description=\"Executes Python code to perform calculations.\",\n)\n\n# Session and Runner\nsession_service = InMemorySessionService()\nsession = asyncio.run(session_service.create_session(\n    app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n))\nrunner = Runner(agent=code_agent, app_name=APP_NAME,\n                session_service=session_service)\n\n# Agent Interaction (Async)\nasync def call_agent_async(query):\n    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n    print(f\"\\n--- Running Query: {query} ---\")\n    final_response_text = \"No final text response captured.\"\n    try:\n        # Use run_async\n        async for event in runner.run_async(\n            user_id=USER_ID, session_id=SESSION_ID, new_message=content\n        ):\n            print(f\"Event ID: {event.id}, Author: {event.author}\")\n\n            # --- Check for specific parts FIRST ---\n            has_specific_part = False\n            if event.content and event.content.parts:\n                for part in event.content.parts:  # Iterate through all parts\n                    if part.executable_code:\n                        # Access the actual code string via .code\n                        print(\n                            f\"  Debug: Agent generated code:\\n```python\\n{part.executable_code.code}\\n```\"\n                        )\n                        has_specific_part = True\n                    elif part.code_execution_result:\n                        # Access outcome and output correctly\n                        print(\n                            f\"  Debug: Code Execution Result: {part.code_execution_result.outcome} - Output:\\n{part.code_execution_result.output}\"\n                        )\n                        has_specific_part = True\n                    # Also print any text parts found in any event for debugging\n                    elif part.text and not part.text.isspace():\n                        print(f\"  Text: '{part.text.strip()}'\")\n                        # Do not set has_specific_part=True here, as we want the final response logic below\n\n            # --- Check for final response AFTER specific parts ---\n            # Only consider it final if it doesn't have the specific code parts we just handled\n            if not has_specific_part and event.is_final_response():\n                if (\n                    event.content\n                    and event.content.parts\n                    and event.content.parts[0].text\n                ):\n                    final_response_text = event.content.parts[0].text.strip()\n                    print(f\"==> Final Agent Response: {final_response_text}\")\n                else:\n                    print(\n                        \"==> Final Agent Response: [No text content in final event]\")\n\n    except Exception as e:\n        print(f\"ERROR during agent run: {e}\")\n    print(\"-\" * 30)\n\n\n# Main async function to run the examples\nasync def main():\n    await call_agent_async(\"Calculate the value of (5 + 7) * 3\")\n    await call_agent_async(\"What is 10 factorial?\")\n\n\n# Execute the main async function\ntry:\n    asyncio.run(main())\nexcept RuntimeError as e:\n    # Handle specific error when running asyncio.run in an already running loop (like Jupyter/Colab)\n    if \"cannot be called from a running event loop\" in str(e):\n        print(\"\\nRunning in an existing event loop (like Colab/Jupyter).\")\n        print(\"Please run `await main()` in a notebook cell instead.\")\n        # If in an interactive environment like a notebook, you might need to run:\n        # await main()\n    else:\n        raise e  # Re-raise other runtime errors"}, {"language": "text", "code": "import com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.InMemorySessionService;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.BuiltInCodeExecutionTool;\nimport com.google.common.collect.ImmutableList;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\n\npublic class CodeExecutionAgentApp {\n\n  private static final String AGENT_NAME = \"calculator_agent\";\n  private static final String APP_NAME = \"calculator\";\n  private static final String USER_ID = \"user1234\";\n  private static final String SESSION_ID = \"session_code_exec_sync\";\n  private static final String GEMINI_MODEL = \"gemini-2.0-flash\";\n\n  /**\n   * Calls the agent with a query and prints the interaction events and final response.\n   *\n   * @param runner The runner instance for the agent.\n   * @param query The query to send to the agent.\n   */\n  public static void callAgent(Runner runner, String query) {\n    Content content =\n        Content.builder().role(\"user\").parts(ImmutableList.of(Part.fromText(query))).build();\n\n    InMemorySessionService sessionService = (InMemorySessionService) runner.sessionService();\n    Session session =\n        sessionService\n            .createSession(APP_NAME, USER_ID, /* state= */ null, SESSION_ID)\n            .blockingGet();\n\n    System.out.println(\"\\n--- Running Query: \" + query + \" ---\");\n    final String[] finalResponseText = {\"No final text response captured.\"};\n\n    try {\n      runner\n          .runAsync(session.userId(), session.id(), content)\n          .forEach(\n              event -> {\n                System.out.println(\"Event ID: \" + event.id() + \", Author: \" + event.author());\n\n                boolean hasSpecificPart = false;\n                if (event.content().isPresent() && event.content().get().parts().isPresent()) {\n                  for (Part part : event.content().get().parts().get()) {\n                    if (part.executableCode().isPresent()) {\n                      System.out.println(\n                          \"  Debug: Agent generated code:\\n```python\\n\"\n                              + part.executableCode().get().code()\n                              + \"\\n```\");\n                      hasSpecificPart = true;\n                    } else if (part.codeExecutionResult().isPresent()) {\n                      System.out.println(\n                          \"  Debug: Code Execution Result: \"\n                              + part.codeExecutionResult().get().outcome()\n                              + \" - Output:\\n\"\n                              + part.codeExecutionResult().get().output());\n                      hasSpecificPart = true;\n                    } else if (part.text().isPresent() && !part.text().get().trim().isEmpty()) {\n                      System.out.println(\"  Text: '\" + part.text().get().trim() + \"'\");\n                    }\n                  }\n                }\n\n                if (!hasSpecificPart && event.finalResponse()) {\n                  if (event.content().isPresent()\n                      && event.content().get().parts().isPresent()\n                      && !event.content().get().parts().get().isEmpty()\n                      && event.content().get().parts().get().get(0).text().isPresent()) {\n                    finalResponseText[0] =\n                        event.content().get().parts().get().get(0).text().get().trim();\n                    System.out.println(\"==> Final Agent Response: \" + finalResponseText[0]);\n                  } else {\n                    System.out.println(\n                        \"==> Final Agent Response: [No text content in final event]\");\n                  }\n                }\n              });\n    } catch (Exception e) {\n      System.err.println(\"ERROR during agent run: \" + e.getMessage());\n      e.printStackTrace();\n    }\n    System.out.println(\"------------------------------\");\n  }\n\n  public static void main(String[] args) {\n    BuiltInCodeExecutionTool codeExecutionTool = new BuiltInCodeExecutionTool();\n\n    BaseAgent codeAgent =\n        LlmAgent.builder()\n            .name(AGENT_NAME)\n            .model(GEMINI_MODEL)\n            .tools(ImmutableList.of(codeExecutionTool))\n            .instruction(\n                \"\"\"\n                                You are a calculator agent.\n                                When given a mathematical expression, write and execute Python code to calculate the result.\n                                Return only the final numerical result as plain text, without markdown or code blocks.\n                                \"\"\")\n            .description(\"Executes Python code to perform calculations.\")\n            .build();\n\n    InMemorySessionService sessionService = new InMemorySessionService();\n    Runner runner = new Runner(codeAgent, APP_NAME, null, sessionService);\n\n    callAgent(runner, \"Calculate the value of (5 + 7) * 3\");\n    callAgent(runner, \"What is 10 factorial?\");\n  }\n}"}]}, {"heading_path": ["GKE Code Executor\u00b6"], "text": "GKE Code Executor \u00b6 Supported in ADK Python v1.14.0 The GKE Code Executor ( GkeCodeExecutor ) provides a secure and scalable method\nfor running LLM-generated code by leveraging the GKE (Google Kubernetes Engine)\nSandbox environment, which uses gVisor for workload isolation. For each code\nexecution request, it dynamically creates an ephemeral, sandboxed Kubernetes Job\nwith a hardened Pod configuration. You should use this executor for production\nenvironments on GKE where security and isolation are critical. ", "code_blocks": []}, {"heading_path": ["How it Works\u00b6"], "text": "How it Works \u00b6 When a request to execute code is made, the GkeCodeExecutor performs the following steps: Creates a ConfigMap: A Kubernetes ConfigMap is created to store the Python code that needs to be executed. Creates a Sandboxed Pod: A new Kubernetes Job is created, which in turn creates a Pod with a hardened security context and the gVisor runtime enabled. The code from the ConfigMap is mounted into this Pod. Executes the Code: The code is executed within the sandboxed Pod, isolated from the underlying node and other workloads. Retrieves the Result: The standard output and error streams from the execution are captured from the Pod's logs. Cleans Up Resources: Once the execution is complete, the Job and the associated ConfigMap are automatically deleted, ensuring that no artifacts are left behind. ", "code_blocks": []}, {"heading_path": ["Key Benefits\u00b6"], "text": "Key Benefits \u00b6 Enhanced Security: Code is executed in a gVisor-sandboxed environment with kernel-level isolation. Ephemeral Environments: Each code execution runs in its own ephemeral Pod, to prevent state transfer between executions. Resource Control: You can configure CPU and memory limits for the execution Pods to prevent resource abuse. Scalability: Allows you to run a large number of code executions in parallel, with GKE handling the scheduling and scaling of the underlying nodes. ", "code_blocks": []}, {"heading_path": ["System requirements\u00b6"], "text": "System requirements \u00b6 The following requirements must be met to successfully deploy your ADK project\nwith the GKE Code Executor tool: GKE cluster with a gVisor-enabled node pool . Agent's service account requires specific RBAC permissions , which allow it to: Create, watch, and delete Jobs for each execution request. Manage ConfigMaps to inject code into the Job's pod. List Pods and read their logs to retrieve the execution result Install the client library with GKE extras: pip install google-adk[gke] For a complete, ready-to-use configuration, see the deployment_rbac.yaml sample. For more information on deploying ADK workflows to GKE, see Deploy to Google Kubernetes Engine (GKE) . Python from google.adk.agents import LlmAgent from google.adk.code_executors import GkeCodeExecutor # Initialize the executor, targeting the namespace where its ServiceAccount # has the required RBAC permissions. # This example also sets a custom timeout and resource limits. gke_executor = GkeCodeExecutor ( namespace = \"agent-sandbox\" , timeout_seconds = 600 , cpu_limit = \"1000m\" , # 1 CPU core mem_limit = \"1Gi\" , ) # The agent now uses this executor for any code it generates. gke_agent = LlmAgent ( name = \"gke_coding_agent\" , model = \"gemini-2.0-flash\" , instruction = \"You are a helpful AI agent that writes and executes Python code.\" , code_executor = gke_executor , ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import LlmAgent\nfrom google.adk.code_executors import GkeCodeExecutor\n\n# Initialize the executor, targeting the namespace where its ServiceAccount\n# has the required RBAC permissions.\n# This example also sets a custom timeout and resource limits.\ngke_executor = GkeCodeExecutor(\n    namespace=\"agent-sandbox\",\n    timeout_seconds=600,\n    cpu_limit=\"1000m\",  # 1 CPU core\n    mem_limit=\"1Gi\",\n)\n\n# The agent now uses this executor for any code it generates.\ngke_agent = LlmAgent(\n    name=\"gke_coding_agent\",\n    model=\"gemini-2.0-flash\",\n    instruction=\"You are a helpful AI agent that writes and executes Python code.\",\n    code_executor=gke_executor,\n)"}]}, {"heading_path": ["Configuration parameters\u00b6"], "text": "Configuration parameters \u00b6 The GkeCodeExecutor can be configured with the following parameters: Parameter Type Description namespace str Kubernetes namespace where the execution Jobs will be created. Defaults to \"default\" . image str Container image to use for the execution Pod. Defaults to \"python:3.11-slim\" . timeout_seconds int Timeout in seconds for the code execution. Defaults to 300 . cpu_requested str Amount of CPU to request for the execution Pod. Defaults to \"200m\" . mem_requested str Amount of memory to request for the execution Pod. Defaults to \"256Mi\" . cpu_limit str Maximum amount of CPU the execution Pod can use. Defaults to \"500m\" . mem_limit str Maximum amount of memory the execution Pod can use. Defaults to \"512Mi\" . kubeconfig_path str Path to a kubeconfig file to use for authentication. Falls back to in-cluster config or the default local kubeconfig. kubeconfig_context str The kubeconfig context to use. ", "code_blocks": []}, {"heading_path": ["Vertex AI RAG Engine\u00b6"], "text": "Vertex AI RAG Engine \u00b6 Supported in ADK Python v0.1.0 Java v0.2.0 The vertex_ai_rag_retrieval tool allows the agent to perform private data retrieval using Vertex\nAI RAG Engine. When you use grounding with Vertex AI RAG Engine, you need to prepare a RAG corpus before hand.\nPlease refer to the RAG ADK agent sample or Vertex AI RAG Engine page for setting it up. Python # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import os from google.adk.agents import Agent from google.adk.tools.retrieval.vertex_ai_rag_retrieval import VertexAiRagRetrieval from vertexai.preview import rag from dotenv import load_dotenv from .prompts import return_instructions_root load_dotenv () ask_vertex_retrieval = VertexAiRagRetrieval ( name = 'retrieve_rag_documentation' , description = ( 'Use this tool to retrieve documentation and reference materials for the question from the RAG corpus,' ), rag_resources = [ rag . RagResource ( # please fill in your own rag corpus # here is a sample rag corpus for testing purpose # e.g. projects/123/locations/us-central1/ragCorpora/456 rag_corpus = os . environ . get ( \"RAG_CORPUS\" ) ) ], similarity_top_k = 10 , vector_distance_threshold = 0.6 , ) root_agent = Agent ( model = 'gemini-2.0-flash-001' , name = 'ask_rag_agent' , instruction = return_instructions_root (), tools = [ ask_vertex_retrieval , ] ) ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\n\nfrom google.adk.agents import Agent\nfrom google.adk.tools.retrieval.vertex_ai_rag_retrieval import VertexAiRagRetrieval\nfrom vertexai.preview import rag\n\nfrom dotenv import load_dotenv\nfrom .prompts import return_instructions_root\n\nload_dotenv()\n\nask_vertex_retrieval = VertexAiRagRetrieval(\n    name='retrieve_rag_documentation',\n    description=(\n        'Use this tool to retrieve documentation and reference materials for the question from the RAG corpus,'\n    ),\n    rag_resources=[\n        rag.RagResource(\n            # please fill in your own rag corpus\n            # here is a sample rag corpus for testing purpose\n            # e.g. projects/123/locations/us-central1/ragCorpora/456\n            rag_corpus=os.environ.get(\"RAG_CORPUS\")\n        )\n    ],\n    similarity_top_k=10,\n    vector_distance_threshold=0.6,\n)\n\nroot_agent = Agent(\n    model='gemini-2.0-flash-001',\n    name='ask_rag_agent',\n    instruction=return_instructions_root(),\n    tools=[\n        ask_vertex_retrieval,\n    ]\n)"}]}, {"heading_path": ["Vertex AI Search\u00b6"], "text": "Vertex AI Search \u00b6 Supported in ADK Python v0.1.0 The vertex_ai_search_tool uses Google Cloud Vertex AI Search, enabling the\nagent to search across your private, configured data stores (e.g., internal\ndocuments, company policies, knowledge bases). This built-in tool requires you\nto provide the specific data store ID during configuration. For further details of the tool, see Understanding Vertex AI Search grounding . # Copyright 2024 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import asyncio from google.adk.agents import LlmAgent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.genai import types from google.adk.tools import VertexAiSearchTool # Replace with your Vertex AI Search Datastore ID, and respective region (e.g. us-central1 or global). # Format: projects/<PROJECT_ID>/locations/<REGION>/collections/default_collection/dataStores/<DATASTORE_ID> DATASTORE_PATH = \"DATASTORE_PATH_HERE\" # Constants APP_NAME_VSEARCH = \"vertex_search_app\" USER_ID_VSEARCH = \"user_vsearch_1\" SESSION_ID_VSEARCH = \"session_vsearch_1\" AGENT_NAME_VSEARCH = \"doc_qa_agent\" GEMINI_2_FLASH = \"gemini-2.0-flash\" # Tool Instantiation # You MUST provide your datastore ID here. vertex_search_tool = VertexAiSearchTool ( data_store_id = DATASTORE_PATH ) # Agent Definition doc_qa_agent = LlmAgent ( name = AGENT_NAME_VSEARCH , model = GEMINI_2_FLASH , # Requires Gemini model tools = [ vertex_search_tool ], instruction = f \"\"\"You are a helpful assistant that answers questions based on information found in the document store: { DATASTORE_PATH } . Use the search tool to find relevant information before answering. If the answer isn't in the documents, say that you couldn't find the information. \"\"\" , description = \"Answers questions using a specific Vertex AI Search datastore.\" , ) # Session and Runner Setup session_service_vsearch = InMemorySessionService () runner_vsearch = Runner ( agent = doc_qa_agent , app_name = APP_NAME_VSEARCH , session_service = session_service_vsearch ) session_vsearch = session_service_vsearch . create_session ( app_name = APP_NAME_VSEARCH , user_id = USER_ID_VSEARCH , session_id = SESSION_ID_VSEARCH ) # Agent Interaction Function async def call_vsearch_agent_async ( query ): print ( \" \\n --- Running Vertex AI Search Agent ---\" ) print ( f \"Query: { query } \" ) if \"DATASTORE_PATH_HERE\" in DATASTORE_PATH : print ( \"Skipping execution: Please replace DATASTORE_PATH_HERE with your actual datastore ID.\" ) print ( \"-\" * 30 ) return content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) final_response_text = \"No response received.\" try : async for event in runner_vsearch . run_async ( user_id = USER_ID_VSEARCH , session_id = SESSION_ID_VSEARCH , new_message = content ): # Like Google Search, results are often embedded in the model's response. if event . is_final_response () and event . content and event . content . parts : final_response_text = event . content . parts [ 0 ] . text . strip () print ( f \"Agent Response: { final_response_text } \" ) # You can inspect event.grounding_metadata for source citations if event . grounding_metadata : print ( f \"  (Grounding metadata found with { len ( event . grounding_metadata . grounding_attributions ) } attributions)\" ) except Exception as e : print ( f \"An error occurred: { e } \" ) print ( \"Ensure your datastore ID is correct and the service account has permissions.\" ) print ( \"-\" * 30 ) # --- Run Example --- async def run_vsearch_example (): # Replace with a question relevant to YOUR datastore content await call_vsearch_agent_async ( \"Summarize the main points about the Q2 strategy document.\" ) await call_vsearch_agent_async ( \"What safety procedures are mentioned for lab X?\" ) # Execute the example # await run_vsearch_example() # Running locally due to potential colab asyncio issues with multiple awaits try : asyncio . run ( run_vsearch_example ()) except RuntimeError as e : if \"cannot be called from a running event loop\" in str ( e ): print ( \"Skipping execution in running event loop (like Colab/Jupyter). Run locally.\" ) else : raise e ", "code_blocks": [{"language": "text", "code": "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\nfrom google.adk.tools import VertexAiSearchTool\n\n# Replace with your Vertex AI Search Datastore ID, and respective region (e.g. us-central1 or global).\n# Format: projects/<PROJECT_ID>/locations/<REGION>/collections/default_collection/dataStores/<DATASTORE_ID>\nDATASTORE_PATH = \"DATASTORE_PATH_HERE\"\n\n# Constants\nAPP_NAME_VSEARCH = \"vertex_search_app\"\nUSER_ID_VSEARCH = \"user_vsearch_1\"\nSESSION_ID_VSEARCH = \"session_vsearch_1\"\nAGENT_NAME_VSEARCH = \"doc_qa_agent\"\nGEMINI_2_FLASH = \"gemini-2.0-flash\"\n\n# Tool Instantiation\n# You MUST provide your datastore ID here.\nvertex_search_tool = VertexAiSearchTool(data_store_id=DATASTORE_PATH)\n\n# Agent Definition\ndoc_qa_agent = LlmAgent(\n    name=AGENT_NAME_VSEARCH,\n    model=GEMINI_2_FLASH, # Requires Gemini model\n    tools=[vertex_search_tool],\n    instruction=f\"\"\"You are a helpful assistant that answers questions based on information found in the document store: {DATASTORE_PATH}.\n    Use the search tool to find relevant information before answering.\n    If the answer isn't in the documents, say that you couldn't find the information.\n    \"\"\",\n    description=\"Answers questions using a specific Vertex AI Search datastore.\",\n)\n\n# Session and Runner Setup\nsession_service_vsearch = InMemorySessionService()\nrunner_vsearch = Runner(\n    agent=doc_qa_agent, app_name=APP_NAME_VSEARCH, session_service=session_service_vsearch\n)\nsession_vsearch = session_service_vsearch.create_session(\n    app_name=APP_NAME_VSEARCH, user_id=USER_ID_VSEARCH, session_id=SESSION_ID_VSEARCH\n)\n\n# Agent Interaction Function\nasync def call_vsearch_agent_async(query):\n    print(\"\\n--- Running Vertex AI Search Agent ---\")\n    print(f\"Query: {query}\")\n    if \"DATASTORE_PATH_HERE\" in DATASTORE_PATH:\n        print(\"Skipping execution: Please replace DATASTORE_PATH_HERE with your actual datastore ID.\")\n        print(\"-\" * 30)\n        return\n\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    final_response_text = \"No response received.\"\n    try:\n        async for event in runner_vsearch.run_async(\n            user_id=USER_ID_VSEARCH, session_id=SESSION_ID_VSEARCH, new_message=content\n        ):\n            # Like Google Search, results are often embedded in the model's response.\n            if event.is_final_response() and event.content and event.content.parts:\n                final_response_text = event.content.parts[0].text.strip()\n                print(f\"Agent Response: {final_response_text}\")\n                # You can inspect event.grounding_metadata for source citations\n                if event.grounding_metadata:\n                    print(f\"  (Grounding metadata found with {len(event.grounding_metadata.grounding_attributions)} attributions)\")\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        print(\"Ensure your datastore ID is correct and the service account has permissions.\")\n    print(\"-\" * 30)\n\n# --- Run Example ---\nasync def run_vsearch_example():\n    # Replace with a question relevant to YOUR datastore content\n    await call_vsearch_agent_async(\"Summarize the main points about the Q2 strategy document.\")\n    await call_vsearch_agent_async(\"What safety procedures are mentioned for lab X?\")\n\n# Execute the example\n# await run_vsearch_example()\n\n# Running locally due to potential colab asyncio issues with multiple awaits\ntry:\n    asyncio.run(run_vsearch_example())\nexcept RuntimeError as e:\n    if \"cannot be called from a running event loop\" in str(e):\n        print(\"Skipping execution in running event loop (like Colab/Jupyter). Run locally.\")\n    else:\n        raise e"}]}, {"heading_path": ["BigQuery\u00b6"], "text": "BigQuery \u00b6 Supported in ADK Python v1.1.0 These are a set of tools aimed to provide integration with BigQuery, namely: list_dataset_ids : Fetches BigQuery dataset ids present in a GCP project. get_dataset_info : Fetches metadata about a BigQuery dataset. list_table_ids : Fetches table ids present in a BigQuery dataset. get_table_info : Fetches metadata about a BigQuery table. execute_sql : Runs a SQL query in BigQuery and fetch the result. forecast : Runs a BigQuery AI time series forecast using the AI.FORECAST function. ask_data_insights : Answers questions about data in BigQuery tables using natural language. They are packaged in the toolset BigQueryToolset . # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import asyncio from google.adk.agents import Agent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.tools.bigquery import BigQueryCredentialsConfig from google.adk.tools.bigquery import BigQueryToolset from google.adk.tools.bigquery.config import BigQueryToolConfig from google.adk.tools.bigquery.config import WriteMode from google.genai import types import google.auth # Define constants for this example agent AGENT_NAME = \"bigquery_agent\" APP_NAME = \"bigquery_app\" USER_ID = \"user1234\" SESSION_ID = \"1234\" GEMINI_MODEL = \"gemini-2.0-flash\" # Define a tool configuration to block any write operations tool_config = BigQueryToolConfig ( write_mode = WriteMode . BLOCKED ) # Uses externally-managed Application Default Credentials (ADC) by default. # This decouples authentication from the agent / tool lifecycle. # https://cloud.google.com/docs/authentication/provide-credentials-adc credentials_config = BigQueryCredentialsConfig () # Instantiate a BigQuery toolset bigquery_toolset = BigQueryToolset ( credentials_config = credentials_config , bigquery_tool_config = tool_config ) # Agent Definition bigquery_agent = Agent ( model = GEMINI_MODEL , name = AGENT_NAME , description = ( \"Agent to answer questions about BigQuery data and models and execute\" \" SQL queries.\" ), instruction = \"\"\" \\ You are a data science agent with access to several BigQuery tools. Make use of those tools to answer the user's questions. \"\"\" , tools = [ bigquery_toolset ], ) # Session and Runner session_service = InMemorySessionService () session = asyncio . run ( session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) ) runner = Runner ( agent = bigquery_agent , app_name = APP_NAME , session_service = session_service ) # Agent Interaction def call_agent ( query ): \"\"\" Helper function to call the agent with a query. \"\"\" content = types . Content ( role = \"user\" , parts = [ types . Part ( text = query )]) events = runner . run ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) print ( \"USER:\" , query ) for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"AGENT:\" , final_response ) call_agent ( \"Are there any ml datasets in bigquery-public-data project?\" ) call_agent ( \"Tell me more about ml_datasets.\" ) call_agent ( \"Which all tables does it have?\" ) call_agent ( \"Tell me more about the census_adult_income table.\" ) call_agent ( \"How many rows are there per income bracket?\" ) call_agent ( \"What is the statistical correlation between education_num, age, and the income_bracket?\" ) ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\n\nfrom google.adk.agents import Agent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools.bigquery import BigQueryCredentialsConfig\nfrom google.adk.tools.bigquery import BigQueryToolset\nfrom google.adk.tools.bigquery.config import BigQueryToolConfig\nfrom google.adk.tools.bigquery.config import WriteMode\nfrom google.genai import types\nimport google.auth\n\n# Define constants for this example agent\nAGENT_NAME = \"bigquery_agent\"\nAPP_NAME = \"bigquery_app\"\nUSER_ID = \"user1234\"\nSESSION_ID = \"1234\"\nGEMINI_MODEL = \"gemini-2.0-flash\"\n\n# Define a tool configuration to block any write operations\ntool_config = BigQueryToolConfig(write_mode=WriteMode.BLOCKED)\n\n# Uses externally-managed Application Default Credentials (ADC) by default.\n# This decouples authentication from the agent / tool lifecycle.\n# https://cloud.google.com/docs/authentication/provide-credentials-adc\ncredentials_config = BigQueryCredentialsConfig()\n\n# Instantiate a BigQuery toolset\nbigquery_toolset = BigQueryToolset(\n    credentials_config=credentials_config, bigquery_tool_config=tool_config\n)\n\n# Agent Definition\nbigquery_agent = Agent(\n    model=GEMINI_MODEL,\n    name=AGENT_NAME,\n    description=(\n        \"Agent to answer questions about BigQuery data and models and execute\"\n        \" SQL queries.\"\n    ),\n    instruction=\"\"\"\\\n        You are a data science agent with access to several BigQuery tools.\n        Make use of those tools to answer the user's questions.\n    \"\"\",\n    tools=[bigquery_toolset],\n)\n\n# Session and Runner\nsession_service = InMemorySessionService()\nsession = asyncio.run(\n    session_service.create_session(\n        app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n    )\n)\nrunner = Runner(\n    agent=bigquery_agent, app_name=APP_NAME, session_service=session_service\n)\n\n\n# Agent Interaction\ndef call_agent(query):\n    \"\"\"\n    Helper function to call the agent with a query.\n    \"\"\"\n    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    print(\"USER:\", query)\n    for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"AGENT:\", final_response)\n\n\ncall_agent(\"Are there any ml datasets in bigquery-public-data project?\")\ncall_agent(\"Tell me more about ml_datasets.\")\ncall_agent(\"Which all tables does it have?\")\ncall_agent(\"Tell me more about the census_adult_income table.\")\ncall_agent(\"How many rows are there per income bracket?\")\ncall_agent(\n    \"What is the statistical correlation between education_num, age, and the income_bracket?\"\n)"}]}, {"heading_path": ["Spanner\u00b6"], "text": "Spanner \u00b6 Supported in ADK Python v1.11.0 These are a set of tools aimed to provide integration with Spanner, namely: list_table_names : Fetches table names present in a GCP Spanner database. list_table_indexes : Fetches table indexes present in a GCP Spanner database. list_table_index_columns : Fetches table index columns present in a GCP Spanner database. list_named_schemas : Fetches named schema for a Spanner database. get_table_schema : Fetches Spanner database table schema and metadata information. execute_sql : Runs a SQL query in Spanner database and fetch the result. similarity_search : Similarity search in Spanner using a text query. They are packaged in the toolset SpannerToolset . # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import asyncio from google.adk.agents import Agent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService # from google.adk.sessions import DatabaseSessionService from google.adk.tools.google_tool import GoogleTool from google.adk.tools.spanner import query_tool from google.adk.tools.spanner.settings import SpannerToolSettings from google.adk.tools.spanner.settings import Capabilities from google.adk.tools.spanner.spanner_credentials import SpannerCredentialsConfig from google.adk.tools.spanner.spanner_toolset import SpannerToolset from google.genai import types from google.adk.tools.tool_context import ToolContext import google.auth from google.auth.credentials import Credentials # Define constants for this example agent AGENT_NAME = \"spanner_agent\" APP_NAME = \"spanner_app\" USER_ID = \"user1234\" SESSION_ID = \"1234\" GEMINI_MODEL = \"gemini-2.5-flash\" # Define Spanner tool config with read capability set to allowed. tool_settings = SpannerToolSettings ( capabilities = [ Capabilities . DATA_READ ]) # Define a credentials config - in this example we are using application default # credentials # https://cloud.google.com/docs/authentication/provide-credentials-adc application_default_credentials , _ = google . auth . default () credentials_config = SpannerCredentialsConfig ( credentials = application_default_credentials ) # Instantiate a Spanner toolset spanner_toolset = SpannerToolset ( credentials_config = credentials_config , spanner_tool_settings = tool_settings ) # Optional # Create a wrapped function tool for the agent on top of the built-in # `execute_sql` tool in the Spanner toolset. # For example, this customized tool can perform a dynamically-built query. def count_rows_tool ( table_name : str , credentials : Credentials , # GoogleTool handles `credentials` settings : SpannerToolSettings , # GoogleTool handles `settings` tool_context : ToolContext , # GoogleTool handles `tool_context` ): \"\"\"Counts the total number of rows for a specified table. Args: table_name: The name of the table for which to count rows. Returns: The total number of rows in the table. \"\"\" # Replace the following settings for a specific Spanner database. PROJECT_ID = \"<PROJECT_ID>\" INSTANCE_ID = \"<INSTANCE_ID>\" DATABASE_ID = \"<DATABASE_ID>\" query = f \"\"\" SELECT count(*) FROM { table_name } \"\"\" return query_tool . execute_sql ( project_id = PROJECT_ID , instance_id = INSTANCE_ID , database_id = DATABASE_ID , query = query , credentials = credentials , settings = settings , tool_context = tool_context , ) # Agent Definition spanner_agent = Agent ( model = GEMINI_MODEL , name = AGENT_NAME , description = ( \"Agent to answer questions about Spanner database and execute SQL queries.\" ), instruction = \"\"\" \\ You are a data assistant agent with access to several Spanner tools. Make use of those tools to answer the user's questions. \"\"\" , tools = [ spanner_toolset , # Add customized Spanner tool based on the built-in Spanner toolset. GoogleTool ( func = count_rows_tool , credentials_config = credentials_config , tool_settings = tool_settings , ), ], ) # Session and Runner session_service = InMemorySessionService () # Optionally, Spanner can be used as the Database Session Service for production. # Note that it's suggested to use a dedicated instance/database for storing sessions. # session_service_spanner_db_url = \"spanner+spanner:///projects/PROJECT_ID/instances/INSTANCE_ID/databases/my-adk-session\" # session_service = DatabaseSessionService(db_url=session_service_spanner_db_url) session = asyncio . run ( session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) ) runner = Runner ( agent = spanner_agent , app_name = APP_NAME , session_service = session_service ) # Agent Interaction def call_agent ( query ): \"\"\" Helper function to call the agent with a query. \"\"\" content = types . Content ( role = \"user\" , parts = [ types . Part ( text = query )]) events = runner . run ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) print ( \"USER:\" , query ) for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"AGENT:\" , final_response ) # Replace the Spanner database and table names below with your own. call_agent ( \"List all tables in projects/<PROJECT_ID>/instances/<INSTANCE_ID>/databases/<DATABASE_ID>\" ) call_agent ( \"Describe the schema of <TABLE_NAME>\" ) call_agent ( \"List the top 5 rows in <TABLE_NAME>\" ) ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\n\nfrom google.adk.agents import Agent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\n# from google.adk.sessions import DatabaseSessionService\nfrom google.adk.tools.google_tool import GoogleTool\nfrom google.adk.tools.spanner import query_tool\nfrom google.adk.tools.spanner.settings import SpannerToolSettings\nfrom google.adk.tools.spanner.settings import Capabilities\nfrom google.adk.tools.spanner.spanner_credentials import SpannerCredentialsConfig\nfrom google.adk.tools.spanner.spanner_toolset import SpannerToolset\nfrom google.genai import types\nfrom google.adk.tools.tool_context import ToolContext\nimport google.auth\nfrom google.auth.credentials import Credentials\n\n# Define constants for this example agent\nAGENT_NAME = \"spanner_agent\"\nAPP_NAME = \"spanner_app\"\nUSER_ID = \"user1234\"\nSESSION_ID = \"1234\"\nGEMINI_MODEL = \"gemini-2.5-flash\"\n\n# Define Spanner tool config with read capability set to allowed.\ntool_settings = SpannerToolSettings(capabilities=[Capabilities.DATA_READ])\n\n# Define a credentials config - in this example we are using application default\n# credentials\n# https://cloud.google.com/docs/authentication/provide-credentials-adc\napplication_default_credentials, _ = google.auth.default()\ncredentials_config = SpannerCredentialsConfig(\n    credentials=application_default_credentials\n)\n\n# Instantiate a Spanner toolset\nspanner_toolset = SpannerToolset(\n    credentials_config=credentials_config, spanner_tool_settings=tool_settings\n)\n\n# Optional\n# Create a wrapped function tool for the agent on top of the built-in\n# `execute_sql` tool in the Spanner toolset.\n# For example, this customized tool can perform a dynamically-built query.\ndef count_rows_tool(\n    table_name: str,\n    credentials: Credentials,  # GoogleTool handles `credentials`\n    settings: SpannerToolSettings,  # GoogleTool handles `settings`\n    tool_context: ToolContext,  # GoogleTool handles `tool_context`\n):\n  \"\"\"Counts the total number of rows for a specified table.\n\n  Args:\n    table_name: The name of the table for which to count rows.\n\n  Returns:\n      The total number of rows in the table.\n  \"\"\"\n\n  # Replace the following settings for a specific Spanner database.\n  PROJECT_ID = \"<PROJECT_ID>\"\n  INSTANCE_ID = \"<INSTANCE_ID>\"\n  DATABASE_ID = \"<DATABASE_ID>\"\n\n  query = f\"\"\"\n  SELECT count(*) FROM {table_name}\n    \"\"\"\n\n  return query_tool.execute_sql(\n      project_id=PROJECT_ID,\n      instance_id=INSTANCE_ID,\n      database_id=DATABASE_ID,\n      query=query,\n      credentials=credentials,\n      settings=settings,\n      tool_context=tool_context,\n  )\n\n# Agent Definition\nspanner_agent = Agent(\n    model=GEMINI_MODEL,\n    name=AGENT_NAME,\n    description=(\n        \"Agent to answer questions about Spanner database and execute SQL queries.\"\n    ),\n    instruction=\"\"\"\\\n        You are a data assistant agent with access to several Spanner tools.\n        Make use of those tools to answer the user's questions.\n    \"\"\",\n    tools=[\n        spanner_toolset,\n        # Add customized Spanner tool based on the built-in Spanner toolset.\n        GoogleTool(\n            func=count_rows_tool,\n            credentials_config=credentials_config,\n            tool_settings=tool_settings,\n        ),\n    ],\n)\n\n\n# Session and Runner\nsession_service = InMemorySessionService()\n\n# Optionally, Spanner can be used as the Database Session Service for production.\n# Note that it's suggested to use a dedicated instance/database for storing sessions.\n# session_service_spanner_db_url = \"spanner+spanner:///projects/PROJECT_ID/instances/INSTANCE_ID/databases/my-adk-session\"\n# session_service = DatabaseSessionService(db_url=session_service_spanner_db_url)\n\nsession = asyncio.run(\n    session_service.create_session(\n        app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n    )\n)\nrunner = Runner(\n    agent=spanner_agent, app_name=APP_NAME, session_service=session_service\n)\n\n\n# Agent Interaction\ndef call_agent(query):\n    \"\"\"\n    Helper function to call the agent with a query.\n    \"\"\"\n    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    print(\"USER:\", query)\n    for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"AGENT:\", final_response)\n\n# Replace the Spanner database and table names below with your own.\ncall_agent(\"List all tables in projects/<PROJECT_ID>/instances/<INSTANCE_ID>/databases/<DATABASE_ID>\")\ncall_agent(\"Describe the schema of <TABLE_NAME>\")\ncall_agent(\"List the top 5 rows in <TABLE_NAME>\")"}]}, {"heading_path": ["Bigtable\u00b6"], "text": "Bigtable \u00b6 Supported in ADK Python v1.12.0 These are a set of tools aimed to provide integration with Bigtable, namely: list_instances : Fetches Bigtable instances in a Google Cloud project. get_instance_info : Fetches metadata instance information in a Google Cloud project. list_tables : Fetches tables in a GCP Bigtable instance. get_table_info : Fetches metadata table information in a GCP Bigtable. execute_sql : Runs a SQL query in Bigtable table and fetch the result. They are packaged in the toolset BigtableToolset . # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import asyncio from google.adk.agents import Agent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.tools.google_tool import GoogleTool from google.adk.tools.bigtable import query_tool from google.adk.tools.bigtable.settings import BigtableToolSettings from google.adk.tools.bigtable.bigtable_credentials import BigtableCredentialsConfig from google.adk.tools.bigtable.bigtable_toolset import BigtableToolset from google.genai import types from google.adk.tools.tool_context import ToolContext import google.auth from google.auth.credentials import Credentials # Define constants for this example agent AGENT_NAME = \"bigtable_agent\" APP_NAME = \"bigtable_app\" USER_ID = \"user1234\" SESSION_ID = \"1234\" GEMINI_MODEL = \"gemini-2.5-flash\" # Define Bigtable tool config with read capability set to allowed. tool_settings = BigtableToolSettings () # Define a credentials config - in this example we are using application default # credentials # https://cloud.google.com/docs/authentication/provide-credentials-adc application_default_credentials , _ = google . auth . default () credentials_config = BigtableCredentialsConfig ( credentials = application_default_credentials ) # Instantiate a Bigtable toolset bigtable_toolset = BigtableToolset ( credentials_config = credentials_config , bigtable_tool_settings = tool_settings ) # Optional # Create a wrapped function tool for the agent on top of the built-in # `execute_sql` tool in the bigtable toolset. # For example, this customized tool can perform a dynamically-built query. def count_rows_tool ( table_name : str , credentials : Credentials , # GoogleTool handles `credentials` settings : BigtableToolSettings , # GoogleTool handles `settings` tool_context : ToolContext , # GoogleTool handles `tool_context` ): \"\"\"Counts the total number of rows for a specified table. Args: table_name: The name of the table for which to count rows. Returns: The total number of rows in the table. \"\"\" # Replace the following settings for a specific bigtable database. PROJECT_ID = \"<PROJECT_ID>\" INSTANCE_ID = \"<INSTANCE_ID>\" query = f \"\"\" SELECT count(*) FROM { table_name } \"\"\" return query_tool . execute_sql ( project_id = PROJECT_ID , instance_id = INSTANCE_ID , query = query , credentials = credentials , settings = settings , tool_context = tool_context , ) # Agent Definition bigtable_agent = Agent ( model = GEMINI_MODEL , name = AGENT_NAME , description = ( \"Agent to answer questions about bigtable database and execute SQL queries.\" ), instruction = \"\"\" \\ You are a data assistant agent with access to several bigtable tools. Make use of those tools to answer the user's questions. \"\"\" , tools = [ bigtable_toolset , # Add customized bigtable tool based on the built-in bigtable toolset. GoogleTool ( func = count_rows_tool , credentials_config = credentials_config , tool_settings = tool_settings , ), ], ) # Session and Runner session_service = InMemorySessionService () session = asyncio . run ( session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) ) runner = Runner ( agent = bigtable_agent , app_name = APP_NAME , session_service = session_service ) # Agent Interaction def call_agent ( query ): \"\"\" Helper function to call the agent with a query. \"\"\" content = types . Content ( role = \"user\" , parts = [ types . Part ( text = query )]) events = runner . run ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) print ( \"USER:\" , query ) for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"AGENT:\" , final_response ) # Replace the bigtable instance and table names below with your own. call_agent ( \"List all tables in projects/<PROJECT_ID>/instances/<INSTANCE_ID>\" ) call_agent ( \"List the top 5 rows in <TABLE_NAME>\" ) ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\n\nfrom google.adk.agents import Agent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools.google_tool import GoogleTool\nfrom google.adk.tools.bigtable import query_tool\nfrom google.adk.tools.bigtable.settings import BigtableToolSettings\nfrom google.adk.tools.bigtable.bigtable_credentials import BigtableCredentialsConfig\nfrom google.adk.tools.bigtable.bigtable_toolset import BigtableToolset\nfrom google.genai import types\nfrom google.adk.tools.tool_context import ToolContext\nimport google.auth\nfrom google.auth.credentials import Credentials\n\n# Define constants for this example agent\nAGENT_NAME = \"bigtable_agent\"\nAPP_NAME = \"bigtable_app\"\nUSER_ID = \"user1234\"\nSESSION_ID = \"1234\"\nGEMINI_MODEL = \"gemini-2.5-flash\"\n\n# Define Bigtable tool config with read capability set to allowed.\ntool_settings = BigtableToolSettings()\n\n# Define a credentials config - in this example we are using application default\n# credentials\n# https://cloud.google.com/docs/authentication/provide-credentials-adc\napplication_default_credentials, _ = google.auth.default()\ncredentials_config = BigtableCredentialsConfig(\n    credentials=application_default_credentials\n)\n\n# Instantiate a Bigtable toolset\nbigtable_toolset = BigtableToolset(\n    credentials_config=credentials_config, bigtable_tool_settings=tool_settings\n)\n\n# Optional\n# Create a wrapped function tool for the agent on top of the built-in\n# `execute_sql` tool in the bigtable toolset.\n# For example, this customized tool can perform a dynamically-built query.\ndef count_rows_tool(\n    table_name: str,\n    credentials: Credentials,  # GoogleTool handles `credentials`\n    settings: BigtableToolSettings,  # GoogleTool handles `settings`\n    tool_context: ToolContext,  # GoogleTool handles `tool_context`\n):\n  \"\"\"Counts the total number of rows for a specified table.\n\n  Args:\n    table_name: The name of the table for which to count rows.\n\n  Returns:\n      The total number of rows in the table.\n  \"\"\"\n\n  # Replace the following settings for a specific bigtable database.\n  PROJECT_ID = \"<PROJECT_ID>\"\n  INSTANCE_ID = \"<INSTANCE_ID>\"\n\n  query = f\"\"\"\n  SELECT count(*) FROM {table_name}\n    \"\"\"\n\n  return query_tool.execute_sql(\n      project_id=PROJECT_ID,\n      instance_id=INSTANCE_ID,\n      query=query,\n      credentials=credentials,\n      settings=settings,\n      tool_context=tool_context,\n  )\n\n# Agent Definition\nbigtable_agent = Agent(\n    model=GEMINI_MODEL,\n    name=AGENT_NAME,\n    description=(\n        \"Agent to answer questions about bigtable database and execute SQL queries.\"\n    ),\n    instruction=\"\"\"\\\n        You are a data assistant agent with access to several bigtable tools.\n        Make use of those tools to answer the user's questions.\n    \"\"\",\n    tools=[\n        bigtable_toolset,\n        # Add customized bigtable tool based on the built-in bigtable toolset.\n        GoogleTool(\n            func=count_rows_tool,\n            credentials_config=credentials_config,\n            tool_settings=tool_settings,\n        ),\n    ],\n)\n\n\n# Session and Runner\nsession_service = InMemorySessionService()\n\nsession = asyncio.run(\n    session_service.create_session(\n        app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n    )\n)\nrunner = Runner(\n    agent=bigtable_agent, app_name=APP_NAME, session_service=session_service\n)\n\n\n# Agent Interaction\ndef call_agent(query):\n    \"\"\"\n    Helper function to call the agent with a query.\n    \"\"\"\n    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    print(\"USER:\", query)\n    for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"AGENT:\", final_response)\n\n# Replace the bigtable instance and table names below with your own.\ncall_agent(\"List all tables in projects/<PROJECT_ID>/instances/<INSTANCE_ID>\")\ncall_agent(\"List the top 5 rows in <TABLE_NAME>\")"}]}, {"heading_path": ["Use Built-in tools with other tools\u00b6"], "text": "Use Built-in tools with other tools \u00b6 Supported in ADK Python Java The following code sample demonstrates how to use multiple built-in tools or how\nto use built-in tools with other tools by using multiple agents: Python Java from google.adk.tools.agent_tool import AgentTool from google.adk.agents import Agent from google.adk.tools import google_search from google.adk.code_executors import BuiltInCodeExecutor search_agent = Agent ( model = 'gemini-2.0-flash' , name = 'SearchAgent' , instruction = \"\"\" You're a specialist in Google Search \"\"\" , tools = [ google_search ], ) coding_agent = Agent ( model = 'gemini-2.0-flash' , name = 'CodeAgent' , instruction = \"\"\" You're a specialist in Code Execution \"\"\" , code_executor = BuiltInCodeExecutor (), ) root_agent = Agent ( name = \"RootAgent\" , model = \"gemini-2.0-flash\" , description = \"Root Agent\" , tools = [ AgentTool ( agent = search_agent ), AgentTool ( agent = coding_agent )], ) import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.LlmAgent ; import com.google.adk.tools.AgentTool ; import com.google.adk.tools.BuiltInCodeExecutionTool ; import com.google.adk.tools.GoogleSearchTool ; import com.google.common.collect.ImmutableList ; public class NestedAgentApp { private static final String MODEL_ID = \"gemini-2.0-flash\" ; public static void main ( String [] args ) { // Define the SearchAgent LlmAgent searchAgent = LlmAgent . builder () . model ( MODEL_ID ) . name ( \"SearchAgent\" ) . instruction ( \"You're a specialist in Google Search\" ) . tools ( new GoogleSearchTool ()) // Instantiate GoogleSearchTool . build (); // Define the CodingAgent LlmAgent codingAgent = LlmAgent . builder () . model ( MODEL_ID ) . name ( \"CodeAgent\" ) . instruction ( \"You're a specialist in Code Execution\" ) . tools ( new BuiltInCodeExecutionTool ()) // Instantiate BuiltInCodeExecutionTool . build (); // Define the RootAgent, which uses AgentTool.create() to wrap SearchAgent and CodingAgent BaseAgent rootAgent = LlmAgent . builder () . name ( \"RootAgent\" ) . model ( MODEL_ID ) . description ( \"Root Agent\" ) . tools ( AgentTool . create ( searchAgent ), // Use create method AgentTool . create ( codingAgent ) // Use create method ) . build (); // Note: This sample only demonstrates the agent definitions. // To run these agents, you'd need to integrate them with a Runner and SessionService, // similar to the previous examples. System . out . println ( \"Agents defined successfully:\" ); System . out . println ( \"  Root Agent: \" + rootAgent . name ()); System . out . println ( \"  Search Agent (nested): \" + searchAgent . name ()); System . out . println ( \"  Code Agent (nested): \" + codingAgent . name ()); } } ", "code_blocks": [{"language": "text", "code": "from google.adk.tools.agent_tool import AgentTool\nfrom google.adk.agents import Agent\nfrom google.adk.tools import google_search\nfrom google.adk.code_executors import BuiltInCodeExecutor\n\n\nsearch_agent = Agent(\n    model='gemini-2.0-flash',\n    name='SearchAgent',\n    instruction=\"\"\"\n    You're a specialist in Google Search\n    \"\"\",\n    tools=[google_search],\n)\ncoding_agent = Agent(\n    model='gemini-2.0-flash',\n    name='CodeAgent',\n    instruction=\"\"\"\n    You're a specialist in Code Execution\n    \"\"\",\n    code_executor=BuiltInCodeExecutor(),\n)\nroot_agent = Agent(\n    name=\"RootAgent\",\n    model=\"gemini-2.0-flash\",\n    description=\"Root Agent\",\n    tools=[AgentTool(agent=search_agent), AgentTool(agent=coding_agent)],\n)"}, {"language": "text", "code": "import com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.tools.AgentTool;\nimport com.google.adk.tools.BuiltInCodeExecutionTool;\nimport com.google.adk.tools.GoogleSearchTool;\nimport com.google.common.collect.ImmutableList;\n\npublic class NestedAgentApp {\n\n  private static final String MODEL_ID = \"gemini-2.0-flash\";\n\n  public static void main(String[] args) {\n\n    // Define the SearchAgent\n    LlmAgent searchAgent =\n        LlmAgent.builder()\n            .model(MODEL_ID)\n            .name(\"SearchAgent\")\n            .instruction(\"You're a specialist in Google Search\")\n            .tools(new GoogleSearchTool()) // Instantiate GoogleSearchTool\n            .build();\n\n\n    // Define the CodingAgent\n    LlmAgent codingAgent =\n        LlmAgent.builder()\n            .model(MODEL_ID)\n            .name(\"CodeAgent\")\n            .instruction(\"You're a specialist in Code Execution\")\n            .tools(new BuiltInCodeExecutionTool()) // Instantiate BuiltInCodeExecutionTool\n            .build();\n\n    // Define the RootAgent, which uses AgentTool.create() to wrap SearchAgent and CodingAgent\n    BaseAgent rootAgent =\n        LlmAgent.builder()\n            .name(\"RootAgent\")\n            .model(MODEL_ID)\n            .description(\"Root Agent\")\n            .tools(\n                AgentTool.create(searchAgent), // Use create method\n                AgentTool.create(codingAgent)   // Use create method\n             )\n            .build();\n\n    // Note: This sample only demonstrates the agent definitions.\n    // To run these agents, you'd need to integrate them with a Runner and SessionService,\n    // similar to the previous examples.\n    System.out.println(\"Agents defined successfully:\");\n    System.out.println(\"  Root Agent: \" + rootAgent.name());\n    System.out.println(\"  Search Agent (nested): \" + searchAgent.name());\n    System.out.println(\"  Code Agent (nested): \" + codingAgent.name());\n  }\n}"}]}, {"heading_path": ["Limitations\u00b6"], "text": "Limitations \u00b6 Warning Currently, for each root agent or single agent, only one built-in tool is\nsupported. No other tools of any type can be used in the same agent. For example, the following approach that uses a built-in tool along with\n other tools within a single agent is not currently supported: Python Java root_agent = Agent ( name = \"RootAgent\" , model = \"gemini-2.0-flash\" , description = \"Root Agent\" , tools = [ custom_function ], code_executor = BuiltInCodeExecutor () # <-- not supported when used with tools ) LlmAgent searchAgent = LlmAgent . builder () . model ( MODEL_ID ) . name ( \"SearchAgent\" ) . instruction ( \"You're a specialist in Google Search\" ) . tools ( new GoogleSearchTool (), new YourCustomTool ()) // <-- not supported . build (); ADK Python has a built-in workaroud which bypasses this limitation for GoogleSearchTool and VertexAiSearchTool (use bypass_multi_tools_limit=True to enable it), e.g. sample agent . Warning Built-in tools cannot be used within a sub-agent, with the exception of GoogleSearchTool and VertexAiSearchTool in ADK Python because of the\nworkaround mentioned above. For example, the following approach that uses built-in tools within sub-agents\nis not currently supported: Python Java url_context_agent = Agent ( model = 'gemini-2.0-flash' , name = 'UrlContextAgent' , instruction = \"\"\" You're a specialist in URL Context \"\"\" , tools = [ url_context ], ) coding_agent = Agent ( model = 'gemini-2.0-flash' , name = 'CodeAgent' , instruction = \"\"\" You're a specialist in Code Execution \"\"\" , code_executor = BuiltInCodeExecutor (), ) root_agent = Agent ( name = \"RootAgent\" , model = \"gemini-2.0-flash\" , description = \"Root Agent\" , sub_agents = [ url_context_agent , coding_agent ], ) LlmAgent searchAgent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"SearchAgent\" ) . instruction ( \"You're a specialist in Google Search\" ) . tools ( new GoogleSearchTool ()) . build (); LlmAgent codingAgent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"CodeAgent\" ) . instruction ( \"You're a specialist in Code Execution\" ) . tools ( new BuiltInCodeExecutionTool ()) . build (); LlmAgent rootAgent = LlmAgent . builder () . name ( \"RootAgent\" ) . model ( \"gemini-2.0-flash\" ) . description ( \"Root Agent\" ) . subAgents ( searchAgent , codingAgent ) // Not supported, as the sub agents use built in tools. . build (); Back to top ", "code_blocks": [{"language": "text", "code": "root_agent = Agent(\n    name=\"RootAgent\",\n    model=\"gemini-2.0-flash\",\n    description=\"Root Agent\",\n    tools=[custom_function], \n    code_executor=BuiltInCodeExecutor() # <-- not supported when used with tools\n)"}, {"language": "text", "code": "LlmAgent searchAgent =\n        LlmAgent.builder()\n            .model(MODEL_ID)\n            .name(\"SearchAgent\")\n            .instruction(\"You're a specialist in Google Search\")\n            .tools(new GoogleSearchTool(), new YourCustomTool()) // <-- not supported\n            .build();"}, {"language": "text", "code": "url_context_agent = Agent(\n    model='gemini-2.0-flash',\n    name='UrlContextAgent',\n    instruction=\"\"\"\n    You're a specialist in URL Context\n    \"\"\",\n    tools=[url_context],\n)\ncoding_agent = Agent(\n    model='gemini-2.0-flash',\n    name='CodeAgent',\n    instruction=\"\"\"\n    You're a specialist in Code Execution\n    \"\"\",\n    code_executor=BuiltInCodeExecutor(),\n)\nroot_agent = Agent(\n    name=\"RootAgent\",\n    model=\"gemini-2.0-flash\",\n    description=\"Root Agent\",\n    sub_agents=[\n        url_context_agent,\n        coding_agent\n    ],\n)"}, {"language": "text", "code": "LlmAgent searchAgent =\n    LlmAgent.builder()\n        .model(\"gemini-2.0-flash\")\n        .name(\"SearchAgent\")\n        .instruction(\"You're a specialist in Google Search\")\n        .tools(new GoogleSearchTool())\n        .build();\n\nLlmAgent codingAgent =\n    LlmAgent.builder()\n        .model(\"gemini-2.0-flash\")\n        .name(\"CodeAgent\")\n        .instruction(\"You're a specialist in Code Execution\")\n        .tools(new BuiltInCodeExecutionTool())\n        .build();\n\n\nLlmAgent rootAgent =\n    LlmAgent.builder()\n        .name(\"RootAgent\")\n        .model(\"gemini-2.0-flash\")\n        .description(\"Root Agent\")\n        .subAgents(searchAgent, codingAgent) // Not supported, as the sub agents use built in tools.\n        .build();"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:10.572697", "source_type": "adk-docs"}
{"doc_id": "bc82043d7366e69e04ed2febf33c0ceaaddeebf3944d31d2145bf89d1cfdc518", "url": "https://google.github.io/adk-docs/tools/gemini-api/computer-use", "title": "Computer use - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Computer Use Toolset with Gemini\u00b6"], "text": "Computer Use Toolset with Gemini \u00b6 Supported in ADK Python v1.17.0 Preview The Computer Use Toolset allows an agent to operate a user interface\nof a computer, such as a browsers, to complete tasks. This tool uses\na specific Gemini model and the Playwright testing tool to control a Chromium browser and can interact with\nweb pages by taking screenshots, clicking, typing, and navigating. For more information about the computer use model, see \nGemini API Computer use or the Google Cloud Vertex AI API Computer use . Preview release The Computer Use model and tool is a Preview release. For\nmore information, see the launch stage descriptions . ", "code_blocks": []}, {"heading_path": ["Setup\u00b6"], "text": "Setup \u00b6 You must install Playwright and its dependencies, including Chromium,\nto be able to use the Computer Use Toolset. Recommended: create and activate a Python virtual environment Create a Python virtual environment: python -m venv .venv Activate the Python virtual environment: Windows CMD Windows Powershell MacOS / Linux .venv\\Scripts\\activate.bat .venv\\Scripts\\Activate.ps1 source .venv/bin/activate To set up the required software libraries for the Computer Use Toolset: Install Python dependencies: pip install termcolor==3.1.0 pip install playwright==1.52.0 pip install browserbase==1.3.0 pip install rich Install the Playwright dependencies, including the Chromium browser: playwright install-deps chromium playwright install chromium ", "code_blocks": [{"language": "text", "code": "python -m venv .venv"}, {"language": "text", "code": ".venv\\Scripts\\activate.bat"}, {"language": "text", "code": ".venv\\Scripts\\Activate.ps1"}, {"language": "text", "code": "source .venv/bin/activate"}, {"language": "text", "code": "pip install termcolor==3.1.0\npip install playwright==1.52.0\npip install browserbase==1.3.0\npip install rich"}, {"language": "text", "code": "playwright install-deps chromium\nplaywright install chromium"}]}, {"heading_path": ["Use the tool\u00b6"], "text": "Use the tool \u00b6 Use the Computer Use Toolset by adding it as a tool to your agent. When you\nconfigure the tool, you must provide a implementation of the BaseComputer class which defines an interface for an agent to use a computer. In the\nfollowing example, the PlaywrightComputer class is defined for this purpose.\nYou can find the code for this implementation in playwright.py file of the computer_use agent sample project. from google.adk import Agent from google.adk.models.google_llm import Gemini from google.adk.tools.computer_use.computer_use_toolset import ComputerUseToolset from typing_extensions import override from .playwright import PlaywrightComputer root_agent = Agent ( model = 'gemini-2.5-computer-use-preview-10-2025' , name = 'hello_world_agent' , description = ( 'computer use agent that can operate a browser on a computer to finish' ' user tasks' ), instruction = 'you are a computer use agent' , tools = [ ComputerUseToolset ( computer = PlaywrightComputer ( screen_size = ( 1280 , 936 ))) ], ) For a complete code example, see the computer_use agent sample project. Back to top ", "code_blocks": [{"language": "text", "code": "from google.adk import Agent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.tools.computer_use.computer_use_toolset import ComputerUseToolset\nfrom typing_extensions import override\n\nfrom .playwright import PlaywrightComputer\n\nroot_agent = Agent(\n    model='gemini-2.5-computer-use-preview-10-2025',\n    name='hello_world_agent',\n    description=(\n        'computer use agent that can operate a browser on a computer to finish'\n        ' user tasks'\n    ),\n    instruction='you are a computer use agent',\n    tools=[\n        ComputerUseToolset(computer=PlaywrightComputer(screen_size=(1280, 936)))\n    ],\n)"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:10.726705", "source_type": "adk-docs"}
{"doc_id": "3dd6080bb39b23fcc410b24bd491fba0a1246ee2d7a1df70fbd867ac1ec9540b", "url": "https://google.github.io/adk-docs/tools/google-cloud-tools", "title": "Overview - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Google Cloud Tools\u00b6"], "text": "Google Cloud Tools \u00b6 Google Cloud tools make it easier to connect your agents to Google Cloud\u2019s\nproducts and services. With just a few lines of code you can use these tools to\nconnect your agents with: Any custom APIs that developers host in Apigee. 100s of prebuilt connectors to enterprise systems such as Salesforce,\n  Workday, and SAP. Automation workflows built using application integration. Databases such as Spanner, AlloyDB, Postgres and more using the MCP Toolbox for\n  databases. ", "code_blocks": []}, {"heading_path": ["Apigee API Hub Tools\u00b6"], "text": "Apigee API Hub Tools \u00b6 Supported in ADK Python v0.1.0 ApiHubToolset lets you turn any documented API from Apigee API hub into a\ntool with a few lines of code. This section shows you the step by step\ninstructions including setting up authentication for a secure connection to your\nAPIs. Prerequisites Install ADK Install the Google Cloud CLI . Apigee API hub instance with documented (i.e. OpenAPI spec) APIs Set up your project structure and create required files project_root_folder | `-- my_agent |-- .env |-- __init__.py |-- agent.py `__ tool.py ", "code_blocks": [{"language": "text", "code": "project_root_folder\n |\n `-- my_agent\n     |-- .env\n     |-- __init__.py\n     |-- agent.py\n     `__ tool.py"}]}, {"heading_path": ["Create an API Hub Toolset\u00b6"], "text": "Create an API Hub Toolset \u00b6 Note: This tutorial includes an agent creation. If you already have an agent,\nyou only need to follow a subset of these steps. Get your access token, so that APIHubToolset can fetch spec from API Hub API.\n   In your terminal run the following command gcloud auth print-access-token # Prints your access token like 'ya29....' Ensure that the account used has the required permissions. You can use the\n   pre-defined role roles/apihub.viewer or assign the following permissions: apihub.specs.get (required) apihub.apis.get (optional) apihub.apis.list (optional) apihub.versions.get (optional) apihub.versions.list (optional) apihub.specs.list (optional) Create a tool with APIHubToolset . Add the below to tools.py If your API requires authentication, you must configure authentication for\nthe tool. The following code sample demonstrates how to configure an API\nkey. ADK supports token based auth (API Key, Bearer token), service account,\nand OpenID Connect. We will soon add support for various OAuth2 flows. from google.adk.tools.openapi_tool.auth.auth_helpers import token_to_scheme_credential from google.adk.tools.apihub_tool.apihub_toolset import APIHubToolset # Provide authentication for your APIs. Not required if your APIs don't required authentication. auth_scheme , auth_credential = token_to_scheme_credential ( \"apikey\" , \"query\" , \"apikey\" , apikey_credential_str ) sample_toolset = APIHubToolset ( name = \"apihub-sample-tool\" , description = \"Sample Tool\" , access_token = \"...\" , # Copy your access token generated in step 1 apihub_resource_name = \"...\" , # API Hub resource name auth_scheme = auth_scheme , auth_credential = auth_credential , ) For production deployment we recommend using a service account instead of an\naccess token. In the code snippet above, use service_account_json=service_account_cred_json_str and provide your\nsecurity account credentials instead of the token. For apihub_resource_name, if you know the specific ID of the OpenAPI Spec\nbeing used for your API, use `projects/my-project-id/locations/us-west1/apis/my-api-id/versions/version-id/specs/spec-id` .\nIf you would like the Toolset to automatically pull the first available spec\nfrom the API, use `projects/my-project-id/locations/us-west1/apis/my-api-id` Create your agent file Agent.py and add the created tools to your agent\n   definition: from google.adk.agents.llm_agent import LlmAgent from .tools import sample_toolset root_agent = LlmAgent ( model = 'gemini-2.0-flash' , name = 'enterprise_assistant' , instruction = 'Help user, leverage the tools you have access to' , tools = sample_toolset . get_tools (), ) Configure your __init__.py to expose your agent from . import agent Start the Google ADK Web UI and try your agent: # make sure to run `adk web` from your project_root_folder adk web Then go to http://localhost:8000 to try your agent from the Web UI. ", "code_blocks": [{"language": "text", "code": "gcloud auth print-access-token\n# Prints your access token like 'ya29....'"}, {"language": "text", "code": "from google.adk.tools.openapi_tool.auth.auth_helpers import token_to_scheme_credential\nfrom google.adk.tools.apihub_tool.apihub_toolset import APIHubToolset\n\n# Provide authentication for your APIs. Not required if your APIs don't required authentication.\nauth_scheme, auth_credential = token_to_scheme_credential(\n    \"apikey\", \"query\", \"apikey\", apikey_credential_str\n)\n\nsample_toolset = APIHubToolset(\n    name=\"apihub-sample-tool\",\n    description=\"Sample Tool\",\n    access_token=\"...\",  # Copy your access token generated in step 1\n    apihub_resource_name=\"...\", # API Hub resource name\n    auth_scheme=auth_scheme,\n    auth_credential=auth_credential,\n)"}, {"language": "text", "code": "from google.adk.agents.llm_agent import LlmAgent\nfrom .tools import sample_toolset\n\nroot_agent = LlmAgent(\n    model='gemini-2.0-flash',\n    name='enterprise_assistant',\n    instruction='Help user, leverage the tools you have access to',\n    tools=sample_toolset.get_tools(),\n)"}, {"language": "text", "code": "from . import agent"}, {"language": "text", "code": "# make sure to run `adk web` from your project_root_folder\nadk web"}]}, {"heading_path": ["Application Integration Tools\u00b6"], "text": "Application Integration Tools \u00b6 Supported in ADK Python v0.1.0 Java v0.3.0 With ApplicationIntegrationToolset , you can seamlessly give your agents\nsecure and governed access to enterprise applications using Integration\nConnectors' 100+ pre-built connectors for systems like Salesforce, ServiceNow,\nJIRA, SAP, and more. It supports both on-premise and SaaS applications. In addition, you can turn\nyour existing Application Integration process automations into agentic workflows\nby providing application integration workflows as tools to your ADK agents. Federated search within Application Integration lets you use ADK agents to query\nmultiple enterprise applications and data sources simultaneously. ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. See how ADK Federated Search in Application Integration works in this video walkthrough ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 ", "code_blocks": []}, {"heading_path": ["1. Install ADK\u00b6"], "text": "1. Install ADK \u00b6 Install Agent Development Kit following the steps in the installation guide . ", "code_blocks": []}, {"heading_path": ["2. Install CLI\u00b6"], "text": "2. Install CLI \u00b6 Install the Google Cloud CLI .\nTo use the tool with default credentials, run the following commands: gcloud config set project <project-id> gcloud auth application-default login gcloud auth application-default set-quota-project <project-id> Replace <project-id> with the unique ID of your Google Cloud project. ", "code_blocks": [{"language": "text", "code": "gcloud config set project <project-id>\ngcloud auth application-default login\ngcloud auth application-default set-quota-project <project-id>"}]}, {"heading_path": ["3. Provision Application Integration workflow and publish Connection Tool\u00b6"], "text": "3. Provision Application Integration workflow and publish Connection Tool \u00b6 Use an existing Application Integration workflow or Integrations Connector connection you want to use with your agent. You can also create a new Application Integration workflow or a connection . Import and publish the Connection Tool from the template library. Note : To use a connector from Integration Connectors, you need to provision\nthe Application Integration in the same region as your connection. ", "code_blocks": []}, {"heading_path": ["4. Create project structure\u00b6"], "text": "4. Create project structure \u00b6 Python Java Set up your project structure and create the required files: project_root_folder \u251c\u2500\u2500 .env \u2514\u2500\u2500 my_agent \u251c\u2500\u2500 __init__.py \u251c\u2500\u2500 agent.py \u2514\u2500\u2500 tools.py When running the agent, make sure to run adk web from the project_root_folder . Set up your project structure and create the required files: project_root_folder \u2514\u2500\u2500 my_agent \u251c\u2500\u2500 agent.java \u2514\u2500\u2500 pom.xml When running the agent, make sure to run the commands from the project_root_folder . ", "code_blocks": [{"language": "text", "code": "project_root_folder\n\u251c\u2500\u2500 .env\n\u2514\u2500\u2500 my_agent\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 agent.py\n    \u2514\u2500\u2500 tools.py"}, {"language": "text", "code": "project_root_folder\n  \u2514\u2500\u2500 my_agent\n      \u251c\u2500\u2500 agent.java\n      \u2514\u2500\u2500 pom.xml"}]}, {"heading_path": ["5. Set roles and permissions\u00b6"], "text": "5. Set roles and permissions \u00b6 To get the permissions that you need to set up ApplicationIntegrationToolset , you must have the following IAM roles on the\nproject (common to both Integration Connectors and Application Integration\nWorkflows): - roles/integrations.integrationEditor\n- roles/connectors.invoker\n- roles/secretmanager.secretAccessor Note: When using Agent Engine (AE) for deployment, don't use roles/integrations.integrationInvoker , as it can result in 403 errors. Use roles/integrations.integrationEditor instead. ", "code_blocks": [{"language": "text", "code": "- roles/integrations.integrationEditor\n- roles/connectors.invoker\n- roles/secretmanager.secretAccessor"}]}, {"heading_path": ["Use Integration Connectors\u00b6"], "text": "Use Integration Connectors \u00b6 Connect your agent to enterprise applications using Integration Connectors . ", "code_blocks": []}, {"heading_path": ["Before you begin\u00b6"], "text": "Before you begin \u00b6 Note: The ExecuteConnection integration is typically created automatically when you provision Application Integration in a given region. If the ExecuteConnection doesn't exist in the list of integrations , you must follow these steps to create it: To use a connector from Integration Connectors, click QUICK SETUP and provision Application Integration in the same region as your connection. Go to the Connection Tool template in the template library and click USE TEMPLATE . Enter the Integration Name as ExecuteConnection (it is mandatory to use this exact integration name only).\n   Then, select the region to match your connection region and click CREATE . Click PUBLISH to publish the integration in the Application Integration editor. ", "code_blocks": []}, {"heading_path": ["Create an Application Integration Toolset\u00b6"], "text": "Create an Application Integration Toolset \u00b6 To create an Application Integration Toolset for Integration Connectors, follow these steps: Create a tool with ApplicationIntegrationToolset in the tools.py file: from google.adk.tools.application_integration_tool.application_integration_toolset import ApplicationIntegrationToolset connector_tool = ApplicationIntegrationToolset ( project = \"test-project\" , # TODO: replace with GCP project of the connection location = \"us-central1\" , #TODO: replace with location of the connection connection = \"test-connection\" , #TODO: replace with connection name entity_operations = { \"Entity_One\" : [ \"LIST\" , \"CREATE\" ], \"Entity_Two\" : []}, #empty list for actions means all operations on the entity are supported. actions = [ \"action1\" ], #TODO: replace with actions service_account_json = '{...}' , # optional. Stringified json for service account key tool_name_prefix = \"tool_prefix2\" , tool_instructions = \"...\" ) Note: You can provide a service account to be used instead of default credentials by generating a Service Account Key , and providing the right Application Integration and Integration Connector IAM roles to the service account. To find the list of supported entities and actions for a connection, use the Connectors APIs: listActions or listEntityTypes . ApplicationIntegrationToolset supports auth_scheme and auth_credential for dynamic OAuth2 authentication for Integration Connectors. To use it, create a tool similar to this in the tools.py file: from google.adk.tools.application_integration_tool.application_integration_toolset import ApplicationIntegrationToolset from google.adk.tools.openapi_tool.auth.auth_helpers import dict_to_auth_scheme from google.adk.auth import AuthCredential from google.adk.auth import AuthCredentialTypes from google.adk.auth import OAuth2Auth oauth2_data_google_cloud = { \"type\" : \"oauth2\" , \"flows\" : { \"authorizationCode\" : { \"authorizationUrl\" : \"https://accounts.google.com/o/oauth2/auth\" , \"tokenUrl\" : \"https://oauth2.googleapis.com/token\" , \"scopes\" : { \"https://www.googleapis.com/auth/cloud-platform\" : ( \"View and manage your data across Google Cloud Platform\" \" services\" ), \"https://www.googleapis.com/auth/calendar.readonly\" : \"View your calendars\" }, } }, } oauth_scheme = dict_to_auth_scheme ( oauth2_data_google_cloud ) auth_credential = AuthCredential ( auth_type = AuthCredentialTypes . OAUTH2 , oauth2 = OAuth2Auth ( client_id = \"...\" , #TODO: replace with client_id client_secret = \"...\" , #TODO: replace with client_secret ), ) connector_tool = ApplicationIntegrationToolset ( project = \"test-project\" , # TODO: replace with GCP project of the connection location = \"us-central1\" , #TODO: replace with location of the connection connection = \"test-connection\" , #TODO: replace with connection name entity_operations = { \"Entity_One\" : [ \"LIST\" , \"CREATE\" ], \"Entity_Two\" : []}, #empty list for actions means all operations on the entity are supported. actions = [ \"GET_calendars/%7BcalendarId%7D/events\" ], #TODO: replace with actions. this one is for list events service_account_json = '{...}' , # optional. Stringified json for service account key tool_name_prefix = \"tool_prefix2\" , tool_instructions = \"...\" , auth_scheme = oauth_scheme , auth_credential = auth_credential ) Update the agent.py file and add tool to your agent: from google.adk.agents.llm_agent import LlmAgent from .tools import connector_tool root_agent = LlmAgent ( model = 'gemini-2.0-flash' , name = 'connector_agent' , instruction = \"Help user, leverage the tools you have access to\" , tools = [ connector_tool ], ) Configure __init__.py to expose your agent: from . import agent Start the Google ADK Web UI and use your agent: # make sure to run `adk web` from your project_root_folder adk web After completing the above steps, go to http://localhost:8000 , and choose my\\_agent agent (which is the same as the agent folder name). ", "code_blocks": [{"language": "text", "code": "from google.adk.tools.application_integration_tool.application_integration_toolset import ApplicationIntegrationToolset\n\nconnector_tool = ApplicationIntegrationToolset(\n    project=\"test-project\", # TODO: replace with GCP project of the connection\n    location=\"us-central1\", #TODO: replace with location of the connection\n    connection=\"test-connection\", #TODO: replace with connection name\n    entity_operations={\"Entity_One\": [\"LIST\",\"CREATE\"], \"Entity_Two\": []},#empty list for actions means all operations on the entity are supported.\n    actions=[\"action1\"], #TODO: replace with actions\n    service_account_json='{...}', # optional. Stringified json for service account key\n    tool_name_prefix=\"tool_prefix2\",\n    tool_instructions=\"...\"\n)"}, {"language": "text", "code": "from google.adk.tools.application_integration_tool.application_integration_toolset import ApplicationIntegrationToolset\nfrom google.adk.tools.openapi_tool.auth.auth_helpers import dict_to_auth_scheme\nfrom google.adk.auth import AuthCredential\nfrom google.adk.auth import AuthCredentialTypes\nfrom google.adk.auth import OAuth2Auth\n\noauth2_data_google_cloud = {\n  \"type\": \"oauth2\",\n  \"flows\": {\n      \"authorizationCode\": {\n          \"authorizationUrl\": \"https://accounts.google.com/o/oauth2/auth\",\n          \"tokenUrl\": \"https://oauth2.googleapis.com/token\",\n          \"scopes\": {\n              \"https://www.googleapis.com/auth/cloud-platform\": (\n                  \"View and manage your data across Google Cloud Platform\"\n                  \" services\"\n              ),\n              \"https://www.googleapis.com/auth/calendar.readonly\": \"View your calendars\"\n          },\n      }\n  },\n}\n\noauth_scheme = dict_to_auth_scheme(oauth2_data_google_cloud)\n\nauth_credential = AuthCredential(\n  auth_type=AuthCredentialTypes.OAUTH2,\n  oauth2=OAuth2Auth(\n      client_id=\"...\", #TODO: replace with client_id\n      client_secret=\"...\", #TODO: replace with client_secret\n  ),\n)\n\nconnector_tool = ApplicationIntegrationToolset(\n    project=\"test-project\", # TODO: replace with GCP project of the connection\n    location=\"us-central1\", #TODO: replace with location of the connection\n    connection=\"test-connection\", #TODO: replace with connection name\n    entity_operations={\"Entity_One\": [\"LIST\",\"CREATE\"], \"Entity_Two\": []},#empty list for actions means all operations on the entity are supported.\n    actions=[\"GET_calendars/%7BcalendarId%7D/events\"], #TODO: replace with actions. this one is for list events\n    service_account_json='{...}', # optional. Stringified json for service account key\n    tool_name_prefix=\"tool_prefix2\",\n    tool_instructions=\"...\",\n    auth_scheme=oauth_scheme,\n    auth_credential=auth_credential\n)"}, {"language": "text", "code": "from google.adk.agents.llm_agent import LlmAgent\nfrom .tools import connector_tool\n\nroot_agent = LlmAgent(\n    model='gemini-2.0-flash',\n    name='connector_agent',\n    instruction=\"Help user, leverage the tools you have access to\",\n    tools=[connector_tool],\n)"}, {"language": "text", "code": "from . import agent"}, {"language": "text", "code": "# make sure to run `adk web` from your project_root_folder\nadk web"}]}, {"heading_path": ["Use Application Integration Workflows\u00b6"], "text": "Use Application Integration Workflows \u00b6 Use an existing Application Integration workflow as a tool for your agent or create a new one. ", "code_blocks": []}, {"heading_path": ["1. Create a tool\u00b6"], "text": "1. Create a tool \u00b6 Python Java To create a tool with ApplicationIntegrationToolset in the tools.py file, use the following code: integration_tool = ApplicationIntegrationToolset ( project = \"test-project\" , # TODO: replace with GCP project of the connection location = \"us-central1\" , #TODO: replace with location of the connection integration = \"test-integration\" , #TODO: replace with integration name triggers = [ \"api_trigger/test_trigger\" ], #TODO: replace with trigger id(s). Empty list would mean all api triggers in the integration to be considered. service_account_json = '{...}' , #optional. Stringified json for service account key tool_name_prefix = \"tool_prefix1\" , tool_instructions = \"...\" ) Note: You can provide a service account to be used instead of using default credentials. To do this, generate a Service Account Key and provide the correct Application Integration and Integration Connector IAM roles to the service account. For more details about the IAM roles, refer to the Prerequisites section. To create a tool with ApplicationIntegrationToolset in the tools.java file, use the following code: import com.google.adk.tools.applicationintegrationtoolset.ApplicationIntegrationToolset ; import com.google.common.collect.ImmutableList ; import com.google.common.collect.ImmutableMap ; public class Tools { private static ApplicationIntegrationToolset integrationTool ; private static ApplicationIntegrationToolset connectionsTool ; static { integrationTool = new ApplicationIntegrationToolset ( \"test-project\" , \"us-central1\" , \"test-integration\" , ImmutableList . of ( \"api_trigger/test-api\" ), null , null , null , \"{...}\" , \"tool_prefix1\" , \"...\" ); connectionsTool = new ApplicationIntegrationToolset ( \"test-project\" , \"us-central1\" , null , null , \"test-connection\" , ImmutableMap . of ( \"Issue\" , ImmutableList . of ( \"GET\" )), ImmutableList . of ( \"ExecuteCustomQuery\" ), \"{...}\" , \"tool_prefix\" , \"...\" ); } } Note: You can provide a service account to be used instead of using default credentials. To do this, generate a Service Account Key and provide the correct Application Integration and Integration Connector IAM roles to the service account. For more details about the IAM roles, refer to the Prerequisites section. ", "code_blocks": [{"language": "text", "code": "integration_tool = ApplicationIntegrationToolset(\n        project=\"test-project\", # TODO: replace with GCP project of the connection\n        location=\"us-central1\", #TODO: replace with location of the connection\n        integration=\"test-integration\", #TODO: replace with integration name\n        triggers=[\"api_trigger/test_trigger\"],#TODO: replace with trigger id(s). Empty list would mean all api triggers in the integration to be considered.\n        service_account_json='{...}', #optional. Stringified json for service account key\n        tool_name_prefix=\"tool_prefix1\",\n        tool_instructions=\"...\"\n    )"}, {"language": "text", "code": "import com.google.adk.tools.applicationintegrationtoolset.ApplicationIntegrationToolset;\n    import com.google.common.collect.ImmutableList;\n    import com.google.common.collect.ImmutableMap;\n\n    public class Tools {\n        private static ApplicationIntegrationToolset integrationTool;\n        private static ApplicationIntegrationToolset connectionsTool;\n\n        static {\n            integrationTool = new ApplicationIntegrationToolset(\n                    \"test-project\",\n                    \"us-central1\",\n                    \"test-integration\",\n                    ImmutableList.of(\"api_trigger/test-api\"),\n                    null,\n                    null,\n                    null,\n                    \"{...}\",\n                    \"tool_prefix1\",\n                    \"...\");\n\n            connectionsTool = new ApplicationIntegrationToolset(\n                    \"test-project\",\n                    \"us-central1\",\n                    null,\n                    null,\n                    \"test-connection\",\n                    ImmutableMap.of(\"Issue\", ImmutableList.of(\"GET\")),\n                    ImmutableList.of(\"ExecuteCustomQuery\"),\n                    \"{...}\",\n                    \"tool_prefix\",\n                    \"...\");\n        }\n    }"}]}, {"heading_path": ["2. Add the tool to your agent\u00b6"], "text": "2. Add the tool to your agent \u00b6 Python Java To update the agent.py file and add the tool to your agent, use the following code: from google.adk.agents.llm_agent import LlmAgent from .tools import integration_tool , connector_tool root_agent = LlmAgent ( model = 'gemini-2.0-flash' , name = 'integration_agent' , instruction = \"Help user, leverage the tools you have access to\" , tools = [ integration_tool ], ) To update the agent.java file and add the tool to your agent, use the following code: ```java\n      import com.google.adk.agent.LlmAgent;\n      import com.google.adk.tools.BaseTool;\n      import com.google.common.collect.ImmutableList; public class MyAgent {\n        public static void main(String[] args) {\n            // Assuming Tools class is defined as in the previous step\n            ImmutableList<BaseTool> tools = ImmutableList.<BaseTool>builder()\n                    .add(Tools.integrationTool)\n                    .add(Tools.connectionsTool)\n                    .build();\n\n            // Finally, create your agent with the tools generated automatically.\n            LlmAgent rootAgent = LlmAgent.builder()\n                    .name(\"science-teacher\")\n                    .description(\"Science teacher agent\")\n                    .model(\"gemini-2.0-flash\")\n                    .instruction(\n                            \"Help user, leverage the tools you have access to.\"\n                    )\n                    .tools(tools)\n                    .build();\n\n            // You can now use rootAgent to interact with the LLM\n            // For example, you can start a conversation with the agent.\n        }\n    }\n``` Note: To find the list of supported entities and actions for a\n        connection, use these Connector APIs: listActions , listEntityTypes . ", "code_blocks": [{"language": "text", "code": "from google.adk.agents.llm_agent import LlmAgent\n    from .tools import integration_tool, connector_tool\n\n    root_agent = LlmAgent(\n        model='gemini-2.0-flash',\n        name='integration_agent',\n        instruction=\"Help user, leverage the tools you have access to\",\n        tools=[integration_tool],\n    )"}, {"language": "text", "code": "public class MyAgent {\n        public static void main(String[] args) {\n            // Assuming Tools class is defined as in the previous step\n            ImmutableList<BaseTool> tools = ImmutableList.<BaseTool>builder()\n                    .add(Tools.integrationTool)\n                    .add(Tools.connectionsTool)\n                    .build();\n\n            // Finally, create your agent with the tools generated automatically.\n            LlmAgent rootAgent = LlmAgent.builder()\n                    .name(\"science-teacher\")\n                    .description(\"Science teacher agent\")\n                    .model(\"gemini-2.0-flash\")\n                    .instruction(\n                            \"Help user, leverage the tools you have access to.\"\n                    )\n                    .tools(tools)\n                    .build();\n\n            // You can now use rootAgent to interact with the LLM\n            // For example, you can start a conversation with the agent.\n        }\n    }\n```"}]}, {"heading_path": ["3. Expose your agent\u00b6"], "text": "3. Expose your agent \u00b6 Python To configure __init__.py to expose your agent, use the following code: from . import agent ", "code_blocks": [{"language": "text", "code": "from . import agent"}]}, {"heading_path": ["4. Use your agent\u00b6"], "text": "4. Use your agent \u00b6 Python Java To start the Google ADK Web UI and use your agent, use the following commands: # make sure to run `adk web` from your project_root_folder adk web After completing the above steps, go to http://localhost:8000 , and choose the my_agent agent (which is the same as the agent folder name). To start the Google ADK Web UI and use your agent, use the following commands: mvn install mvn exec:java \\ -Dexec.mainClass = \"com.google.adk.web.AdkWebServer\" \\ -Dexec.args = \"--adk.agents.source-dir=src/main/java\" \\ -Dexec.classpathScope = \"compile\" After completing the above steps, go to http://localhost:8000 , and choose the my_agent agent (which is the same as the agent folder name). Back to top ", "code_blocks": [{"language": "text", "code": "# make sure to run `adk web` from your project_root_folder\n    adk web"}, {"language": "text", "code": "mvn install\n\n    mvn exec:java \\\n        -Dexec.mainClass=\"com.google.adk.web.AdkWebServer\" \\\n        -Dexec.args=\"--adk.agents.source-dir=src/main/java\" \\\n        -Dexec.classpathScope=\"compile\""}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:11.273529", "source_type": "adk-docs"}
{"doc_id": "3b59f5309d72cb865bd9eb33c187c419bdeec54c13358771739d123dde4918e2", "url": "https://google.github.io/adk-docs/tools/google-cloud/mcp-toolbox-for-databases", "title": "MCP Toolbox for Databases - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["MCP Toolbox for Databases\u00b6"], "text": "MCP Toolbox for Databases \u00b6 Supported in ADK Python Go MCP Toolbox for Databases is an\nopen source MCP server for databases. It was designed with enterprise-grade and\nproduction-quality in mind. It enables you to develop tools easier, faster, and\nmore securely by handling the complexities such as connection pooling,\nauthentication, and more. Google\u2019s Agent Development Kit (ADK) has built in support for Toolbox. For more\ninformation on getting started or configuring Toolbox, see the documentation . ", "code_blocks": []}, {"heading_path": ["Supported Data Sources\u00b6"], "text": "Supported Data Sources \u00b6 MCP Toolbox provides out-of-the-box toolsets for the following databases and data platforms: ", "code_blocks": []}, {"heading_path": ["Google Cloud\u00b6"], "text": "Google Cloud \u00b6 BigQuery (including tools for SQL execution, schema discovery, and AI-powered time series forecasting) AlloyDB (PostgreSQL-compatible, with tools for both standard queries and natural language queries) AlloyDB Admin Spanner (supporting both GoogleSQL and PostgreSQL dialects) Cloud SQL (with dedicated support for Cloud SQL for PostgreSQL , Cloud SQL for MySQL , and Cloud SQL for SQL Server ) Cloud SQL Admin Firestore Bigtable Dataplex (for data discovery and metadata search) Cloud Monitoring ", "code_blocks": []}, {"heading_path": ["Relational & SQL Databases\u00b6"], "text": "Relational & SQL Databases \u00b6 PostgreSQL (generic) MySQL (generic) Microsoft SQL Server (generic) ClickHouse TiDB OceanBase Firebird SQLite YugabyteDB ", "code_blocks": []}, {"heading_path": ["NoSQL & Key-Value Stores\u00b6"], "text": "NoSQL & Key-Value Stores \u00b6 MongoDB Couchbase Redis Valkey Cassandra ", "code_blocks": []}, {"heading_path": ["Graph Databases\u00b6"], "text": "Graph Databases \u00b6 Neo4j (with tools for Cypher queries and schema inspection) Dgraph ", "code_blocks": []}, {"heading_path": ["Data Platforms & Federation\u00b6"], "text": "Data Platforms & Federation \u00b6 Looker (for running Looks, queries, and building dashboards via the Looker API) Trino (for running federated queries across multiple sources) ", "code_blocks": []}, {"heading_path": ["Other\u00b6"], "text": "Other \u00b6 HTTP ", "code_blocks": []}, {"heading_path": ["Configure and deploy\u00b6"], "text": "Configure and deploy \u00b6 Toolbox is an open source server that you deploy and manage yourself. For more\ninstructions on deploying and configuring, see the official Toolbox\ndocumentation: Installing the Server Configuring Toolbox ", "code_blocks": []}, {"heading_path": ["Install Client SDK for ADK\u00b6"], "text": "Install Client SDK for ADK \u00b6 Python Go ADK relies on the toolbox-core python package to use Toolbox. Install the\npackage before getting started: pip install toolbox-core ", "code_blocks": [{"language": "text", "code": "pip install toolbox-core"}]}, {"heading_path": ["Loading Toolbox Tools\u00b6"], "text": "Loading Toolbox Tools \u00b6 Once you\u2019re Toolbox server is configured and up and running, you can load tools\nfrom your server using ADK: from google.adk.agents import Agent from toolbox_core import ToolboxSyncClient toolbox = ToolboxSyncClient ( \"https://127.0.0.1:5000\" ) # Load a specific set of tools tools = toolbox . load_toolset ( 'my-toolset-name' ), # Load single tool tools = toolbox . load_tool ( 'my-tool-name' ), root_agent = Agent ( ... , tools = tools # Provide the list of tools to the Agent ) ADK relies on the mcp-toolbox-sdk-go go module to use Toolbox. Install the\nmodule before getting started: go get github.com/googleapis/mcp-toolbox-sdk-go ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom toolbox_core import ToolboxSyncClient\n\ntoolbox = ToolboxSyncClient(\"https://127.0.0.1:5000\")\n\n# Load a specific set of tools\ntools = toolbox.load_toolset('my-toolset-name'),\n# Load single tool\ntools = toolbox.load_tool('my-tool-name'),\n\nroot_agent = Agent(\n    ...,\n    tools=tools # Provide the list of tools to the Agent\n\n)"}, {"language": "text", "code": "go get github.com/googleapis/mcp-toolbox-sdk-go"}]}, {"heading_path": ["Loading Toolbox Tools\u00b6"], "text": "Loading Toolbox Tools \u00b6 Once you\u2019re Toolbox server is configured and up and running, you can load tools\nfrom your server using ADK: package main import ( \"context\" \"fmt\" \"github.com/googleapis/mcp-toolbox-sdk-go/tbadk\" \"google.golang.org/adk/agent/llmagent\" ) func main () { toolboxClient , err := tbadk . NewToolboxClient ( \"https://127.0.0.1:5000\" ) if err != nil { log . Fatalf ( \"Failed to create MCP Toolbox client: %v\" , err ) } // Load a specific set of tools toolboxtools , err := toolboxClient . LoadToolset ( \"my-toolset-name\" , ctx ) if err != nil { return fmt . Sprintln ( \"Could not load Toolbox Toolset\" , err ) } toolsList := make ([] tool . Tool , len ( toolboxtools )) for i := range toolboxtools { toolsList [ i ] = & toolboxtools [ i ] } llmagent , err := llmagent . New ( llmagent . Config { ... , Tools : toolsList , }) // Load a single tool tool , err := client . LoadTool ( \"my-tool-name\" , ctx ) if err != nil { return fmt . Sprintln ( \"Could not load Toolbox Tool\" , err ) } llmagent , err := llmagent . New ( llmagent . Config { ... , Tools : [] tool . Tool { & toolboxtool }, }) } ", "code_blocks": [{"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/googleapis/mcp-toolbox-sdk-go/tbadk\"\n    \"google.golang.org/adk/agent/llmagent\"\n)\n\nfunc main() {\n\n  toolboxClient, err := tbadk.NewToolboxClient(\"https://127.0.0.1:5000\")\n    if err != nil {\n        log.Fatalf(\"Failed to create MCP Toolbox client: %v\", err)\n    }\n\n  // Load a specific set of tools\n  toolboxtools, err := toolboxClient.LoadToolset(\"my-toolset-name\", ctx)\n  if err != nil {\n    return fmt.Sprintln(\"Could not load Toolbox Toolset\", err)\n  }\n\n  toolsList := make([]tool.Tool, len(toolboxtools))\n    for i := range toolboxtools {\n      toolsList[i] = &toolboxtools[i]\n    }\n\n  llmagent, err := llmagent.New(llmagent.Config{\n    ...,\n    Tools:       toolsList,\n  })\n\n  // Load a single tool\n  tool, err := client.LoadTool(\"my-tool-name\", ctx)\n  if err != nil {\n    return fmt.Sprintln(\"Could not load Toolbox Tool\", err)\n  }\n\n  llmagent, err := llmagent.New(llmagent.Config{\n    ...,\n    Tools:       []tool.Tool{&toolboxtool},\n  })\n}"}]}, {"heading_path": ["Advanced Toolbox Features\u00b6"], "text": "Advanced Toolbox Features \u00b6 Toolbox has a variety of features to make developing Gen AI tools for databases.\nFor more information, read more about the following features: Authenticated Parameters : bind tool inputs to values from OIDC tokens automatically, making it easy to run sensitive queries without potentially leaking data Authorized Invocations: restrict access to use a tool based on the users Auth token OpenTelemetry : get metrics and tracing from Toolbox with OpenTelemetry Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:11.726691", "source_type": "adk-docs"}
{"doc_id": "d85e39faa283c4a29b12ffdc1eb08cc2b928ecca9486fc46092cc1e152698877", "url": "https://google.github.io/adk-docs/tools/google-cloud/bigquery-agent-analytics", "title": "BigQuery Agent Analytics - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["BigQuery Agent Analytics Plugin\u00b6"], "text": "BigQuery Agent Analytics Plugin \u00b6 Supported in ADK Python v1.18.0 Preview Availability To try this plugin, it is recommended to build ADK from the Top of the tree or wait for the official \nrelease of version 1.19. This note will be removed once version 1.19 is out. The BigQuery Agent Analytics Plugin significantly enhances the Agent Development Kit (ADK) by providing a robust solution for in-depth agent behavior analysis. Using the ADK Plugin architecture and the BigQuery Storage Write API, it captures and logs critical operational events directly into a Google BigQuery table, empowering you with advanced capabilities for debugging, real-time monitoring, and comprehensive offline performance evaluation. Preview release The BigQuery Agent Analytics Plugin is in Preview release. For more\ninformation, see the launch stage descriptions . BigQuery Storage Write API This feature uses BigQuery Storage Write API , which is a paid service.\nFor information on costs, see the BigQuery documentation . ", "code_blocks": []}, {"heading_path": ["Use cases\u00b6"], "text": "Use cases \u00b6 Agent workflow debugging and analysis: Capture a wide range of plugin lifecycle events (LLM calls, tool usage) and agent-yielded\n    events (user input, model responses), into a well-defined schema. High-volume analysis and debugging: Logging operations are performed\n    asynchronously in a separate thread to avoid blocking the main agent\n    execution. Designed to handle high event volumes, the plugin preserves\n    event order via timestamps. The agent event data recorded varies based on the ADK event type. For more\ninformation, see Event types and payloads . ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Google Cloud Project with the BigQuery API enabled. BigQuery Dataset: Create a dataset to store logging tables before\n    using the plugin. The plugin automatically would create the necessary events table within the dataset if the table does not exist. By default, this table is named agent_events, while you can customize this with the table_id parameter in the plugin configuration. Authentication: Local: Run gcloud auth application-default login . Cloud: Ensure your service account has the required permissions. ", "code_blocks": []}, {"heading_path": ["IAM permissions\u00b6"], "text": "IAM permissions \u00b6 For the agent to work properly, the principal (e.g., service account, user account) under which the agent is running needs these Google Cloud roles:\n* roles/bigquery.jobUser at Project Level to run BigQuery queries in your project. This role doesn't grant access to any data on its own.\n* roles/bigquery.dataEditor at Table Level to write log/event data to a BigQuery Table of your choice.\nIf you need the agent to create this table, you need to grant the roles/bigquery.dataEditor on the BigQuery dataset where you want the table to be created. ", "code_blocks": []}, {"heading_path": ["Use with agent\u00b6"], "text": "Use with agent \u00b6 You use the BigQuery Analytics Plugin by configuring and registering it with\nyour ADK agent's App object. The following example shows an implementation of an\nagent with this plugin and BigQuery tools enabled: my_bq_agent/agent.py # my_bq_agent/agent.py import os import google.auth from google.adk.apps import App from google.adk.plugins.bigquery_agent_analytics_plugin import BigQueryAgentAnalyticsPlugin from google.adk.agents import Agent from google.adk.models.google_llm import Gemini from google.adk.tools.bigquery import BigQueryToolset , BigQueryCredentialsConfig # --- Configuration --- PROJECT_ID = os . environ . get ( \"GOOGLE_CLOUD_PROJECT\" , \"your-gcp-project-id\" ) DATASET_ID = os . environ . get ( \"BIG_QUERY_DATASET_ID\" , \"your-big-query-dataset-id\" ) LOCATION = os . environ . get ( \"GOOGLE_CLOUD_LOCATION\" , \"your-gcp-project-location\" ) # use the location of your google cloud project if PROJECT_ID == \"your-gcp-project-id\" : raise ValueError ( \"Please set GOOGLE_CLOUD_PROJECT or update the code.\" ) if DATASET_ID == \"your-big-query-dataset-id\" : raise ValueError ( \"Please set BIG_QUERY_DATASET_ID or update the code.\" ) if LOCATION == \"your-gcp-project-location\" : raise ValueError ( \"Please set GOOGLE_CLOUD_LOCATION or update the code.\" ) # --- CRITICAL: Set environment variables BEFORE Gemini instantiation --- os . environ [ 'GOOGLE_CLOUD_PROJECT' ] = PROJECT_ID os . environ [ 'GOOGLE_CLOUD_LOCATION' ] = LOCATION os . environ [ 'GOOGLE_GENAI_USE_VERTEXAI' ] = 'True' # Make sure you have Vertex AI API enabled # --- Initialize the Plugin --- bq_logging_plugin = BigQueryAgentAnalyticsPlugin ( project_id = PROJECT_ID , # project_id is required input from user dataset_id = DATASET_ID , # dataset_id is required input from user table_id = \"agent_events\" # Optional: defaults to \"agent_events\". The plugin automatically creates this table if it doesn't exist. ) # --- Initialize Tools and Model --- credentials , _ = google . auth . default ( scopes = [ \"https://www.googleapis.com/auth/cloud-platform\" ]) bigquery_toolset = BigQueryToolset ( credentials_config = BigQueryCredentialsConfig ( credentials = credentials ) ) llm = Gemini ( model = \"gemini-2.5-flash\" , ) root_agent = Agent ( model = llm , name = 'my_bq_agent' , instruction = \"You are a helpful assistant with access to BigQuery tools.\" , tools = [ bigquery_toolset ] ) # --- Create the App --- app = App ( name = \"my_bq_agent\" , root_agent = root_agent , plugins = [ bq_logging_plugin ], # Register the plugin here ) ", "code_blocks": [{"language": "text", "code": "# my_bq_agent/agent.py\nimport os\nimport google.auth\nfrom google.adk.apps import App\nfrom google.adk.plugins.bigquery_agent_analytics_plugin import BigQueryAgentAnalyticsPlugin\nfrom google.adk.agents import Agent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.tools.bigquery import BigQueryToolset, BigQueryCredentialsConfig\n\n# --- Configuration ---\nPROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"your-gcp-project-id\")\nDATASET_ID = os.environ.get(\"BIG_QUERY_DATASET_ID\", \"your-big-query-dataset-id\")\nLOCATION = os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"your-gcp-project-location\") # use the location of your google cloud project\n\nif PROJECT_ID == \"your-gcp-project-id\":\n    raise ValueError(\"Please set GOOGLE_CLOUD_PROJECT or update the code.\")\nif DATASET_ID == \"your-big-query-dataset-id\":\n    raise ValueError(\"Please set BIG_QUERY_DATASET_ID or update the code.\")\nif LOCATION == \"your-gcp-project-location\":\n    raise ValueError(\"Please set GOOGLE_CLOUD_LOCATION or update the code.\")\n\n# --- CRITICAL: Set environment variables BEFORE Gemini instantiation ---\nos.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\nos.environ['GOOGLE_CLOUD_LOCATION'] = LOCATION\nos.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'True' # Make sure you have Vertex AI API enabled\n\n# --- Initialize the Plugin ---\nbq_logging_plugin = BigQueryAgentAnalyticsPlugin(\n    project_id=PROJECT_ID, # project_id is required input from user\n    dataset_id=DATASET_ID, # dataset_id is required input from user\n    table_id=\"agent_events\" # Optional: defaults to \"agent_events\". The plugin automatically creates this table if it doesn't exist.\n)\n\n# --- Initialize Tools and Model ---\ncredentials, _ = google.auth.default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\nbigquery_toolset = BigQueryToolset(\n    credentials_config=BigQueryCredentialsConfig(credentials=credentials)\n)\n\nllm = Gemini(\n    model=\"gemini-2.5-flash\",\n)\n\nroot_agent = Agent(\n    model=llm,\n    name='my_bq_agent',\n    instruction=\"You are a helpful assistant with access to BigQuery tools.\",\n    tools=[bigquery_toolset]\n)\n\n# --- Create the App ---\napp = App(\n    name=\"my_bq_agent\",\n    root_agent=root_agent,\n    plugins=[bq_logging_plugin], # Register the plugin here\n)"}]}, {"heading_path": ["Run and test agent\u00b6"], "text": "Run and test agent \u00b6 Test the plugin by running the agent and making a few requests through the chat\ninterface, such as \u201dtell me what you can do\u201d or  \"List datasets in my cloud project \u201c. These actions create events which are\nrecorded in your Google Cloud project BigQuery instance. Once these events have\nbeen processed, you can view the data for them in the BigQuery Console , using this query SELECT timestamp , event_type , content FROM ` your - gcp - project - id . your - big - query - dataset - id . agent_events ` ORDER BY timestamp DESC LIMIT 20 ; ", "code_blocks": [{"language": "text", "code": "SELECT timestamp, event_type, content\nFROM `your-gcp-project-id.your-big-query-dataset-id.agent_events`\nORDER BY timestamp DESC\nLIMIT 20;"}]}, {"heading_path": ["Configuration options\u00b6"], "text": "Configuration options \u00b6 You can customize the plugin using BigQueryLoggerConfig . enabled ( bool , default: True ): To disable the plugin from logging agent data to the BigQuery table, set this parameter to False. event_allowlist ( Optional[List[str]] , default: None ): A list\n    of event types to log. If None , all events are logged except those in event_denylist . For a comprehensive list of supported event types, refer\n    to the Event types and payloads section. event_denylist ( Optional[List[str]] , default: None ): A list of\n    event types to skip logging. For a comprehensive list of supported event\n    types, refer to the Event types and payloads section. content_formatter ( Optional[Callable[[Any], str]] , default: None ): An optional function to format event content before logging. The\n    following code illustrates how to implement the content formatter. shutdown_timeout ( float , default: 5.0 ): Seconds to wait for\n    logs to flush during shutdown. client_close_timeout ( float , default: 2.0 ): Seconds to wait\n    for the BigQuery client to close. max_content_length ( int , default: 500 ): The maximum length of\n    content parts before truncation. The following code sample shows how to define a configuration for the\nBigQuery Agent Analytics plugin: import json import re from google.adk.plugins.bigquery_agent_analytics_plugin import BigQueryLoggerConfig def redact_dollar_amounts ( event_content : Any ) -> str : \"\"\" Custom formatter to redact dollar amounts (e.g., $600, $12.50) and ensure JSON output if the input is a dict. \"\"\" text_content = \"\" if isinstance ( event_content , dict ): text_content = json . dumps ( event_content ) else : text_content = str ( event_content ) # Regex to find dollar amounts: $ followed by digits, optionally with commas or decimals. # Examples: $600, $1,200.50, $0.99 redacted_content = re . sub ( r '\\$\\d+(?:,\\d {3} )*(?:\\.\\d+)?' , 'xxx' , text_content ) return redacted_content config = BigQueryLoggerConfig ( enabled = True , event_allowlist = [ \"LLM_REQUEST\" , \"LLM_RESPONSE\" ], # Only log these events # event_denylist=[\"TOOL_STARTING\"], # Skip these events shutdown_timeout = 10.0 , # Wait up to 10s for logs to flush on exit client_close_timeout = 2.0 , # Wait up to 2s for BQ client to close max_content_length = 500 , # Truncate content to 500 chars (default) content_formatter = redact_dollar_amounts , # Redact the dollar amounts in the logging content ) plugin = BigQueryAgentAnalyticsPlugin ( ... , config = config ) ", "code_blocks": [{"language": "text", "code": "import json\nimport re\n\nfrom google.adk.plugins.bigquery_agent_analytics_plugin import BigQueryLoggerConfig\n\ndef redact_dollar_amounts(event_content: Any) -> str:\n    \"\"\"\n    Custom formatter to redact dollar amounts (e.g., $600, $12.50)\n    and ensure JSON output if the input is a dict.\n    \"\"\"\n    text_content = \"\"\n    if isinstance(event_content, dict):\n        text_content = json.dumps(event_content)\n    else:\n        text_content = str(event_content)\n\n    # Regex to find dollar amounts: $ followed by digits, optionally with commas or decimals.\n    # Examples: $600, $1,200.50, $0.99\n    redacted_content = re.sub(r'\\$\\d+(?:,\\d{3})*(?:\\.\\d+)?', 'xxx', text_content)\n\n    return redacted_content\n\nconfig = BigQueryLoggerConfig(\n    enabled=True,\n    event_allowlist=[\"LLM_REQUEST\", \"LLM_RESPONSE\"], # Only log these events\n    # event_denylist=[\"TOOL_STARTING\"], # Skip these events\n    shutdown_timeout=10.0, # Wait up to 10s for logs to flush on exit\n    client_close_timeout=2.0, # Wait up to 2s for BQ client to close\n    max_content_length=500, # Truncate content to 500 chars (default)\n    content_formatter=redact_dollar_amounts, # Redact the dollar amounts in the logging content\n\n)\n\nplugin = BigQueryAgentAnalyticsPlugin(..., config=config)"}]}, {"heading_path": ["Schema and production setup\u00b6"], "text": "Schema and production setup \u00b6 The plugin automatically creates the table if it does not exist. However, for\nproduction, we recommend creating the table manually with partitioning and clustering for performance and cost optimization. Recommended DDL: CREATE TABLE ` your - gcp - project - id . adk_agent_logs . agent_events ` ( timestamp TIMESTAMP NOT NULL OPTIONS ( description = \"The UTC time at which the event was logged.\" ), event_type STRING OPTIONS ( description = \"Indicates the type of event being logged (e.g., 'LLM_REQUEST', 'TOOL_COMPLETED').\" ), agent STRING OPTIONS ( description = \"The name of the ADK agent or author associated with the event.\" ), session_id STRING OPTIONS ( description = \"A unique identifier to group events within a single conversation or user session.\" ), invocation_id STRING OPTIONS ( description = \"A unique identifier for each individual agent execution or turn within a session.\" ), user_id STRING OPTIONS ( description = \"The identifier of the user associated with the current session.\" ), content STRING OPTIONS ( description = \"The event-specific data (payload). Format varies by event_type.\" ), error_message STRING OPTIONS ( description = \"Populated if an error occurs during the processing of the event.\" ), is_truncated BOOLEAN OPTIONS ( description = \"Boolean flag indicates if the content field was truncated due to size limits.\" ) ) PARTITION BY DATE ( timestamp ) CLUSTER BY event_type , agent , user_id ; ", "code_blocks": [{"language": "text", "code": "CREATE TABLE `your-gcp-project-id.adk_agent_logs.agent_events`\n(\n  timestamp TIMESTAMP NOT NULL OPTIONS(description=\"The UTC time at which the event was logged.\"),\n  event_type STRING OPTIONS(description=\"Indicates the type of event being logged (e.g., 'LLM_REQUEST', 'TOOL_COMPLETED').\"),\n  agent STRING OPTIONS(description=\"The name of the ADK agent or author associated with the event.\"),\n  session_id STRING OPTIONS(description=\"A unique identifier to group events within a single conversation or user session.\"),\n  invocation_id STRING OPTIONS(description=\"A unique identifier for each individual agent execution or turn within a session.\"),\n  user_id STRING OPTIONS(description=\"The identifier of the user associated with the current session.\"),\n  content STRING OPTIONS(description=\"The event-specific data (payload). Format varies by event_type.\"),\n  error_message STRING OPTIONS(description=\"Populated if an error occurs during the processing of the event.\"),\n  is_truncated BOOLEAN OPTIONS(description=\"Boolean flag indicates if the content field was truncated due to size limits.\")\n)\nPARTITION BY DATE(timestamp)\nCLUSTER BY event_type, agent, user_id;"}]}, {"heading_path": ["Event types and payloads\u00b6"], "text": "Event types and payloads \u00b6 The content column contains a formatted string specific to the event_type .\nThe following table descibes these events and corresponding content. Note All variable content fields (e.g., user input, model response, tool arguments, system prompt) are truncated to max_content_length characters (configured in BigQueryLoggerConfig , default 500) to manage log size. ", "code_blocks": []}, {"heading_path": ["LLM interactions (plugin lifecycle)\u00b6"], "text": "LLM interactions (plugin lifecycle) \u00b6 These events track the raw requests sent to and responses received from the\nLLM. Event Type Trigger Condition Content Format Logic Example Content LLM_REQUEST before_model_callback Model: {model} | Prompt: {prompt} | System Prompt: Model: {model} | Prompt: {formatted_contents} | System Prompt: {system_prompt} | Params: {params} | Available Tools: {tool_names} Model: gemini-2.5-flash | Prompt: user: Model: gemini-flash-2.5| Prompt: user: text: 'Hello'| System Prompt: You are a helpful assistant. | Params: {temperature=1.0} | Available Tools: ['bigquery_tool'] LLM_RESPONSE after_model_callback If Tool Call: Tool Name: {func_names} | Token\nUsage: {usage} **If Text:** `Tool Name: text_response, text: '{text}' | Token Usage:\n{usage}` Tool Name: text_response, text: 'Here is the data.' | Token Usage: {prompt: 10, candidates: 5, total: 15} LLM_ERROR on_model_error_callback None (Error details are in error_message column) None ", "code_blocks": []}, {"heading_path": ["Tool usage (plugin lifecycle)\u00b6"], "text": "Tool usage (plugin lifecycle) \u00b6 These events track the execution of tools by the agent. Event Type Trigger Condition Content Format Logic Example Content TOOL_STARTING before_tool_callback Tool Name: {name}, Description: {desc}, Arguments: {args} Tool Name: list_datasets, Description: Lists datasets..., Arguments: {'project_id': 'my-project'} TOOL_COMPLETED after_tool_callback Tool Name: {name}, Result: {result} Tool Name: list_datasets, Result: ['dataset_1', 'dataset_2'] TOOL_ERROR on_tool_error_callback Tool Name: {name}, Arguments: {args} (Error details in error_message ) Tool Name: list_datasets, Arguments: {} ", "code_blocks": []}, {"heading_path": ["Agent lifecycle (plugin lifecycle)\u00b6"], "text": "Agent lifecycle (plugin lifecycle) \u00b6 These events track the start and end of agent execution, including\nsub-agents. Event Type Trigger Condition Content Format Logic Example Content INVOCATION_STARTING before_run_callback None None INVOCATION_COMPLETED after_run_callback None None AGENT_STARTING before_agent_callback Agent Name: {agent_name} Agent Name: sub_agent_researcher AGENT_COMPLETED after_agent_callback Agent Name: {agent_name} Agent Name: sub_agent_researcher ", "code_blocks": []}, {"heading_path": ["User and generic events (Event stream)\u00b6"], "text": "User and generic events (Event stream) \u00b6 These events are derived from the Event objects yielded by the agent or the\nrunner. Event Type Trigger Condition Content Format Logic Example Content USER_MESSAGE_RECEIVED on_user_message_callback User Content: {formatted_message} User Content: text: 'Show me the sales data.' TOOL_CALL event.get_function_calls() is true call: {func_name} call: list_datasets TOOL_RESULT event.get_function_responses() is true resp: {func_name} resp: list_datasets MODEL_RESPONSE event.content has parts text: '{text}' text: 'I found 2 datasets.' ", "code_blocks": []}, {"heading_path": ["Advanced analysis queries\u00b6"], "text": "Advanced analysis queries \u00b6 The following example queries demonstrate how to extract information from the\nrecorded ADK agent event analytics data in BigQuery. You can run these queries\nusing the BigQuery Console . Before executing these queries, ensure you update the GCP project ID, BigQuery dataset ID, and the table ID (defaulting to \"agent_events\" if unspecified) within the provided SQL. Trace a specific conversation turn SELECT timestamp , event_type , agent , content FROM ` your - gcp - project - id . your - dataset - id . agent_events ` WHERE invocation_id = 'your-invocation-id' ORDER BY timestamp ASC ; Daily invocation volume SELECT DATE ( timestamp ) as log_date , COUNT ( DISTINCT invocation_id ) as count FROM ` your - gcp - project - id . your - dataset - id . agent_events ` WHERE event_type = 'INVOCATION_STARTING' GROUP BY log_date ORDER BY log_date DESC ; Token usage analysis SELECT AVG ( CAST ( REGEXP_EXTRACT ( content , r \"Token Usage:.*total: ([0-9]+)\" ) AS INT64 )) as avg_tokens FROM ` your - gcp - project - id . your - dataset - id . agent_events ` WHERE event_type = 'LLM_RESPONSE' ; Error monitoring SELECT timestamp , event_type , error_message FROM ` your - gcp - project - id . your - dataset - id . agent_events ` WHERE error_message IS NOT NULL ORDER BY timestamp DESC LIMIT 50 ; ", "code_blocks": [{"language": "text", "code": "SELECT timestamp, event_type, agent, content\nFROM `your-gcp-project-id.your-dataset-id.agent_events`\nWHERE invocation_id = 'your-invocation-id'\nORDER BY timestamp ASC;"}, {"language": "text", "code": "SELECT DATE(timestamp) as log_date, COUNT(DISTINCT invocation_id) as count\nFROM `your-gcp-project-id.your-dataset-id.agent_events`\nWHERE event_type = 'INVOCATION_STARTING'\nGROUP BY log_date ORDER BY log_date DESC;"}, {"language": "text", "code": "SELECT\n  AVG(CAST(REGEXP_EXTRACT(content, r\"Token Usage:.*total: ([0-9]+)\") AS INT64)) as avg_tokens\nFROM `your-gcp-project-id.your-dataset-id.agent_events`\nWHERE event_type = 'LLM_RESPONSE';"}, {"language": "text", "code": "SELECT timestamp, event_type, error_message\nFROM `your-gcp-project-id.your-dataset-id.agent_events`\nWHERE error_message IS NOT NULL\nORDER BY timestamp DESC LIMIT 50;"}]}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 BigQuery Storage Write API BigQuery product documentation Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:12.394619", "source_type": "adk-docs"}
{"doc_id": "d57ad5d175a1ca07221a2adfb1479bffe8bc9facf6882c587b3ab71aa2cc7392", "url": "https://google.github.io/adk-docs/tools/google-cloud/code-exec-agent-engine", "title": "Code Execution with Agent Engine - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Code Execution Tool with Agent Engine\u00b6"], "text": "Code Execution Tool with Agent Engine \u00b6 Supported in ADK Python v1.17.0 Preview The Agent Engine Code Execution ADK Tool provides a low-latency, highly\nefficient method for running AI-generated code using the Google Cloud Agent Engine service. This tool is designed for fast execution, tailored for agentic workflows,\nand uses sandboxed environments for improved security. The Code Execution tool \nallows code and data to persist over multiple requests, enabling complex, \nmulti-step coding tasks, including: Code development and debugging: Create agent tasks that test and\n    iterate on versions of code over multiple requests. Code with data analysis: Upload data files up to 100MB, and run\n    multiple code-based analyses without the need to reload data for each code run. This code execution tool is part of the Agent Engine suite, however you do not\nhave to deploy your agent to Agent Engine to use it. You can run your agent\nlocally or with other services and use this tool. For more information about the\nCode Execution feature in Agent Engine, see the Agent Engine Code Execution documentation. Preview release The Agent Engine Code Execution feature is a Preview release. For\nmore information, see the launch stage descriptions . ", "code_blocks": []}, {"heading_path": ["Use the Tool\u00b6"], "text": "Use the Tool \u00b6 Using the Agent Engine Code Execution tool requires that you create a sandbox\nenvironment with Google Cloud Agent Engine before using the tool with an ADK\nagent. To use the Code Execution tool with your ADK agent: Follow the instructions in the Agent Engine Code Execution quickstart to create a code execution sandbox environment. Create an ADK agent with settings to access the Google Cloud project\n    where you created the sandbox environment. The following code example shows an agent configured to use the Code\n    Executor tool. Replace SANDBOX_RESOURCE_NAME with the sandbox environment \n    resource name you created. from google.adk.agents.llm_agent import Agent from google.adk.code_executors.agent_engine_sandbox_code_executor import AgentEngineSandboxCodeExecutor root_agent = Agent ( model = \"gemini-2.5-flash\" , name = \"agent_engine_code_execution_agent\" , instruction = \"You are a helpful agent that can write and execute code to answer questions and solve problems.\" , code_executor = AgentEngineSandboxCodeExecutor ( sandbox_resource_name = \"SANDBOX_RESOURCE_NAME\" , ), ) For details on the expected format of the sandbox_resource_name value, and the\nalternative agent_engine_resource_name parameter, see Configuration\nparameters . For a more advanced example, including\nrecommended system instructions for the tool, see the Advanced\nexample or the full agent code example . ", "code_blocks": [{"language": "text", "code": "from google.adk.agents.llm_agent import Agent\nfrom google.adk.code_executors.agent_engine_sandbox_code_executor import AgentEngineSandboxCodeExecutor\n\nroot_agent = Agent(\n    model=\"gemini-2.5-flash\",\n    name=\"agent_engine_code_execution_agent\",\n    instruction=\"You are a helpful agent that can write and execute code to answer questions and solve problems.\",\n    code_executor=AgentEngineSandboxCodeExecutor(\n        sandbox_resource_name=\"SANDBOX_RESOURCE_NAME\",\n    ),\n)"}]}, {"heading_path": ["How it works\u00b6"], "text": "How it works \u00b6 The AgentEngineCodeExecutor Tool maintains a single sandbox throughout an\nagent's task, meaning the sandbox's state persists across all operations within\nan ADK workflow session. Sandbox creation: For multi-step tasks requiring code execution,\n    the Agent Engine creates a sandbox with specified language and machine\n    configurations, isolating the code execution environment. If no sandbox is\n    pre-created, the code execution tool will automatically create one using\n    default settings. Code execution with persistence: AI-generated code for a tool call\n    is streamed to the sandbox and then executed within the isolated\n    environment. After execution, the sandbox remains active for subsequent\n    tool calls within the same session, preserving variables, imported modules,\n    and file state for the next tool call from the same agent. Result retrieval: The standard output, and any captured error\n    streams are collected and passed back to the calling agent. Sandbox clean up: Once the agent task or conversation concludes, the\n    agent can explicitly delete the sandbox, or rely on the TTL feature of the\n    sandbox specified when creating the sandbox. ", "code_blocks": []}, {"heading_path": ["Key benefits\u00b6"], "text": "Key benefits \u00b6 Persistent state: Solve complex tasks where data manipulation or\n    variable context must carry over between multiple tool calls. Targeted Isolation: Provides robust process-level isolation,\n    ensuring that tool code execution is safe while remaining lightweight. Agent Engine integration: Tightly integrated into the Agent Engine\n    tool-use and orchestration layer. Low-latency performance: Designed for speed, allowing agents to\n    execute complex tool-use workflows efficiently without significant overhead. Flexible compute configurations: Create sandboxes with specific\n    programming language, processing power, and memory configurations. ", "code_blocks": []}, {"heading_path": ["System requirements\u00b6\u00b6"], "text": "System requirements\u00b6 \u00b6 The following requirements must be met to successfully use the Agent Engine\nCode Execution tool with your ADK agents: Google Cloud project with Vertex API enabled Agent's service account requires roles/aiplatform.user role, which\n    allow it to: Create, get, list and delete code execution sandboxes Execute code execution sandbox ", "code_blocks": []}, {"heading_path": ["Configuration parameters\u00b6"], "text": "Configuration parameters \u00b6 The Agent Engine Code Execution tool has the following parameters. You must set\none of the following resource parameters: sandbox_resource_name : A sandbox resource path to an\n    existing sandbox environment it uses for each tool call. The expected\nstring format is as follows: projects/{$PROJECT_ID}/locations/{$LOCATION_ID}/reasoningEngines/{$REASONING_ENGINE_ID}/sandboxEnvironments/{$SANDBOX_ENVIRONMENT_ID} # Example: projects/my-vertex-agent-project/locations/us-central1/reasoningEngines/6842888880301111172/sandboxEnvironments/6545148888889161728 agent_engine_resource_name : Agent Engine resource name where the tool\ncreates a sandbox environment. The expected string format is as follows: projects/{$PROJECT_ID}/locations/{$LOCATION_ID}/reasoningEngines/{$REASONING_ENGINE_ID} # Example: projects/my-vertex-agent-project/locations/us-central1/reasoningEngines/6842888880301111172 You can use Google Cloud Agent Engine's API to configure Agent Engine sandbox\nenvironments separately using a Google Cloud client connection, including the\nfollowing settings: Programming languages, including Python and JavaScript Compute environment , including CPU and memory sizes For more information on connecting to Google Cloud Agent Engine and configuring\nsandbox environments, see the Agent Engine Code Execution quickstart . ", "code_blocks": [{"language": "text", "code": "projects/{$PROJECT_ID}/locations/{$LOCATION_ID}/reasoningEngines/{$REASONING_ENGINE_ID}/sandboxEnvironments/{$SANDBOX_ENVIRONMENT_ID}\n\n# Example:\nprojects/my-vertex-agent-project/locations/us-central1/reasoningEngines/6842888880301111172/sandboxEnvironments/6545148888889161728"}, {"language": "text", "code": "projects/{$PROJECT_ID}/locations/{$LOCATION_ID}/reasoningEngines/{$REASONING_ENGINE_ID}\n\n# Example:\nprojects/my-vertex-agent-project/locations/us-central1/reasoningEngines/6842888880301111172"}]}, {"heading_path": ["Advanced example\u00b6"], "text": "Advanced example \u00b6 The following example code shows how to implement use of the Code Executor tool\nin an ADK agent. This example includes a base_system_instruction clause to set\nthe operating guidelines for code execution. This instruction clause is\noptional, but strongly recommended for getting the best results from this tool. from google.adk.agents.llm_agent import Agent from google.adk.code_executors.agent_engine_sandbox_code_executor import AgentEngineSandboxCodeExecutor def base_system_instruction (): \"\"\"Returns: data science agent system instruction.\"\"\" return \"\"\" # Guidelines **Objective:** Assist the user in achieving their data analysis goals, **with emphasis on avoiding assumptions and ensuring accuracy.** Reaching that goal can involve multiple steps. When you need to generate code, you **don't** need to solve the goal in one go. Only generate the next step at a time. **Code Execution:** All code snippets provided will be executed within the sandbox environment. **Statefulness:** All code snippets are executed and the variables stays in the environment. You NEVER need to re-initialize variables. You NEVER need to reload files. You NEVER need to re-import libraries. **Output Visibility:** Always print the output of code execution to visualize results, especially for data exploration and analysis. For example: - To look a the shape of a pandas.DataFrame do: ```tool_code print(df.shape) ``` The output will be presented to you as: ```tool_outputs (49, 7) ``` - To display the result of a numerical computation: ```tool_code x = 10 ** 9 - 12 ** 5 print(f'{{x=}}') ``` The output will be presented to you as: ```tool_outputs x=999751168 ``` - You **never** generate ```tool_outputs yourself. - You can then use this output to decide on next steps. - Print just variables (e.g., `print(f'{{variable=}}')`. **No Assumptions:** **Crucially, avoid making assumptions about the nature of the data or column names.** Base findings solely on the data itself. Always use the information obtained from `explore_df` to guide your analysis. **Available files:** Only use the files that are available as specified in the list of available files. **Data in prompt:** Some queries contain the input data directly in the prompt. You have to parse that data into a pandas DataFrame. ALWAYS parse all the data. NEVER edit the data that are given to you. **Answerability:** Some queries may not be answerable with the available data. In those cases, inform the user why you cannot process their query and suggest what type of data would be needed to fulfill their request. \"\"\" root_agent = Agent ( model = \"gemini-2.5-flash\" , name = \"agent_engine_code_execution_agent\" , instruction = base_system_instruction () + \"\"\" You need to assist the user with their queries by looking at the data and the context in the conversation. You final answer should summarize the code and code execution relevant to the user query. You should include all pieces of data to answer the user query, such as the table from code execution results. If you cannot answer the question directly, you should follow the guidelines above to generate the next step. If the question can be answered directly with writing any code, you should do that. If you doesn't have enough data to answer the question, you should ask for clarification from the user. You should NEVER install any package on your own like `pip install ...`. When plotting trends, you should make sure to sort and order the data by the x-axis. \"\"\" , code_executor = AgentEngineSandboxCodeExecutor ( # Replace with your sandbox resource name if you already have one. sandbox_resource_name = \"SANDBOX_RESOURCE_NAME\" , # Replace with agent engine resource name used for creating sandbox if # sandbox_resource_name is not set: # agent_engine_resource_name=\"AGENT_ENGINE_RESOURCE_NAME\", ), ) For a complete version of an ADK agent using this example code, see the agent_engine_code_execution sample . Back to top ", "code_blocks": [{"language": "text", "code": "from google.adk.agents.llm_agent import Agent\nfrom google.adk.code_executors.agent_engine_sandbox_code_executor import AgentEngineSandboxCodeExecutor\n\ndef base_system_instruction():\n  \"\"\"Returns: data science agent system instruction.\"\"\"\n\n  return \"\"\"\n  # Guidelines\n\n  **Objective:** Assist the user in achieving their data analysis goals, **with emphasis on avoiding assumptions and ensuring accuracy.** Reaching that goal can involve multiple steps. When you need to generate code, you **don't** need to solve the goal in one go. Only generate the next step at a time.\n\n  **Code Execution:** All code snippets provided will be executed within the sandbox environment.\n\n  **Statefulness:** All code snippets are executed and the variables stays in the environment. You NEVER need to re-initialize variables. You NEVER need to reload files. You NEVER need to re-import libraries.\n\n  **Output Visibility:** Always print the output of code execution to visualize results, especially for data exploration and analysis. For example:\n    - To look a the shape of a pandas.DataFrame do:\n      ```tool_code\n      print(df.shape)\n      ```\n      The output will be presented to you as:\n      ```tool_outputs\n      (49, 7)\n\n      ```\n    - To display the result of a numerical computation:\n      ```tool_code\n      x = 10 ** 9 - 12 ** 5\n      print(f'{{x=}}')\n      ```\n      The output will be presented to you as:\n      ```tool_outputs\n      x=999751168\n\n      ```\n    - You **never** generate ```tool_outputs yourself.\n    - You can then use this output to decide on next steps.\n    - Print just variables (e.g., `print(f'{{variable=}}')`.\n\n  **No Assumptions:** **Crucially, avoid making assumptions about the nature of the data or column names.** Base findings solely on the data itself. Always use the information obtained from `explore_df` to guide your analysis.\n\n  **Available files:** Only use the files that are available as specified in the list of available files.\n\n  **Data in prompt:** Some queries contain the input data directly in the prompt. You have to parse that data into a pandas DataFrame. ALWAYS parse all the data. NEVER edit the data that are given to you.\n\n  **Answerability:** Some queries may not be answerable with the available data. In those cases, inform the user why you cannot process their query and suggest what type of data would be needed to fulfill their request.\n\n  \"\"\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-flash\",\n    name=\"agent_engine_code_execution_agent\",\n    instruction=base_system_instruction() + \"\"\"\n\n\nYou need to assist the user with their queries by looking at the data and the context in the conversation.\nYou final answer should summarize the code and code execution relevant to the user query.\n\nYou should include all pieces of data to answer the user query, such as the table from code execution results.\nIf you cannot answer the question directly, you should follow the guidelines above to generate the next step.\nIf the question can be answered directly with writing any code, you should do that.\nIf you doesn't have enough data to answer the question, you should ask for clarification from the user.\n\nYou should NEVER install any package on your own like `pip install ...`.\nWhen plotting trends, you should make sure to sort and order the data by the x-axis.\n\n\n\"\"\",\n    code_executor=AgentEngineSandboxCodeExecutor(\n        # Replace with your sandbox resource name if you already have one.\n        sandbox_resource_name=\"SANDBOX_RESOURCE_NAME\",\n        # Replace with agent engine resource name used for creating sandbox if\n        # sandbox_resource_name is not set:\n        # agent_engine_resource_name=\"AGENT_ENGINE_RESOURCE_NAME\",\n    ),\n)"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:12.733877", "source_type": "adk-docs"}
{"doc_id": "62f7afa645dab121b150bb722095c252155b8c7f5e3342c851a46844e7e65998", "url": "https://google.github.io/adk-docs/tools/third-party", "title": "Third-Party Tools - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Third-Party Tools\u00b6"], "text": "Third-Party Tools \u00b6 Check out the following third-party tools that you can use with ADK agents: ", "code_blocks": []}, {"heading_path": ["AgentQL"], "text": "AgentQL Extract resilient, structured web data using natural language ", "code_blocks": []}, {"heading_path": ["Bright Data"], "text": "Bright Data One MCP for the web - connect your AI to real web data ", "code_blocks": []}, {"heading_path": ["Browserbase"], "text": "Browserbase Powers web browsing capabilities for AI agents ", "code_blocks": []}, {"heading_path": ["Exa"], "text": "Exa Search and extract structured content from websites and live data ", "code_blocks": []}, {"heading_path": ["Firecrawl"], "text": "Firecrawl Empower your AI apps with clean data from any website ", "code_blocks": []}, {"heading_path": ["GitHub"], "text": "GitHub Analyze code, manage issues and PRs, and automate workflows ", "code_blocks": []}, {"heading_path": ["Hugging Face"], "text": "Hugging Face Access models, datasets, research papers, and AI tools ", "code_blocks": []}, {"heading_path": ["Notion"], "text": "Notion Search workspaces, create pages, and manage tasks and databases ", "code_blocks": []}, {"heading_path": ["Tavily"], "text": "Tavily Provides real-time web search, extraction, and crawling tools Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:13.220213", "source_type": "adk-docs"}
{"doc_id": "474e3fac62ae9816ed7f8fd73aa486823d244def8a924b181a3a3c142363a106", "url": "https://google.github.io/adk-docs/tools/third-party/agentql", "title": "AgentQL - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["AgentQL\u00b6"], "text": "AgentQL \u00b6 The AgentQL MCP Server connects\nyour ADK agent to AgentQL . AgentQL is a semantic\nextraction engine that queries web elements based on their meaning rather than\ntheir CSS or XPath selectors. This functionality allows agents to retrieve\nspecific data points from web pages, PDFs, and authenticated sessions using\nnatural language definitions. ", "code_blocks": []}, {"heading_path": ["Use cases\u00b6"], "text": "Use cases \u00b6 Resilient Web Extraction : Extract data from dynamic websites using natural\n  language descriptions. This feature allows your agent to reliably gather\n  information from sites that frequently update their layout or CSS without\n  breaking. Data Normalization : Convert unstructured web pages into clean, predictable\n  JSON formats. This capability enables your agent to instantly normalize data\n  from different sources (like multiple job boards or shopping sites) into a\n  single schema. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Create an API Key in AgentQL. Refer to the documentation for more information. ", "code_blocks": []}, {"heading_path": ["Use with agent\u00b6"], "text": "Use with agent \u00b6 Local MCP Server from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from mcp import StdioServerParameters AGENTQL_API_KEY = \"YOUR_AGENTQL_API_KEY\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"agentql_agent\" , instruction = \"Help users get information from AgentQL\" , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = \"npx\" , args = [ \"-y\" , \"agentql-mcp\" , ], env = { \"AGENTQL_API_KEY\" : AGENTQL_API_KEY , } ), timeout = 300 , ), ) ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom mcp import StdioServerParameters\n\nAGENTQL_API_KEY = \"YOUR_AGENTQL_API_KEY\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"agentql_agent\",\n    instruction=\"Help users get information from AgentQL\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"-y\",\n                        \"agentql-mcp\",\n                    ],\n                    env={\n                        \"AGENTQL_API_KEY\": AGENTQL_API_KEY,\n                    }\n                ),\n                timeout=300,\n            ),\n        )\n    ],\n)"}]}, {"heading_path": ["Available tools\u00b6"], "text": "Available tools \u00b6 Tool Description extract-web-data Extract structured data from a given 'url', using 'prompt' as a description of actual data and its fields to extract ", "code_blocks": []}, {"heading_path": ["Best practices\u00b6"], "text": "Best practices \u00b6 To ensure accurate extraction, follow these guidelines when prompting the agent: Describe the data, not the element : Avoid visual descriptions (e.g., \"the\n  blue button\"). Instead, describe the data entity (e.g., \"the submit button\" or\n  \"the product price\"). Define the hierarchy : If extracting a list, explicitly instruct the agent\n  to look for a collection of items and define the fields required for each\n  item. Filter semantically : You can instruct the tool to ignore specific data\n  types (e.g., \"exclude ads and navigation links\") within the prompt itself. ", "code_blocks": []}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 AgentQL MCP Server Documentation AgentQL MCP Server Repository Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:13.956317", "source_type": "adk-docs"}
{"doc_id": "d6bc547b1f62e50be70d4cbe1f5ab216b7156616b478a66470ac226e1f9bd567", "url": "https://google.github.io/adk-docs/tools/third-party/bright-data", "title": "Bright Data - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Bright Data\u00b6"], "text": "Bright Data \u00b6 The Bright Data MCP Server connects your ADK agent to Bright Data's web data platform. This\ntool gives your agent the ability to perform real-time web searches, scrape\nwebpages, extract structured data, control browsers remotely, and access\npre-built data feeds from popular platforms. ", "code_blocks": []}, {"heading_path": ["Use cases\u00b6"], "text": "Use cases \u00b6 Real-Time Web Search : Perform optimized web searches to get up-to-date\n  information in AI-friendly formats (JSON/Markdown). Structured Data Extraction : Use AI-powered extraction to convert any\n  webpage into clean, structured JSON data with optional custom prompts. Browser Automation : Control real browsers remotely for complex\n  interactions, JavaScript rendering, and dynamic content extraction. Pre-Built Data APIs : Access 60+ structured datasets from popular platforms\n  including Amazon, LinkedIn, Instagram, TikTok, Google Maps, and more. Advertisement Analysis : Extract and analyze advertisements from webpages\n  using industry-standard ad blocking filter lists. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Sign up for a Bright Data account to obtain an API\n  token. Refer to the documentation for more\n  information. The server offers a free tier with 5,000 requests/month , which is useful for\n  prototyping and everyday workflows. ", "code_blocks": []}, {"heading_path": ["Use with agent\u00b6"], "text": "Use with agent \u00b6 Local MCP Server Remote MCP Server from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from mcp import StdioServerParameters BRIGHTDATA_API_TOKEN = \"YOUR_BRIGHTDATA_API_TOKEN\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"brightdata_agent\" , instruction = \"Help users access web data using Bright Data\" , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = \"npx\" , args = [ \"@brightdata/mcp\" , ], env = { \"API_TOKEN\" : BRIGHTDATA_API_TOKEN , \"PRO_MODE\" : \"true\" , # Optional: Enable all 60+ tools } ), timeout = 300 , ), ) ], ) from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset BRIGHTDATA_API_TOKEN = \"YOUR_BRIGHTDATA_API_TOKEN\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"brightdata_agent\" , instruction = \"\"\"Help users access web data using Bright Data\"\"\" , tools = [ MCPToolset ( connection_params = StreamableHTTPServerParams ( url = f \"https://mcp.brightdata.com/mcp?token= { BRIGHTDATA_API_TOKEN } \" , ), ) ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom mcp import StdioServerParameters\n\nBRIGHTDATA_API_TOKEN = \"YOUR_BRIGHTDATA_API_TOKEN\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"brightdata_agent\",\n    instruction=\"Help users access web data using Bright Data\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"@brightdata/mcp\",\n                    ],\n                    env={\n                        \"API_TOKEN\": BRIGHTDATA_API_TOKEN,\n                        \"PRO_MODE\": \"true\",  # Optional: Enable all 60+ tools\n                    }\n                ),\n                timeout=300,\n            ),\n        )\n    ],\n)"}, {"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\n\nBRIGHTDATA_API_TOKEN = \"YOUR_BRIGHTDATA_API_TOKEN\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"brightdata_agent\",\n    instruction=\"\"\"Help users access web data using Bright Data\"\"\",\n    tools=[\n        MCPToolset(\n            connection_params=StreamableHTTPServerParams(\n                url=f\"https://mcp.brightdata.com/mcp?token={BRIGHTDATA_API_TOKEN}\",\n            ),\n        )\n    ],\n)"}]}, {"heading_path": ["Example usage\u00b6"], "text": "Example usage \u00b6 Once your agent is set up and running, you can interact with it through the\ncommand-line interface or web interface. Here are some examples: Sample agent prompts: Get me the current price and details of the iPhone 15 Pro on Amazon Search for \"climate change news 2025\" on Google and summarize the top 5\nresults Scrape the homepage of techcrunch.com and extract all article headlines and\nlinks The agent automatically calls the appropriate Bright Data tools to provide\ncomprehensive answers, making it easy to access real-time web data without\nmanual navigation or worrying about getting blocked. ", "code_blocks": []}, {"heading_path": ["Available tools\u00b6"], "text": "Available tools \u00b6 The Bright Data MCP server operates in two modes: ", "code_blocks": []}, {"heading_path": ["Rapid Mode (Free Tier - Default)\u00b6"], "text": "Rapid Mode (Free Tier - Default) \u00b6 Tool Description search_engine Scrape Google, Bing, or Yandex SERPs as JSON or Markdown. scrape_as_markdown Convert webpages into clean Markdown with built-in unblocking. scrape_as_html Return raw HTML from webpages while bypassing blockers. extract Transform Markdown output into structured JSON with custom prompts. session_stats View session usage statistics and tool call counts. ", "code_blocks": []}, {"heading_path": ["Pro Mode (60+ Additional Tools)\u00b6"], "text": "Pro Mode (60+ Additional Tools) \u00b6 Enable Pro Mode by setting PRO_MODE=true in environment variables to access: Batch Operations: - search_engine_batch : Run up to 10 search queries simultaneously.\n- scrape_batch : Scrape up to 10 URLs simultaneously. Browser Automation: - scraping_browser.* : Full browser control for complex interactions.\n- Navigate, click, type, scroll, take screenshots, and more. Web Data APIs (60+ Structured Datasets): E-commerce : web_data_amazon_product , web_data_walmart_product , web_data_ebay_product , web_data_etsy_products , web_data_bestbuy_products , web_data_zara_products Social Media : web_data_linkedin_person_profile , web_data_instagram_profiles , web_data_facebook_posts , web_data_tiktok_profiles , web_data_x_posts , web_data_reddit_posts Business Intelligence : web_data_linkedin_company_profile , web_data_crunchbase_company , web_data_zoominfo_company_profile Search & Reviews : web_data_amazon_product_search , web_data_amazon_product_reviews , web_data_google_maps_reviews , web_data_facebook_company_reviews Maps & Local : web_data_google_maps_reviews , web_data_zillow_properties_listing , web_data_booking_hotel_listings App Stores : web_data_google_play_store , web_data_apple_app_store Media & News : web_data_youtube_videos , web_data_youtube_comments , web_data_reuter_news Developer Tools : web_data_github_repository_file Finance : web_data_yahoo_finance_business All Web Data API tools return cached or fresh structured data in JSON format,\noften more reliable than real-time scraping. ", "code_blocks": []}, {"heading_path": ["Configuration options\u00b6"], "text": "Configuration options \u00b6 The Bright Data MCP server supports several environment variables for\ncustomization: Variable Description Default API_TOKEN Your Bright Data API token (required) - PRO_MODE Enable all 60+ advanced tools false RATE_LIMIT Custom rate limiting (e.g., \"100/1h\", \"50/30m\") No limit WEB_UNLOCKER_ZONE Custom Web Unlocker zone name mcp_unlocker BROWSER_ZONE Custom Browser API zone name mcp_browser ", "code_blocks": []}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 Bright Data MCP Server Documentation Bright Data MCP Server Repository Complete Tool Documentation Example Use Cases Interactive Playground Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:14.378305", "source_type": "adk-docs"}
{"doc_id": "c131cbbf2925251002882bfe94adfc5422201d864c5dab1f765f85f1e93b1ac1", "url": "https://google.github.io/adk-docs/tools/third-party/browserbase", "title": "Browserbase - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Browserbase\u00b6"], "text": "Browserbase \u00b6 The Browserbase MCP Server connects to cloud browser automation capabilities using Browserbase and Stagehand . It enables your ADK agent\nto interact with web pages, take screenshots, extract information, and perform\nautomated actions. ", "code_blocks": []}, {"heading_path": ["Use cases\u00b6"], "text": "Use cases \u00b6 Automated Web Workflows : Empower your agent to perform multi-step tasks\n  like logging into websites, filling out forms, submitting data, and navigating\n  complex user flows. Intelligent Data Extraction : Automatically browse to specific pages and\nextract structured data, text content, or other information for use in your\nagent's tasks. Visual Monitoring & Interaction : Capture full-page or element-specific\nscreenshots to visually monitor websites, test UI elements, or feed visual\ncontext back to a vision-enabled model. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Sign up for a Browserbase account to\n  obtain an API key and project ID. Refer to the documentation for\n  more information. ", "code_blocks": []}, {"heading_path": ["Use with agent\u00b6"], "text": "Use with agent \u00b6 Local MCP Server from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from mcp import StdioServerParameters BROWSERBASE_API_KEY = \"YOUR_BROWSERBASE_API_KEY\" BROWSERBASE_PROJECT_ID = \"YOUR_BROWSERBASE_PROJECT_ID\" GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"browserbase_agent\" , instruction = \"Help users get information from Browserbase\" , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = \"npx\" , args = [ \"-y\" , \"@browserbasehq/mcp-server-browserbase\" , ], env = { \"BROWSERBASE_API_KEY\" : BROWSERBASE_API_KEY , \"BROWSERBASE_PROJECT_ID\" : BROWSERBASE_PROJECT_ID , \"GEMINI_API_KEY\" : GEMINI_API_KEY , } ), timeout = 300 , ), ) ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom mcp import StdioServerParameters\n\nBROWSERBASE_API_KEY = \"YOUR_BROWSERBASE_API_KEY\"\nBROWSERBASE_PROJECT_ID = \"YOUR_BROWSERBASE_PROJECT_ID\"\nGEMINI_API_KEY = \"YOUR_GEMINI_API_KEY\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"browserbase_agent\",\n    instruction=\"Help users get information from Browserbase\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"-y\",\n                        \"@browserbasehq/mcp-server-browserbase\",\n                    ],\n                    env={\n                        \"BROWSERBASE_API_KEY\": BROWSERBASE_API_KEY,\n                        \"BROWSERBASE_PROJECT_ID\": BROWSERBASE_PROJECT_ID,\n                        \"GEMINI_API_KEY\": GEMINI_API_KEY,\n                    }\n                ),\n                timeout=300,\n            ),\n        )\n    ],\n)"}]}, {"heading_path": ["Available tools\u00b6"], "text": "Available tools \u00b6 Tool Description browserbase_stagehand_navigate Navigate to any URL in the browser browserbase_stagehand_act Perform an action on the web page using natural language browserbase_stagehand_extract Extract all text content from the current page (filters out CSS and JavaScript) browserbase_stagehand_observe Observe and find actionable elements on the web page browserbase_screenshot Capture a PNG screenshot of the current page browserbase_stagehand_get_url Get the current URL of the browser page browserbase_session_create Create or reuse a cloud browser session using Browserbase with fully initialized Stagehand browserbase_session_close Close the current Browserbase session, disconnect the browser, and cleanup Stagehand instance ", "code_blocks": []}, {"heading_path": ["Configuration\u00b6"], "text": "Configuration \u00b6 The Browserbase MCP server accepts the following command-line flags: Flag Description --proxies Enable Browserbase proxies for the session --advancedStealth Enable Browserbase Advanced Stealth (Only for Scale Plan Users) --keepAlive Enable Browserbase Keep Alive Session --contextId <contextId> Specify a Browserbase Context ID to use --persist Whether to persist the Browserbase context (default: true) --port <port> Port to listen on for HTTP/SHTTP transport --host <host> Host to bind server to (default: localhost, use 0.0.0.0 for all interfaces) --cookies [json] JSON array of cookies to inject into the browser --browserWidth <width> Browser viewport width (default: 1024) --browserHeight <height> Browser viewport height (default: 768) --modelName <model> The model to use for Stagehand (default: gemini-2.0-flash) --modelApiKey <key> API key for the custom model provider (required when using custom models) --experimental Enable experimental features (default: false) ", "code_blocks": []}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 Browserbase MCP Server Documentation Browserbase MCP Server Configuration Browserbase MCP Server Repository Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:14.922001", "source_type": "adk-docs"}
{"doc_id": "f8903fc55746a601b8e743d781e55423851bb480f72ffbe04d8cc72bd522142a", "url": "https://google.github.io/adk-docs/tools/third-party/exa", "title": "Exa - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Exa\u00b6"], "text": "Exa \u00b6 The Exa MCP Server connects your\nADK agent to Exa's search engine , a platform built\nspecifically for AI. This gives your agent the ability to search for relevant\nwebpages, find similar content based on a link, retrieve clean, parsed content\nfrom URLs, get direct answers to questions, and automate in-depth research\nreports using natural language. ", "code_blocks": []}, {"heading_path": ["Use cases\u00b6"], "text": "Use cases \u00b6 Find Code & Technical Examples : Search across GitHub, documentation, and\n  technical forums to find up-to-date code snippets, API usage patterns, and\n  implementation examples. Perform In-Depth Research : Launch comprehensive research reports on\n  complex topics, gather detailed information on companies, or find professional\n  profiles on LinkedIn. Access Real-Time Web Content : Perform general web searches to get\n  up-to-date information or extract the full content from specific articles,\n  blog posts, or web pages. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Create an API Key in Exa. Refer to the documentation for more\n  information. ", "code_blocks": []}, {"heading_path": ["Use with agent\u00b6"], "text": "Use with agent \u00b6 Local MCP Server Remote MCP Server from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from mcp import StdioServerParameters EXA_API_KEY = \"YOUR_EXA_API_KEY\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"exa_agent\" , instruction = \"Help users get information from Exa\" , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = \"npx\" , args = [ \"-y\" , \"exa-mcp-server\" , # (Optional) Specify which tools to enable # If you don't specify any tools, all tools enabled by default will be used. # \"--tools=get_code_context_exa,web_search_exa\", ], env = { \"EXA_API_KEY\" : EXA_API_KEY , } ), timeout = 30 , ), ) ], ) from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset EXA_API_KEY = \"YOUR_EXA_API_KEY\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"exa_agent\" , instruction = \"\"\"Help users get information from Exa\"\"\" , tools = [ MCPToolset ( connection_params = StreamableHTTPServerParams ( url = \"https://mcp.exa.ai/mcp?exaApiKey=\" + EXA_API_KEY , # (Optional) Specify which tools to enable # If you don't specify any tools, all tools enabled by default will be used. # url=\"https://mcp.exa.ai/mcp?exaApiKey=\" + EXA_API_KEY + \"&enabledTools=%5B%22crawling_exa%22%5D\", ), ) ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom mcp import StdioServerParameters\n\nEXA_API_KEY = \"YOUR_EXA_API_KEY\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"exa_agent\",\n    instruction=\"Help users get information from Exa\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"-y\",\n                        \"exa-mcp-server\",\n                        # (Optional) Specify which tools to enable\n                        # If you don't specify any tools, all tools enabled by default will be used.\n                        # \"--tools=get_code_context_exa,web_search_exa\",\n                    ],\n                    env={\n                        \"EXA_API_KEY\": EXA_API_KEY,\n                    }\n                ),\n                timeout=30,\n            ),\n        )\n    ],\n)"}, {"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\n\nEXA_API_KEY = \"YOUR_EXA_API_KEY\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"exa_agent\",\n    instruction=\"\"\"Help users get information from Exa\"\"\",\n    tools=[\n        MCPToolset(\n            connection_params=StreamableHTTPServerParams(\n                url=\"https://mcp.exa.ai/mcp?exaApiKey=\" + EXA_API_KEY,\n                # (Optional) Specify which tools to enable\n                # If you don't specify any tools, all tools enabled by default will be used.\n                # url=\"https://mcp.exa.ai/mcp?exaApiKey=\" + EXA_API_KEY + \"&enabledTools=%5B%22crawling_exa%22%5D\",\n            ),\n        )\n    ],\n)"}]}, {"heading_path": ["Available tools\u00b6"], "text": "Available tools \u00b6 Tool Description get_code_context_exa Search and get relevant code snippets, examples, and documentation from open source libraries, GitHub repositories, and programming frameworks. Perfect for finding up-to-date code documentation, implementation examples, API usage patterns, and best practices from real codebases. web_search_exa Performs real-time web searches with optimized results and content extraction. company_research Comprehensive company research tool that crawls company websites to gather detailed information about businesses. crawling Extracts content from specific URLs, useful for reading articles, PDFs, or any web page when you have the exact URL. linkedin_search Search LinkedIn for companies and people using Exa AI. Simply include company names, person names, or specific LinkedIn URLs in your query. deep_researcher_start Start a smart AI researcher for complex questions. The AI will search the web, read many sources, and think deeply about your question to create a detailed research report. deep_researcher_check Check if your research is ready and get the results. Use this after starting a research task to see if it's done and get your comprehensive report. ", "code_blocks": []}, {"heading_path": ["Configuration\u00b6"], "text": "Configuration \u00b6 To specify which tools to use in the Local Exa MCP server, you can use the --tools parameter: --tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check To specify which tools to use in the Remote Exa MCP server, you can use the enabledTools URL parameter: https://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY&enabledTools=%5B%22crawling_exa%22%5D ", "code_blocks": [{"language": "text", "code": "--tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check"}, {"language": "text", "code": "https://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY&enabledTools=%5B%22crawling_exa%22%5D"}]}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 Exa MCP Server Documentation Exa MCP Server Repository Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:15.443887", "source_type": "adk-docs"}
{"doc_id": "1af215f55740dc6053528d2ab36539de0091f92d368515d842586ebce1e54a86", "url": "https://google.github.io/adk-docs/tools/third-party/firecrawl", "title": "Firecrawl - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Firecrawl\u00b6"], "text": "Firecrawl \u00b6 The Firecrawl MCP Server connects your ADK agent to the Firecrawl API, a\nservice that can crawl any website and convert its content into clean,\nstructured markdown. This allows your agent to ingest, search, and reason over\nweb data from any URL, including all its subpages. ", "code_blocks": []}, {"heading_path": ["Features\u00b6"], "text": "Features \u00b6 Agent-based Web Research : Deploy an agent that can take a topic, use the\n  search tool to find relevant URLs, and then use the scrape tool to extract the\n  full content of each page for analysis or summarization. Structured Data Extraction : Use the extract tool to pull specific,\n  structured information (like product names, prices, or contact info) from a\n  list of URLs, powered by LLM extraction. Large-Scale Content Ingestion : Automate the scraping of entire websites or\n  large batches of URLs using the batch scrape and crawl tools. This is ideal\n  for populating a vector database for a RAG (Retrieval-Augmented Generation)\n  pipeline. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Sign up on Firecrawl and get an API key ", "code_blocks": []}, {"heading_path": ["Usage with ADK\u00b6"], "text": "Usage with ADK \u00b6 Local MCP Server Remote MCP Server from google.adk.agents.llm_agent import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from mcp import StdioServerParameters FIRECRAWL_API_KEY = \"YOUR_FIRECRAWL_API_KEY\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"firecrawl_agent\" , description = \"A helpful assistant for scraping websites with Firecrawl\" , instruction = \"Help the user search for website content\" , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = \"npx\" , args = [ \"-y\" , \"firecrawl-mcp\" , ], env = { \"FIRECRAWL_API_KEY\" : FIRECRAWL_API_KEY , } ), timeout = 30 , ), ) ], ) from google.adk.agents.llm_agent import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset FIRECRAWL_API_KEY = \"YOUR_FIRECRAWL_API_KEY\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"firecrawl_agent\" , description = \"A helpful assistant for scraping websites with Firecrawl\" , instruction = \"Help the user search for website content\" , tools = [ MCPToolset ( connection_params = StreamableHTTPServerParams ( url = f \"https://mcp.firecrawl.dev/ { FIRECRAWL_API_KEY } /v2/mcp\" , ), ) ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents.llm_agent import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom mcp import StdioServerParameters\n\nFIRECRAWL_API_KEY = \"YOUR_FIRECRAWL_API_KEY\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"firecrawl_agent\",\n    description=\"A helpful assistant for scraping websites with Firecrawl\",\n    instruction=\"Help the user search for website content\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"-y\",\n                        \"firecrawl-mcp\",\n                    ],\n                    env={\n                        \"FIRECRAWL_API_KEY\": FIRECRAWL_API_KEY,\n                    }\n                ),\n                timeout=30,\n            ),\n        )\n    ],\n)"}, {"language": "text", "code": "from google.adk.agents.llm_agent import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\n\nFIRECRAWL_API_KEY = \"YOUR_FIRECRAWL_API_KEY\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"firecrawl_agent\",\n    description=\"A helpful assistant for scraping websites with Firecrawl\",\n    instruction=\"Help the user search for website content\",\n    tools=[\n        MCPToolset(\n            connection_params=StreamableHTTPServerParams(\n                url=f\"https://mcp.firecrawl.dev/{FIRECRAWL_API_KEY}/v2/mcp\",\n            ),\n        )\n    ],\n)"}]}, {"heading_path": ["Available tools\u00b6"], "text": "Available tools \u00b6 This toolset provides a comprehensive suite of functions for web crawling,\nscraping, and searching: Tool Name Description Scrape Tool firecrawl_scrape Scrape content from a single URL with advanced options Batch Scrape Tool firecrawl_batch_scrape Scrape multiple URLs efficiently with built-in rate limiting and parallel processing Check Batch Status firecrawl_check_batch_status Check the status of a batch operation Map Tool firecrawl_map Map a website to discover all indexed URLs on the site Search Tool firecrawl_search Search the web and optionally extract content from search results Crawl Tool firecrawl_crawl Start an asynchronous crawl with advanced options Check Crawl Status firecrawl_check_crawl_status Check the status of a crawl job Extract Tool firecrawl_extract Extract structured information from web pages using LLM capabilities. Supports both cloud AI and self-hosted LLM extraction ", "code_blocks": []}, {"heading_path": ["Configuration\u00b6"], "text": "Configuration \u00b6 The Firecrawl MCP server can be configured using environment variables: Required : FIRECRAWL_API_KEY : Your Firecrawl API key Required when using cloud API (default) Optional when using self-hosted instance with FIRECRAWL_API_URL Firecrawl API URL (optional) : FIRECRAWL_API_URL (Optional): Custom API endpoint for self-hosted instances Example: https://firecrawl.your-domain.com If not provided, the cloud API will be used (requires API key) Retry configuration (optional) : FIRECRAWL_RETRY_MAX_ATTEMPTS : Maximum number of retry attempts (default: 3) FIRECRAWL_RETRY_INITIAL_DELAY : Initial delay in milliseconds before first retry (default: 1000) FIRECRAWL_RETRY_MAX_DELAY : Maximum delay in milliseconds between retries (default: 10000) FIRECRAWL_RETRY_BACKOFF_FACTOR : Exponential backoff multiplier (default: 2) Credit usage monitoring (optional) : FIRECRAWL_CREDIT_WARNING_THRESHOLD : Credit usage warning threshold (default: 1000) FIRECRAWL_CREDIT_CRITICAL_THRESHOLD : Credit usage critical threshold (default: 100) ", "code_blocks": []}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 Firecrawl MCP Server Documentation Firecrawl MCP Server Repository Firecrawl Use Cases Firecrawl Advanced Scraping Guide Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:15.935662", "source_type": "adk-docs"}
{"doc_id": "6ac4e39e4d6d04120f867cc80b84a3e78592b3ff4a15b0cf6e5205b1da6e5303", "url": "https://google.github.io/adk-docs/tools/third-party/github", "title": "GitHub - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["GitHub\u00b6"], "text": "GitHub \u00b6 The GitHub MCP Server connects AI\ntools directly to GitHub's platform. This gives your ADK agent the ability to\nread repositories and code files, manage issues and PRs, analyze code, and\nautomate workflows using natural language. ", "code_blocks": []}, {"heading_path": ["Use cases\u00b6"], "text": "Use cases \u00b6 Repository Management : Browse and query code, search files, analyze\n  commits, and understand project structure across any repository you have\n  access to. Issue & PR Automation : Create, update, and manage issues and pull\n  requests. Let AI help triage bugs, review code changes, and maintain project\n  boards. Code Analysis : Examine security findings, review Dependabot alerts,\n  understand code patterns, and get comprehensive insights into your codebase. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Create a Personal Access Token in GitHub. Refer to the documentation for more information. ", "code_blocks": []}, {"heading_path": ["Use with agent\u00b6"], "text": "Use with agent \u00b6 Remote MCP Server from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset GITHUB_TOKEN = \"YOUR_GITHUB_TOKEN\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"github_agent\" , instruction = \"Help users get information from GitHub\" , tools = [ MCPToolset ( connection_params = StreamableHTTPServerParams ( url = \"https://api.githubcopilot.com/mcp/\" , headers = { \"Authorization\" : f \"Bearer { GITHUB_TOKEN } \" , \"X-MCP-Toolsets\" : \"all\" , \"X-MCP-Readonly\" : \"true\" }, ), ) ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\n\nGITHUB_TOKEN = \"YOUR_GITHUB_TOKEN\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"github_agent\",\n    instruction=\"Help users get information from GitHub\",\n    tools=[\n        MCPToolset(\n            connection_params=StreamableHTTPServerParams(\n                url=\"https://api.githubcopilot.com/mcp/\",\n                headers={\n                    \"Authorization\": f\"Bearer {GITHUB_TOKEN}\",\n                    \"X-MCP-Toolsets\": \"all\",\n                    \"X-MCP-Readonly\": \"true\"\n                },\n            ),\n        )\n    ],\n)"}]}, {"heading_path": ["Available tools\u00b6"], "text": "Available tools \u00b6 Tool Description context Tools that provide context about the current user and GitHub context you are operating in copilot Copilot related tools (e.g. Copilot Coding Agent) copilot_spaces Copilot Spaces related tools actions GitHub Actions workflows and CI/CD operations code_security Code security related tools, such as GitHub Code Scanning dependabot Dependabot tools discussions GitHub Discussions related tools experiments Experimental features that are not considered stable yet gists GitHub Gist related tools github_support_docs_search Search docs to answer GitHub product and support questions issues GitHub Issues related tools labels GitHub Labels related tools notifications GitHub Notifications related tools orgs GitHub Organization related tools projects GitHub Projects related tools pull_requests GitHub Pull Request related tools repos GitHub Repository related tools secret_protection Secret protection related tools, such as GitHub Secret Scanning security_advisories Security advisories related tools stargazers GitHub Stargazers related tools users GitHub User related tools ", "code_blocks": []}, {"heading_path": ["Configuration\u00b6"], "text": "Configuration \u00b6 The Remote GitHub MCP server has optional headers that can be used to configure\navailable toolsets and read-only mode: X-MCP-Toolsets : Comma-separated list of toolsets to enable. (e.g., \"repos,issues\") If the list is empty, default toolsets will be used. If a bad toolset is\n  provided, the server will fail to start and emit a 400 bad request status.\n  Whitespace is ignored. X-MCP-Readonly : Enables only \"read\" tools. If this header is empty, \"false\", \"f\", \"no\", \"n\", \"0\", or \"off\" (ignoring\n  whitespace and case), it will be interpreted as false. All other values\n  are interpreted as true. ", "code_blocks": []}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 GitHub MCP Server Repository Remote GitHub MCP Server Documentation Policies and Governance for the GitHub MCP Server Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:16.432690", "source_type": "adk-docs"}
{"doc_id": "fc9f1ffafa4b9991778b23ad7e2c16fd2679537f701a63f213dbbb7f066b75f1", "url": "https://google.github.io/adk-docs/tools/third-party/hugging-face", "title": "Hugging Face - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Hugging Face\u00b6"], "text": "Hugging Face \u00b6 The Hugging Face MCP Server can be used to connect\nyour ADK agent to the Hugging Face Hub and thousands of Gradio AI Applications. ", "code_blocks": []}, {"heading_path": ["Use cases\u00b6"], "text": "Use cases \u00b6 Discover AI/ML Assets : Search and filter the Hub for models, datasets, and\n  papers based on tasks, libraries, or keywords. Build Multi-Step Workflows : Chain tools together, such as transcribing\n  audio with one tool and then summarizing the resulting text with another. Find AI Applications : Search for Gradio Spaces that can perform a specific\n  task, like background removal or text-to-speech. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Create a user access token in\n  Hugging Face. Refer to the documentation for more\n  information. ", "code_blocks": []}, {"heading_path": ["Use with agent\u00b6"], "text": "Use with agent \u00b6 Local MCP Server Remote MCP Server from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from mcp import StdioServerParameters HUGGING_FACE_TOKEN = \"YOUR_HUGGING_FACE_TOKEN\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"hugging_face_agent\" , instruction = \"Help users get information from Hugging Face\" , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = \"npx\" , args = [ \"-y\" , \"@llmindset/hf-mcp-server\" , ], env = { \"HF_TOKEN\" : HUGGING_FACE_TOKEN , } ), timeout = 30 , ), ) ], ) from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset HUGGING_FACE_TOKEN = \"YOUR_HUGGING_FACE_TOKEN\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"hugging_face_agent\" , instruction = \"\"\"Help users get information from Hugging Face\"\"\" , tools = [ MCPToolset ( connection_params = StreamableHTTPServerParams ( url = \"https://huggingface.co/mcp\" , headers = { \"Authorization\" : f \"Bearer { HUGGING_FACE_TOKEN } \" , }, ), ) ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom mcp import StdioServerParameters\n\nHUGGING_FACE_TOKEN = \"YOUR_HUGGING_FACE_TOKEN\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"hugging_face_agent\",\n    instruction=\"Help users get information from Hugging Face\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"-y\",\n                        \"@llmindset/hf-mcp-server\",\n                    ],\n                    env={\n                        \"HF_TOKEN\": HUGGING_FACE_TOKEN,\n                    }\n                ),\n                timeout=30,\n            ),\n        )\n    ],\n)"}, {"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\n\nHUGGING_FACE_TOKEN = \"YOUR_HUGGING_FACE_TOKEN\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"hugging_face_agent\",\n    instruction=\"\"\"Help users get information from Hugging Face\"\"\",\n    tools=[\n        MCPToolset(\n            connection_params=StreamableHTTPServerParams(\n                url=\"https://huggingface.co/mcp\",\n                headers={\n                    \"Authorization\": f\"Bearer {HUGGING_FACE_TOKEN}\",\n                },\n            ),\n        )\n    ],\n)"}]}, {"heading_path": ["Available tools\u00b6"], "text": "Available tools \u00b6 Tool Description Spaces Semantic Search Find the best AI Apps via natural language queries Papers Semantic Search Find ML Research Papers via natural language queries Model Search Search for ML models with filters for task, library, etc\u2026 Dataset Search Search for datasets with filters for author, tags, etc\u2026 Documentation Semantic Search Search the Hugging Face documentation library Hub Repository Details Get detailed information about Models, Datasets and Spaces ", "code_blocks": []}, {"heading_path": ["Configuration\u00b6"], "text": "Configuration \u00b6 To configure which tools are available in your Hugging Face Hub MCP server,\nvisit the MCP Settings Page in your\nHugging Face account. To configure the local MCP server, you can use the following environment\nvariables: TRANSPORT : The transport type to use ( stdio , sse , streamableHttp , or streamableHttpJson ) DEFAULT_HF_TOKEN : \u26a0\ufe0f Requests are serviced with the HF_TOKEN received in\n  the Authorization: Bearer header. The DEFAULT_HF_TOKEN is used if no header\n  was sent. Only set this in Development / Test environments or for local STDIO\n  Deployments. \u26a0\ufe0f If running with stdio transport, HF_TOKEN is used if DEFAULT_HF_TOKEN is\n  not set. HF_API_TIMEOUT : Timeout for Hugging Face API requests in milliseconds\n  (default: 12500ms / 12.5 seconds) USER_CONFIG_API : URL to use for User settings (defaults to Local front-end) MCP_STRICT_COMPLIANCE : set to True for GET 405 rejects in JSON Mode (default\n  serves a welcome page). AUTHENTICATE_TOOL : whether to include an Authenticate tool to issue an OAuth\n  challenge when called SEARCH_ENABLES_FETCH : When set to true, automatically enables the\n  hf_doc_fetch tool whenever hf_doc_search is enabled ", "code_blocks": []}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 Hugging Face MCP Server Repository Hugging Face MCP Server Documentation Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:16.926324", "source_type": "adk-docs"}
{"doc_id": "63e5a73d67075817351adebe320b702134c227780809875e0fc3e98b9208c182", "url": "https://google.github.io/adk-docs/tools/third-party/notion", "title": "Notion - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Notion\u00b6"], "text": "Notion \u00b6 The Notion MCP Server connects your ADK agent to Notion, allowing it to search, create, and manage\npages, databases, and more within a workspace. This gives your agent the ability\nto query, create, and organize content in your Notion workspace using natural\nlanguage. ", "code_blocks": []}, {"heading_path": ["Use cases\u00b6"], "text": "Use cases \u00b6 Search your workspace : Find project pages, meeting notes, or documents\n  based on content. Create new content : Generate new pages for meeting notes, project plans,\n  or tasks. Manage tasks and databases : Update the status of a task, add items to a\n  database, or change properties. Organize your workspace : Move pages, duplicate templates, or add comments\n  to documents. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Obtain a Notion integration token by going to Notion Integrations in your\n  profile. Refer to the authorization documentation for more details. Ensure relevant pages and databases can be accessed by your integration. Visit\n  the Access tab in your Notion Integration settings,\n  then grant access by selecting the pages you'd like to use. ", "code_blocks": []}, {"heading_path": ["Use with agent\u00b6"], "text": "Use with agent \u00b6 Local MCP Server from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from mcp import StdioServerParameters NOTION_TOKEN = \"YOUR_NOTION_TOKEN\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"notion_agent\" , instruction = \"Help users get information from Notion\" , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = \"npx\" , args = [ \"-y\" , \"@notionhq/notion-mcp-server\" , ], env = { \"NOTION_TOKEN\" : NOTION_TOKEN , } ), timeout = 30 , ), ) ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom mcp import StdioServerParameters\n\nNOTION_TOKEN = \"YOUR_NOTION_TOKEN\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"notion_agent\",\n    instruction=\"Help users get information from Notion\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"-y\",\n                        \"@notionhq/notion-mcp-server\",\n                    ],\n                    env={\n                        \"NOTION_TOKEN\": NOTION_TOKEN,\n                    }\n                ),\n                timeout=30,\n            ),\n        )\n    ],\n)"}]}, {"heading_path": ["Available tools\u00b6"], "text": "Available tools \u00b6 Tool Description notion-search Search across your Notion workspace and connected tools like Slack, Google Drive, and Jira. Falls back to basic workspace search if AI features aren\u2019t available. notion-fetch Retrieves content from a Notion page or database by its URL notion-create-pages Creates one or more Notion pages with specified properties and content. notion-update-page Update a Notion page's properties or content. notion-move-pages Move one or more Notion pages or databases to a new parent. notion-duplicate-page Duplicate a Notion page within your workspace. This action is completed async. notion-create-database Creates a new Notion database, initial data source, and initial view with the specified properties. notion-update-database Update a Notion data source's properties, name, description, or other attributes. notion-create-comment Add a comment to a page notion-get-comments Lists all comments on a specific page, including threaded discussions. notion-get-teams Retrieves a list of teams (teamspaces) in the current workspace. notion-get-users Lists all users in the workspace with their details. notion-get-user Retrieve your user information by ID notion-get-self Retrieves information about your own bot user and the Notion workspace you\u2019re connected to. ", "code_blocks": []}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 Notion MCP Server Documentation Notion MCP Server Repository Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:17.386287", "source_type": "adk-docs"}
{"doc_id": "a49827929961fa15929e754850daa09c9056093af33fb23e1021430af5f95ac4", "url": "https://google.github.io/adk-docs/tools/third-party/tavily", "title": "Tavily - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Tavily\u00b6"], "text": "Tavily \u00b6 The Tavily MCP Server connects your\nADK agent to Tavily's AI-focused search, extraction, and crawling platform. This\ntool gives your agent the ability to perform real-time web searches,\nintelligently extract specific data from web pages, and crawl or create\nstructured maps of websites. ", "code_blocks": []}, {"heading_path": ["Use cases\u00b6"], "text": "Use cases \u00b6 Real-Time Web Search : Perform optimized, real-time web searches to get\n  up-to-date information for your agent's tasks. Intelligent Data Extraction : Extract specific, clean data and content from\n  any web page without needing to parse the full HTML. Website Exploration : Automatically crawl websites to explore content or\n  create a structured map of a site's layout and pages. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Sign up for a Tavily account to obtain an API key.\n  Refer to the documentation for more\n  information. ", "code_blocks": []}, {"heading_path": ["Use with agent\u00b6"], "text": "Use with agent \u00b6 Local MCP Server Remote MCP Server from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from mcp import StdioServerParameters TAVILY_API_KEY = \"YOUR_TAVILY_API_KEY\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"tavily_agent\" , instruction = \"Help users get information from Tavily\" , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = \"npx\" , args = [ \"-y\" , \"tavily-mcp@latest\" , ], env = { \"TAVILY_API_KEY\" : TAVILY_API_KEY , } ), timeout = 30 , ), ) ], ) from google.adk.agents import Agent from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset TAVILY_API_KEY = \"YOUR_TAVILY_API_KEY\" root_agent = Agent ( model = \"gemini-2.5-pro\" , name = \"tavily_agent\" , instruction = \"\"\"Help users get information from Tavily\"\"\" , tools = [ MCPToolset ( connection_params = StreamableHTTPServerParams ( url = \"https://mcp.tavily.com/mcp/\" , headers = { \"Authorization\" : f \"Bearer { TAVILY_API_KEY } \" , }, ), ) ], ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom mcp import StdioServerParameters\n\nTAVILY_API_KEY = \"YOUR_TAVILY_API_KEY\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"tavily_agent\",\n    instruction=\"Help users get information from Tavily\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command=\"npx\",\n                    args=[\n                        \"-y\",\n                        \"tavily-mcp@latest\",\n                    ],\n                    env={\n                        \"TAVILY_API_KEY\": TAVILY_API_KEY,\n                    }\n                ),\n                timeout=30,\n            ),\n        )\n    ],\n)"}, {"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPServerParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\n\nTAVILY_API_KEY = \"YOUR_TAVILY_API_KEY\"\n\nroot_agent = Agent(\n    model=\"gemini-2.5-pro\",\n    name=\"tavily_agent\",\n    instruction=\"\"\"Help users get information from Tavily\"\"\",\n    tools=[\n        MCPToolset(\n            connection_params=StreamableHTTPServerParams(\n                url=\"https://mcp.tavily.com/mcp/\",\n                headers={\n                    \"Authorization\": f\"Bearer {TAVILY_API_KEY}\",\n                },\n            ),\n        )\n    ],\n)"}]}, {"heading_path": ["Example usage\u00b6"], "text": "Example usage \u00b6 Once your agent is set up and running, you can interact with it through the\ncommand-line interface or web interface. Here's a simple example: Sample agent prompt: Find all documentation pages on tavily.com and provide instructions on how to get started with Tavily The agent automatically calls multiple Tavily tools to provide comprehensive\nanswers, making it easy to explore websites and gather information without\nmanual navigation: ", "code_blocks": []}, {"heading_path": ["Available tools\u00b6"], "text": "Available tools \u00b6 Once connected, your agent gains access to Tavily's web intelligence tools: Tool Description tavily-search Execute a search query to find relevant information across the web. \u200b tavily-extract Extract structured data from any web page. Extract text, links, and images from single pages or batch process multiple URLs efficiently. \u200b tavily-map Traverses websites like a graph and can explore hundreds of paths in parallel with intelligent discovery to generate comprehensive site maps. \u200b tavily-crawl Traversal tool that can explore hundreds of paths in parallel with built-in extraction and intelligent discovery. ", "code_blocks": []}, {"heading_path": ["Additional resources\u00b6"], "text": "Additional resources \u00b6 Tavily MCP Server Documentation Tavily MCP Server Repository Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:17.801097", "source_type": "adk-docs"}
{"doc_id": "c86e232132ec079c272d982399b6ddcf7508dffce7ac02e985ff3a797b2ddbda", "url": "https://google.github.io/adk-docs/tools/third-party/ag-ui", "title": "Agentic UI (AG-UI) - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Build chat experiences with AG-UI and CopilotKit\u00b6"], "text": "Build chat experiences with AG-UI and CopilotKit \u00b6 As an agent builder, you want users to interact with your agents through a rich\nand responsive interface. Building UIs from scratch requires a lot of effort,\nespecially to support streaming events and client state. That's exactly what AG-UI was designed for - rich user experiences\ndirectly connected to an agent. AG-UI provides a consistent interface\nto empower rich clients across technology stacks, from mobile to the web and\neven the command line. There are a number of different clients that support\nAG-UI: CopilotKit provides tooling and components to tightly integrate your agent with web applications Clients for Kotlin , Java , Go , and CLI implementations in TypeScript This tutorial uses CopilotKit to create a sample app backed by an ADK agent that\ndemonstrates some of the features supported by AG-UI. ", "code_blocks": []}, {"heading_path": ["Quickstart\u00b6"], "text": "Quickstart \u00b6 To get started, let's create a sample application with an ADK agent and a simple\nweb client: npx create-ag-ui-app@latest --adk ", "code_blocks": [{"language": "text", "code": "npx create-ag-ui-app@latest --adk"}]}, {"heading_path": ["Chat\u00b6"], "text": "Chat \u00b6 Chat is a familiar interface for exposing your agent, and AG-UI handles\nstreaming messages between your users and agents: src/app/page.tsx < CopilotSidebar clickOutsideToClose = { false } defaultOpen = { true } labels = {{ title : \"Popup Assistant\" , initial : \"\ud83d\udc4b Hi, there! You're chatting with an agent. This agent comes with a few tools to get you started...\" }} /> Learn more about the chat UI in the CopilotKit docs . ", "code_blocks": [{"language": "text", "code": "<CopilotSidebar\n  clickOutsideToClose={false}\n  defaultOpen={true}\n  labels={{\n    title: \"Popup Assistant\",\n    initial: \"\ud83d\udc4b Hi, there! You're chatting with an agent. This agent comes with a few tools to get you started...\"\n  }}\n/>"}]}, {"heading_path": ["Tool Based Generative UI (Rendering Tools)\u00b6"], "text": "Tool Based Generative UI (Rendering Tools) \u00b6 AG-UI lets you share tool information with a Generative UI so that it can be\ndisplayed to users: src/app/page.tsx useCopilotAction ({ name : \"get_weather\" , description : \"Get the weather for a given location.\" , available : \"disabled\" , parameters : [ { name : \"location\" , type : \"string\" , required : true }, ], render : ({ args }) => { return < WeatherCard location = { args . location } themeColor = { themeColor } /> }, }); Learn more about the Tool-based Generative UI in the CopilotKit docs . ", "code_blocks": [{"language": "text", "code": "useCopilotAction({\n  name: \"get_weather\",\n  description: \"Get the weather for a given location.\",\n  available: \"disabled\",\n  parameters: [\n    { name: \"location\", type: \"string\", required: true },\n  ],\n  render: ({ args }) => {\n    return <WeatherCard location={args.location} themeColor={themeColor} />\n  },\n});"}]}, {"heading_path": ["Shared State\u00b6"], "text": "Shared State \u00b6 ADK agents can be stateful, and synchronizing that state between your agents and\nyour UIs enables powerful and fluid user experiences. State can be synchronized\nboth ways so agents are automatically aware of changes made by your user or\nother parts of your application: src/app/page.tsx const { state , setState } = useCoAgent < AgentState >({ name : \"my_agent\" , initialState : { proverbs : [ \"CopilotKit may be new, but its the best thing since sliced bread.\" , ], }, }) Learn more about shared state in the CopilotKit docs . ", "code_blocks": [{"language": "text", "code": "const { state, setState } = useCoAgent<AgentState>({\n  name: \"my_agent\",\n  initialState: {\n    proverbs: [\n      \"CopilotKit may be new, but its the best thing since sliced bread.\",\n    ],\n  },\n})"}]}, {"heading_path": ["Try it out!\u00b6"], "text": "Try it out! \u00b6 npm install && npm run dev ", "code_blocks": [{"language": "text", "code": "npm install && npm run dev"}]}, {"heading_path": ["Resources\u00b6"], "text": "Resources \u00b6 To see what other features you can build into your UI with AG-UI, refer to the CopilotKit docs: Agentic Generative UI Human in the Loop Frontend Actions Or try them out in the AG-UI Dojo . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:18.320108", "source_type": "adk-docs"}
{"doc_id": "be0b42c271d31175873af1ba8702f310e5361d8401d5ba2efccc9bcc49b2496f", "url": "https://google.github.io/adk-docs/tools-custom", "title": "Custom Tools for ADK - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Custom Tools for ADK\u00b6"], "text": "Custom Tools for ADK \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 In an ADK agent workflow, Tools are programming functions with structured input\nand output that can be called by an ADK Agent to perform actions. ADK Tools\nfunction similarly to how you use a Function Call with Gemini or other generative AI models. You can perform various actions and\nprogramming functions with an ADK Tool, such as: Querying databases Making API requests: getting weather data, booking systems Searching the web Executing code snippets Retrieving information from documents (RAG) Interacting with other software or services ADK Tools list Before building your own Tools for ADK, check out the ADK Tools list for pre-built tools you can use with ADK Agents. ", "code_blocks": []}, {"heading_path": ["What is a Tool?\u00b6"], "text": "What is a Tool? \u00b6 In the context of ADK, a Tool represents a specific\ncapability provided to an AI agent, enabling it to perform actions and interact\nwith the world beyond its core text generation and reasoning abilities. What\ndistinguishes capable agents from basic language models is often their effective\nuse of tools. Technically, a tool is typically a modular code component\u2014 like a Python/ Java\nfunction , a class method, or even another specialized agent\u2014designed to\nexecute a distinct, predefined task. These tasks often involve interacting with\nexternal systems or data. ", "code_blocks": []}, {"heading_path": ["Key Characteristics\u00b6"], "text": "Key Characteristics \u00b6 Action-Oriented: Tools perform specific actions for an agent, such as\nsearching for information, calling an API, or performing calculations. Extends Agent capabilities: They empower agents to access real-time information, affect external systems, and overcome the knowledge limitations inherent in their training data. Execute predefined logic: Crucially, tools execute specific, developer-defined logic. They do not possess their own independent reasoning capabilities like the agent's core Large Language Model (LLM). The LLM reasons about which tool to use, when, and with what inputs, but the tool itself just executes its designated function. ", "code_blocks": []}, {"heading_path": ["How Agents Use Tools\u00b6"], "text": "How Agents Use Tools \u00b6 Agents leverage tools dynamically through mechanisms often involving function calling. The process generally follows these steps: Reasoning: The agent's LLM analyzes its system instruction, conversation history, and user request. Selection: Based on the analysis, the LLM decides on which tool, if any, to execute, based on the tools available to the agent and the docstrings that describes each tool. Invocation: The LLM generates the required arguments (inputs) for the selected tool and triggers its execution. Observation: The agent receives the output (result) returned by the tool. Finalization: The agent incorporates the tool's output into its ongoing reasoning process to formulate the next response, decide the subsequent step, or determine if the goal has been achieved. Think of the tools as a specialized toolkit that the agent's intelligent core (the LLM) can access and utilize as needed to accomplish complex tasks. ", "code_blocks": []}, {"heading_path": ["Tool Types in ADK\u00b6"], "text": "Tool Types in ADK \u00b6 ADK offers flexibility by supporting several types of tools: Function Tools : Tools created by you, tailored to your specific application's needs. Functions/Methods : Define standard synchronous functions or methods in your code (e.g., Python def). Agents-as-Tools : Use another, potentially specialized, agent as a tool for a parent agent. Long Running Function Tools : Support for tools that perform asynchronous operations or take significant time to complete. Built-in Tools : Ready-to-use tools provided by the framework for common tasks.\n        Examples: Google Search, Code Execution, Retrieval-Augmented Generation (RAG). Third-Party Tools: Integrate tools seamlessly from popular external libraries. Navigate to the respective documentation pages linked above for detailed information and examples for each tool type. ", "code_blocks": []}, {"heading_path": ["Referencing Tool in Agent\u2019s Instructions\u00b6"], "text": "Referencing Tool in Agent\u2019s Instructions \u00b6 Within an agent's instructions, you can directly reference a tool by using its function name. If the tool's function name and docstring are sufficiently descriptive, your instructions can primarily focus on when the Large Language Model (LLM) should utilize the tool . This promotes clarity and helps the model understand the intended use of each tool. It is crucial to clearly instruct the agent on how to handle different return values that a tool might produce. For example, if a tool returns an error message, your instructions should specify whether the agent should retry the operation, give up on the task, or request additional information from the user. Furthermore, ADK supports the sequential use of tools, where the output of one tool can serve as the input for another. When implementing such workflows, it's important to describe the intended sequence of tool usage within the agent's instructions to guide the model through the necessary steps. ", "code_blocks": []}, {"heading_path": ["Example\u00b6"], "text": "Example \u00b6 The following example showcases how an agent can use tools by referencing their function names in its instructions . It also demonstrates how to guide the agent to handle different return values from tools , such as success or error messages, and how to orchestrate the sequential use of multiple tools to accomplish a task. Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import asyncio from google.adk.agents import Agent from google.adk.tools import FunctionTool from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.genai import types APP_NAME = \"weather_sentiment_agent\" USER_ID = \"user1234\" SESSION_ID = \"1234\" MODEL_ID = \"gemini-2.0-flash\" # Tool 1 def get_weather_report ( city : str ) -> dict : \"\"\"Retrieves the current weather report for a specified city. Returns: dict: A dictionary containing the weather information with a 'status' key ('success' or 'error') and a 'report' key with the weather details if successful, or an 'error_message' if an error occurred. \"\"\" if city . lower () == \"london\" : return { \"status\" : \"success\" , \"report\" : \"The current weather in London is cloudy with a temperature of 18 degrees Celsius and a chance of rain.\" } elif city . lower () == \"paris\" : return { \"status\" : \"success\" , \"report\" : \"The weather in Paris is sunny with a temperature of 25 degrees Celsius.\" } else : return { \"status\" : \"error\" , \"error_message\" : f \"Weather information for ' { city } ' is not available.\" } weather_tool = FunctionTool ( func = get_weather_report ) # Tool 2 def analyze_sentiment ( text : str ) -> dict : \"\"\"Analyzes the sentiment of the given text. Returns: dict: A dictionary with 'sentiment' ('positive', 'negative', or 'neutral') and a 'confidence' score. \"\"\" if \"good\" in text . lower () or \"sunny\" in text . lower (): return { \"sentiment\" : \"positive\" , \"confidence\" : 0.8 } elif \"rain\" in text . lower () or \"bad\" in text . lower (): return { \"sentiment\" : \"negative\" , \"confidence\" : 0.7 } else : return { \"sentiment\" : \"neutral\" , \"confidence\" : 0.6 } sentiment_tool = FunctionTool ( func = analyze_sentiment ) # Agent weather_sentiment_agent = Agent ( model = MODEL_ID , name = 'weather_sentiment_agent' , instruction = \"\"\"You are a helpful assistant that provides weather information and analyzes the sentiment of user feedback. **If the user asks about the weather in a specific city, use the 'get_weather_report' tool to retrieve the weather details.** **If the 'get_weather_report' tool returns a 'success' status, provide the weather report to the user.** **If the 'get_weather_report' tool returns an 'error' status, inform the user that the weather information for the specified city is not available and ask if they have another city in mind.** **After providing a weather report, if the user gives feedback on the weather (e.g., 'That's good' or 'I don't like rain'), use the 'analyze_sentiment' tool to understand their sentiment.** Then, briefly acknowledge their sentiment. You can handle these tasks sequentially if needed.\"\"\" , tools = [ weather_tool , sentiment_tool ] ) async def main (): \"\"\"Main function to run the agent asynchronously.\"\"\" # Session and Runner Setup session_service = InMemorySessionService () # Use 'await' to correctly create the session await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = weather_sentiment_agent , app_name = APP_NAME , session_service = session_service ) # Agent Interaction query = \"weather in london?\" print ( f \"User Query: { query } \" ) content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) # The runner's run method handles the async loop internally events = runner . run ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response:\" , final_response ) # Standard way to run the main async function if __name__ == \"__main__\" : asyncio . run ( main ()) // Copyright 2025 Google LLC // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // //     http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package main import ( \"context\" \"fmt\" \"log\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) type getWeatherReportArgs struct { City string `json:\"city\" jsonschema:\"The city for which to get the weather report.\"` } type getWeatherReportResult struct { Status string `json:\"status\"` Report string `json:\"report,omitempty\"` ErrorMessage string `json:\"error_message,omitempty\"` } func getWeatherReport ( ctx tool . Context , args getWeatherReportArgs ) getWeatherReportResult { if strings . ToLower ( args . City ) == \"london\" { return getWeatherReportResult { Status : \"success\" , Report : \"The current weather in London is cloudy with a temperature of 18 degrees Celsius and a chance of rain.\" } } if strings . ToLower ( args . City ) == \"paris\" { return getWeatherReportResult { Status : \"success\" , Report : \"The weather in Paris is sunny with a temperature of 25 degrees Celsius.\" } } return getWeatherReportResult { Status : \"error\" , ErrorMessage : fmt . Sprintf ( \"Weather information for '%s' is not available.\" , args . City )} } type analyzeSentimentArgs struct { Text string `json:\"text\" jsonschema:\"The text to analyze for sentiment.\"` } type analyzeSentimentResult struct { Sentiment string `json:\"sentiment\"` Confidence float64 `json:\"confidence\"` } func analyzeSentiment ( ctx tool . Context , args analyzeSentimentArgs ) analyzeSentimentResult { if strings . Contains ( strings . ToLower ( args . Text ), \"good\" ) || strings . Contains ( strings . ToLower ( args . Text ), \"sunny\" ) { return analyzeSentimentResult { Sentiment : \"positive\" , Confidence : 0.8 } } if strings . Contains ( strings . ToLower ( args . Text ), \"rain\" ) || strings . Contains ( strings . ToLower ( args . Text ), \"bad\" ) { return analyzeSentimentResult { Sentiment : \"negative\" , Confidence : 0.7 } } return analyzeSentimentResult { Sentiment : \"neutral\" , Confidence : 0.6 } } func main () { ctx := context . Background () model , err := gemini . NewModel ( ctx , \"gemini-2.0-flash\" , & genai . ClientConfig {}) if err != nil { log . Fatal ( err ) } weatherTool , err := functiontool . New ( functiontool . Config { Name : \"get_weather_report\" , Description : \"Retrieves the current weather report for a specified city.\" , }, getWeatherReport , ) if err != nil { log . Fatal ( err ) } sentimentTool , err := functiontool . New ( functiontool . Config { Name : \"analyze_sentiment\" , Description : \"Analyzes the sentiment of the given text.\" , }, analyzeSentiment , ) if err != nil { log . Fatal ( err ) } weatherSentimentAgent , err := llmagent . New ( llmagent . Config { Name : \"weather_sentiment_agent\" , Model : model , Instruction : \"You are a helpful assistant that provides weather information and analyzes the sentiment of user feedback. **If the user asks about the weather in a specific city, use the 'get_weather_report' tool to retrieve the weather details.** **If the 'get_weather_report' tool returns a 'success' status, provide the weather report to the user.** **If the 'get_weather_report' tool returns an 'error' status, inform the user that the weather information for the specified city is not available and ask if they have another city in mind.** **After providing a weather report, if the user gives feedback on the weather (e.g., 'That's good' or 'I don't like rain'), use the 'analyze_sentiment' tool to understand their sentiment.** Then, briefly acknowledge their sentiment. You can handle these tasks sequentially if needed.\" , Tools : [] tool . Tool { weatherTool , sentimentTool }, }) if err != nil { log . Fatal ( err ) } sessionService := session . InMemoryService () runner , err := runner . New ( runner . Config { AppName : \"weather_sentiment_agent\" , Agent : weatherSentimentAgent , SessionService : sessionService , }) if err != nil { log . Fatal ( err ) } session , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : \"weather_sentiment_agent\" , UserID : \"user1234\" , }) if err != nil { log . Fatal ( err ) } run ( ctx , runner , session . Session . ID (), \"weather in london?\" ) run ( ctx , runner , session . Session . ID (), \"I don't like rain.\" ) } func run ( ctx context . Context , r * runner . Runner , sessionID string , prompt string ) { fmt . Printf ( \"\\n> %s\\n\" , prompt ) events := r . Run ( ctx , \"user1234\" , sessionID , genai . NewContentFromText ( prompt , genai . RoleUser ), agent . RunConfig { StreamingMode : agent . StreamingModeNone , }, ) for event , err := range events { if err != nil { log . Fatalf ( \"ERROR during agent execution: %v\" , err ) } if event . Content . Parts [ 0 ]. Text != \"\" { fmt . Printf ( \"Agent Response: %s\\n\" , event . Content . Parts [ 0 ]. Text ) } } } import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.LlmAgent ; import com.google.adk.runner.Runner ; import com.google.adk.sessions.InMemorySessionService ; import com.google.adk.sessions.Session ; import com.google.adk.tools.Annotations.Schema ; import com.google.adk.tools.FunctionTool ; import com.google.adk.tools.ToolContext ; // Ensure this import is correct import com.google.common.collect.ImmutableList ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import java.util.HashMap ; import java.util.Locale ; import java.util.Map ; public class WeatherSentimentAgentApp { private static final String APP_NAME = \"weather_sentiment_agent\" ; private static final String USER_ID = \"user1234\" ; private static final String SESSION_ID = \"1234\" ; private static final String MODEL_ID = \"gemini-2.0-flash\" ; /** * Retrieves the current weather report for a specified city. * * @param city The city for which to retrieve the weather report. * @param toolContext The context for the tool. * @return A dictionary containing the weather information. */ public static Map < String , Object > getWeatherReport ( @Schema ( name = \"city\" ) String city , @Schema ( name = \"toolContext\" ) ToolContext toolContext ) { Map < String , Object > response = new HashMap <> (); if ( city . toLowerCase ( Locale . ROOT ). equals ( \"london\" )) { response . put ( \"status\" , \"success\" ); response . put ( \"report\" , \"The current weather in London is cloudy with a temperature of 18 degrees Celsius and a\" + \" chance of rain.\" ); } else if ( city . toLowerCase ( Locale . ROOT ). equals ( \"paris\" )) { response . put ( \"status\" , \"success\" ); response . put ( \"report\" , \"The weather in Paris is sunny with a temperature of 25 degrees Celsius.\" ); } else { response . put ( \"status\" , \"error\" ); response . put ( \"error_message\" , String . format ( \"Weather information for '%s' is not available.\" , city )); } return response ; } /** * Analyzes the sentiment of the given text. * * @param text The text to analyze. * @param toolContext The context for the tool. * @return A dictionary with sentiment and confidence score. */ public static Map < String , Object > analyzeSentiment ( @Schema ( name = \"text\" ) String text , @Schema ( name = \"toolContext\" ) ToolContext toolContext ) { Map < String , Object > response = new HashMap <> (); String lowerText = text . toLowerCase ( Locale . ROOT ); if ( lowerText . contains ( \"good\" ) || lowerText . contains ( \"sunny\" )) { response . put ( \"sentiment\" , \"positive\" ); response . put ( \"confidence\" , 0.8 ); } else if ( lowerText . contains ( \"rain\" ) || lowerText . contains ( \"bad\" )) { response . put ( \"sentiment\" , \"negative\" ); response . put ( \"confidence\" , 0.7 ); } else { response . put ( \"sentiment\" , \"neutral\" ); response . put ( \"confidence\" , 0.6 ); } return response ; } /** * Calls the agent with the given query and prints the final response. * * @param runner The runner to use. * @param query The query to send to the agent. */ public static void callAgent ( Runner runner , String query ) { Content content = Content . fromParts ( Part . fromText ( query )); InMemorySessionService sessionService = ( InMemorySessionService ) runner . sessionService (); Session session = sessionService . createSession ( APP_NAME , USER_ID , /* state= */ null , SESSION_ID ) . blockingGet (); runner . runAsync ( session . userId (), session . id (), content ) . forEach ( event -> { if ( event . finalResponse () && event . content (). isPresent () && event . content (). get (). parts (). isPresent () && ! event . content (). get (). parts (). get (). isEmpty () && event . content (). get (). parts (). get (). get ( 0 ). text (). isPresent ()) { String finalResponse = event . content (). get (). parts (). get (). get ( 0 ). text (). get (); System . out . println ( \"Agent Response: \" + finalResponse ); } }); } public static void main ( String [] args ) throws NoSuchMethodException { FunctionTool weatherTool = FunctionTool . create ( WeatherSentimentAgentApp . class . getMethod ( \"getWeatherReport\" , String . class , ToolContext . class )); FunctionTool sentimentTool = FunctionTool . create ( WeatherSentimentAgentApp . class . getMethod ( \"analyzeSentiment\" , String . class , ToolContext . class )); BaseAgent weatherSentimentAgent = LlmAgent . builder () . model ( MODEL_ID ) . name ( \"weather_sentiment_agent\" ) . description ( \"Weather Sentiment Agent\" ) . instruction ( \"\"\" You are a helpful assistant that provides weather information and analyzes the sentiment of user feedback **If the user asks about the weather in a specific city, use the 'get_weather_report' tool to retrieve the weather details.** **If the 'get_weather_report' tool returns a 'success' status, provide the weather report to the user.** **If the 'get_weather_report' tool returns an 'error' status, inform the user that the weather information for the specified city is not available and ask if they have another city in mind.** **After providing a weather report, if the user gives feedback on the weather (e.g., 'That's good' or 'I don't like rain'), use the 'analyze_sentiment' tool to understand their sentiment.** Then, briefly acknowledge their sentiment. You can handle these tasks sequentially if needed. \"\"\" ) . tools ( ImmutableList . of ( weatherTool , sentimentTool )) . build (); InMemorySessionService sessionService = new InMemorySessionService (); Runner runner = new Runner ( weatherSentimentAgent , APP_NAME , null , sessionService ); // Change the query to ensure the tool is called with a valid city that triggers a \"success\" // response from the tool, like \"london\" (without the question mark). callAgent ( runner , \"weather in paris\" ); } } ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\nfrom google.adk.agents import Agent\nfrom google.adk.tools import FunctionTool\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\nAPP_NAME=\"weather_sentiment_agent\"\nUSER_ID=\"user1234\"\nSESSION_ID=\"1234\"\nMODEL_ID=\"gemini-2.0-flash\"\n\n# Tool 1\ndef get_weather_report(city: str) -> dict:\n    \"\"\"Retrieves the current weather report for a specified city.\n\n    Returns:\n        dict: A dictionary containing the weather information with a 'status' key ('success' or 'error') and a 'report' key with the weather details if successful, or an 'error_message' if an error occurred.\n    \"\"\"\n    if city.lower() == \"london\":\n        return {\"status\": \"success\", \"report\": \"The current weather in London is cloudy with a temperature of 18 degrees Celsius and a chance of rain.\"}\n    elif city.lower() == \"paris\":\n        return {\"status\": \"success\", \"report\": \"The weather in Paris is sunny with a temperature of 25 degrees Celsius.\"}\n    else:\n        return {\"status\": \"error\", \"error_message\": f\"Weather information for '{city}' is not available.\"}\n\nweather_tool = FunctionTool(func=get_weather_report)\n\n\n# Tool 2\ndef analyze_sentiment(text: str) -> dict:\n    \"\"\"Analyzes the sentiment of the given text.\n\n    Returns:\n        dict: A dictionary with 'sentiment' ('positive', 'negative', or 'neutral') and a 'confidence' score.\n    \"\"\"\n    if \"good\" in text.lower() or \"sunny\" in text.lower():\n        return {\"sentiment\": \"positive\", \"confidence\": 0.8}\n    elif \"rain\" in text.lower() or \"bad\" in text.lower():\n        return {\"sentiment\": \"negative\", \"confidence\": 0.7}\n    else:\n        return {\"sentiment\": \"neutral\", \"confidence\": 0.6}\n\nsentiment_tool = FunctionTool(func=analyze_sentiment)\n\n\n# Agent\nweather_sentiment_agent = Agent(\n    model=MODEL_ID,\n    name='weather_sentiment_agent',\n    instruction=\"\"\"You are a helpful assistant that provides weather information and analyzes the sentiment of user feedback.\n**If the user asks about the weather in a specific city, use the 'get_weather_report' tool to retrieve the weather details.**\n**If the 'get_weather_report' tool returns a 'success' status, provide the weather report to the user.**\n**If the 'get_weather_report' tool returns an 'error' status, inform the user that the weather information for the specified city is not available and ask if they have another city in mind.**\n**After providing a weather report, if the user gives feedback on the weather (e.g., 'That's good' or 'I don't like rain'), use the 'analyze_sentiment' tool to understand their sentiment.** Then, briefly acknowledge their sentiment.\nYou can handle these tasks sequentially if needed.\"\"\",\n    tools=[weather_tool, sentiment_tool]\n)\n\nasync def main():\n    \"\"\"Main function to run the agent asynchronously.\"\"\"\n    # Session and Runner Setup\n    session_service = InMemorySessionService()\n    # Use 'await' to correctly create the session\n    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n\n    runner = Runner(agent=weather_sentiment_agent, app_name=APP_NAME, session_service=session_service)\n\n    # Agent Interaction\n    query = \"weather in london?\"\n    print(f\"User Query: {query}\")\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n\n    # The runner's run method handles the async loop internally\n    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"Agent Response:\", final_response)\n\n# Standard way to run the main async function\nif __name__ == \"__main__\":\n    asyncio.run(main())"}, {"language": "text", "code": "// Copyright 2025 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\ntype getWeatherReportArgs struct {\n    City string `json:\"city\" jsonschema:\"The city for which to get the weather report.\"`\n}\n\ntype getWeatherReportResult struct {\n    Status       string `json:\"status\"`\n    Report       string `json:\"report,omitempty\"`\n    ErrorMessage string `json:\"error_message,omitempty\"`\n}\n\nfunc getWeatherReport(ctx tool.Context, args getWeatherReportArgs) getWeatherReportResult {\n    if strings.ToLower(args.City) == \"london\" {\n        return getWeatherReportResult{Status: \"success\", Report: \"The current weather in London is cloudy with a temperature of 18 degrees Celsius and a chance of rain.\"}\n    }\n    if strings.ToLower(args.City) == \"paris\" {\n        return getWeatherReportResult{Status: \"success\", Report: \"The weather in Paris is sunny with a temperature of 25 degrees Celsius.\"}\n    }\n    return getWeatherReportResult{Status: \"error\", ErrorMessage: fmt.Sprintf(\"Weather information for '%s' is not available.\", args.City)}\n}\n\ntype analyzeSentimentArgs struct {\n    Text string `json:\"text\" jsonschema:\"The text to analyze for sentiment.\"`\n}\n\ntype analyzeSentimentResult struct {\n    Sentiment  string  `json:\"sentiment\"`\n    Confidence float64 `json:\"confidence\"`\n}\n\nfunc analyzeSentiment(ctx tool.Context, args analyzeSentimentArgs) analyzeSentimentResult {\n    if strings.Contains(strings.ToLower(args.Text), \"good\") || strings.Contains(strings.ToLower(args.Text), \"sunny\") {\n        return analyzeSentimentResult{Sentiment: \"positive\", Confidence: 0.8}\n    }\n    if strings.Contains(strings.ToLower(args.Text), \"rain\") || strings.Contains(strings.ToLower(args.Text), \"bad\") {\n        return analyzeSentimentResult{Sentiment: \"negative\", Confidence: 0.7}\n    }\n    return analyzeSentimentResult{Sentiment: \"neutral\", Confidence: 0.6}\n}\n\nfunc main() {\n    ctx := context.Background()\n    model, err := gemini.NewModel(ctx, \"gemini-2.0-flash\", &genai.ClientConfig{})\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    weatherTool, err := functiontool.New(\n        functiontool.Config{\n            Name:        \"get_weather_report\",\n            Description: \"Retrieves the current weather report for a specified city.\",\n        },\n        getWeatherReport,\n    )\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    sentimentTool, err := functiontool.New(\n        functiontool.Config{\n            Name:        \"analyze_sentiment\",\n            Description: \"Analyzes the sentiment of the given text.\",\n        },\n        analyzeSentiment,\n    )\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    weatherSentimentAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"weather_sentiment_agent\",\n        Model:       model,\n        Instruction: \"You are a helpful assistant that provides weather information and analyzes the sentiment of user feedback. **If the user asks about the weather in a specific city, use the 'get_weather_report' tool to retrieve the weather details.** **If the 'get_weather_report' tool returns a 'success' status, provide the weather report to the user.** **If the 'get_weather_report' tool returns an 'error' status, inform the user that the weather information for the specified city is not available and ask if they have another city in mind.** **After providing a weather report, if the user gives feedback on the weather (e.g., 'That's good' or 'I don't like rain'), use the 'analyze_sentiment' tool to understand their sentiment.** Then, briefly acknowledge their sentiment. You can handle these tasks sequentially if needed.\",\n        Tools:       []tool.Tool{weatherTool, sentimentTool},\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    sessionService := session.InMemoryService()\n    runner, err := runner.New(runner.Config{\n        AppName:        \"weather_sentiment_agent\",\n        Agent:          weatherSentimentAgent,\n        SessionService: sessionService,\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    session, err := sessionService.Create(ctx, &session.CreateRequest{\n        AppName: \"weather_sentiment_agent\",\n        UserID:  \"user1234\",\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    run(ctx, runner, session.Session.ID(), \"weather in london?\")\n    run(ctx, runner, session.Session.ID(), \"I don't like rain.\")\n}\n\nfunc run(ctx context.Context, r *runner.Runner, sessionID string, prompt string) {\n    fmt.Printf(\"\\n> %s\\n\", prompt)\n    events := r.Run(\n        ctx,\n        \"user1234\",\n        sessionID,\n        genai.NewContentFromText(prompt, genai.RoleUser),\n        agent.RunConfig{\n            StreamingMode: agent.StreamingModeNone,\n        },\n    )\n    for event, err := range events {\n        if err != nil {\n            log.Fatalf(\"ERROR during agent execution: %v\", err)\n        }\n\n        if event.Content.Parts[0].Text != \"\" {\n            fmt.Printf(\"Agent Response: %s\\n\", event.Content.Parts[0].Text)\n        }\n    }\n}"}, {"language": "text", "code": "import com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.InMemorySessionService;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.Annotations.Schema;\nimport com.google.adk.tools.FunctionTool;\nimport com.google.adk.tools.ToolContext; // Ensure this import is correct\nimport com.google.common.collect.ImmutableList;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport java.util.HashMap;\nimport java.util.Locale;\nimport java.util.Map;\n\npublic class WeatherSentimentAgentApp {\n\n  private static final String APP_NAME = \"weather_sentiment_agent\";\n  private static final String USER_ID = \"user1234\";\n  private static final String SESSION_ID = \"1234\";\n  private static final String MODEL_ID = \"gemini-2.0-flash\";\n\n  /**\n   * Retrieves the current weather report for a specified city.\n   *\n   * @param city The city for which to retrieve the weather report.\n   * @param toolContext The context for the tool.\n   * @return A dictionary containing the weather information.\n   */\n  public static Map<String, Object> getWeatherReport(\n      @Schema(name = \"city\")\n      String city,\n      @Schema(name = \"toolContext\")\n      ToolContext toolContext) {\n    Map<String, Object> response = new HashMap<>();\n\n    if (city.toLowerCase(Locale.ROOT).equals(\"london\")) {\n      response.put(\"status\", \"success\");\n      response.put(\n          \"report\",\n          \"The current weather in London is cloudy with a temperature of 18 degrees Celsius and a\"\n              + \" chance of rain.\");\n    } else if (city.toLowerCase(Locale.ROOT).equals(\"paris\")) {\n      response.put(\"status\", \"success\");\n      response.put(\n          \"report\", \"The weather in Paris is sunny with a temperature of 25 degrees Celsius.\");\n    } else {\n      response.put(\"status\", \"error\");\n      response.put(\n          \"error_message\", String.format(\"Weather information for '%s' is not available.\", city));\n    }\n    return response;\n  }\n\n  /**\n   * Analyzes the sentiment of the given text.\n   *\n   * @param text The text to analyze.\n   * @param toolContext The context for the tool.\n   * @return A dictionary with sentiment and confidence score.\n   */\n  public static Map<String, Object> analyzeSentiment(\n      @Schema(name = \"text\")\n      String text,\n      @Schema(name = \"toolContext\")\n      ToolContext toolContext) {\n    Map<String, Object> response = new HashMap<>();\n    String lowerText = text.toLowerCase(Locale.ROOT);\n    if (lowerText.contains(\"good\") || lowerText.contains(\"sunny\")) {\n      response.put(\"sentiment\", \"positive\");\n      response.put(\"confidence\", 0.8);\n    } else if (lowerText.contains(\"rain\") || lowerText.contains(\"bad\")) {\n      response.put(\"sentiment\", \"negative\");\n      response.put(\"confidence\", 0.7);\n    } else {\n      response.put(\"sentiment\", \"neutral\");\n      response.put(\"confidence\", 0.6);\n    }\n    return response;\n  }\n\n  /**\n   * Calls the agent with the given query and prints the final response.\n   *\n   * @param runner The runner to use.\n   * @param query The query to send to the agent.\n   */\n  public static void callAgent(Runner runner, String query) {\n    Content content = Content.fromParts(Part.fromText(query));\n\n    InMemorySessionService sessionService = (InMemorySessionService) runner.sessionService();\n    Session session =\n        sessionService\n            .createSession(APP_NAME, USER_ID, /* state= */ null, SESSION_ID)\n            .blockingGet();\n\n    runner\n        .runAsync(session.userId(), session.id(), content)\n        .forEach(\n            event -> {\n              if (event.finalResponse()\n                  && event.content().isPresent()\n                  && event.content().get().parts().isPresent()\n                  && !event.content().get().parts().get().isEmpty()\n                  && event.content().get().parts().get().get(0).text().isPresent()) {\n                String finalResponse = event.content().get().parts().get().get(0).text().get();\n                System.out.println(\"Agent Response: \" + finalResponse);\n              }\n            });\n  }\n\n  public static void main(String[] args) throws NoSuchMethodException {\n    FunctionTool weatherTool =\n        FunctionTool.create(\n            WeatherSentimentAgentApp.class.getMethod(\n                \"getWeatherReport\", String.class, ToolContext.class));\n    FunctionTool sentimentTool =\n        FunctionTool.create(\n            WeatherSentimentAgentApp.class.getMethod(\n                \"analyzeSentiment\", String.class, ToolContext.class));\n\n    BaseAgent weatherSentimentAgent =\n        LlmAgent.builder()\n            .model(MODEL_ID)\n            .name(\"weather_sentiment_agent\")\n            .description(\"Weather Sentiment Agent\")\n            .instruction(\"\"\"\n                    You are a helpful assistant that provides weather information and analyzes the\n                    sentiment of user feedback\n                    **If the user asks about the weather in a specific city, use the\n                    'get_weather_report' tool to retrieve the weather details.**\n                    **If the 'get_weather_report' tool returns a 'success' status, provide the\n                    weather report to the user.**\n                    **If the 'get_weather_report' tool returns an 'error' status, inform the\n                    user that the weather information for the specified city is not available\n                    and ask if they have another city in mind.**\n                    **After providing a weather report, if the user gives feedback on the\n                    weather (e.g., 'That's good' or 'I don't like rain'), use the\n                    'analyze_sentiment' tool to understand their sentiment.** Then, briefly\n                    acknowledge their sentiment.\n                    You can handle these tasks sequentially if needed.\n                    \"\"\")\n            .tools(ImmutableList.of(weatherTool, sentimentTool))\n            .build();\n\n    InMemorySessionService sessionService = new InMemorySessionService();\n    Runner runner = new Runner(weatherSentimentAgent, APP_NAME, null, sessionService);\n\n    // Change the query to ensure the tool is called with a valid city that triggers a \"success\"\n    // response from the tool, like \"london\" (without the question mark).\n    callAgent(runner, \"weather in paris\");\n  }\n}"}]}, {"heading_path": ["Tool Context\u00b6"], "text": "Tool Context \u00b6 For more advanced scenarios, ADK allows you to access additional contextual information within your tool function by including the special parameter tool_context: ToolContext . By including this in the function signature, ADK will automatically provide an instance of the ToolContext class when your tool is called during agent execution. The ToolContext provides access to several key pieces of information and control levers: state: State : Read and modify the current session's state. Changes made here are tracked and persisted. actions: EventActions : Influence the agent's subsequent actions after the tool runs (e.g., skip summarization, transfer to another agent). function_call_id: str : The unique identifier assigned by the framework to this specific invocation of the tool. Useful for tracking and correlating with authentication responses. This can also be helpful when multiple tools are called within a single model response. function_call_event_id: str : This attribute provides the unique identifier of the event that triggered the current tool call. This can be useful for tracking and logging purposes. auth_response: Any : Contains the authentication response/credentials if an authentication flow was completed before this tool call. Access to Services: Methods to interact with configured services like Artifacts and Memory. Note that you shouldn't include the tool_context parameter in the tool function docstring. Since ToolContext is automatically injected by the ADK framework after the LLM decides to call the tool function, it is not relevant for the LLM's decision-making and including it can confuse the LLM. ", "code_blocks": []}, {"heading_path": ["State Management\u00b6"], "text": "State Management \u00b6 The tool_context.state attribute provides direct read and write access to the state associated with the current session. It behaves like a dictionary but ensures that any modifications are tracked as deltas and persisted by the session service. This enables tools to maintain and share information across different interactions and agent steps. Reading State : Use standard dictionary access ( tool_context.state['my_key'] ) or the .get() method ( tool_context.state.get('my_key', default_value) ). Writing State : Assign values directly ( tool_context.state['new_key'] = 'new_value' ). These changes are recorded in the state_delta of the resulting event. State Prefixes : Remember the standard state prefixes: app:* : Shared across all users of the application. user:* : Specific to the current user across all their sessions. (No prefix): Specific to the current session. temp:* : Temporary, not persisted across invocations (useful for passing data within a single run call but generally less useful inside a tool context which operates between LLM calls). Python Go Java from google.adk.tools import ToolContext , FunctionTool def update_user_preference ( preference : str , value : str , tool_context : ToolContext ): \"\"\"Updates a user-specific preference.\"\"\" user_prefs_key = \"user:preferences\" # Get current preferences or initialize if none exist preferences = tool_context . state . get ( user_prefs_key , {}) preferences [ preference ] = value # Write the updated dictionary back to the state tool_context . state [ user_prefs_key ] = preferences print ( f \"Tool: Updated user preference ' { preference } ' to ' { value } '\" ) return { \"status\" : \"success\" , \"updated_preference\" : preference } pref_tool = FunctionTool ( func = update_user_preference ) # In an Agent: # my_agent = Agent(..., tools=[pref_tool]) # When the LLM calls update_user_preference(preference='theme', value='dark', ...): # The tool_context.state will be updated, and the change will be part of the # resulting tool response event's actions.state_delta. import ( \"fmt\" \"google.golang.org/adk/tool\" ) type updateUserPreferenceArgs struct { Preference string `json:\"preference\" jsonschema:\"The name of the preference to set.\"` Value string `json:\"value\" jsonschema:\"The value to set for the preference.\"` } type updateUserPreferenceResult struct { Status string `json:\"status\"` UpdatedPreference string `json:\"updated_preference\"` } func updateUserPreference ( ctx tool . Context , args updateUserPreferenceArgs ) updateUserPreferenceResult { userPrefsKey := \"user:preferences\" val , err := ctx . State (). Get ( userPrefsKey ) if err != nil { val = make ( map [ string ] any ) } preferencesMap , ok := val .( map [ string ] any ) if ! ok { preferencesMap = make ( map [ string ] any ) } preferencesMap [ args . Preference ] = args . Value if err := ctx . State (). Set ( userPrefsKey , preferencesMap ); err != nil { return updateUserPreferenceResult { Status : \"error\" } } fmt . Printf ( \"Tool: Updated user preference '%s' to '%s'\\n\" , args . Preference , args . Value ) return updateUserPreferenceResult { Status : \"success\" , UpdatedPreference : args . Preference } } import com.google.adk.tools.FunctionTool ; import com.google.adk.tools.ToolContext ; // Updates a user-specific preference. public Map < String , String > updateUserThemePreference ( String value , ToolContext toolContext ) { String userPrefsKey = \"user:preferences:theme\" ; // Get current preferences or initialize if none exist String preference = toolContext . state (). getOrDefault ( userPrefsKey , \"\" ). toString (); if ( preference . isEmpty ()) { preference = value ; } // Write the updated dictionary back to the state toolContext . state (). put ( \"user:preferences\" , preference ); System . out . printf ( \"Tool: Updated user preference %s to %s\" , userPrefsKey , preference ); return Map . of ( \"status\" , \"success\" , \"updated_preference\" , toolContext . state (). get ( userPrefsKey ). toString ()); // When the LLM calls updateUserThemePreference(\"dark\"): // The toolContext.state will be updated, and the change will be part of the // resulting tool response event's actions.stateDelta. } ", "code_blocks": [{"language": "text", "code": "from google.adk.tools import ToolContext, FunctionTool\n\ndef update_user_preference(preference: str, value: str, tool_context: ToolContext):\n    \"\"\"Updates a user-specific preference.\"\"\"\n    user_prefs_key = \"user:preferences\"\n    # Get current preferences or initialize if none exist\n    preferences = tool_context.state.get(user_prefs_key, {})\n    preferences[preference] = value\n    # Write the updated dictionary back to the state\n    tool_context.state[user_prefs_key] = preferences\n    print(f\"Tool: Updated user preference '{preference}' to '{value}'\")\n    return {\"status\": \"success\", \"updated_preference\": preference}\n\npref_tool = FunctionTool(func=update_user_preference)\n\n# In an Agent:\n# my_agent = Agent(..., tools=[pref_tool])\n\n# When the LLM calls update_user_preference(preference='theme', value='dark', ...):\n# The tool_context.state will be updated, and the change will be part of the\n# resulting tool response event's actions.state_delta."}, {"language": "text", "code": "import (\n    \"fmt\"\n\n    \"google.golang.org/adk/tool\"\n)\n\ntype updateUserPreferenceArgs struct {\n    Preference string `json:\"preference\" jsonschema:\"The name of the preference to set.\"`\n    Value      string `json:\"value\" jsonschema:\"The value to set for the preference.\"`\n}\n\ntype updateUserPreferenceResult struct {\n    Status            string `json:\"status\"`\n    UpdatedPreference string `json:\"updated_preference\"`\n}\n\nfunc updateUserPreference(ctx tool.Context, args updateUserPreferenceArgs) updateUserPreferenceResult {\n    userPrefsKey := \"user:preferences\"\n    val, err := ctx.State().Get(userPrefsKey)\n    if err != nil {\n        val = make(map[string]any)\n    }\n\n    preferencesMap, ok := val.(map[string]any)\n    if !ok {\n        preferencesMap = make(map[string]any)\n    }\n\n    preferencesMap[args.Preference] = args.Value\n\n    if err := ctx.State().Set(userPrefsKey, preferencesMap); err != nil {\n        return updateUserPreferenceResult{Status: \"error\"}\n    }\n\n    fmt.Printf(\"Tool: Updated user preference '%s' to '%s'\\n\", args.Preference, args.Value)\n    return updateUserPreferenceResult{Status: \"success\", UpdatedPreference: args.Preference}\n}"}, {"language": "text", "code": "import com.google.adk.tools.FunctionTool;\nimport com.google.adk.tools.ToolContext;\n\n// Updates a user-specific preference.\npublic Map<String, String> updateUserThemePreference(String value, ToolContext toolContext) {\n  String userPrefsKey = \"user:preferences:theme\";\n\n  // Get current preferences or initialize if none exist\n  String preference = toolContext.state().getOrDefault(userPrefsKey, \"\").toString();\n  if (preference.isEmpty()) {\n    preference = value;\n  }\n\n  // Write the updated dictionary back to the state\n  toolContext.state().put(\"user:preferences\", preference);\n  System.out.printf(\"Tool: Updated user preference %s to %s\", userPrefsKey, preference);\n\n  return Map.of(\"status\", \"success\", \"updated_preference\", toolContext.state().get(userPrefsKey).toString());\n  // When the LLM calls updateUserThemePreference(\"dark\"):\n  // The toolContext.state will be updated, and the change will be part of the\n  // resulting tool response event's actions.stateDelta.\n}"}]}, {"heading_path": ["Controlling Agent Flow\u00b6"], "text": "Controlling Agent Flow \u00b6 The tool_context.actions attribute ( ToolContext.actions() in Java and tool.Context.Actions() in Go) holds an EventActions object. Modifying attributes on this object allows your tool to influence what the agent or framework does after the tool finishes execution. skip_summarization: bool : (Default: False) If set to True, instructs the ADK to bypass the LLM call that typically summarizes the tool's output. This is useful if your tool's return value is already a user-ready message. transfer_to_agent: str : Set this to the name of another agent. The framework will halt the current agent's execution and transfer control of the conversation to the specified agent . This allows tools to dynamically hand off tasks to more specialized agents. escalate: bool : (Default: False) Setting this to True signals that the current agent cannot handle the request and should pass control up to its parent agent (if in a hierarchy). In a LoopAgent, setting escalate=True in a sub-agent's tool will terminate the loop. ", "code_blocks": []}, {"heading_path": ["Example\u00b6"], "text": "Example \u00b6 Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.agents import Agent from google.adk.tools import FunctionTool from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.tools import ToolContext from google.genai import types APP_NAME = \"customer_support_agent\" USER_ID = \"user1234\" SESSION_ID = \"1234\" def check_and_transfer ( query : str , tool_context : ToolContext ) -> str : \"\"\"Checks if the query requires escalation and transfers to another agent if needed.\"\"\" if \"urgent\" in query . lower (): print ( \"Tool: Detected urgency, transferring to the support agent.\" ) tool_context . actions . transfer_to_agent = \"support_agent\" return \"Transferring to the support agent...\" else : return f \"Processed query: ' { query } '. No further action needed.\" escalation_tool = FunctionTool ( func = check_and_transfer ) main_agent = Agent ( model = 'gemini-2.0-flash' , name = 'main_agent' , instruction = \"\"\"You are the first point of contact for customer support of an analytics tool. Answer general queries. If the user indicates urgency, use the 'check_and_transfer' tool.\"\"\" , tools = [ check_and_transfer ] ) support_agent = Agent ( model = 'gemini-2.0-flash' , name = 'support_agent' , instruction = \"\"\"You are the dedicated support agent. Mentioned you are a support handler and please help the user with their urgent issue.\"\"\" ) main_agent . sub_agents = [ support_agent ] # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = main_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) async for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response: \" , final_response ) # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"this is urgent, i cant login\" ) // Copyright 2025 Google LLC // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // //     http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package main import ( \"context\" \"fmt\" \"log\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) type checkAndTransferArgs struct { Query string `json:\"query\" jsonschema:\"The user's query to check for urgency.\"` } type checkAndTransferResult struct { Status string `json:\"status\"` } func checkAndTransfer ( ctx tool . Context , args checkAndTransferArgs ) checkAndTransferResult { if strings . Contains ( strings . ToLower ( args . Query ), \"urgent\" ) { fmt . Println ( \"Tool: Detected urgency, transferring to the support agent.\" ) ctx . Actions (). TransferToAgent = \"support_agent\" return checkAndTransferResult { Status : \"Transferring to the support agent...\" } } return checkAndTransferResult { Status : fmt . Sprintf ( \"Processed query: '%s'. No further action needed.\" , args . Query )} } func main () { ctx := context . Background () model , err := gemini . NewModel ( ctx , \"gemini-2.0-flash\" , & genai . ClientConfig {}) if err != nil { log . Fatal ( err ) } supportAgent , err := llmagent . New ( llmagent . Config { Name : \"support_agent\" , Model : model , Instruction : \"You are the dedicated support agent. Mentioned you are a support handler and please help the user with their urgent issue.\" , }) if err != nil { log . Fatal ( err ) } checkAndTransferTool , err := functiontool . New ( functiontool . Config { Name : \"check_and_transfer\" , Description : \"Checks if the query requires escalation and transfers to another agent if needed.\" , }, checkAndTransfer , ) if err != nil { log . Fatal ( err ) } mainAgent , err := llmagent . New ( llmagent . Config { Name : \"main_agent\" , Model : model , Instruction : \"You are the first point of contact for customer support of an analytics tool. Answer general queries. If the user indicates urgency, use the 'check_and_transfer' tool.\" , Tools : [] tool . Tool { checkAndTransferTool }, SubAgents : [] agent . Agent { supportAgent }, }) if err != nil { log . Fatal ( err ) } sessionService := session . InMemoryService () runner , err := runner . New ( runner . Config { AppName : \"customer_support_agent\" , Agent : mainAgent , SessionService : sessionService , }) if err != nil { log . Fatal ( err ) } session , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : \"customer_support_agent\" , UserID : \"user1234\" , }) if err != nil { log . Fatal ( err ) } run ( ctx , runner , session . Session . ID (), \"this is urgent, i cant login\" ) } func run ( ctx context . Context , r * runner . Runner , sessionID string , prompt string ) { fmt . Printf ( \"\\n> %s\\n\" , prompt ) events := r . Run ( ctx , \"user1234\" , sessionID , genai . NewContentFromText ( prompt , genai . RoleUser ), agent . RunConfig { StreamingMode : agent . StreamingModeNone , }, ) for event , err := range events { if err != nil { log . Fatalf ( \"ERROR during agent execution: %v\" , err ) } if event . Content . Parts [ 0 ]. Text != \"\" { fmt . Printf ( \"Agent Response: %s\\n\" , event . Content . Parts [ 0 ]. Text ) } } } import com.google.adk.agents.LlmAgent ; import com.google.adk.runner.Runner ; import com.google.adk.sessions.InMemorySessionService ; import com.google.adk.sessions.Session ; import com.google.adk.tools.Annotations.Schema ; import com.google.adk.tools.FunctionTool ; import com.google.adk.tools.ToolContext ; import com.google.common.collect.ImmutableList ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import java.util.HashMap ; import java.util.Locale ; import java.util.Map ; public class CustomerSupportAgentApp { private static final String APP_NAME = \"customer_support_agent\" ; private static final String USER_ID = \"user1234\" ; private static final String SESSION_ID = \"1234\" ; private static final String MODEL_ID = \"gemini-2.0-flash\" ; /** * Checks if the query requires escalation and transfers to another agent if needed. * * @param query The user's query. * @param toolContext The context for the tool. * @return A map indicating the result of the check and transfer. */ public static Map < String , Object > checkAndTransfer ( @Schema ( name = \"query\" , description = \"the user query\" ) String query , @Schema ( name = \"toolContext\" , description = \"the tool context\" ) ToolContext toolContext ) { Map < String , Object > response = new HashMap <> (); if ( query . toLowerCase ( Locale . ROOT ). contains ( \"urgent\" )) { System . out . println ( \"Tool: Detected urgency, transferring to the support agent.\" ); toolContext . actions (). setTransferToAgent ( \"support_agent\" ); response . put ( \"status\" , \"transferring\" ); response . put ( \"message\" , \"Transferring to the support agent...\" ); } else { response . put ( \"status\" , \"processed\" ); response . put ( \"message\" , String . format ( \"Processed query: '%s'. No further action needed.\" , query )); } return response ; } /** * Calls the agent with the given query and prints the final response. * * @param runner The runner to use. * @param query The query to send to the agent. */ public static void callAgent ( Runner runner , String query ) { Content content = Content . fromParts ( Part . fromText ( query )); InMemorySessionService sessionService = ( InMemorySessionService ) runner . sessionService (); // Fixed: session ID does not need to be an optional. Session session = sessionService . createSession ( APP_NAME , USER_ID , /* state= */ null , SESSION_ID ) . blockingGet (); runner . runAsync ( session . userId (), session . id (), content ) . forEach ( event -> { if ( event . finalResponse () && event . content (). isPresent () && event . content (). get (). parts (). isPresent () && ! event . content (). get (). parts (). get (). isEmpty () && event . content (). get (). parts (). get (). get ( 0 ). text (). isPresent ()) { String finalResponse = event . content (). get (). parts (). get (). get ( 0 ). text (). get (); System . out . println ( \"Agent Response: \" + finalResponse ); } }); } public static void main ( String [] args ) throws NoSuchMethodException { FunctionTool escalationTool = FunctionTool . create ( CustomerSupportAgentApp . class . getMethod ( \"checkAndTransfer\" , String . class , ToolContext . class )); LlmAgent supportAgent = LlmAgent . builder () . model ( MODEL_ID ) . name ( \"support_agent\" ) . description ( \"\"\" The dedicated support agent. Mentions it is a support handler and helps the user with their urgent issue. \"\"\" ) . instruction ( \"\"\" You are the dedicated support agent. Mentioned you are a support handler and please help the user with their urgent issue. \"\"\" ) . build (); LlmAgent mainAgent = LlmAgent . builder () . model ( MODEL_ID ) . name ( \"main_agent\" ) . description ( \"\"\" The first point of contact for customer support of an analytics tool. Answers general queries. If the user indicates urgency, uses the 'check_and_transfer' tool. \"\"\" ) . instruction ( \"\"\" You are the first point of contact for customer support of an analytics tool. Answer general queries. If the user indicates urgency, use the 'check_and_transfer' tool. \"\"\" ) . tools ( ImmutableList . of ( escalationTool )) . subAgents ( supportAgent ) . build (); // Fixed: LlmAgent.subAgents() expects 0 arguments. // Sub-agents are now added to the main agent via its builder, // as `subAgents` is a property that should be set during agent construction // if it's not dynamically managed. InMemorySessionService sessionService = new InMemorySessionService (); Runner runner = new Runner ( mainAgent , APP_NAME , null , sessionService ); // Agent Interaction callAgent ( runner , \"this is urgent, i cant login\" ); } } ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.agents import Agent\nfrom google.adk.tools import FunctionTool\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import ToolContext\nfrom google.genai import types\n\nAPP_NAME=\"customer_support_agent\"\nUSER_ID=\"user1234\"\nSESSION_ID=\"1234\"\n\n\ndef check_and_transfer(query: str, tool_context: ToolContext) -> str:\n    \"\"\"Checks if the query requires escalation and transfers to another agent if needed.\"\"\"\n    if \"urgent\" in query.lower():\n        print(\"Tool: Detected urgency, transferring to the support agent.\")\n        tool_context.actions.transfer_to_agent = \"support_agent\"\n        return \"Transferring to the support agent...\"\n    else:\n        return f\"Processed query: '{query}'. No further action needed.\"\n\nescalation_tool = FunctionTool(func=check_and_transfer)\n\nmain_agent = Agent(\n    model='gemini-2.0-flash',\n    name='main_agent',\n    instruction=\"\"\"You are the first point of contact for customer support of an analytics tool. Answer general queries. If the user indicates urgency, use the 'check_and_transfer' tool.\"\"\",\n    tools=[check_and_transfer]\n)\n\nsupport_agent = Agent(\n    model='gemini-2.0-flash',\n    name='support_agent',\n    instruction=\"\"\"You are the dedicated support agent. Mentioned you are a support handler and please help the user with their urgent issue.\"\"\"\n)\n\nmain_agent.sub_agents = [support_agent]\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=main_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n# Agent Interaction\nasync def call_agent_async(query):\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    async for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"Agent Response: \", final_response)\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"this is urgent, i cant login\")"}, {"language": "text", "code": "// Copyright 2025 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\ntype checkAndTransferArgs struct {\n    Query string `json:\"query\" jsonschema:\"The user's query to check for urgency.\"`\n}\n\ntype checkAndTransferResult struct {\n    Status string `json:\"status\"`\n}\n\nfunc checkAndTransfer(ctx tool.Context, args checkAndTransferArgs) checkAndTransferResult {\n    if strings.Contains(strings.ToLower(args.Query), \"urgent\") {\n        fmt.Println(\"Tool: Detected urgency, transferring to the support agent.\")\n        ctx.Actions().TransferToAgent = \"support_agent\"\n        return checkAndTransferResult{Status: \"Transferring to the support agent...\"}\n    }\n    return checkAndTransferResult{Status: fmt.Sprintf(\"Processed query: '%s'. No further action needed.\", args.Query)}\n}\n\nfunc main() {\n    ctx := context.Background()\n    model, err := gemini.NewModel(ctx, \"gemini-2.0-flash\", &genai.ClientConfig{})\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    supportAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"support_agent\",\n        Model:       model,\n        Instruction: \"You are the dedicated support agent. Mentioned you are a support handler and please help the user with their urgent issue.\",\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    checkAndTransferTool, err := functiontool.New(\n        functiontool.Config{\n            Name:        \"check_and_transfer\",\n            Description: \"Checks if the query requires escalation and transfers to another agent if needed.\",\n        },\n        checkAndTransfer,\n    )\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    mainAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"main_agent\",\n        Model:       model,\n        Instruction: \"You are the first point of contact for customer support of an analytics tool. Answer general queries. If the user indicates urgency, use the 'check_and_transfer' tool.\",\n        Tools:       []tool.Tool{checkAndTransferTool},\n        SubAgents:   []agent.Agent{supportAgent},\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    sessionService := session.InMemoryService()\n    runner, err := runner.New(runner.Config{\n        AppName:        \"customer_support_agent\",\n        Agent:          mainAgent,\n        SessionService: sessionService,\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    session, err := sessionService.Create(ctx, &session.CreateRequest{\n        AppName: \"customer_support_agent\",\n        UserID:  \"user1234\",\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    run(ctx, runner, session.Session.ID(), \"this is urgent, i cant login\")\n}\n\nfunc run(ctx context.Context, r *runner.Runner, sessionID string, prompt string) {\n    fmt.Printf(\"\\n> %s\\n\", prompt)\n    events := r.Run(\n        ctx,\n        \"user1234\",\n        sessionID,\n        genai.NewContentFromText(prompt, genai.RoleUser),\n        agent.RunConfig{\n            StreamingMode: agent.StreamingModeNone,\n        },\n    )\n    for event, err := range events {\n        if err != nil {\n            log.Fatalf(\"ERROR during agent execution: %v\", err)\n        }\n\n        if event.Content.Parts[0].Text != \"\" {\n            fmt.Printf(\"Agent Response: %s\\n\", event.Content.Parts[0].Text)\n        }\n    }\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.InMemorySessionService;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.Annotations.Schema;\nimport com.google.adk.tools.FunctionTool;\nimport com.google.adk.tools.ToolContext;\nimport com.google.common.collect.ImmutableList;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport java.util.HashMap;\nimport java.util.Locale;\nimport java.util.Map;\n\npublic class CustomerSupportAgentApp {\n\n  private static final String APP_NAME = \"customer_support_agent\";\n  private static final String USER_ID = \"user1234\";\n  private static final String SESSION_ID = \"1234\";\n  private static final String MODEL_ID = \"gemini-2.0-flash\";\n\n  /**\n   * Checks if the query requires escalation and transfers to another agent if needed.\n   *\n   * @param query The user's query.\n   * @param toolContext The context for the tool.\n   * @return A map indicating the result of the check and transfer.\n   */\n  public static Map<String, Object> checkAndTransfer(\n      @Schema(name = \"query\", description = \"the user query\")\n      String query,\n      @Schema(name = \"toolContext\", description = \"the tool context\")\n      ToolContext toolContext) {\n    Map<String, Object> response = new HashMap<>();\n    if (query.toLowerCase(Locale.ROOT).contains(\"urgent\")) {\n      System.out.println(\"Tool: Detected urgency, transferring to the support agent.\");\n      toolContext.actions().setTransferToAgent(\"support_agent\");\n      response.put(\"status\", \"transferring\");\n      response.put(\"message\", \"Transferring to the support agent...\");\n    } else {\n      response.put(\"status\", \"processed\");\n      response.put(\n          \"message\", String.format(\"Processed query: '%s'. No further action needed.\", query));\n    }\n    return response;\n  }\n\n  /**\n   * Calls the agent with the given query and prints the final response.\n   *\n   * @param runner The runner to use.\n   * @param query The query to send to the agent.\n   */\n  public static void callAgent(Runner runner, String query) {\n    Content content =\n        Content.fromParts(Part.fromText(query));\n\n    InMemorySessionService sessionService = (InMemorySessionService) runner.sessionService();\n    // Fixed: session ID does not need to be an optional.\n    Session session =\n        sessionService\n            .createSession(APP_NAME, USER_ID, /* state= */ null, SESSION_ID)\n            .blockingGet();\n\n    runner\n        .runAsync(session.userId(), session.id(), content)\n        .forEach(\n            event -> {\n              if (event.finalResponse()\n                  && event.content().isPresent()\n                  && event.content().get().parts().isPresent()\n                  && !event.content().get().parts().get().isEmpty()\n                  && event.content().get().parts().get().get(0).text().isPresent()) {\n                String finalResponse = event.content().get().parts().get().get(0).text().get();\n                System.out.println(\"Agent Response: \" + finalResponse);\n              }\n            });\n  }\n\n  public static void main(String[] args) throws NoSuchMethodException {\n    FunctionTool escalationTool =\n        FunctionTool.create(\n            CustomerSupportAgentApp.class.getMethod(\n                \"checkAndTransfer\", String.class, ToolContext.class));\n\n    LlmAgent supportAgent =\n        LlmAgent.builder()\n            .model(MODEL_ID)\n            .name(\"support_agent\")\n            .description(\"\"\"\n                The dedicated support agent.\n                Mentions it is a support handler and helps the user with their urgent issue.\n            \"\"\")\n            .instruction(\"\"\"\n                You are the dedicated support agent.\n                Mentioned you are a support handler and please help the user with their urgent issue.\n            \"\"\")\n            .build();\n\n    LlmAgent mainAgent =\n        LlmAgent.builder()\n            .model(MODEL_ID)\n            .name(\"main_agent\")\n            .description(\"\"\"\n                The first point of contact for customer support of an analytics tool.\n                Answers general queries.\n                If the user indicates urgency, uses the 'check_and_transfer' tool.\n                \"\"\")\n            .instruction(\"\"\"\n                You are the first point of contact for customer support of an analytics tool.\n                Answer general queries.\n                If the user indicates urgency, use the 'check_and_transfer' tool.\n                \"\"\")\n            .tools(ImmutableList.of(escalationTool))\n            .subAgents(supportAgent)\n            .build();\n    // Fixed: LlmAgent.subAgents() expects 0 arguments.\n    // Sub-agents are now added to the main agent via its builder,\n    // as `subAgents` is a property that should be set during agent construction\n    // if it's not dynamically managed.\n\n    InMemorySessionService sessionService = new InMemorySessionService();\n    Runner runner = new Runner(mainAgent, APP_NAME, null, sessionService);\n\n    // Agent Interaction\n    callAgent(runner, \"this is urgent, i cant login\");\n  }\n}"}]}, {"heading_path": ["Explanation\u00b6"], "text": "Explanation \u00b6 We define two agents: main_agent and support_agent . The main_agent is designed to be the initial point of contact. The check_and_transfer tool, when called by main_agent , examines the user's query. If the query contains the word \"urgent\", the tool accesses the tool_context , specifically tool_context.actions , and sets the transfer_to_agent attribute to support_agent . This action signals to the framework to transfer the control of the conversation to the agent named support_agent . When the main_agent processes the urgent query, the check_and_transfer tool triggers the transfer. The subsequent response would ideally come from the support_agent . For a normal query without urgency, the tool simply processes it without triggering a transfer. This example illustrates how a tool, through EventActions in its ToolContext, can dynamically influence the flow of the conversation by transferring control to another specialized agent. ", "code_blocks": []}, {"heading_path": ["Authentication\u00b6"], "text": "Authentication \u00b6 Supported in ADK Python v0.1.0 ToolContext provides mechanisms for tools interacting with authenticated APIs. If your tool needs to handle authentication, you might use the following: auth_response : Contains credentials (e.g., a token) if authentication was already handled by the framework before your tool was called (common with RestApiTool and OpenAPI security schemes). request_credential(auth_config: dict) : Call this method if your tool determines authentication is needed but credentials aren't available. This signals the framework to start an authentication flow based on the provided auth_config. get_auth_response() : Call this in a subsequent invocation (after request_credential was successfully handled) to retrieve the credentials the user provided. For detailed explanations of authentication flows, configuration, and examples, please refer to the dedicated Tool Authentication documentation page. ", "code_blocks": []}, {"heading_path": ["Context-Aware Data Access Methods\u00b6"], "text": "Context-Aware Data Access Methods \u00b6 These methods provide convenient ways for your tool to interact with persistent data associated with the session or user, managed by configured services. list_artifacts() (or listArtifacts() in Java): Returns a list of filenames (or keys) for all artifacts currently stored for the session via the artifact_service. Artifacts are typically files (images, documents, etc.) uploaded by the user or generated by tools/agents. load_artifact(filename: str) : Retrieves a specific artifact by its filename from the artifact_service . You can optionally specify a version; if omitted, the latest version is returned. Returns a google.genai.types.Part object containing the artifact data and mime type, or None if not found. save_artifact(filename: str, artifact: types.Part) : Saves a new version of an artifact to the artifact_service. Returns the new version number (starting from 0). search_memory(query: str) : (Support in ADK Python and Go)\n    Queries the user's long-term memory using the configured memory_service . This is useful for retrieving relevant information from past interactions or stored knowledge. The structure of the SearchMemoryResponse depends on the specific memory service implementation but typically contains relevant text snippets or conversation excerpts. ", "code_blocks": []}, {"heading_path": ["Example\u00b6"], "text": "Example \u00b6 Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.tools import ToolContext , FunctionTool from google.genai import types def process_document ( document_name : str , analysis_query : str , tool_context : ToolContext ) -> dict : \"\"\"Analyzes a document using context from memory.\"\"\" # 1. Load the artifact print ( f \"Tool: Attempting to load artifact: { document_name } \" ) document_part = tool_context . load_artifact ( document_name ) if not document_part : return { \"status\" : \"error\" , \"message\" : f \"Document ' { document_name } ' not found.\" } document_text = document_part . text # Assuming it's text for simplicity print ( f \"Tool: Loaded document ' { document_name } ' ( { len ( document_text ) } chars).\" ) # 2. Search memory for related context print ( f \"Tool: Searching memory for context related to: ' { analysis_query } '\" ) memory_response = tool_context . search_memory ( f \"Context for analyzing document about { analysis_query } \" ) memory_context = \" \\n \" . join ( [ m . events [ 0 ] . content . parts [ 0 ] . text for m in memory_response . memories if m . events and m . events [ 0 ] . content ] ) # Simplified extraction print ( f \"Tool: Found memory context: { memory_context [: 100 ] } ...\" ) # 3. Perform analysis (placeholder) analysis_result = f \"Analysis of ' { document_name } ' regarding ' { analysis_query } ' using memory context: [Placeholder Analysis Result]\" print ( \"Tool: Performed analysis.\" ) # 4. Save the analysis result as a new artifact analysis_part = types . Part . from_text ( text = analysis_result ) new_artifact_name = f \"analysis_ { document_name } \" version = await tool_context . save_artifact ( new_artifact_name , analysis_part ) print ( f \"Tool: Saved analysis result as ' { new_artifact_name } ' version { version } .\" ) return { \"status\" : \"success\" , \"analysis_artifact\" : new_artifact_name , \"version\" : version , } doc_analysis_tool = FunctionTool ( func = process_document ) # In an Agent: # Assume artifact 'report.txt' was previously saved. # Assume memory service is configured and has relevant past data. # my_agent = Agent(..., tools=[doc_analysis_tool], artifact_service=..., memory_service=...) // Copyright 2025 Google LLC // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // //     http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package main import ( \"fmt\" \"google.golang.org/adk/tool\" \"google.golang.org/genai\" ) type processDocumentArgs struct { DocumentName string `json:\"document_name\" jsonschema:\"The name of the document to be processed.\"` AnalysisQuery string `json:\"analysis_query\" jsonschema:\"The query for the analysis.\"` } type processDocumentResult struct { Status string `json:\"status\"` AnalysisArtifact string `json:\"analysis_artifact,omitempty\"` Version int64 `json:\"version,omitempty\"` Message string `json:\"message,omitempty\"` } func processDocument ( ctx tool . Context , args processDocumentArgs ) processDocumentResult { fmt . Printf ( \"Tool: Attempting to load artifact: %s\\n\" , args . DocumentName ) // List all artifacts listResponse , err := ctx . Artifacts (). List ( ctx ) if err != nil { return processDocumentResult { Status : \"error\" , Message : \"Failed to list artifacts.\" } } fmt . Println ( \"Tool: Available artifacts:\" ) for _ , file := range listResponse . FileNames { fmt . Printf ( \" - %s\\n\" , file ) } documentPart , err := ctx . Artifacts (). Load ( ctx , args . DocumentName ) if err != nil { return processDocumentResult { Status : \"error\" , Message : fmt . Sprintf ( \"Document '%s' not found.\" , args . DocumentName )} } fmt . Printf ( \"Tool: Loaded document '%s' of size %d bytes.\\n\" , args . DocumentName , len ( documentPart . Part . InlineData . Data )) // 3. Search memory for related context fmt . Printf ( \"Tool: Searching memory for context related to: '%s'\\n\" , args . AnalysisQuery ) memoryResp , err := ctx . SearchMemory ( ctx , args . AnalysisQuery ) if err != nil { fmt . Printf ( \"Tool: Error searching memory: %v\\n\" , err ) } memoryResultCount := 0 if memoryResp != nil { memoryResultCount = len ( memoryResp . Memories ) } fmt . Printf ( \"Tool: Found %d memory results.\\n\" , memoryResultCount ) analysisResult := fmt . Sprintf ( \"Analysis of '%s' regarding '%s' using memory context: [Placeholder Analysis Result]\" , args . DocumentName , args . AnalysisQuery ) fmt . Println ( \"Tool: Performed analysis.\" ) analysisPart := genai . NewPartFromText ( analysisResult ) newArtifactName := fmt . Sprintf ( \"analysis_%s\" , args . DocumentName ) version , err := ctx . Artifacts (). Save ( ctx , newArtifactName , analysisPart ) if err != nil { return processDocumentResult { Status : \"error\" , Message : \"Failed to save artifact.\" } } fmt . Printf ( \"Tool: Saved analysis result as '%s' version %d.\\n\" , newArtifactName , version . Version ) return processDocumentResult { Status : \"success\" , AnalysisArtifact : newArtifactName , Version : version . Version , } } // Analyzes a document using context from memory. // You can also list, load and save artifacts using Callback Context or LoadArtifacts tool. public static @NonNull Maybe < ImmutableMap < String , Object >> processDocument ( @Annotations.Schema ( description = \"The name of the document to analyze.\" ) String documentName , @Annotations.Schema ( description = \"The query for the analysis.\" ) String analysisQuery , ToolContext toolContext ) { // 1. List all available artifacts System . out . printf ( \"Listing all available artifacts %s:\" , toolContext . listArtifacts (). blockingGet ()); // 2. Load an artifact to memory System . out . println ( \"Tool: Attempting to load artifact: \" + documentName ); Part documentPart = toolContext . loadArtifact ( documentName , Optional . empty ()). blockingGet (); if ( documentPart == null ) { System . out . println ( \"Tool: Document '\" + documentName + \"' not found.\" ); return Maybe . just ( ImmutableMap . < String , Object > of ( \"status\" , \"error\" , \"message\" , \"Document '\" + documentName + \"' not found.\" )); } String documentText = documentPart . text (). orElse ( \"\" ); System . out . println ( \"Tool: Loaded document '\" + documentName + \"' (\" + documentText . length () + \" chars).\" ); // 3. Perform analysis (placeholder) String analysisResult = \"Analysis of '\" + documentName + \"' regarding '\" + analysisQuery + \" [Placeholder Analysis Result]\" ; System . out . println ( \"Tool: Performed analysis.\" ); // 4. Save the analysis result as a new artifact Part analysisPart = Part . fromText ( analysisResult ); String newArtifactName = \"analysis_\" + documentName ; toolContext . saveArtifact ( newArtifactName , analysisPart ); return Maybe . just ( ImmutableMap . < String , Object > builder () . put ( \"status\" , \"success\" ) . put ( \"analysis_artifact\" , newArtifactName ) . build ()); } // FunctionTool processDocumentTool = //      FunctionTool.create(ToolContextArtifactExample.class, \"processDocument\"); // In the Agent, include this function tool. // LlmAgent agent = LlmAgent().builder().tools(processDocumentTool).build(); By leveraging the ToolContext , developers can create more sophisticated and context-aware custom tools that seamlessly integrate with ADK's architecture and enhance the overall capabilities of their agents. ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.tools import ToolContext, FunctionTool\nfrom google.genai import types\n\n\ndef process_document(\n    document_name: str, analysis_query: str, tool_context: ToolContext\n) -> dict:\n    \"\"\"Analyzes a document using context from memory.\"\"\"\n\n    # 1. Load the artifact\n    print(f\"Tool: Attempting to load artifact: {document_name}\")\n    document_part = tool_context.load_artifact(document_name)\n\n    if not document_part:\n        return {\"status\": \"error\", \"message\": f\"Document '{document_name}' not found.\"}\n\n    document_text = document_part.text  # Assuming it's text for simplicity\n    print(f\"Tool: Loaded document '{document_name}' ({len(document_text)} chars).\")\n\n    # 2. Search memory for related context\n    print(f\"Tool: Searching memory for context related to: '{analysis_query}'\")\n    memory_response = tool_context.search_memory(\n        f\"Context for analyzing document about {analysis_query}\"\n    )\n    memory_context = \"\\n\".join(\n        [\n            m.events[0].content.parts[0].text\n            for m in memory_response.memories\n            if m.events and m.events[0].content\n        ]\n    )  # Simplified extraction\n    print(f\"Tool: Found memory context: {memory_context[:100]}...\")\n\n    # 3. Perform analysis (placeholder)\n    analysis_result = f\"Analysis of '{document_name}' regarding '{analysis_query}' using memory context: [Placeholder Analysis Result]\"\n    print(\"Tool: Performed analysis.\")\n\n    # 4. Save the analysis result as a new artifact\n    analysis_part = types.Part.from_text(text=analysis_result)\n    new_artifact_name = f\"analysis_{document_name}\"\n    version = await tool_context.save_artifact(new_artifact_name, analysis_part)\n    print(f\"Tool: Saved analysis result as '{new_artifact_name}' version {version}.\")\n\n    return {\n        \"status\": \"success\",\n        \"analysis_artifact\": new_artifact_name,\n        \"version\": version,\n    }\n\n\ndoc_analysis_tool = FunctionTool(func=process_document)\n\n# In an Agent:\n# Assume artifact 'report.txt' was previously saved.\n# Assume memory service is configured and has relevant past data.\n# my_agent = Agent(..., tools=[doc_analysis_tool], artifact_service=..., memory_service=...)"}, {"language": "text", "code": "// Copyright 2025 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage main\n\nimport (\n    \"fmt\"\n\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/genai\"\n)\n\ntype processDocumentArgs struct {\n    DocumentName  string `json:\"document_name\" jsonschema:\"The name of the document to be processed.\"`\n    AnalysisQuery string `json:\"analysis_query\" jsonschema:\"The query for the analysis.\"`\n}\n\ntype processDocumentResult struct {\n    Status           string `json:\"status\"`\n    AnalysisArtifact string `json:\"analysis_artifact,omitempty\"`\n    Version          int64  `json:\"version,omitempty\"`\n    Message          string `json:\"message,omitempty\"`\n}\n\nfunc processDocument(ctx tool.Context, args processDocumentArgs) processDocumentResult {\n    fmt.Printf(\"Tool: Attempting to load artifact: %s\\n\", args.DocumentName)\n\n    // List all artifacts\n    listResponse, err := ctx.Artifacts().List(ctx)\n    if err != nil {\n        return processDocumentResult{Status: \"error\", Message: \"Failed to list artifacts.\"}\n    }\n\n    fmt.Println(\"Tool: Available artifacts:\")\n    for _, file := range listResponse.FileNames {\n        fmt.Printf(\" - %s\\n\", file)\n    }\n\n    documentPart, err := ctx.Artifacts().Load(ctx, args.DocumentName)\n    if err != nil {\n        return processDocumentResult{Status: \"error\", Message: fmt.Sprintf(\"Document '%s' not found.\", args.DocumentName)}\n    }\n\n    fmt.Printf(\"Tool: Loaded document '%s' of size %d bytes.\\n\", args.DocumentName, len(documentPart.Part.InlineData.Data))\n\n    // 3. Search memory for related context\n    fmt.Printf(\"Tool: Searching memory for context related to: '%s'\\n\", args.AnalysisQuery)\n    memoryResp, err := ctx.SearchMemory(ctx, args.AnalysisQuery)\n    if err != nil {\n        fmt.Printf(\"Tool: Error searching memory: %v\\n\", err)\n    }\n    memoryResultCount := 0\n    if memoryResp != nil {\n        memoryResultCount = len(memoryResp.Memories)\n    }\n    fmt.Printf(\"Tool: Found %d memory results.\\n\", memoryResultCount)\n\n    analysisResult := fmt.Sprintf(\"Analysis of '%s' regarding '%s' using memory context: [Placeholder Analysis Result]\", args.DocumentName, args.AnalysisQuery)\n    fmt.Println(\"Tool: Performed analysis.\")\n\n    analysisPart := genai.NewPartFromText(analysisResult)\n    newArtifactName := fmt.Sprintf(\"analysis_%s\", args.DocumentName)\n    version, err := ctx.Artifacts().Save(ctx, newArtifactName, analysisPart)\n    if err != nil {\n        return processDocumentResult{Status: \"error\", Message: \"Failed to save artifact.\"}\n    }\n    fmt.Printf(\"Tool: Saved analysis result as '%s' version %d.\\n\", newArtifactName, version.Version)\n\n    return processDocumentResult{\n        Status:           \"success\",\n        AnalysisArtifact: newArtifactName,\n        Version:          version.Version,\n    }\n}"}, {"language": "text", "code": "// Analyzes a document using context from memory.\n// You can also list, load and save artifacts using Callback Context or LoadArtifacts tool.\npublic static @NonNull Maybe<ImmutableMap<String, Object>> processDocument(\n    @Annotations.Schema(description = \"The name of the document to analyze.\") String documentName,\n    @Annotations.Schema(description = \"The query for the analysis.\") String analysisQuery,\n    ToolContext toolContext) {\n\n  // 1. List all available artifacts\n  System.out.printf(\n      \"Listing all available artifacts %s:\", toolContext.listArtifacts().blockingGet());\n\n  // 2. Load an artifact to memory\n  System.out.println(\"Tool: Attempting to load artifact: \" + documentName);\n  Part documentPart = toolContext.loadArtifact(documentName, Optional.empty()).blockingGet();\n  if (documentPart == null) {\n    System.out.println(\"Tool: Document '\" + documentName + \"' not found.\");\n    return Maybe.just(\n        ImmutableMap.<String, Object>of(\n            \"status\", \"error\", \"message\", \"Document '\" + documentName + \"' not found.\"));\n  }\n  String documentText = documentPart.text().orElse(\"\");\n  System.out.println(\n      \"Tool: Loaded document '\" + documentName + \"' (\" + documentText.length() + \" chars).\");\n\n  // 3. Perform analysis (placeholder)\n  String analysisResult =\n      \"Analysis of '\"\n          + documentName\n          + \"' regarding '\"\n          + analysisQuery\n          + \" [Placeholder Analysis Result]\";\n  System.out.println(\"Tool: Performed analysis.\");\n\n  // 4. Save the analysis result as a new artifact\n  Part analysisPart = Part.fromText(analysisResult);\n  String newArtifactName = \"analysis_\" + documentName;\n\n  toolContext.saveArtifact(newArtifactName, analysisPart);\n\n  return Maybe.just(\n      ImmutableMap.<String, Object>builder()\n          .put(\"status\", \"success\")\n          .put(\"analysis_artifact\", newArtifactName)\n          .build());\n}\n// FunctionTool processDocumentTool =\n//      FunctionTool.create(ToolContextArtifactExample.class, \"processDocument\");\n// In the Agent, include this function tool.\n// LlmAgent agent = LlmAgent().builder().tools(processDocumentTool).build();"}]}, {"heading_path": ["Defining Effective Tool Functions\u00b6"], "text": "Defining Effective Tool Functions \u00b6 When using a method or function as an ADK Tool, how you define it significantly impacts the agent's ability to use it correctly. The agent's Large Language Model (LLM) relies heavily on the function's name , parameters (arguments) , type hints , and docstring / source code comments to understand its purpose and generate the correct call. Here are key guidelines for defining effective tool functions: Function Name: Use descriptive, verb-noun based names that clearly indicate the action (e.g., get_weather , searchDocuments , schedule_meeting ). Avoid generic names like run , process , handle_data , or overly ambiguous names like doStuff . Even with a good description, a name like do_stuff might confuse the model about when to use the tool versus, for example, cancelFlight . The LLM uses the function name as a primary identifier during tool selection. Parameters (Arguments): Your function can have any number of parameters. Use clear and descriptive names (e.g., city instead of c , search_query instead of q ). Provide type hints in Python for all parameters (e.g., city: str , user_id: int , items: list[str] ). This is essential for ADK to generate the correct schema for the LLM. Ensure all parameter types are JSON serializable . All java primitives as well as standard Python types like str , int , float , bool , list , dict , and their combinations are generally safe. Avoid complex custom class instances as direct parameters unless they have a clear JSON representation. Do not set default values for parameters. E.g., def my_func(param1: str = \"default\") . Default values are not reliably supported or used by the underlying models during function call generation. All necessary information should be derived by the LLM from the context or explicitly requested if missing. self / cls Handled Automatically: Implicit parameters like self (for instance methods) or cls (for class methods) are automatically handled by ADK and excluded from the schema shown to the LLM. You only need to define type hints and descriptions for the logical parameters your tool requires the LLM to provide. Return Type: The function's return value must be a dictionary ( dict ) in Python or a Map in Java. If your function returns a non-dictionary type (e.g., a string, number, list), the ADK framework will automatically wrap it into a dictionary/Map like {'result': your_original_return_value} before passing the result back to the model. Design the dictionary/Map keys and values to be descriptive and easily understood by the LLM . Remember, the model reads this output to decide its next step. Include meaningful keys. For example, instead of returning just an error code like 500 , return {'status': 'error', 'error_message': 'Database connection failed'} . It's a highly recommended practice to include a status key (e.g., 'success' , 'error' , 'pending' , 'ambiguous' ) to clearly indicate the outcome of the tool execution for the model. Docstring / Source Code Comments: This is critical. The docstring is the primary source of descriptive information for the LLM. Clearly state what the tool does . Be specific about its purpose and limitations. Explain when the tool should be used. Provide context or example scenarios to guide the LLM's decision-making. Describe each parameter clearly. Explain what information the LLM needs to provide for that argument. Describe the structure and meaning of the expected dict return value , especially the different status values and associated data keys. Do not describe the injected ToolContext parameter . Avoid mentioning the optional tool_context: ToolContext parameter within the docstring description since it is not a parameter the LLM needs to know about. ToolContext is injected by ADK, after the LLM decides to call it. Example of a good definition: Python Go Java def lookup_order_status ( order_id : str ) -> dict : \"\"\"Fetches the current status of a customer's order using its ID. Use this tool ONLY when a user explicitly asks for the status of a specific order and provides the order ID. Do not use it for general inquiries. Args: order_id: The unique identifier of the order to look up. Returns: A dictionary indicating the outcome. On success, status is 'success' and includes an 'order' dictionary. On failure, status is 'error' and includes an 'error_message'. Example success: {'status': 'success', 'order': {'state': 'shipped', 'tracking_number': '1Z9...'}} Example error: {'status': 'error', 'error_message': 'Order ID not found.'} \"\"\" # ... function implementation to fetch status ... if status_details := fetch_status_from_backend ( order_id ): return { \"status\" : \"success\" , \"order\" : { \"state\" : status_details . state , \"tracking_number\" : status_details . tracking , }, } else : return { \"status\" : \"error\" , \"error_message\" : f \"Order ID { order_id } not found.\" } import ( \"fmt\" \"google.golang.org/adk/tool\" ) type lookupOrderStatusArgs struct { OrderID string `json:\"order_id\" jsonschema:\"The ID of the order to look up.\"` } type order struct { State string `json:\"state\"` TrackingNumber string `json:\"tracking_number\"` } type lookupOrderStatusResult struct { Status string `json:\"status\"` Order order `json:\"order,omitempty\"` ErrorMessage string `json:\"error_message,omitempty\"` } func lookupOrderStatus ( ctx tool . Context , args lookupOrderStatusArgs ) lookupOrderStatusResult { // ... function implementation to fetch status ... if statusDetails , ok := fetchStatusFromBackend ( args . OrderID ); ok { return lookupOrderStatusResult { Status : \"success\" , Order : order { State : statusDetails . State , TrackingNumber : statusDetails . Tracking , }, } } return lookupOrderStatusResult { Status : \"error\" , ErrorMessage : fmt . Sprintf ( \"Order ID %s not found.\" , args . OrderID )} } /** * Retrieves the current weather report for a specified city. * * @param city The city for which to retrieve the weather report. * @param toolContext The context for the tool. * @return A dictionary containing the weather information. */ public static Map < String , Object > getWeatherReport ( String city , ToolContext toolContext ) { Map < String , Object > response = new HashMap <> (); if ( city . toLowerCase ( Locale . ROOT ). equals ( \"london\" )) { response . put ( \"status\" , \"success\" ); response . put ( \"report\" , \"The current weather in London is cloudy with a temperature of 18 degrees Celsius and a\" + \" chance of rain.\" ); } else if ( city . toLowerCase ( Locale . ROOT ). equals ( \"paris\" )) { response . put ( \"status\" , \"success\" ); response . put ( \"report\" , \"The weather in Paris is sunny with a temperature of 25 degrees Celsius.\" ); } else { response . put ( \"status\" , \"error\" ); response . put ( \"error_message\" , String . format ( \"Weather information for '%s' is not available.\" , city )); } return response ; } Simplicity and Focus: Keep Tools Focused: Each tool should ideally perform one well-defined task. Fewer Parameters are Better: Models generally handle tools with fewer, clearly defined parameters more reliably than those with many optional or complex ones. Use Simple Data Types: Prefer basic types ( str , int , bool , float , List[str] , in Python , or int , byte , short , long , float , double , boolean and char in Java ) over complex custom classes or deeply nested structures as parameters when possible. Decompose Complex Tasks: Break down functions that perform multiple distinct logical steps into smaller, more focused tools. For instance, instead of a single update_user_profile(profile: ProfileObject) tool, consider separate tools like update_user_name(name: str) , update_user_address(address: str) , update_user_preferences(preferences: list[str]) , etc. This makes it easier for the LLM to select and use the correct capability. By adhering to these guidelines, you provide the LLM with the clarity and structure it needs to effectively utilize your custom function tools, leading to more capable and reliable agent behavior. ", "code_blocks": [{"language": "text", "code": "def lookup_order_status(order_id: str) -> dict:\n  \"\"\"Fetches the current status of a customer's order using its ID.\n\n  Use this tool ONLY when a user explicitly asks for the status of\n  a specific order and provides the order ID. Do not use it for\n  general inquiries.\n\n  Args:\n      order_id: The unique identifier of the order to look up.\n\n  Returns:\n      A dictionary indicating the outcome.\n      On success, status is 'success' and includes an 'order' dictionary.\n      On failure, status is 'error' and includes an 'error_message'.\n      Example success: {'status': 'success', 'order': {'state': 'shipped', 'tracking_number': '1Z9...'}}\n      Example error: {'status': 'error', 'error_message': 'Order ID not found.'}\n  \"\"\"\n  # ... function implementation to fetch status ...\n  if status_details := fetch_status_from_backend(order_id):\n    return {\n        \"status\": \"success\",\n        \"order\": {\n            \"state\": status_details.state,\n            \"tracking_number\": status_details.tracking,\n        },\n    }\n  else:\n    return {\"status\": \"error\", \"error_message\": f\"Order ID {order_id} not found.\"}"}, {"language": "text", "code": "import (\n    \"fmt\"\n\n    \"google.golang.org/adk/tool\"\n)\n\ntype lookupOrderStatusArgs struct {\n    OrderID string `json:\"order_id\" jsonschema:\"The ID of the order to look up.\"`\n}\n\ntype order struct {\n    State          string `json:\"state\"`\n    TrackingNumber string `json:\"tracking_number\"`\n}\n\ntype lookupOrderStatusResult struct {\n    Status       string `json:\"status\"`\n    Order        order  `json:\"order,omitempty\"`\n    ErrorMessage string `json:\"error_message,omitempty\"`\n}\n\nfunc lookupOrderStatus(ctx tool.Context, args lookupOrderStatusArgs) lookupOrderStatusResult {\n    // ... function implementation to fetch status ...\n    if statusDetails, ok := fetchStatusFromBackend(args.OrderID); ok {\n        return lookupOrderStatusResult{\n            Status: \"success\",\n            Order: order{\n                State:          statusDetails.State,\n                TrackingNumber: statusDetails.Tracking,\n            },\n        }\n    }\n    return lookupOrderStatusResult{Status: \"error\", ErrorMessage: fmt.Sprintf(\"Order ID %s not found.\", args.OrderID)}\n}"}, {"language": "text", "code": "/**\n * Retrieves the current weather report for a specified city.\n *\n * @param city The city for which to retrieve the weather report.\n * @param toolContext The context for the tool.\n * @return A dictionary containing the weather information.\n */\npublic static Map<String, Object> getWeatherReport(String city, ToolContext toolContext) {\n    Map<String, Object> response = new HashMap<>();\n    if (city.toLowerCase(Locale.ROOT).equals(\"london\")) {\n        response.put(\"status\", \"success\");\n        response.put(\n                \"report\",\n                \"The current weather in London is cloudy with a temperature of 18 degrees Celsius and a\"\n                        + \" chance of rain.\");\n    } else if (city.toLowerCase(Locale.ROOT).equals(\"paris\")) {\n        response.put(\"status\", \"success\");\n        response.put(\"report\", \"The weather in Paris is sunny with a temperature of 25 degrees Celsius.\");\n    } else {\n        response.put(\"status\", \"error\");\n        response.put(\"error_message\", String.format(\"Weather information for '%s' is not available.\", city));\n    }\n    return response;\n}"}]}, {"heading_path": ["Toolsets: Grouping and Dynamically Providing Tools\u00b6"], "text": "Toolsets: Grouping and Dynamically Providing Tools \u00b6 Supported in ADK Python v0.5.0 Beyond individual tools, ADK introduces the concept of a Toolset via the BaseToolset interface (defined in google.adk.tools.base_toolset ). A toolset allows you to manage and provide a collection of BaseTool instances, often dynamically, to an agent. This approach is beneficial for: Organizing Related Tools: Grouping tools that serve a common purpose (e.g., all tools for mathematical operations, or all tools interacting with a specific API). Dynamic Tool Availability: Enabling an agent to have different tools available based on the current context (e.g., user permissions, session state, or other runtime conditions). The get_tools method of a toolset can decide which tools to expose. Integrating External Tool Providers: Toolsets can act as adapters for tools coming from external systems, like an OpenAPI specification or an MCP server, converting them into ADK-compatible BaseTool objects. ", "code_blocks": []}, {"heading_path": ["The BaseToolset Interface\u00b6"], "text": "The BaseToolset Interface \u00b6 Any class acting as a toolset in ADK should implement the BaseToolset abstract base class. This interface primarily defines two methods: async def get_tools(...) -> list[BaseTool]: This is the core method of a toolset. When an ADK agent needs to know its available tools, it will call get_tools() on each BaseToolset instance provided in its tools list. It receives an optional readonly_context (an instance of ReadonlyContext ). This context provides read-only access to information like the current session state ( readonly_context.state ), agent name, and invocation ID. The toolset can use this context to dynamically decide which tools to return. It must return a list of BaseTool instances (e.g., FunctionTool , RestApiTool ). async def close(self) -> None: This asynchronous method is called by the ADK framework when the toolset is no longer needed, for example, when an agent server is shutting down or the Runner is being closed. Implement this method to perform any necessary cleanup, such as closing network connections, releasing file handles, or cleaning up other resources managed by the toolset. ", "code_blocks": []}, {"heading_path": ["Using Toolsets with Agents\u00b6"], "text": "Using Toolsets with Agents \u00b6 You can include instances of your BaseToolset implementations directly in an LlmAgent 's tools list, alongside individual BaseTool instances. When the agent initializes or needs to determine its available capabilities, the ADK framework will iterate through the tools list: If an item is a BaseTool instance, it's used directly. If an item is a BaseToolset instance, its get_tools() method is called (with the current ReadonlyContext ), and the returned list of BaseTool s is added to the agent's available tools. ", "code_blocks": []}, {"heading_path": ["Example: A Simple Math Toolset\u00b6"], "text": "Example: A Simple Math Toolset \u00b6 Let's create a basic example of a toolset that provides simple arithmetic operations. # 1. Define the individual tool functions def add_numbers ( a : int , b : int , tool_context : ToolContext ) -> Dict [ str , Any ]: \"\"\"Adds two integer numbers. Args: a: The first number. b: The second number. Returns: A dictionary with the sum, e.g., {'status': 'success', 'result': 5} \"\"\" print ( f \"Tool: add_numbers called with a= { a } , b= { b } \" ) result = a + b # Example: Storing something in tool_context state tool_context . state [ \"last_math_operation\" ] = \"addition\" return { \"status\" : \"success\" , \"result\" : result } def subtract_numbers ( a : int , b : int ) -> Dict [ str , Any ]: \"\"\"Subtracts the second number from the first. Args: a: The first number. b: The second number. Returns: A dictionary with the difference, e.g., {'status': 'success', 'result': 1} \"\"\" print ( f \"Tool: subtract_numbers called with a= { a } , b= { b } \" ) return { \"status\" : \"success\" , \"result\" : a - b } # 2. Create the Toolset by implementing BaseToolset class SimpleMathToolset ( BaseToolset ): def __init__ ( self , prefix : str = \"math_\" ): self . prefix = prefix # Create FunctionTool instances once self . _add_tool = FunctionTool ( func = add_numbers , name = f \" { self . prefix } add_numbers\" , # Toolset can customize names ) self . _subtract_tool = FunctionTool ( func = subtract_numbers , name = f \" { self . prefix } subtract_numbers\" ) print ( f \"SimpleMathToolset initialized with prefix ' { self . prefix } '\" ) async def get_tools ( self , readonly_context : Optional [ ReadonlyContext ] = None ) -> List [ BaseTool ]: print ( f \"SimpleMathToolset.get_tools() called.\" ) # Example of dynamic behavior: # Could use readonly_context.state to decide which tools to return # For instance, if readonly_context.state.get(\"enable_advanced_math\"): #    return [self._add_tool, self._subtract_tool, self._multiply_tool] # For this simple example, always return both tools tools_to_return = [ self . _add_tool , self . _subtract_tool ] print ( f \"SimpleMathToolset providing tools: { [ t . name for t in tools_to_return ] } \" ) return tools_to_return async def close ( self ) -> None : # No resources to clean up in this simple example print ( f \"SimpleMathToolset.close() called for prefix ' { self . prefix } '.\" ) await asyncio . sleep ( 0 ) # Placeholder for async cleanup if needed # 3. Define an individual tool (not part of the toolset) def greet_user ( name : str = \"User\" ) -> Dict [ str , str ]: \"\"\"Greets the user.\"\"\" print ( f \"Tool: greet_user called with name= { name } \" ) return { \"greeting\" : f \"Hello, { name } !\" } greet_tool = FunctionTool ( func = greet_user ) # 4. Instantiate the toolset math_toolset_instance = SimpleMathToolset ( prefix = \"calculator_\" ) # 5. Define an agent that uses both the individual tool and the toolset calculator_agent = LlmAgent ( name = \"CalculatorAgent\" , model = \"gemini-2.0-flash\" , # Replace with your desired model instruction = \"You are a helpful calculator and greeter. \" \"Use 'greet_user' for greetings. \" \"Use 'calculator_add_numbers' to add and 'calculator_subtract_numbers' to subtract. \" \"Announce the state of 'last_math_operation' if it's set.\" , tools = [ greet_tool , math_toolset_instance ], # Individual tool  # Toolset instance ) In this example: SimpleMathToolset implements BaseToolset and its get_tools() method returns FunctionTool instances for add_numbers and subtract_numbers . It also customizes their names using a prefix. The calculator_agent is configured with both an individual greet_tool and an instance of SimpleMathToolset . When calculator_agent is run, ADK will call math_toolset_instance.get_tools() . The agent's LLM will then have access to greet_user , calculator_add_numbers , and calculator_subtract_numbers to handle user requests. The add_numbers tool demonstrates writing to tool_context.state , and the agent's instruction mentions reading this state. The close() method is called to ensure any resources held by the toolset are released. Toolsets offer a powerful way to organize, manage, and dynamically provide collections of tools to your ADK agents, leading to more modular, maintainable, and adaptable agentic applications. Back to top ", "code_blocks": [{"language": "text", "code": "# 1. Define the individual tool functions\ndef add_numbers(a: int, b: int, tool_context: ToolContext) -> Dict[str, Any]:\n    \"\"\"Adds two integer numbers.\n    Args:\n        a: The first number.\n        b: The second number.\n    Returns:\n        A dictionary with the sum, e.g., {'status': 'success', 'result': 5}\n    \"\"\"\n    print(f\"Tool: add_numbers called with a={a}, b={b}\")\n    result = a + b\n    # Example: Storing something in tool_context state\n    tool_context.state[\"last_math_operation\"] = \"addition\"\n    return {\"status\": \"success\", \"result\": result}\n\n\ndef subtract_numbers(a: int, b: int) -> Dict[str, Any]:\n    \"\"\"Subtracts the second number from the first.\n    Args:\n        a: The first number.\n        b: The second number.\n    Returns:\n        A dictionary with the difference, e.g., {'status': 'success', 'result': 1}\n    \"\"\"\n    print(f\"Tool: subtract_numbers called with a={a}, b={b}\")\n    return {\"status\": \"success\", \"result\": a - b}\n\n\n# 2. Create the Toolset by implementing BaseToolset\nclass SimpleMathToolset(BaseToolset):\n    def __init__(self, prefix: str = \"math_\"):\n        self.prefix = prefix\n        # Create FunctionTool instances once\n        self._add_tool = FunctionTool(\n            func=add_numbers,\n            name=f\"{self.prefix}add_numbers\",  # Toolset can customize names\n        )\n        self._subtract_tool = FunctionTool(\n            func=subtract_numbers, name=f\"{self.prefix}subtract_numbers\"\n        )\n        print(f\"SimpleMathToolset initialized with prefix '{self.prefix}'\")\n\n    async def get_tools(\n        self, readonly_context: Optional[ReadonlyContext] = None\n    ) -> List[BaseTool]:\n        print(f\"SimpleMathToolset.get_tools() called.\")\n        # Example of dynamic behavior:\n        # Could use readonly_context.state to decide which tools to return\n        # For instance, if readonly_context.state.get(\"enable_advanced_math\"):\n        #    return [self._add_tool, self._subtract_tool, self._multiply_tool]\n\n        # For this simple example, always return both tools\n        tools_to_return = [self._add_tool, self._subtract_tool]\n        print(f\"SimpleMathToolset providing tools: {[t.name for t in tools_to_return]}\")\n        return tools_to_return\n\n    async def close(self) -> None:\n        # No resources to clean up in this simple example\n        print(f\"SimpleMathToolset.close() called for prefix '{self.prefix}'.\")\n        await asyncio.sleep(0)  # Placeholder for async cleanup if needed\n\n\n# 3. Define an individual tool (not part of the toolset)\ndef greet_user(name: str = \"User\") -> Dict[str, str]:\n    \"\"\"Greets the user.\"\"\"\n    print(f\"Tool: greet_user called with name={name}\")\n    return {\"greeting\": f\"Hello, {name}!\"}\n\n\ngreet_tool = FunctionTool(func=greet_user)\n\n# 4. Instantiate the toolset\nmath_toolset_instance = SimpleMathToolset(prefix=\"calculator_\")\n\n# 5. Define an agent that uses both the individual tool and the toolset\ncalculator_agent = LlmAgent(\n    name=\"CalculatorAgent\",\n    model=\"gemini-2.0-flash\",  # Replace with your desired model\n    instruction=\"You are a helpful calculator and greeter. \"\n    \"Use 'greet_user' for greetings. \"\n    \"Use 'calculator_add_numbers' to add and 'calculator_subtract_numbers' to subtract. \"\n    \"Announce the state of 'last_math_operation' if it's set.\",\n    tools=[greet_tool, math_toolset_instance],  # Individual tool  # Toolset instance\n)"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:19.116493", "source_type": "adk-docs"}
{"doc_id": "b08dc9357fe4d7440385f59891a6a1ec4adb30eabe5bcb119d3ab40236c668fe", "url": "https://google.github.io/adk-docs/tools-custom/function-tools", "title": "Overview - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Function tools\u00b6"], "text": "Function tools \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 When pre-built ADK tools don't meet your requirements, you can create custom function tools . Building function tools allows you to create tailored functionality, such as connecting to proprietary databases or implementing unique algorithms.\nFor example, a function tool, myfinancetool , might be a function that calculates a specific financial metric. ADK also supports long running functions, so if that calculation takes a while, the agent can continue working on other tasks. ADK offers several ways to create functions tools, each suited to different levels of complexity and control: Function Tools Long Running Function Tools Agents-as-a-Tool ", "code_blocks": []}, {"heading_path": ["Function Tools\u00b6"], "text": "Function Tools \u00b6 Transforming a Python function into a tool is a straightforward way to integrate custom logic into your agents. When you assign a function to an agent\u2019s tools list, the framework automatically wraps it as a FunctionTool . ", "code_blocks": []}, {"heading_path": ["How it Works\u00b6"], "text": "How it Works \u00b6 The ADK framework automatically inspects your Python function's signature\u2014including its name, docstring, parameters, type hints, and default values\u2014to generate a schema. This schema is what the LLM uses to understand the tool's purpose, when to use it, and what arguments it requires. ", "code_blocks": []}, {"heading_path": ["Defining Function Signatures\u00b6"], "text": "Defining Function Signatures \u00b6 A well-defined function signature is crucial for the LLM to use your tool correctly. ", "code_blocks": []}, {"heading_path": ["Parameters\u00b6"], "text": "Parameters \u00b6 ", "code_blocks": []}, {"heading_path": ["Required Parameters\u00b6"], "text": "Required Parameters \u00b6 Python Go A parameter is considered required if it has a type hint but no default value . The LLM must provide a value for this argument when it calls the tool. The parameter's description is taken from the function's docstring. Example: Required Parameters def get_weather ( city : str , unit : str ): \"\"\" Retrieves the weather for a city in the specified unit. Args: city (str): The city name. unit (str): The temperature unit, either 'Celsius' or 'Fahrenheit'. \"\"\" # ... function logic ... return { \"status\" : \"success\" , \"report\" : f \"Weather for { city } is sunny.\" } In this example, both city and unit are mandatory. If the LLM tries to call get_weather without one of them, the ADK will return an error to the LLM, prompting it to correct the call. In Go, you use struct tags to control the JSON schema. The two primary tags are json and jsonschema . A parameter is considered required if its struct field does not have the omitempty or omitzero option in its json tag. The jsonschema tag is used to provide the argument's description. This is crucial for the LLM to understand what the argument is for. Example: Required Parameters // GetWeatherParams defines the arguments for the getWeather tool. type GetWeatherParams struct { // This field is REQUIRED (no \"omitempty\"). // The jsonschema tag provides the description. Location string `json:\"location\" jsonschema:\"The city and state, e.g., San Francisco, CA\"` // This field is also REQUIRED. Unit string `json:\"unit\" jsonschema:\"The temperature unit, either 'celsius' or 'fahrenheit'\"` } In this example, both location and unit are mandatory. ", "code_blocks": [{"language": "text", "code": "def get_weather(city: str, unit: str):\n    \"\"\"\n    Retrieves the weather for a city in the specified unit.\n\n    Args:\n        city (str): The city name.\n        unit (str): The temperature unit, either 'Celsius' or 'Fahrenheit'.\n    \"\"\"\n    # ... function logic ...\n    return {\"status\": \"success\", \"report\": f\"Weather for {city} is sunny.\"}"}, {"language": "text", "code": "// GetWeatherParams defines the arguments for the getWeather tool.\ntype GetWeatherParams struct {\n    // This field is REQUIRED (no \"omitempty\").\n    // The jsonschema tag provides the description.\n    Location string `json:\"location\" jsonschema:\"The city and state, e.g., San Francisco, CA\"`\n\n    // This field is also REQUIRED.\n    Unit     string `json:\"unit\" jsonschema:\"The temperature unit, either 'celsius' or 'fahrenheit'\"`\n}"}]}, {"heading_path": ["Optional Parameters\u00b6"], "text": "Optional Parameters \u00b6 Python Go A parameter is considered optional if you provide a default value . This is the standard Python way to define optional arguments. You can also mark a parameter as optional using typing.Optional[SomeType] or the | None syntax (Python 3.10+). Example: Optional Parameters def search_flights ( destination : str , departure_date : str , flexible_days : int = 0 ): \"\"\" Searches for flights. Args: destination (str): The destination city. departure_date (str): The desired departure date. flexible_days (int, optional): Number of flexible days for the search. Defaults to 0. \"\"\" # ... function logic ... if flexible_days > 0 : return { \"status\" : \"success\" , \"report\" : f \"Found flexible flights to { destination } .\" } return { \"status\" : \"success\" , \"report\" : f \"Found flights to { destination } on { departure_date } .\" } Here, flexible_days is optional. The LLM can choose to provide it, but it's not required. A parameter is considered optional if its struct field has the omitempty or omitzero option in its json tag. Example: Optional Parameters // GetWeatherParams defines the arguments for the getWeather tool. type GetWeatherParams struct { // Location is required. Location string `json:\"location\" jsonschema:\"The city and state, e.g., San Francisco, CA\"` // Unit is optional. Unit string `json:\"unit,omitempty\" jsonschema:\"The temperature unit, either 'celsius' or 'fahrenheit'\"` // Days is optional. Days int `json:\"days,omitzero\" jsonschema:\"The number of forecast days to return (defaults to 1)\"` } Here, unit and days are optional. The LLM can choose to provide them, but they are not required. ", "code_blocks": [{"language": "text", "code": "def search_flights(destination: str, departure_date: str, flexible_days: int = 0):\n    \"\"\"\n    Searches for flights.\n\n    Args:\n        destination (str): The destination city.\n        departure_date (str): The desired departure date.\n        flexible_days (int, optional): Number of flexible days for the search. Defaults to 0.\n    \"\"\"\n    # ... function logic ...\n    if flexible_days > 0:\n        return {\"status\": \"success\", \"report\": f\"Found flexible flights to {destination}.\"}\n    return {\"status\": \"success\", \"report\": f\"Found flights to {destination} on {departure_date}.\"}"}, {"language": "text", "code": "// GetWeatherParams defines the arguments for the getWeather tool.\ntype GetWeatherParams struct {\n    // Location is required.\n    Location string `json:\"location\" jsonschema:\"The city and state, e.g., San Francisco, CA\"`\n\n    // Unit is optional.\n    Unit string `json:\"unit,omitempty\" jsonschema:\"The temperature unit, either 'celsius' or 'fahrenheit'\"`\n\n    // Days is optional.\n    Days int `json:\"days,omitzero\" jsonschema:\"The number of forecast days to return (defaults to 1)\"`\n}"}]}, {"heading_path": ["Optional Parameters with typing.Optional\u00b6"], "text": "Optional Parameters with typing.Optional \u00b6 You can also mark a parameter as optional using typing.Optional[SomeType] or the | None syntax (Python 3.10+). This signals that the parameter can be None . When combined with a default value of None , it behaves as a standard optional parameter. Example: typing.Optional Python from typing import Optional def create_user_profile ( username : str , bio : Optional [ str ] = None ): \"\"\" Creates a new user profile. Args: username (str): The user's unique username. bio (str, optional): A short biography for the user. Defaults to None. \"\"\" # ... function logic ... if bio : return { \"status\" : \"success\" , \"message\" : f \"Profile for { username } created with a bio.\" } return { \"status\" : \"success\" , \"message\" : f \"Profile for { username } created.\" } ", "code_blocks": [{"language": "text", "code": "from typing import Optional\n\ndef create_user_profile(username: str, bio: Optional[str] = None):\n    \"\"\"\n    Creates a new user profile.\n\n    Args:\n        username (str): The user's unique username.\n        bio (str, optional): A short biography for the user. Defaults to None.\n    \"\"\"\n    # ... function logic ...\n    if bio:\n        return {\"status\": \"success\", \"message\": f\"Profile for {username} created with a bio.\"}\n    return {\"status\": \"success\", \"message\": f\"Profile for {username} created.\"}"}]}, {"heading_path": ["Variadic Parameters (*args and **kwargs)\u00b6"], "text": "Variadic Parameters ( *args and **kwargs ) \u00b6 While you can include *args (variable positional arguments) and **kwargs (variable keyword arguments) in your function signature for other purposes, they are ignored by the ADK framework when generating the tool schema for the LLM. The LLM will not be aware of them and cannot pass arguments to them. It's best to rely on explicitly defined parameters for all data you expect from the LLM. ", "code_blocks": []}, {"heading_path": ["Return Type\u00b6"], "text": "Return Type \u00b6 The preferred return type for a Function Tool is a dictionary in Python or Map in Java. This allows you to structure the response with key-value pairs, providing context and clarity to the LLM. If your function returns a type other than a dictionary, the framework automatically wraps it into a dictionary with a single key named \"result\" . Strive to make your return values as descriptive as possible. For example, instead of returning a numeric error code, return a dictionary with an \"error_message\" key containing a human-readable explanation. Remember that the LLM , not a piece of code, needs to understand the result. As a best practice, include a \"status\" key in your return dictionary to indicate the overall outcome (e.g., \"success\", \"error\", \"pending\"), providing the LLM with a clear signal about the operation's state. ", "code_blocks": []}, {"heading_path": ["Docstrings\u00b6"], "text": "Docstrings \u00b6 The docstring of your function serves as the tool's description and is sent to the LLM. Therefore, a well-written and comprehensive docstring is crucial for the LLM to understand how to use the tool effectively. Clearly explain the purpose of the function, the meaning of its parameters, and the expected return values. ", "code_blocks": []}, {"heading_path": ["Passing Data Between Tools\u00b6"], "text": "Passing Data Between Tools \u00b6 When an agent calls multiple tools in a sequence, you might need to pass data from one tool to another. The recommended way to do this is by using the temp: prefix in the session state. A tool can write data to a temp: variable, and a subsequent tool can read it. This data is only available for the current invocation and is discarded afterwards. Shared Invocation Context All tool calls within a single agent turn share the same InvocationContext . This means they also share the same temporary ( temp: ) state, which is how data can be passed between them. ", "code_blocks": []}, {"heading_path": ["Example\u00b6"], "text": "Example \u00b6 Example Python Go Java This tool is a python function which obtains the Stock price of a given Stock ticker/ symbol. Note : You need to pip install yfinance library before using this tool. # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.agents import Agent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.genai import types import yfinance as yf APP_NAME = \"stock_app\" USER_ID = \"1234\" SESSION_ID = \"session1234\" def get_stock_price ( symbol : str ): \"\"\" Retrieves the current stock price for a given symbol. Args: symbol (str): The stock symbol (e.g., \"AAPL\", \"GOOG\"). Returns: float: The current stock price, or None if an error occurs. \"\"\" try : stock = yf . Ticker ( symbol ) historical_data = stock . history ( period = \"1d\" ) if not historical_data . empty : current_price = historical_data [ 'Close' ] . iloc [ - 1 ] return current_price else : return None except Exception as e : print ( f \"Error retrieving stock price for { symbol } : { e } \" ) return None stock_price_agent = Agent ( model = 'gemini-2.0-flash' , name = 'stock_agent' , instruction = 'You are an agent who retrieves stock prices. If a ticker symbol is provided, fetch the current price. If only a company name is given, first perform a Google search to find the correct ticker symbol before retrieving the stock price. If the provided ticker symbol is invalid or data cannot be retrieved, inform the user that the stock price could not be found.' , description = 'This agent specializes in retrieving real-time stock prices. Given a stock ticker symbol (e.g., AAPL, GOOG, MSFT) or the stock name, use the tools and reliable data sources to provide the most up-to-date price.' , tools = [ get_stock_price ], # You can add Python functions directly to the tools list; they will be automatically wrapped as FunctionTools. ) # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = stock_price_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) async for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response: \" , final_response ) # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"stock price of GOOG\" ) The return value from this tool will be wrapped into a dictionary. { \"result\" : \"$123\" } This tool retrieves the mocked value of a stock price. import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) // Copyright 2025 Google LLC // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // //     http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package main import ( \"context\" \"fmt\" \"log\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/agenttool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) // mockStockPrices provides a simple in-memory database of stock prices // to simulate a real-world stock data API. This allows the example to // demonstrate tool functionality without making external network calls. var mockStockPrices = map [ string ] float64 { \"GOOG\" : 300.6 , \"AAPL\" : 123.4 , \"MSFT\" : 234.5 , } // getStockPriceArgs defines the schema for the arguments passed to the getStockPrice tool. // Using a struct is the recommended approach in the Go ADK as it provides strong // typing and clear validation for the expected inputs. type getStockPriceArgs struct { Symbol string `json:\"symbol\" jsonschema:\"The stock ticker symbol, e.g., GOOG\"` } // getStockPriceResults defines the output schema for the getStockPrice tool. type getStockPriceResults struct { Symbol string `json:\"symbol\"` Price float64 `json:\"price,omitempty\"` Error string `json:\"error,omitempty\"` } // getStockPrice is a tool that retrieves the stock price for a given ticker symbol // from the mockStockPrices map. It demonstrates how a function can be used as a // tool by an agent. If the symbol is found, it returns a struct containing the // symbol and its price. Otherwise, it returns a struct with an error message. func getStockPrice ( ctx tool . Context , input getStockPriceArgs ) getStockPriceResults { symbolUpper := strings . ToUpper ( input . Symbol ) if price , ok := mockStockPrices [ symbolUpper ]; ok { fmt . Printf ( \"Tool: Found price for %s: %f\\n\" , input . Symbol , price ) return getStockPriceResults { Symbol : input . Symbol , Price : price } } return getStockPriceResults { Symbol : input . Symbol , Error : \"No data found for symbol\" } } // createStockAgent initializes and configures an LlmAgent. // This agent is equipped with the getStockPrice tool and is instructed // on how to respond to user queries about stock prices. It uses the // Gemini model to understand user intent and decide when to use its tools. func createStockAgent ( ctx context . Context ) ( agent . Agent , error ) { stockPriceTool , err := functiontool . New ( functiontool . Config { Name : \"get_stock_price\" , Description : \"Retrieves the current stock price for a given symbol.\" , }, getStockPrice ) if err != nil { return nil , err } model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } return llmagent . New ( llmagent . Config { Name : \"stock_agent\" , Model : model , Instruction : \"You are an agent who retrieves stock prices. If a ticker symbol is provided, fetch the current price. If only a company name is given, first perform a Google search to find the correct ticker symbol before retrieving the stock price. If the provided ticker symbol is invalid or data cannot be retrieved, inform the user that the stock price could not be found.\" , Description : \"This agent specializes in retrieving real-time stock prices. Given a stock ticker symbol (e.g., AAPL, GOOG, MSFT) or the stock name, use the tools and reliable data sources to provide the most up-to-date price.\" , Tools : [] tool . Tool { stockPriceTool , }, }) } // userID and appName are constants used to identify the user and application // throughout the session. These values are important for logging, tracking, // and managing state across different agent interactions. const ( userID = \"example_user_id\" appName = \"example_app\" ) // callAgent orchestrates the execution of the agent for a given prompt. // It sets up the necessary services, creates a session, and uses a runner // to manage the agent's lifecycle. It streams the agent's responses and // prints them to the console, handling any potential errors during the run. func callAgent ( ctx context . Context , a agent . Agent , prompt string ) { sessionService := session . InMemoryService () // Create a new session for the agent interactions. session , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , }) if err != nil { log . Fatalf ( \"Failed to create the session service: %v\" , err ) } config := runner . Config { AppName : appName , Agent : a , SessionService : sessionService , } // Create the runner to manage the agent execution. r , err := runner . New ( config ) if err != nil { log . Fatalf ( \"Failed to create the runner: %v\" , err ) } sessionID := session . Session . ID () userMsg := & genai . Content { Parts : [] * genai . Part { genai . NewPartFromText ( prompt ), }, Role : string ( genai . RoleUser ), } for event , err := range r . Run ( ctx , userID , sessionID , userMsg , agent . RunConfig { StreamingMode : agent . StreamingModeNone , }) { if err != nil { fmt . Printf ( \"\\nAGENT_ERROR: %v\\n\" , err ) } else { for _ , p := range event . Content . Parts { fmt . Print ( p . Text ) } } } } // RunAgentSimulation serves as the entry point for this example. // It creates the stock agent and then simulates a series of user interactions // by sending different prompts to the agent. This function showcases how the // agent responds to various queries, including both successful and unsuccessful // attempts to retrieve stock prices. func RunAgentSimulation () { // Create the stock agent agent , err := createStockAgent ( context . Background ()) if err != nil { panic ( err ) } fmt . Println ( \"Agent created:\" , agent . Name ()) prompts := [] string { \"stock price of GOOG\" , \"What's the price of MSFT?\" , \"Can you find the stock price for an unknown company XYZ?\" , } // Simulate running the agent with different prompts for _ , prompt := range prompts { fmt . Printf ( \"\\nPrompt: %s\\nResponse: \" , prompt ) callAgent ( context . Background (), agent , prompt ) fmt . Println ( \"\\n---\" ) } } // createSummarizerAgent creates an agent whose sole purpose is to summarize text. func createSummarizerAgent ( ctx context . Context ) ( agent . Agent , error ) { model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig {}) if err != nil { return nil , err } return llmagent . New ( llmagent . Config { Name : \"SummarizerAgent\" , Model : model , Instruction : \"You are an expert at summarizing text. Take the user's input and provide a concise summary.\" , Description : \"An agent that summarizes text.\" , }) } // createMainAgent creates the primary agent that will use the summarizer agent as a tool. func createMainAgent ( ctx context . Context , tools ... tool . Tool ) ( agent . Agent , error ) { model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig {}) if err != nil { return nil , err } return llmagent . New ( llmagent . Config { Name : \"MainAgent\" , Model : model , Instruction : \"You are a helpful assistant. If you are asked to summarize a long text, use the 'summarize' tool. \" + \"After getting the summary, present it to the user by saying 'Here is a summary of the text:'.\" , Description : \"The main agent that can delegate tasks.\" , Tools : tools , }) } func RunAgentAsToolSimulation () { ctx := context . Background () // 1. Create the Tool Agent (Summarizer) summarizerAgent , err := createSummarizerAgent ( ctx ) if err != nil { log . Fatalf ( \"Failed to create summarizer agent: %v\" , err ) } // 2. Wrap the Tool Agent in an AgentTool summarizeTool := agenttool . New ( summarizerAgent , & agenttool . Config { SkipSummarization : true , }) // 3. Create the Main Agent and provide it with the AgentTool mainAgent , err := createMainAgent ( ctx , summarizeTool ) if err != nil { log . Fatalf ( \"Failed to create main agent: %v\" , err ) } // 4. Run the main agent prompt := ` Please summarize this text for me: Quantum computing represents a fundamentally different approach to computation, leveraging the bizarre principles of quantum mechanics to process information. Unlike classical computers that rely on bits representing either 0 or 1, quantum computers use qubits which can exist in a state of superposition - effectively being 0, 1, or a combination of both simultaneously. Furthermore, qubits can become entangled, meaning their fates are intertwined regardless of distance, allowing for complex correlations. This parallelism and interconnectedness grant quantum computers the potential to solve specific types of incredibly complex problems - such as drug discovery, materials science, complex system optimization, and breaking certain types of cryptography - far faster than even the most powerful classical supercomputers could ever achieve, although the technology is still largely in its developmental stages. ` fmt . Printf ( \"\\nPrompt: %s\\nResponse: \" , prompt ) callAgent ( context . Background (), mainAgent , prompt ) fmt . Println ( \"\\n---\" ) } func main () { fmt . Println ( \"Attempting to run the agent simulation...\" ) RunAgentSimulation () fmt . Println ( \"\\nAttempting to run the agent-as-a-tool simulation...\" ) RunAgentAsToolSimulation () } The return value from this tool will be a getStockPriceResults instance. For i n pu t ` { \"symbol\" : \"GOOG\" } ` : { \"price\" : 300.6 , \"symbol\" : \"GOOG\" } This tool retrieves the mocked value of a stock price. import com.google.adk.agents.LlmAgent ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.adk.tools.Annotations.Schema ; import com.google.adk.tools.FunctionTool ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import java.util.HashMap ; import java.util.Map ; public class StockPriceAgent { private static final String APP_NAME = \"stock_agent\" ; private static final String USER_ID = \"user1234\" ; // Mock data for various stocks functionality // NOTE: This is a MOCK implementation. In a real Java application, // you would use a financial data API or library. private static final Map < String , Double > mockStockPrices = new HashMap <> (); static { mockStockPrices . put ( \"GOOG\" , 1.0 ); mockStockPrices . put ( \"AAPL\" , 1.0 ); mockStockPrices . put ( \"MSFT\" , 1.0 ); } @Schema ( description = \"Retrieves the current stock price for a given symbol.\" ) public static Map < String , Object > getStockPrice ( @Schema ( description = \"The stock symbol (e.g., \\\"AAPL\\\", \\\"GOOG\\\")\" , name = \"symbol\" ) String symbol ) { try { if ( mockStockPrices . containsKey ( symbol . toUpperCase ())) { double currentPrice = mockStockPrices . get ( symbol . toUpperCase ()); System . out . println ( \"Tool: Found price for \" + symbol + \": \" + currentPrice ); return Map . of ( \"symbol\" , symbol , \"price\" , currentPrice ); } else { return Map . of ( \"symbol\" , symbol , \"error\" , \"No data found for symbol\" ); } } catch ( Exception e ) { return Map . of ( \"symbol\" , symbol , \"error\" , e . getMessage ()); } } public static void callAgent ( String prompt ) { // Create the FunctionTool from the Java method FunctionTool getStockPriceTool = FunctionTool . create ( StockPriceAgent . class , \"getStockPrice\" ); LlmAgent stockPriceAgent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"stock_agent\" ) . instruction ( \"You are an agent who retrieves stock prices. If a ticker symbol is provided, fetch the current price. If only a company name is given, first perform a Google search to find the correct ticker symbol before retrieving the stock price. If the provided ticker symbol is invalid or data cannot be retrieved, inform the user that the stock price could not be found.\" ) . description ( \"This agent specializes in retrieving real-time stock prices. Given a stock ticker symbol (e.g., AAPL, GOOG, MSFT) or the stock name, use the tools and reliable data sources to provide the most up-to-date price.\" ) . tools ( getStockPriceTool ) // Add the Java FunctionTool . build (); // Create an InMemoryRunner InMemoryRunner runner = new InMemoryRunner ( stockPriceAgent , APP_NAME ); // InMemoryRunner automatically creates a session service. Create a session using the service Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( prompt )); // Run the agent Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } public static void main ( String [] args ) { callAgent ( \"stock price of GOOG\" ); callAgent ( \"What's the price of MSFT?\" ); callAgent ( \"Can you find the stock price for an unknown company XYZ?\" ); } } The return value from this tool will be wrapped into a Map . For i n pu t `GOOG` : { \"symbol\" : \"GOOG\" , \"price\" : \"1.0\" } ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.agents import Agent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\nimport yfinance as yf\n\n\nAPP_NAME = \"stock_app\"\nUSER_ID = \"1234\"\nSESSION_ID = \"session1234\"\n\ndef get_stock_price(symbol: str):\n    \"\"\"\n    Retrieves the current stock price for a given symbol.\n\n    Args:\n        symbol (str): The stock symbol (e.g., \"AAPL\", \"GOOG\").\n\n    Returns:\n        float: The current stock price, or None if an error occurs.\n    \"\"\"\n    try:\n        stock = yf.Ticker(symbol)\n        historical_data = stock.history(period=\"1d\")\n        if not historical_data.empty:\n            current_price = historical_data['Close'].iloc[-1]\n            return current_price\n        else:\n            return None\n    except Exception as e:\n        print(f\"Error retrieving stock price for {symbol}: {e}\")\n        return None\n\n\nstock_price_agent = Agent(\n    model='gemini-2.0-flash',\n    name='stock_agent',\n    instruction= 'You are an agent who retrieves stock prices. If a ticker symbol is provided, fetch the current price. If only a company name is given, first perform a Google search to find the correct ticker symbol before retrieving the stock price. If the provided ticker symbol is invalid or data cannot be retrieved, inform the user that the stock price could not be found.',\n    description='This agent specializes in retrieving real-time stock prices. Given a stock ticker symbol (e.g., AAPL, GOOG, MSFT) or the stock name, use the tools and reliable data sources to provide the most up-to-date price.',\n    tools=[get_stock_price], # You can add Python functions directly to the tools list; they will be automatically wrapped as FunctionTools.\n)\n\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=stock_price_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n# Agent Interaction\nasync def call_agent_async(query):\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    async for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"Agent Response: \", final_response)\n\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"stock price of GOOG\")"}, {"language": "text", "code": "{\"result\": \"$123\"}"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\n// Copyright 2025 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/agenttool\"\n    \"google.golang.org/adk/tool/functiontool\"\n\n    \"google.golang.org/genai\"\n)\n\n// mockStockPrices provides a simple in-memory database of stock prices\n// to simulate a real-world stock data API. This allows the example to\n// demonstrate tool functionality without making external network calls.\nvar mockStockPrices = map[string]float64{\n    \"GOOG\": 300.6,\n    \"AAPL\": 123.4,\n    \"MSFT\": 234.5,\n}\n\n// getStockPriceArgs defines the schema for the arguments passed to the getStockPrice tool.\n// Using a struct is the recommended approach in the Go ADK as it provides strong\n// typing and clear validation for the expected inputs.\ntype getStockPriceArgs struct {\n    Symbol string `json:\"symbol\" jsonschema:\"The stock ticker symbol, e.g., GOOG\"`\n}\n\n// getStockPriceResults defines the output schema for the getStockPrice tool.\ntype getStockPriceResults struct {\n    Symbol string  `json:\"symbol\"`\n    Price  float64 `json:\"price,omitempty\"`\n    Error  string  `json:\"error,omitempty\"`\n}\n\n// getStockPrice is a tool that retrieves the stock price for a given ticker symbol\n// from the mockStockPrices map. It demonstrates how a function can be used as a\n// tool by an agent. If the symbol is found, it returns a struct containing the\n// symbol and its price. Otherwise, it returns a struct with an error message.\nfunc getStockPrice(ctx tool.Context, input getStockPriceArgs) getStockPriceResults {\n    symbolUpper := strings.ToUpper(input.Symbol)\n    if price, ok := mockStockPrices[symbolUpper]; ok {\n        fmt.Printf(\"Tool: Found price for %s: %f\\n\", input.Symbol, price)\n        return getStockPriceResults{Symbol: input.Symbol, Price: price}\n    }\n    return getStockPriceResults{Symbol: input.Symbol, Error: \"No data found for symbol\"}\n}\n\n// createStockAgent initializes and configures an LlmAgent.\n// This agent is equipped with the getStockPrice tool and is instructed\n// on how to respond to user queries about stock prices. It uses the\n// Gemini model to understand user intent and decide when to use its tools.\nfunc createStockAgent(ctx context.Context) (agent.Agent, error) {\n    stockPriceTool, err := functiontool.New(\n        functiontool.Config{\n            Name:        \"get_stock_price\",\n            Description: \"Retrieves the current stock price for a given symbol.\",\n        },\n        getStockPrice)\n    if err != nil {\n        return nil, err\n    }\n\n    model, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{})\n\n    if err != nil {\n        log.Fatalf(\"Failed to create model: %v\", err)\n    }\n\n    return llmagent.New(llmagent.Config{\n        Name:        \"stock_agent\",\n        Model:       model,\n        Instruction: \"You are an agent who retrieves stock prices. If a ticker symbol is provided, fetch the current price. If only a company name is given, first perform a Google search to find the correct ticker symbol before retrieving the stock price. If the provided ticker symbol is invalid or data cannot be retrieved, inform the user that the stock price could not be found.\",\n        Description: \"This agent specializes in retrieving real-time stock prices. Given a stock ticker symbol (e.g., AAPL, GOOG, MSFT) or the stock name, use the tools and reliable data sources to provide the most up-to-date price.\",\n        Tools: []tool.Tool{\n            stockPriceTool,\n        },\n    })\n}\n\n// userID and appName are constants used to identify the user and application\n// throughout the session. These values are important for logging, tracking,\n// and managing state across different agent interactions.\nconst (\n    userID  = \"example_user_id\"\n    appName = \"example_app\"\n)\n\n// callAgent orchestrates the execution of the agent for a given prompt.\n// It sets up the necessary services, creates a session, and uses a runner\n// to manage the agent's lifecycle. It streams the agent's responses and\n// prints them to the console, handling any potential errors during the run.\nfunc callAgent(ctx context.Context, a agent.Agent, prompt string) {\n    sessionService := session.InMemoryService()\n    // Create a new session for the agent interactions.\n    session, err := sessionService.Create(ctx, &session.CreateRequest{\n        AppName: appName,\n        UserID:  userID,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create the session service: %v\", err)\n    }\n    config := runner.Config{\n        AppName:        appName,\n        Agent:          a,\n        SessionService: sessionService,\n    }\n\n    // Create the runner to manage the agent execution.\n    r, err := runner.New(config)\n\n    if err != nil {\n        log.Fatalf(\"Failed to create the runner: %v\", err)\n    }\n\n    sessionID := session.Session.ID()\n\n    userMsg := &genai.Content{\n        Parts: []*genai.Part{\n            genai.NewPartFromText(prompt),\n        },\n        Role: string(genai.RoleUser),\n    }\n\n    for event, err := range r.Run(ctx, userID, sessionID, userMsg, agent.RunConfig{\n        StreamingMode: agent.StreamingModeNone,\n    }) {\n        if err != nil {\n            fmt.Printf(\"\\nAGENT_ERROR: %v\\n\", err)\n        } else {\n            for _, p := range event.Content.Parts {\n                fmt.Print(p.Text)\n            }\n        }\n    }\n}\n\n// RunAgentSimulation serves as the entry point for this example.\n// It creates the stock agent and then simulates a series of user interactions\n// by sending different prompts to the agent. This function showcases how the\n// agent responds to various queries, including both successful and unsuccessful\n// attempts to retrieve stock prices.\nfunc RunAgentSimulation() {\n    // Create the stock agent\n    agent, err := createStockAgent(context.Background())\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Println(\"Agent created:\", agent.Name())\n\n    prompts := []string{\n        \"stock price of GOOG\",\n        \"What's the price of MSFT?\",\n        \"Can you find the stock price for an unknown company XYZ?\",\n    }\n\n    // Simulate running the agent with different prompts\n    for _, prompt := range prompts {\n        fmt.Printf(\"\\nPrompt: %s\\nResponse: \", prompt)\n        callAgent(context.Background(), agent, prompt)\n        fmt.Println(\"\\n---\")\n    }\n}\n\n// createSummarizerAgent creates an agent whose sole purpose is to summarize text.\nfunc createSummarizerAgent(ctx context.Context) (agent.Agent, error) {\n    model, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{})\n    if err != nil {\n        return nil, err\n    }\n    return llmagent.New(llmagent.Config{\n        Name:        \"SummarizerAgent\",\n        Model:       model,\n        Instruction: \"You are an expert at summarizing text. Take the user's input and provide a concise summary.\",\n        Description: \"An agent that summarizes text.\",\n    })\n}\n\n// createMainAgent creates the primary agent that will use the summarizer agent as a tool.\nfunc createMainAgent(ctx context.Context, tools ...tool.Tool) (agent.Agent, error) {\n    model, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{})\n    if err != nil {\n        return nil, err\n    }\n    return llmagent.New(llmagent.Config{\n        Name:  \"MainAgent\",\n        Model: model,\n        Instruction: \"You are a helpful assistant. If you are asked to summarize a long text, use the 'summarize' tool. \" +\n            \"After getting the summary, present it to the user by saying 'Here is a summary of the text:'.\",\n        Description: \"The main agent that can delegate tasks.\",\n        Tools:       tools,\n    })\n}\n\nfunc RunAgentAsToolSimulation() {\n    ctx := context.Background()\n\n    // 1. Create the Tool Agent (Summarizer)\n    summarizerAgent, err := createSummarizerAgent(ctx)\n    if err != nil {\n        log.Fatalf(\"Failed to create summarizer agent: %v\", err)\n    }\n\n    // 2. Wrap the Tool Agent in an AgentTool\n    summarizeTool := agenttool.New(summarizerAgent, &agenttool.Config{\n        SkipSummarization: true,\n    })\n\n    // 3. Create the Main Agent and provide it with the AgentTool\n    mainAgent, err := createMainAgent(ctx, summarizeTool)\n    if err != nil {\n        log.Fatalf(\"Failed to create main agent: %v\", err)\n    }\n\n    // 4. Run the main agent\n    prompt := `\n        Please summarize this text for me:\n        Quantum computing represents a fundamentally different approach to computation,\n        leveraging the bizarre principles of quantum mechanics to process information. Unlike classical computers\n        that rely on bits representing either 0 or 1, quantum computers use qubits which can exist in a state of superposition - effectively\n        being 0, 1, or a combination of both simultaneously. Furthermore, qubits can become entangled,\n        meaning their fates are intertwined regardless of distance, allowing for complex correlations. This parallelism and\n        interconnectedness grant quantum computers the potential to solve specific types of incredibly complex problems - such\n        as drug discovery, materials science, complex system optimization, and breaking certain types of cryptography - far\n        faster than even the most powerful classical supercomputers could ever achieve, although the technology is still largely in its developmental stages.\n    `\n    fmt.Printf(\"\\nPrompt: %s\\nResponse: \", prompt)\n    callAgent(context.Background(), mainAgent, prompt)\n    fmt.Println(\"\\n---\")\n}\n\n\nfunc main() {\n    fmt.Println(\"Attempting to run the agent simulation...\")\n    RunAgentSimulation()\n    fmt.Println(\"\\nAttempting to run the agent-as-a-tool simulation...\")\n    RunAgentAsToolSimulation()\n}"}, {"language": "text", "code": "For input `{\"symbol\": \"GOOG\"}`: {\"price\":300.6,\"symbol\":\"GOOG\"}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.Annotations.Schema;\nimport com.google.adk.tools.FunctionTool;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class StockPriceAgent {\n\n  private static final String APP_NAME = \"stock_agent\";\n  private static final String USER_ID = \"user1234\";\n\n  // Mock data for various stocks functionality\n  // NOTE: This is a MOCK implementation. In a real Java application,\n  // you would use a financial data API or library.\n  private static final Map<String, Double> mockStockPrices = new HashMap<>();\n\n  static {\n    mockStockPrices.put(\"GOOG\", 1.0);\n    mockStockPrices.put(\"AAPL\", 1.0);\n    mockStockPrices.put(\"MSFT\", 1.0);\n  }\n\n  @Schema(description = \"Retrieves the current stock price for a given symbol.\")\n  public static Map<String, Object> getStockPrice(\n      @Schema(description = \"The stock symbol (e.g., \\\"AAPL\\\", \\\"GOOG\\\")\",\n        name = \"symbol\")\n      String symbol) {\n\n    try {\n      if (mockStockPrices.containsKey(symbol.toUpperCase())) {\n        double currentPrice = mockStockPrices.get(symbol.toUpperCase());\n        System.out.println(\"Tool: Found price for \" + symbol + \": \" + currentPrice);\n        return Map.of(\"symbol\", symbol, \"price\", currentPrice);\n      } else {\n        return Map.of(\"symbol\", symbol, \"error\", \"No data found for symbol\");\n      }\n    } catch (Exception e) {\n      return Map.of(\"symbol\", symbol, \"error\", e.getMessage());\n    }\n  }\n\n  public static void callAgent(String prompt) {\n    // Create the FunctionTool from the Java method\n    FunctionTool getStockPriceTool = FunctionTool.create(StockPriceAgent.class, \"getStockPrice\");\n\n    LlmAgent stockPriceAgent =\n        LlmAgent.builder()\n            .model(\"gemini-2.0-flash\")\n            .name(\"stock_agent\")\n            .instruction(\n                \"You are an agent who retrieves stock prices. If a ticker symbol is provided, fetch the current price. If only a company name is given, first perform a Google search to find the correct ticker symbol before retrieving the stock price. If the provided ticker symbol is invalid or data cannot be retrieved, inform the user that the stock price could not be found.\")\n            .description(\n                \"This agent specializes in retrieving real-time stock prices. Given a stock ticker symbol (e.g., AAPL, GOOG, MSFT) or the stock name, use the tools and reliable data sources to provide the most up-to-date price.\")\n            .tools(getStockPriceTool) // Add the Java FunctionTool\n            .build();\n\n    // Create an InMemoryRunner\n    InMemoryRunner runner = new InMemoryRunner(stockPriceAgent, APP_NAME);\n    // InMemoryRunner automatically creates a session service. Create a session using the service\n    Session session = runner.sessionService().createSession(APP_NAME, USER_ID).blockingGet();\n    Content userMessage = Content.fromParts(Part.fromText(prompt));\n\n    // Run the agent\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n    // Stream event response\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n\n  public static void main(String[] args) {\n    callAgent(\"stock price of GOOG\");\n    callAgent(\"What's the price of MSFT?\");\n    callAgent(\"Can you find the stock price for an unknown company XYZ?\");\n  }\n}"}, {"language": "text", "code": "For input `GOOG`: {\"symbol\": \"GOOG\", \"price\": \"1.0\"}"}]}, {"heading_path": ["Best Practices\u00b6"], "text": "Best Practices \u00b6 While you have considerable flexibility in defining your function, remember that simplicity enhances usability for the LLM. Consider these guidelines: Fewer Parameters are Better: Minimize the number of parameters to reduce complexity. Simple Data Types: Favor primitive data types like str and int over custom classes whenever possible. Meaningful Names: The function's name and parameter names significantly influence how the LLM interprets and utilizes the tool. Choose names that clearly reflect the function's purpose and the meaning of its inputs. Avoid generic names like do_stuff() or beAgent() . Build for Parallel Execution: Improve function calling performance when multiple tools are run by building for asynchronous operation. For information on enabling parallel execution for tools, see Increase tool performance with parallel execution . ", "code_blocks": []}, {"heading_path": ["Long Running Function Tools\u00b6"], "text": "Long Running Function Tools \u00b6 This tool is designed to help you start and manage tasks that are handled outside the operation of your agent workflow, and require a significant amount of processing time, without blocking the agent's execution. This tool is a subclass of FunctionTool . When using a LongRunningFunctionTool , your function can initiate the long-running operation and optionally return an initial result , such as a long-running operation id. Once a long running function tool is invoked the agent runner pauses the agent run and lets the agent client to decide whether to continue or wait until the long-running operation finishes. The agent client can query the progress of the long-running operation and send back an intermediate or final response. The agent can then continue with other tasks. An example is the human-in-the-loop scenario where the agent needs human approval before proceeding with a task. Warning: Execution handling Long Running Function Tools are designed to help you start and manage long running\ntasks as part of your agent workflow, but not perform the actual, long task.\nFor tasks that require significant time to complete, you should implement a separate\nserver to do the task. Tip: Parallel execution Depending on the type of tool you are building, designing for asychronous\noperation may be a better solution than creating a long running tool. For\nmore information, see Increase tool performance with parallel execution . ", "code_blocks": []}, {"heading_path": ["How it Works\u00b6"], "text": "How it Works \u00b6 In Python, you wrap a function with LongRunningFunctionTool .  In Java, you pass a Method name to LongRunningFunctionTool.create() . Initiation: When the LLM calls the tool, your function starts the long-running operation. Initial Updates: Your function should optionally return an initial result (e.g. the long-running operaiton id). The ADK framework takes the result and sends it back to the LLM packaged within a FunctionResponse . This allows the LLM to inform the user (e.g., status, percentage complete, messages). And then the agent run is ended / paused. Continue or Wait: After each agent run is completed. Agent client can query the progress of the long-running operation and decide whether to continue the agent run with an intermediate response (to update the progress) or wait until a final response is retrieved. Agent client should send the intermediate or final response back to the agent for the next run. Framework Handling: The ADK framework manages the execution. It sends the intermediate or final FunctionResponse sent by agent client to the LLM to generate a user friendly message. ", "code_blocks": []}, {"heading_path": ["Creating the Tool\u00b6"], "text": "Creating the Tool \u00b6 Define your tool function and wrap it using the LongRunningFunctionTool class: Python Go Java # 1. Define the long running function def ask_for_approval ( purpose : str , amount : float ) -> dict [ str , Any ]: \"\"\"Ask for approval for the reimbursement.\"\"\" # create a ticket for the approval # Send a notification to the approver with the link of the ticket return { 'status' : 'pending' , 'approver' : 'Sean Zhou' , 'purpose' : purpose , 'amount' : amount , 'ticket-id' : 'approval-ticket-1' } def reimburse ( purpose : str , amount : float ) -> str : \"\"\"Reimburse the amount of money to the employee.\"\"\" # send the reimbrusement request to payment vendor return { 'status' : 'ok' } # 2. Wrap the function with LongRunningFunctionTool long_running_tool = LongRunningFunctionTool ( func = ask_for_approval ) import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) // CreateTicketArgs defines the arguments for our long-running tool. type CreateTicketArgs struct { Urgency string `json:\"urgency\" jsonschema:\"The urgency level of the ticket.\"` } // CreateTicketResults defines the *initial* output of our long-running tool. type CreateTicketResults struct { Status string `json:\"status\"` TicketId string `json:\"ticket_id\"` } // createTicketAsync simulates the *initiation* of a long-running ticket creation task. func createTicketAsync ( ctx tool . Context , args CreateTicketArgs ) CreateTicketResults { log . Printf ( \"TOOL_EXEC: 'create_ticket_long_running' called with urgency: %s (Call ID: %s)\\n\" , args . Urgency , ctx . FunctionCallID ()) // \"Generate\" a ticket ID and return it in the initial response. ticketID := \"TICKET-ABC-123\" log . Printf ( \"ACTION: Generated Ticket ID: %s for Call ID: %s\\n\" , ticketID , ctx . FunctionCallID ()) // In a real application, you would save the association between the // FunctionCallID and the ticketID to handle the async response later. return CreateTicketResults { Status : \"started\" , TicketId : ticketID , } } func createTicketAgent ( ctx context . Context ) ( agent . Agent , error ) { ticketTool , err := functiontool . New ( functiontool . Config { Name : \"create_ticket_long_running\" , Description : \"Creates a new support ticket with a specified urgency level.\" , }, createTicketAsync , ) if err != nil { return nil , fmt . Errorf ( \"failed to create long running tool: %w\" , err ) } model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig {}) if err != nil { return nil , fmt . Errorf ( \"failed to create model: %v\" , err ) } return llmagent . New ( llmagent . Config { Name : \"ticket_agent\" , Model : model , Instruction : \"You are a helpful assistant for creating support tickets. Provide the status of the ticket at each interaction.\" , Tools : [] tool . Tool { ticketTool }, }) } import com.google.adk.agents.LlmAgent ; import com.google.adk.tools.LongRunningFunctionTool ; import java.util.HashMap ; import java.util.Map ; public class ExampleLongRunningFunction { // Define your Long Running function. // Ask for approval for the reimbursement. public static Map < String , Object > askForApproval ( String purpose , double amount ) { // Simulate creating a ticket and sending a notification System . out . println ( \"Simulating ticket creation for purpose: \" + purpose + \", amount: \" + amount ); // Send a notification to the approver with the link of the ticket Map < String , Object > result = new HashMap <> (); result . put ( \"status\" , \"pending\" ); result . put ( \"approver\" , \"Sean Zhou\" ); result . put ( \"purpose\" , purpose ); result . put ( \"amount\" , amount ); result . put ( \"ticket-id\" , \"approval-ticket-1\" ); return result ; } public static void main ( String [] args ) throws NoSuchMethodException { // Pass the method to LongRunningFunctionTool.create LongRunningFunctionTool approveTool = LongRunningFunctionTool . create ( ExampleLongRunningFunction . class , \"askForApproval\" ); // Include the tool in the agent LlmAgent approverAgent = LlmAgent . builder () // ... . tools ( approveTool ) . build (); } } ", "code_blocks": [{"language": "text", "code": "# 1. Define the long running function\ndef ask_for_approval(\n    purpose: str, amount: float\n) -> dict[str, Any]:\n    \"\"\"Ask for approval for the reimbursement.\"\"\"\n    # create a ticket for the approval\n    # Send a notification to the approver with the link of the ticket\n    return {'status': 'pending', 'approver': 'Sean Zhou', 'purpose' : purpose, 'amount': amount, 'ticket-id': 'approval-ticket-1'}\n\ndef reimburse(purpose: str, amount: float) -> str:\n    \"\"\"Reimburse the amount of money to the employee.\"\"\"\n    # send the reimbrusement request to payment vendor\n    return {'status': 'ok'}\n\n# 2. Wrap the function with LongRunningFunctionTool\nlong_running_tool = LongRunningFunctionTool(func=ask_for_approval)"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\n// CreateTicketArgs defines the arguments for our long-running tool.\ntype CreateTicketArgs struct {\n    Urgency string `json:\"urgency\" jsonschema:\"The urgency level of the ticket.\"`\n}\n\n// CreateTicketResults defines the *initial* output of our long-running tool.\ntype CreateTicketResults struct {\n    Status   string `json:\"status\"`\n    TicketId string `json:\"ticket_id\"`\n}\n\n// createTicketAsync simulates the *initiation* of a long-running ticket creation task.\nfunc createTicketAsync(ctx tool.Context, args CreateTicketArgs) CreateTicketResults {\n    log.Printf(\"TOOL_EXEC: 'create_ticket_long_running' called with urgency: %s (Call ID: %s)\\n\", args.Urgency, ctx.FunctionCallID())\n\n    // \"Generate\" a ticket ID and return it in the initial response.\n    ticketID := \"TICKET-ABC-123\"\n    log.Printf(\"ACTION: Generated Ticket ID: %s for Call ID: %s\\n\", ticketID, ctx.FunctionCallID())\n\n    // In a real application, you would save the association between the\n    // FunctionCallID and the ticketID to handle the async response later.\n    return CreateTicketResults{\n        Status:   \"started\",\n        TicketId: ticketID,\n    }\n}\n\nfunc createTicketAgent(ctx context.Context) (agent.Agent, error) {\n    ticketTool, err := functiontool.New(\n        functiontool.Config{\n            Name:        \"create_ticket_long_running\",\n            Description: \"Creates a new support ticket with a specified urgency level.\",\n        },\n        createTicketAsync,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create long running tool: %w\", err)\n    }\n\n    model, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{})\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create model: %v\", err)\n    }\n\n    return llmagent.New(llmagent.Config{\n        Name:        \"ticket_agent\",\n        Model:       model,\n        Instruction: \"You are a helpful assistant for creating support tickets. Provide the status of the ticket at each interaction.\",\n        Tools:       []tool.Tool{ticketTool},\n    })\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.tools.LongRunningFunctionTool;\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class ExampleLongRunningFunction {\n\n  // Define your Long Running function.\n  // Ask for approval for the reimbursement.\n  public static Map<String, Object> askForApproval(String purpose, double amount) {\n    // Simulate creating a ticket and sending a notification\n    System.out.println(\n        \"Simulating ticket creation for purpose: \" + purpose + \", amount: \" + amount);\n\n    // Send a notification to the approver with the link of the ticket\n    Map<String, Object> result = new HashMap<>();\n    result.put(\"status\", \"pending\");\n    result.put(\"approver\", \"Sean Zhou\");\n    result.put(\"purpose\", purpose);\n    result.put(\"amount\", amount);\n    result.put(\"ticket-id\", \"approval-ticket-1\");\n    return result;\n  }\n\n  public static void main(String[] args) throws NoSuchMethodException {\n    // Pass the method to LongRunningFunctionTool.create\n    LongRunningFunctionTool approveTool =\n        LongRunningFunctionTool.create(ExampleLongRunningFunction.class, \"askForApproval\");\n\n    // Include the tool in the agent\n    LlmAgent approverAgent =\n        LlmAgent.builder()\n            // ...\n            .tools(approveTool)\n            .build();\n  }\n}"}]}, {"heading_path": ["Intermediate / Final result Updates\u00b6"], "text": "Intermediate / Final result Updates \u00b6 Agent client received an event with long running function calls and check the status of the ticket. Then Agent client can send the intermediate or final response back to update the progress. The framework packages this value (even if it's None) into the content of the FunctionResponse sent back to the LLM. Note: Long running function response with Resume feature If your ADK agent workflow is configured with the Resume feature, you also must include\nthe Invocation ID ( invocation_id ) parameter with the long running \nfunction response. The Invocation ID you provide must be the same \ninvocation that generated the long running function request, otherwise \nthe system starts a new invocation with the response. If your\nagent uses the Resume feature, consider including the Invocation ID\nas a parameter with your long running function request, so it can be\nincluded with the response. For more details on using the Resume \nfeature, see Resume stopped agents . Applies to only Java ADK When passing ToolContext with Function Tools, ensure that one of the following is true: The Schema is passed with the ToolContext parameter in the function signature, like: @com.google.adk.tools.Annotations.Schema(name = \"toolContext\") ToolContext toolContext OR The following -parameters flag is set to the mvn compiler plugin <build> <plugins> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-compiler-plugin</artifactId> <version>3.14.0</version> <!-- or newer --> <configuration> <compilerArgs> <arg>-parameters</arg> </compilerArgs> </configuration> </plugin> </plugins> </build> This constraint is temporary and will be removed. Python Go Java # Agent Interaction async def call_agent_async ( query ): def get_long_running_function_call ( event : Event ) -> types . FunctionCall : # Get the long running function call from the event if not event . long_running_tool_ids or not event . content or not event . content . parts : return for part in event . content . parts : if ( part and part . function_call and event . long_running_tool_ids and part . function_call . id in event . long_running_tool_ids ): return part . function_call def get_function_response ( event : Event , function_call_id : str ) -> types . FunctionResponse : # Get the function response for the fuction call with specified id. if not event . content or not event . content . parts : return for part in event . content . parts : if ( part and part . function_response and part . function_response . id == function_call_id ): return part . function_response content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () print ( \" \\n Running agent...\" ) events_async = runner . run_async ( session_id = session . id , user_id = USER_ID , new_message = content ) long_running_function_call , long_running_function_response , ticket_id = None , None , None async for event in events_async : # Use helper to check for the specific auth request event if not long_running_function_call : long_running_function_call = get_long_running_function_call ( event ) else : _potential_response = get_function_response ( event , long_running_function_call . id ) if _potential_response : # Only update if we get a non-None response long_running_function_response = _potential_response ticket_id = long_running_function_response . response [ 'ticket-id' ] if event . content and event . content . parts : if text := '' . join ( part . text or '' for part in event . content . parts ): print ( f '[ { event . author } ]: { text } ' ) if long_running_function_response : # query the status of the correpsonding ticket via tciket_id # send back an intermediate / final response updated_response = long_running_function_response . model_copy ( deep = True ) updated_response . response = { 'status' : 'approved' } async for event in runner . run_async ( session_id = session . id , user_id = USER_ID , new_message = types . Content ( parts = [ types . Part ( function_response = updated_response )], role = 'user' ) ): if event . content and event . content . parts : if text := '' . join ( part . text or '' for part in event . content . parts ): print ( f '[ { event . author } ]: { text } ' ) The following example demonstrates a multi-turn workflow. First, the user asks the agent to create a ticket. The agent calls the long-running tool and the client captures the FunctionCall ID. The client then simulates the asynchronous work completing by sending subsequent FunctionResponse messages back to the agent to provide the ticket ID and final status. // runTurn executes a single turn with the agent and returns the captured function call ID. func runTurn ( ctx context . Context , r * runner . Runner , sessionID , turnLabel string , content * genai . Content ) string { var funcCallID atomic . Value // Safely store the found ID. fmt . Printf ( \"\\n--- %s ---\\n\" , turnLabel ) for event , err := range r . Run ( ctx , userID , sessionID , content , agent . RunConfig { StreamingMode : agent . StreamingModeNone , }) { if err != nil { fmt . Printf ( \"\\nAGENT_ERROR: %v\\n\" , err ) continue } // Print a summary of the event for clarity. printEventSummary ( event , turnLabel ) // Capture the function call ID from the event. for _ , part := range event . Content . Parts { if fc := part . FunctionCall ; fc != nil { if fc . Name == \"create_ticket_long_running\" { funcCallID . Store ( fc . ID ) } } } } if id , ok := funcCallID . Load ().( string ); ok { return id } return \"\" } func main () { ctx := context . Background () ticketAgent , err := createTicketAgent ( ctx ) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } // Setup the runner and session. sessionService := session . InMemoryService () session , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID }) if err != nil { log . Fatalf ( \"Failed to create session: %v\" , err ) } r , err := runner . New ( runner . Config { AppName : appName , Agent : ticketAgent , SessionService : sessionService }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } // --- Turn 1: User requests to create a ticket. --- initialUserMessage := genai . NewContentFromText ( \"Create a high urgency ticket for me.\" , genai . RoleUser ) funcCallID := runTurn ( ctx , r , session . Session . ID (), \"Turn 1: User Request\" , initialUserMessage ) if funcCallID == \"\" { log . Fatal ( \"ERROR: Tool 'create_ticket_long_running' not called in Turn 1.\" ) } fmt . Printf ( \"ACTION: Captured FunctionCall ID: %s\\n\" , funcCallID ) // --- Turn 2: App provides the final status of the ticket. --- // In a real application, the ticketID would be retrieved from a database // using the funcCallID. For this example, we'll use the same ID. ticketID := \"TICKET-ABC-123\" willContinue := false // Signal that this is the final response. ticketStatusResponse := & genai . FunctionResponse { Name : \"create_ticket_long_running\" , ID : funcCallID , Response : map [ string ] any { \"status\" : \"approved\" , \"ticket_id\" : ticketID , }, WillContinue : & willContinue , } appResponseWithStatus := & genai . Content { Role : string ( genai . RoleUser ), Parts : [] * genai . Part {{ FunctionResponse : ticketStatusResponse }}, } runTurn ( ctx , r , session . Session . ID (), \"Turn 2: App provides ticket status\" , appResponseWithStatus ) fmt . Println ( \"Long running function completed successfully.\" ) } // printEventSummary provides a readable log of agent and LLM interactions. func printEventSummary ( event * session . Event , turnLabel string ) { for _ , part := range event . Content . Parts { // Check for a text part. if part . Text != \"\" { fmt . Printf ( \"[%s][%s_TEXT]: %s\\n\" , turnLabel , event . Author , part . Text ) } // Check for a function call part. if fc := part . FunctionCall ; fc != nil { fmt . Printf ( \"[%s][%s_CALL]: %s(%v) ID: %s\\n\" , turnLabel , event . Author , fc . Name , fc . Args , fc . ID ) } } } import com.google.adk.agents.LlmAgent ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.runner.Runner ; import com.google.adk.sessions.Session ; import com.google.adk.tools.Annotations.Schema ; import com.google.adk.tools.LongRunningFunctionTool ; import com.google.adk.tools.ToolContext ; import com.google.common.collect.ImmutableList ; import com.google.common.collect.ImmutableMap ; import com.google.genai.types.Content ; import com.google.genai.types.FunctionCall ; import com.google.genai.types.FunctionResponse ; import com.google.genai.types.Part ; import java.util.Optional ; import java.util.UUID ; import java.util.concurrent.atomic.AtomicReference ; import java.util.stream.Collectors ; public class LongRunningFunctionExample { private static String USER_ID = \"user123\" ; @Schema ( name = \"create_ticket_long_running\" , description = \"\"\" Creates a new support ticket with a specified urgency level. Examples of urgency are 'high', 'medium', or 'low'. The ticket creation is a long-running process, and its ID will be provided when ready. \"\"\" ) public static void createTicketAsync ( @Schema ( name = \"urgency\" , description = \"The urgency level for the new ticket, such as 'high', 'medium', or 'low'.\" ) String urgency , @Schema ( name = \"toolContext\" ) // Ensures ADK injection ToolContext toolContext ) { System . out . printf ( \"TOOL_EXEC: 'create_ticket_long_running' called with urgency: %s (Call ID: %s)%n\" , urgency , toolContext . functionCallId (). orElse ( \"N/A\" )); } public static void main ( String [] args ) { LlmAgent agent = LlmAgent . builder () . name ( \"ticket_agent\" ) . description ( \"Agent for creating tickets via a long-running task.\" ) . model ( \"gemini-2.0-flash\" ) . tools ( ImmutableList . of ( LongRunningFunctionTool . create ( LongRunningFunctionExample . class , \"createTicketAsync\" ))) . build (); Runner runner = new InMemoryRunner ( agent ); Session session = runner . sessionService (). createSession ( agent . name (), USER_ID , null , null ). blockingGet (); // --- Turn 1: User requests ticket --- System . out . println ( \"\\n--- Turn 1: User Request ---\" ); Content initialUserMessage = Content . fromParts ( Part . fromText ( \"Create a high urgency ticket for me.\" )); AtomicReference < String > funcCallIdRef = new AtomicReference <> (); runner . runAsync ( USER_ID , session . id (), initialUserMessage ) . blockingForEach ( event -> { printEventSummary ( event , \"T1\" ); if ( funcCallIdRef . get () == null ) { // Capture the first relevant function call ID event . content (). flatMap ( Content :: parts ). orElse ( ImmutableList . of ()). stream () . map ( Part :: functionCall ) . flatMap ( Optional :: stream ) . filter ( fc -> \"create_ticket_long_running\" . equals ( fc . name (). orElse ( \"\" ))) . findFirst () . flatMap ( FunctionCall :: id ) . ifPresent ( funcCallIdRef :: set ); } }); if ( funcCallIdRef . get () == null ) { System . out . println ( \"ERROR: Tool 'create_ticket_long_running' not called in Turn 1.\" ); return ; } System . out . println ( \"ACTION: Captured FunctionCall ID: \" + funcCallIdRef . get ()); // --- Turn 2: App provides initial ticket_id (simulating async tool completion) --- System . out . println ( \"\\n--- Turn 2: App provides ticket_id ---\" ); String ticketId = \"TICKET-\" + UUID . randomUUID (). toString (). substring ( 0 , 8 ). toUpperCase (); FunctionResponse ticketCreatedFuncResponse = FunctionResponse . builder () . name ( \"create_ticket_long_running\" ) . id ( funcCallIdRef . get ()) . response ( ImmutableMap . of ( \"ticket_id\" , ticketId )) . build (); Content appResponseWithTicketId = Content . builder () . parts ( ImmutableList . of ( Part . builder (). functionResponse ( ticketCreatedFuncResponse ). build ())) . role ( \"user\" ) . build (); runner . runAsync ( USER_ID , session . id (), appResponseWithTicketId ) . blockingForEach ( event -> printEventSummary ( event , \"T2\" )); System . out . println ( \"ACTION: Sent ticket_id \" + ticketId + \" to agent.\" ); // --- Turn 3: App provides ticket status update --- System . out . println ( \"\\n--- Turn 3: App provides ticket status ---\" ); FunctionResponse ticketStatusFuncResponse = FunctionResponse . builder () . name ( \"create_ticket_long_running\" ) . id ( funcCallIdRef . get ()) . response ( ImmutableMap . of ( \"status\" , \"approved\" , \"ticket_id\" , ticketId )) . build (); Content appResponseWithStatus = Content . builder () . parts ( ImmutableList . of ( Part . builder (). functionResponse ( ticketStatusFuncResponse ). build ())) . role ( \"user\" ) . build (); runner . runAsync ( USER_ID , session . id (), appResponseWithStatus ) . blockingForEach ( event -> printEventSummary ( event , \"T3_FINAL\" )); System . out . println ( \"Long running function completed successfully.\" ); } private static void printEventSummary ( Event event , String turnLabel ) { event . content () . ifPresent ( content -> { String text = content . parts (). orElse ( ImmutableList . of ()). stream () . map ( part -> part . text (). orElse ( \"\" )) . filter ( s -> ! s . isEmpty ()) . collect ( Collectors . joining ( \" \" )); if ( ! text . isEmpty ()) { System . out . printf ( \"[%s][%s_TEXT]: %s%n\" , turnLabel , event . author (), text ); } content . parts (). orElse ( ImmutableList . of ()). stream () . map ( Part :: functionCall ) . flatMap ( Optional :: stream ) . findFirst () // Assuming one function call per relevant event for simplicity . ifPresent ( fc -> System . out . printf ( \"[%s][%s_CALL]: %s(%s) ID: %s%n\" , turnLabel , event . author (), fc . name (). orElse ( \"N/A\" ), fc . args (). orElse ( ImmutableMap . of ()), fc . id (). orElse ( \"N/A\" ))); }); } } Python complete example: File Processing Simulation # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import asyncio from typing import Any from google.adk.agents import Agent from google.adk.events import Event from google.adk.runners import Runner from google.adk.tools import LongRunningFunctionTool from google.adk.sessions import InMemorySessionService from google.genai import types # 1. Define the long running function def ask_for_approval ( purpose : str , amount : float ) -> dict [ str , Any ]: \"\"\"Ask for approval for the reimbursement.\"\"\" # create a ticket for the approval # Send a notification to the approver with the link of the ticket return { 'status' : 'pending' , 'approver' : 'Sean Zhou' , 'purpose' : purpose , 'amount' : amount , 'ticket-id' : 'approval-ticket-1' } def reimburse ( purpose : str , amount : float ) -> str : \"\"\"Reimburse the amount of money to the employee.\"\"\" # send the reimbrusement request to payment vendor return { 'status' : 'ok' } # 2. Wrap the function with LongRunningFunctionTool long_running_tool = LongRunningFunctionTool ( func = ask_for_approval ) # 3. Use the tool in an Agent file_processor_agent = Agent ( # Use a model compatible with function calling model = \"gemini-2.0-flash\" , name = 'reimbursement_agent' , instruction = \"\"\" You are an agent whose job is to handle the reimbursement process for the employees. If the amount is less than $100, you will automatically approve the reimbursement. If the amount is greater than $100, you will ask for approval from the manager. If the manager approves, you will call reimburse() to reimburse the amount to the employee. If the manager rejects, you will inform the employee of the rejection. \"\"\" , tools = [ reimburse , long_running_tool ] ) APP_NAME = \"human_in_the_loop\" USER_ID = \"1234\" SESSION_ID = \"session1234\" # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = file_processor_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): def get_long_running_function_call ( event : Event ) -> types . FunctionCall : # Get the long running function call from the event if not event . long_running_tool_ids or not event . content or not event . content . parts : return for part in event . content . parts : if ( part and part . function_call and event . long_running_tool_ids and part . function_call . id in event . long_running_tool_ids ): return part . function_call def get_function_response ( event : Event , function_call_id : str ) -> types . FunctionResponse : # Get the function response for the fuction call with specified id. if not event . content or not event . content . parts : return for part in event . content . parts : if ( part and part . function_response and part . function_response . id == function_call_id ): return part . function_response content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () print ( \" \\n Running agent...\" ) events_async = runner . run_async ( session_id = session . id , user_id = USER_ID , new_message = content ) long_running_function_call , long_running_function_response , ticket_id = None , None , None async for event in events_async : # Use helper to check for the specific auth request event if not long_running_function_call : long_running_function_call = get_long_running_function_call ( event ) else : _potential_response = get_function_response ( event , long_running_function_call . id ) if _potential_response : # Only update if we get a non-None response long_running_function_response = _potential_response ticket_id = long_running_function_response . response [ 'ticket-id' ] if event . content and event . content . parts : if text := '' . join ( part . text or '' for part in event . content . parts ): print ( f '[ { event . author } ]: { text } ' ) if long_running_function_response : # query the status of the correpsonding ticket via tciket_id # send back an intermediate / final response updated_response = long_running_function_response . model_copy ( deep = True ) updated_response . response = { 'status' : 'approved' } async for event in runner . run_async ( session_id = session . id , user_id = USER_ID , new_message = types . Content ( parts = [ types . Part ( function_response = updated_response )], role = 'user' ) ): if event . content and event . content . parts : if text := '' . join ( part . text or '' for part in event . content . parts ): print ( f '[ { event . author } ]: { text } ' ) # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. # reimbursement that doesn't require approval # asyncio.run(call_agent_async(\"Please reimburse 50$ for meals\")) await call_agent_async ( \"Please reimburse 50$ for meals\" ) # For Notebooks, uncomment this line and comment the above line # reimbursement that requires approval # asyncio.run(call_agent_async(\"Please reimburse 200$ for meals\")) await call_agent_async ( \"Please reimburse 200$ for meals\" ) # For Notebooks, uncomment this line and comment the above line ", "code_blocks": [{"language": "text", "code": "@com.google.adk.tools.Annotations.Schema(name = \"toolContext\") ToolContext toolContext"}, {"language": "text", "code": "<build>\n    <plugins>\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-compiler-plugin</artifactId>\n            <version>3.14.0</version> <!-- or newer -->\n            <configuration>\n                <compilerArgs>\n                    <arg>-parameters</arg>\n                </compilerArgs>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>"}, {"language": "text", "code": "# Agent Interaction\nasync def call_agent_async(query):\n\n    def get_long_running_function_call(event: Event) -> types.FunctionCall:\n        # Get the long running function call from the event\n        if not event.long_running_tool_ids or not event.content or not event.content.parts:\n            return\n        for part in event.content.parts:\n            if (\n                part\n                and part.function_call\n                and event.long_running_tool_ids\n                and part.function_call.id in event.long_running_tool_ids\n            ):\n                return part.function_call\n\n    def get_function_response(event: Event, function_call_id: str) -> types.FunctionResponse:\n        # Get the function response for the fuction call with specified id.\n        if not event.content or not event.content.parts:\n            return\n        for part in event.content.parts:\n            if (\n                part\n                and part.function_response\n                and part.function_response.id == function_call_id\n            ):\n                return part.function_response\n\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n\n    print(\"\\nRunning agent...\")\n    events_async = runner.run_async(\n        session_id=session.id, user_id=USER_ID, new_message=content\n    )\n\n\n    long_running_function_call, long_running_function_response, ticket_id = None, None, None\n    async for event in events_async:\n        # Use helper to check for the specific auth request event\n        if not long_running_function_call:\n            long_running_function_call = get_long_running_function_call(event)\n        else:\n            _potential_response = get_function_response(event, long_running_function_call.id)\n            if _potential_response: # Only update if we get a non-None response\n                long_running_function_response = _potential_response\n                ticket_id = long_running_function_response.response['ticket-id']\n        if event.content and event.content.parts:\n            if text := ''.join(part.text or '' for part in event.content.parts):\n                print(f'[{event.author}]: {text}')\n\n\n    if long_running_function_response:\n        # query the status of the correpsonding ticket via tciket_id\n        # send back an intermediate / final response\n        updated_response = long_running_function_response.model_copy(deep=True)\n        updated_response.response = {'status': 'approved'}\n        async for event in runner.run_async(\n          session_id=session.id, user_id=USER_ID, new_message=types.Content(parts=[types.Part(function_response = updated_response)], role='user')\n        ):\n            if event.content and event.content.parts:\n                if text := ''.join(part.text or '' for part in event.content.parts):\n                    print(f'[{event.author}]: {text}')"}, {"language": "text", "code": "// runTurn executes a single turn with the agent and returns the captured function call ID.\nfunc runTurn(ctx context.Context, r *runner.Runner, sessionID, turnLabel string, content *genai.Content) string {\n    var funcCallID atomic.Value // Safely store the found ID.\n\n    fmt.Printf(\"\\n--- %s ---\\n\", turnLabel)\n    for event, err := range r.Run(ctx, userID, sessionID, content, agent.RunConfig{\n        StreamingMode: agent.StreamingModeNone,\n    }) {\n        if err != nil {\n            fmt.Printf(\"\\nAGENT_ERROR: %v\\n\", err)\n            continue\n        }\n        // Print a summary of the event for clarity.\n        printEventSummary(event, turnLabel)\n\n        // Capture the function call ID from the event.\n        for _, part := range event.Content.Parts {\n            if fc := part.FunctionCall; fc != nil {\n                if fc.Name == \"create_ticket_long_running\" {\n                    funcCallID.Store(fc.ID)\n                }\n            }\n        }\n    }\n\n    if id, ok := funcCallID.Load().(string); ok {\n        return id\n    }\n    return \"\"\n}\n\nfunc main() {\n    ctx := context.Background()\n    ticketAgent, err := createTicketAgent(ctx)\n    if err != nil {\n        log.Fatalf(\"Failed to create agent: %v\", err)\n    }\n\n    // Setup the runner and session.\n    sessionService := session.InMemoryService()\n    session, err := sessionService.Create(ctx, &session.CreateRequest{AppName: appName, UserID: userID})\n    if err != nil {\n        log.Fatalf(\"Failed to create session: %v\", err)\n    }\n    r, err := runner.New(runner.Config{AppName: appName, Agent: ticketAgent, SessionService: sessionService})\n    if err != nil {\n        log.Fatalf(\"Failed to create runner: %v\", err)\n    }\n\n    // --- Turn 1: User requests to create a ticket. ---\n    initialUserMessage := genai.NewContentFromText(\"Create a high urgency ticket for me.\", genai.RoleUser)\n    funcCallID := runTurn(ctx, r, session.Session.ID(), \"Turn 1: User Request\", initialUserMessage)\n    if funcCallID == \"\" {\n        log.Fatal(\"ERROR: Tool 'create_ticket_long_running' not called in Turn 1.\")\n    }\n    fmt.Printf(\"ACTION: Captured FunctionCall ID: %s\\n\", funcCallID)\n\n    // --- Turn 2: App provides the final status of the ticket. ---\n    // In a real application, the ticketID would be retrieved from a database\n    // using the funcCallID. For this example, we'll use the same ID.\n    ticketID := \"TICKET-ABC-123\"\n    willContinue := false // Signal that this is the final response.\n    ticketStatusResponse := &genai.FunctionResponse{\n        Name: \"create_ticket_long_running\",\n        ID:   funcCallID,\n        Response: map[string]any{\n            \"status\":    \"approved\",\n            \"ticket_id\": ticketID,\n        },\n        WillContinue: &willContinue,\n    }\n    appResponseWithStatus := &genai.Content{\n        Role:  string(genai.RoleUser),\n        Parts: []*genai.Part{{FunctionResponse: ticketStatusResponse}},\n    }\n    runTurn(ctx, r, session.Session.ID(), \"Turn 2: App provides ticket status\", appResponseWithStatus)\n    fmt.Println(\"Long running function completed successfully.\")\n}\n\n// printEventSummary provides a readable log of agent and LLM interactions.\nfunc printEventSummary(event *session.Event, turnLabel string) {\n    for _, part := range event.Content.Parts {\n        // Check for a text part.\n        if part.Text != \"\" {\n            fmt.Printf(\"[%s][%s_TEXT]: %s\\n\", turnLabel, event.Author, part.Text)\n        }\n        // Check for a function call part.\n        if fc := part.FunctionCall; fc != nil {\n            fmt.Printf(\"[%s][%s_CALL]: %s(%v) ID: %s\\n\", turnLabel, event.Author, fc.Name, fc.Args, fc.ID)\n        }\n    }\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.Annotations.Schema;\nimport com.google.adk.tools.LongRunningFunctionTool;\nimport com.google.adk.tools.ToolContext;\nimport com.google.common.collect.ImmutableList;\nimport com.google.common.collect.ImmutableMap;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.FunctionCall;\nimport com.google.genai.types.FunctionResponse;\nimport com.google.genai.types.Part;\nimport java.util.Optional;\nimport java.util.UUID;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\n\npublic class LongRunningFunctionExample {\n\n  private static String USER_ID = \"user123\";\n\n  @Schema(\n      name = \"create_ticket_long_running\",\n      description = \"\"\"\n          Creates a new support ticket with a specified urgency level.\n          Examples of urgency are 'high', 'medium', or 'low'.\n          The ticket creation is a long-running process, and its ID will be provided when ready.\n      \"\"\")\n  public static void createTicketAsync(\n      @Schema(\n              name = \"urgency\",\n              description =\n                  \"The urgency level for the new ticket, such as 'high', 'medium', or 'low'.\")\n          String urgency,\n      @Schema(name = \"toolContext\") // Ensures ADK injection\n          ToolContext toolContext) {\n    System.out.printf(\n        \"TOOL_EXEC: 'create_ticket_long_running' called with urgency: %s (Call ID: %s)%n\",\n        urgency, toolContext.functionCallId().orElse(\"N/A\"));\n  }\n\n  public static void main(String[] args) {\n    LlmAgent agent =\n        LlmAgent.builder()\n            .name(\"ticket_agent\")\n            .description(\"Agent for creating tickets via a long-running task.\")\n            .model(\"gemini-2.0-flash\")\n            .tools(\n                ImmutableList.of(\n                    LongRunningFunctionTool.create(\n                        LongRunningFunctionExample.class, \"createTicketAsync\")))\n            .build();\n\n    Runner runner = new InMemoryRunner(agent);\n    Session session =\n        runner.sessionService().createSession(agent.name(), USER_ID, null, null).blockingGet();\n\n    // --- Turn 1: User requests ticket ---\n    System.out.println(\"\\n--- Turn 1: User Request ---\");\n    Content initialUserMessage =\n        Content.fromParts(Part.fromText(\"Create a high urgency ticket for me.\"));\n\n    AtomicReference<String> funcCallIdRef = new AtomicReference<>();\n    runner\n        .runAsync(USER_ID, session.id(), initialUserMessage)\n        .blockingForEach(\n            event -> {\n              printEventSummary(event, \"T1\");\n              if (funcCallIdRef.get() == null) { // Capture the first relevant function call ID\n                event.content().flatMap(Content::parts).orElse(ImmutableList.of()).stream()\n                    .map(Part::functionCall)\n                    .flatMap(Optional::stream)\n                    .filter(fc -> \"create_ticket_long_running\".equals(fc.name().orElse(\"\")))\n                    .findFirst()\n                    .flatMap(FunctionCall::id)\n                    .ifPresent(funcCallIdRef::set);\n              }\n            });\n\n    if (funcCallIdRef.get() == null) {\n      System.out.println(\"ERROR: Tool 'create_ticket_long_running' not called in Turn 1.\");\n      return;\n    }\n    System.out.println(\"ACTION: Captured FunctionCall ID: \" + funcCallIdRef.get());\n\n    // --- Turn 2: App provides initial ticket_id (simulating async tool completion) ---\n    System.out.println(\"\\n--- Turn 2: App provides ticket_id ---\");\n    String ticketId = \"TICKET-\" + UUID.randomUUID().toString().substring(0, 8).toUpperCase();\n    FunctionResponse ticketCreatedFuncResponse =\n        FunctionResponse.builder()\n            .name(\"create_ticket_long_running\")\n            .id(funcCallIdRef.get())\n            .response(ImmutableMap.of(\"ticket_id\", ticketId))\n            .build();\n    Content appResponseWithTicketId =\n        Content.builder()\n            .parts(\n                ImmutableList.of(\n                    Part.builder().functionResponse(ticketCreatedFuncResponse).build()))\n            .role(\"user\")\n            .build();\n\n    runner\n        .runAsync(USER_ID, session.id(), appResponseWithTicketId)\n        .blockingForEach(event -> printEventSummary(event, \"T2\"));\n    System.out.println(\"ACTION: Sent ticket_id \" + ticketId + \" to agent.\");\n\n    // --- Turn 3: App provides ticket status update ---\n    System.out.println(\"\\n--- Turn 3: App provides ticket status ---\");\n    FunctionResponse ticketStatusFuncResponse =\n        FunctionResponse.builder()\n            .name(\"create_ticket_long_running\")\n            .id(funcCallIdRef.get())\n            .response(ImmutableMap.of(\"status\", \"approved\", \"ticket_id\", ticketId))\n            .build();\n    Content appResponseWithStatus =\n        Content.builder()\n            .parts(\n                ImmutableList.of(Part.builder().functionResponse(ticketStatusFuncResponse).build()))\n            .role(\"user\")\n            .build();\n\n    runner\n        .runAsync(USER_ID, session.id(), appResponseWithStatus)\n        .blockingForEach(event -> printEventSummary(event, \"T3_FINAL\"));\n    System.out.println(\"Long running function completed successfully.\");\n  }\n\n  private static void printEventSummary(Event event, String turnLabel) {\n    event\n        .content()\n        .ifPresent(\n            content -> {\n              String text =\n                  content.parts().orElse(ImmutableList.of()).stream()\n                      .map(part -> part.text().orElse(\"\"))\n                      .filter(s -> !s.isEmpty())\n                      .collect(Collectors.joining(\" \"));\n              if (!text.isEmpty()) {\n                System.out.printf(\"[%s][%s_TEXT]: %s%n\", turnLabel, event.author(), text);\n              }\n              content.parts().orElse(ImmutableList.of()).stream()\n                  .map(Part::functionCall)\n                  .flatMap(Optional::stream)\n                  .findFirst() // Assuming one function call per relevant event for simplicity\n                  .ifPresent(\n                      fc ->\n                          System.out.printf(\n                              \"[%s][%s_CALL]: %s(%s) ID: %s%n\",\n                              turnLabel,\n                              event.author(),\n                              fc.name().orElse(\"N/A\"),\n                              fc.args().orElse(ImmutableMap.of()),\n                              fc.id().orElse(\"N/A\")));\n            });\n  }\n}"}, {"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\nfrom typing import Any\nfrom google.adk.agents import Agent\nfrom google.adk.events import Event\nfrom google.adk.runners import Runner\nfrom google.adk.tools import LongRunningFunctionTool\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\n\n# 1. Define the long running function\ndef ask_for_approval(\n    purpose: str, amount: float\n) -> dict[str, Any]:\n    \"\"\"Ask for approval for the reimbursement.\"\"\"\n    # create a ticket for the approval\n    # Send a notification to the approver with the link of the ticket\n    return {'status': 'pending', 'approver': 'Sean Zhou', 'purpose' : purpose, 'amount': amount, 'ticket-id': 'approval-ticket-1'}\n\ndef reimburse(purpose: str, amount: float) -> str:\n    \"\"\"Reimburse the amount of money to the employee.\"\"\"\n    # send the reimbrusement request to payment vendor\n    return {'status': 'ok'}\n\n# 2. Wrap the function with LongRunningFunctionTool\nlong_running_tool = LongRunningFunctionTool(func=ask_for_approval)\n\n\n# 3. Use the tool in an Agent\nfile_processor_agent = Agent(\n    # Use a model compatible with function calling\n    model=\"gemini-2.0-flash\",\n    name='reimbursement_agent',\n    instruction=\"\"\"\n      You are an agent whose job is to handle the reimbursement process for\n      the employees. If the amount is less than $100, you will automatically\n      approve the reimbursement.\n\n      If the amount is greater than $100, you will\n      ask for approval from the manager. If the manager approves, you will\n      call reimburse() to reimburse the amount to the employee. If the manager\n      rejects, you will inform the employee of the rejection.\n    \"\"\",\n    tools=[reimburse, long_running_tool]\n)\n\n\nAPP_NAME = \"human_in_the_loop\"\nUSER_ID = \"1234\"\nSESSION_ID = \"session1234\"\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=file_processor_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n\n# Agent Interaction\nasync def call_agent_async(query):\n\n    def get_long_running_function_call(event: Event) -> types.FunctionCall:\n        # Get the long running function call from the event\n        if not event.long_running_tool_ids or not event.content or not event.content.parts:\n            return\n        for part in event.content.parts:\n            if (\n                part\n                and part.function_call\n                and event.long_running_tool_ids\n                and part.function_call.id in event.long_running_tool_ids\n            ):\n                return part.function_call\n\n    def get_function_response(event: Event, function_call_id: str) -> types.FunctionResponse:\n        # Get the function response for the fuction call with specified id.\n        if not event.content or not event.content.parts:\n            return\n        for part in event.content.parts:\n            if (\n                part\n                and part.function_response\n                and part.function_response.id == function_call_id\n            ):\n                return part.function_response\n\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n\n    print(\"\\nRunning agent...\")\n    events_async = runner.run_async(\n        session_id=session.id, user_id=USER_ID, new_message=content\n    )\n\n\n    long_running_function_call, long_running_function_response, ticket_id = None, None, None\n    async for event in events_async:\n        # Use helper to check for the specific auth request event\n        if not long_running_function_call:\n            long_running_function_call = get_long_running_function_call(event)\n        else:\n            _potential_response = get_function_response(event, long_running_function_call.id)\n            if _potential_response: # Only update if we get a non-None response\n                long_running_function_response = _potential_response\n                ticket_id = long_running_function_response.response['ticket-id']\n        if event.content and event.content.parts:\n            if text := ''.join(part.text or '' for part in event.content.parts):\n                print(f'[{event.author}]: {text}')\n\n\n    if long_running_function_response:\n        # query the status of the correpsonding ticket via tciket_id\n        # send back an intermediate / final response\n        updated_response = long_running_function_response.model_copy(deep=True)\n        updated_response.response = {'status': 'approved'}\n        async for event in runner.run_async(\n          session_id=session.id, user_id=USER_ID, new_message=types.Content(parts=[types.Part(function_response = updated_response)], role='user')\n        ):\n            if event.content and event.content.parts:\n                if text := ''.join(part.text or '' for part in event.content.parts):\n                    print(f'[{event.author}]: {text}')\n\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\n\n# reimbursement that doesn't require approval\n# asyncio.run(call_agent_async(\"Please reimburse 50$ for meals\"))\nawait call_agent_async(\"Please reimburse 50$ for meals\") # For Notebooks, uncomment this line and comment the above line\n# reimbursement that requires approval\n# asyncio.run(call_agent_async(\"Please reimburse 200$ for meals\"))\nawait call_agent_async(\"Please reimburse 200$ for meals\") # For Notebooks, uncomment this line and comment the above line"}]}, {"heading_path": ["Key aspects of this example\u00b6"], "text": "Key aspects of this example \u00b6 LongRunningFunctionTool : Wraps the supplied method/function; the framework handles sending yielded updates and the final return value as sequential FunctionResponses. Agent instruction : Directs the LLM to use the tool and understand the incoming FunctionResponse stream (progress vs. completion) for user updates. Final return : The function returns the final result dictionary, which is sent in the concluding FunctionResponse to indicate completion. ", "code_blocks": []}, {"heading_path": ["Agent-as-a-Tool\u00b6"], "text": "Agent-as-a-Tool \u00b6 This powerful feature allows you to leverage the capabilities of other agents within your system by calling them as tools. The Agent-as-a-Tool enables you to invoke another agent to perform a specific task, effectively delegating responsibility . This is conceptually similar to creating a Python function that calls another agent and uses the agent's response as the function's return value. ", "code_blocks": []}, {"heading_path": ["Key difference from sub-agents\u00b6"], "text": "Key difference from sub-agents \u00b6 It's important to distinguish an Agent-as-a-Tool from a Sub-Agent. Agent-as-a-Tool: When Agent A calls Agent B as a tool (using Agent-as-a-Tool), Agent B's answer is passed back to Agent A, which then summarizes the answer and generates a response to the user. Agent A retains control and continues to handle future user input. Sub-agent: When Agent A calls Agent B as a sub-agent, the responsibility of answering the user is completely transferred to Agent B . Agent A is effectively out of the loop. All subsequent user input will be answered by Agent B. ", "code_blocks": []}, {"heading_path": ["Usage\u00b6"], "text": "Usage \u00b6 To use an agent as a tool, wrap the agent with the AgentTool class. Python Go Java tools = [ AgentTool ( agent = agent_b )] agenttool . New ( agent , & agenttool . Config { ... }) AgentTool . create ( agent ) ", "code_blocks": [{"language": "text", "code": "tools=[AgentTool(agent=agent_b)]"}, {"language": "text", "code": "agenttool.New(agent, &agenttool.Config{...})"}, {"language": "text", "code": "AgentTool.create(agent)"}]}, {"heading_path": ["Customization\u00b6"], "text": "Customization \u00b6 The AgentTool class provides the following attributes for customizing its behavior: skip_summarization: bool: If set to True, the framework will bypass the LLM-based summarization of the tool agent's response. This can be useful when the tool's response is already well-formatted and requires no further processing. Example Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.agents import Agent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.tools.agent_tool import AgentTool from google.genai import types APP_NAME = \"summary_agent\" USER_ID = \"user1234\" SESSION_ID = \"1234\" summary_agent = Agent ( model = \"gemini-2.0-flash\" , name = \"summary_agent\" , instruction = \"\"\"You are an expert summarizer. Please read the following text and provide a concise summary.\"\"\" , description = \"Agent to summarize text\" , ) root_agent = Agent ( model = 'gemini-2.0-flash' , name = 'root_agent' , instruction = \"\"\"You are a helpful assistant. When the user provides a text, use the 'summarize' tool to generate a summary. Always forward the user's message exactly as received to the 'summarize' tool, without modifying or summarizing it yourself. Present the response from the tool to the user.\"\"\" , tools = [ AgentTool ( agent = summary_agent , skip_summarization = True )] ) # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = root_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) async for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response: \" , final_response ) long_text = \"\"\"Quantum computing represents a fundamentally different approach to computation, leveraging the bizarre principles of quantum mechanics to process information. Unlike classical computers that rely on bits representing either 0 or 1, quantum computers use qubits which can exist in a state of superposition - effectively being 0, 1, or a combination of both simultaneously. Furthermore, qubits can become entangled, meaning their fates are intertwined regardless of distance, allowing for complex correlations. This parallelism and interconnectedness grant quantum computers the potential to solve specific types of incredibly complex problems - such as drug discovery, materials science, complex system optimization, and breaking certain types of cryptography - far faster than even the most powerful classical supercomputers could ever achieve, although the technology is still largely in its developmental stages.\"\"\" # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( long_text ) import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/agenttool\" \"google.golang.org/genai\" ) // createSummarizerAgent creates an agent whose sole purpose is to summarize text. func createSummarizerAgent ( ctx context . Context ) ( agent . Agent , error ) { model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig {}) if err != nil { return nil , err } return llmagent . New ( llmagent . Config { Name : \"SummarizerAgent\" , Model : model , Instruction : \"You are an expert at summarizing text. Take the user's input and provide a concise summary.\" , Description : \"An agent that summarizes text.\" , }) } // createMainAgent creates the primary agent that will use the summarizer agent as a tool. func createMainAgent ( ctx context . Context , tools ... tool . Tool ) ( agent . Agent , error ) { model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig {}) if err != nil { return nil , err } return llmagent . New ( llmagent . Config { Name : \"MainAgent\" , Model : model , Instruction : \"You are a helpful assistant. If you are asked to summarize a long text, use the 'summarize' tool. \" + \"After getting the summary, present it to the user by saying 'Here is a summary of the text:'.\" , Description : \"The main agent that can delegate tasks.\" , Tools : tools , }) } func RunAgentAsToolSimulation () { ctx := context . Background () // 1. Create the Tool Agent (Summarizer) summarizerAgent , err := createSummarizerAgent ( ctx ) if err != nil { log . Fatalf ( \"Failed to create summarizer agent: %v\" , err ) } // 2. Wrap the Tool Agent in an AgentTool summarizeTool := agenttool . New ( summarizerAgent , & agenttool . Config { SkipSummarization : true , }) // 3. Create the Main Agent and provide it with the AgentTool mainAgent , err := createMainAgent ( ctx , summarizeTool ) if err != nil { log . Fatalf ( \"Failed to create main agent: %v\" , err ) } // 4. Run the main agent prompt := ` Please summarize this text for me: Quantum computing represents a fundamentally different approach to computation, leveraging the bizarre principles of quantum mechanics to process information. Unlike classical computers that rely on bits representing either 0 or 1, quantum computers use qubits which can exist in a state of superposition - effectively being 0, 1, or a combination of both simultaneously. Furthermore, qubits can become entangled, meaning their fates are intertwined regardless of distance, allowing for complex correlations. This parallelism and interconnectedness grant quantum computers the potential to solve specific types of incredibly complex problems - such as drug discovery, materials science, complex system optimization, and breaking certain types of cryptography - far faster than even the most powerful classical supercomputers could ever achieve, although the technology is still largely in its developmental stages. ` fmt . Printf ( \"\\nPrompt: %s\\nResponse: \" , prompt ) callAgent ( context . Background (), mainAgent , prompt ) fmt . Println ( \"\\n---\" ) } import com.google.adk.agents.LlmAgent ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.adk.tools.AgentTool ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; public class AgentToolCustomization { private static final String APP_NAME = \"summary_agent\" ; private static final String USER_ID = \"user1234\" ; public static void initAgentAndRun ( String prompt ) { LlmAgent summaryAgent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"summaryAgent\" ) . instruction ( \"You are an expert summarizer. Please read the following text and provide a concise summary.\" ) . description ( \"Agent to summarize text\" ) . build (); // Define root_agent LlmAgent rootAgent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"rootAgent\" ) . instruction ( \"You are a helpful assistant. When the user provides a text, always use the 'summaryAgent' tool to generate a summary. Always forward the user's message exactly as received to the 'summaryAgent' tool, without modifying or summarizing it yourself. Present the response from the tool to the user.\" ) . description ( \"Assistant agent\" ) . tools ( AgentTool . create ( summaryAgent , true )) // Set skipSummarization to true . build (); // Create an InMemoryRunner InMemoryRunner runner = new InMemoryRunner ( rootAgent , APP_NAME ); // InMemoryRunner automatically creates a session service. Create a session using the service Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( prompt )); // Run the agent Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } public static void main ( String [] args ) { String longText = \"\"\" Quantum computing represents a fundamentally different approach to computation, leveraging the bizarre principles of quantum mechanics to process information. Unlike classical computers that rely on bits representing either 0 or 1, quantum computers use qubits which can exist in a state of superposition - effectively being 0, 1, or a combination of both simultaneously. Furthermore, qubits can become entangled, meaning their fates are intertwined regardless of distance, allowing for complex correlations. This parallelism and interconnectedness grant quantum computers the potential to solve specific types of incredibly complex problems - such as drug discovery, materials science, complex system optimization, and breaking certain types of cryptography - far faster than even the most powerful classical supercomputers could ever achieve, although the technology is still largely in its developmental stages.\"\"\" ; initAgentAndRun ( longText ); } } ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.agents import Agent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.genai import types\n\nAPP_NAME=\"summary_agent\"\nUSER_ID=\"user1234\"\nSESSION_ID=\"1234\"\n\nsummary_agent = Agent(\n    model=\"gemini-2.0-flash\",\n    name=\"summary_agent\",\n    instruction=\"\"\"You are an expert summarizer. Please read the following text and provide a concise summary.\"\"\",\n    description=\"Agent to summarize text\",\n)\n\nroot_agent = Agent(\n    model='gemini-2.0-flash',\n    name='root_agent',\n    instruction=\"\"\"You are a helpful assistant. When the user provides a text, use the 'summarize' tool to generate a summary. Always forward the user's message exactly as received to the 'summarize' tool, without modifying or summarizing it yourself. Present the response from the tool to the user.\"\"\",\n    tools=[AgentTool(agent=summary_agent, skip_summarization=True)]\n)\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n\n# Agent Interaction\nasync def call_agent_async(query):\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    async for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"Agent Response: \", final_response)\n\n\nlong_text = \"\"\"Quantum computing represents a fundamentally different approach to computation, \nleveraging the bizarre principles of quantum mechanics to process information. Unlike classical computers \nthat rely on bits representing either 0 or 1, quantum computers use qubits which can exist in a state of superposition - effectively \nbeing 0, 1, or a combination of both simultaneously. Furthermore, qubits can become entangled, \nmeaning their fates are intertwined regardless of distance, allowing for complex correlations. This parallelism and \ninterconnectedness grant quantum computers the potential to solve specific types of incredibly complex problems - such \nas drug discovery, materials science, complex system optimization, and breaking certain types of cryptography - far \nfaster than even the most powerful classical supercomputers could ever achieve, although the technology is still largely in its developmental stages.\"\"\"\n\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(long_text)"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/agenttool\"\n    \"google.golang.org/genai\"\n)\n\n// createSummarizerAgent creates an agent whose sole purpose is to summarize text.\nfunc createSummarizerAgent(ctx context.Context) (agent.Agent, error) {\n    model, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{})\n    if err != nil {\n        return nil, err\n    }\n    return llmagent.New(llmagent.Config{\n        Name:        \"SummarizerAgent\",\n        Model:       model,\n        Instruction: \"You are an expert at summarizing text. Take the user's input and provide a concise summary.\",\n        Description: \"An agent that summarizes text.\",\n    })\n}\n\n// createMainAgent creates the primary agent that will use the summarizer agent as a tool.\nfunc createMainAgent(ctx context.Context, tools ...tool.Tool) (agent.Agent, error) {\n    model, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{})\n    if err != nil {\n        return nil, err\n    }\n    return llmagent.New(llmagent.Config{\n        Name:  \"MainAgent\",\n        Model: model,\n        Instruction: \"You are a helpful assistant. If you are asked to summarize a long text, use the 'summarize' tool. \" +\n            \"After getting the summary, present it to the user by saying 'Here is a summary of the text:'.\",\n        Description: \"The main agent that can delegate tasks.\",\n        Tools:       tools,\n    })\n}\n\nfunc RunAgentAsToolSimulation() {\n    ctx := context.Background()\n\n    // 1. Create the Tool Agent (Summarizer)\n    summarizerAgent, err := createSummarizerAgent(ctx)\n    if err != nil {\n        log.Fatalf(\"Failed to create summarizer agent: %v\", err)\n    }\n\n    // 2. Wrap the Tool Agent in an AgentTool\n    summarizeTool := agenttool.New(summarizerAgent, &agenttool.Config{\n        SkipSummarization: true,\n    })\n\n    // 3. Create the Main Agent and provide it with the AgentTool\n    mainAgent, err := createMainAgent(ctx, summarizeTool)\n    if err != nil {\n        log.Fatalf(\"Failed to create main agent: %v\", err)\n    }\n\n    // 4. Run the main agent\n    prompt := `\n        Please summarize this text for me:\n        Quantum computing represents a fundamentally different approach to computation,\n        leveraging the bizarre principles of quantum mechanics to process information. Unlike classical computers\n        that rely on bits representing either 0 or 1, quantum computers use qubits which can exist in a state of superposition - effectively\n        being 0, 1, or a combination of both simultaneously. Furthermore, qubits can become entangled,\n        meaning their fates are intertwined regardless of distance, allowing for complex correlations. This parallelism and\n        interconnectedness grant quantum computers the potential to solve specific types of incredibly complex problems - such\n        as drug discovery, materials science, complex system optimization, and breaking certain types of cryptography - far\n        faster than even the most powerful classical supercomputers could ever achieve, although the technology is still largely in its developmental stages.\n    `\n    fmt.Printf(\"\\nPrompt: %s\\nResponse: \", prompt)\n    callAgent(context.Background(), mainAgent, prompt)\n    fmt.Println(\"\\n---\")\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.AgentTool;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\n\npublic class AgentToolCustomization {\n\n  private static final String APP_NAME = \"summary_agent\";\n  private static final String USER_ID = \"user1234\";\n\n  public static void initAgentAndRun(String prompt) {\n\n    LlmAgent summaryAgent =\n        LlmAgent.builder()\n            .model(\"gemini-2.0-flash\")\n            .name(\"summaryAgent\")\n            .instruction(\n                \"You are an expert summarizer. Please read the following text and provide a concise summary.\")\n            .description(\"Agent to summarize text\")\n            .build();\n\n    // Define root_agent\n    LlmAgent rootAgent =\n        LlmAgent.builder()\n            .model(\"gemini-2.0-flash\")\n            .name(\"rootAgent\")\n            .instruction(\n                \"You are a helpful assistant. When the user provides a text, always use the 'summaryAgent' tool to generate a summary. Always forward the user's message exactly as received to the 'summaryAgent' tool, without modifying or summarizing it yourself. Present the response from the tool to the user.\")\n            .description(\"Assistant agent\")\n            .tools(AgentTool.create(summaryAgent, true)) // Set skipSummarization to true\n            .build();\n\n    // Create an InMemoryRunner\n    InMemoryRunner runner = new InMemoryRunner(rootAgent, APP_NAME);\n    // InMemoryRunner automatically creates a session service. Create a session using the service\n    Session session = runner.sessionService().createSession(APP_NAME, USER_ID).blockingGet();\n    Content userMessage = Content.fromParts(Part.fromText(prompt));\n\n    // Run the agent\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n    // Stream event response\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n\n  public static void main(String[] args) {\n    String longText =\n        \"\"\"\n            Quantum computing represents a fundamentally different approach to computation,\n            leveraging the bizarre principles of quantum mechanics to process information. Unlike classical computers\n            that rely on bits representing either 0 or 1, quantum computers use qubits which can exist in a state of superposition - effectively\n            being 0, 1, or a combination of both simultaneously. Furthermore, qubits can become entangled,\n            meaning their fates are intertwined regardless of distance, allowing for complex correlations. This parallelism and\n            interconnectedness grant quantum computers the potential to solve specific types of incredibly complex problems - such\n            as drug discovery, materials science, complex system optimization, and breaking certain types of cryptography - far\n            faster than even the most powerful classical supercomputers could ever achieve, although the technology is still largely in its developmental stages.\"\"\";\n\n    initAgentAndRun(longText);\n  }\n}"}]}, {"heading_path": ["How it works\u00b6"], "text": "How it works \u00b6 When the main_agent receives the long text, its instruction tells it to use the 'summarize' tool for long texts. The framework recognizes 'summarize' as an AgentTool that wraps the summary_agent . Behind the scenes, the main_agent will call the summary_agent with the long text as input. The summary_agent will process the text according to its instruction and generate a summary. The response from the summary_agent is then passed back to the main_agent . The main_agent can then take the summary and formulate its final response to the user (e.g., \"Here's a summary of the text: ...\") Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:19.880496", "source_type": "adk-docs"}
{"doc_id": "fe376a63003e1058891e9d95b3ab4cdc9560c5e623e6725ffc353049e672d3d2", "url": "https://google.github.io/adk-docs/tools-custom/performance", "title": "Tool performance - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Increase tool performance with parallel execution\u00b6"], "text": "Increase tool performance with parallel execution \u00b6 Supported in ADK Python v1.10.0 Starting with Agent Development Kit (ADK) version 1.10.0 for Python, the framework\nattempts to run any agent-requested function tools in parallel. This behavior can significantly improve the performance and\nresponsiveness of your agents, particularly for agents that rely on multiple\nexternal APIs or long-running tasks. For example, if you have 3 tools that each\ntake 2 seconds, by running them in parallel, the total execution time will be\ncloser to 2 seconds, instead of 6 seconds. The ability to run tool functions\nparallel can improve the performance of your agents, particularly in the\nfollowing scenarios: Research tasks: Where the agent collects information from multiple\n    sources before proceeding to the next stage of the workflow. API calls: Where the agent accesses several APIs independently, such\n    as searching for available flights using APIs from multiple airlines. Publishing and communication tasks: When the agent needs to publish\n    or communicate through multiple, independent channels or multiple recipients. However, your custom tools must be built with asynchronous execution support to\nenable this performance improvement. This guide explains how parallel tool\nexecution works in the ADK and how to build your tools to take full advantage of\nthis processing feature. Warning Any ADK Tools that use synchronous processing in a set of tool function\ncalls will block other tools from executing in parallel, even if the other\ntools allow for parallel execution. ", "code_blocks": []}, {"heading_path": ["Build parallel-ready tools\u00b6"], "text": "Build parallel-ready tools \u00b6 Enable parallel execution of your tool functions by defining them as\nasynchronous functions. In Python code, this means using async def and await syntax which allows the ADK to run them concurrently in an asyncio event loop.\nThe following sections show examples of agent tools built for parallel\nprocessing and asynchronous operations. ", "code_blocks": []}, {"heading_path": ["Example of http web call\u00b6"], "text": "Example of http web call \u00b6 The following code example show how to modify the get_weather() function to\noperate asynchronously and allow for parallel execution: async def get_weather ( city : str ) -> dict : async with aiohttp . ClientSession () as session : async with session . get ( f \"http://api.weather.com/ { city } \" ) as response : return await response . json () ", "code_blocks": [{"language": "text", "code": "async def get_weather(city: str) -> dict:\n      async with aiohttp.ClientSession() as session:\n          async with session.get(f\"http://api.weather.com/{city}\") as response:\n              return await response.json()"}]}, {"heading_path": ["Example of database call\u00b6"], "text": "Example of database call \u00b6 The following code example show how to write a database calling function to\noperate asynchronously: async def query_database ( query : str ) -> list : async with asyncpg . connect ( \"postgresql://...\" ) as conn : return await conn . fetch ( query ) ", "code_blocks": [{"language": "text", "code": "async def query_database(query: str) -> list:\n      async with asyncpg.connect(\"postgresql://...\") as conn:\n          return await conn.fetch(query)"}]}, {"heading_path": ["Example of yielding behavior for long loops\u00b6"], "text": "Example of yielding behavior for long loops \u00b6 In cases where a tool is processing multiple requests or numerous long running\nrequests, consider adding yielding code to allow other tools to execute, as\nshown in the following code sample: async def process_data ( data : list ) -> dict : results = [] for i , item in enumerate ( data ): processed = await process_item ( item ) # Yield point results . append ( processed ) # Add periodic yield points for long loops if i % 100 == 0 : await asyncio . sleep ( 0 ) # Yield control return { \"results\" : results } Important Use the asyncio.sleep() function for pauses to avoid blocking\nexecution of other functions. ", "code_blocks": [{"language": "text", "code": "async def process_data(data: list) -> dict:\n      results = []\n      for i, item in enumerate(data):\n          processed = await process_item(item)  # Yield point\n          results.append(processed)\n\n          # Add periodic yield points for long loops\n          if i % 100 == 0:\n              await asyncio.sleep(0)  # Yield control\n      return {\"results\": results}"}]}, {"heading_path": ["Example of thread pools for intensive operations\u00b6"], "text": "Example of thread pools for intensive operations \u00b6 When performing processing-intensive functions, consider creating thread pools\nfor better management of available computing resources, as shown in the\nfollowing example: async def cpu_intensive_tool ( data : list ) -> dict : loop = asyncio . get_event_loop () # Use thread pool for CPU-bound work with ThreadPoolExecutor () as executor : result = await loop . run_in_executor ( executor , expensive_computation , data ) return { \"result\" : result } ", "code_blocks": [{"language": "text", "code": "async def cpu_intensive_tool(data: list) -> dict:\n      loop = asyncio.get_event_loop()\n\n      # Use thread pool for CPU-bound work\n      with ThreadPoolExecutor() as executor:\n          result = await loop.run_in_executor(\n              executor,\n              expensive_computation,\n              data\n          )\n      return {\"result\": result}"}]}, {"heading_path": ["Example of process chunking\u00b6"], "text": "Example of process chunking \u00b6 When performing processes on long lists or large amounts of data, consider\ncombining a thread pool technique with dividing up processing into chunks of\ndata, and yielding processing time between the chunks, as shown in the following\nexample: async def process_large_dataset ( dataset : list ) -> dict : results = [] chunk_size = 1000 for i in range ( 0 , len ( dataset ), chunk_size ): chunk = dataset [ i : i + chunk_size ] # Process chunk in thread pool loop = asyncio . get_event_loop () with ThreadPoolExecutor () as executor : chunk_result = await loop . run_in_executor ( executor , process_chunk , chunk ) results . extend ( chunk_result ) # Yield control between chunks await asyncio . sleep ( 0 ) return { \"total_processed\" : len ( results ), \"results\" : results } ", "code_blocks": [{"language": "text", "code": "async def process_large_dataset(dataset: list) -> dict:\n      results = []\n      chunk_size = 1000\n\n      for i in range(0, len(dataset), chunk_size):\n          chunk = dataset[i:i + chunk_size]\n\n          # Process chunk in thread pool\n          loop = asyncio.get_event_loop()\n          with ThreadPoolExecutor() as executor:\n              chunk_result = await loop.run_in_executor(\n                  executor, process_chunk, chunk\n              )\n\n          results.extend(chunk_result)\n\n          # Yield control between chunks\n          await asyncio.sleep(0)\n\n      return {\"total_processed\": len(results), \"results\": results}"}]}, {"heading_path": ["Write parallel-ready prompts and tool descriptions\u00b6"], "text": "Write parallel-ready prompts and tool descriptions \u00b6 When building prompts for AI models, consider explicitly specifying or hinting\nthat function calls be made in parallel. The following example of an AI prompt\ndirects the model to use tools in parallel: When users ask for multiple pieces of information, always call functions in parallel. Examples: - \"Get weather for London and currency rate USD to EUR\" \u2192 Call both functions simultaneously - \"Compare cities A and B\" \u2192 Call get_weather, get_population, get_distance in parallel - \"Analyze multiple stocks\" \u2192 Call get_stock_price for each stock in parallel Always prefer multiple specific function calls over single complex calls. The following example shows a tool function description that hints at more\nefficient use through parallel execution: async def get_weather ( city : str ) -> dict : \"\"\"Get current weather for a single city. This function is optimized for parallel execution - call multiple times for different cities. Args: city: Name of the city, for example: 'London', 'New York' Returns: Weather data including temperature, conditions, humidity \"\"\" await asyncio . sleep ( 2 ) # Simulate API call return { \"city\" : city , \"temp\" : 72 , \"condition\" : \"sunny\" } ", "code_blocks": [{"language": "text", "code": "When users ask for multiple pieces of information, always call functions in\nparallel.\n\n  Examples:\n  - \"Get weather for London and currency rate USD to EUR\" \u2192 Call both functions\n    simultaneously\n  - \"Compare cities A and B\" \u2192 Call get_weather, get_population, get_distance in \n    parallel\n  - \"Analyze multiple stocks\" \u2192 Call get_stock_price for each stock in parallel\n\n  Always prefer multiple specific function calls over single complex calls."}, {"language": "text", "code": "async def get_weather(city: str) -> dict:\n      \"\"\"Get current weather for a single city.\n\n      This function is optimized for parallel execution - call multiple times for different cities.\n\n      Args:\n          city: Name of the city, for example: 'London', 'New York'\n\n      Returns:\n          Weather data including temperature, conditions, humidity\n      \"\"\"\n      await asyncio.sleep(2)  # Simulate API call\n      return {\"city\": city, \"temp\": 72, \"condition\": \"sunny\"}"}]}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 For more information on building Tools for agents and function calling, see Function Tools . For\nmore detailed examples of tools that take advantage of parallel processing, see\nthe samples in the adk-python repository. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:20.032401", "source_type": "adk-docs"}
{"doc_id": "5719ea4789b25b875461ec284f9493d4654e19b06758ba3cab8dbb52d0658376", "url": "https://google.github.io/adk-docs/tools-custom/confirmation", "title": "Action confirmations - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Get action confirmation for ADK Tools\u00b6"], "text": "Get action confirmation for ADK Tools \u00b6 Supported in ADK Python v1.14.0 Experimental Some agent workflows require confirmation for decision making, verification,\nsecurity, or general oversight. In these cases, you want to get a response from\na human or supervising system before proceeding with a workflow. The Tool\nConfirmation feature in the Agent Development Kit (ADK) allows an ADK Tool to\npause its execution and interact with a user or other system for confirmation or\nto gather structured data before proceeding. You can use Tool Confirmation with\nan ADK Tool in the following ways: Boolean Confirmation : You can\n    configure a FunctionTool with a require_confirmation parameter. This\n    option pauses the tool for a yes or no confirmation response. Advanced Confirmation : For scenarios requiring\n    structured data responses, you can configure a FunctionTool with a text\n    prompt to explain the confirmation and an expected response. Experimental The Tool Confirmation feature is experimental and has some known limitations .\nWe welcome your feedback ! You can configure how a request is communicated to a user, and the system can\nalso use remote responses sent via the ADK\nserver's REST API. When using the confirmation feature with the ADK web user\ninterface, the agent workflow displays a dialog box to the user to request\ninput, as shown in Figure 1: Figure 1. Example confirmation response request dialog box using an\nadvanced, tool response implementation. The following sections describe how to use this feature for the confirmation\nscenarios. For a complete code sample, see the human_tool_confirmation example. There are additional ways to incorporate human input into your agent\nworkflow, for more details, see the Human-in-the-loop agent pattern. ", "code_blocks": []}, {"heading_path": ["Boolean confirmation\u00b6"], "text": "Boolean confirmation \u00b6 When your tool only requires a simple yes or no from the user, you can\nappend a confirmation step using the FunctionTool class as a wrapper. For\nexample, if you have a tool called reimburse , you can enable a confirmation\nstep by wrapping it with the FunctionTool class and setting the require_confirmation parameter to True , as shown in the following example: # From agent.py root_agent = Agent( ... tools=[ # Set require_confirmation to True to require user confirmation # for the tool call. FunctionTool(reimburse, require_confirmation=True), ], ... This implementation method requires minimal code, but is limited to simple\napprovals from the user or confirming system. For a complete example of this\napproach, see the human_tool_confirmation code sample. ", "code_blocks": [{"language": "text", "code": "# From agent.py\nroot_agent = Agent(\n   ...\n   tools=[\n        # Set require_confirmation to True to require user confirmation\n        # for the tool call.\n        FunctionTool(reimburse, require_confirmation=True),\n    ],\n..."}]}, {"heading_path": ["Require confirmation function\u00b6"], "text": "Require confirmation function \u00b6 You can modify the behavior require_confirmation response by replacing its\ninput value with a function that returns a boolean response. The following\nexample shows a function for determining if a confirmation is required: async def confirmation_threshold( amount: int, tool_context: ToolContext ) -> bool: \"\"\"Returns true if the amount is greater than 1000.\"\"\" return amount > 1000 This function than then be set as the parameter value for the require_confirmation parameter: root_agent = Agent( ... tools=[ # Set require_confirmation to True to require user confirmation FunctionTool(reimburse, require_confirmation=confirmation_threshold), ], ... For a complete example of this implementation, see the human_tool_confirmation code sample. ", "code_blocks": [{"language": "text", "code": "async def confirmation_threshold(\n    amount: int, tool_context: ToolContext\n) -> bool:\n  \"\"\"Returns true if the amount is greater than 1000.\"\"\"\n  return amount > 1000"}, {"language": "text", "code": "root_agent = Agent(\n   ...\n   tools=[\n        # Set require_confirmation to True to require user confirmation\n        FunctionTool(reimburse, require_confirmation=confirmation_threshold),\n    ],\n..."}]}, {"heading_path": ["Advanced confirmation\u00b6"], "text": "Advanced confirmation \u00b6 When a tool confirmation requires more details for the user or a more complex\nresponse, use a tool_confirmation implementation. This approach extends the ToolContext object to add a text description of the request for the user and\nallows for more complex response data. When implementing tool confirmation this\nway, you can pause a tool's execution, request specific information, and then\nresume the tool with the provided data. This confirmation flow has a request stage where the system assembles and sends\nan input request human response, and a response stage where the system receives\nand processes the returned data. ", "code_blocks": []}, {"heading_path": ["Confirmation definition\u00b6"], "text": "Confirmation definition \u00b6 When creating a Tool with an advanced confirmation, create a function that\nincludes a ToolContext object. Then define the confirmation using a\ntool_confirmation object, the tool_context.request_confirmation() method with hint and payload parameters. These properties are used as follows: hint : Descriptive message that explains what is needed from the user. payload : The structure of the data you expect in return. This data\n    type is Any and must be serializable into a JSON-formatted string, such as\n    a dictionary or pydantic model. The following code shows an example implementation for a tool that processes\ntime off requests for an employee: def request_time_off(days: int, tool_context: ToolContext): \"\"\"Request day off for the employee.\"\"\" ... tool_confirmation = tool_context.tool_confirmation if not tool_confirmation: tool_context.request_confirmation( hint=( 'Please approve or reject the tool call request_time_off() by' ' responding with a FunctionResponse with an expected' ' ToolConfirmation payload.' ), payload={ 'approved_days': 0, }, ) # Return intermediate status indicating that the tool is waiting for # a confirmation response: return {'status': 'Manager approval is required.'} approved_days = tool_confirmation.payload['approved_days'] approved_days = min(approved_days, days) if approved_days == 0: return {'status': 'The time off request is rejected.', 'approved_days': 0} return { 'status': 'ok', 'approved_days': approved_days, } For a complete example of this approach, see the human_tool_confirmation code sample. Keep in mind that the agent workflow tool execution pauses while a\nconfirmation is obtained. After confirmation is received, you can access the\nconfirmation response in the tool_confirmation.payload object and then proceed\nwith the execution of the workflow. ", "code_blocks": [{"language": "text", "code": "def request_time_off(days: int, tool_context: ToolContext):\n  \"\"\"Request day off for the employee.\"\"\"\n  ...\n  tool_confirmation = tool_context.tool_confirmation\n  if not tool_confirmation:\n    tool_context.request_confirmation(\n        hint=(\n            'Please approve or reject the tool call request_time_off() by'\n            ' responding with a FunctionResponse with an expected'\n            ' ToolConfirmation payload.'\n        ),\n        payload={\n            'approved_days': 0,\n        },\n    )\n    # Return intermediate status indicating that the tool is waiting for\n    # a confirmation response:\n    return {'status': 'Manager approval is required.'}\n\n  approved_days = tool_confirmation.payload['approved_days']\n  approved_days = min(approved_days, days)\n  if approved_days == 0:\n    return {'status': 'The time off request is rejected.', 'approved_days': 0}\n  return {\n      'status': 'ok',\n      'approved_days': approved_days,\n  }"}]}, {"heading_path": ["Remote confirmation with REST API\u00b6"], "text": "Remote confirmation with REST API \u00b6 If there is no active user interface for a human confirmation of an agent\nworkflow, you can handle the confirmation through a command-line interface or by\nrouting it through another channel like email or a chat application. To confirm\nthe tool call, the user or calling application needs to send a FunctionResponse event with the tool confirmation data. You can send the request to the ADK API server's /run or /run_sse endpoint,\nor directly to the ADK runner. The following example uses a curl command to\nsend the confirmation to the /run_sse endpoint: curl -X POST http://localhost:8000/run_sse \\ -H \"Content-Type: application/json\" \\ -d '{ \"app_name\": \"human_tool_confirmation\", \"user_id\": \"user\", \"session_id\": \"7828f575-2402-489f-8079-74ea95b6a300\", \"new_message\": { \"parts\": [ { \"function_response\": { \"id\": \"adk-13b84a8c-c95c-4d66-b006-d72b30447e35\", \"name\": \"adk_request_confirmation\", \"response\": { \"confirmed\": true } } } ], \"role\": \"user\" } }' A REST-based response for a confirmation must meet the following\nrequirements: The id in the function_response should match the function_call_id from the RequestConfirmation FunctionCall event. The name should be adk_request_confirmation . The response object contains the confirmation status and any\n    additional payload data required by the tool. Note: Confirmation with Resume feature If your ADK agent workflow is configured with the Resume feature, you also must include\nthe Invocation ID ( invocation_id ) parameter with the confirmation\nresponse. The Invocation ID you provide must be the same invocation\nthat generated the confirmation request, otherwise the system\nstarts a new invocation with the confirmation response. If your\nagent uses the Resume feature, consider including the Invocation ID\nas a parameter with your confirmation request, so it can be\nincluded with the response. For more details on using the Resume\nfeature, see Resume stopped agents . ", "code_blocks": [{"language": "text", "code": "curl -X POST http://localhost:8000/run_sse \\\n -H \"Content-Type: application/json\" \\\n -d '{\n    \"app_name\": \"human_tool_confirmation\",\n    \"user_id\": \"user\",\n    \"session_id\": \"7828f575-2402-489f-8079-74ea95b6a300\",\n    \"new_message\": {\n        \"parts\": [\n            {\n                \"function_response\": {\n                    \"id\": \"adk-13b84a8c-c95c-4d66-b006-d72b30447e35\",\n                    \"name\": \"adk_request_confirmation\",\n                    \"response\": {\n                        \"confirmed\": true\n                    }\n                }\n            }\n        ],\n        \"role\": \"user\"\n    }\n}'"}]}, {"heading_path": ["Known limitations\u00b6"], "text": "Known limitations \u00b6 The tool confirmation feature has the following limitations: DatabaseSessionService is not supported by this feature. VertexAiSessionService is not supported by this feature. ", "code_blocks": []}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 For more information on building ADK tools for agent workflows, see Function\ntools . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:20.698115", "source_type": "adk-docs"}
{"doc_id": "b23ccd925d3b1d93ca2303f873bde2a313563ddaa4eda254824cfd70fc653b80", "url": "https://google.github.io/adk-docs/tools-custom/mcp-tools", "title": "MCP tools - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Model Context Protocol Tools\u00b6"], "text": "Model Context Protocol Tools \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 This guide walks you through two ways of integrating Model Context Protocol (MCP) with ADK. ", "code_blocks": []}, {"heading_path": ["What is Model Context Protocol (MCP)?\u00b6"], "text": "What is Model Context Protocol (MCP)? \u00b6 The Model Context Protocol (MCP) is an open standard designed to standardize how Large Language Models (LLMs) like Gemini and Claude communicate with external applications, data sources, and tools. Think of it as a universal connection mechanism that simplifies how LLMs obtain context, execute actions, and interact with various systems. MCP follows a client-server architecture, defining how data (resources), interactive templates (prompts), and actionable functions (tools) are exposed by an MCP server and consumed by an MCP client (which could be an LLM host application or an AI agent). This guide covers two primary integration patterns: Using Existing MCP Servers within ADK: An ADK agent acts as an MCP client, leveraging tools provided by external MCP servers. Exposing ADK Tools via an MCP Server: Building an MCP server that wraps ADK tools, making them accessible to any MCP client. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Before you begin, ensure you have the following set up: Set up ADK: Follow the standard ADK setup instructions in the quickstart. Install/update Python/Java: MCP requires Python version of 3.9 or higher for Python or Java 17 or higher. Setup Node.js and npx: (Python only) Many community MCP servers are distributed as Node.js packages and run using npx . Install Node.js (which includes npx) if you haven't already. For details, see https://nodejs.org/en . Verify Installations: (Python only) Confirm adk and npx are in your PATH within the activated virtual environment: # Both commands should print the path to the executables. which adk which npx ", "code_blocks": [{"language": "text", "code": "# Both commands should print the path to the executables.\nwhich adk\nwhich npx"}]}, {"heading_path": ["1. Using MCP servers with ADK agents (ADK as an MCP client) in adk web\u00b6"], "text": "1. Using MCP servers with ADK agents (ADK as an MCP client) in adk web \u00b6 This section demonstrates how to integrate tools from external MCP (Model Context Protocol) servers into your ADK agents. This is the most common integration pattern when your ADK agent needs to use capabilities provided by an existing service that exposes an MCP interface. You will see how the MCPToolset class can be directly added to your agent's tools list, enabling seamless connection to an MCP server, discovery of its tools, and making them available for your agent to use. These examples primarily focus on interactions within the adk web development environment. ", "code_blocks": []}, {"heading_path": ["MCPToolset class\u00b6"], "text": "MCPToolset class \u00b6 The MCPToolset class is ADK's primary mechanism for integrating tools from an MCP server. When you include an MCPToolset instance in your agent's tools list, it automatically handles the interaction with the specified MCP server. Here's how it works: Connection Management: On initialization, MCPToolset establishes and manages the connection to the MCP server. This can be a local server process (using StdioConnectionParams for communication over standard input/output) or a remote server (using SseConnectionParams for Server-Sent Events). The toolset also handles the graceful shutdown of this connection when the agent or application terminates. Tool Discovery & Adaptation: Once connected, MCPToolset queries the MCP server for its available tools (via the list_tools MCP method). It then converts the schemas of these discovered MCP tools into ADK-compatible BaseTool instances. Exposure to Agent: These adapted tools are then made available to your LlmAgent as if they were native ADK tools. Proxying Tool Calls: When your LlmAgent decides to use one of these tools, MCPToolset transparently proxies the call (using the call_tool MCP method) to the MCP server, sends the necessary arguments, and returns the server's response back to the agent. Filtering (Optional): You can use the tool_filter parameter when creating an MCPToolset to select a specific subset of tools from the MCP server, rather than exposing all of them to your agent. The following examples demonstrate how to use MCPToolset within the adk web development environment. For scenarios where you need more fine-grained control over the MCP connection lifecycle or are not using adk web , refer to the \"Using MCP Tools in your own Agent out of adk web \" section later in this page. ", "code_blocks": []}, {"heading_path": ["Example 1: File System MCP Server\u00b6"], "text": "Example 1: File System MCP Server \u00b6 This Python example demonstrates connecting to a local MCP server that provides file system operations. ", "code_blocks": []}, {"heading_path": ["Step 1: Define your Agent with MCPToolset\u00b6"], "text": "Step 1: Define your Agent with MCPToolset \u00b6 Create an agent.py file (e.g., in ./adk_agent_samples/mcp_agent/agent.py ). The MCPToolset is instantiated directly within the tools list of your LlmAgent . Important: Replace \"/path/to/your/folder\" in the args list with the absolute path to an actual folder on your local system that the MCP server can access. Important: Place the .env file in the parent directory of the ./adk_agent_samples directory. # ./adk_agent_samples/mcp_agent/agent.py import os # Required for path operations from google.adk.agents import LlmAgent from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from mcp import StdioServerParameters # It's good practice to define paths dynamically if possible, # or ensure the user understands the need for an ABSOLUTE path. # For this example, we'll construct a path relative to this file, # assuming '/path/to/your/folder' is in the same directory as agent.py. # REPLACE THIS with an actual absolute path if needed for your setup. TARGET_FOLDER_PATH = os . path . join ( os . path . dirname ( os . path . abspath ( __file__ )), \"/path/to/your/folder\" ) # Ensure TARGET_FOLDER_PATH is an absolute path for the MCP server. # If you created ./adk_agent_samples/mcp_agent/your_folder, root_agent = LlmAgent ( model = 'gemini-2.0-flash' , name = 'filesystem_assistant_agent' , instruction = 'Help the user manage their files. You can list files, read files, etc.' , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = 'npx' , args = [ \"-y\" , # Argument for npx to auto-confirm install \"@modelcontextprotocol/server-filesystem\" , # IMPORTANT: This MUST be an ABSOLUTE path to a folder the # npx process can access. # Replace with a valid absolute path on your system. # For example: \"/Users/youruser/accessible_mcp_files\" # or use a dynamically constructed absolute path: os . path . abspath ( TARGET_FOLDER_PATH ), ], ), ), # Optional: Filter which tools from the MCP server are exposed # tool_filter=['list_directory', 'read_file'] ) ], ) ", "code_blocks": [{"language": "text", "code": "# ./adk_agent_samples/mcp_agent/agent.py\nimport os # Required for path operations\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom mcp import StdioServerParameters\n\n# It's good practice to define paths dynamically if possible,\n# or ensure the user understands the need for an ABSOLUTE path.\n# For this example, we'll construct a path relative to this file,\n# assuming '/path/to/your/folder' is in the same directory as agent.py.\n# REPLACE THIS with an actual absolute path if needed for your setup.\nTARGET_FOLDER_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"/path/to/your/folder\")\n# Ensure TARGET_FOLDER_PATH is an absolute path for the MCP server.\n# If you created ./adk_agent_samples/mcp_agent/your_folder,\n\nroot_agent = LlmAgent(\n    model='gemini-2.0-flash',\n    name='filesystem_assistant_agent',\n    instruction='Help the user manage their files. You can list files, read files, etc.',\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command='npx',\n                    args=[\n                        \"-y\",  # Argument for npx to auto-confirm install\n                        \"@modelcontextprotocol/server-filesystem\",\n                        # IMPORTANT: This MUST be an ABSOLUTE path to a folder the\n                        # npx process can access.\n                        # Replace with a valid absolute path on your system.\n                        # For example: \"/Users/youruser/accessible_mcp_files\"\n                        # or use a dynamically constructed absolute path:\n                        os.path.abspath(TARGET_FOLDER_PATH),\n                    ],\n                ),\n            ),\n            # Optional: Filter which tools from the MCP server are exposed\n            # tool_filter=['list_directory', 'read_file']\n        )\n    ],\n)"}]}, {"heading_path": ["Step 2: Create an __init__.py file\u00b6"], "text": "Step 2: Create an __init__.py file \u00b6 Ensure you have an __init__.py in the same directory as agent.py to make it a discoverable Python package for ADK. # ./adk_agent_samples/mcp_agent/__init__.py from . import agent ", "code_blocks": [{"language": "text", "code": "# ./adk_agent_samples/mcp_agent/__init__.py\nfrom . import agent"}]}, {"heading_path": ["Step 3: Run adk web and Interact\u00b6"], "text": "Step 3: Run adk web and Interact \u00b6 Navigate to the parent directory of mcp_agent (e.g., adk_agent_samples ) in your terminal and run: cd ./adk_agent_samples # Or your equivalent parent directory adk web Note for Windows users When hitting the _make_subprocess_transport NotImplementedError , consider using adk web --no-reload instead. Once the ADK Web UI loads in your browser: Select the filesystem_assistant_agent from the agent dropdown. Try prompts like: \"List files in the current directory.\" \"Can you read the file named sample.txt?\" (assuming you created it in TARGET_FOLDER_PATH ). \"What is the content of another_file.md ?\" You should see the agent interacting with the MCP file system server, and the server's responses (file listings, file content) relayed through the agent. The adk web console (terminal where you ran the command) might also show logs from the npx process if it outputs to stderr. For Java, refer to the following sample to define an agent that initializes the MCPToolset : package agents ; import com.google.adk.JsonBaseModel ; import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.RunConfig ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.tools.mcp.McpTool ; import com.google.adk.tools.mcp.McpToolset ; import com.google.adk.tools.mcp.McpToolset.McpToolsAndToolsetResult ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.modelcontextprotocol.client.transport.ServerParameters ; import java.util.List ; import java.util.concurrent.CompletableFuture ; public class McpAgentCreator { /** * Initializes an McpToolset, retrieves tools from an MCP server using stdio, * creates an LlmAgent with these tools, sends a prompt to the agent, * and ensures the toolset is closed. * @param args Command line arguments (not used). */ public static void main ( String [] args ) { //Note: you may have permissions issues if the folder is outside home String yourFolderPath = \"~/path/to/folder\" ; ServerParameters connectionParams = ServerParameters . builder ( \"npx\" ) . args ( List . of ( \"-y\" , \"@modelcontextprotocol/server-filesystem\" , yourFolderPath )) . build (); try { CompletableFuture < McpToolsAndToolsetResult > futureResult = McpToolset . fromServer ( connectionParams , JsonBaseModel . getMapper ()); McpToolsAndToolsetResult result = futureResult . join (); try ( McpToolset toolset = result . getToolset ()) { List < McpTool > tools = result . getTools (); LlmAgent agent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"enterprise_assistant\" ) . description ( \"An agent to help users access their file systems\" ) . instruction ( \"Help user accessing their file systems. You can list files in a directory.\" ) . tools ( tools ) . build (); System . out . println ( \"Agent created: \" + agent . name ()); InMemoryRunner runner = new InMemoryRunner ( agent ); String userId = \"user123\" ; String sessionId = \"1234\" ; String promptText = \"Which files are in this directory - \" + yourFolderPath + \"?\" ; // Explicitly create the session first try { // appName for InMemoryRunner defaults to agent.name() if not specified in constructor runner . sessionService (). createSession ( runner . appName (), userId , null , sessionId ). blockingGet (); System . out . println ( \"Session created: \" + sessionId + \" for user: \" + userId ); } catch ( Exception sessionCreationException ) { System . err . println ( \"Failed to create session: \" + sessionCreationException . getMessage ()); sessionCreationException . printStackTrace (); return ; } Content promptContent = Content . fromParts ( Part . fromText ( promptText )); System . out . println ( \"\\nSending prompt: \\\"\" + promptText + \"\\\" to agent...\\n\" ); runner . runAsync ( userId , sessionId , promptContent , RunConfig . builder (). build ()) . blockingForEach ( event -> { System . out . println ( \"Event received: \" + event . toJson ()); }); } } catch ( Exception e ) { System . err . println ( \"An error occurred: \" + e . getMessage ()); e . printStackTrace (); } } } Assuming a folder containing three files named first , second and third , successful response will look like this: Event received: { \"id\" : \"163a449e-691a-48a2-9e38-8cadb6d1f136\" , \"invocationId\" : \"e-c2458c56-e57a-45b2-97de-ae7292e505ef\" , \"author\" : \"enterprise_assistant\" , \"content\" : { \"parts\" : [{ \"functionCall\" : { \"id\" : \"adk-388b4ac2-d40e-4f6a-bda6-f051110c6498\" , \"args\" : { \"path\" : \"~/home-test\" } , \"name\" : \"list_directory\" }}] , \"role\" : \"model\" } , \"actions\" : { \"stateDelta\" : {} , \"artifactDelta\" : {} , \"requestedAuthConfigs\" : {}} , \"timestamp\" :1747377543788 } Event received: { \"id\" : \"8728380b-bfad-4d14-8421-fa98d09364f1\" , \"invocationId\" : \"e-c2458c56-e57a-45b2-97de-ae7292e505ef\" , \"author\" : \"enterprise_assistant\" , \"content\" : { \"parts\" : [{ \"functionResponse\" : { \"id\" : \"adk-388b4ac2-d40e-4f6a-bda6-f051110c6498\" , \"name\" : \"list_directory\" , \"response\" : { \"text_output\" : [{ \"text\" : \"[FILE] first\\n[FILE] second\\n[FILE] third\" }]}}}] , \"role\" : \"user\" } , \"actions\" : { \"stateDelta\" : {} , \"artifactDelta\" : {} , \"requestedAuthConfigs\" : {}} , \"timestamp\" :1747377544679 } Event received: { \"id\" : \"8fe7e594-3e47-4254-8b57-9106ad8463cb\" , \"invocationId\" : \"e-c2458c56-e57a-45b2-97de-ae7292e505ef\" , \"author\" : \"enterprise_assistant\" , \"content\" : { \"parts\" : [{ \"text\" : \"There are three files in the directory: first, second, and third.\" }] , \"role\" : \"model\" } , \"actions\" : { \"stateDelta\" : {} , \"artifactDelta\" : {} , \"requestedAuthConfigs\" : {}} , \"timestamp\" :1747377544689 } ", "code_blocks": [{"language": "text", "code": "cd ./adk_agent_samples # Or your equivalent parent directory\nadk web"}, {"language": "text", "code": "package agents;\n\nimport com.google.adk.JsonBaseModel;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.RunConfig;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.tools.mcp.McpTool;\nimport com.google.adk.tools.mcp.McpToolset;\nimport com.google.adk.tools.mcp.McpToolset.McpToolsAndToolsetResult;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.modelcontextprotocol.client.transport.ServerParameters;\n\nimport java.util.List;\nimport java.util.concurrent.CompletableFuture;\n\npublic class McpAgentCreator {\n\n    /**\n     * Initializes an McpToolset, retrieves tools from an MCP server using stdio,\n     * creates an LlmAgent with these tools, sends a prompt to the agent,\n     * and ensures the toolset is closed.\n     * @param args Command line arguments (not used).\n     */\n    public static void main(String[] args) {\n        //Note: you may have permissions issues if the folder is outside home\n        String yourFolderPath = \"~/path/to/folder\";\n\n        ServerParameters connectionParams = ServerParameters.builder(\"npx\")\n                .args(List.of(\n                        \"-y\",\n                        \"@modelcontextprotocol/server-filesystem\",\n                        yourFolderPath\n                ))\n                .build();\n\n        try {\n            CompletableFuture<McpToolsAndToolsetResult> futureResult =\n                    McpToolset.fromServer(connectionParams, JsonBaseModel.getMapper());\n\n            McpToolsAndToolsetResult result = futureResult.join();\n\n            try (McpToolset toolset = result.getToolset()) {\n                List<McpTool> tools = result.getTools();\n\n                LlmAgent agent = LlmAgent.builder()\n                        .model(\"gemini-2.0-flash\")\n                        .name(\"enterprise_assistant\")\n                        .description(\"An agent to help users access their file systems\")\n                        .instruction(\n                                \"Help user accessing their file systems. You can list files in a directory.\"\n                        )\n                        .tools(tools)\n                        .build();\n\n                System.out.println(\"Agent created: \" + agent.name());\n\n                InMemoryRunner runner = new InMemoryRunner(agent);\n                String userId = \"user123\";\n                String sessionId = \"1234\";\n                String promptText = \"Which files are in this directory - \" + yourFolderPath + \"?\";\n\n                // Explicitly create the session first\n                try {\n                    // appName for InMemoryRunner defaults to agent.name() if not specified in constructor\n                    runner.sessionService().createSession(runner.appName(), userId, null, sessionId).blockingGet();\n                    System.out.println(\"Session created: \" + sessionId + \" for user: \" + userId);\n                } catch (Exception sessionCreationException) {\n                    System.err.println(\"Failed to create session: \" + sessionCreationException.getMessage());\n                    sessionCreationException.printStackTrace();\n                    return;\n                }\n\n                Content promptContent = Content.fromParts(Part.fromText(promptText));\n\n                System.out.println(\"\\nSending prompt: \\\"\" + promptText + \"\\\" to agent...\\n\");\n\n                runner.runAsync(userId, sessionId, promptContent, RunConfig.builder().build())\n                        .blockingForEach(event -> {\n                            System.out.println(\"Event received: \" + event.toJson());\n                        });\n            }\n        } catch (Exception e) {\n            System.err.println(\"An error occurred: \" + e.getMessage());\n            e.printStackTrace();\n        }\n    }\n}"}, {"language": "text", "code": "Event received: {\"id\":\"163a449e-691a-48a2-9e38-8cadb6d1f136\",\"invocationId\":\"e-c2458c56-e57a-45b2-97de-ae7292e505ef\",\"author\":\"enterprise_assistant\",\"content\":{\"parts\":[{\"functionCall\":{\"id\":\"adk-388b4ac2-d40e-4f6a-bda6-f051110c6498\",\"args\":{\"path\":\"~/home-test\"},\"name\":\"list_directory\"}}],\"role\":\"model\"},\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"timestamp\":1747377543788}\n\nEvent received: {\"id\":\"8728380b-bfad-4d14-8421-fa98d09364f1\",\"invocationId\":\"e-c2458c56-e57a-45b2-97de-ae7292e505ef\",\"author\":\"enterprise_assistant\",\"content\":{\"parts\":[{\"functionResponse\":{\"id\":\"adk-388b4ac2-d40e-4f6a-bda6-f051110c6498\",\"name\":\"list_directory\",\"response\":{\"text_output\":[{\"text\":\"[FILE] first\\n[FILE] second\\n[FILE] third\"}]}}}],\"role\":\"user\"},\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"timestamp\":1747377544679}\n\nEvent received: {\"id\":\"8fe7e594-3e47-4254-8b57-9106ad8463cb\",\"invocationId\":\"e-c2458c56-e57a-45b2-97de-ae7292e505ef\",\"author\":\"enterprise_assistant\",\"content\":{\"parts\":[{\"text\":\"There are three files in the directory: first, second, and third.\"}],\"role\":\"model\"},\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"timestamp\":1747377544689}"}]}, {"heading_path": ["Example 2: Google Maps MCP Server\u00b6"], "text": "Example 2: Google Maps MCP Server \u00b6 This example demonstrates connecting to the Google Maps MCP server. ", "code_blocks": []}, {"heading_path": ["Step 1: Get API Key and Enable APIs\u00b6"], "text": "Step 1: Get API Key and Enable APIs \u00b6 Google Maps API Key: Follow the directions at Use API keys to obtain a Google Maps API Key. Enable APIs: In your Google Cloud project, ensure the following APIs are enabled: Directions API Routes API\nFor instructions, see the Getting started with Google Maps Platform documentation. ", "code_blocks": []}, {"heading_path": ["Step 2: Define your Agent with MCPToolset for Google Maps\u00b6"], "text": "Step 2: Define your Agent with MCPToolset for Google Maps \u00b6 Modify your agent.py file (e.g., in ./adk_agent_samples/mcp_agent/agent.py ). Replace YOUR_GOOGLE_MAPS_API_KEY with the actual API key you obtained. # ./adk_agent_samples/mcp_agent/agent.py import os from google.adk.agents import LlmAgent from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from mcp import StdioServerParameters # Retrieve the API key from an environment variable or directly insert it. # Using an environment variable is generally safer. # Ensure this environment variable is set in the terminal where you run 'adk web'. # Example: export GOOGLE_MAPS_API_KEY=\"YOUR_ACTUAL_KEY\" google_maps_api_key = os . environ . get ( \"GOOGLE_MAPS_API_KEY\" ) if not google_maps_api_key : # Fallback or direct assignment for testing - NOT RECOMMENDED FOR PRODUCTION google_maps_api_key = \"YOUR_GOOGLE_MAPS_API_KEY_HERE\" # Replace if not using env var if google_maps_api_key == \"YOUR_GOOGLE_MAPS_API_KEY_HERE\" : print ( \"WARNING: GOOGLE_MAPS_API_KEY is not set. Please set it as an environment variable or in the script.\" ) # You might want to raise an error or exit if the key is crucial and not found. root_agent = LlmAgent ( model = 'gemini-2.0-flash' , name = 'maps_assistant_agent' , instruction = 'Help the user with mapping, directions, and finding places using Google Maps tools.' , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = 'npx' , args = [ \"-y\" , \"@modelcontextprotocol/server-google-maps\" , ], # Pass the API key as an environment variable to the npx process # This is how the MCP server for Google Maps expects the key. env = { \"GOOGLE_MAPS_API_KEY\" : google_maps_api_key } ), ), # You can filter for specific Maps tools if needed: # tool_filter=['get_directions', 'find_place_by_id'] ) ], ) ", "code_blocks": [{"language": "text", "code": "# ./adk_agent_samples/mcp_agent/agent.py\nimport os\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom mcp import StdioServerParameters\n\n# Retrieve the API key from an environment variable or directly insert it.\n# Using an environment variable is generally safer.\n# Ensure this environment variable is set in the terminal where you run 'adk web'.\n# Example: export GOOGLE_MAPS_API_KEY=\"YOUR_ACTUAL_KEY\"\ngoogle_maps_api_key = os.environ.get(\"GOOGLE_MAPS_API_KEY\")\n\nif not google_maps_api_key:\n    # Fallback or direct assignment for testing - NOT RECOMMENDED FOR PRODUCTION\n    google_maps_api_key = \"YOUR_GOOGLE_MAPS_API_KEY_HERE\" # Replace if not using env var\n    if google_maps_api_key == \"YOUR_GOOGLE_MAPS_API_KEY_HERE\":\n        print(\"WARNING: GOOGLE_MAPS_API_KEY is not set. Please set it as an environment variable or in the script.\")\n        # You might want to raise an error or exit if the key is crucial and not found.\n\nroot_agent = LlmAgent(\n    model='gemini-2.0-flash',\n    name='maps_assistant_agent',\n    instruction='Help the user with mapping, directions, and finding places using Google Maps tools.',\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command='npx',\n                    args=[\n                        \"-y\",\n                        \"@modelcontextprotocol/server-google-maps\",\n                    ],\n                    # Pass the API key as an environment variable to the npx process\n                    # This is how the MCP server for Google Maps expects the key.\n                    env={\n                        \"GOOGLE_MAPS_API_KEY\": google_maps_api_key\n                    }\n                ),\n            ),\n            # You can filter for specific Maps tools if needed:\n            # tool_filter=['get_directions', 'find_place_by_id']\n        )\n    ],\n)"}]}, {"heading_path": ["Step 3: Ensure __init__.py Exists\u00b6"], "text": "Step 3: Ensure __init__.py Exists \u00b6 If you created this in Example 1, you can skip this. Otherwise, ensure you have an __init__.py in the ./adk_agent_samples/mcp_agent/ directory: # ./adk_agent_samples/mcp_agent/__init__.py from . import agent ", "code_blocks": [{"language": "text", "code": "# ./adk_agent_samples/mcp_agent/__init__.py\nfrom . import agent"}]}, {"heading_path": ["Step 4: Run adk web and Interact\u00b6"], "text": "Step 4: Run adk web and Interact \u00b6 Set Environment Variable (Recommended): Before running adk web , it's best to set your Google Maps API key as an environment variable in your terminal: export GOOGLE_MAPS_API_KEY = \"YOUR_ACTUAL_GOOGLE_MAPS_API_KEY\" Replace YOUR_ACTUAL_GOOGLE_MAPS_API_KEY with your key. Run adk web :\n    Navigate to the parent directory of mcp_agent (e.g., adk_agent_samples ) and run: cd ./adk_agent_samples # Or your equivalent parent directory adk web Interact in the UI : Select the maps_assistant_agent . Try prompts like: \"Get directions from GooglePlex to SFO.\" \"Find coffee shops near Golden Gate Park.\" \"What's the route from Paris, France to Berlin, Germany?\" You should see the agent use the Google Maps MCP tools to provide directions or location-based information. For Java, refer to the following sample to define an agent that initializes the MCPToolset : package agents ; import com.google.adk.JsonBaseModel ; import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.RunConfig ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.tools.mcp.McpTool ; import com.google.adk.tools.mcp.McpToolset ; import com.google.adk.tools.mcp.McpToolset.McpToolsAndToolsetResult ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.modelcontextprotocol.client.transport.ServerParameters ; import java.util.List ; import java.util.Map ; import java.util.Collections ; import java.util.HashMap ; import java.util.concurrent.CompletableFuture ; import java.util.Arrays ; public class MapsAgentCreator { /** * Initializes an McpToolset for Google Maps, retrieves tools, * creates an LlmAgent, sends a map-related prompt, and closes the toolset. * @param args Command line arguments (not used). */ public static void main ( String [] args ) { // TODO: Replace with your actual Google Maps API key, on a project with the Places API enabled. String googleMapsApiKey = \"YOUR_GOOGLE_MAPS_API_KEY\" ; Map < String , String > envVariables = new HashMap <> (); envVariables . put ( \"GOOGLE_MAPS_API_KEY\" , googleMapsApiKey ); ServerParameters connectionParams = ServerParameters . builder ( \"npx\" ) . args ( List . of ( \"-y\" , \"@modelcontextprotocol/server-google-maps\" )) . env ( Collections . unmodifiableMap ( envVariables )) . build (); try { CompletableFuture < McpToolsAndToolsetResult > futureResult = McpToolset . fromServer ( connectionParams , JsonBaseModel . getMapper ()); McpToolsAndToolsetResult result = futureResult . join (); try ( McpToolset toolset = result . getToolset ()) { List < McpTool > tools = result . getTools (); LlmAgent agent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"maps_assistant\" ) . description ( \"Maps assistant\" ) . instruction ( \"Help user with mapping and directions using available tools.\" ) . tools ( tools ) . build (); System . out . println ( \"Agent created: \" + agent . name ()); InMemoryRunner runner = new InMemoryRunner ( agent ); String userId = \"maps-user-\" + System . currentTimeMillis (); String sessionId = \"maps-session-\" + System . currentTimeMillis (); String promptText = \"Please give me directions to the nearest pharmacy to Madison Square Garden.\" ; try { runner . sessionService (). createSession ( runner . appName (), userId , null , sessionId ). blockingGet (); System . out . println ( \"Session created: \" + sessionId + \" for user: \" + userId ); } catch ( Exception sessionCreationException ) { System . err . println ( \"Failed to create session: \" + sessionCreationException . getMessage ()); sessionCreationException . printStackTrace (); return ; } Content promptContent = Content . fromParts ( Part . fromText ( promptText )) System . out . println ( \"\\nSending prompt: \\\"\" + promptText + \"\\\" to agent...\\n\" ); runner . runAsync ( userId , sessionId , promptContent , RunConfig . builder (). build ()) . blockingForEach ( event -> { System . out . println ( \"Event received: \" + event . toJson ()); }); } } catch ( Exception e ) { System . err . println ( \"An error occurred: \" + e . getMessage ()); e . printStackTrace (); } } } A successful response will look like this: Event received: { \"id\" : \"1a4deb46-c496-4158-bd41-72702c773368\" , \"invocationId\" : \"e-48994aa0-531c-47be-8c57-65215c3e0319\" , \"author\" : \"maps_assistant\" , \"content\" : { \"parts\" : [{ \"text\" : \"OK. I see a few options. The closest one is CVS Pharmacy at 5 Pennsylvania Plaza, New York, NY 10001, United States. Would you like directions?\\n\" }] , \"role\" : \"model\" } , \"actions\" : { \"stateDelta\" : {} , \"artifactDelta\" : {} , \"requestedAuthConfigs\" : {}} , \"timestamp\" :1747380026642 } ", "code_blocks": [{"language": "text", "code": "export GOOGLE_MAPS_API_KEY=\"YOUR_ACTUAL_GOOGLE_MAPS_API_KEY\""}, {"language": "text", "code": "cd ./adk_agent_samples # Or your equivalent parent directory\nadk web"}, {"language": "text", "code": "package agents;\n\nimport com.google.adk.JsonBaseModel;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.RunConfig;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.tools.mcp.McpTool;\nimport com.google.adk.tools.mcp.McpToolset;\nimport com.google.adk.tools.mcp.McpToolset.McpToolsAndToolsetResult;\n\n\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\n\nimport io.modelcontextprotocol.client.transport.ServerParameters;\n\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.Arrays;\n\npublic class MapsAgentCreator {\n\n    /**\n     * Initializes an McpToolset for Google Maps, retrieves tools,\n     * creates an LlmAgent, sends a map-related prompt, and closes the toolset.\n     * @param args Command line arguments (not used).\n     */\n    public static void main(String[] args) {\n        // TODO: Replace with your actual Google Maps API key, on a project with the Places API enabled.\n        String googleMapsApiKey = \"YOUR_GOOGLE_MAPS_API_KEY\";\n\n        Map<String, String> envVariables = new HashMap<>();\n        envVariables.put(\"GOOGLE_MAPS_API_KEY\", googleMapsApiKey);\n\n        ServerParameters connectionParams = ServerParameters.builder(\"npx\")\n                .args(List.of(\n                        \"-y\",\n                        \"@modelcontextprotocol/server-google-maps\"\n                ))\n                .env(Collections.unmodifiableMap(envVariables))\n                .build();\n\n        try {\n            CompletableFuture<McpToolsAndToolsetResult> futureResult =\n                    McpToolset.fromServer(connectionParams, JsonBaseModel.getMapper());\n\n            McpToolsAndToolsetResult result = futureResult.join();\n\n            try (McpToolset toolset = result.getToolset()) {\n                List<McpTool> tools = result.getTools();\n\n                LlmAgent agent = LlmAgent.builder()\n                        .model(\"gemini-2.0-flash\")\n                        .name(\"maps_assistant\")\n                        .description(\"Maps assistant\")\n                        .instruction(\"Help user with mapping and directions using available tools.\")\n                        .tools(tools)\n                        .build();\n\n                System.out.println(\"Agent created: \" + agent.name());\n\n                InMemoryRunner runner = new InMemoryRunner(agent);\n                String userId = \"maps-user-\" + System.currentTimeMillis();\n                String sessionId = \"maps-session-\" + System.currentTimeMillis();\n\n                String promptText = \"Please give me directions to the nearest pharmacy to Madison Square Garden.\";\n\n                try {\n                    runner.sessionService().createSession(runner.appName(), userId, null, sessionId).blockingGet();\n                    System.out.println(\"Session created: \" + sessionId + \" for user: \" + userId);\n                } catch (Exception sessionCreationException) {\n                    System.err.println(\"Failed to create session: \" + sessionCreationException.getMessage());\n                    sessionCreationException.printStackTrace();\n                    return;\n                }\n\n                Content promptContent = Content.fromParts(Part.fromText(promptText))\n\n                System.out.println(\"\\nSending prompt: \\\"\" + promptText + \"\\\" to agent...\\n\");\n\n                runner.runAsync(userId, sessionId, promptContent, RunConfig.builder().build())\n                        .blockingForEach(event -> {\n                            System.out.println(\"Event received: \" + event.toJson());\n                        });\n            }\n        } catch (Exception e) {\n            System.err.println(\"An error occurred: \" + e.getMessage());\n            e.printStackTrace();\n        }\n    }\n}"}, {"language": "text", "code": "Event received: {\"id\":\"1a4deb46-c496-4158-bd41-72702c773368\",\"invocationId\":\"e-48994aa0-531c-47be-8c57-65215c3e0319\",\"author\":\"maps_assistant\",\"content\":{\"parts\":[{\"text\":\"OK. I see a few options. The closest one is CVS Pharmacy at 5 Pennsylvania Plaza, New York, NY 10001, United States. Would you like directions?\\n\"}],\"role\":\"model\"},\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"timestamp\":1747380026642}"}]}, {"heading_path": ["2. Building an MCP server with ADK tools (MCP server exposing ADK)\u00b6"], "text": "2. Building an MCP server with ADK tools (MCP server exposing ADK) \u00b6 This pattern allows you to wrap existing ADK tools and make them available to any standard MCP client application. The example in this section exposes the ADK load_web_page tool through a custom-built MCP server. ", "code_blocks": []}, {"heading_path": ["Summary of steps\u00b6"], "text": "Summary of steps \u00b6 You will create a standard Python MCP server application using the mcp library. Within this server, you will: Instantiate the ADK tool(s) you want to expose (e.g., FunctionTool(load_web_page) ). Implement the MCP server's @app.list_tools() handler to advertise the ADK tool(s). This involves converting the ADK tool definition to the MCP schema using the adk_to_mcp_tool_type utility from google.adk.tools.mcp_tool.conversion_utils . Implement the MCP server's @app.call_tool() handler. This handler will: Receive tool call requests from MCP clients. Identify if the request targets one of your wrapped ADK tools. Execute the ADK tool's .run_async() method. Format the ADK tool's result into an MCP-compliant response (e.g., mcp.types.TextContent ). ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Install the MCP server library in the same Python environment as your ADK installation: pip install mcp ", "code_blocks": [{"language": "text", "code": "pip install mcp"}]}, {"heading_path": ["Step 1: Create the MCP Server Script\u00b6"], "text": "Step 1: Create the MCP Server Script \u00b6 Create a new Python file for your MCP server, for example, my_adk_mcp_server.py . ", "code_blocks": []}, {"heading_path": ["Step 2: Implement the Server Logic\u00b6"], "text": "Step 2: Implement the Server Logic \u00b6 Add the following code to my_adk_mcp_server.py . This script sets up an MCP server that exposes the ADK load_web_page tool. # my_adk_mcp_server.py import asyncio import json import os from dotenv import load_dotenv # MCP Server Imports from mcp import types as mcp_types # Use alias to avoid conflict from mcp.server.lowlevel import Server , NotificationOptions from mcp.server.models import InitializationOptions import mcp.server.stdio # For running as a stdio server # ADK Tool Imports from google.adk.tools.function_tool import FunctionTool from google.adk.tools.load_web_page import load_web_page # Example ADK tool # ADK <-> MCP Conversion Utility from google.adk.tools.mcp_tool.conversion_utils import adk_to_mcp_tool_type # --- Load Environment Variables (If ADK tools need them, e.g., API keys) --- load_dotenv () # Create a .env file in the same directory if needed # --- Prepare the ADK Tool --- # Instantiate the ADK tool you want to expose. # This tool will be wrapped and called by the MCP server. print ( \"Initializing ADK load_web_page tool...\" ) adk_tool_to_expose = FunctionTool ( load_web_page ) print ( f \"ADK tool ' { adk_tool_to_expose . name } ' initialized and ready to be exposed via MCP.\" ) # --- End ADK Tool Prep --- # --- MCP Server Setup --- print ( \"Creating MCP Server instance...\" ) # Create a named MCP Server instance using the mcp.server library app = Server ( \"adk-tool-exposing-mcp-server\" ) # Implement the MCP server's handler to list available tools @app . list_tools () async def list_mcp_tools () -> list [ mcp_types . Tool ]: \"\"\"MCP handler to list tools this server exposes.\"\"\" print ( \"MCP Server: Received list_tools request.\" ) # Convert the ADK tool's definition to the MCP Tool schema format mcp_tool_schema = adk_to_mcp_tool_type ( adk_tool_to_expose ) print ( f \"MCP Server: Advertising tool: { mcp_tool_schema . name } \" ) return [ mcp_tool_schema ] # Implement the MCP server's handler to execute a tool call @app . call_tool () async def call_mcp_tool ( name : str , arguments : dict ) -> list [ mcp_types . Content ]: # MCP uses mcp_types.Content \"\"\"MCP handler to execute a tool call requested by an MCP client.\"\"\" print ( f \"MCP Server: Received call_tool request for ' { name } ' with args: { arguments } \" ) # Check if the requested tool name matches our wrapped ADK tool if name == adk_tool_to_expose . name : try : # Execute the ADK tool's run_async method. # Note: tool_context is None here because this MCP server is # running the ADK tool outside of a full ADK Runner invocation. # If the ADK tool requires ToolContext features (like state or auth), # this direct invocation might need more sophisticated handling. adk_tool_response = await adk_tool_to_expose . run_async ( args = arguments , tool_context = None , ) print ( f \"MCP Server: ADK tool ' { name } ' executed. Response: { adk_tool_response } \" ) # Format the ADK tool's response (often a dict) into an MCP-compliant format. # Here, we serialize the response dictionary as a JSON string within TextContent. # Adjust formatting based on the ADK tool's output and client needs. response_text = json . dumps ( adk_tool_response , indent = 2 ) # MCP expects a list of mcp_types.Content parts return [ mcp_types . TextContent ( type = \"text\" , text = response_text )] except Exception as e : print ( f \"MCP Server: Error executing ADK tool ' { name } ': { e } \" ) # Return an error message in MCP format error_text = json . dumps ({ \"error\" : f \"Failed to execute tool ' { name } ': { str ( e ) } \" }) return [ mcp_types . TextContent ( type = \"text\" , text = error_text )] else : # Handle calls to unknown tools print ( f \"MCP Server: Tool ' { name } ' not found/exposed by this server.\" ) error_text = json . dumps ({ \"error\" : f \"Tool ' { name } ' not implemented by this server.\" }) return [ mcp_types . TextContent ( type = \"text\" , text = error_text )] # --- MCP Server Runner --- async def run_mcp_stdio_server (): \"\"\"Runs the MCP server, listening for connections over standard input/output.\"\"\" # Use the stdio_server context manager from the mcp.server.stdio library async with mcp . server . stdio . stdio_server () as ( read_stream , write_stream ): print ( \"MCP Stdio Server: Starting handshake with client...\" ) await app . run ( read_stream , write_stream , InitializationOptions ( server_name = app . name , # Use the server name defined above server_version = \"0.1.0\" , capabilities = app . get_capabilities ( # Define server capabilities - consult MCP docs for options notification_options = NotificationOptions (), experimental_capabilities = {}, ), ), ) print ( \"MCP Stdio Server: Run loop finished or client disconnected.\" ) if __name__ == \"__main__\" : print ( \"Launching MCP Server to expose ADK tools via stdio...\" ) try : asyncio . run ( run_mcp_stdio_server ()) except KeyboardInterrupt : print ( \" \\n MCP Server (stdio) stopped by user.\" ) except Exception as e : print ( f \"MCP Server (stdio) encountered an error: { e } \" ) finally : print ( \"MCP Server (stdio) process exiting.\" ) # --- End MCP Server --- ", "code_blocks": [{"language": "text", "code": "# my_adk_mcp_server.py\nimport asyncio\nimport json\nimport os\nfrom dotenv import load_dotenv\n\n# MCP Server Imports\nfrom mcp import types as mcp_types # Use alias to avoid conflict\nfrom mcp.server.lowlevel import Server, NotificationOptions\nfrom mcp.server.models import InitializationOptions\nimport mcp.server.stdio # For running as a stdio server\n\n# ADK Tool Imports\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.adk.tools.load_web_page import load_web_page # Example ADK tool\n# ADK <-> MCP Conversion Utility\nfrom google.adk.tools.mcp_tool.conversion_utils import adk_to_mcp_tool_type\n\n# --- Load Environment Variables (If ADK tools need them, e.g., API keys) ---\nload_dotenv() # Create a .env file in the same directory if needed\n\n# --- Prepare the ADK Tool ---\n# Instantiate the ADK tool you want to expose.\n# This tool will be wrapped and called by the MCP server.\nprint(\"Initializing ADK load_web_page tool...\")\nadk_tool_to_expose = FunctionTool(load_web_page)\nprint(f\"ADK tool '{adk_tool_to_expose.name}' initialized and ready to be exposed via MCP.\")\n# --- End ADK Tool Prep ---\n\n# --- MCP Server Setup ---\nprint(\"Creating MCP Server instance...\")\n# Create a named MCP Server instance using the mcp.server library\napp = Server(\"adk-tool-exposing-mcp-server\")\n\n# Implement the MCP server's handler to list available tools\n@app.list_tools()\nasync def list_mcp_tools() -> list[mcp_types.Tool]:\n    \"\"\"MCP handler to list tools this server exposes.\"\"\"\n    print(\"MCP Server: Received list_tools request.\")\n    # Convert the ADK tool's definition to the MCP Tool schema format\n    mcp_tool_schema = adk_to_mcp_tool_type(adk_tool_to_expose)\n    print(f\"MCP Server: Advertising tool: {mcp_tool_schema.name}\")\n    return [mcp_tool_schema]\n\n# Implement the MCP server's handler to execute a tool call\n@app.call_tool()\nasync def call_mcp_tool(\n    name: str, arguments: dict\n) -> list[mcp_types.Content]: # MCP uses mcp_types.Content\n    \"\"\"MCP handler to execute a tool call requested by an MCP client.\"\"\"\n    print(f\"MCP Server: Received call_tool request for '{name}' with args: {arguments}\")\n\n    # Check if the requested tool name matches our wrapped ADK tool\n    if name == adk_tool_to_expose.name:\n        try:\n            # Execute the ADK tool's run_async method.\n            # Note: tool_context is None here because this MCP server is\n            # running the ADK tool outside of a full ADK Runner invocation.\n            # If the ADK tool requires ToolContext features (like state or auth),\n            # this direct invocation might need more sophisticated handling.\n            adk_tool_response = await adk_tool_to_expose.run_async(\n                args=arguments,\n                tool_context=None,\n            )\n            print(f\"MCP Server: ADK tool '{name}' executed. Response: {adk_tool_response}\")\n\n            # Format the ADK tool's response (often a dict) into an MCP-compliant format.\n            # Here, we serialize the response dictionary as a JSON string within TextContent.\n            # Adjust formatting based on the ADK tool's output and client needs.\n            response_text = json.dumps(adk_tool_response, indent=2)\n            # MCP expects a list of mcp_types.Content parts\n            return [mcp_types.TextContent(type=\"text\", text=response_text)]\n\n        except Exception as e:\n            print(f\"MCP Server: Error executing ADK tool '{name}': {e}\")\n            # Return an error message in MCP format\n            error_text = json.dumps({\"error\": f\"Failed to execute tool '{name}': {str(e)}\"})\n            return [mcp_types.TextContent(type=\"text\", text=error_text)]\n    else:\n        # Handle calls to unknown tools\n        print(f\"MCP Server: Tool '{name}' not found/exposed by this server.\")\n        error_text = json.dumps({\"error\": f\"Tool '{name}' not implemented by this server.\"})\n        return [mcp_types.TextContent(type=\"text\", text=error_text)]\n\n# --- MCP Server Runner ---\nasync def run_mcp_stdio_server():\n    \"\"\"Runs the MCP server, listening for connections over standard input/output.\"\"\"\n    # Use the stdio_server context manager from the mcp.server.stdio library\n    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):\n        print(\"MCP Stdio Server: Starting handshake with client...\")\n        await app.run(\n            read_stream,\n            write_stream,\n            InitializationOptions(\n                server_name=app.name, # Use the server name defined above\n                server_version=\"0.1.0\",\n                capabilities=app.get_capabilities(\n                    # Define server capabilities - consult MCP docs for options\n                    notification_options=NotificationOptions(),\n                    experimental_capabilities={},\n                ),\n            ),\n        )\n        print(\"MCP Stdio Server: Run loop finished or client disconnected.\")\n\nif __name__ == \"__main__\":\n    print(\"Launching MCP Server to expose ADK tools via stdio...\")\n    try:\n        asyncio.run(run_mcp_stdio_server())\n    except KeyboardInterrupt:\n        print(\"\\nMCP Server (stdio) stopped by user.\")\n    except Exception as e:\n        print(f\"MCP Server (stdio) encountered an error: {e}\")\n    finally:\n        print(\"MCP Server (stdio) process exiting.\")\n# --- End MCP Server ---"}]}, {"heading_path": ["Step 3: Test your Custom MCP Server with an ADK Agent\u00b6"], "text": "Step 3: Test your Custom MCP Server with an ADK Agent \u00b6 Now, create an ADK agent that will act as a client to the MCP server you just built. This ADK agent will use MCPToolset to connect to your my_adk_mcp_server.py script. Create an agent.py (e.g., in ./adk_agent_samples/mcp_client_agent/agent.py ): # ./adk_agent_samples/mcp_client_agent/agent.py import os from google.adk.agents import LlmAgent from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from mcp import StdioServerParameters # IMPORTANT: Replace this with the ABSOLUTE path to your my_adk_mcp_server.py script PATH_TO_YOUR_MCP_SERVER_SCRIPT = \"/path/to/your/my_adk_mcp_server.py\" # <<< REPLACE if PATH_TO_YOUR_MCP_SERVER_SCRIPT == \"/path/to/your/my_adk_mcp_server.py\" : print ( \"WARNING: PATH_TO_YOUR_MCP_SERVER_SCRIPT is not set. Please update it in agent.py.\" ) # Optionally, raise an error if the path is critical root_agent = LlmAgent ( model = 'gemini-2.0-flash' , name = 'web_reader_mcp_client_agent' , instruction = \"Use the 'load_web_page' tool to fetch content from a URL provided by the user.\" , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = 'python3' , # Command to run your MCP server script args = [ PATH_TO_YOUR_MCP_SERVER_SCRIPT ], # Argument is the path to the script ) ) # tool_filter=['load_web_page'] # Optional: ensure only specific tools are loaded ) ], ) And an __init__.py in the same directory: # ./adk_agent_samples/mcp_client_agent/__init__.py from . import agent To run the test: Start your custom MCP server (optional, for separate observation): You can run your my_adk_mcp_server.py directly in one terminal to see its logs: python3 /path/to/your/my_adk_mcp_server.py It will print \"Launching MCP Server...\" and wait. The ADK agent (run via adk web ) will then connect to this process if the command in StdioConnectionParams is set up to execute it. (Alternatively, MCPToolset will start this server script as a subprocess automatically when the agent initializes). Run adk web for the client agent: Navigate to the parent directory of mcp_client_agent (e.g., adk_agent_samples ) and run: cd ./adk_agent_samples # Or your equivalent parent directory adk web Interact in the ADK Web UI: Select the web_reader_mcp_client_agent . Try a prompt like: \"Load the content from https://example.com\" The ADK agent ( web_reader_mcp_client_agent ) will use MCPToolset to start and connect to your my_adk_mcp_server.py . Your MCP server will receive the call_tool request, execute the ADK load_web_page tool, and return the result. The ADK agent will then relay this information. You should see logs from both the ADK Web UI (and its terminal) and potentially from your my_adk_mcp_server.py terminal if you ran it separately. This example demonstrates how ADK tools can be encapsulated within an MCP server, making them accessible to a broader range of MCP-compliant clients, not just ADK agents. Refer to the documentation , to try it out with Claude Desktop. ", "code_blocks": [{"language": "text", "code": "# ./adk_agent_samples/mcp_client_agent/agent.py\nimport os\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom mcp import StdioServerParameters\n\n# IMPORTANT: Replace this with the ABSOLUTE path to your my_adk_mcp_server.py script\nPATH_TO_YOUR_MCP_SERVER_SCRIPT = \"/path/to/your/my_adk_mcp_server.py\" # <<< REPLACE\n\nif PATH_TO_YOUR_MCP_SERVER_SCRIPT == \"/path/to/your/my_adk_mcp_server.py\":\n    print(\"WARNING: PATH_TO_YOUR_MCP_SERVER_SCRIPT is not set. Please update it in agent.py.\")\n    # Optionally, raise an error if the path is critical\n\nroot_agent = LlmAgent(\n    model='gemini-2.0-flash',\n    name='web_reader_mcp_client_agent',\n    instruction=\"Use the 'load_web_page' tool to fetch content from a URL provided by the user.\",\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params = StdioServerParameters(\n                    command='python3', # Command to run your MCP server script\n                    args=[PATH_TO_YOUR_MCP_SERVER_SCRIPT], # Argument is the path to the script\n                )\n            )\n            # tool_filter=['load_web_page'] # Optional: ensure only specific tools are loaded\n        )\n    ],\n)"}, {"language": "text", "code": "# ./adk_agent_samples/mcp_client_agent/__init__.py\nfrom . import agent"}, {"language": "text", "code": "python3 /path/to/your/my_adk_mcp_server.py"}, {"language": "text", "code": "cd ./adk_agent_samples # Or your equivalent parent directory\nadk web"}]}, {"heading_path": ["Using MCP Tools in your own Agent out of adk web\u00b6"], "text": "Using MCP Tools in your own Agent out of adk web \u00b6 This section is relevant to you if: You are developing your own Agent using ADK And, you are NOT using adk web , And, you are exposing the agent via your own UI Using MCP Tools requires a different setup than using regular tools, due to the fact that specs for MCP Tools are fetched asynchronously\nfrom the MCP Server running remotely, or in another process. The following example is modified from the \"Example 1: File System MCP Server\" example above. The main differences are: Your tool and agent are created asynchronously You need to properly manage the exit stack, so that your agents and tools are destructed properly when the connection to MCP Server is closed. # agent.py (modify get_tools_async and other parts as needed) # ./adk_agent_samples/mcp_agent/agent.py import os import asyncio from dotenv import load_dotenv from google.genai import types from google.adk.agents.llm_agent import LlmAgent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService # Optional from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams from mcp import StdioServerParameters # Load environment variables from .env file in the parent directory # Place this near the top, before using env vars like API keys load_dotenv ( '../.env' ) # Ensure TARGET_FOLDER_PATH is an absolute path for the MCP server. TARGET_FOLDER_PATH = os . path . join ( os . path . dirname ( os . path . abspath ( __file__ )), \"/path/to/your/folder\" ) # --- Step 1: Agent Definition --- async def get_agent_async (): \"\"\"Creates an ADK Agent equipped with tools from the MCP Server.\"\"\" toolset = MCPToolset ( # Use StdioConnectionParams for local process communication connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = 'npx' , # Command to run the server args = [ \"-y\" , # Arguments for the command \"@modelcontextprotocol/server-filesystem\" , TARGET_FOLDER_PATH ], ), ), tool_filter = [ 'read_file' , 'list_directory' ] # Optional: filter specific tools # For remote servers, you would use SseConnectionParams instead: # connection_params=SseConnectionParams(url=\"http://remote-server:port/path\", headers={...}) ) # Use in an agent root_agent = LlmAgent ( model = 'gemini-2.0-flash' , # Adjust model name if needed based on availability name = 'enterprise_assistant' , instruction = 'Help user accessing their file systems' , tools = [ toolset ], # Provide the MCP tools to the ADK agent ) return root_agent , toolset # --- Step 2: Main Execution Logic --- async def async_main (): session_service = InMemorySessionService () # Artifact service might not be needed for this example artifacts_service = InMemoryArtifactService () session = await session_service . create_session ( state = {}, app_name = 'mcp_filesystem_app' , user_id = 'user_fs' ) # TODO: Change the query to be relevant to YOUR specified folder. # e.g., \"list files in the 'documents' subfolder\" or \"read the file 'notes.txt'\" query = \"list files in the tests folder\" print ( f \"User Query: ' { query } '\" ) content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) root_agent , toolset = await get_agent_async () runner = Runner ( app_name = 'mcp_filesystem_app' , agent = root_agent , artifact_service = artifacts_service , # Optional session_service = session_service , ) print ( \"Running agent...\" ) events_async = runner . run_async ( session_id = session . id , user_id = session . user_id , new_message = content ) async for event in events_async : print ( f \"Event received: { event } \" ) # Cleanup is handled automatically by the agent framework # But you can also manually close if needed: print ( \"Closing MCP server connection...\" ) await toolset . close () print ( \"Cleanup complete.\" ) if __name__ == '__main__' : try : asyncio . run ( async_main ()) except Exception as e : print ( f \"An error occurred: { e } \" ) ", "code_blocks": [{"language": "text", "code": "# agent.py (modify get_tools_async and other parts as needed)\n# ./adk_agent_samples/mcp_agent/agent.py\nimport os\nimport asyncio\nfrom dotenv import load_dotenv\nfrom google.genai import types\nfrom google.adk.agents.llm_agent import LlmAgent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService # Optional\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\nfrom mcp import StdioServerParameters\n\n# Load environment variables from .env file in the parent directory\n# Place this near the top, before using env vars like API keys\nload_dotenv('../.env')\n\n# Ensure TARGET_FOLDER_PATH is an absolute path for the MCP server.\nTARGET_FOLDER_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"/path/to/your/folder\")\n\n# --- Step 1: Agent Definition ---\nasync def get_agent_async():\n  \"\"\"Creates an ADK Agent equipped with tools from the MCP Server.\"\"\"\n  toolset = MCPToolset(\n      # Use StdioConnectionParams for local process communication\n      connection_params=StdioConnectionParams(\n          server_params = StdioServerParameters(\n            command='npx', # Command to run the server\n            args=[\"-y\",    # Arguments for the command\n                \"@modelcontextprotocol/server-filesystem\",\n                TARGET_FOLDER_PATH],\n          ),\n      ),\n      tool_filter=['read_file', 'list_directory'] # Optional: filter specific tools\n      # For remote servers, you would use SseConnectionParams instead:\n      # connection_params=SseConnectionParams(url=\"http://remote-server:port/path\", headers={...})\n  )\n\n  # Use in an agent\n  root_agent = LlmAgent(\n      model='gemini-2.0-flash', # Adjust model name if needed based on availability\n      name='enterprise_assistant',\n      instruction='Help user accessing their file systems',\n      tools=[toolset], # Provide the MCP tools to the ADK agent\n  )\n  return root_agent, toolset\n\n# --- Step 2: Main Execution Logic ---\nasync def async_main():\n  session_service = InMemorySessionService()\n  # Artifact service might not be needed for this example\n  artifacts_service = InMemoryArtifactService()\n\n  session = await session_service.create_session(\n      state={}, app_name='mcp_filesystem_app', user_id='user_fs'\n  )\n\n  # TODO: Change the query to be relevant to YOUR specified folder.\n  # e.g., \"list files in the 'documents' subfolder\" or \"read the file 'notes.txt'\"\n  query = \"list files in the tests folder\"\n  print(f\"User Query: '{query}'\")\n  content = types.Content(role='user', parts=[types.Part(text=query)])\n\n  root_agent, toolset = await get_agent_async()\n\n  runner = Runner(\n      app_name='mcp_filesystem_app',\n      agent=root_agent,\n      artifact_service=artifacts_service, # Optional\n      session_service=session_service,\n  )\n\n  print(\"Running agent...\")\n  events_async = runner.run_async(\n      session_id=session.id, user_id=session.user_id, new_message=content\n  )\n\n  async for event in events_async:\n    print(f\"Event received: {event}\")\n\n  # Cleanup is handled automatically by the agent framework\n  # But you can also manually close if needed:\n  print(\"Closing MCP server connection...\")\n  await toolset.close()\n  print(\"Cleanup complete.\")\n\nif __name__ == '__main__':\n  try:\n    asyncio.run(async_main())\n  except Exception as e:\n    print(f\"An error occurred: {e}\")"}]}, {"heading_path": ["Key considerations\u00b6"], "text": "Key considerations \u00b6 When working with MCP and ADK, keep these points in mind: Protocol vs. Library: MCP is a protocol specification, defining communication rules. ADK is a Python library/framework for building agents. MCPToolset bridges these by implementing the client side of the MCP protocol within the ADK framework. Conversely, building an MCP server in Python requires using the model-context-protocol library. ADK Tools vs. MCP Tools: ADK Tools (BaseTool, FunctionTool, AgentTool, etc.) are Python objects designed for direct use within the ADK's LlmAgent and Runner. MCP Tools are capabilities exposed by an MCP Server according to the protocol's schema. MCPToolset makes these look like ADK tools to an LlmAgent. Asynchronous nature: Both ADK and the MCP Python library are heavily based on the asyncio Python library. Tool implementations and server handlers should generally be async functions. Stateful sessions (MCP): MCP establishes stateful, persistent connections between a client and server instance. This differs from typical stateless REST APIs. Deployment: This statefulness can pose challenges for scaling and deployment, especially for remote servers handling many users. The original MCP design often assumed client and server were co-located. Managing these persistent connections requires careful infrastructure considerations (e.g., load balancing, session affinity). ADK MCPToolset: Manages this connection lifecycle. The exit_stack pattern shown in the examples is crucial for ensuring the connection (and potentially the server process) is properly terminated when the ADK agent finishes. ", "code_blocks": []}, {"heading_path": ["Deploying Agents with MCP Tools\u00b6"], "text": "Deploying Agents with MCP Tools \u00b6 When deploying ADK agents that use MCP tools to production environments like Cloud Run, GKE, or Vertex AI Agent Engine, you need to consider how MCP connections will work in containerized and distributed environments. ", "code_blocks": []}, {"heading_path": ["Critical Deployment Requirement: Synchronous Agent Definition\u00b6"], "text": "Critical Deployment Requirement: Synchronous Agent Definition \u00b6 \u26a0\ufe0f Important: When deploying agents with MCP tools, the agent and its MCPToolset must be defined synchronously in your agent.py file. While adk web allows for asynchronous agent creation, deployment environments require synchronous instantiation. # \u2705 CORRECT: Synchronous agent definition for deployment import os from google.adk.agents.llm_agent import LlmAgent from google.adk.tools.mcp_tool import StdioConnectionParams from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset from mcp import StdioServerParameters _allowed_path = os . path . dirname ( os . path . abspath ( __file__ )) root_agent = LlmAgent ( model = 'gemini-2.0-flash' , name = 'enterprise_assistant' , instruction = f 'Help user accessing their file systems. Allowed directory: { _allowed_path } ' , tools = [ MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = 'npx' , args = [ '-y' , '@modelcontextprotocol/server-filesystem' , _allowed_path ], ), timeout = 5 , # Configure appropriate timeouts ), # Filter tools for security in production tool_filter = [ 'read_file' , 'read_multiple_files' , 'list_directory' , 'directory_tree' , 'search_files' , 'get_file_info' , 'list_allowed_directories' , ], ) ], ) # \u274c WRONG: Asynchronous patterns don't work in deployment async def get_agent (): # This won't work for deployment toolset = await create_mcp_toolset_async () return LlmAgent ( tools = [ toolset ]) ", "code_blocks": [{"language": "text", "code": "# \u2705 CORRECT: Synchronous agent definition for deployment\nimport os\nfrom google.adk.agents.llm_agent import LlmAgent\nfrom google.adk.tools.mcp_tool import StdioConnectionParams\nfrom google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\nfrom mcp import StdioServerParameters\n\n_allowed_path = os.path.dirname(os.path.abspath(__file__))\n\nroot_agent = LlmAgent(\n    model='gemini-2.0-flash',\n    name='enterprise_assistant',\n    instruction=f'Help user accessing their file systems. Allowed directory: {_allowed_path}',\n    tools=[\n        MCPToolset(\n            connection_params=StdioConnectionParams(\n                server_params=StdioServerParameters(\n                    command='npx',\n                    args=['-y', '@modelcontextprotocol/server-filesystem', _allowed_path],\n                ),\n                timeout=5,  # Configure appropriate timeouts\n            ),\n            # Filter tools for security in production\n            tool_filter=[\n                'read_file', 'read_multiple_files', 'list_directory',\n                'directory_tree', 'search_files', 'get_file_info',\n                'list_allowed_directories',\n            ],\n        )\n    ],\n)"}, {"language": "text", "code": "# \u274c WRONG: Asynchronous patterns don't work in deployment\nasync def get_agent():  # This won't work for deployment\n    toolset = await create_mcp_toolset_async()\n    return LlmAgent(tools=[toolset])"}]}, {"heading_path": ["Quick Deployment Commands\u00b6"], "text": "Quick Deployment Commands \u00b6 ", "code_blocks": []}, {"heading_path": ["Vertex AI Agent Engine\u00b6"], "text": "Vertex AI Agent Engine \u00b6 uv run adk deploy agent_engine \\ --project = <your-gcp-project-id> \\ --region = <your-gcp-region> \\ --staging_bucket = \"gs://<your-gcs-bucket>\" \\ --display_name = \"My MCP Agent\" \\ ./path/to/your/agent_directory ", "code_blocks": [{"language": "text", "code": "uv run adk deploy agent_engine \\\n  --project=<your-gcp-project-id> \\\n  --region=<your-gcp-region> \\\n  --staging_bucket=\"gs://<your-gcs-bucket>\" \\\n  --display_name=\"My MCP Agent\" \\\n  ./path/to/your/agent_directory"}]}, {"heading_path": ["Cloud Run\u00b6"], "text": "Cloud Run \u00b6 uv run adk deploy cloud_run \\ --project = <your-gcp-project-id> \\ --region = <your-gcp-region> \\ --service_name = <your-service-name> \\ ./path/to/your/agent_directory ", "code_blocks": [{"language": "text", "code": "uv run adk deploy cloud_run \\\n  --project=<your-gcp-project-id> \\\n  --region=<your-gcp-region> \\\n  --service_name=<your-service-name> \\\n  ./path/to/your/agent_directory"}]}, {"heading_path": ["Deployment Patterns\u00b6"], "text": "Deployment Patterns \u00b6 ", "code_blocks": []}, {"heading_path": ["Pattern 1: Self-Contained Stdio MCP Servers\u00b6"], "text": "Pattern 1: Self-Contained Stdio MCP Servers \u00b6 For MCP servers that can be packaged as npm packages or Python modules (like @modelcontextprotocol/server-filesystem ), you can include them directly in your agent container: Container Requirements: # Example for npm-based MCP servers FROM python:3.13-slim # Install Node.js and npm for MCP servers RUN apt-get update && apt-get install -y nodejs npm && rm -rf /var/lib/apt/lists/* # Install your Python dependencies COPY requirements.txt . RUN pip install -r requirements.txt # Copy your agent code COPY . . # Your agent can now use StdioConnectionParams with 'npx' commands CMD [ \"python\" , \"main.py\" ] Agent Configuration: # This works in containers because npx and the MCP server run in the same environment MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = 'npx' , args = [ \"-y\" , \"@modelcontextprotocol/server-filesystem\" , \"/app/data\" ], ), ), ) ", "code_blocks": [{"language": "text", "code": "# Example for npm-based MCP servers\nFROM python:3.13-slim\n\n# Install Node.js and npm for MCP servers\nRUN apt-get update && apt-get install -y nodejs npm && rm -rf /var/lib/apt/lists/*\n\n# Install your Python dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Copy your agent code\nCOPY . .\n\n# Your agent can now use StdioConnectionParams with 'npx' commands\nCMD [\"python\", \"main.py\"]"}, {"language": "text", "code": "# This works in containers because npx and the MCP server run in the same environment\nMCPToolset(\n    connection_params=StdioConnectionParams(\n        server_params=StdioServerParameters(\n            command='npx',\n            args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/app/data\"],\n        ),\n    ),\n)"}]}, {"heading_path": ["Pattern 2: Remote MCP Servers (Streamable HTTP)\u00b6"], "text": "Pattern 2: Remote MCP Servers (Streamable HTTP) \u00b6 For production deployments requiring scalability, deploy MCP servers as separate services and connect via Streamable HTTP: MCP Server Deployment (Cloud Run): # deploy_mcp_server.py - Separate Cloud Run service using Streamable HTTP import contextlib import logging from collections.abc import AsyncIterator from typing import Any import anyio import click import mcp.types as types from mcp.server.lowlevel import Server from mcp.server.streamable_http_manager import StreamableHTTPSessionManager from starlette.applications import Starlette from starlette.routing import Mount from starlette.types import Receive , Scope , Send logger = logging . getLogger ( __name__ ) def create_mcp_server (): \"\"\"Create and configure the MCP server.\"\"\" app = Server ( \"adk-mcp-streamable-server\" ) @app . call_tool () async def call_tool ( name : str , arguments : dict [ str , Any ]) -> list [ types . ContentBlock ]: \"\"\"Handle tool calls from MCP clients.\"\"\" # Example tool implementation - replace with your actual ADK tools if name == \"example_tool\" : result = arguments . get ( \"input\" , \"No input provided\" ) return [ types . TextContent ( type = \"text\" , text = f \"Processed: { result } \" ) ] else : raise ValueError ( f \"Unknown tool: { name } \" ) @app . list_tools () async def list_tools () -> list [ types . Tool ]: \"\"\"List available tools.\"\"\" return [ types . Tool ( name = \"example_tool\" , description = \"Example tool for demonstration\" , inputSchema = { \"type\" : \"object\" , \"properties\" : { \"input\" : { \"type\" : \"string\" , \"description\" : \"Input text to process\" } }, \"required\" : [ \"input\" ] } ) ] return app def main ( port : int = 8080 , json_response : bool = False ): \"\"\"Main server function.\"\"\" logging . basicConfig ( level = logging . INFO ) app = create_mcp_server () # Create session manager with stateless mode for scalability session_manager = StreamableHTTPSessionManager ( app = app , event_store = None , json_response = json_response , stateless = True , # Important for Cloud Run scalability ) async def handle_streamable_http ( scope : Scope , receive : Receive , send : Send ) -> None : await session_manager . handle_request ( scope , receive , send ) @contextlib . asynccontextmanager async def lifespan ( app : Starlette ) -> AsyncIterator [ None ]: \"\"\"Manage session manager lifecycle.\"\"\" async with session_manager . run (): logger . info ( \"MCP Streamable HTTP server started!\" ) try : yield finally : logger . info ( \"MCP server shutting down...\" ) # Create ASGI application starlette_app = Starlette ( debug = False , # Set to False for production routes = [ Mount ( \"/mcp\" , app = handle_streamable_http ), ], lifespan = lifespan , ) import uvicorn uvicorn . run ( starlette_app , host = \"0.0.0.0\" , port = port ) if __name__ == \"__main__\" : main () Agent Configuration for Remote MCP: # Your ADK agent connects to the remote MCP service via Streamable HTTP MCPToolset ( connection_params = StreamableHTTPConnectionParams ( url = \"https://your-mcp-server-url.run.app/mcp\" , headers = { \"Authorization\" : \"Bearer your-auth-token\" } ), ) ", "code_blocks": [{"language": "text", "code": "# deploy_mcp_server.py - Separate Cloud Run service using Streamable HTTP\nimport contextlib\nimport logging\nfrom collections.abc import AsyncIterator\nfrom typing import Any\n\nimport anyio\nimport click\nimport mcp.types as types\nfrom mcp.server.lowlevel import Server\nfrom mcp.server.streamable_http_manager import StreamableHTTPSessionManager\nfrom starlette.applications import Starlette\nfrom starlette.routing import Mount\nfrom starlette.types import Receive, Scope, Send\n\nlogger = logging.getLogger(__name__)\n\ndef create_mcp_server():\n    \"\"\"Create and configure the MCP server.\"\"\"\n    app = Server(\"adk-mcp-streamable-server\")\n\n    @app.call_tool()\n    async def call_tool(name: str, arguments: dict[str, Any]) -> list[types.ContentBlock]:\n        \"\"\"Handle tool calls from MCP clients.\"\"\"\n        # Example tool implementation - replace with your actual ADK tools\n        if name == \"example_tool\":\n            result = arguments.get(\"input\", \"No input provided\")\n            return [\n                types.TextContent(\n                    type=\"text\",\n                    text=f\"Processed: {result}\"\n                )\n            ]\n        else:\n            raise ValueError(f\"Unknown tool: {name}\")\n\n    @app.list_tools()\n    async def list_tools() -> list[types.Tool]:\n        \"\"\"List available tools.\"\"\"\n        return [\n            types.Tool(\n                name=\"example_tool\",\n                description=\"Example tool for demonstration\",\n                inputSchema={\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"input\": {\n                            \"type\": \"string\",\n                            \"description\": \"Input text to process\"\n                        }\n                    },\n                    \"required\": [\"input\"]\n                }\n            )\n        ]\n\n    return app\n\ndef main(port: int = 8080, json_response: bool = False):\n    \"\"\"Main server function.\"\"\"\n    logging.basicConfig(level=logging.INFO)\n\n    app = create_mcp_server()\n\n    # Create session manager with stateless mode for scalability\n    session_manager = StreamableHTTPSessionManager(\n        app=app,\n        event_store=None,\n        json_response=json_response,\n        stateless=True,  # Important for Cloud Run scalability\n    )\n\n    async def handle_streamable_http(scope: Scope, receive: Receive, send: Send) -> None:\n        await session_manager.handle_request(scope, receive, send)\n\n    @contextlib.asynccontextmanager\n    async def lifespan(app: Starlette) -> AsyncIterator[None]:\n        \"\"\"Manage session manager lifecycle.\"\"\"\n        async with session_manager.run():\n            logger.info(\"MCP Streamable HTTP server started!\")\n            try:\n                yield\n            finally:\n                logger.info(\"MCP server shutting down...\")\n\n    # Create ASGI application\n    starlette_app = Starlette(\n        debug=False,  # Set to False for production\n        routes=[\n            Mount(\"/mcp\", app=handle_streamable_http),\n        ],\n        lifespan=lifespan,\n    )\n\n    import uvicorn\n    uvicorn.run(starlette_app, host=\"0.0.0.0\", port=port)\n\nif __name__ == \"__main__\":\n    main()"}, {"language": "text", "code": "# Your ADK agent connects to the remote MCP service via Streamable HTTP\nMCPToolset(\n    connection_params=StreamableHTTPConnectionParams(\n        url=\"https://your-mcp-server-url.run.app/mcp\",\n        headers={\"Authorization\": \"Bearer your-auth-token\"}\n    ),\n)"}]}, {"heading_path": ["Pattern 3: Sidecar MCP Servers (GKE)\u00b6"], "text": "Pattern 3: Sidecar MCP Servers (GKE) \u00b6 In Kubernetes environments, you can deploy MCP servers as sidecar containers: # deployment.yaml - GKE with MCP sidecar apiVersion : apps/v1 kind : Deployment metadata : name : adk-agent-with-mcp spec : template : spec : containers : # Main ADK agent container - name : adk-agent image : your-adk-agent:latest ports : - containerPort : 8080 env : - name : MCP_SERVER_URL value : \"http://localhost:8081\" # MCP server sidecar - name : mcp-server image : your-mcp-server:latest ports : - containerPort : 8081 ", "code_blocks": [{"language": "text", "code": "# deployment.yaml - GKE with MCP sidecar\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: adk-agent-with-mcp\nspec:\n  template:\n    spec:\n      containers:\n      # Main ADK agent container\n      - name: adk-agent\n        image: your-adk-agent:latest\n        ports:\n        - containerPort: 8080\n        env:\n        - name: MCP_SERVER_URL\n          value: \"http://localhost:8081\"\n\n      # MCP server sidecar\n      - name: mcp-server\n        image: your-mcp-server:latest\n        ports:\n        - containerPort: 8081"}]}, {"heading_path": ["Connection Management Considerations\u00b6"], "text": "Connection Management Considerations \u00b6 ", "code_blocks": []}, {"heading_path": ["Stdio Connections\u00b6"], "text": "Stdio Connections \u00b6 Pros: Simple setup, process isolation, works well in containers Cons: Process overhead, not suitable for high-scale deployments Best for: Development, single-tenant deployments, simple MCP servers ", "code_blocks": []}, {"heading_path": ["SSE/HTTP Connections\u00b6"], "text": "SSE/HTTP Connections \u00b6 Pros: Network-based, scalable, can handle multiple clients Cons: Requires network infrastructure, authentication complexity Best for: Production deployments, multi-tenant systems, external MCP services ", "code_blocks": []}, {"heading_path": ["Production Deployment Checklist\u00b6"], "text": "Production Deployment Checklist \u00b6 When deploying agents with MCP tools to production: \u2705 Connection Lifecycle - Ensure proper cleanup of MCP connections using exit_stack patterns\n- Configure appropriate timeouts for connection establishment and requests\n- Implement retry logic for transient connection failures \u2705 Resource Management - Monitor memory usage for stdio MCP servers (each spawns a process)\n- Configure appropriate CPU/memory limits for MCP server processes\n- Consider connection pooling for remote MCP servers \u2705 Security - Use authentication headers for remote MCP connections\n- Restrict network access between ADK agents and MCP servers\n- Filter MCP tools using tool_filter to limit exposed functionality - Validate MCP tool inputs to prevent injection attacks\n- Use restrictive file paths for filesystem MCP servers (e.g., os.path.dirname(os.path.abspath(__file__)) )\n- Consider read-only tool filters for production environments \u2705 Monitoring & Observability - Log MCP connection establishment and teardown events\n- Monitor MCP tool execution times and success rates\n- Set up alerts for MCP connection failures \u2705 Scalability - For high-volume deployments, prefer remote MCP servers over stdio\n- Configure session affinity if using stateful MCP servers\n- Consider MCP server connection limits and implement circuit breakers ", "code_blocks": []}, {"heading_path": ["Environment-Specific Configurations\u00b6"], "text": "Environment-Specific Configurations \u00b6 ", "code_blocks": []}, {"heading_path": ["Cloud Run\u00b6"], "text": "Cloud Run \u00b6 # Cloud Run environment variables for MCP configuration import os # Detect Cloud Run environment if os . getenv ( 'K_SERVICE' ): # Use remote MCP servers in Cloud Run mcp_connection = SseConnectionParams ( url = os . getenv ( 'MCP_SERVER_URL' ), headers = { 'Authorization' : f \"Bearer { os . getenv ( 'MCP_AUTH_TOKEN' ) } \" } ) else : # Use stdio for local development mcp_connection = StdioConnectionParams ( server_params = StdioServerParameters ( command = 'npx' , args = [ \"-y\" , \"@modelcontextprotocol/server-filesystem\" , \"/tmp\" ] ) ) MCPToolset ( connection_params = mcp_connection ) ", "code_blocks": [{"language": "text", "code": "# Cloud Run environment variables for MCP configuration\nimport os\n\n# Detect Cloud Run environment\nif os.getenv('K_SERVICE'):\n    # Use remote MCP servers in Cloud Run\n    mcp_connection = SseConnectionParams(\n        url=os.getenv('MCP_SERVER_URL'),\n        headers={'Authorization': f\"Bearer {os.getenv('MCP_AUTH_TOKEN')}\"}\n    )\nelse:\n    # Use stdio for local development\n    mcp_connection = StdioConnectionParams(\n        server_params=StdioServerParameters(\n            command='npx',\n            args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/tmp\"]\n        )\n    )\n\nMCPToolset(connection_params=mcp_connection)"}]}, {"heading_path": ["GKE\u00b6"], "text": "GKE \u00b6 # GKE-specific MCP configuration # Use service discovery for MCP servers within the cluster MCPToolset ( connection_params = SseConnectionParams ( url = \"http://mcp-service.default.svc.cluster.local:8080/sse\" ), ) ", "code_blocks": [{"language": "text", "code": "# GKE-specific MCP configuration\n# Use service discovery for MCP servers within the cluster\nMCPToolset(\n    connection_params=SseConnectionParams(\n        url=\"http://mcp-service.default.svc.cluster.local:8080/sse\"\n    ),\n)"}]}, {"heading_path": ["Vertex AI Agent Engine\u00b6"], "text": "Vertex AI Agent Engine \u00b6 # Agent Engine managed deployment # Prefer lightweight, self-contained MCP servers or external services MCPToolset ( connection_params = SseConnectionParams ( url = \"https://your-managed-mcp-service.googleapis.com/sse\" , headers = { 'Authorization' : 'Bearer $(gcloud auth print-access-token)' } ), ) ", "code_blocks": [{"language": "text", "code": "# Agent Engine managed deployment\n# Prefer lightweight, self-contained MCP servers or external services\nMCPToolset(\n    connection_params=SseConnectionParams(\n        url=\"https://your-managed-mcp-service.googleapis.com/sse\",\n        headers={'Authorization': 'Bearer $(gcloud auth print-access-token)'}\n    ),\n)"}]}, {"heading_path": ["Troubleshooting Deployment Issues\u00b6"], "text": "Troubleshooting Deployment Issues \u00b6 Common MCP Deployment Problems: Stdio Process Startup Failures # Debug stdio connection issues MCPToolset ( connection_params = StdioConnectionParams ( server_params = StdioServerParameters ( command = 'npx' , args = [ \"-y\" , \"@modelcontextprotocol/server-filesystem\" , \"/app/data\" ], # Add environment debugging env = { 'DEBUG' : '1' } ), ), ) Network Connectivity Issues # Test remote MCP connectivity import aiohttp async def test_mcp_connection (): async with aiohttp . ClientSession () as session : async with session . get ( 'https://your-mcp-server.com/health' ) as resp : print ( f \"MCP Server Health: { resp . status } \" ) Resource Exhaustion Monitor container memory usage when using stdio MCP servers Set appropriate limits in Kubernetes deployments Use remote MCP servers for resource-intensive operations ", "code_blocks": [{"language": "text", "code": "# Debug stdio connection issues\nMCPToolset(\n    connection_params=StdioConnectionParams(\n        server_params=StdioServerParameters(\n            command='npx',\n            args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/app/data\"],\n            # Add environment debugging\n            env={'DEBUG': '1'}\n        ),\n    ),\n)"}, {"language": "text", "code": "# Test remote MCP connectivity\nimport aiohttp\n\nasync def test_mcp_connection():\n    async with aiohttp.ClientSession() as session:\n        async with session.get('https://your-mcp-server.com/health') as resp:\n            print(f\"MCP Server Health: {resp.status}\")"}]}, {"heading_path": ["Further Resources\u00b6"], "text": "Further Resources \u00b6 Model Context Protocol Documentation MCP Specification MCP Python SDK & Examples Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:21.289984", "source_type": "adk-docs"}
{"doc_id": "2026c97a4664914dcd6223e65495798603551eff5e375d7c97e4d9d5eeb1ed5d", "url": "https://google.github.io/adk-docs/tools-custom/openapi-tools", "title": "OpenAPI tools - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Integrate REST APIs with OpenAPI\u00b6"], "text": "Integrate REST APIs with OpenAPI \u00b6 Supported in ADK Python v0.1.0 ADK simplifies interacting with external REST APIs by automatically generating callable tools directly from an OpenAPI Specification (v3.x) . This eliminates the need to manually define individual function tools for each API endpoint. Core Benefit Use OpenAPIToolset to instantly create agent tools ( RestApiTool ) from your existing API documentation (OpenAPI spec), enabling agents to seamlessly call your web services. ", "code_blocks": []}, {"heading_path": ["Key Components\u00b6"], "text": "Key Components \u00b6 OpenAPIToolset : This is the primary class you'll use. You initialize it with your OpenAPI specification, and it handles the parsing and generation of tools. RestApiTool : This class represents a single, callable API operation (like GET /pets/{petId} or POST /pets ). OpenAPIToolset creates one RestApiTool instance for each operation defined in your spec. ", "code_blocks": []}, {"heading_path": ["How it Works\u00b6"], "text": "How it Works \u00b6 The process involves these main steps when you use OpenAPIToolset : Initialization & Parsing : You provide the OpenAPI specification to OpenAPIToolset either as a Python dictionary, a JSON string, or a YAML string. The toolset internally parses the spec, resolving any internal references ( $ref ) to understand the complete API structure. Operation Discovery : It identifies all valid API operations (e.g., GET , POST , PUT , DELETE ) defined within the paths object of your specification. Tool Generation : For each discovered operation, OpenAPIToolset automatically creates a corresponding RestApiTool instance. Tool Name : Derived from the operationId in the spec (converted to snake_case , max 60 chars). If operationId is missing, a name is generated from the method and path. Tool Description : Uses the summary or description from the operation for the LLM. API Details : Stores the required HTTP method, path, server base URL, parameters (path, query, header, cookie), and request body schema internally. RestApiTool Functionality : Each generated RestApiTool : Schema Generation : Dynamically creates a FunctionDeclaration based on the operation's parameters and request body. This schema tells the LLM how to call the tool (what arguments are expected). Execution : When called by the LLM, it constructs the correct HTTP request (URL, headers, query params, body) using the arguments provided by the LLM and the details from the OpenAPI spec. It handles authentication (if configured) and executes the API call using the requests library. Response Handling : Returns the API response (typically JSON) back to the agent flow. Authentication : You can configure global authentication (like API keys or OAuth - see Authentication for details) when initializing OpenAPIToolset . This authentication configuration is automatically applied to all generated RestApiTool instances. ", "code_blocks": []}, {"heading_path": ["Usage Workflow\u00b6"], "text": "Usage Workflow \u00b6 Follow these steps to integrate an OpenAPI spec into your agent: Obtain Spec : Get your OpenAPI specification document (e.g., load from a .json or .yaml file, fetch from a URL). Instantiate Toolset : Create an OpenAPIToolset instance, passing the spec content and type ( spec_str / spec_dict , spec_str_type ). Provide authentication details ( auth_scheme , auth_credential ) if required by the API. from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset # Example with a JSON string openapi_spec_json = '...' # Your OpenAPI JSON string toolset = OpenAPIToolset ( spec_str = openapi_spec_json , spec_str_type = \"json\" ) # Example with a dictionary # openapi_spec_dict = {...} # Your OpenAPI spec as a dict # toolset = OpenAPIToolset(spec_dict=openapi_spec_dict) Add to Agent : Include the retrieved tools in your LlmAgent 's tools list. from google.adk.agents import LlmAgent my_agent = LlmAgent ( name = \"api_interacting_agent\" , model = \"gemini-2.0-flash\" , # Or your preferred model tools = [ toolset ], # Pass the toolset # ... other agent config ... ) Instruct Agent : Update your agent's instructions to inform it about the new API capabilities and the names of the tools it can use (e.g., list_pets , create_pet ). The tool descriptions generated from the spec will also help the LLM. Run Agent : Execute your agent using the Runner . When the LLM determines it needs to call one of the APIs, it will generate a function call targeting the appropriate RestApiTool , which will then handle the HTTP request automatically. ", "code_blocks": [{"language": "text", "code": "from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset\n\n# Example with a JSON string\nopenapi_spec_json = '...' # Your OpenAPI JSON string\ntoolset = OpenAPIToolset(spec_str=openapi_spec_json, spec_str_type=\"json\")\n\n# Example with a dictionary\n# openapi_spec_dict = {...} # Your OpenAPI spec as a dict\n# toolset = OpenAPIToolset(spec_dict=openapi_spec_dict)"}, {"language": "text", "code": "from google.adk.agents import LlmAgent\n\nmy_agent = LlmAgent(\n    name=\"api_interacting_agent\",\n    model=\"gemini-2.0-flash\", # Or your preferred model\n    tools=[toolset], # Pass the toolset\n    # ... other agent config ...\n)"}]}, {"heading_path": ["Example\u00b6"], "text": "Example \u00b6 This example demonstrates generating tools from a simple Pet Store OpenAPI spec (using httpbin.org for mock responses) and interacting with them via an agent. Code: Pet Store API openapi_example.py # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import asyncio import uuid # For unique session IDs from dotenv import load_dotenv from google.adk.agents import LlmAgent from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.genai import types # --- OpenAPI Tool Imports --- from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset # --- Load Environment Variables (If ADK tools need them, e.g., API keys) --- load_dotenv () # Create a .env file in the same directory if needed # --- Constants --- APP_NAME_OPENAPI = \"openapi_petstore_app\" USER_ID_OPENAPI = \"user_openapi_1\" SESSION_ID_OPENAPI = f \"session_openapi_ { uuid . uuid4 () } \" # Unique session ID AGENT_NAME_OPENAPI = \"petstore_manager_agent\" GEMINI_MODEL = \"gemini-2.0-flash\" # --- Sample OpenAPI Specification (JSON String) --- # A basic Pet Store API example using httpbin.org as a mock server openapi_spec_string = \"\"\" { \"openapi\": \"3.0.0\", \"info\": { \"title\": \"Simple Pet Store API (Mock)\", \"version\": \"1.0.1\", \"description\": \"An API to manage pets in a store, using httpbin for responses.\" }, \"servers\": [ { \"url\": \"https://httpbin.org\", \"description\": \"Mock server (httpbin.org)\" } ], \"paths\": { \"/get\": { \"get\": { \"summary\": \"List all pets (Simulated)\", \"operationId\": \"listPets\", \"description\": \"Simulates returning a list of pets. Uses httpbin's /get endpoint which echoes query parameters.\", \"parameters\": [ { \"name\": \"limit\", \"in\": \"query\", \"description\": \"Maximum number of pets to return\", \"required\": false, \"schema\": { \"type\": \"integer\", \"format\": \"int32\" } }, { \"name\": \"status\", \"in\": \"query\", \"description\": \"Filter pets by status\", \"required\": false, \"schema\": { \"type\": \"string\", \"enum\": [\"available\", \"pending\", \"sold\"] } } ], \"responses\": { \"200\": { \"description\": \"A list of pets (echoed query params).\", \"content\": { \"application/json\": { \"schema\": { \"type\": \"object\" } } } } } } }, \"/post\": { \"post\": { \"summary\": \"Create a pet (Simulated)\", \"operationId\": \"createPet\", \"description\": \"Simulates adding a new pet. Uses httpbin's /post endpoint which echoes the request body.\", \"requestBody\": { \"description\": \"Pet object to add\", \"required\": true, \"content\": { \"application/json\": { \"schema\": { \"type\": \"object\", \"required\": [\"name\"], \"properties\": { \"name\": {\"type\": \"string\", \"description\": \"Name of the pet\"}, \"tag\": {\"type\": \"string\", \"description\": \"Optional tag for the pet\"} } } } } }, \"responses\": { \"201\": { \"description\": \"Pet created successfully (echoed request body).\", \"content\": { \"application/json\": { \"schema\": { \"type\": \"object\" } } } } } } }, \"/get?petId= {petId} \": { \"get\": { \"summary\": \"Info for a specific pet (Simulated)\", \"operationId\": \"showPetById\", \"description\": \"Simulates returning info for a pet ID. Uses httpbin's /get endpoint.\", \"parameters\": [ { \"name\": \"petId\", \"in\": \"path\", \"description\": \"This is actually passed as a query param to httpbin /get\", \"required\": true, \"schema\": { \"type\": \"integer\", \"format\": \"int64\" } } ], \"responses\": { \"200\": { \"description\": \"Information about the pet (echoed query params)\", \"content\": { \"application/json\": { \"schema\": { \"type\": \"object\" } } } }, \"404\": { \"description\": \"Pet not found (simulated)\" } } } } } } \"\"\" # --- Create OpenAPIToolset --- petstore_toolset = OpenAPIToolset ( spec_str = openapi_spec_string , spec_str_type = 'json' , # No authentication needed for httpbin.org ) # --- Agent Definition --- root_agent = LlmAgent ( name = AGENT_NAME_OPENAPI , model = GEMINI_MODEL , tools = [ petstore_toolset ], # Pass the list of RestApiTool objects instruction = \"\"\"You are a Pet Store assistant managing pets via an API. Use the available tools to fulfill user requests. When creating a pet, confirm the details echoed back by the API. When listing pets, mention any filters used (like limit or status). When showing a pet by ID, state the ID you requested. \"\"\" , description = \"Manages a Pet Store using tools generated from an OpenAPI spec.\" ) # --- Session and Runner Setup --- async def setup_session_and_runner (): session_service_openapi = InMemorySessionService () runner_openapi = Runner ( agent = root_agent , app_name = APP_NAME_OPENAPI , session_service = session_service_openapi , ) await session_service_openapi . create_session ( app_name = APP_NAME_OPENAPI , user_id = USER_ID_OPENAPI , session_id = SESSION_ID_OPENAPI , ) return runner_openapi # --- Agent Interaction Function --- async def call_openapi_agent_async ( query , runner_openapi ): print ( \" \\n --- Running OpenAPI Pet Store Agent ---\" ) print ( f \"Query: { query } \" ) content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) final_response_text = \"Agent did not provide a final text response.\" try : async for event in runner_openapi . run_async ( user_id = USER_ID_OPENAPI , session_id = SESSION_ID_OPENAPI , new_message = content ): # Optional: Detailed event logging for debugging # print(f\"  DEBUG Event: Author={event.author}, Type={'Final' if event.is_final_response() else 'Intermediate'}, Content={str(event.content)[:100]}...\") if event . get_function_calls (): call = event . get_function_calls ()[ 0 ] print ( f \"  Agent Action: Called function ' { call . name } ' with args { call . args } \" ) elif event . get_function_responses (): response = event . get_function_responses ()[ 0 ] print ( f \"  Agent Action: Received response for ' { response . name } '\" ) # print(f\"  Tool Response Snippet: {str(response.response)[:200]}...\") # Uncomment for response details elif event . is_final_response () and event . content and event . content . parts : # Capture the last final text response final_response_text = event . content . parts [ 0 ] . text . strip () print ( f \"Agent Final Response: { final_response_text } \" ) except Exception as e : print ( f \"An error occurred during agent run: { e } \" ) import traceback traceback . print_exc () # Print full traceback for errors print ( \"-\" * 30 ) # --- Run Examples --- async def run_openapi_example (): runner_openapi = await setup_session_and_runner () # Trigger listPets await call_openapi_agent_async ( \"Show me the pets available.\" , runner_openapi ) # Trigger createPet await call_openapi_agent_async ( \"Please add a new dog named 'Dukey'.\" , runner_openapi ) # Trigger showPetById await call_openapi_agent_async ( \"Get info for pet with ID 123.\" , runner_openapi ) # --- Execute --- if __name__ == \"__main__\" : print ( \"Executing OpenAPI example...\" ) # Use asyncio.run() for top-level execution try : asyncio . run ( run_openapi_example ()) except RuntimeError as e : if \"cannot be called from a running event loop\" in str ( e ): print ( \"Info: Cannot run asyncio.run from a running event loop (e.g., Jupyter/Colab).\" ) # If in Jupyter/Colab, you might need to run like this: # await run_openapi_example() else : raise e print ( \"OpenAPI example finished.\" ) Back to top ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\nimport uuid # For unique session IDs\nfrom dotenv import load_dotenv\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\n# --- OpenAPI Tool Imports ---\nfrom google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset\n\n# --- Load Environment Variables (If ADK tools need them, e.g., API keys) ---\nload_dotenv() # Create a .env file in the same directory if needed\n\n# --- Constants ---\nAPP_NAME_OPENAPI = \"openapi_petstore_app\"\nUSER_ID_OPENAPI = \"user_openapi_1\"\nSESSION_ID_OPENAPI = f\"session_openapi_{uuid.uuid4()}\" # Unique session ID\nAGENT_NAME_OPENAPI = \"petstore_manager_agent\"\nGEMINI_MODEL = \"gemini-2.0-flash\"\n\n# --- Sample OpenAPI Specification (JSON String) ---\n# A basic Pet Store API example using httpbin.org as a mock server\nopenapi_spec_string = \"\"\"\n{\n  \"openapi\": \"3.0.0\",\n  \"info\": {\n    \"title\": \"Simple Pet Store API (Mock)\",\n    \"version\": \"1.0.1\",\n    \"description\": \"An API to manage pets in a store, using httpbin for responses.\"\n  },\n  \"servers\": [\n    {\n      \"url\": \"https://httpbin.org\",\n      \"description\": \"Mock server (httpbin.org)\"\n    }\n  ],\n  \"paths\": {\n    \"/get\": {\n      \"get\": {\n        \"summary\": \"List all pets (Simulated)\",\n        \"operationId\": \"listPets\",\n        \"description\": \"Simulates returning a list of pets. Uses httpbin's /get endpoint which echoes query parameters.\",\n        \"parameters\": [\n          {\n            \"name\": \"limit\",\n            \"in\": \"query\",\n            \"description\": \"Maximum number of pets to return\",\n            \"required\": false,\n            \"schema\": { \"type\": \"integer\", \"format\": \"int32\" }\n          },\n          {\n             \"name\": \"status\",\n             \"in\": \"query\",\n             \"description\": \"Filter pets by status\",\n             \"required\": false,\n             \"schema\": { \"type\": \"string\", \"enum\": [\"available\", \"pending\", \"sold\"] }\n          }\n        ],\n        \"responses\": {\n          \"200\": {\n            \"description\": \"A list of pets (echoed query params).\",\n            \"content\": { \"application/json\": { \"schema\": { \"type\": \"object\" } } }\n          }\n        }\n      }\n    },\n    \"/post\": {\n      \"post\": {\n        \"summary\": \"Create a pet (Simulated)\",\n        \"operationId\": \"createPet\",\n        \"description\": \"Simulates adding a new pet. Uses httpbin's /post endpoint which echoes the request body.\",\n        \"requestBody\": {\n          \"description\": \"Pet object to add\",\n          \"required\": true,\n          \"content\": {\n            \"application/json\": {\n              \"schema\": {\n                \"type\": \"object\",\n                \"required\": [\"name\"],\n                \"properties\": {\n                  \"name\": {\"type\": \"string\", \"description\": \"Name of the pet\"},\n                  \"tag\": {\"type\": \"string\", \"description\": \"Optional tag for the pet\"}\n                }\n              }\n            }\n          }\n        },\n        \"responses\": {\n          \"201\": {\n            \"description\": \"Pet created successfully (echoed request body).\",\n            \"content\": { \"application/json\": { \"schema\": { \"type\": \"object\" } } }\n          }\n        }\n      }\n    },\n    \"/get?petId={petId}\": {\n      \"get\": {\n        \"summary\": \"Info for a specific pet (Simulated)\",\n        \"operationId\": \"showPetById\",\n        \"description\": \"Simulates returning info for a pet ID. Uses httpbin's /get endpoint.\",\n        \"parameters\": [\n          {\n            \"name\": \"petId\",\n            \"in\": \"path\",\n            \"description\": \"This is actually passed as a query param to httpbin /get\",\n            \"required\": true,\n            \"schema\": { \"type\": \"integer\", \"format\": \"int64\" }\n          }\n        ],\n        \"responses\": {\n          \"200\": {\n            \"description\": \"Information about the pet (echoed query params)\",\n            \"content\": { \"application/json\": { \"schema\": { \"type\": \"object\" } } }\n          },\n          \"404\": { \"description\": \"Pet not found (simulated)\" }\n        }\n      }\n    }\n  }\n}\n\"\"\"\n\n# --- Create OpenAPIToolset ---\npetstore_toolset = OpenAPIToolset(\n    spec_str=openapi_spec_string,\n    spec_str_type='json',\n    # No authentication needed for httpbin.org\n)\n\n# --- Agent Definition ---\nroot_agent = LlmAgent(\n    name=AGENT_NAME_OPENAPI,\n    model=GEMINI_MODEL,\n    tools=[petstore_toolset], # Pass the list of RestApiTool objects\n    instruction=\"\"\"You are a Pet Store assistant managing pets via an API.\n    Use the available tools to fulfill user requests.\n    When creating a pet, confirm the details echoed back by the API.\n    When listing pets, mention any filters used (like limit or status).\n    When showing a pet by ID, state the ID you requested.\n    \"\"\",\n    description=\"Manages a Pet Store using tools generated from an OpenAPI spec.\"\n)\n\n# --- Session and Runner Setup ---\nasync def setup_session_and_runner():\n    session_service_openapi = InMemorySessionService()\n    runner_openapi = Runner(\n        agent=root_agent,\n        app_name=APP_NAME_OPENAPI,\n        session_service=session_service_openapi,\n    )\n    await session_service_openapi.create_session(\n        app_name=APP_NAME_OPENAPI,\n        user_id=USER_ID_OPENAPI,\n        session_id=SESSION_ID_OPENAPI,\n    )\n    return runner_openapi\n\n# --- Agent Interaction Function ---\nasync def call_openapi_agent_async(query, runner_openapi):\n    print(\"\\n--- Running OpenAPI Pet Store Agent ---\")\n    print(f\"Query: {query}\")\n\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    final_response_text = \"Agent did not provide a final text response.\"\n    try:\n        async for event in runner_openapi.run_async(\n            user_id=USER_ID_OPENAPI, session_id=SESSION_ID_OPENAPI, new_message=content\n            ):\n            # Optional: Detailed event logging for debugging\n            # print(f\"  DEBUG Event: Author={event.author}, Type={'Final' if event.is_final_response() else 'Intermediate'}, Content={str(event.content)[:100]}...\")\n            if event.get_function_calls():\n                call = event.get_function_calls()[0]\n                print(f\"  Agent Action: Called function '{call.name}' with args {call.args}\")\n            elif event.get_function_responses():\n                response = event.get_function_responses()[0]\n                print(f\"  Agent Action: Received response for '{response.name}'\")\n                # print(f\"  Tool Response Snippet: {str(response.response)[:200]}...\") # Uncomment for response details\n            elif event.is_final_response() and event.content and event.content.parts:\n                # Capture the last final text response\n                final_response_text = event.content.parts[0].text.strip()\n\n        print(f\"Agent Final Response: {final_response_text}\")\n\n    except Exception as e:\n        print(f\"An error occurred during agent run: {e}\")\n        import traceback\n        traceback.print_exc() # Print full traceback for errors\n    print(\"-\" * 30)\n\n# --- Run Examples ---\nasync def run_openapi_example():\n    runner_openapi = await setup_session_and_runner()\n\n    # Trigger listPets\n    await call_openapi_agent_async(\"Show me the pets available.\", runner_openapi)\n    # Trigger createPet\n    await call_openapi_agent_async(\"Please add a new dog named 'Dukey'.\", runner_openapi)\n    # Trigger showPetById\n    await call_openapi_agent_async(\"Get info for pet with ID 123.\", runner_openapi)\n\n# --- Execute ---\nif __name__ == \"__main__\":\n    print(\"Executing OpenAPI example...\")\n    # Use asyncio.run() for top-level execution\n    try:\n        asyncio.run(run_openapi_example())\n    except RuntimeError as e:\n        if \"cannot be called from a running event loop\" in str(e):\n            print(\"Info: Cannot run asyncio.run from a running event loop (e.g., Jupyter/Colab).\")\n            # If in Jupyter/Colab, you might need to run like this:\n            # await run_openapi_example()\n        else:\n            raise e\n    print(\"OpenAPI example finished.\")"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:21.532883", "source_type": "adk-docs"}
{"doc_id": "7f3ac8dc79bb0a20ee4bdc6d600bfdc670c90f1d063ca0a81a1499d4c743ec9e", "url": "https://google.github.io/adk-docs/tools-custom/authentication", "title": "Authentication - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Authenticating with Tools\u00b6"], "text": "Authenticating with Tools \u00b6 Supported in ADK Python v0.1.0 Many tools need to access protected resources (like user data in Google Calendar, Salesforce records, etc.) and require authentication. ADK provides a system to handle various authentication methods securely. The key components involved are: AuthScheme : Defines how an API expects authentication credentials (e.g., as an API Key in a header, an OAuth 2.0 Bearer token). ADK supports the same types of authentication schemes as OpenAPI 3.0. To know more about what each type of credential is, refer to OpenAPI doc: Authentication . ADK uses specific classes like APIKey , HTTPBearer , OAuth2 , OpenIdConnectWithConfig . AuthCredential : Holds the initial information needed to start the authentication process (e.g., your application's OAuth Client ID/Secret, an API key value). It includes an auth_type (like API_KEY , OAUTH2 , SERVICE_ACCOUNT ) specifying the credential type. The general flow involves providing these details when configuring a tool. ADK then attempts to automatically exchange the initial credential for a usable one (like an access token) before the tool makes an API call. For flows requiring user interaction (like OAuth consent), a specific interactive process involving the Agent Client application is triggered. ", "code_blocks": []}, {"heading_path": ["Supported Initial Credential Types\u00b6"], "text": "Supported Initial Credential Types \u00b6 API_KEY: For simple key/value authentication. Usually requires no exchange. HTTP: Can represent Basic Auth (not recommended/supported for exchange) or already obtained Bearer tokens. If it's a Bearer token, no exchange is needed. OAUTH2: For standard OAuth 2.0 flows. Requires configuration (client ID, secret, scopes) and often triggers the interactive flow for user consent. OPEN_ID_CONNECT: For authentication based on OpenID Connect. Similar to OAuth2, often requires configuration and user interaction. SERVICE_ACCOUNT: For Google Cloud Service Account credentials (JSON key or Application Default Credentials). Typically exchanged for a Bearer token. ", "code_blocks": []}, {"heading_path": ["Configuring Authentication on Tools\u00b6"], "text": "Configuring Authentication on Tools \u00b6 You set up authentication when defining your tool: RestApiTool / OpenAPIToolset : Pass auth_scheme and auth_credential during initialization GoogleApiToolSet Tools : ADK has built-in 1st party tools like Google Calendar, BigQuery etc,. Use the toolset's specific method. APIHubToolset / ApplicationIntegrationToolset : Pass auth_scheme and auth_credential during initialization, if the API managed in API Hub / provided by Application Integration requires authentication. WARNING Storing sensitive credentials like access tokens and especially refresh tokens directly in the session state might pose security risks depending on your session storage backend ( SessionService ) and overall application security posture. InMemorySessionService : Suitable for testing and development, but data is lost when the process ends. Less risk as it's transient. Database/Persistent Storage: Strongly consider encrypting the token data before storing it in the database using a robust encryption library (like cryptography ) and managing encryption keys securely (e.g., using a key management service). Secure Secret Stores: For production environments, storing sensitive credentials in a dedicated secret manager (like Google Cloud Secret Manager or HashiCorp Vault) is the most recommended approach . Your tool could potentially store only short-lived access tokens or secure references (not the refresh token itself) in the session state, fetching the necessary secrets from the secure store when needed. ", "code_blocks": []}, {"heading_path": ["Journey 1: Building Agentic Applications with Authenticated Tools\u00b6"], "text": "Journey 1: Building Agentic Applications with Authenticated Tools \u00b6 This section focuses on using pre-existing tools (like those from RestApiTool/ OpenAPIToolset , APIHubToolset , GoogleApiToolSet ) that require authentication within your agentic application. Your main responsibility is configuring the tools and handling the client-side part of interactive authentication flows (if required by the tool). ", "code_blocks": []}, {"heading_path": ["1. Configuring Tools with Authentication\u00b6"], "text": "1. Configuring Tools with Authentication \u00b6 When adding an authenticated tool to your agent, you need to provide its required AuthScheme and your application's initial AuthCredential . A. Using OpenAPI-based Toolsets ( OpenAPIToolset , APIHubToolset , etc.) Pass the scheme and credential during toolset initialization. The toolset applies them to all generated tools. Here are few ways to create tools with authentication in ADK. API Key OAuth2 Service Account OpenID connect Create a tool requiring an API Key. from google.adk.tools.openapi_tool.auth.auth_helpers import token_to_scheme_credential from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset auth_scheme , auth_credential = token_to_scheme_credential ( \"apikey\" , \"query\" , \"apikey\" , \"YOUR_API_KEY_STRING\" ) sample_api_toolset = OpenAPIToolset ( spec_str = \"...\" , # Fill this with an OpenAPI spec string spec_str_type = \"yaml\" , auth_scheme = auth_scheme , auth_credential = auth_credential , ) Create a tool requiring OAuth2. from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset from fastapi.openapi.models import OAuth2 from fastapi.openapi.models import OAuthFlowAuthorizationCode from fastapi.openapi.models import OAuthFlows from google.adk.auth import AuthCredential from google.adk.auth import AuthCredentialTypes from google.adk.auth import OAuth2Auth auth_scheme = OAuth2 ( flows = OAuthFlows ( authorizationCode = OAuthFlowAuthorizationCode ( authorizationUrl = \"https://accounts.google.com/o/oauth2/auth\" , tokenUrl = \"https://oauth2.googleapis.com/token\" , scopes = { \"https://www.googleapis.com/auth/calendar\" : \"calendar scope\" }, ) ) ) auth_credential = AuthCredential ( auth_type = AuthCredentialTypes . OAUTH2 , oauth2 = OAuth2Auth ( client_id = YOUR_OAUTH_CLIENT_ID , client_secret = YOUR_OAUTH_CLIENT_SECRET ), ) calendar_api_toolset = OpenAPIToolset ( spec_str = google_calendar_openapi_spec_str , # Fill this with an openapi spec spec_str_type = 'yaml' , auth_scheme = auth_scheme , auth_credential = auth_credential , ) Create a tool requiring Service Account. from google.adk.tools.openapi_tool.auth.auth_helpers import service_account_dict_to_scheme_credential from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset service_account_cred = json . loads ( service_account_json_str ) auth_scheme , auth_credential = service_account_dict_to_scheme_credential ( config = service_account_cred , scopes = [ \"https://www.googleapis.com/auth/cloud-platform\" ], ) sample_toolset = OpenAPIToolset ( spec_str = sa_openapi_spec_str , # Fill this with an openapi spec spec_str_type = 'json' , auth_scheme = auth_scheme , auth_credential = auth_credential , ) Create a tool requiring OpenID connect. from google.adk.auth.auth_schemes import OpenIdConnectWithConfig from google.adk.auth.auth_credential import AuthCredential , AuthCredentialTypes , OAuth2Auth from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset auth_scheme = OpenIdConnectWithConfig ( authorization_endpoint = OAUTH2_AUTH_ENDPOINT_URL , token_endpoint = OAUTH2_TOKEN_ENDPOINT_URL , scopes = [ 'openid' , 'YOUR_OAUTH_SCOPES\"] ) auth_credential = AuthCredential ( auth_type = AuthCredentialTypes . OPEN_ID_CONNECT , oauth2 = OAuth2Auth ( client_id = \"...\" , client_secret = \"...\" , ) ) userinfo_toolset = OpenAPIToolset ( spec_str = content , # Fill in an actual spec spec_str_type = 'yaml' , auth_scheme = auth_scheme , auth_credential = auth_credential , ) B. Using Google API Toolsets (e.g., calendar_tool_set ) These toolsets often have dedicated configuration methods. Tip: For how to create a Google OAuth Client ID & Secret, see this guide: Get your Google API Client ID # Example: Configuring Google Calendar Tools from google.adk.tools.google_api_tool import calendar_tool_set client_id = \"YOUR_GOOGLE_OAUTH_CLIENT_ID.apps.googleusercontent.com\" client_secret = \"YOUR_GOOGLE_OAUTH_CLIENT_SECRET\" # Use the specific configure method for this toolset type calendar_tool_set . configure_auth ( client_id = oauth_client_id , client_secret = oauth_client_secret ) # agent = LlmAgent(..., tools=calendar_tool_set.get_tool('calendar_tool_set')) The sequence diagram of auth request flow (where tools are requesting auth credentials) looks like below: ", "code_blocks": [{"language": "text", "code": "from google.adk.tools.openapi_tool.auth.auth_helpers import token_to_scheme_credential\nfrom google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset\n\nauth_scheme, auth_credential = token_to_scheme_credential(\n    \"apikey\", \"query\", \"apikey\", \"YOUR_API_KEY_STRING\"\n)\nsample_api_toolset = OpenAPIToolset(\n    spec_str=\"...\",  # Fill this with an OpenAPI spec string\n    spec_str_type=\"yaml\",\n    auth_scheme=auth_scheme,\n    auth_credential=auth_credential,\n)"}, {"language": "text", "code": "from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset\nfrom fastapi.openapi.models import OAuth2\nfrom fastapi.openapi.models import OAuthFlowAuthorizationCode\nfrom fastapi.openapi.models import OAuthFlows\nfrom google.adk.auth import AuthCredential\nfrom google.adk.auth import AuthCredentialTypes\nfrom google.adk.auth import OAuth2Auth\n\nauth_scheme = OAuth2(\n    flows=OAuthFlows(\n        authorizationCode=OAuthFlowAuthorizationCode(\n            authorizationUrl=\"https://accounts.google.com/o/oauth2/auth\",\n            tokenUrl=\"https://oauth2.googleapis.com/token\",\n            scopes={\n                \"https://www.googleapis.com/auth/calendar\": \"calendar scope\"\n            },\n        )\n    )\n)\nauth_credential = AuthCredential(\n    auth_type=AuthCredentialTypes.OAUTH2,\n    oauth2=OAuth2Auth(\n        client_id=YOUR_OAUTH_CLIENT_ID, \n        client_secret=YOUR_OAUTH_CLIENT_SECRET\n    ),\n)\n\ncalendar_api_toolset = OpenAPIToolset(\n    spec_str=google_calendar_openapi_spec_str, # Fill this with an openapi spec\n    spec_str_type='yaml',\n    auth_scheme=auth_scheme,\n    auth_credential=auth_credential,\n)"}, {"language": "text", "code": "from google.adk.tools.openapi_tool.auth.auth_helpers import service_account_dict_to_scheme_credential\nfrom google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset\n\nservice_account_cred = json.loads(service_account_json_str)\nauth_scheme, auth_credential = service_account_dict_to_scheme_credential(\n    config=service_account_cred,\n    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n)\nsample_toolset = OpenAPIToolset(\n    spec_str=sa_openapi_spec_str, # Fill this with an openapi spec\n    spec_str_type='json',\n    auth_scheme=auth_scheme,\n    auth_credential=auth_credential,\n)"}, {"language": "text", "code": "from google.adk.auth.auth_schemes import OpenIdConnectWithConfig\nfrom google.adk.auth.auth_credential import AuthCredential, AuthCredentialTypes, OAuth2Auth\nfrom google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset\n\nauth_scheme = OpenIdConnectWithConfig(\n    authorization_endpoint=OAUTH2_AUTH_ENDPOINT_URL,\n    token_endpoint=OAUTH2_TOKEN_ENDPOINT_URL,\n    scopes=['openid', 'YOUR_OAUTH_SCOPES\"]\n)\nauth_credential = AuthCredential(\n    auth_type=AuthCredentialTypes.OPEN_ID_CONNECT,\n    oauth2=OAuth2Auth(\n        client_id=\"...\",\n        client_secret=\"...\",\n    )\n)\n\nuserinfo_toolset = OpenAPIToolset(\n    spec_str=content, # Fill in an actual spec\n    spec_str_type='yaml',\n    auth_scheme=auth_scheme,\n    auth_credential=auth_credential,\n)"}, {"language": "text", "code": "# Example: Configuring Google Calendar Tools\nfrom google.adk.tools.google_api_tool import calendar_tool_set\n\nclient_id = \"YOUR_GOOGLE_OAUTH_CLIENT_ID.apps.googleusercontent.com\"\nclient_secret = \"YOUR_GOOGLE_OAUTH_CLIENT_SECRET\"\n\n# Use the specific configure method for this toolset type\ncalendar_tool_set.configure_auth(\n    client_id=oauth_client_id, client_secret=oauth_client_secret\n)\n\n# agent = LlmAgent(..., tools=calendar_tool_set.get_tool('calendar_tool_set'))"}]}, {"heading_path": ["2. Handling the Interactive OAuth/OIDC Flow (Client-Side)\u00b6"], "text": "2. Handling the Interactive OAuth/OIDC Flow (Client-Side) \u00b6 If a tool requires user login/consent (typically OAuth 2.0 or OIDC), the ADK framework pauses execution and signals your Agent Client application. There are two cases: Agent Client application runs the agent directly (via runner.run_async ) in the same process. e.g. UI backend, CLI app, or Spark job etc. Agent Client application interacts with ADK's fastapi server via /run or /run_sse endpoint. While ADK's fastapi server could be setup on the same server or different server as Agent Client application The second case is a special case of first case, because /run or /run_sse endpoint also invokes runner.run_async . The only differences are: Whether to call a python function to run the agent (first case) or call a service endpoint to run the agent (second case). Whether the result events are in-memory objects (first case) or serialized json string in http response (second case). Below sections focus on the first case and you should be able to map it to the second case very straightforward. We will also describe some differences to handle for the second case if necessary. Here's the step-by-step process for your client application: Step 1: Run Agent & Detect Auth Request Initiate the agent interaction using runner.run_async . Iterate through the yielded events. Look for a specific function call event whose function call has a special name: adk_request_credential . This event signals that user interaction is needed. You can use helper functions to identify this event and extract necessary information. (For the second case, the logic is similar. You deserialize the event from the http response). # runner = Runner(...) # session = await session_service.create_session(...) # content = types.Content(...) # User's initial query print ( \" \\n Running agent...\" ) events_async = runner . run_async ( session_id = session . id , user_id = 'user' , new_message = content ) auth_request_function_call_id , auth_config = None , None async for event in events_async : # Use helper to check for the specific auth request event if ( auth_request_function_call := get_auth_request_function_call ( event )): print ( \"--> Authentication required by agent.\" ) # Store the ID needed to respond later if not ( auth_request_function_call_id := auth_request_function_call . id ): raise ValueError ( f 'Cannot get function call id from function call: { auth_request_function_call } ' ) # Get the AuthConfig containing the auth_uri etc. auth_config = get_auth_config ( auth_request_function_call ) break # Stop processing events for now, need user interaction if not auth_request_function_call_id : print ( \" \\n Auth not required or agent finished.\" ) # return # Or handle final response if received Helper functions helpers.py : from google.adk.events import Event from google.adk.auth import AuthConfig # Import necessary type from google.genai import types def get_auth_request_function_call ( event : Event ) -> types . FunctionCall : # Get the special auth request function call from the event if not event . content or not event . content . parts : return for part in event . content . parts : if ( part and part . function_call and part . function_call . name == 'adk_request_credential' and event . long_running_tool_ids and part . function_call . id in event . long_running_tool_ids ): return part . function_call def get_auth_config ( auth_request_function_call : types . FunctionCall ) -> AuthConfig : # Extracts the AuthConfig object from the arguments of the auth request function call if not auth_request_function_call . args or not ( auth_config := auth_request_function_call . args . get ( 'authConfig' )): raise ValueError ( f 'Cannot get auth config from function call: { auth_request_function_call } ' ) if isinstance ( auth_config , dict ): auth_config = AuthConfig . model_validate ( auth_config ) elif not isinstance ( auth_config , AuthConfig ): raise ValueError ( f 'Cannot get auth config { auth_config } is not an instance of AuthConfig.' ) return auth_config Step 2: Redirect User for Authorization Get the authorization URL ( auth_uri ) from the auth_config extracted in the previous step. Crucially, append your application's redirect_uri as a query parameter to this auth_uri . This redirect_uri must be pre-registered with your OAuth provider (e.g., Google Cloud Console , Okta admin panel ). Direct the user to this complete URL (e.g., open it in their browser). # (Continuing after detecting auth needed) if auth_request_function_call_id and auth_config : # Get the base authorization URL from the AuthConfig base_auth_uri = auth_config . exchanged_auth_credential . oauth2 . auth_uri if base_auth_uri : redirect_uri = 'http://localhost:8000/callback' # MUST match your OAuth client app config # Append redirect_uri (use urlencode in production) auth_request_uri = base_auth_uri + f '&redirect_uri= { redirect_uri } ' # Now you need to redirect your end user to this auth_request_uri or ask them to open this auth_request_uri in their browser # This auth_request_uri should be served by the corresponding auth provider and the end user should login and authorize your applicaiton to access their data # And then the auth provider will redirect the end user to the redirect_uri you provided # Next step: Get this callback URL from the user (or your web server handler) else : print ( \"ERROR: Auth URI not found in auth_config.\" ) # Handle error Step 3. Handle the Redirect Callback (Client): Your application must have a mechanism (e.g., a web server route at the redirect_uri ) to receive the user after they authorize the application with the provider. The provider redirects the user to your redirect_uri and appends an authorization_code (and potentially state , scope ) as query parameters to the URL. Capture the full callback URL from this incoming request. (This step happens outside the main agent execution loop, in your web server or equivalent callback handler.) Step 4. Send Authentication Result Back to ADK (Client): Once you have the full callback URL (containing the authorization code), retrieve the auth_request_function_call_id and the auth_config object saved in Client Step 1. Set the captured callback URL into the exchanged_auth_credential.oauth2.auth_response_uri field. Also ensure exchanged_auth_credential.oauth2.redirect_uri contains the redirect URI you used. Create a types.Content object containing a types.Part with a types.FunctionResponse . Set name to \"adk_request_credential\" . (Note: This is a special name for ADK to proceed with authentication. Do not use other names.) Set id to the auth_request_function_call_id you saved. Set response to the serialized (e.g., .model_dump() ) updated AuthConfig object. Call runner.run_async again for the same session, passing this FunctionResponse content as the new_message . # (Continuing after user interaction) # Simulate getting the callback URL (e.g., from user paste or web handler) auth_response_uri = await get_user_input ( f 'Paste the full callback URL here: \\n > ' ) auth_response_uri = auth_response_uri . strip () # Clean input if not auth_response_uri : print ( \"Callback URL not provided. Aborting.\" ) return # Update the received AuthConfig with the callback details auth_config . exchanged_auth_credential . oauth2 . auth_response_uri = auth_response_uri # Also include the redirect_uri used, as the token exchange might need it auth_config . exchanged_auth_credential . oauth2 . redirect_uri = redirect_uri # Construct the FunctionResponse Content object auth_content = types . Content ( role = 'user' , # Role can be 'user' when sending a FunctionResponse parts = [ types . Part ( function_response = types . FunctionResponse ( id = auth_request_function_call_id , # Link to the original request name = 'adk_request_credential' , # Special framework function name response = auth_config . model_dump () # Send back the *updated* AuthConfig ) ) ], ) # --- Resume Execution --- print ( \" \\n Submitting authentication details back to the agent...\" ) events_async_after_auth = runner . run_async ( session_id = session . id , user_id = 'user' , new_message = auth_content , # Send the FunctionResponse back ) # --- Process Final Agent Output --- print ( \" \\n --- Agent Response after Authentication ---\" ) async for event in events_async_after_auth : # Process events normally, expecting the tool call to succeed now print ( event ) # Print the full event for inspection Note: Authorization response with Resume feature If your ADK agent workflow is configured with the Resume feature, you also must include\nthe Invocation ID ( invocation_id ) parameter with the authorization\nresponse. The Invocation ID you provide must be the same invocation\nthat generated the authorization request, otherwise the system\nstarts a new invocation with the authorization response. If your\nagent uses the Resume feature, consider including the Invocation ID\nas a parameter with your authorization request, so it can be included\nwith the authorization response. For more details on using the Resume \nfeature, see Resume stopped agents . Step 5: ADK Handles Token Exchange & Tool Retry and gets Tool result ADK receives the FunctionResponse for adk_request_credential . It uses the information in the updated AuthConfig (including the callback URL containing the code) to perform the OAuth token exchange with the provider's token endpoint, obtaining the access token (and possibly refresh token). ADK internally makes these tokens available by setting them in the session state). ADK automatically retries the original tool call (the one that initially failed due to missing auth). This time, the tool finds the valid tokens (via tool_context.get_auth_response() ) and successfully executes the authenticated API call. The agent receives the actual result from the tool and generates its final response to the user. The sequence diagram of auth response flow (where Agent Client send back the auth response and ADK retries tool calling) looks like below: ", "code_blocks": [{"language": "text", "code": "# runner = Runner(...)\n# session = await session_service.create_session(...)\n# content = types.Content(...) # User's initial query\n\nprint(\"\\nRunning agent...\")\nevents_async = runner.run_async(\n    session_id=session.id, user_id='user', new_message=content\n)\n\nauth_request_function_call_id, auth_config = None, None\n\nasync for event in events_async:\n    # Use helper to check for the specific auth request event\n    if (auth_request_function_call := get_auth_request_function_call(event)):\n        print(\"--> Authentication required by agent.\")\n        # Store the ID needed to respond later\n        if not (auth_request_function_call_id := auth_request_function_call.id):\n            raise ValueError(f'Cannot get function call id from function call: {auth_request_function_call}')\n        # Get the AuthConfig containing the auth_uri etc.\n        auth_config = get_auth_config(auth_request_function_call)\n        break # Stop processing events for now, need user interaction\n\nif not auth_request_function_call_id:\n    print(\"\\nAuth not required or agent finished.\")\n    # return # Or handle final response if received"}, {"language": "text", "code": "from google.adk.events import Event\nfrom google.adk.auth import AuthConfig # Import necessary type\nfrom google.genai import types\n\ndef get_auth_request_function_call(event: Event) -> types.FunctionCall:\n    # Get the special auth request function call from the event\n    if not event.content or not event.content.parts:\n        return\n    for part in event.content.parts:\n        if (\n            part \n            and part.function_call \n            and part.function_call.name == 'adk_request_credential'\n            and event.long_running_tool_ids \n            and part.function_call.id in event.long_running_tool_ids\n        ):\n\n            return part.function_call\n\ndef get_auth_config(auth_request_function_call: types.FunctionCall) -> AuthConfig:\n    # Extracts the AuthConfig object from the arguments of the auth request function call\n    if not auth_request_function_call.args or not (auth_config := auth_request_function_call.args.get('authConfig')):\n        raise ValueError(f'Cannot get auth config from function call: {auth_request_function_call}')\n    if isinstance(auth_config, dict):\n        auth_config = AuthConfig.model_validate(auth_config)\n    elif not isinstance(auth_config, AuthConfig):\n        raise ValueError(f'Cannot get auth config {auth_config} is not an instance of AuthConfig.')\n    return auth_config"}, {"language": "text", "code": "# (Continuing after detecting auth needed)\n\nif auth_request_function_call_id and auth_config:\n    # Get the base authorization URL from the AuthConfig\n    base_auth_uri = auth_config.exchanged_auth_credential.oauth2.auth_uri\n\n    if base_auth_uri:\n        redirect_uri = 'http://localhost:8000/callback' # MUST match your OAuth client app config\n        # Append redirect_uri (use urlencode in production)\n        auth_request_uri = base_auth_uri + f'&redirect_uri={redirect_uri}'\n        # Now you need to redirect your end user to this auth_request_uri or ask them to open this auth_request_uri in their browser\n        # This auth_request_uri should be served by the corresponding auth provider and the end user should login and authorize your applicaiton to access their data\n        # And then the auth provider will redirect the end user to the redirect_uri you provided\n        # Next step: Get this callback URL from the user (or your web server handler)\n    else:\n         print(\"ERROR: Auth URI not found in auth_config.\")\n         # Handle error"}, {"language": "text", "code": "# (Continuing after user interaction)\n\n    # Simulate getting the callback URL (e.g., from user paste or web handler)\n    auth_response_uri = await get_user_input(\n        f'Paste the full callback URL here:\\n> '\n    )\n    auth_response_uri = auth_response_uri.strip() # Clean input\n\n    if not auth_response_uri:\n        print(\"Callback URL not provided. Aborting.\")\n        return\n\n    # Update the received AuthConfig with the callback details\n    auth_config.exchanged_auth_credential.oauth2.auth_response_uri = auth_response_uri\n    # Also include the redirect_uri used, as the token exchange might need it\n    auth_config.exchanged_auth_credential.oauth2.redirect_uri = redirect_uri\n\n    # Construct the FunctionResponse Content object\n    auth_content = types.Content(\n        role='user', # Role can be 'user' when sending a FunctionResponse\n        parts=[\n            types.Part(\n                function_response=types.FunctionResponse(\n                    id=auth_request_function_call_id,       # Link to the original request\n                    name='adk_request_credential', # Special framework function name\n                    response=auth_config.model_dump() # Send back the *updated* AuthConfig\n                )\n            )\n        ],\n    )\n\n    # --- Resume Execution ---\n    print(\"\\nSubmitting authentication details back to the agent...\")\n    events_async_after_auth = runner.run_async(\n        session_id=session.id,\n        user_id='user',\n        new_message=auth_content, # Send the FunctionResponse back\n    )\n\n    # --- Process Final Agent Output ---\n    print(\"\\n--- Agent Response after Authentication ---\")\n    async for event in events_async_after_auth:\n        # Process events normally, expecting the tool call to succeed now\n        print(event) # Print the full event for inspection"}]}, {"heading_path": ["Journey 2: Building Custom Tools (FunctionTool) Requiring Authentication\u00b6"], "text": "Journey 2: Building Custom Tools ( FunctionTool ) Requiring Authentication \u00b6 This section focuses on implementing the authentication logic inside your custom Python function when creating a new ADK Tool. We will implement a FunctionTool as an example. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Your function signature must include tool_context: ToolContext . ADK automatically injects this object, providing access to state and auth mechanisms. from google.adk.tools import FunctionTool , ToolContext from typing import Dict def my_authenticated_tool_function ( param1 : str , ... , tool_context : ToolContext ) -> dict : # ... your logic ... pass my_tool = FunctionTool ( func = my_authenticated_tool_function ) ", "code_blocks": [{"language": "text", "code": "from google.adk.tools import FunctionTool, ToolContext\nfrom typing import Dict\n\ndef my_authenticated_tool_function(param1: str, ..., tool_context: ToolContext) -> dict:\n    # ... your logic ...\n    pass\n\nmy_tool = FunctionTool(func=my_authenticated_tool_function)"}]}, {"heading_path": ["Authentication Logic within the Tool Function\u00b6"], "text": "Authentication Logic within the Tool Function \u00b6 Implement the following steps inside your function: Step 1: Check for Cached & Valid Credentials: Inside your tool function, first check if valid credentials (e.g., access/refresh tokens) are already stored from a previous run in this session. Credentials for the current sessions should be stored in tool_context.invocation_context.session.state (a dictionary of state) Check existence of existing credentials by checking tool_context.invocation_context.session.state.get(credential_name, None) . from google.oauth2.credentials import Credentials from google.auth.transport.requests import Request # Inside your tool function TOKEN_CACHE_KEY = \"my_tool_tokens\" # Choose a unique key SCOPES = [ \"scope1\" , \"scope2\" ] # Define required scopes creds = None cached_token_info = tool_context . state . get ( TOKEN_CACHE_KEY ) if cached_token_info : try : creds = Credentials . from_authorized_user_info ( cached_token_info , SCOPES ) if not creds . valid and creds . expired and creds . refresh_token : creds . refresh ( Request ()) tool_context . state [ TOKEN_CACHE_KEY ] = json . loads ( creds . to_json ()) # Update cache elif not creds . valid : creds = None # Invalid, needs re-auth tool_context . state [ TOKEN_CACHE_KEY ] = None except Exception as e : print ( f \"Error loading/refreshing cached creds: { e } \" ) creds = None tool_context . state [ TOKEN_CACHE_KEY ] = None if creds and creds . valid : # Skip to Step 5: Make Authenticated API Call pass else : # Proceed to Step 2... pass Step 2: Check for Auth Response from Client If Step 1 didn't yield valid credentials, check if the client just completed the interactive flow by calling exchanged_credential = tool_context.get_auth_response() . This returns the updated exchanged_credential object sent back by the client (containing the callback URL in auth_response_uri ). # Use auth_scheme and auth_credential configured in the tool. # exchanged_credential: AuthCredential | None exchanged_credential = tool_context . get_auth_response ( AuthConfig ( auth_scheme = auth_scheme , raw_auth_credential = auth_credential , )) # If exchanged_credential is not None, then there is already an exchanged credetial from the auth response. if exchanged_credential : # ADK exchanged the access token already for us access_token = exchanged_credential . oauth2 . access_token refresh_token = exchanged_credential . oauth2 . refresh_token creds = Credentials ( token = access_token , refresh_token = refresh_token , token_uri = auth_scheme . flows . authorizationCode . tokenUrl , client_id = auth_credential . oauth2 . client_id , client_secret = auth_credential . oauth2 . client_secret , scopes = list ( auth_scheme . flows . authorizationCode . scopes . keys ()), ) # Cache the token in session state and call the API, skip to step 5 Step 3: Initiate Authentication Request If no valid credentials (Step 1.) and no auth response (Step 2.) are found, the tool needs to start the OAuth flow. Define the AuthScheme and initial AuthCredential and call tool_context.request_credential() . Return a response indicating authorization is needed. # Use auth_scheme and auth_credential configured in the tool. tool_context . request_credential ( AuthConfig ( auth_scheme = auth_scheme , raw_auth_credential = auth_credential , )) return { 'pending' : true , 'message' : 'Awaiting user authentication.' } # By setting request_credential, ADK detects a pending authentication event. It pauses execution and ask end user to login. Step 4: Exchange Authorization Code for Tokens ADK automatically generates oauth authorization URL and presents it to your Agent Client application. your Agent Client application should follow the same way described in Journey 1 to redirect the user to the authorization URL (with redirect_uri appended). Once a user completes the login flow following the authorization URL and ADK extracts the authentication callback url from Agent Client applications, automatically parses the auth code, and generates auth token. At the next Tool call, tool_context.get_auth_response in step 2 will contain a valid credential to use in subsequent API calls. Step 5: Cache Obtained Credentials After successfully obtaining the token from ADK (Step 2) or if the token is still valid (Step 1), immediately store the new Credentials object in tool_context.state (serialized, e.g., as JSON) using your cache key. # Inside your tool function, after obtaining 'creds' (either refreshed or newly exchanged) # Cache the new/refreshed tokens tool_context . state [ TOKEN_CACHE_KEY ] = json . loads ( creds . to_json ()) print ( f \"DEBUG: Cached/updated tokens under key: { TOKEN_CACHE_KEY } \" ) # Proceed to Step 6 (Make API Call) Step 6: Make Authenticated API Call Once you have a valid Credentials object ( creds from Step 1 or Step 4), use it to make the actual call to the protected API using the appropriate client library (e.g., googleapiclient , requests ). Pass the credentials=creds argument. Include error handling, especially for HttpError 401/403, which might mean the token expired or was revoked between calls. If you get such an error, consider clearing the cached token ( tool_context.state.pop(...) ) and potentially returning the auth_required status again to force re-authentication. # Inside your tool function, using the valid 'creds' object # Ensure creds is valid before proceeding if not creds or not creds . valid : return { \"status\" : \"error\" , \"error_message\" : \"Cannot proceed without valid credentials.\" } try : service = build ( \"calendar\" , \"v3\" , credentials = creds ) # Example api_result = service . events () . list ( ... ) . execute () # Proceed to Step 7 except Exception as e : # Handle API errors (e.g., check for 401/403, maybe clear cache and re-request auth) print ( f \"ERROR: API call failed: { e } \" ) return { \"status\" : \"error\" , \"error_message\" : f \"API call failed: { e } \" } Step 7: Return Tool Result After a successful API call, process the result into a dictionary format that is useful for the LLM. Crucially, include a along with the data. # Inside your tool function, after successful API call processed_result = [ ... ] # Process api_result for the LLM return { \"status\" : \"success\" , \"data\" : processed_result } Full Code Tools and Agent Agent CLI Helper Spec tools_and_agent.py import os from google.adk.auth.auth_schemes import OpenIdConnectWithConfig from google.adk.auth.auth_credential import AuthCredential , AuthCredentialTypes , OAuth2Auth from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset from google.adk.agents.llm_agent import LlmAgent # --- Authentication Configuration --- # This section configures how the agent will handle authentication using OpenID Connect (OIDC), # often layered on top of OAuth 2.0. # Define the Authentication Scheme using OpenID Connect. # This object tells the ADK *how* to perform the OIDC/OAuth2 flow. # It requires details specific to your Identity Provider (IDP), like Google OAuth, Okta, Auth0, etc. # Note: Replace the example Okta URLs and credentials with your actual IDP details. # All following fields are required, and available from your IDP. auth_scheme = OpenIdConnectWithConfig ( # The URL of the IDP's authorization endpoint where the user is redirected to log in. authorization_endpoint = \"https://your-endpoint.okta.com/oauth2/v1/authorize\" , # The URL of the IDP's token endpoint where the authorization code is exchanged for tokens. token_endpoint = \"https://your-token-endpoint.okta.com/oauth2/v1/token\" , # The scopes (permissions) your application requests from the IDP. # 'openid' is standard for OIDC. 'profile' and 'email' request user profile info. scopes = [ 'openid' , 'profile' , \"email\" ] ) # Define the Authentication Credentials for your specific application. # This object holds the client identifier and secret that your application uses # to identify itself to the IDP during the OAuth2 flow. # !! SECURITY WARNING: Avoid hardcoding secrets in production code. !! # !! Use environment variables or a secret management system instead. !! auth_credential = AuthCredential ( auth_type = AuthCredentialTypes . OPEN_ID_CONNECT , oauth2 = OAuth2Auth ( client_id = \"CLIENT_ID\" , client_secret = \"CIENT_SECRET\" , ) ) # --- Toolset Configuration from OpenAPI Specification --- # This section defines a sample set of tools the agent can use, configured with Authentication # from steps above. # This sample set of tools use endpoints protected by Okta and requires an OpenID Connect flow # to acquire end user credentials. with open ( os . path . join ( os . path . dirname ( __file__ ), 'spec.yaml' ), 'r' ) as f : spec_content = f . read () userinfo_toolset = OpenAPIToolset ( spec_str = spec_content , spec_str_type = 'yaml' , # ** Crucially, associate the authentication scheme and credentials with these tools. ** # This tells the ADK that the tools require the defined OIDC/OAuth2 flow. auth_scheme = auth_scheme , auth_credential = auth_credential , ) # --- Agent Configuration --- # Configure and create the main LLM Agent. root_agent = LlmAgent ( model = 'gemini-2.0-flash' , name = 'enterprise_assistant' , instruction = 'Help user integrate with multiple enterprise systems, including retrieving user information which may require authentication.' , tools = userinfo_toolset . get_tools (), ) # --- Ready for Use --- # The `root_agent` is now configured with tools protected by OIDC/OAuth2 authentication. # When the agent attempts to use one of these tools, the ADK framework will automatically # trigger the authentication flow defined by `auth_scheme` and `auth_credential` # if valid credentials are not already available in the session. # The subsequent interaction flow would guide the user through the login process and handle # token exchanging, and automatically attach the exchanged token to the endpoint defined in # the tool. agent_cli.py import asyncio from dotenv import load_dotenv from google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from google.genai import types from .helpers import is_pending_auth_event , get_function_call_id , get_function_call_auth_config , get_user_input from .tools_and_agent import root_agent load_dotenv () agent = root_agent async def async_main (): \"\"\" Main asynchronous function orchestrating the agent interaction and authentication flow. \"\"\" # --- Step 1: Service Initialization --- # Use in-memory services for session and artifact storage (suitable for demos/testing). session_service = InMemorySessionService () artifacts_service = InMemoryArtifactService () # Create a new user session to maintain conversation state. session = session_service . create_session ( state = {}, # Optional state dictionary for session-specific data app_name = 'my_app' , # Application identifier user_id = 'user' # User identifier ) # --- Step 2: Initial User Query --- # Define the user's initial request. query = 'Show me my user info' print ( f \"user: { query } \" ) # Format the query into the Content structure expected by the ADK Runner. content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) # Initialize the ADK Runner runner = Runner ( app_name = 'my_app' , agent = agent , artifact_service = artifacts_service , session_service = session_service , ) # --- Step 3: Send Query and Handle Potential Auth Request --- print ( \" \\n Running agent with initial query...\" ) events_async = runner . run_async ( session_id = session . id , user_id = 'user' , new_message = content ) # Variables to store details if an authentication request occurs. auth_request_event_id , auth_config = None , None # Iterate through the events generated by the first run. async for event in events_async : # Check if this event is the specific 'adk_request_credential' function call. if is_pending_auth_event ( event ): print ( \"--> Authentication required by agent.\" ) auth_request_event_id = get_function_call_id ( event ) auth_config = get_function_call_auth_config ( event ) # Once the auth request is found and processed, exit this loop. # We need to pause execution here to get user input for authentication. break # If no authentication request was detected after processing all events, exit. if not auth_request_event_id or not auth_config : print ( \" \\n Authentication not required for this query or processing finished.\" ) return # Exit the main function # --- Step 4: Manual Authentication Step (Simulated OAuth 2.0 Flow) --- # This section simulates the user interaction part of an OAuth 2.0 flow. # In a real web application, this would involve browser redirects. # Define the Redirect URI. This *must* match one of the URIs registered # with the OAuth provider for your application. The provider sends the user # back here after they approve the request. redirect_uri = 'http://localhost:8000/dev-ui' # Example for local development # Construct the Authorization URL that the user must visit. # This typically includes the provider's authorization endpoint URL, # client ID, requested scopes, response type (e.g., 'code'), and the redirect URI. # Here, we retrieve the base authorization URI from the AuthConfig provided by ADK # and append the redirect_uri. # NOTE: A robust implementation would use urlencode and potentially add state, scope, etc. auth_request_uri = ( auth_config . exchanged_auth_credential . oauth2 . auth_uri + f '&redirect_uri= { redirect_uri } ' # Simple concatenation; ensure correct query param format ) print ( \" \\n --- User Action Required ---\" ) # Prompt the user to visit the authorization URL, log in, grant permissions, # and then paste the *full* URL they are redirected back to (which contains the auth code). auth_response_uri = await get_user_input ( f '1. Please open this URL in your browser to log in: \\n { auth_request_uri } \\n\\n ' f '2. After successful login and authorization, your browser will be redirected. \\n ' f '   Copy the *entire* URL from the browser \\' s address bar. \\n\\n ' f '3. Paste the copied URL here and press Enter: \\n\\n > ' ) # --- Step 5: Prepare Authentication Response for the Agent --- # Update the AuthConfig object with the information gathered from the user. # The ADK framework needs the full response URI (containing the code) # and the original redirect URI to complete the OAuth token exchange process internally. auth_config . exchanged_auth_credential . oauth2 . auth_response_uri = auth_response_uri auth_config . exchanged_auth_credential . oauth2 . redirect_uri = redirect_uri # Construct a FunctionResponse Content object to send back to the agent/runner. # This response explicitly targets the 'adk_request_credential' function call # identified earlier by its ID. auth_content = types . Content ( role = 'user' , parts = [ types . Part ( function_response = types . FunctionResponse ( # Crucially, link this response to the original request using the saved ID. id = auth_request_event_id , # The special name of the function call we are responding to. name = 'adk_request_credential' , # The payload containing all necessary authentication details. response = auth_config . model_dump (), ) ) ], ) # --- Step 6: Resume Execution with Authentication --- print ( \" \\n Submitting authentication details back to the agent...\" ) # Run the agent again, this time providing the `auth_content` (FunctionResponse). # The ADK Runner intercepts this, processes the 'adk_request_credential' response # (performs token exchange, stores credentials), and then allows the agent # to retry the original tool call that required authentication, now succeeding with # a valid access token embedded. events_async = runner . run_async ( session_id = session . id , user_id = 'user' , new_message = auth_content , # Provide the prepared auth response ) # Process and print the final events from the agent after authentication is complete. # This stream now contain the actual result from the tool (e.g., the user info). print ( \" \\n --- Agent Response after Authentication ---\" ) async for event in events_async : print ( event ) if __name__ == '__main__' : asyncio . run ( async_main ()) helpers.py from google.adk.auth import AuthConfig from google.adk.events import Event import asyncio # --- Helper Functions --- async def get_user_input ( prompt : str ) -> str : \"\"\" Asynchronously prompts the user for input in the console. Uses asyncio's event loop and run_in_executor to avoid blocking the main asynchronous execution thread while waiting for synchronous `input()`. Args: prompt: The message to display to the user. Returns: The string entered by the user. \"\"\" loop = asyncio . get_event_loop () # Run the blocking `input()` function in a separate thread managed by the executor. return await loop . run_in_executor ( None , input , prompt ) def is_pending_auth_event ( event : Event ) -> bool : \"\"\" Checks if an ADK Event represents a request for user authentication credentials. The ADK framework emits a specific function call ('adk_request_credential') when a tool requires authentication that hasn't been previously satisfied. Args: event: The ADK Event object to inspect. Returns: True if the event is an 'adk_request_credential' function call, False otherwise. \"\"\" # Safely checks nested attributes to avoid errors if event structure is incomplete. return ( event . content and event . content . parts and event . content . parts [ 0 ] # Assuming the function call is in the first part and event . content . parts [ 0 ] . function_call # The specific function name indicating an auth request from the ADK framework. and event . content . parts [ 0 ] . function_call . name == 'adk_request_credential' ) def get_function_call_id ( event : Event ) -> str : \"\"\" Extracts the unique ID of the function call from an ADK Event. This ID is crucial for correlating a function *response* back to the specific function *call* that the agent initiated to request for auth credentials. Args: event: The ADK Event object containing the function call. Returns: The unique identifier string of the function call. Raises: ValueError: If the function call ID cannot be found in the event structure. (Corrected typo from `contents` to `content` below) \"\"\" # Navigate through the event structure to find the function call ID. if ( event and event . content and event . content . parts and event . content . parts [ 0 ] # Use content, not contents and event . content . parts [ 0 ] . function_call and event . content . parts [ 0 ] . function_call . id ): return event . content . parts [ 0 ] . function_call . id # If the ID is missing, raise an error indicating an unexpected event format. raise ValueError ( f 'Cannot get function call id from event { event } ' ) def get_function_call_auth_config ( event : Event ) -> AuthConfig : \"\"\" Extracts the authentication configuration details from an 'adk_request_credential' event. Client should use this AuthConfig to necessary authentication details (like OAuth codes and state) and sent it back to the ADK to continue OAuth token exchanging. Args: event: The ADK Event object containing the 'adk_request_credential' call. Returns: An AuthConfig object populated with details from the function call arguments. Raises: ValueError: If the 'auth_config' argument cannot be found in the event. (Corrected typo from `contents` to `content` below) \"\"\" if ( event and event . content and event . content . parts and event . content . parts [ 0 ] # Use content, not contents and event . content . parts [ 0 ] . function_call and event . content . parts [ 0 ] . function_call . args and event . content . parts [ 0 ] . function_call . args . get ( 'auth_config' ) ): # Reconstruct the AuthConfig object using the dictionary provided in the arguments. # The ** operator unpacks the dictionary into keyword arguments for the constructor. return AuthConfig ( ** event . content . parts [ 0 ] . function_call . args . get ( 'auth_config' ) ) raise ValueError ( f 'Cannot get auth config from event { event } ' ) openapi : 3.0.1 info : title : Okta User Info API version : 1.0.0 description : |- API to retrieve user profile information based on a valid Okta OIDC Access Token. Authentication is handled via OpenID Connect with Okta. contact : name : API Support email : support@example.com # Replace with actual contact if available servers : - url : <substitute with your server name> description : Production Environment paths : /okta-jwt-user-api : get : summary : Get Authenticated User Info description : |- Fetches profile details for the user operationId : getUserInfo tags : - User Profile security : - okta_oidc : - openid - email - profile responses : '200' : description : Successfully retrieved user information. content : application/json : schema : type : object properties : sub : type : string description : Subject identifier for the user. example : \"abcdefg\" name : type : string description : Full name of the user. example : \"Example LastName\" locale : type : string description : User's locale, e.g., en-US or en_US. example : \"en_US\" email : type : string format : email description : User's primary email address. example : \"username@example.com\" preferred_username : type : string description : Preferred username of the user (often the email). example : \"username@example.com\" given_name : type : string description : Given name (first name) of the user. example : \"Example\" family_name : type : string description : Family name (last name) of the user. example : \"LastName\" zoneinfo : type : string description : User's timezone, e.g., America/Los_Angeles. example : \"America/Los_Angeles\" updated_at : type : integer format : int64 # Using int64 for Unix timestamp description : Timestamp when the user's profile was last updated (Unix epoch time). example : 1743617719 email_verified : type : boolean description : Indicates if the user's email address has been verified. example : true required : - sub - name - locale - email - preferred_username - given_name - family_name - zoneinfo - updated_at - email_verified '401' : description : Unauthorized. The provided Bearer token is missing, invalid, or expired. content : application/json : schema : $ref : '#/components/schemas/Error' '403' : description : Forbidden. The provided token does not have the required scopes or permissions to access this resource. content : application/json : schema : $ref : '#/components/schemas/Error' components : securitySchemes : okta_oidc : type : openIdConnect description : Authentication via Okta using OpenID Connect. Requires a Bearer Access Token. openIdConnectUrl : https://your-endpoint.okta.com/.well-known/openid-configuration schemas : Error : type : object properties : code : type : string description : An error code. message : type : string description : A human-readable error message. required : - code - message Back to top ", "code_blocks": [{"language": "text", "code": "from google.oauth2.credentials import Credentials\nfrom google.auth.transport.requests import Request\n\n# Inside your tool function\nTOKEN_CACHE_KEY = \"my_tool_tokens\" # Choose a unique key\nSCOPES = [\"scope1\", \"scope2\"] # Define required scopes\n\ncreds = None\ncached_token_info = tool_context.state.get(TOKEN_CACHE_KEY)\nif cached_token_info:\n    try:\n        creds = Credentials.from_authorized_user_info(cached_token_info, SCOPES)\n        if not creds.valid and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n            tool_context.state[TOKEN_CACHE_KEY] = json.loads(creds.to_json()) # Update cache\n        elif not creds.valid:\n            creds = None # Invalid, needs re-auth\n            tool_context.state[TOKEN_CACHE_KEY] = None\n    except Exception as e:\n        print(f\"Error loading/refreshing cached creds: {e}\")\n        creds = None\n        tool_context.state[TOKEN_CACHE_KEY] = None\n\nif creds and creds.valid:\n    # Skip to Step 5: Make Authenticated API Call\n    pass\nelse:\n    # Proceed to Step 2...\n    pass"}, {"language": "text", "code": "# Use auth_scheme and auth_credential configured in the tool.\n# exchanged_credential: AuthCredential | None\n\nexchanged_credential = tool_context.get_auth_response(AuthConfig(\n  auth_scheme=auth_scheme,\n  raw_auth_credential=auth_credential,\n))\n# If exchanged_credential is not None, then there is already an exchanged credetial from the auth response. \nif exchanged_credential:\n   # ADK exchanged the access token already for us\n        access_token = exchanged_credential.oauth2.access_token\n        refresh_token = exchanged_credential.oauth2.refresh_token\n        creds = Credentials(\n            token=access_token,\n            refresh_token=refresh_token,\n            token_uri=auth_scheme.flows.authorizationCode.tokenUrl,\n            client_id=auth_credential.oauth2.client_id,\n            client_secret=auth_credential.oauth2.client_secret,\n            scopes=list(auth_scheme.flows.authorizationCode.scopes.keys()),\n        )\n    # Cache the token in session state and call the API, skip to step 5"}, {"language": "text", "code": "# Use auth_scheme and auth_credential configured in the tool.\n\n  tool_context.request_credential(AuthConfig(\n    auth_scheme=auth_scheme,\n    raw_auth_credential=auth_credential,\n  ))\n  return {'pending': true, 'message': 'Awaiting user authentication.'}\n\n# By setting request_credential, ADK detects a pending authentication event. It pauses execution and ask end user to login."}, {"language": "text", "code": "# Inside your tool function, after obtaining 'creds' (either refreshed or newly exchanged)\n# Cache the new/refreshed tokens\ntool_context.state[TOKEN_CACHE_KEY] = json.loads(creds.to_json())\nprint(f\"DEBUG: Cached/updated tokens under key: {TOKEN_CACHE_KEY}\")\n# Proceed to Step 6 (Make API Call)"}, {"language": "text", "code": "# Inside your tool function, using the valid 'creds' object\n# Ensure creds is valid before proceeding\nif not creds or not creds.valid:\n   return {\"status\": \"error\", \"error_message\": \"Cannot proceed without valid credentials.\"}\n\ntry:\n   service = build(\"calendar\", \"v3\", credentials=creds) # Example\n   api_result = service.events().list(...).execute()\n   # Proceed to Step 7\nexcept Exception as e:\n   # Handle API errors (e.g., check for 401/403, maybe clear cache and re-request auth)\n   print(f\"ERROR: API call failed: {e}\")\n   return {\"status\": \"error\", \"error_message\": f\"API call failed: {e}\"}"}, {"language": "text", "code": "# Inside your tool function, after successful API call\n    processed_result = [...] # Process api_result for the LLM\n    return {\"status\": \"success\", \"data\": processed_result}"}, {"language": "text", "code": "import os\n\nfrom google.adk.auth.auth_schemes import OpenIdConnectWithConfig\nfrom google.adk.auth.auth_credential import AuthCredential, AuthCredentialTypes, OAuth2Auth\nfrom google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset\nfrom google.adk.agents.llm_agent import LlmAgent\n\n# --- Authentication Configuration ---\n# This section configures how the agent will handle authentication using OpenID Connect (OIDC),\n# often layered on top of OAuth 2.0.\n\n# Define the Authentication Scheme using OpenID Connect.\n# This object tells the ADK *how* to perform the OIDC/OAuth2 flow.\n# It requires details specific to your Identity Provider (IDP), like Google OAuth, Okta, Auth0, etc.\n# Note: Replace the example Okta URLs and credentials with your actual IDP details.\n# All following fields are required, and available from your IDP.\nauth_scheme = OpenIdConnectWithConfig(\n    # The URL of the IDP's authorization endpoint where the user is redirected to log in.\n    authorization_endpoint=\"https://your-endpoint.okta.com/oauth2/v1/authorize\",\n    # The URL of the IDP's token endpoint where the authorization code is exchanged for tokens.\n    token_endpoint=\"https://your-token-endpoint.okta.com/oauth2/v1/token\",\n    # The scopes (permissions) your application requests from the IDP.\n    # 'openid' is standard for OIDC. 'profile' and 'email' request user profile info.\n    scopes=['openid', 'profile', \"email\"]\n)\n\n# Define the Authentication Credentials for your specific application.\n# This object holds the client identifier and secret that your application uses\n# to identify itself to the IDP during the OAuth2 flow.\n# !! SECURITY WARNING: Avoid hardcoding secrets in production code. !!\n# !! Use environment variables or a secret management system instead. !!\nauth_credential = AuthCredential(\n  auth_type=AuthCredentialTypes.OPEN_ID_CONNECT,\n  oauth2=OAuth2Auth(\n    client_id=\"CLIENT_ID\",\n    client_secret=\"CIENT_SECRET\",\n  )\n)\n\n\n# --- Toolset Configuration from OpenAPI Specification ---\n# This section defines a sample set of tools the agent can use, configured with Authentication\n# from steps above.\n# This sample set of tools use endpoints protected by Okta and requires an OpenID Connect flow\n# to acquire end user credentials.\nwith open(os.path.join(os.path.dirname(__file__), 'spec.yaml'), 'r') as f:\n    spec_content = f.read()\n\nuserinfo_toolset = OpenAPIToolset(\n   spec_str=spec_content,\n   spec_str_type='yaml',\n   # ** Crucially, associate the authentication scheme and credentials with these tools. **\n   # This tells the ADK that the tools require the defined OIDC/OAuth2 flow.\n   auth_scheme=auth_scheme,\n   auth_credential=auth_credential,\n)\n\n# --- Agent Configuration ---\n# Configure and create the main LLM Agent.\nroot_agent = LlmAgent(\n    model='gemini-2.0-flash',\n    name='enterprise_assistant',\n    instruction='Help user integrate with multiple enterprise systems, including retrieving user information which may require authentication.',\n    tools=userinfo_toolset.get_tools(),\n)\n\n# --- Ready for Use ---\n# The `root_agent` is now configured with tools protected by OIDC/OAuth2 authentication.\n# When the agent attempts to use one of these tools, the ADK framework will automatically\n# trigger the authentication flow defined by `auth_scheme` and `auth_credential`\n# if valid credentials are not already available in the session.\n# The subsequent interaction flow would guide the user through the login process and handle\n# token exchanging, and automatically attach the exchanged token to the endpoint defined in\n# the tool."}, {"language": "text", "code": "import asyncio\nfrom dotenv import load_dotenv\nfrom google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\nfrom .helpers import is_pending_auth_event, get_function_call_id, get_function_call_auth_config, get_user_input\nfrom .tools_and_agent import root_agent\n\nload_dotenv()\n\nagent = root_agent\n\nasync def async_main():\n  \"\"\"\n  Main asynchronous function orchestrating the agent interaction and authentication flow.\n  \"\"\"\n  # --- Step 1: Service Initialization ---\n  # Use in-memory services for session and artifact storage (suitable for demos/testing).\n  session_service = InMemorySessionService()\n  artifacts_service = InMemoryArtifactService()\n\n  # Create a new user session to maintain conversation state.\n  session = session_service.create_session(\n      state={},  # Optional state dictionary for session-specific data\n      app_name='my_app', # Application identifier\n      user_id='user' # User identifier\n  )\n\n  # --- Step 2: Initial User Query ---\n  # Define the user's initial request.\n  query = 'Show me my user info'\n  print(f\"user: {query}\")\n\n  # Format the query into the Content structure expected by the ADK Runner.\n  content = types.Content(role='user', parts=[types.Part(text=query)])\n\n  # Initialize the ADK Runner\n  runner = Runner(\n      app_name='my_app',\n      agent=agent,\n      artifact_service=artifacts_service,\n      session_service=session_service,\n  )\n\n  # --- Step 3: Send Query and Handle Potential Auth Request ---\n  print(\"\\nRunning agent with initial query...\")\n  events_async = runner.run_async(\n      session_id=session.id, user_id='user', new_message=content\n  )\n\n  # Variables to store details if an authentication request occurs.\n  auth_request_event_id, auth_config = None, None\n\n  # Iterate through the events generated by the first run.\n  async for event in events_async:\n    # Check if this event is the specific 'adk_request_credential' function call.\n    if is_pending_auth_event(event):\n      print(\"--> Authentication required by agent.\")\n      auth_request_event_id = get_function_call_id(event)\n      auth_config = get_function_call_auth_config(event)\n      # Once the auth request is found and processed, exit this loop.\n      # We need to pause execution here to get user input for authentication.\n      break\n\n\n  # If no authentication request was detected after processing all events, exit.\n  if not auth_request_event_id or not auth_config:\n      print(\"\\nAuthentication not required for this query or processing finished.\")\n      return # Exit the main function\n\n  # --- Step 4: Manual Authentication Step (Simulated OAuth 2.0 Flow) ---\n  # This section simulates the user interaction part of an OAuth 2.0 flow.\n  # In a real web application, this would involve browser redirects.\n\n  # Define the Redirect URI. This *must* match one of the URIs registered\n  # with the OAuth provider for your application. The provider sends the user\n  # back here after they approve the request.\n  redirect_uri = 'http://localhost:8000/dev-ui' # Example for local development\n\n  # Construct the Authorization URL that the user must visit.\n  # This typically includes the provider's authorization endpoint URL,\n  # client ID, requested scopes, response type (e.g., 'code'), and the redirect URI.\n  # Here, we retrieve the base authorization URI from the AuthConfig provided by ADK\n  # and append the redirect_uri.\n  # NOTE: A robust implementation would use urlencode and potentially add state, scope, etc.\n  auth_request_uri = (\n      auth_config.exchanged_auth_credential.oauth2.auth_uri\n      + f'&redirect_uri={redirect_uri}' # Simple concatenation; ensure correct query param format\n  )\n\n  print(\"\\n--- User Action Required ---\")\n  # Prompt the user to visit the authorization URL, log in, grant permissions,\n  # and then paste the *full* URL they are redirected back to (which contains the auth code).\n  auth_response_uri = await get_user_input(\n      f'1. Please open this URL in your browser to log in:\\n   {auth_request_uri}\\n\\n'\n      f'2. After successful login and authorization, your browser will be redirected.\\n'\n      f'   Copy the *entire* URL from the browser\\'s address bar.\\n\\n'\n      f'3. Paste the copied URL here and press Enter:\\n\\n> '\n  )\n\n  # --- Step 5: Prepare Authentication Response for the Agent ---\n  # Update the AuthConfig object with the information gathered from the user.\n  # The ADK framework needs the full response URI (containing the code)\n  # and the original redirect URI to complete the OAuth token exchange process internally.\n  auth_config.exchanged_auth_credential.oauth2.auth_response_uri = auth_response_uri\n  auth_config.exchanged_auth_credential.oauth2.redirect_uri = redirect_uri\n\n  # Construct a FunctionResponse Content object to send back to the agent/runner.\n  # This response explicitly targets the 'adk_request_credential' function call\n  # identified earlier by its ID.\n  auth_content = types.Content(\n      role='user',\n      parts=[\n          types.Part(\n              function_response=types.FunctionResponse(\n                  # Crucially, link this response to the original request using the saved ID.\n                  id=auth_request_event_id,\n                  # The special name of the function call we are responding to.\n                  name='adk_request_credential',\n                  # The payload containing all necessary authentication details.\n                  response=auth_config.model_dump(),\n              )\n          )\n      ],\n  )\n\n  # --- Step 6: Resume Execution with Authentication ---\n  print(\"\\nSubmitting authentication details back to the agent...\")\n  # Run the agent again, this time providing the `auth_content` (FunctionResponse).\n  # The ADK Runner intercepts this, processes the 'adk_request_credential' response\n  # (performs token exchange, stores credentials), and then allows the agent\n  # to retry the original tool call that required authentication, now succeeding with\n  # a valid access token embedded.\n  events_async = runner.run_async(\n      session_id=session.id,\n      user_id='user',\n      new_message=auth_content, # Provide the prepared auth response\n  )\n\n  # Process and print the final events from the agent after authentication is complete.\n  # This stream now contain the actual result from the tool (e.g., the user info).\n  print(\"\\n--- Agent Response after Authentication ---\")\n  async for event in events_async:\n    print(event)\n\n\nif __name__ == '__main__':\n  asyncio.run(async_main())"}, {"language": "text", "code": "from google.adk.auth import AuthConfig\nfrom google.adk.events import Event\nimport asyncio\n\n# --- Helper Functions ---\nasync def get_user_input(prompt: str) -> str:\n  \"\"\"\n  Asynchronously prompts the user for input in the console.\n\n  Uses asyncio's event loop and run_in_executor to avoid blocking the main\n  asynchronous execution thread while waiting for synchronous `input()`.\n\n  Args:\n    prompt: The message to display to the user.\n\n  Returns:\n    The string entered by the user.\n  \"\"\"\n  loop = asyncio.get_event_loop()\n  # Run the blocking `input()` function in a separate thread managed by the executor.\n  return await loop.run_in_executor(None, input, prompt)\n\n\ndef is_pending_auth_event(event: Event) -> bool:\n  \"\"\"\n  Checks if an ADK Event represents a request for user authentication credentials.\n\n  The ADK framework emits a specific function call ('adk_request_credential')\n  when a tool requires authentication that hasn't been previously satisfied.\n\n  Args:\n    event: The ADK Event object to inspect.\n\n  Returns:\n    True if the event is an 'adk_request_credential' function call, False otherwise.\n  \"\"\"\n  # Safely checks nested attributes to avoid errors if event structure is incomplete.\n  return (\n      event.content\n      and event.content.parts\n      and event.content.parts[0] # Assuming the function call is in the first part\n      and event.content.parts[0].function_call\n      # The specific function name indicating an auth request from the ADK framework.\n      and event.content.parts[0].function_call.name == 'adk_request_credential'\n  )\n\n\ndef get_function_call_id(event: Event) -> str:\n  \"\"\"\n  Extracts the unique ID of the function call from an ADK Event.\n\n  This ID is crucial for correlating a function *response* back to the specific\n  function *call* that the agent initiated to request for auth credentials.\n\n  Args:\n    event: The ADK Event object containing the function call.\n\n  Returns:\n    The unique identifier string of the function call.\n\n  Raises:\n    ValueError: If the function call ID cannot be found in the event structure.\n                (Corrected typo from `contents` to `content` below)\n  \"\"\"\n  # Navigate through the event structure to find the function call ID.\n  if (\n      event\n      and event.content\n      and event.content.parts\n      and event.content.parts[0] # Use content, not contents\n      and event.content.parts[0].function_call\n      and event.content.parts[0].function_call.id\n  ):\n    return event.content.parts[0].function_call.id\n  # If the ID is missing, raise an error indicating an unexpected event format.\n  raise ValueError(f'Cannot get function call id from event {event}')\n\n\ndef get_function_call_auth_config(event: Event) -> AuthConfig:\n  \"\"\"\n  Extracts the authentication configuration details from an 'adk_request_credential' event.\n\n  Client should use this AuthConfig to necessary authentication details (like OAuth codes and state)\n  and sent it back to the ADK to continue OAuth token exchanging.\n\n  Args:\n    event: The ADK Event object containing the 'adk_request_credential' call.\n\n  Returns:\n    An AuthConfig object populated with details from the function call arguments.\n\n  Raises:\n    ValueError: If the 'auth_config' argument cannot be found in the event.\n                (Corrected typo from `contents` to `content` below)\n  \"\"\"\n  if (\n      event\n      and event.content\n      and event.content.parts\n      and event.content.parts[0] # Use content, not contents\n      and event.content.parts[0].function_call\n      and event.content.parts[0].function_call.args\n      and event.content.parts[0].function_call.args.get('auth_config')\n  ):\n    # Reconstruct the AuthConfig object using the dictionary provided in the arguments.\n    # The ** operator unpacks the dictionary into keyword arguments for the constructor.\n    return AuthConfig(\n          **event.content.parts[0].function_call.args.get('auth_config')\n      )\n  raise ValueError(f'Cannot get auth config from event {event}')"}, {"language": "text", "code": "openapi: 3.0.1\ninfo:\ntitle: Okta User Info API\nversion: 1.0.0\ndescription: |-\n   API to retrieve user profile information based on a valid Okta OIDC Access Token.\n   Authentication is handled via OpenID Connect with Okta.\ncontact:\n   name: API Support\n   email: support@example.com # Replace with actual contact if available\nservers:\n- url: <substitute with your server name>\n   description: Production Environment\npaths:\n/okta-jwt-user-api:\n   get:\n      summary: Get Authenticated User Info\n      description: |-\n      Fetches profile details for the user\n      operationId: getUserInfo\n      tags:\n      - User Profile\n      security:\n      - okta_oidc:\n            - openid\n            - email\n            - profile\n      responses:\n      '200':\n         description: Successfully retrieved user information.\n         content:\n            application/json:\n            schema:\n               type: object\n               properties:\n                  sub:\n                  type: string\n                  description: Subject identifier for the user.\n                  example: \"abcdefg\"\n                  name:\n                  type: string\n                  description: Full name of the user.\n                  example: \"Example LastName\"\n                  locale:\n                  type: string\n                  description: User's locale, e.g., en-US or en_US.\n                  example: \"en_US\"\n                  email:\n                  type: string\n                  format: email\n                  description: User's primary email address.\n                  example: \"username@example.com\"\n                  preferred_username:\n                  type: string\n                  description: Preferred username of the user (often the email).\n                  example: \"username@example.com\"\n                  given_name:\n                  type: string\n                  description: Given name (first name) of the user.\n                  example: \"Example\"\n                  family_name:\n                  type: string\n                  description: Family name (last name) of the user.\n                  example: \"LastName\"\n                  zoneinfo:\n                  type: string\n                  description: User's timezone, e.g., America/Los_Angeles.\n                  example: \"America/Los_Angeles\"\n                  updated_at:\n                  type: integer\n                  format: int64 # Using int64 for Unix timestamp\n                  description: Timestamp when the user's profile was last updated (Unix epoch time).\n                  example: 1743617719\n                  email_verified:\n                  type: boolean\n                  description: Indicates if the user's email address has been verified.\n                  example: true\n               required:\n                  - sub\n                  - name\n                  - locale\n                  - email\n                  - preferred_username\n                  - given_name\n                  - family_name\n                  - zoneinfo\n                  - updated_at\n                  - email_verified\n      '401':\n         description: Unauthorized. The provided Bearer token is missing, invalid, or expired.\n         content:\n            application/json:\n            schema:\n               $ref: '#/components/schemas/Error'\n      '403':\n         description: Forbidden. The provided token does not have the required scopes or permissions to access this resource.\n         content:\n            application/json:\n            schema:\n               $ref: '#/components/schemas/Error'\ncomponents:\nsecuritySchemes:\n   okta_oidc:\n      type: openIdConnect\n      description: Authentication via Okta using OpenID Connect. Requires a Bearer Access Token.\n      openIdConnectUrl: https://your-endpoint.okta.com/.well-known/openid-configuration\nschemas:\n   Error:\n      type: object\n      properties:\n      code:\n         type: string\n         description: An error code.\n      message:\n         type: string\n         description: A human-readable error message.\n      required:\n         - code\n         - message"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:22.300577", "source_type": "adk-docs"}
{"doc_id": "7b09a8381a2fbe35784aa3c9358e584dbca578662d58b26799d12b633d2bc7a1", "url": "https://google.github.io/adk-docs/runtime", "title": "Agent Runtime - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Runtime\u00b6"], "text": "Runtime \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 The ADK Runtime is the underlying engine that powers your agent application during user interactions. It's the system that takes your defined agents, tools, and callbacks and orchestrates their execution in response to user input, managing the flow of information, state changes, and interactions with external services like LLMs or storage. Think of the Runtime as the \"engine\" of your agentic application. You define the parts (agents, tools), and the Runtime handles how they connect and run together to fulfill a user's request. ", "code_blocks": []}, {"heading_path": ["Core Idea: The Event Loop\u00b6"], "text": "Core Idea: The Event Loop \u00b6 At its heart, the ADK Runtime operates on an Event Loop . This loop facilitates a back-and-forth communication between the Runner component and your defined \"Execution Logic\" (which includes your Agents, the LLM calls they make, Callbacks, and Tools). In simple terms: The Runner receives a user query and asks the main Agent to start processing. The Agent (and its associated logic) runs until it has something to report (like a response, a request to use a tool, or a state change) \u2013 it then yields or emits an Event . The Runner receives this Event , processes any associated actions (like saving state changes via Services ), and forwards the event onwards (e.g., to the user interface). Only after the Runner has processed the event does the Agent 's logic resume from where it paused, now potentially seeing the effects of the changes committed by the Runner. This cycle repeats until the agent has no more events to yield for the current user query. This event-driven loop is the fundamental pattern governing how ADK executes your agent code. ", "code_blocks": []}, {"heading_path": ["The Heartbeat: The Event Loop - Inner workings\u00b6"], "text": "The Heartbeat: The Event Loop - Inner workings \u00b6 The Event Loop is the core operational pattern defining the interaction between the Runner and your custom code (Agents, Tools, Callbacks, collectively referred to as \"Execution Logic\" or \"Logic Components\" in the design document). It establishes a clear division of responsibilities: Note The specific method names and parameter names may vary slightly by SDK language (e.g., agent_to_run.run_async(...) in Python, agent.Run(...) in Go, agent_to_run.runAsync(...) in Java ). Refer to the language-specific API documentation for details. ", "code_blocks": []}, {"heading_path": ["Runner's Role (Orchestrator)\u00b6"], "text": "Runner's Role (Orchestrator) \u00b6 The Runner acts as the central coordinator for a single user invocation. Its responsibilities in the loop are: Initiation: Receives the end user's query ( new_message ) and typically appends it to the session history via the SessionService . Kick-off: Starts the event generation process by calling the main agent's execution method (e.g., agent_to_run.run_async(...) ). Receive & Process: Waits for the agent logic to yield or emit an Event . Upon receiving an event, the Runner promptly processes it. This involves: Using configured Services ( SessionService , ArtifactService , MemoryService ) to commit changes indicated in event.actions (like state_delta , artifact_delta ). Performing other internal bookkeeping. Yield Upstream: Forwards the processed event onwards (e.g., to the calling application or UI for rendering). Iterate: Signals the agent logic that processing is complete for the yielded event, allowing it to resume and generate the next event. Conceptual Runner Loop: Python Go Java # Simplified view of Runner's main loop logic def run ( new_query , ... ) -> Generator [ Event ]: # 1. Append new_query to session event history (via SessionService) session_service . append_event ( session , Event ( author = 'user' , content = new_query )) # 2. Kick off event loop by calling the agent agent_event_generator = agent_to_run . run_async ( context ) async for event in agent_event_generator : # 3. Process the generated event and commit changes session_service . append_event ( session , event ) # Commits state/artifact deltas etc. # memory_service.update_memory(...) # If applicable # artifact_service might have already been called via context during agent run # 4. Yield event for upstream processing (e.g., UI rendering) yield event # Runner implicitly signals agent generator can continue after yielding // Simplified conceptual view of the Runner's main loop logic in Go func ( r * Runner ) RunConceptual ( ctx context . Context , session * session . Session , newQuery * genai . Content ) iter . Seq2 [ * Event , error ] { return func ( yield func ( * Event , error ) bool ) { // 1. Append new_query to session event history (via SessionService) // ... userEvent := session . NewEvent ( ctx . InvocationID ()) // Simplified for conceptual view userEvent . Author = \"user\" userEvent . LLMResponse = model . LLMResponse { Content : newQuery } if _ , err := r . sessionService . Append ( ctx , & session . AppendRequest { Event : userEvent }); err != nil { yield ( nil , err ) return } // 2. Kick off event stream by calling the agent // Assuming agent.Run also returns iter.Seq2[*Event, error] agentEventsAndErrs := r . agent . Run ( ctx , & agent . RunRequest { Session : session , Input : newQuery }) for event , err := range agentEventsAndErrs { if err != nil { if ! yield ( event , err ) { // Yield event even if there's an error, then stop return } return // Agent finished with an error } // 3. Process the generated event and commit changes // Only commit non-partial event to a session service (as seen in actual code) if ! event . LLMResponse . Partial { if _ , err := r . sessionService . Append ( ctx , & session . AppendRequest { Event : event }); err != nil { yield ( nil , err ) return } } // memory_service.update_memory(...) // If applicable // artifact_service might have already been called via context during agent run // 4. Yield event for upstream processing if ! yield ( event , nil ) { return // Upstream consumer stopped } } // Agent finished successfully } } // Simplified conceptual view of the Runner's main loop logic in Java. public Flowable < Event > runConceptual ( Session session , InvocationContext invocationContext , Content newQuery ) { // 1. Append new_query to session event history (via SessionService) // ... sessionService . appendEvent ( session , userEvent ). blockingGet (); // 2. Kick off event stream by calling the agent Flowable < Event > agentEventStream = agentToRun . runAsync ( invocationContext ); // 3. Process each generated event, commit changes, and \"yield\" or \"emit\" return agentEventStream . map ( event -> { // This mutates the session object (adds event, applies stateDelta). // The return value of appendEvent (a Single<Event>) is conceptually // just the event itself after processing. sessionService . appendEvent ( session , event ). blockingGet (); // Simplified blocking call // memory_service.update_memory(...) // If applicable - conceptual // artifact_service might have already been called via context during agent run // 4. \"Yield\" event for upstream processing //    In RxJava, returning the event in map effectively yields it to the next operator or subscriber. return event ; }); } ", "code_blocks": [{"language": "text", "code": "# Simplified view of Runner's main loop logic\ndef run(new_query, ...) -> Generator[Event]:\n    # 1. Append new_query to session event history (via SessionService)\n    session_service.append_event(session, Event(author='user', content=new_query))\n\n    # 2. Kick off event loop by calling the agent\n    agent_event_generator = agent_to_run.run_async(context)\n\n    async for event in agent_event_generator:\n        # 3. Process the generated event and commit changes\n        session_service.append_event(session, event) # Commits state/artifact deltas etc.\n        # memory_service.update_memory(...) # If applicable\n        # artifact_service might have already been called via context during agent run\n\n        # 4. Yield event for upstream processing (e.g., UI rendering)\n        yield event\n        # Runner implicitly signals agent generator can continue after yielding"}, {"language": "text", "code": "// Simplified conceptual view of the Runner's main loop logic in Go\nfunc (r *Runner) RunConceptual(ctx context.Context, session *session.Session, newQuery *genai.Content) iter.Seq2[*Event, error] {\n    return func(yield func(*Event, error) bool) {\n        // 1. Append new_query to session event history (via SessionService)\n        // ...\n        userEvent := session.NewEvent(ctx.InvocationID()) // Simplified for conceptual view\n        userEvent.Author = \"user\"\n        userEvent.LLMResponse = model.LLMResponse{Content: newQuery}\n\n        if _, err := r.sessionService.Append(ctx, &session.AppendRequest{Event: userEvent}); err != nil {\n            yield(nil, err)\n            return\n        }\n\n        // 2. Kick off event stream by calling the agent\n        // Assuming agent.Run also returns iter.Seq2[*Event, error]\n        agentEventsAndErrs := r.agent.Run(ctx, &agent.RunRequest{Session: session, Input: newQuery})\n\n        for event, err := range agentEventsAndErrs {\n            if err != nil {\n                if !yield(event, err) { // Yield event even if there's an error, then stop\n                    return\n                }\n                return // Agent finished with an error\n            }\n\n            // 3. Process the generated event and commit changes\n            // Only commit non-partial event to a session service (as seen in actual code)\n            if !event.LLMResponse.Partial {\n                if _, err := r.sessionService.Append(ctx, &session.AppendRequest{Event: event}); err != nil {\n                    yield(nil, err)\n                    return\n                }\n            }\n            // memory_service.update_memory(...) // If applicable\n            // artifact_service might have already been called via context during agent run\n\n            // 4. Yield event for upstream processing\n            if !yield(event, nil) {\n                return // Upstream consumer stopped\n            }\n        }\n        // Agent finished successfully\n    }\n}"}, {"language": "text", "code": "// Simplified conceptual view of the Runner's main loop logic in Java.\npublic Flowable<Event> runConceptual(\n    Session session,\n    InvocationContext invocationContext,\n    Content newQuery\n    ) {\n\n    // 1. Append new_query to session event history (via SessionService)\n    // ...\n    sessionService.appendEvent(session, userEvent).blockingGet();\n\n    // 2. Kick off event stream by calling the agent\n    Flowable<Event> agentEventStream = agentToRun.runAsync(invocationContext);\n\n    // 3. Process each generated event, commit changes, and \"yield\" or \"emit\"\n    return agentEventStream.map(event -> {\n        // This mutates the session object (adds event, applies stateDelta).\n        // The return value of appendEvent (a Single<Event>) is conceptually\n        // just the event itself after processing.\n        sessionService.appendEvent(session, event).blockingGet(); // Simplified blocking call\n\n        // memory_service.update_memory(...) // If applicable - conceptual\n        // artifact_service might have already been called via context during agent run\n\n        // 4. \"Yield\" event for upstream processing\n        //    In RxJava, returning the event in map effectively yields it to the next operator or subscriber.\n        return event;\n    });\n}"}]}, {"heading_path": ["Execution Logic's Role (Agent, Tool, Callback)\u00b6"], "text": "Execution Logic's Role (Agent, Tool, Callback) \u00b6 Your code within agents, tools, and callbacks is responsible for the actual computation and decision-making. Its interaction with the loop involves: Execute: Runs its logic based on the current InvocationContext , including the session state as it was when execution resumed . Yield: When the logic needs to communicate (send a message, call a tool, report a state change), it constructs an Event containing the relevant content and actions, and then yield s this event back to the Runner . Pause: Crucially, execution of the agent logic pauses immediately after the yield statement (or return in RxJava). It waits for the Runner to complete step 3 (processing and committing). Resume: Only after the Runner has processed the yielded event does the agent logic resume execution from the statement immediately following the yield . See Updated State: Upon resumption, the agent logic can now reliably access the session state ( ctx.session.state ) reflecting the changes that were committed by the Runner from the previously yielded event. Conceptual Execution Logic: Python Go Java # Simplified view of logic inside Agent.run_async, callbacks, or tools # ... previous code runs based on current state ... # 1. Determine a change or output is needed, construct the event # Example: Updating state update_data = { 'field_1' : 'value_2' } event_with_state_change = Event ( author = self . name , actions = EventActions ( state_delta = update_data ), content = types . Content ( parts = [ types . Part ( text = \"State updated.\" )]) # ... other event fields ... ) # 2. Yield the event to the Runner for processing & commit yield event_with_state_change # <<<<<<<<<<<< EXECUTION PAUSES HERE >>>>>>>>>>>> # <<<<<<<<<<<< RUNNER PROCESSES & COMMITS THE EVENT >>>>>>>>>>>> # 3. Resume execution ONLY after Runner is done processing the above event. # Now, the state committed by the Runner is reliably reflected. # Subsequent code can safely assume the change from the yielded event happened. val = ctx . session . state [ 'field_1' ] # here `val` is guaranteed to be \"value_2\" (assuming Runner committed successfully) print ( f \"Resumed execution. Value of field_1 is now: { val } \" ) # ... subsequent code continues ... # Maybe yield another event later... // Simplified view of logic inside Agent.Run, callbacks, or tools // ... previous code runs based on current state ... // 1. Determine a change or output is needed, construct the event // Example: Updating state updateData := map [ string ] interface {}{ \"field_1\" : \"value_2\" } eventWithStateChange := & Event { Author : self . Name (), Actions : & EventActions { StateDelta : updateData }, Content : genai . NewContentFromText ( \"State updated.\" , \"model\" ), // ... other event fields ... } // 2. Yield the event to the Runner for processing & commit // In Go, this is done by sending the event to a channel. eventsChan <- eventWithStateChange // <<<<<<<<<<<< EXECUTION PAUSES HERE (conceptually) >>>>>>>>>>>> // The Runner on the other side of the channel will receive and process the event. // The agent's goroutine might continue, but the logical flow waits for the next input or step. // <<<<<<<<<<<< RUNNER PROCESSES & COMMITS THE EVENT >>>>>>>>>>>> // 3. Resume execution ONLY after Runner is done processing the above event. // In a real Go implementation, this would likely be handled by the agent receiving // a new RunRequest or context indicating the next step. The updated state // would be part of the session object in that new request. // For this conceptual example, we'll just check the state. val := ctx . State . Get ( \"field_1\" ) // here `val` is guaranteed to be \"value_2\" because the Runner would have // updated the session state before calling the agent again. fmt . Printf ( \"Resumed execution. Value of field_1 is now: %v\\n\" , val ) // ... subsequent code continues ... // Maybe send another event to the channel later... // Simplified view of logic inside Agent.runAsync, callbacks, or tools // ... previous code runs based on current state ... // 1. Determine a change or output is needed, construct the event // Example: Updating state ConcurrentMap < String , Object > updateData = new ConcurrentHashMap <> (); updateData . put ( \"field_1\" , \"value_2\" ); EventActions actions = EventActions . builder (). stateDelta ( updateData ). build (); Content eventContent = Content . builder (). parts ( Part . fromText ( \"State updated.\" )). build (); Event eventWithStateChange = Event . builder () . author ( self . name ()) . actions ( actions ) . content ( Optional . of ( eventContent )) // ... other event fields ... . build (); // 2. \"Yield\" the event. In RxJava, this means emitting it into the stream. //    The Runner (or upstream consumer) will subscribe to this Flowable. //    When the Runner receives this event, it will process it (e.g., call sessionService.appendEvent). //    The 'appendEvent' in Java ADK mutates the 'Session' object held within 'ctx' (InvocationContext). // <<<<<<<<<<<< CONCEPTUAL PAUSE POINT >>>>>>>>>>>> // In RxJava, the emission of 'eventWithStateChange' happens, and then the stream // might continue with a 'flatMap' or 'concatMap' operator that represents // the logic *after* the Runner has processed this event. // To model the \"resume execution ONLY after Runner is done processing\": // The Runner's `appendEvent` is usually an async operation itself (returns Single<Event>). // The agent's flow needs to be structured such that subsequent logic // that depends on the committed state runs *after* that `appendEvent` completes. // This is how the Runner typically orchestrates it: // Runner: //   agent.runAsync(ctx) //     .concatMapEager(eventFromAgent -> //         sessionService.appendEvent(ctx.session(), eventFromAgent) // This updates ctx.session().state() //             .toFlowable() // Emits the event after it's processed //     ) //     .subscribe(processedEvent -> { /* UI renders processedEvent */ }); // So, within the agent's own logic, if it needs to do something *after* an event it yielded // has been processed and its state changes are reflected in ctx.session().state(), // that subsequent logic would typically be in another step of its reactive chain. // For this conceptual example, we'll emit the event, and then simulate the \"resume\" // as a subsequent operation in the Flowable chain. return Flowable . just ( eventWithStateChange ) // Step 2: Yield the event . concatMap ( yieldedEvent -> { // <<<<<<<<<<<< RUNNER CONCEPTUALLY PROCESSES & COMMITS THE EVENT >>>>>>>>>>>> // At this point, in a real runner, ctx.session().appendEvent(yieldedEvent) would have been called // by the Runner, and ctx.session().state() would be updated. // Since we are *inside* the agent's conceptual logic trying to model this, // we assume the Runner's action has implicitly updated our 'ctx.session()'. // 3. Resume execution. // Now, the state committed by the Runner (via sessionService.appendEvent) // is reliably reflected in ctx.session().state(). Object val = ctx . session (). state (). get ( \"field_1\" ); // here `val` is guaranteed to be \"value_2\" because the `sessionService.appendEvent` // called by the Runner would have updated the session state within the `ctx` object. System . out . println ( \"Resumed execution. Value of field_1 is now: \" + val ); // ... subsequent code continues ... // If this subsequent code needs to yield another event, it would do so here. This cooperative yield/pause/resume cycle between the Runner and your Execution Logic, mediated by Event objects, forms the core of the ADK Runtime. ", "code_blocks": [{"language": "text", "code": "# Simplified view of logic inside Agent.run_async, callbacks, or tools\n\n# ... previous code runs based on current state ...\n\n# 1. Determine a change or output is needed, construct the event\n# Example: Updating state\nupdate_data = {'field_1': 'value_2'}\nevent_with_state_change = Event(\n    author=self.name,\n    actions=EventActions(state_delta=update_data),\n    content=types.Content(parts=[types.Part(text=\"State updated.\")])\n    # ... other event fields ...\n)\n\n# 2. Yield the event to the Runner for processing & commit\nyield event_with_state_change\n# <<<<<<<<<<<< EXECUTION PAUSES HERE >>>>>>>>>>>>\n\n# <<<<<<<<<<<< RUNNER PROCESSES & COMMITS THE EVENT >>>>>>>>>>>>\n\n# 3. Resume execution ONLY after Runner is done processing the above event.\n# Now, the state committed by the Runner is reliably reflected.\n# Subsequent code can safely assume the change from the yielded event happened.\nval = ctx.session.state['field_1']\n# here `val` is guaranteed to be \"value_2\" (assuming Runner committed successfully)\nprint(f\"Resumed execution. Value of field_1 is now: {val}\")\n\n# ... subsequent code continues ...\n# Maybe yield another event later..."}, {"language": "text", "code": "// Simplified view of logic inside Agent.Run, callbacks, or tools\n\n// ... previous code runs based on current state ...\n\n// 1. Determine a change or output is needed, construct the event\n// Example: Updating state\nupdateData := map[string]interface{}{\"field_1\": \"value_2\"}\neventWithStateChange := &Event{\n    Author: self.Name(),\n    Actions: &EventActions{StateDelta: updateData},\n    Content: genai.NewContentFromText(\"State updated.\", \"model\"),\n    // ... other event fields ...\n}\n\n// 2. Yield the event to the Runner for processing & commit\n// In Go, this is done by sending the event to a channel.\neventsChan <- eventWithStateChange\n// <<<<<<<<<<<< EXECUTION PAUSES HERE (conceptually) >>>>>>>>>>>>\n// The Runner on the other side of the channel will receive and process the event.\n// The agent's goroutine might continue, but the logical flow waits for the next input or step.\n\n// <<<<<<<<<<<< RUNNER PROCESSES & COMMITS THE EVENT >>>>>>>>>>>>\n\n// 3. Resume execution ONLY after Runner is done processing the above event.\n// In a real Go implementation, this would likely be handled by the agent receiving\n// a new RunRequest or context indicating the next step. The updated state\n// would be part of the session object in that new request.\n// For this conceptual example, we'll just check the state.\nval := ctx.State.Get(\"field_1\")\n// here `val` is guaranteed to be \"value_2\" because the Runner would have\n// updated the session state before calling the agent again.\nfmt.Printf(\"Resumed execution. Value of field_1 is now: %v\\n\", val)\n\n// ... subsequent code continues ...\n// Maybe send another event to the channel later..."}, {"language": "text", "code": "// Simplified view of logic inside Agent.runAsync, callbacks, or tools\n// ... previous code runs based on current state ...\n\n// 1. Determine a change or output is needed, construct the event\n// Example: Updating state\nConcurrentMap<String, Object> updateData = new ConcurrentHashMap<>();\nupdateData.put(\"field_1\", \"value_2\");\n\nEventActions actions = EventActions.builder().stateDelta(updateData).build();\nContent eventContent = Content.builder().parts(Part.fromText(\"State updated.\")).build();\n\nEvent eventWithStateChange = Event.builder()\n    .author(self.name())\n    .actions(actions)\n    .content(Optional.of(eventContent))\n    // ... other event fields ...\n    .build();\n\n// 2. \"Yield\" the event. In RxJava, this means emitting it into the stream.\n//    The Runner (or upstream consumer) will subscribe to this Flowable.\n//    When the Runner receives this event, it will process it (e.g., call sessionService.appendEvent).\n//    The 'appendEvent' in Java ADK mutates the 'Session' object held within 'ctx' (InvocationContext).\n\n// <<<<<<<<<<<< CONCEPTUAL PAUSE POINT >>>>>>>>>>>>\n// In RxJava, the emission of 'eventWithStateChange' happens, and then the stream\n// might continue with a 'flatMap' or 'concatMap' operator that represents\n// the logic *after* the Runner has processed this event.\n\n// To model the \"resume execution ONLY after Runner is done processing\":\n// The Runner's `appendEvent` is usually an async operation itself (returns Single<Event>).\n// The agent's flow needs to be structured such that subsequent logic\n// that depends on the committed state runs *after* that `appendEvent` completes.\n\n// This is how the Runner typically orchestrates it:\n// Runner:\n//   agent.runAsync(ctx)\n//     .concatMapEager(eventFromAgent ->\n//         sessionService.appendEvent(ctx.session(), eventFromAgent) // This updates ctx.session().state()\n//             .toFlowable() // Emits the event after it's processed\n//     )\n//     .subscribe(processedEvent -> { /* UI renders processedEvent */ });\n\n// So, within the agent's own logic, if it needs to do something *after* an event it yielded\n// has been processed and its state changes are reflected in ctx.session().state(),\n// that subsequent logic would typically be in another step of its reactive chain.\n\n// For this conceptual example, we'll emit the event, and then simulate the \"resume\"\n// as a subsequent operation in the Flowable chain.\n\nreturn Flowable.just(eventWithStateChange) // Step 2: Yield the event\n    .concatMap(yieldedEvent -> {\n        // <<<<<<<<<<<< RUNNER CONCEPTUALLY PROCESSES & COMMITS THE EVENT >>>>>>>>>>>>\n        // At this point, in a real runner, ctx.session().appendEvent(yieldedEvent) would have been called\n        // by the Runner, and ctx.session().state() would be updated.\n        // Since we are *inside* the agent's conceptual logic trying to model this,\n        // we assume the Runner's action has implicitly updated our 'ctx.session()'.\n\n        // 3. Resume execution.\n        // Now, the state committed by the Runner (via sessionService.appendEvent)\n        // is reliably reflected in ctx.session().state().\n        Object val = ctx.session().state().get(\"field_1\");\n        // here `val` is guaranteed to be \"value_2\" because the `sessionService.appendEvent`\n        // called by the Runner would have updated the session state within the `ctx` object.\n\n        System.out.println(\"Resumed execution. Value of field_1 is now: \" + val);\n\n        // ... subsequent code continues ...\n        // If this subsequent code needs to yield another event, it would do so here."}]}, {"heading_path": ["Key components of the Runtime\u00b6"], "text": "Key components of the Runtime \u00b6 Several components work together within the ADK Runtime to execute an agent invocation. Understanding their roles clarifies how the event loop functions: ", "code_blocks": []}, {"heading_path": ["Runner\u00b6"], "text": "Runner \u00b6 Role: The main entry point and orchestrator for a single user query ( run_async ). Function: Manages the overall Event Loop, receives events yielded by the Execution Logic, coordinates with Services to process and commit event actions (state/artifact changes), and forwards processed events upstream (e.g., to the UI). It essentially drives the conversation turn by turn based on yielded events. (Defined in google.adk.runners.runner ). ", "code_blocks": []}, {"heading_path": ["Execution Logic Components\u00b6"], "text": "Execution Logic Components \u00b6 Role: The parts containing your custom code and the core agent capabilities. Components: Agent ( BaseAgent , LlmAgent , etc.): Your primary logic units that process information and decide on actions. They implement the _run_async_impl method which yields events. Tools ( BaseTool , FunctionTool , AgentTool , etc.): External functions or capabilities used by agents (often LlmAgent ) to interact with the outside world or perform specific tasks. They execute and return results, which are then wrapped in events. Callbacks (Functions): User-defined functions attached to agents (e.g., before_agent_callback , after_model_callback ) that hook into specific points in the execution flow, potentially modifying behavior or state, whose effects are captured in events. Function: Perform the actual thinking, calculation, or external interaction. They communicate their results or needs by yielding Event objects and pausing until the Runner processes them. ", "code_blocks": []}, {"heading_path": ["Event\u00b6"], "text": "Event \u00b6 Role: The message passed back and forth between the Runner and the Execution Logic. Function: Represents an atomic occurrence (user input, agent text, tool call/result, state change request, control signal). It carries both the content of the occurrence and the intended side effects ( actions like state_delta ). ", "code_blocks": []}, {"heading_path": ["Services\u00b6"], "text": "Services \u00b6 Role: Backend components responsible for managing persistent or shared resources. Used primarily by the Runner during event processing. Components: SessionService ( BaseSessionService , InMemorySessionService , etc.): Manages Session objects, including saving/loading them, applying state_delta to the session state, and appending events to the event history . ArtifactService ( BaseArtifactService , InMemoryArtifactService , GcsArtifactService , etc.): Manages the storage and retrieval of binary artifact data. Although save_artifact is called via context during execution logic, the artifact_delta in the event confirms the action for the Runner/SessionService. MemoryService ( BaseMemoryService , etc.): (Optional) Manages long-term semantic memory across sessions for a user. Function: Provide the persistence layer. The Runner interacts with them to ensure changes signaled by event.actions are reliably stored before the Execution Logic resumes. ", "code_blocks": []}, {"heading_path": ["Session\u00b6"], "text": "Session \u00b6 Role: A data container holding the state and history for one specific conversation between a user and the application. Function: Stores the current state dictionary, the list of all past events ( event history ), and references to associated artifacts. It's the primary record of the interaction, managed by the SessionService . ", "code_blocks": []}, {"heading_path": ["Invocation\u00b6"], "text": "Invocation \u00b6 Role: A conceptual term representing everything that happens in response to a single user query, from the moment the Runner receives it until the agent logic finishes yielding events for that query. Function: An invocation might involve multiple agent runs (if using agent transfer or AgentTool ), multiple LLM calls, tool executions, and callback executions, all tied together by a single invocation_id within the InvocationContext . State variables prefixed with temp: are strictly scoped to a single invocation and discarded afterwards. These players interact continuously through the Event Loop to process a user's request. ", "code_blocks": []}, {"heading_path": ["How It Works: A Simplified Invocation\u00b6"], "text": "How It Works: A Simplified Invocation \u00b6 Let's trace a simplified flow for a typical user query that involves an LLM agent calling a tool: ", "code_blocks": []}, {"heading_path": ["Step-by-Step Breakdown\u00b6"], "text": "Step-by-Step Breakdown \u00b6 User Input: The User sends a query (e.g., \"What's the capital of France?\"). Runner Starts: Runner.run_async begins. It interacts with the SessionService to load the relevant Session and adds the user query as the first Event to the session history. An InvocationContext ( ctx ) is prepared. Agent Execution: The Runner calls agent.run_async(ctx) on the designated root agent (e.g., an LlmAgent ). LLM Call (Example): The Agent_Llm determines it needs information, perhaps by calling a tool. It prepares a request for the LLM . Let's assume the LLM decides to call MyTool . Yield FunctionCall Event: The Agent_Llm receives the FunctionCall response from the LLM, wraps it in an Event(author='Agent_Llm', content=Content(parts=[Part(function_call=...)])) , and yields or emits this event. Agent Pauses: The Agent_Llm 's execution pauses immediately after the yield . Runner Processes: The Runner receives the FunctionCall event. It passes it to the SessionService to record it in the history. The Runner then yields the event upstream to the User (or application). Agent Resumes: The Runner signals that the event is processed, and Agent_Llm resumes execution. Tool Execution: The Agent_Llm 's internal flow now proceeds to execute the requested MyTool . It calls tool.run_async(...) . Tool Returns Result: MyTool executes and returns its result (e.g., {'result': 'Paris'} ). Yield FunctionResponse Event: The agent ( Agent_Llm ) wraps the tool result into an Event containing a FunctionResponse part (e.g., Event(author='Agent_Llm', content=Content(role='user', parts=[Part(function_response=...)])) ). This event might also contain actions if the tool modified state ( state_delta ) or saved artifacts ( artifact_delta ). The agent yield s this event. Agent Pauses: Agent_Llm pauses again. Runner Processes: Runner receives the FunctionResponse event. It passes it to SessionService which applies any state_delta / artifact_delta and adds the event to history. Runner yields the event upstream. Agent Resumes: Agent_Llm resumes, now knowing the tool result and any state changes are committed. Final LLM Call (Example): Agent_Llm sends the tool result back to the LLM to generate a natural language response. Yield Final Text Event: Agent_Llm receives the final text from the LLM , wraps it in an Event(author='Agent_Llm', content=Content(parts=[Part(text=...)])) , and yield s it. Agent Pauses: Agent_Llm pauses. Runner Processes: Runner receives the final text event, passes it to SessionService for history, and yields it upstream to the User . This is likely marked as the is_final_response() . Agent Resumes & Finishes: Agent_Llm resumes. Having completed its task for this invocation, its run_async generator finishes. Runner Completes: The Runner sees the agent's generator is exhausted and finishes its loop for this invocation. This yield/pause/process/resume cycle ensures that state changes are consistently applied and that the execution logic always operates on the most recently committed state after yielding an event. ", "code_blocks": []}, {"heading_path": ["Important Runtime Behaviors\u00b6"], "text": "Important Runtime Behaviors \u00b6 Understanding a few key aspects of how the ADK Runtime handles state, streaming, and asynchronous operations is crucial for building predictable and efficient agents. ", "code_blocks": []}, {"heading_path": ["State Updates & Commitment Timing\u00b6"], "text": "State Updates & Commitment Timing \u00b6 The Rule: When your code (in an agent, tool, or callback) modifies the session state (e.g., context.state['my_key'] = 'new_value' ), this change is initially recorded locally within the current InvocationContext . The change is only guaranteed to be persisted (saved by the SessionService ) after the Event carrying the corresponding state_delta in its actions has been yield -ed by your code and subsequently processed by the Runner . Implication: Code that runs after resuming from a yield can reliably assume that the state changes signaled in the yielded event have been committed. Python Go Java # Inside agent logic (conceptual) # 1. Modify state ctx . session . state [ 'status' ] = 'processing' event1 = Event ( ... , actions = EventActions ( state_delta = { 'status' : 'processing' })) # 2. Yield event with the delta yield event1 # --- PAUSE --- Runner processes event1, SessionService commits 'status' = 'processing' --- # 3. Resume execution # Now it's safe to rely on the committed state current_status = ctx . session . state [ 'status' ] # Guaranteed to be 'processing' print ( f \"Status after resuming: { current_status } \" ) // Inside agent logic (conceptual) func ( a * Agent ) RunConceptual ( ctx agent . InvocationContext ) iter . Seq2 [ * session . Event , error ] { // The entire logic is wrapped in a function that will be returned as an iterator. return func ( yield func ( * session . Event , error ) bool ) { // ... previous code runs based on current state from the input `ctx` ... // e.g., val := ctx.State().Get(\"field_1\") might return \"value_1\" here. // 1. Determine a change or output is needed, construct the event updateData := map [ string ] interface {}{ \"field_1\" : \"value_2\" } eventWithStateChange := session . NewEvent ( ctx . InvocationID ()) eventWithStateChange . Author = a . Name () eventWithStateChange . Actions = & session . EventActions { StateDelta : updateData } // ... other event fields ... // 2. Yield the event to the Runner for processing & commit. // The agent's execution continues immediately after this call. if ! yield ( eventWithStateChange , nil ) { // If yield returns false, it means the consumer (the Runner) // has stopped listening, so we should stop producing events. return } // <<<<<<<<<<<< RUNNER PROCESSES & COMMITS THE EVENT >>>>>>>>>>>> // This happens outside the agent, after the agent's iterator has // produced the event. // 3. The agent CANNOT immediately see the state change it just yielded. // The state is immutable within a single `Run` invocation. val := ctx . State (). Get ( \"field_1\" ) // `val` here is STILL \"value_1\" (or whatever it was at the start). // The updated state (\"value_2\") will only be available in the `ctx` // of the *next* `Run` invocation in a subsequent turn. // ... subsequent code continues, potentially yielding more events ... finalEvent := session . NewEvent ( ctx . InvocationID ()) finalEvent . Author = a . Name () // ... yield ( finalEvent , nil ) } } // Inside agent logic (conceptual) // ... previous code runs based on current state ... // 1. Prepare state modification and construct the event ConcurrentHashMap < String , Object > stateChanges = new ConcurrentHashMap <> (); stateChanges . put ( \"status\" , \"processing\" ); EventActions actions = EventActions . builder (). stateDelta ( stateChanges ). build (); Content content = Content . builder (). parts ( Part . fromText ( \"Status update: processing\" )). build (); Event event1 = Event . builder () . actions ( actions ) // ... . build (); // 2. Yield event with the delta return Flowable . just ( event1 ) . map ( emittedEvent -> { // --- CONCEPTUAL PAUSE & RUNNER PROCESSING --- // 3. Resume execution (conceptually) // Now it's safe to rely on the committed state. String currentStatus = ( String ) ctx . session (). state (). get ( \"status\" ); System . out . println ( \"Status after resuming (inside agent logic): \" + currentStatus ); // Guaranteed to be 'processing' // The event itself (event1) is passed on. // If subsequent logic within this agent step produced *another* event, // you'd use concatMap to emit that new event. return emittedEvent ; }); // ... subsequent agent logic might involve further reactive operators // or emitting more events based on the now-updated `ctx.session().state()`. ", "code_blocks": [{"language": "text", "code": "# Inside agent logic (conceptual)\n\n# 1. Modify state\nctx.session.state['status'] = 'processing'\nevent1 = Event(..., actions=EventActions(state_delta={'status': 'processing'}))\n\n# 2. Yield event with the delta\nyield event1\n# --- PAUSE --- Runner processes event1, SessionService commits 'status' = 'processing' ---\n\n# 3. Resume execution\n# Now it's safe to rely on the committed state\ncurrent_status = ctx.session.state['status'] # Guaranteed to be 'processing'\nprint(f\"Status after resuming: {current_status}\")"}, {"language": "text", "code": "// Inside agent logic (conceptual)\n\nfunc (a *Agent) RunConceptual(ctx agent.InvocationContext) iter.Seq2[*session.Event, error] {\n  // The entire logic is wrapped in a function that will be returned as an iterator.\n  return func(yield func(*session.Event, error) bool) {\n      // ... previous code runs based on current state from the input `ctx` ...\n      // e.g., val := ctx.State().Get(\"field_1\") might return \"value_1\" here.\n\n      // 1. Determine a change or output is needed, construct the event\n      updateData := map[string]interface{}{\"field_1\": \"value_2\"}\n      eventWithStateChange := session.NewEvent(ctx.InvocationID())\n      eventWithStateChange.Author = a.Name()\n      eventWithStateChange.Actions = &session.EventActions{StateDelta: updateData}\n      // ... other event fields ...\n\n\n      // 2. Yield the event to the Runner for processing & commit.\n      // The agent's execution continues immediately after this call.\n      if !yield(eventWithStateChange, nil) {\n          // If yield returns false, it means the consumer (the Runner)\n          // has stopped listening, so we should stop producing events.\n          return\n      }\n\n      // <<<<<<<<<<<< RUNNER PROCESSES & COMMITS THE EVENT >>>>>>>>>>>>\n      // This happens outside the agent, after the agent's iterator has\n      // produced the event.\n\n      // 3. The agent CANNOT immediately see the state change it just yielded.\n      // The state is immutable within a single `Run` invocation.\n      val := ctx.State().Get(\"field_1\")\n      // `val` here is STILL \"value_1\" (or whatever it was at the start).\n      // The updated state (\"value_2\") will only be available in the `ctx`\n      // of the *next* `Run` invocation in a subsequent turn.\n\n      // ... subsequent code continues, potentially yielding more events ...\n      finalEvent := session.NewEvent(ctx.InvocationID())\n      finalEvent.Author = a.Name()\n      // ...\n      yield(finalEvent, nil)\n  }\n}"}, {"language": "text", "code": "// Inside agent logic (conceptual)\n// ... previous code runs based on current state ...\n\n// 1. Prepare state modification and construct the event\nConcurrentHashMap<String, Object> stateChanges = new ConcurrentHashMap<>();\nstateChanges.put(\"status\", \"processing\");\n\nEventActions actions = EventActions.builder().stateDelta(stateChanges).build();\nContent content = Content.builder().parts(Part.fromText(\"Status update: processing\")).build();\n\nEvent event1 = Event.builder()\n    .actions(actions)\n    // ...\n    .build();\n\n// 2. Yield event with the delta\nreturn Flowable.just(event1)\n    .map(\n        emittedEvent -> {\n            // --- CONCEPTUAL PAUSE & RUNNER PROCESSING ---\n            // 3. Resume execution (conceptually)\n            // Now it's safe to rely on the committed state.\n            String currentStatus = (String) ctx.session().state().get(\"status\");\n            System.out.println(\"Status after resuming (inside agent logic): \" + currentStatus); // Guaranteed to be 'processing'\n\n            // The event itself (event1) is passed on.\n            // If subsequent logic within this agent step produced *another* event,\n            // you'd use concatMap to emit that new event.\n            return emittedEvent;\n        });\n\n// ... subsequent agent logic might involve further reactive operators\n// or emitting more events based on the now-updated `ctx.session().state()`."}]}, {"heading_path": ["\"Dirty Reads\" of Session State\u00b6"], "text": "\"Dirty Reads\" of Session State \u00b6 Definition: While commitment happens after the yield, code running later within the same invocation , but before the state-changing event is actually yielded and processed, can often see the local, uncommitted changes . This is sometimes called a \"dirty read\". Example: Python Go Java # Code in before_agent_callback callback_context . state [ 'field_1' ] = 'value_1' # State is locally set to 'value_1', but not yet committed by Runner # ... agent runs ... # Code in a tool called later *within the same invocation* # Readable (dirty read), but 'value_1' isn't guaranteed persistent yet. val = tool_context . state [ 'field_1' ] # 'val' will likely be 'value_1' here print ( f \"Dirty read value in tool: { val } \" ) # Assume the event carrying the state_delta={'field_1': 'value_1'} # is yielded *after* this tool runs and is processed by the Runner. // Code in before_agent_callback // The callback would modify the context's session state directly. // This change is local to the current invocation context. ctx . State . Set ( \"field_1\" , \"value_1\" ) // State is locally set to 'value_1', but not yet committed by Runner // ... agent runs ... // Code in a tool called later *within the same invocation* // Readable (dirty read), but 'value_1' isn't guaranteed persistent yet. val := ctx . State . Get ( \"field_1\" ) // 'val' will likely be 'value_1' here fmt . Printf ( \"Dirty read value in tool: %v\\n\" , val ) // Assume the event carrying the state_delta={'field_1': 'value_1'} // is yielded *after* this tool runs and is processed by the Runner. // Modify state - Code in BeforeAgentCallback // AND stages this change in callbackContext.eventActions().stateDelta(). callbackContext . state (). put ( \"field_1\" , \"value_1\" ); // --- agent runs ... --- // --- Code in a tool called later *within the same invocation* --- // Readable (dirty read), but 'value_1' isn't guaranteed persistent yet. Object val = toolContext . state (). get ( \"field_1\" ); // 'val' will likely be 'value_1' here System . out . println ( \"Dirty read value in tool: \" + val ); // Assume the event carrying the state_delta={'field_1': 'value_1'} // is yielded *after* this tool runs and is processed by the Runner. Implications: Benefit: Allows different parts of your logic within a single complex step (e.g., multiple callbacks or tool calls before the next LLM turn) to coordinate using state without waiting for a full yield/commit cycle. Caveat: Relying heavily on dirty reads for critical logic can be risky. If the invocation fails before the event carrying the state_delta is yielded and processed by the Runner , the uncommitted state change will be lost. For critical state transitions, ensure they are associated with an event that gets successfully processed. ", "code_blocks": [{"language": "text", "code": "# Code in before_agent_callback\ncallback_context.state['field_1'] = 'value_1'\n# State is locally set to 'value_1', but not yet committed by Runner\n\n# ... agent runs ...\n\n# Code in a tool called later *within the same invocation*\n# Readable (dirty read), but 'value_1' isn't guaranteed persistent yet.\nval = tool_context.state['field_1'] # 'val' will likely be 'value_1' here\nprint(f\"Dirty read value in tool: {val}\")\n\n# Assume the event carrying the state_delta={'field_1': 'value_1'}\n# is yielded *after* this tool runs and is processed by the Runner."}, {"language": "text", "code": "// Code in before_agent_callback\n// The callback would modify the context's session state directly.\n// This change is local to the current invocation context.\nctx.State.Set(\"field_1\", \"value_1\")\n// State is locally set to 'value_1', but not yet committed by Runner\n\n// ... agent runs ...\n\n// Code in a tool called later *within the same invocation*\n// Readable (dirty read), but 'value_1' isn't guaranteed persistent yet.\nval := ctx.State.Get(\"field_1\") // 'val' will likely be 'value_1' here\nfmt.Printf(\"Dirty read value in tool: %v\\n\", val)\n\n// Assume the event carrying the state_delta={'field_1': 'value_1'}\n// is yielded *after* this tool runs and is processed by the Runner."}, {"language": "text", "code": "// Modify state - Code in BeforeAgentCallback\n// AND stages this change in callbackContext.eventActions().stateDelta().\ncallbackContext.state().put(\"field_1\", \"value_1\");\n\n// --- agent runs ... ---\n\n// --- Code in a tool called later *within the same invocation* ---\n// Readable (dirty read), but 'value_1' isn't guaranteed persistent yet.\nObject val = toolContext.state().get(\"field_1\"); // 'val' will likely be 'value_1' here\nSystem.out.println(\"Dirty read value in tool: \" + val);\n// Assume the event carrying the state_delta={'field_1': 'value_1'}\n// is yielded *after* this tool runs and is processed by the Runner."}]}, {"heading_path": ["Streaming vs. Non-Streaming Output (partial=True)\u00b6"], "text": "Streaming vs. Non-Streaming Output ( partial=True ) \u00b6 This primarily relates to how responses from the LLM are handled, especially when using streaming generation APIs. Streaming: The LLM generates its response token-by-token or in small chunks. The framework (often within BaseLlmFlow ) yields multiple Event objects for a single conceptual response. Most of these events will have partial=True . The Runner , upon receiving an event with partial=True , typically forwards it immediately upstream (for UI display) but skips processing its actions (like state_delta ). Eventually, the framework yields a final event for that response, marked as non-partial ( partial=False or implicitly via turn_complete=True ). The Runner fully processes only this final event , committing any associated state_delta or artifact_delta . Non-Streaming: The LLM generates the entire response at once. The framework yields a single event marked as non-partial, which the Runner processes fully. Why it Matters: Ensures that state changes are applied atomically and only once based on the complete response from the LLM, while still allowing the UI to display text progressively as it's generated. ", "code_blocks": []}, {"heading_path": ["Async is Primary (run_async)\u00b6"], "text": "Async is Primary ( run_async ) \u00b6 Core Design: The ADK Runtime is fundamentally built on asynchronous libraries (like Python's asyncio and Java's RxJava ) to handle concurrent operations (like waiting for LLM responses or tool executions) efficiently without blocking. Main Entry Point: Runner.run_async is the primary method for executing agent invocations. All core runnable components (Agents, specific flows) use asynchronous methods internally. Synchronous Convenience ( run ): A synchronous Runner.run method exists mainly for convenience (e.g., in simple scripts or testing environments). However, internally, Runner.run typically just calls Runner.run_async and manages the async event loop execution for you. Developer Experience: We recommend designing your applications (e.g., web servers using ADK) to be asynchronous for best performance. In Python, this means using asyncio ; in Java, leverage RxJava 's reactive programming model. Sync Callbacks/Tools: The ADK framework supports both asynchronous and synchronous functions for tools and callbacks. Blocking I/O: For long-running synchronous I/O operations, the framework attempts to prevent stalls. Python ADK may use asyncio.to_thread, while Java ADK often relies on appropriate RxJava schedulers or wrappers for blocking calls. CPU-Bound Work: Purely CPU-intensive synchronous tasks will still block their execution thread in both environments. Understanding these behaviors helps you write more robust ADK applications and debug issues related to state consistency, streaming updates, and asynchronous execution. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:22.587447", "source_type": "adk-docs"}
{"doc_id": "fa52e7b1ce5ed4df0db99e96de78868735adf629a723776a70ec457c64f474f6", "url": "https://google.github.io/adk-docs/runtime/runconfig", "title": "Runtime Config - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Runtime Configuration\u00b6"], "text": "Runtime Configuration \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 RunConfig defines runtime behavior and options for agents in the ADK. It\ncontrols speech and streaming settings, function calling, artifact saving, and\nlimits on LLM calls. When constructing an agent run, you can pass a RunConfig to customize how the\nagent interacts with models, handles audio, and streams responses. By default,\nno streaming is enabled and inputs aren\u2019t retained as artifacts. Use RunConfig to override these defaults. ", "code_blocks": []}, {"heading_path": ["Class Definition\u00b6"], "text": "Class Definition \u00b6 The RunConfig class holds configuration parameters for an agent's runtime behavior. Python ADK uses Pydantic for this validation. Go ADK has mutable structs by default. Java ADK typically uses immutable data classes. Python Go Java class RunConfig ( BaseModel ): \"\"\"Configs for runtime behavior of agents.\"\"\" model_config = ConfigDict ( extra = 'forbid' , ) speech_config : Optional [ types . SpeechConfig ] = None response_modalities : Optional [ list [ str ]] = None save_input_blobs_as_artifacts : bool = False support_cfc : bool = False streaming_mode : StreamingMode = StreamingMode . NONE output_audio_transcription : Optional [ types . AudioTranscriptionConfig ] = None max_llm_calls : int = 500 type StreamingMode string const ( StreamingModeNone StreamingMode = \"none\" StreamingModeSSE StreamingMode = \"sse\" ) // RunConfig controls runtime behavior. type RunConfig struct { // Streaming mode, None or StreamingMode.SSE. StreamingMode StreamingMode // Whether or not to save the input blobs as artifacts SaveInputBlobsAsArtifacts bool } public abstract class RunConfig { public enum StreamingMode { NONE , SSE , BIDI } public abstract @Nullable SpeechConfig speechConfig (); public abstract ImmutableList < Modality > responseModalities (); public abstract boolean saveInputBlobsAsArtifacts (); public abstract @Nullable AudioTranscriptionConfig outputAudioTranscription (); public abstract int maxLlmCalls (); // ... } ", "code_blocks": [{"language": "text", "code": "class RunConfig(BaseModel):\n    \"\"\"Configs for runtime behavior of agents.\"\"\"\n\n    model_config = ConfigDict(\n        extra='forbid',\n    )\n\n    speech_config: Optional[types.SpeechConfig] = None\n    response_modalities: Optional[list[str]] = None\n    save_input_blobs_as_artifacts: bool = False\n    support_cfc: bool = False\n    streaming_mode: StreamingMode = StreamingMode.NONE\n    output_audio_transcription: Optional[types.AudioTranscriptionConfig] = None\n    max_llm_calls: int = 500"}, {"language": "text", "code": "type StreamingMode string\n\nconst (\n    StreamingModeNone StreamingMode = \"none\"\n    StreamingModeSSE  StreamingMode = \"sse\"\n)\n\n// RunConfig controls runtime behavior.\ntype RunConfig struct {\n    // Streaming mode, None or StreamingMode.SSE.\n    StreamingMode StreamingMode\n    // Whether or not to save the input blobs as artifacts\n    SaveInputBlobsAsArtifacts bool\n}"}, {"language": "text", "code": "public abstract class RunConfig {\n\n  public enum StreamingMode {\n    NONE,\n    SSE,\n    BIDI\n  }\n\n  public abstract @Nullable SpeechConfig speechConfig();\n\n  public abstract ImmutableList<Modality> responseModalities();\n\n  public abstract boolean saveInputBlobsAsArtifacts();\n\n  public abstract @Nullable AudioTranscriptionConfig outputAudioTranscription();\n\n  public abstract int maxLlmCalls();\n\n  // ...\n}"}]}, {"heading_path": ["Runtime Parameters\u00b6"], "text": "Runtime Parameters \u00b6 Parameter Python Type Go Type Java Type Default (Py / Go / Java ) Description speech_config Optional[types.SpeechConfig] N/A SpeechConfig (nullable via @Nullable ) None / N/A / null Configures speech synthesis (voice, language) using the SpeechConfig type. response_modalities Optional[list[str]] N/A ImmutableList<Modality> None / N/A / Empty ImmutableList List of desired output modalities (e.g., Python: [\"TEXT\", \"AUDIO\"] ; Java: uses structured Modality objects). save_input_blobs_as_artifacts bool bool boolean False / false / false If true , saves input blobs (e.g., uploaded files) as run artifacts for debugging/auditing. streaming_mode StreamingMode StreamingMode StreamingMode StreamingMode.NONE / agent.StreamingModeNone / StreamingMode.NONE Sets the streaming behavior: NONE (default), SSE (server-sent events), or BIDI (bidirectional) ( Python/Java ). output_audio_transcription Optional[types.AudioTranscriptionConfig] N/A AudioTranscriptionConfig (nullable via @Nullable ) None / N/A / null Configures transcription of generated audio output using the AudioTranscriptionConfig type. max_llm_calls int N/A int 500 / N/A / 500 Limits total LLM calls per run. 0 or negative means unlimited (warned); sys.maxsize raises ValueError . support_cfc bool N/A bool False / N/A / false Python: Enables Compositional Function Calling. Requires streaming_mode=SSE and uses the LIVE API. Experimental. ", "code_blocks": []}, {"heading_path": ["speech_config\u00b6"], "text": "speech_config \u00b6 Supported in ADK Python v0.1.0 Java v0.1.0 Note The interface or definition of SpeechConfig is the same, irrespective of the language. Speech configuration settings for live agents with audio capabilities. The SpeechConfig class has the following structure: class SpeechConfig ( _common . BaseModel ): \"\"\"The speech generation configuration.\"\"\" voice_config : Optional [ VoiceConfig ] = Field ( default = None , description = \"\"\"The configuration for the speaker to use.\"\"\" , ) language_code : Optional [ str ] = Field ( default = None , description = \"\"\"Language code (ISO 639. e.g. en-US) for the speech synthesization. Only available for Live API.\"\"\" , ) The voice_config parameter uses the VoiceConfig class: class VoiceConfig ( _common . BaseModel ): \"\"\"The configuration for the voice to use.\"\"\" prebuilt_voice_config : Optional [ PrebuiltVoiceConfig ] = Field ( default = None , description = \"\"\"The configuration for the speaker to use.\"\"\" , ) And PrebuiltVoiceConfig has the following structure: class PrebuiltVoiceConfig ( _common . BaseModel ): \"\"\"The configuration for the prebuilt speaker to use.\"\"\" voice_name : Optional [ str ] = Field ( default = None , description = \"\"\"The name of the prebuilt voice to use.\"\"\" , ) These nested configuration classes allow you to specify: voice_config : The name of the prebuilt voice to use (in the PrebuiltVoiceConfig ) language_code : ISO 639 language code (e.g., \"en-US\") for speech synthesis When implementing voice-enabled agents, configure these parameters to control\nhow your agent sounds when speaking. ", "code_blocks": [{"language": "text", "code": "class SpeechConfig(_common.BaseModel):\n    \"\"\"The speech generation configuration.\"\"\"\n\n    voice_config: Optional[VoiceConfig] = Field(\n        default=None,\n        description=\"\"\"The configuration for the speaker to use.\"\"\",\n    )\n    language_code: Optional[str] = Field(\n        default=None,\n        description=\"\"\"Language code (ISO 639. e.g. en-US) for the speech synthesization.\n        Only available for Live API.\"\"\",\n    )"}, {"language": "text", "code": "class VoiceConfig(_common.BaseModel):\n    \"\"\"The configuration for the voice to use.\"\"\"\n\n    prebuilt_voice_config: Optional[PrebuiltVoiceConfig] = Field(\n        default=None,\n        description=\"\"\"The configuration for the speaker to use.\"\"\",\n    )"}, {"language": "text", "code": "class PrebuiltVoiceConfig(_common.BaseModel):\n    \"\"\"The configuration for the prebuilt speaker to use.\"\"\"\n\n    voice_name: Optional[str] = Field(\n        default=None,\n        description=\"\"\"The name of the prebuilt voice to use.\"\"\",\n    )"}]}, {"heading_path": ["response_modalities\u00b6"], "text": "response_modalities \u00b6 Supported in ADK Python v0.1.0 Java v0.1.0 Defines the output modalities for the agent. If not set, defaults to AUDIO.\nResponse modalities determine how the agent communicates with users through\nvarious channels (e.g., text, audio). ", "code_blocks": []}, {"heading_path": ["save_input_blobs_as_artifacts\u00b6"], "text": "save_input_blobs_as_artifacts \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 When enabled, input blobs will be saved as artifacts during agent execution.\nThis is useful for debugging and audit purposes, allowing developers to review\nthe exact data received by agents. ", "code_blocks": []}, {"heading_path": ["support_cfc\u00b6"], "text": "support_cfc \u00b6 Supported in ADK Python v0.1.0 Experimental Enables Compositional Function Calling (CFC) support. Only applicable when using\nStreamingMode.SSE. When enabled, the LIVE API will be invoked as only it\nsupports CFC functionality. Experimental release The support_cfc feature is experimental and its API or behavior might\nchange in future releases. ", "code_blocks": []}, {"heading_path": ["streaming_mode\u00b6"], "text": "streaming_mode \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Configures the streaming behavior of the agent. Possible values: StreamingMode.NONE : No streaming; responses delivered as complete units StreamingMode.SSE : Server-Sent Events streaming; one-way streaming from server to client StreamingMode.BIDI : Bidirectional streaming; simultaneous communication in both directions Streaming modes affect both performance and user experience. SSE streaming lets users see partial responses as they're generated, while BIDI streaming enables real-time interactive experiences. ", "code_blocks": []}, {"heading_path": ["output_audio_transcription\u00b6"], "text": "output_audio_transcription \u00b6 Supported in ADK Python v0.1.0 Java v0.1.0 Configuration for transcribing audio outputs from live agents with audio\nresponse capability. This enables automatic transcription of audio responses for\naccessibility, record-keeping, and multi-modal applications. ", "code_blocks": []}, {"heading_path": ["max_llm_calls\u00b6"], "text": "max_llm_calls \u00b6 Supported in ADK Python v0.1.0 Java v0.1.0 Sets a limit on the total number of LLM calls for a given agent run. Values greater than 0 and less than sys.maxsize : Enforces a bound on LLM calls Values less than or equal to 0: Allows unbounded LLM calls (not recommended for production) This parameter prevents excessive API usage and potential runaway processes.\nSince LLM calls often incur costs and consume resources, setting appropriate\nlimits is crucial. ", "code_blocks": []}, {"heading_path": ["Validation Rules\u00b6"], "text": "Validation Rules \u00b6 The RunConfig class validates its parameters to ensure proper agent operation. While Python ADK uses Pydantic for automatic type validation, Java ADK relies on its static typing and may include explicit checks in the RunConfig's construction.\nFor the max_llm_calls parameter specifically: Extremely large values (like sys.maxsize in Python or Integer.MAX_VALUE in Java) are typically disallowed to prevent issues. Values of zero or less will usually trigger a warning about unlimited LLM interactions. ", "code_blocks": []}, {"heading_path": ["Examples\u00b6"], "text": "Examples \u00b6 ", "code_blocks": []}, {"heading_path": ["Basic runtime configuration\u00b6"], "text": "Basic runtime configuration \u00b6 Python Go Java from google.genai.adk import RunConfig , StreamingMode config = RunConfig ( streaming_mode = StreamingMode . NONE , max_llm_calls = 100 ) import \"google.golang.org/adk/agent\" config := agent . RunConfig { StreamingMode : agent . StreamingModeNone , } import com.google.adk.agents.RunConfig ; import com.google.adk.agents.RunConfig.StreamingMode ; RunConfig config = RunConfig . builder () . setStreamingMode ( StreamingMode . NONE ) . setMaxLlmCalls ( 100 ) . build (); This configuration creates a non-streaming agent with a limit of 100 LLM calls,\nsuitable for simple task-oriented agents where complete responses are\npreferable. ", "code_blocks": [{"language": "text", "code": "from google.genai.adk import RunConfig, StreamingMode\n\nconfig = RunConfig(\n    streaming_mode=StreamingMode.NONE,\n    max_llm_calls=100\n)"}, {"language": "text", "code": "import \"google.golang.org/adk/agent\"\n\nconfig := agent.RunConfig{\n    StreamingMode: agent.StreamingModeNone,\n}"}, {"language": "text", "code": "import com.google.adk.agents.RunConfig;\nimport com.google.adk.agents.RunConfig.StreamingMode;\n\nRunConfig config = RunConfig.builder()\n        .setStreamingMode(StreamingMode.NONE)\n        .setMaxLlmCalls(100)\n        .build();"}]}, {"heading_path": ["Enabling streaming\u00b6"], "text": "Enabling streaming \u00b6 Python Go Java from google.genai.adk import RunConfig , StreamingMode config = RunConfig ( streaming_mode = StreamingMode . SSE , max_llm_calls = 200 ) import \"google.golang.org/adk/agent\" config := agent . RunConfig { StreamingMode : agent . StreamingModeSSE , } import com.google.adk.agents.RunConfig ; import com.google.adk.agents.RunConfig.StreamingMode ; RunConfig config = RunConfig . builder () . setStreamingMode ( StreamingMode . SSE ) . setMaxLlmCalls ( 200 ) . build (); Using SSE streaming allows users to see responses as they're generated,\nproviding a more responsive feel for chatbots and assistants. ", "code_blocks": [{"language": "text", "code": "from google.genai.adk import RunConfig, StreamingMode\n\nconfig = RunConfig(\n    streaming_mode=StreamingMode.SSE,\n    max_llm_calls=200\n)"}, {"language": "text", "code": "import \"google.golang.org/adk/agent\"\n\nconfig := agent.RunConfig{\n    StreamingMode: agent.StreamingModeSSE,\n}"}, {"language": "text", "code": "import com.google.adk.agents.RunConfig;\nimport com.google.adk.agents.RunConfig.StreamingMode;\n\nRunConfig config = RunConfig.builder()\n    .setStreamingMode(StreamingMode.SSE)\n    .setMaxLlmCalls(200)\n    .build();"}]}, {"heading_path": ["Enabling speech support\u00b6"], "text": "Enabling speech support \u00b6 Python Java from google.genai.adk import RunConfig , StreamingMode from google.genai import types config = RunConfig ( speech_config = types . SpeechConfig ( language_code = \"en-US\" , voice_config = types . VoiceConfig ( prebuilt_voice_config = types . PrebuiltVoiceConfig ( voice_name = \"Kore\" ) ), ), response_modalities = [ \"AUDIO\" , \"TEXT\" ], save_input_blobs_as_artifacts = True , support_cfc = True , streaming_mode = StreamingMode . SSE , max_llm_calls = 1000 , ) import com.google.adk.agents.RunConfig ; import com.google.adk.agents.RunConfig.StreamingMode ; import com.google.common.collect.ImmutableList ; import com.google.genai.types.Content ; import com.google.genai.types.Modality ; import com.google.genai.types.Part ; import com.google.genai.types.PrebuiltVoiceConfig ; import com.google.genai.types.SpeechConfig ; import com.google.genai.types.VoiceConfig ; RunConfig runConfig = RunConfig . builder () . setStreamingMode ( StreamingMode . SSE ) . setMaxLlmCalls ( 1000 ) . setSaveInputBlobsAsArtifacts ( true ) . setResponseModalities ( ImmutableList . of ( new Modality ( \"AUDIO\" ), new Modality ( \"TEXT\" ))) . setSpeechConfig ( SpeechConfig . builder () . voiceConfig ( VoiceConfig . builder () . prebuiltVoiceConfig ( PrebuiltVoiceConfig . builder (). voiceName ( \"Kore\" ). build ()) . build ()) . languageCode ( \"en-US\" ) . build ()) . build (); This comprehensive example configures an agent with: Speech capabilities using the \"Kore\" voice (US English) Both audio and text output modalities Artifact saving for input blobs (useful for debugging) SSE streaming for responsive interaction A limit of 1000 LLM calls ", "code_blocks": [{"language": "text", "code": "from google.genai.adk import RunConfig, StreamingMode\nfrom google.genai import types\n\nconfig = RunConfig(\n    speech_config=types.SpeechConfig(\n        language_code=\"en-US\",\n        voice_config=types.VoiceConfig(\n            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n                voice_name=\"Kore\"\n            )\n        ),\n    ),\n    response_modalities=[\"AUDIO\", \"TEXT\"],\n    save_input_blobs_as_artifacts=True,\n    support_cfc=True,\n    streaming_mode=StreamingMode.SSE,\n    max_llm_calls=1000,\n)"}, {"language": "text", "code": "import com.google.adk.agents.RunConfig;\nimport com.google.adk.agents.RunConfig.StreamingMode;\nimport com.google.common.collect.ImmutableList;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Modality;\nimport com.google.genai.types.Part;\nimport com.google.genai.types.PrebuiltVoiceConfig;\nimport com.google.genai.types.SpeechConfig;\nimport com.google.genai.types.VoiceConfig;\n\nRunConfig runConfig =\n    RunConfig.builder()\n        .setStreamingMode(StreamingMode.SSE)\n        .setMaxLlmCalls(1000)\n        .setSaveInputBlobsAsArtifacts(true)\n        .setResponseModalities(ImmutableList.of(new Modality(\"AUDIO\"), new Modality(\"TEXT\")))\n        .setSpeechConfig(\n            SpeechConfig.builder()\n                .voiceConfig(\n                    VoiceConfig.builder()\n                        .prebuiltVoiceConfig(\n                            PrebuiltVoiceConfig.builder().voiceName(\"Kore\").build())\n                        .build())\n                .languageCode(\"en-US\")\n                .build())\n        .build();"}]}, {"heading_path": ["Enabling Experimental CFC Support\u00b6"], "text": "Enabling Experimental CFC Support \u00b6 Supported in ADK Python v0.1.0 Experimental ```python\n    from google.genai.adk import RunConfig, StreamingMode\n\n    config = RunConfig(\n        streaming_mode=StreamingMode.SSE,\n        support_cfc=True,\n        max_llm_calls=150\n    )\n``` Enabling Compositional Function Calling creates an agent that can dynamically\nexecute functions based on model outputs, powerful for applications requiring\ncomplex workflows. Back to top ", "code_blocks": [{"language": "text", "code": "```python\n    from google.genai.adk import RunConfig, StreamingMode\n\n    config = RunConfig(\n        streaming_mode=StreamingMode.SSE,\n        support_cfc=True,\n        max_llm_calls=150\n    )\n```"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:23.057131", "source_type": "adk-docs"}
{"doc_id": "be105ab4d306e1a1d49964bda3b4e01aec7c823cdd8f55372bce3b11aa820198", "url": "https://google.github.io/adk-docs/runtime/api-server", "title": "API Server - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Use the API Server\u00b6"], "text": "Use the API Server \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 Before you deploy your agent, you should test it to ensure that it is working as\nintended. The easiest way to test your agent in your development environment is\nto use the ADK API server. Python Go Java adk api_server go run agent . go web api Make sure to update the port number. Maven Gradle With Maven, compile and run the ADK web server: mvn compile exec:java \\ -Dexec.args=\"--adk.agents.source-dir=src/main/java/agents --server.port=8080\" With Gradle, the build.gradle or build.gradle.kts build file should have the following Java plugin in its plugins section: plugins { id ( 'java' ) // other plugins } Then, elsewhere in the build file, at the top-level, create a new task: tasks . register ( 'runADKWebServer' , JavaExec ) { dependsOn classes classpath = sourceSets . main . runtimeClasspath mainClass = 'com.google.adk.web.AdkWebServer' args '--adk.agents.source-dir=src/main/java/agents' , '--server.port=8080' } Finally, on the command-line, run the following command: gradle runADKWebServer In Java, both the Dev UI and the API server are bundled together. This command will launch a local web server, where you can run cURL commands or send API requests to test your agent. Advanced Usage and Debugging For a complete reference on all available endpoints, request/response formats, and tips for debugging (including how to use the interactive API documentation), see the ADK API Server Guide below. ", "code_blocks": [{"language": "text", "code": "adk api_server"}, {"language": "text", "code": "go run agent.go web api"}, {"language": "text", "code": "mvn compile exec:java \\\n -Dexec.args=\"--adk.agents.source-dir=src/main/java/agents --server.port=8080\""}, {"language": "text", "code": "plugins {\n    id('java')\n    // other plugins\n}"}, {"language": "text", "code": "tasks.register('runADKWebServer', JavaExec) {\n    dependsOn classes\n    classpath = sourceSets.main.runtimeClasspath\n    mainClass = 'com.google.adk.web.AdkWebServer'\n    args '--adk.agents.source-dir=src/main/java/agents', '--server.port=8080'\n}"}, {"language": "text", "code": "gradle runADKWebServer"}]}, {"heading_path": ["Local testing\u00b6"], "text": "Local testing \u00b6 Local testing involves launching a local web server, creating a session, and\nsending queries to your agent. First, ensure you are in the correct working\ndirectory: parent_folder/ \u2514\u2500\u2500 my_sample_agent/ \u2514\u2500\u2500 agent.py (or Agent.java) Launch the Local Server Next, launch the local server using the commands listed above. The output should appear similar to: Python Java INFO: Started server process [ 12345 ] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://localhost:8000 ( Press CTRL+C to quit ) 2025 -05-13T23:32:08.972-06:00 INFO 37864 --- [ ebServer.main ()] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port 8080 ( http ) with context path '/' 2025 -05-13T23:32:08.980-06:00 INFO 37864 --- [ ebServer.main ()] com.google.adk.web.AdkWebServer : Started AdkWebServer in 1 .15 seconds ( process running for 2 .877 ) 2025 -05-13T23:32:08.981-06:00 INFO 37864 --- [ ebServer.main ()] com.google.adk.web.AdkWebServer : AdkWebServer application started successfully. Your server is now running locally. Ensure you use the correct port number in all the subsequent commands. Create a new session With the API server still running, open a new terminal window or tab and create\na new session with the agent using: curl -X POST http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_123 \\ -H \"Content-Type: application/json\" \\ -d '{\"key1\": \"value1\", \"key2\": 42}' Let's break down what's happening: http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_123 : This\n  creates a new session for your agent my_sample_agent , which is the name of\n  the agent folder, for a user ID ( u_123 ) and for a session ID ( s_123 ). You\n  can replace my_sample_agent with the name of your agent folder. You can\n  replace u_123 with a specific user ID, and s_123 with a specific session\n  ID. {\"key1\": \"value1\", \"key2\": 42} : This is optional. You can use\n  this to customize the agent's pre-existing state (dict) when creating the\n  session. This should return the session information if it was created successfully. The\noutput should appear similar to: { \"id\" : \"s_123\" , \"appName\" : \"my_sample_agent\" , \"userId\" : \"u_123\" , \"state\" :{ \"key1\" : \"value1\" , \"key2\" : 42 }, \"events\" :[], \"lastUpdateTime\" : 1743711430.022186 } Info You cannot create multiple sessions with exactly the same user ID and\nsession ID. If you try to, you may see a response, like: {\"detail\":\"Session already exists: s_123\"} . To fix this, you can either\ndelete that session (e.g., s_123 ), or choose a different session ID. Send a query There are two ways to send queries via POST to your agent, via the /run or /run_sse routes. POST http://localhost:8000/run : collects all events as a list and returns the\n  list all at once. Suitable for most users (if you are unsure, we recommend\n  using this one). POST http://localhost:8000/run_sse : returns as Server-Sent-Events, which is a\n  stream of event objects. Suitable for those who want to be notified as soon as\n  the event is available. With /run_sse , you can also set streaming to true to enable token-level streaming. Using /run curl -X POST http://localhost:8000/run \\ -H \"Content-Type: application/json\" \\ -d '{ \"appName\": \"my_sample_agent\", \"userId\": \"u_123\", \"sessionId\": \"s_123\", \"newMessage\": { \"role\": \"user\", \"parts\": [{ \"text\": \"Hey whats the weather in new york today\" }] } }' If using /run , you will see the full output of events at the same time, as a\nlist, which should appear similar to: [{ \"content\" :{ \"parts\" :[{ \"functionCall\" :{ \"id\" : \"af-e75e946d-c02a-4aad-931e-49e4ab859838\" , \"args\" :{ \"city\" : \"new york\" }, \"name\" : \"get_weather\" }}], \"role\" : \"model\" }, \"invocationId\" : \"e-71353f1e-aea1-4821-aa4b-46874a766853\" , \"author\" : \"weather_time_agent\" , \"actions\" :{ \"stateDelta\" :{}, \"artifactDelta\" :{}, \"requestedAuthConfigs\" :{}}, \"longRunningToolIds\" :[], \"id\" : \"2Btee6zW\" , \"timestamp\" : 1743712220.385936 },{ \"content\" :{ \"parts\" :[{ \"functionResponse\" :{ \"id\" : \"af-e75e946d-c02a-4aad-931e-49e4ab859838\" , \"name\" : \"get_weather\" , \"response\" :{ \"status\" : \"success\" , \"report\" : \"The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).\" }}}], \"role\" : \"user\" }, \"invocationId\" : \"e-71353f1e-aea1-4821-aa4b-46874a766853\" , \"author\" : \"weather_time_agent\" , \"actions\" :{ \"stateDelta\" :{}, \"artifactDelta\" :{}, \"requestedAuthConfigs\" :{}}, \"id\" : \"PmWibL2m\" , \"timestamp\" : 1743712221.895042 },{ \"content\" :{ \"parts\" :[{ \"text\" : \"OK. The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).\\n\" }], \"role\" : \"model\" }, \"invocationId\" : \"e-71353f1e-aea1-4821-aa4b-46874a766853\" , \"author\" : \"weather_time_agent\" , \"actions\" :{ \"stateDelta\" :{}, \"artifactDelta\" :{}, \"requestedAuthConfigs\" :{}}, \"id\" : \"sYT42eVC\" , \"timestamp\" : 1743712221.899018 }] Using /run_sse curl -X POST http://localhost:8000/run_sse \\ -H \"Content-Type: application/json\" \\ -d '{ \"appName\": \"my_sample_agent\", \"userId\": \"u_123\", \"sessionId\": \"s_123\", \"newMessage\": { \"role\": \"user\", \"parts\": [{ \"text\": \"Hey whats the weather in new york today\" }] }, \"streaming\": false }' You can set streaming to true to enable token-level streaming, which means\nthe response will be returned to you in multiple chunks and the output should\nappear similar to: data: { \"content\" : { \"parts\" : [{ \"functionCall\" : { \"id\" : \"af-f83f8af9-f732-46b6-8cb5-7b5b73bbf13d\" , \"args\" : { \"city\" : \"new york\" } , \"name\" : \"get_weather\" }}] , \"role\" : \"model\" } , \"invocationId\" : \"e-3f6d7765-5287-419e-9991-5fffa1a75565\" , \"author\" : \"weather_time_agent\" , \"actions\" : { \"stateDelta\" : {} , \"artifactDelta\" : {} , \"requestedAuthConfigs\" : {}} , \"longRunningToolIds\" : [] , \"id\" : \"ptcjaZBa\" , \"timestamp\" :1743712255.313043 } data: { \"content\" : { \"parts\" : [{ \"functionResponse\" : { \"id\" : \"af-f83f8af9-f732-46b6-8cb5-7b5b73bbf13d\" , \"name\" : \"get_weather\" , \"response\" : { \"status\" : \"success\" , \"report\" : \"The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).\" }}}] , \"role\" : \"user\" } , \"invocationId\" : \"e-3f6d7765-5287-419e-9991-5fffa1a75565\" , \"author\" : \"weather_time_agent\" , \"actions\" : { \"stateDelta\" : {} , \"artifactDelta\" : {} , \"requestedAuthConfigs\" : {}} , \"id\" : \"5aocxjaq\" , \"timestamp\" :1743712257.387306 } data: { \"content\" : { \"parts\" : [{ \"text\" : \"OK. The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).\\n\" }] , \"role\" : \"model\" } , \"invocationId\" : \"e-3f6d7765-5287-419e-9991-5fffa1a75565\" , \"author\" : \"weather_time_agent\" , \"actions\" : { \"stateDelta\" : {} , \"artifactDelta\" : {} , \"requestedAuthConfigs\" : {}} , \"id\" : \"rAnWGSiV\" , \"timestamp\" :1743712257.391317 } Send a query with a base64 encoded file using /run or /run_sse curl -X POST http://localhost:8000/run \\ --H 'Content-Type: application/json' \\ --d '{ \"appName\":\"my_sample_agent\", \"userId\":\"u_123\", \"sessionId\":\"s_123\", \"newMessage\":{ \"role\":\"user\", \"parts\":[ { \"text\":\"Describe this image\" }, { \"inlineData\":{ \"displayName\":\"my_image.png\", \"data\":\"iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAYAAAD0eNT6AAAACXBIWXMAAAsTAAALEwEAmpw...\", \"mimeType\":\"image/png\" } } ] }, \"streaming\":false }' Info If you are using /run_sse , you should see each event as soon as it becomes\navailable. ", "code_blocks": [{"language": "text", "code": "parent_folder/\n\u2514\u2500\u2500 my_sample_agent/\n    \u2514\u2500\u2500 agent.py (or Agent.java)"}, {"language": "text", "code": "INFO:     Started server process [12345]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)"}, {"language": "text", "code": "2025-05-13T23:32:08.972-06:00  INFO 37864 --- [ebServer.main()] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8080 (http) with context path '/'\n2025-05-13T23:32:08.980-06:00  INFO 37864 --- [ebServer.main()] com.google.adk.web.AdkWebServer          : Started AdkWebServer in 1.15 seconds (process running for 2.877)\n2025-05-13T23:32:08.981-06:00  INFO 37864 --- [ebServer.main()] com.google.adk.web.AdkWebServer          : AdkWebServer application started successfully."}, {"language": "text", "code": "curl -X POST http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_123 \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"key1\": \"value1\", \"key2\": 42}'"}, {"language": "text", "code": "{\"id\":\"s_123\",\"appName\":\"my_sample_agent\",\"userId\":\"u_123\",\"state\":{\"key1\":\"value1\",\"key2\":42},\"events\":[],\"lastUpdateTime\":1743711430.022186}"}, {"language": "text", "code": "curl -X POST http://localhost:8000/run \\\n-H \"Content-Type: application/json\" \\\n-d '{\n\"appName\": \"my_sample_agent\",\n\"userId\": \"u_123\",\n\"sessionId\": \"s_123\",\n\"newMessage\": {\n    \"role\": \"user\",\n    \"parts\": [{\n    \"text\": \"Hey whats the weather in new york today\"\n    }]\n}\n}'"}, {"language": "text", "code": "[{\"content\":{\"parts\":[{\"functionCall\":{\"id\":\"af-e75e946d-c02a-4aad-931e-49e4ab859838\",\"args\":{\"city\":\"new york\"},\"name\":\"get_weather\"}}],\"role\":\"model\"},\"invocationId\":\"e-71353f1e-aea1-4821-aa4b-46874a766853\",\"author\":\"weather_time_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"longRunningToolIds\":[],\"id\":\"2Btee6zW\",\"timestamp\":1743712220.385936},{\"content\":{\"parts\":[{\"functionResponse\":{\"id\":\"af-e75e946d-c02a-4aad-931e-49e4ab859838\",\"name\":\"get_weather\",\"response\":{\"status\":\"success\",\"report\":\"The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).\"}}}],\"role\":\"user\"},\"invocationId\":\"e-71353f1e-aea1-4821-aa4b-46874a766853\",\"author\":\"weather_time_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"id\":\"PmWibL2m\",\"timestamp\":1743712221.895042},{\"content\":{\"parts\":[{\"text\":\"OK. The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).\\n\"}],\"role\":\"model\"},\"invocationId\":\"e-71353f1e-aea1-4821-aa4b-46874a766853\",\"author\":\"weather_time_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"id\":\"sYT42eVC\",\"timestamp\":1743712221.899018}]"}, {"language": "text", "code": "curl -X POST http://localhost:8000/run_sse \\\n-H \"Content-Type: application/json\" \\\n-d '{\n\"appName\": \"my_sample_agent\",\n\"userId\": \"u_123\",\n\"sessionId\": \"s_123\",\n\"newMessage\": {\n    \"role\": \"user\",\n    \"parts\": [{\n    \"text\": \"Hey whats the weather in new york today\"\n    }]\n},\n\"streaming\": false\n}'"}, {"language": "text", "code": "data: {\"content\":{\"parts\":[{\"functionCall\":{\"id\":\"af-f83f8af9-f732-46b6-8cb5-7b5b73bbf13d\",\"args\":{\"city\":\"new york\"},\"name\":\"get_weather\"}}],\"role\":\"model\"},\"invocationId\":\"e-3f6d7765-5287-419e-9991-5fffa1a75565\",\"author\":\"weather_time_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"longRunningToolIds\":[],\"id\":\"ptcjaZBa\",\"timestamp\":1743712255.313043}\n\ndata: {\"content\":{\"parts\":[{\"functionResponse\":{\"id\":\"af-f83f8af9-f732-46b6-8cb5-7b5b73bbf13d\",\"name\":\"get_weather\",\"response\":{\"status\":\"success\",\"report\":\"The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).\"}}}],\"role\":\"user\"},\"invocationId\":\"e-3f6d7765-5287-419e-9991-5fffa1a75565\",\"author\":\"weather_time_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"id\":\"5aocxjaq\",\"timestamp\":1743712257.387306}\n\ndata: {\"content\":{\"parts\":[{\"text\":\"OK. The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).\\n\"}],\"role\":\"model\"},\"invocationId\":\"e-3f6d7765-5287-419e-9991-5fffa1a75565\",\"author\":\"weather_time_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{}},\"id\":\"rAnWGSiV\",\"timestamp\":1743712257.391317}"}, {"language": "text", "code": "curl -X POST http://localhost:8000/run \\\n--H 'Content-Type: application/json' \\\n--d '{\n   \"appName\":\"my_sample_agent\",\n   \"userId\":\"u_123\",\n   \"sessionId\":\"s_123\",\n   \"newMessage\":{\n      \"role\":\"user\",\n      \"parts\":[\n         {\n            \"text\":\"Describe this image\"\n         },\n         {\n            \"inlineData\":{\n               \"displayName\":\"my_image.png\",\n               \"data\":\"iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAYAAAD0eNT6AAAACXBIWXMAAAsTAAALEwEAmpw...\",\n               \"mimeType\":\"image/png\"\n            }\n         }\n      ]\n   },\n   \"streaming\":false\n}'"}]}, {"heading_path": ["Integrations\u00b6"], "text": "Integrations \u00b6 ADK uses Callbacks to integrate with third-party\nobservability tools. These integrations capture detailed traces of agent calls\nand interactions, which are crucial for understanding behavior, debugging\nissues, and evaluating performance. Comet Opik is an open-source LLM\n  observability and evaluation platform that natively supports ADK . ", "code_blocks": []}, {"heading_path": ["Deploying your agent\u00b6"], "text": "Deploying your agent \u00b6 Now that you've verified the local operation of your agent, you're ready to move\non to deploying your agent! Here are some ways you can deploy your agent: Deploy to Agent Engine , the easiest way to deploy\n  your ADK agents to a managed service in Vertex AI on Google Cloud. Deploy to Cloud Run and have full control over how\n  you scale and manage your agents using serverless architecture on Google\n  Cloud. ", "code_blocks": []}, {"heading_path": ["The ADK API Server\u00b6"], "text": "The ADK API Server \u00b6 The ADK API Server is a pre-packaged FastAPI web server that exposes your agents through a RESTful API. It is the primary tool for local testing and development, allowing you to interact with your agents programmatically before deploying them. ", "code_blocks": []}, {"heading_path": ["Running the Server\u00b6"], "text": "Running the Server \u00b6 To start the server, run the following command from your project's root directory: adk api_server By default, the server runs on http://localhost:8000 . You will see output confirming that the server has started: INFO: Uvicorn running on http://localhost:8000 ( Press CTRL+C to quit ) ", "code_blocks": [{"language": "text", "code": "adk api_server"}, {"language": "text", "code": "INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)"}]}, {"heading_path": ["Debugging with Interactive API Docs\u00b6"], "text": "Debugging with Interactive API Docs \u00b6 The API server automatically generates interactive API documentation using Swagger UI. This is an invaluable tool for exploring endpoints, understanding request formats, and testing your agent directly from your browser. To access the interactive docs, start the API server and navigate to http://localhost:8000/docs in your web browser. You will see a complete, interactive list of all available API endpoints, which you can expand to see detailed information about parameters, request bodies, and response schemas. You can even click \"Try it out\" to send live requests to your running agents. ", "code_blocks": []}, {"heading_path": ["API Endpoints\u00b6"], "text": "API Endpoints \u00b6 The following sections detail the primary endpoints for interacting with your agents. JSON Naming Convention Both Request and Response bodies will use camelCase for field names (e.g., \"appName\" ). ", "code_blocks": []}, {"heading_path": ["Utility Endpoints\u00b6"], "text": "Utility Endpoints \u00b6 ", "code_blocks": []}, {"heading_path": ["List Available Agents\u00b6"], "text": "List Available Agents \u00b6 Returns a list of all agent applications discovered by the server. Method: GET Path: /list-apps Example Request curl -X GET http://localhost:8000/list-apps Example Response [ \"my_sample_agent\" , \"another_agent\" ] ", "code_blocks": [{"language": "text", "code": "curl -X GET http://localhost:8000/list-apps"}, {"language": "text", "code": "[\"my_sample_agent\", \"another_agent\"]"}]}, {"heading_path": ["Session Management\u00b6"], "text": "Session Management \u00b6 Sessions store the state and event history for a specific user's interaction with an agent. ", "code_blocks": []}, {"heading_path": ["Update a Session\u00b6"], "text": "Update a Session \u00b6 Updates an existing session. Method: PATCH Path: /apps/{app_name}/users/{user_id}/sessions/{session_id} Request Body { \"stateDelta\" : { \"key1\" : \"value1\" , \"key2\" : 42 } } Example Request curl -X PATCH http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_abc \\ -H \"Content-Type: application/json\" \\ -d '{\"stateDelta\":{\"visit_count\": 5}}' Example Response { \"id\" : \"s_abc\" , \"appName\" : \"my_sample_agent\" , \"userId\" : \"u_123\" , \"state\" :{ \"visit_count\" : 5 }, \"events\" :[], \"lastUpdateTime\" : 1743711430.022186 } ", "code_blocks": [{"language": "text", "code": "{\n  \"stateDelta\": {\n    \"key1\": \"value1\",\n    \"key2\": 42\n  }\n}"}, {"language": "text", "code": "curl -X PATCH http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_abc \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"stateDelta\":{\"visit_count\": 5}}'"}, {"language": "text", "code": "{\"id\":\"s_abc\",\"appName\":\"my_sample_agent\",\"userId\":\"u_123\",\"state\":{\"visit_count\":5},\"events\":[],\"lastUpdateTime\":1743711430.022186}"}]}, {"heading_path": ["Get a Session\u00b6"], "text": "Get a Session \u00b6 Retrieves the details of a specific session, including its current state and all associated events. Method: GET Path: /apps/{app_name}/users/{user_id}/sessions/{session_id} Example Request curl -X GET http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_abc Example Response { \"id\" : \"s_abc\" , \"appName\" : \"my_sample_agent\" , \"userId\" : \"u_123\" , \"state\" :{ \"visit_count\" : 5 }, \"events\" :[ ... ], \"lastUpdateTime\" : 1743711430.022186 } ", "code_blocks": [{"language": "text", "code": "curl -X GET http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_abc"}, {"language": "text", "code": "{\"id\":\"s_abc\",\"appName\":\"my_sample_agent\",\"userId\":\"u_123\",\"state\":{\"visit_count\":5},\"events\":[...],\"lastUpdateTime\":1743711430.022186}"}]}, {"heading_path": ["Delete a Session\u00b6"], "text": "Delete a Session \u00b6 Deletes a session and all of its associated data. Method: DELETE Path: /apps/{app_name}/users/{user_id}/sessions/{session_id} Example Request curl -X DELETE http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_abc Example Response A successful deletion returns an empty response with a 204 No Content status code. ", "code_blocks": [{"language": "text", "code": "curl -X DELETE http://localhost:8000/apps/my_sample_agent/users/u_123/sessions/s_abc"}]}, {"heading_path": ["Agent Execution\u00b6"], "text": "Agent Execution \u00b6 These endpoints are used to send a new message to an agent and get a response. ", "code_blocks": []}, {"heading_path": ["Run Agent (Single Response)\u00b6"], "text": "Run Agent (Single Response) \u00b6 Executes the agent and returns all generated events in a single JSON array after the run is complete. Method: POST Path: /run Request Body { \"appName\" : \"my_sample_agent\" , \"userId\" : \"u_123\" , \"sessionId\" : \"s_abc\" , \"newMessage\" : { \"role\" : \"user\" , \"parts\" : [ { \"text\" : \"What is the capital of France?\" } ] } } Example Request curl -X POST http://localhost:8000/run \\ -H \"Content-Type: application/json\" \\ -d '{ \"appName\": \"my_sample_agent\", \"userId\": \"u_123\", \"sessionId\": \"s_abc\", \"newMessage\": { \"role\": \"user\", \"parts\": [{\"text\": \"What is the capital of France?\"}] } }' ", "code_blocks": [{"language": "text", "code": "{\n  \"appName\": \"my_sample_agent\",\n  \"userId\": \"u_123\",\n  \"sessionId\": \"s_abc\",\n  \"newMessage\": {\n    \"role\": \"user\",\n    \"parts\": [\n      { \"text\": \"What is the capital of France?\" }\n    ]\n  }\n}"}, {"language": "text", "code": "curl -X POST http://localhost:8000/run \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"appName\": \"my_sample_agent\",\n    \"userId\": \"u_123\",\n    \"sessionId\": \"s_abc\",\n    \"newMessage\": {\n      \"role\": \"user\",\n      \"parts\": [{\"text\": \"What is the capital of France?\"}]\n    }\n  }'"}]}, {"heading_path": ["Run Agent (Streaming)\u00b6"], "text": "Run Agent (Streaming) \u00b6 Executes the agent and streams events back to the client as they are generated using Server-Sent Events (SSE) . Method: POST Path: /run_sse Request Body The request body is the same as for /run , with an additional optional streaming flag. { \"appName\" : \"my_sample_agent\" , \"userId\" : \"u_123\" , \"sessionId\" : \"s_abc\" , \"newMessage\" : { \"role\" : \"user\" , \"parts\" : [ { \"text\" : \"What is the weather in New York?\" } ] }, \"streaming\" : true } - streaming : (Optional) Set to true to enable token-level streaming for model responses. Defaults to false . Example Request curl -X POST http://localhost:8000/run_sse \\ -H \"Content-Type: application/json\" \\ -d '{ \"appName\": \"my_sample_agent\", \"userId\": \"u_123\", \"sessionId\": \"s_abc\", \"newMessage\": { \"role\": \"user\", \"parts\": [{\"text\": \"What is the weather in New York?\"}] }, \"streaming\": false }' Back to top ", "code_blocks": [{"language": "text", "code": "{\n  \"appName\": \"my_sample_agent\",\n  \"userId\": \"u_123\",\n  \"sessionId\": \"s_abc\",\n  \"newMessage\": {\n    \"role\": \"user\",\n    \"parts\": [\n      { \"text\": \"What is the weather in New York?\" }\n    ]\n  },\n  \"streaming\": true\n}"}, {"language": "text", "code": "curl -X POST http://localhost:8000/run_sse \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"appName\": \"my_sample_agent\",\n    \"userId\": \"u_123\",\n    \"sessionId\": \"s_abc\",\n    \"newMessage\": {\n      \"role\": \"user\",\n      \"parts\": [{\"text\": \"What is the weather in New York?\"}]\n    },\n    \"streaming\": false\n  }'"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:23.589120", "source_type": "adk-docs"}
{"doc_id": "90cbc59bf15d935523fa9310a6f5cef61740b940e30082e415032e736448373c", "url": "https://google.github.io/adk-docs/runtime/resume", "title": "Resume Agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Resume stopped agents\u00b6"], "text": "Resume stopped agents \u00b6 Supported in ADK Python v1.14.0 An ADK agent's execution can be interrupted by various factors including\ndropped network connections, power failure, or a required external system going\noffline. The Resume feature of ADK allows an agent workflow to pick up where it\nleft off, avoiding the need to restart the entire workflow. In ADK Python 1.16\nand higher, you can configure an ADK workflow to be resumable, so that it tracks\nthe execution of workflow and then allows you to resume it after an unexpected\ninterruption. This guide explains how to configure your ADK agent workflow to be resumable.\nIf you use Custom Agents, you can update them to be resumable. For more\ninformation, see Add resume to custom Agents . ", "code_blocks": []}, {"heading_path": ["Add resumable configuration\u00b6"], "text": "Add resumable configuration \u00b6 Enable the Resume function for an agent workflow by applying a Resumabiltiy\nconfiguration to the App object of your ADK workflow, as shown in the following\ncode example: app = App ( name = 'my_resumable_agent' , root_agent = root_agent , # Set the resumability config to enable resumability. resumability_config = ResumabilityConfig ( is_resumable = True , ), ) Caution: Long Running Functions, Confirmations, Authentication For agents that use Long Running Functions , Confirmations , or Authentication requiring user input, adding a resumable confirmation changes how these features\noperate. For more information, see the documentation for those features. Note: Custom Agents Resume is not supported by default for Custom Agents. You must\nupdate the agent code for a Custom Agent to support the Resume feature. For\ninformation on modifying Custom Agents to support incremental resume\nfunctionality, see Add resume to custom Agents . ", "code_blocks": [{"language": "text", "code": "app = App(\n    name='my_resumable_agent',\n    root_agent=root_agent,\n    # Set the resumability config to enable resumability.\n    resumability_config=ResumabilityConfig(\n        is_resumable=True,\n    ),\n)"}]}, {"heading_path": ["Resume a stopped workflow\u00b6"], "text": "Resume a stopped workflow \u00b6 When an ADK workflow stops execution you can resume the workflow using a\ncommand containing the Invocation ID for the workflow instance, which can be\nfound in the Event history of the workflow. Make sure the ADK API server is running, in case it was\ninterrupted or powered off, and then run the following command to resume the\nworkflow, as shown in the following API request example. # restart the API server if needed: adk api_server my_resumable_agent/ # resume the agent: curl -X POST http://localhost:8000/run_sse \\ -H \"Content-Type: application/json\" \\ -d '{ \"app_name\": \"my_resumable_agent\", \"user_id\": \"u_123\", \"session_id\": \"s_abc\", \"invocation_id\": \"invocation-123\", }' You can also resume a workflow using the Runner object Run Async method, as\nshown below: runner . run_async ( user_id = 'u_123' , session_id = 's_abc' , invocation_id = 'invocation-123' ) # When new_message is set to a function response, # we are trying to resume a long running function. Note Resuming a workflow from the ADK Web user interface or using the ADK\ncommand line (CLI) tool is not currently supported. ", "code_blocks": [{"language": "text", "code": "# restart the API server if needed:\nadk api_server my_resumable_agent/\n\n# resume the agent:\ncurl -X POST http://localhost:8000/run_sse \\\n -H \"Content-Type: application/json\" \\\n -d '{\n   \"app_name\": \"my_resumable_agent\",\n   \"user_id\": \"u_123\",\n   \"session_id\": \"s_abc\",\n   \"invocation_id\": \"invocation-123\",\n }'"}, {"language": "text", "code": "runner.run_async(user_id='u_123', session_id='s_abc', \n    invocation_id='invocation-123')\n\n# When new_message is set to a function response,\n# we are trying to resume a long running function."}]}, {"heading_path": ["How it works\u00b6"], "text": "How it works \u00b6 The Resume feature works by logging completed Agent workflow tasks,\nincluding incremental steps using Events and Event Actions .\ntracking completion of agent tasks within a resumable workflow. If a workflow is\ninterrupted and then later restarted, the system resumes the workflow by setting\nthe completion state of each agent. If an agent did not complete, the workflow\nsystem reinstates any completed Events for that agent, and restarts the workflow\nfrom the partially completed state. For multi-agent workflows, the specific\nresume behavior varies, based on the multi-agent classes in your workflow, as\ndescribed below: Sequential Agent : Reads the current_sub_agent from its saved state\n    to find the next sub-agent to run in the sequence. Loop Agent : Uses the current_sub_agent and times_looped values to\n    continue the loop from the last completed iteration and sub-agent. Parallel Agent : Determines which sub-agents have already completed\n    and only runs those that have not finished. Event logging includes results from Tools which successfully returned a result.\nSo if an agent successfully executed Function Tools A and B, and then failed\nduring execution of tool C, the system reinstates the results from the\ntools A and B, and resumes the workflow by re-running the tool C request. Caution: Tool execution behavior When resuming a workflow with Tools, the Resume feature ensures\nthat the Tools in an agent are run at least once , and may run more than\nonce when resuming a workflow. If your agent uses Tools where duplicate runs\nwould have a negative impact, such as purchases, you should modify the Tool to\ncheck for and prevent duplicate runs. Note: Workflow modification with Resume not supported Do not modify a stopped agent workflow before resuming it. \nFor example adding or removing agents from workflow that has stopped\nand then resuming that workflow is not supported. ", "code_blocks": []}, {"heading_path": ["Add resume to custom Agents\u00b6"], "text": "Add resume to custom Agents \u00b6 Custom agents have specific implementation requirements in order to support\nresumability. You must decide on and define workflow steps within your custom\nagent which produce a result which can be preserved before handing off to the\nnext step of processing. The following steps outline how to modify a Custom\nAgent to support a workflow Resume. Create CustomAgentState class : Extend the BaseAgentState to create\n    an object that preserves the state of your agent. Optionally, create WorkFlowStep class : If your custom agent\n    has sequential steps, consider creating a WorkFlowStep list object that\n    defines the discrete, savable steps of the agent. Add initial agent state: Modify your agent's async run function to\n    set the initial state of your agent. Add agent state checkpoints : Modify your agent's async run function\n    to generate and save the agent state for each completed step of the agent's\n    overall task. Add end of agent status to track agent state: Modify your agent's\n    async run function to include an end_of_agent=True status upon successful\n    completion of the agent's full task. The following example shows the required code modifications to the example\nStoryFlowAgent class shown in the Custom Agents guide: class WorkflowStep ( int , Enum ): INITIAL_STORY_GENERATION = 1 CRITIC_REVISER_LOOP = 2 POST_PROCESSING = 3 CONDITIONAL_REGENERATION = 4 # Extend BaseAgentState ### class StoryFlowAgentState(BaseAgentState): ###   step = WorkflowStep @override async def _run_async_impl ( self , ctx : InvocationContext ) -> AsyncGenerator [ Event , None ]: \"\"\" Implements the custom orchestration logic for the story workflow. Uses the instance attributes assigned by Pydantic (e.g., self.story_generator). \"\"\" agent_state = self . _load_agent_state ( ctx , WorkflowStep ) if agent_state is None : # Record the start of the agent agent_state = StoryFlowAgentState ( step = WorkflowStep . INITIAL_STORY_GENERATION ) yield self . _create_agent_state_event ( ctx , agent_state ) next_step = agent_state . step logger . info ( f \"[ { self . name } ] Starting story generation workflow.\" ) # Step 1. Initial Story Generation if next_step <= WorkflowStep . INITIAL_STORY_GENERATION : logger . info ( f \"[ { self . name } ] Running StoryGenerator...\" ) async for event in self . story_generator . run_async ( ctx ): yield event # Check if story was generated before proceeding if \"current_story\" not in ctx . session . state or not ctx . session . state [ \"current_story\" ]: return # Stop processing if initial story failed agent_state = StoryFlowAgentState ( step = WorkflowStep . CRITIC_REVISER_LOOP ) yield self . _create_agent_state_event ( ctx , agent_state ) # Step 2. Critic-Reviser Loop if next_step <= WorkflowStep . CRITIC_REVISER_LOOP : logger . info ( f \"[ { self . name } ] Running CriticReviserLoop...\" ) async for event in self . loop_agent . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from CriticReviserLoop: \" f \" { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event agent_state = StoryFlowAgentState ( step = WorkflowStep . POST_PROCESSING ) yield self . _create_agent_state_event ( ctx , agent_state ) # Step 3. Sequential Post-Processing (Grammar and Tone Check) if next_step <= WorkflowStep . POST_PROCESSING : logger . info ( f \"[ { self . name } ] Running PostProcessing...\" ) async for event in self . sequential_agent . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from PostProcessing: \" f \" { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event agent_state = StoryFlowAgentState ( step = WorkflowStep . CONDITIONAL_REGENERATION ) yield self . _create_agent_state_event ( ctx , agent_state ) # Step 4. Tone-Based Conditional Logic if next_step <= WorkflowStep . CONDITIONAL_REGENERATION : tone_check_result = ctx . session . state . get ( \"tone_check_result\" ) if tone_check_result == \"negative\" : logger . info ( f \"[ { self . name } ] Tone is negative. Regenerating story...\" ) async for event in self . story_generator . run_async ( ctx ): logger . info ( f \"[ { self . name } ] Event from StoryGenerator (Regen): \" f \" { event . model_dump_json ( indent = 2 , exclude_none = True ) } \" ) yield event else : logger . info ( f \"[ { self . name } ] Tone is not negative. Keeping current story.\" ) logger . info ( f \"[ { self . name } ] Workflow finished.\" ) yield self . _create_agent_state_event ( ctx , end_of_agent = True ) Back to top ", "code_blocks": [{"language": "text", "code": "class WorkflowStep(int, Enum):\n INITIAL_STORY_GENERATION = 1\n CRITIC_REVISER_LOOP = 2\n POST_PROCESSING = 3\n CONDITIONAL_REGENERATION = 4\n\n# Extend BaseAgentState\n\n### class StoryFlowAgentState(BaseAgentState):\n\n###   step = WorkflowStep\n\n@override\nasync def _run_async_impl(\n    self, ctx: InvocationContext\n) -> AsyncGenerator[Event, None]:\n    \"\"\"\n    Implements the custom orchestration logic for the story workflow.\n    Uses the instance attributes assigned by Pydantic (e.g., self.story_generator).\n    \"\"\"\n    agent_state = self._load_agent_state(ctx, WorkflowStep)\n\n    if agent_state is None:\n      # Record the start of the agent\n      agent_state = StoryFlowAgentState(step=WorkflowStep.INITIAL_STORY_GENERATION)\n      yield self._create_agent_state_event(ctx, agent_state)\n\n    next_step = agent_state.step\n    logger.info(f\"[{self.name}] Starting story generation workflow.\")\n\n    # Step 1. Initial Story Generation\n    if next_step <= WorkflowStep.INITIAL_STORY_GENERATION:\n      logger.info(f\"[{self.name}] Running StoryGenerator...\")\n      async for event in self.story_generator.run_async(ctx):\n          yield event\n\n      # Check if story was generated before proceeding\n      if \"current_story\" not in ctx.session.state or not ctx.session.state[\n          \"current_story\"\n      ]:\n          return  # Stop processing if initial story failed\n\n    agent_state = StoryFlowAgentState(step=WorkflowStep.CRITIC_REVISER_LOOP)\n    yield self._create_agent_state_event(ctx, agent_state)\n\n    # Step 2. Critic-Reviser Loop\n    if next_step <= WorkflowStep.CRITIC_REVISER_LOOP:\n      logger.info(f\"[{self.name}] Running CriticReviserLoop...\")\n      async for event in self.loop_agent.run_async(ctx):\n          logger.info(\n              f\"[{self.name}] Event from CriticReviserLoop: \"\n              f\"{event.model_dump_json(indent=2, exclude_none=True)}\"\n          )\n          yield event\n\n    agent_state = StoryFlowAgentState(step=WorkflowStep.POST_PROCESSING)\n    yield self._create_agent_state_event(ctx, agent_state)\n\n    # Step 3. Sequential Post-Processing (Grammar and Tone Check)\n    if next_step <= WorkflowStep.POST_PROCESSING:\n      logger.info(f\"[{self.name}] Running PostProcessing...\")\n      async for event in self.sequential_agent.run_async(ctx):\n          logger.info(\n              f\"[{self.name}] Event from PostProcessing: \"\n              f\"{event.model_dump_json(indent=2, exclude_none=True)}\"\n          )\n          yield event\n\n    agent_state = StoryFlowAgentState(step=WorkflowStep.CONDITIONAL_REGENERATION)\n    yield self._create_agent_state_event(ctx, agent_state)\n\n    # Step 4. Tone-Based Conditional Logic\n    if next_step <= WorkflowStep.CONDITIONAL_REGENERATION:\n      tone_check_result = ctx.session.state.get(\"tone_check_result\")\n      if tone_check_result == \"negative\":\n          logger.info(f\"[{self.name}] Tone is negative. Regenerating story...\")\n          async for event in self.story_generator.run_async(ctx):\n              logger.info(\n                  f\"[{self.name}] Event from StoryGenerator (Regen): \"\n                  f\"{event.model_dump_json(indent=2, exclude_none=True)}\"\n              )\n              yield event\n      else:\n          logger.info(f\"[{self.name}] Tone is not negative. Keeping current story.\")\n\n    logger.info(f\"[{self.name}] Workflow finished.\")\n    yield self._create_agent_state_event(ctx, end_of_agent=True)"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:24.134727", "source_type": "adk-docs"}
{"doc_id": "1b73c9b2ad0b485e6607718c596fc51c2432d6fea7091f65bce70f02aeaf8f74", "url": "https://google.github.io/adk-docs/deploy", "title": "Deploying Your Agent - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Deploying Your Agent\u00b6"], "text": "Deploying Your Agent \u00b6 Once you've built and tested your agent using ADK,\nthe next step is to deploy it so it can be accessed, queried, and used in\nproduction or integrated with other applications. Deployment moves your agent\nfrom your local development machine to a scalable and reliable environment. ", "code_blocks": []}, {"heading_path": ["Deployment Options\u00b6"], "text": "Deployment Options \u00b6 Your ADK agent can be deployed to a range of different environments based\non your needs for production readiness or custom flexibility: ", "code_blocks": []}, {"heading_path": ["Agent Engine in Vertex AI\u00b6"], "text": "Agent Engine in Vertex AI \u00b6 Agent Engine is a fully managed auto-scaling service on Google Cloud\nspecifically designed for deploying, managing, and scaling AI agents built with\nframeworks such as ADK. Learn more about deploying your agent to Vertex AI Agent Engine . ", "code_blocks": []}, {"heading_path": ["Cloud Run\u00b6"], "text": "Cloud Run \u00b6 Cloud Run is a managed auto-scaling compute platform on\nGoogle Cloud that enables you to run your agent as a container-based\napplication. Learn more about deploying your agent to Cloud Run . ", "code_blocks": []}, {"heading_path": ["Google Kubernetes Engine (GKE)\u00b6"], "text": "Google Kubernetes Engine (GKE) \u00b6 Google Kubernetes Engine (GKE) is a managed\nKubernetes service of Google Cloud that allows you to run your agent in a containerized\nenvironment. GKE is a good option if you need more control over the deployment as well as\nfor running Open Models. Learn more about deploying your agent to GKE . ", "code_blocks": []}, {"heading_path": ["Other Container-friendly Infrastructure\u00b6"], "text": "Other Container-friendly Infrastructure \u00b6 You can manually package your Agent into a container image and then run it in\nany environment that supports container images.  For example you can run it\nlocally in Docker or Podman. This is a good option if you prefer to run offline\nor disconnected, or otherwise in a system that has no connection to Google\nCloud. Follow the instructions for deploying your agent to Cloud Run .\nIn the \"Deployment Commands\" section for gcloud CLI, you will find an example FastAPI entry point and \nDockerfile. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:24.599647", "source_type": "adk-docs"}
{"doc_id": "c94646beb16a6e9a4b03dc0a35a51550dee7c48364fa8d2267a131e9443c0849", "url": "https://google.github.io/adk-docs/deploy/agent-engine", "title": "Agent Engine - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Deploy to Vertex AI Agent Engine\u00b6"], "text": "Deploy to Vertex AI Agent Engine \u00b6 Supported in ADK Python Agent Engine is a fully managed Google Cloud service enabling developers to deploy, manage,\nand scale AI agents in production. Agent Engine handles the infrastructure to\nscale agents in production so you can focus on creating intelligent and\nimpactful applications. This guide provides an accelerated deployment\ninstruction set for when you want to deploy an ADK project quickly, and a\nstandard, step-by-step set of instructions for when you want to carefully manage\ndeploying an agent to Agent Engine. Preview: Vertex AI in express mode If you don't have a Google Cloud project, you can try Agent Engine without cost using Vertex AI in Express mode .\nFor details on using this feature, see the Standard deployment section. ", "code_blocks": []}, {"heading_path": ["Accelerated deployment\u00b6"], "text": "Accelerated deployment \u00b6 This section describes how to perform a deployment using the Agent Starter Pack (ASP) and the ADK command line interface (CLI) tool. This approach uses the ASP\ntool to apply a project template to your existing project, add deployment\nartifacts, and prepare your agent project for deployment. These instructions\nshow you how to use ASP to provision a Google Cloud project with services needed\nfor deploying your ADK project, as follows: Prerequisites : Setup Google Cloud\n    account, a project, and install required software. Prepare your ADK project : Modify your\n    existing ADK project files to get ready for deployment. Connect to your Google Cloud project :\n    Connect your development environment to Google Cloud and your Google Cloud\n    project. Deploy your ADK project :  Provision\n    required services in your Google Cloud project and upload your ADK project code. For information on testing a deployed agent, see Test deployed agent .\nFor more information on using Agent Starter Pack and its command line tools,\nsee the CLI reference and Development guide . ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 You need the following resources configured to use this deployment path: Google Cloud account , with administrator access to: Google Cloud Project : An empty Google Cloud project with billing enabled .\n    For information on creating projects, see Creating and managing projects . Python Environment : A Python version between 3.9 and 3.13. UV Tool: Manage Python development environment and running ASP\n    tools. For installation details, see Install UV . Google Cloud CLI tool : The gcloud command line interface. For\n    installation details, see Google Cloud Command Line Interface . Make tool : Build automation tool. This tool is part of most\n    Unix-based systems, for installation details, see the Make tool documentation. ", "code_blocks": []}, {"heading_path": ["Prepare your ADK project\u00b6"], "text": "Prepare your ADK project \u00b6 When you deploy an ADK project to Agent Engine, you need some additional files\nto support the deployment operation. The following ASP command backs up your\nproject and then adds files to your project for deployment purposes. These instructions assume you have an existing ADK project that you are modifying\nfor deployment. If you do not have an ADK project, or want to use a test\nproject, complete the Python Quickstart guide,\nwhich creates a multi_tool_agent project. The following instructions use the multi_tool_agent project as an\nexample. To prepare your ADK project for deployment to Agent Engine: In a terminal window of your development environment, navigate to the parent directory that contains your agent folder. For example, if your\n    project structure is: your-project-directory/ \u251c\u2500\u2500 multi_tool_agent/ \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u251c\u2500\u2500 agent.py \u2502   \u2514\u2500\u2500 .env Navigate to your-project-directory/ Run the ASP enhance command to add the needed files required for\n    deployment into your project. uvx agent-starter-pack enhance --adk -d agent_engine Follow the instructions from the ASP tool. In general, you can accept\n    the default answers to all questions. However for the GCP region , \n    option, make sure you select one of the supported regions for Agent Engine . When you successfully complete this process, the tool shows the following message: > Success! Your agent project is ready. Note The ASP tool may show a reminder to connect to Google Cloud while\nrunning, but that connection is not required at this stage. For more information about the changes ASP makes to your ADK project, see Changes to your ADK project . ", "code_blocks": [{"language": "text", "code": "your-project-directory/\n\u251c\u2500\u2500 multi_tool_agent/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 agent.py\n\u2502   \u2514\u2500\u2500 .env"}, {"language": "text", "code": "uvx agent-starter-pack enhance --adk -d agent_engine"}, {"language": "text", "code": "> Success! Your agent project is ready."}]}, {"heading_path": ["Connect to your Google Cloud project\u00b6"], "text": "Connect to your Google Cloud project \u00b6 Before you deploy your ADK project, you must connect to Google Cloud and your\nproject. After logging into your Google Cloud account, you should verify that\nyour deployment target project is visible from your account and that it is\nconfigured as your current project. To connect to Google Cloud and list your project: In a terminal window of your development environment, login to your\n    Google Cloud account: gcloud auth application-default login Set your target project using the Google Cloud Project ID: gcloud config set project your-project-id-xxxxx Verify your Google Cloud target project is set: gcloud config get-value project Once you have successfully connected to Google Cloud and set your Cloud Project\nID, you are ready to deploy your ADK project files to Agent Engine. ", "code_blocks": [{"language": "text", "code": "gcloud auth application-default login"}, {"language": "text", "code": "gcloud config set project your-project-id-xxxxx"}, {"language": "text", "code": "gcloud config get-value project"}]}, {"heading_path": ["Deploy your ADK project\u00b6"], "text": "Deploy your ADK project \u00b6 When using the ASP tool, you deploy in stages. In the first stage, you run a make command that provisions the services needed to run your ADK workflow on\nAgent Engine. In the second stage, your project code is uploaded to the Agent\nEngine service and the agent project is executed. Important Make sure your Google Cloud target deployment project is set as your current\nproject before performing these steps . The make backend command uses\nyour currently set Google Cloud project when it performs a deployment. For\ninformation on setting and checking your current project, see Connect to your Google Cloud project . To deploy your ADK project to Agent Engine in your Google Cloud project: In a terminal window, ensure you are in the parent directory (e.g., your-project-directory/ ) that contains your agent folder. Deploy the code from the updated local project into the Google Cloud\ndevelopment environment, by running the following ASP make command: make backend Once this process completes successfully, you should be able to interact with\nthe agent running on Google Cloud Agent Engine. For details on testing the\ndeployed agent, see the next section. Once this process completes successfully, you should be able to interact with\nthe agent running on Google Cloud Agent Engine. For details on testing the\ndeployed agent, see Test deployed agent . ", "code_blocks": [{"language": "text", "code": "make backend"}]}, {"heading_path": ["Changes to your ADK project\u00b6"], "text": "Changes to your ADK project \u00b6 The ASP tools add more files to your project for deployment. The procedure\nbelow backs up your existing project files before modifying them. This guide\nuses the multi_tool_agent project as a reference example. The original project has the following file\nstructure to start with: multi_tool_agent/ \u251c\u2500 __init__.py \u251c\u2500 agent.py \u2514\u2500 .env After running the ASP enhance command to add Agent Engine deployment\ninformation, the new structure is as follows: multi-tool-agent/ \u251c\u2500 app/                 # Core application code \u2502   \u251c\u2500 agent.py         # Main agent logic \u2502   \u251c\u2500 agent_engine_app.py # Agent Engine application logic \u2502   \u2514\u2500 utils/           # Utility functions and helpers \u251c\u2500 .cloudbuild/         # CI/CD pipeline configurations for Google Cloud Build \u251c\u2500 deployment/          # Infrastructure and deployment scripts \u251c\u2500 notebooks/           # Jupyter notebooks for prototyping and evaluation \u251c\u2500 tests/               # Unit, integration, and load tests \u251c\u2500 Makefile             # Makefile for common commands \u251c\u2500 GEMINI.md            # AI-assisted development guide \u2514\u2500 pyproject.toml       # Project dependencies and configuration See the README.md file in your updated ADK project folder for more information.\nFor more information on using Agent Starter Pack, see the Development guide . ", "code_blocks": [{"language": "text", "code": "multi_tool_agent/\n\u251c\u2500 __init__.py\n\u251c\u2500 agent.py\n\u2514\u2500 .env"}, {"language": "text", "code": "multi-tool-agent/\n\u251c\u2500 app/                 # Core application code\n\u2502   \u251c\u2500 agent.py         # Main agent logic\n\u2502   \u251c\u2500 agent_engine_app.py # Agent Engine application logic\n\u2502   \u2514\u2500 utils/           # Utility functions and helpers\n\u251c\u2500 .cloudbuild/         # CI/CD pipeline configurations for Google Cloud Build\n\u251c\u2500 deployment/          # Infrastructure and deployment scripts\n\u251c\u2500 notebooks/           # Jupyter notebooks for prototyping and evaluation\n\u251c\u2500 tests/               # Unit, integration, and load tests\n\u251c\u2500 Makefile             # Makefile for common commands\n\u251c\u2500 GEMINI.md            # AI-assisted development guide\n\u2514\u2500 pyproject.toml       # Project dependencies and configuration"}]}, {"heading_path": ["Standard deployment\u00b6"], "text": "Standard deployment \u00b6 This section describes how to perform a deployment to Agent Engine step-by-step.\nThese instructions are more appropriate if you want to carefully manage your\ndeployment settings, or are modifying an existing deployment with Agent Engine. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 These instructions assume you have already defined an ADK project and GCP project. If you do not\nhave an ADK project, see the instructions for creating a test project in Define your agent . Preview: Vertex AI in express mode If you do not have an exising GCP project, you can try Agent Engine without cost using Vertex AI in Express mode . Google Cloud Project Vertex AI express mode Before starting deployment procedure, ensure you have the following: Google Cloud Project : A Google Cloud project with the Vertex AI API enabled . Authenticated gcloud CLI : You need to be authenticated with Google Cloud. Run the following command in your terminal: gcloud auth application-default login Google Cloud Storage (GCS) Bucket : Agent Engine requires a GCS bucket to stage your agent's code and dependencies for deployment. If you don't have a bucket, create one by following the instructions here . Python Environment : A Python version between 3.9 and 3.13. Install Vertex AI SDK Agent Engine is part of the Vertex AI SDK for Python. For more information, you can review the Agent Engine quickstart documentation . pip install google-cloud-aiplatform [ adk,agent_engines ] > = 1 .111 Before starting deployment procedure, ensure you have the following: API Key from Express Mode project : Sign up for an Express Mode project with your gmail account following the Express mode sign up . Get an API key from that project to use with Agent Engine! Python Environment : A Python version between 3.9 and 3.13. Install Vertex AI SDK Agent Engine is part of the Vertex AI SDK for Python. For more information, you can review the Agent Engine quickstart documentation . pip install google-cloud-aiplatform [ adk,agent_engines ] > = 1 .111 ", "code_blocks": [{"language": "text", "code": "gcloud auth application-default login"}, {"language": "text", "code": "pip install google-cloud-aiplatform[adk,agent_engines]>=1.111"}, {"language": "text", "code": "pip install google-cloud-aiplatform[adk,agent_engines]>=1.111"}]}, {"heading_path": ["Define your agent\u00b6"], "text": "Define your agent \u00b6 These instructions assume you have an existing ADK project that you are modifying\nfor deployment. If you do not have an ADK project, or want to use a test\nproject, complete the Python Quickstart guide,\nwhich creates a multi_tool_agent project. The following instructions use the multi_tool_agent project as an\nexample. ", "code_blocks": []}, {"heading_path": ["Initialize Vertex AI\u00b6"], "text": "Initialize Vertex AI \u00b6 Next, initialize the Vertex AI SDK. This tells the SDK which Google Cloud project and region to use, and where to stage files for deployment. For IDE Users You can place this initialization code in a separate deploy.py script along with the deployment logic for the following steps: 3 through 6. Google Cloud Project Vertex AI express mode deploy.py import vertexai from agent import root_agent # modify this if your agent is not in agent.py # TODO: Fill in these values for your project PROJECT_ID = \"your-gcp-project-id\" LOCATION = \"us-central1\" # For other options, see https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview#supported-regions STAGING_BUCKET = \"gs://your-gcs-bucket-name\" # Initialize the Vertex AI SDK vertexai . init ( project = PROJECT_ID , location = LOCATION , staging_bucket = STAGING_BUCKET , ) deploy.py import vertexai from agent import root_agent # modify this if your agent is not in agent.py # TODO: Fill in these values for your api key API_KEY = \"your-express-mode-api-key\" # Initialize the Vertex AI SDK vertexai . init ( api_key = API_KEY , ) ", "code_blocks": [{"language": "text", "code": "import vertexai\nfrom agent import root_agent # modify this if your agent is not in agent.py\n\n# TODO: Fill in these values for your project\nPROJECT_ID = \"your-gcp-project-id\"\nLOCATION = \"us-central1\"  # For other options, see https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview#supported-regions\nSTAGING_BUCKET = \"gs://your-gcs-bucket-name\"\n\n# Initialize the Vertex AI SDK\nvertexai.init(\n    project=PROJECT_ID,\n    location=LOCATION,\n    staging_bucket=STAGING_BUCKET,\n)"}, {"language": "text", "code": "import vertexai\nfrom agent import root_agent # modify this if your agent is not in agent.py\n\n# TODO: Fill in these values for your api key\nAPI_KEY = \"your-express-mode-api-key\"\n\n# Initialize the Vertex AI SDK\nvertexai.init(\n    api_key=API_KEY,\n)"}]}, {"heading_path": ["Prepare the agent for deployment\u00b6"], "text": "Prepare the agent for deployment \u00b6 To make your agent compatible with Agent Engine, you need to wrap it in an AdkApp object. deploy.py from vertexai import agent_engines # Wrap the agent in an AdkApp object app = agent_engines . AdkApp ( agent = root_agent , enable_tracing = True , ) Info When an AdkApp is deployed to Agent Engine, it automatically uses VertexAiSessionService for persistent, managed session state. This provides multi-turn conversational memory without any additional configuration. For local testing, the application defaults to a temporary, in-memory session service. ", "code_blocks": [{"language": "text", "code": "from vertexai import agent_engines\n\n# Wrap the agent in an AdkApp object\napp = agent_engines.AdkApp(\n    agent=root_agent,\n    enable_tracing=True,\n)"}]}, {"heading_path": ["Test agent locally (optional)\u00b6"], "text": "Test agent locally (optional) \u00b6 Before deploying, you can test your agent's behavior locally. The async_stream_query method returns a stream of events that represent the agent's execution trace. deploy.py # Create a local session to maintain conversation history session = await app . async_create_session ( user_id = \"u_123\" ) print ( session ) Expected output for create_session (local): Session(id='c6a33dae-26ef-410c-9135-b434a528291f', app_name='default-app-name', user_id='u_123', state={}, events=[], last_update_time=1743440392.8689594) Send a query to the agent. Copy-paste the following code to your \"deploy.py\" python script or a notebook. deploy.py events = [] async for event in app . async_stream_query ( user_id = \"u_123\" , session_id = session . id , message = \"whats the weather in new york\" , ): events . append ( event ) # The full event stream shows the agent's thought process print ( \"--- Full Event Stream ---\" ) for event in events : print ( event ) # For quick tests, you can extract just the final text response final_text_responses = [ e for e in events if e . get ( \"content\" , {}) . get ( \"parts\" , [{}])[ 0 ] . get ( \"text\" ) and not e . get ( \"content\" , {}) . get ( \"parts\" , [{}])[ 0 ] . get ( \"function_call\" ) ] if final_text_responses : print ( \" \\n --- Final Response ---\" ) print ( final_text_responses [ 0 ][ \"content\" ][ \"parts\" ][ 0 ][ \"text\" ]) ", "code_blocks": [{"language": "text", "code": "# Create a local session to maintain conversation history\nsession = await app.async_create_session(user_id=\"u_123\")\nprint(session)"}, {"language": "text", "code": "Session(id='c6a33dae-26ef-410c-9135-b434a528291f', app_name='default-app-name', user_id='u_123', state={}, events=[], last_update_time=1743440392.8689594)"}, {"language": "text", "code": "events = []\nasync for event in app.async_stream_query(\n    user_id=\"u_123\",\n    session_id=session.id,\n    message=\"whats the weather in new york\",\n):\n    events.append(event)\n\n# The full event stream shows the agent's thought process\nprint(\"--- Full Event Stream ---\")\nfor event in events:\n    print(event)\n\n# For quick tests, you can extract just the final text response\nfinal_text_responses = [\n    e for e in events\n    if e.get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\")\n    and not e.get(\"content\", {}).get(\"parts\", [{}])[0].get(\"function_call\")\n]\nif final_text_responses:\n    print(\"\\n--- Final Response ---\")\n    print(final_text_responses[0][\"content\"][\"parts\"][0][\"text\"])"}]}, {"heading_path": ["Understanding the output\u00b6"], "text": "Understanding the output \u00b6 When you run the code above, you will see a few types of events: Tool Call Event : The model asks to call a tool (e.g., get_weather ). Tool Response Event : The system provides the result of the tool call back to the model. Model Response Event : The final text response from the agent after it has processed the tool results. Expected output for async_stream_query (local): {'parts': [{'function_call': {'id': 'af-a33fedb0-29e6-4d0c-9eb3-00c402969395', 'args': {'city': 'new york'}, 'name': 'get_weather'}}], 'role': 'model'} {'parts': [{'function_response': {'id': 'af-a33fedb0-29e6-4d0c-9eb3-00c402969395', 'name': 'get_weather', 'response': {'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}}}], 'role': 'user'} {'parts': [{'text': 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}], 'role': 'model'} ", "code_blocks": [{"language": "text", "code": "{'parts': [{'function_call': {'id': 'af-a33fedb0-29e6-4d0c-9eb3-00c402969395', 'args': {'city': 'new york'}, 'name': 'get_weather'}}], 'role': 'model'}\n{'parts': [{'function_response': {'id': 'af-a33fedb0-29e6-4d0c-9eb3-00c402969395', 'name': 'get_weather', 'response': {'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}}}], 'role': 'user'}\n{'parts': [{'text': 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}], 'role': 'model'}"}]}, {"heading_path": ["Deploy to agent engine\u00b6"], "text": "Deploy to agent engine \u00b6 Once you are satisfied with your agent's local behavior, you can deploy it. You can do this using the Python SDK or the adk command-line tool. This process packages your code, builds it into a container, and deploys it to the managed Agent Engine service. This process can take several minutes. ADK CLI Python Vertex AI express mode You can deploy from your terminal using the adk deploy command line tool.\nThe following example deploy command uses the multi_tool_agent sample\ncode as the project to be deployed: adk deploy agent_engine \\ --project = my-cloud-project-xxxxx \\ --region = us-central1 \\ --staging_bucket = gs://my-cloud-project-staging-bucket-name \\ --display_name = \"My Agent Name\" \\ /multi_tool_agent Find the names of your available storage buckets in the Cloud Storage Bucket section of your deployment project in the Google Cloud Console.\nFor more details on using the adk deploy command, see the ADK CLI reference . Tip Make sure your main ADK agent definition ( root_agent ) is \ndiscoverable when deploying your ADK project. This code block initiates the deployment from a Python script or notebook. deploy.py from vertexai import agent_engines remote_app = agent_engines . create ( agent_engine = app , requirements = [ \"google-cloud-aiplatform[adk,agent_engines]\" ] ) print ( f \"Deployment finished!\" ) print ( f \"Resource Name: { remote_app . resource_name } \" ) # Resource Name: \"projects/{PROJECT_NUMBER}/locations/{LOCATION}/reasoningEngines/{RESOURCE_ID}\" #       Note: The PROJECT_NUMBER is different than the PROJECT_ID. Vertex AI express mode supports both ADK CLI deployment and Python deployment. The following example deploy command uses the multi_tool_agent sample\ncode as the project to be deployed with express mode: adk deploy agent_engine \\ --display_name = \"My Agent Name\" \\ --api_key = your-api-key-here /multi_tool_agent Tip Make sure your main ADK agent definition ( root_agent ) is \ndiscoverable when deploying your ADK project. This code block initiates the deployment from a Python script or notebook. deploy.py from vertexai import agent_engines remote_app = agent_engines . create ( agent_engine = app , requirements = [ \"google-cloud-aiplatform[adk,agent_engines]\" ] ) print ( f \"Deployment finished!\" ) print ( f \"Resource Name: { remote_app . resource_name } \" ) # Resource Name: \"projects/{PROJECT_NUMBER}/locations/{LOCATION}/reasoningEngines/{RESOURCE_ID}\" #       Note: The PROJECT_NUMBER is different than the PROJECT_ID. ", "code_blocks": [{"language": "text", "code": "adk deploy agent_engine \\\n    --project=my-cloud-project-xxxxx \\\n    --region=us-central1 \\\n    --staging_bucket=gs://my-cloud-project-staging-bucket-name \\\n    --display_name=\"My Agent Name\" \\\n    /multi_tool_agent"}, {"language": "text", "code": "from vertexai import agent_engines\n\nremote_app = agent_engines.create(\n    agent_engine=app,\n    requirements=[\n        \"google-cloud-aiplatform[adk,agent_engines]\"   \n    ]\n)\n\nprint(f\"Deployment finished!\")\nprint(f\"Resource Name: {remote_app.resource_name}\")\n# Resource Name: \"projects/{PROJECT_NUMBER}/locations/{LOCATION}/reasoningEngines/{RESOURCE_ID}\"\n#       Note: The PROJECT_NUMBER is different than the PROJECT_ID."}, {"language": "text", "code": "adk deploy agent_engine \\\n    --display_name=\"My Agent Name\" \\\n    --api_key=your-api-key-here\n    /multi_tool_agent"}, {"language": "text", "code": "from vertexai import agent_engines\n\nremote_app = agent_engines.create(\n    agent_engine=app,\n    requirements=[\n        \"google-cloud-aiplatform[adk,agent_engines]\"   \n    ]\n)\n\nprint(f\"Deployment finished!\")\nprint(f\"Resource Name: {remote_app.resource_name}\")\n# Resource Name: \"projects/{PROJECT_NUMBER}/locations/{LOCATION}/reasoningEngines/{RESOURCE_ID}\"\n#       Note: The PROJECT_NUMBER is different than the PROJECT_ID."}]}, {"heading_path": ["Monitoring and verification\u00b6"], "text": "Monitoring and verification \u00b6 You can monitor the deployment status in the Agent Engine UI in the Google Cloud Console. The remote_app.resource_name is the unique identifier for your deployed agent. You will need it to interact with the agent. You can also get this from the response returned by the ADK CLI command. For additional details, you can visit the Agent Engine documentation deploying an agent and managing deployed agents . ", "code_blocks": []}, {"heading_path": ["Test deployed agent\u00b6"], "text": "Test deployed agent \u00b6 Once you have completed the deployment of your agent to Agent Engine, you can\nview your deployed agent through the Google Cloud Console, and interact\nwith the agent using REST calls or the Vertex AI SDK for Python. To view your deployed agent in the Cloud Console: Navigate to the Agent Engine page in the Google Cloud Console: https://console.cloud.google.com/vertex-ai/agents/agent-engines This page lists all deployed agents in your currently selected Google Cloud \nproject. If you do not see your agent listed, make sure you have your\ntarget project selected in Google Cloud Console. For more information on\nselecting an exising Google Cloud project, see Creating and managing projects . ", "code_blocks": []}, {"heading_path": ["Find Google Cloud project information\u00b6"], "text": "Find Google Cloud project information \u00b6 You need the address and resource identification for your project ( PROJECT_ID , LOCATION , RESOURCE_ID ) to be able to test your deployment. You can use Cloud\nConsole or the gcloud command line tool to find this information. Vertex AI express mode API key If you are using Vertex AI express mode, you can skip this step and use your API key. To find your project information with Google Cloud Console: In the Google Cloud Console, navigate to the Agent Engine page: https://console.cloud.google.com/vertex-ai/agents/agent-engines At the top of the page, select API URLs , and then copy the Query\n    URL string for your deployed agent, which should be in this format: https://$(LOCATION_ID)-aiplatform.googleapis.com/v1/projects/$(PROJECT_ID)/locations/$(LOCATION_ID)/reasoningEngines/$(RESOURCE_ID):query To find your project information with gloud : In your development environment, make sure you are authenticated to \n    Google Cloud and run the following command to list your project: gcloud projects list Take the Project ID used for deployment and run this command to get\n    the additional details: gcloud asset search-all-resources \\ --scope = projects/ $( PROJECT_ID ) \\ --asset-types = 'aiplatform.googleapis.com/ReasoningEngine' \\ --format = \"table(name,assetType,location,reasoning_engine_id)\" ", "code_blocks": [{"language": "text", "code": "https://$(LOCATION_ID)-aiplatform.googleapis.com/v1/projects/$(PROJECT_ID)/locations/$(LOCATION_ID)/reasoningEngines/$(RESOURCE_ID):query"}, {"language": "text", "code": "gcloud projects list"}, {"language": "text", "code": "gcloud asset search-all-resources \\\n    --scope=projects/$(PROJECT_ID) \\\n    --asset-types='aiplatform.googleapis.com/ReasoningEngine' \\\n    --format=\"table(name,assetType,location,reasoning_engine_id)\""}]}, {"heading_path": ["Test using REST calls\u00b6"], "text": "Test using REST calls \u00b6 A simple way to interact with your deployed agent in Agent Engine is to use REST\ncalls with the curl tool. This section describes the how to check your\nconnection to the agent and also to test processing of a request by the deployed\nagent. ", "code_blocks": []}, {"heading_path": ["Check connection to agent\u00b6"], "text": "Check connection to agent \u00b6 You can check your connection to the running agent using the Query URL available in the Agent Engine section of the Cloud Console. This check does not\nexecute the deployed agent, but returns information about the agent. To send a REST call get a response from deployed agent: In a terminal window of your development environment, build a request\n    and execute it: Google Cloud Project Vertex AI express mode curl -X GET \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ \"https:// $( LOCATION ) -aiplatform.googleapis.com/v1/projects/ $( PROJECT_ID ) /locations/ $( LOCATION ) /reasoningEngines\" curl -X GET \\ -H \"x-goog-api-key:YOUR-EXPRESS-MODE-API-KEY\" \\ \"https://aiplatform.googleapis.com/v1/reasoningEngines\" If your deployment was successful, this request responds with a list of valid\nrequests and expected data formats. Access for agent connections This connection test requires the calling user has a valid access token for the\ndeployed agent. When testing from other environments, make sure the calling user\nhas access to connect to the agent in your Google Cloud project. ", "code_blocks": [{"language": "text", "code": "curl -X GET \\\n    -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n    \"https://$(LOCATION)-aiplatform.googleapis.com/v1/projects/$(PROJECT_ID)/locations/$(LOCATION)/reasoningEngines\""}, {"language": "text", "code": "curl -X GET \\\n    -H \"x-goog-api-key:YOUR-EXPRESS-MODE-API-KEY\" \\\n    \"https://aiplatform.googleapis.com/v1/reasoningEngines\""}]}, {"heading_path": ["Send an agent request\u00b6"], "text": "Send an agent request \u00b6 When getting responses from your agent project, you must first create a\nsession, receive a Session ID, and then send your requests using that Session\nID. This process is described in the following instructions. To test interaction with the deployed agent via REST: In a terminal window of your development environment, create a session\n    by building a request using this template: Google Cloud Project Vertex AI express mode curl \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H \"Content-Type: application/json\" \\ https:// $( LOCATION ) -aiplatform.googleapis.com/v1/projects/ $( PROJECT_ID ) /locations/ $( LOCATION ) /reasoningEngines/ $( RESOURCE_ID ) :query \\ -d '{\"class_method\": \"async_create_session\", \"input\": {\"user_id\": \"u_123\"},}' curl \\ -H \"x-goog-api-key:YOUR-EXPRESS-MODE-API-KEY\" \\ -H \"Content-Type: application/json\" \\ https://aiplatform.googleapis.com/v1/reasoningEngines/ $( RESOURCE_ID ) :query \\ -d '{\"class_method\": \"async_create_session\", \"input\": {\"user_id\": \"u_123\"},}' In the response to the previous command, extract the created Session ID from the id field: { \"output\" : { \"userId\" : \"u_123\" , \"lastUpdateTime\" : 1757690426.337745 , \"state\" : {}, \"id\" : \"4857885913439920384\" , # Sessio n ID \"appName\" : \"9888888855577777776\" , \"events\" : [] } } In a terminal window of your development environment, send a message to\n    your agent by building a request using this template and the Session ID\n    created in the previous step: Google Cloud Project Vertex AI express mode curl \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H \"Content-Type: application/json\" \\ https:// $( LOCATION ) -aiplatform.googleapis.com/v1/projects/ $( PROJECT_ID ) /locations/ $( LOCATION ) /reasoningEngines/ $( RESOURCE_ID ) :streamQuery?alt = sse -d '{ \"class_method\": \"async_stream_query\", \"input\": { \"user_id\": \"u_123\", \"session_id\": \"4857885913439920384\", \"message\": \"Hey whats the weather in new york today?\", } }' curl \\ -H \"x-goog-api-key:YOUR-EXPRESS-MODE-API-KEY\" \\ -H \"Content-Type: application/json\" \\ https://aiplatform.googleapis.com/v1/reasoningEngines/ $( RESOURCE_ID ) :streamQuery?alt = sse -d '{ \"class_method\": \"async_stream_query\", \"input\": { \"user_id\": \"u_123\", \"session_id\": \"4857885913439920384\", \"message\": \"Hey whats the weather in new york today?\", } }' This request should generate a response from your deployed agent code in JSON\nformat. For more information about interacting with a deployed ADK agent in\nAgent Engine using REST calls, see Manage deployed agents and Use a Agent Development Kit agent in the Agent Engine documentation. ", "code_blocks": [{"language": "text", "code": "curl \\\n    -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n    -H \"Content-Type: application/json\" \\\n    https://$(LOCATION)-aiplatform.googleapis.com/v1/projects/$(PROJECT_ID)/locations/$(LOCATION)/reasoningEngines/$(RESOURCE_ID):query \\\n    -d '{\"class_method\": \"async_create_session\", \"input\": {\"user_id\": \"u_123\"},}'"}, {"language": "text", "code": "curl \\\n    -H \"x-goog-api-key:YOUR-EXPRESS-MODE-API-KEY\" \\\n    -H \"Content-Type: application/json\" \\\n    https://aiplatform.googleapis.com/v1/reasoningEngines/$(RESOURCE_ID):query \\\n    -d '{\"class_method\": \"async_create_session\", \"input\": {\"user_id\": \"u_123\"},}'"}, {"language": "text", "code": "{\n    \"output\": {\n        \"userId\": \"u_123\",\n        \"lastUpdateTime\": 1757690426.337745,\n        \"state\": {},\n        \"id\": \"4857885913439920384\", # Session ID\n        \"appName\": \"9888888855577777776\",\n        \"events\": []\n    }\n}"}, {"language": "text", "code": "curl \\\n-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n-H \"Content-Type: application/json\" \\\nhttps://$(LOCATION)-aiplatform.googleapis.com/v1/projects/$(PROJECT_ID)/locations/$(LOCATION)/reasoningEngines/$(RESOURCE_ID):streamQuery?alt=sse -d '{\n\"class_method\": \"async_stream_query\",\n\"input\": {\n    \"user_id\": \"u_123\",\n    \"session_id\": \"4857885913439920384\",\n    \"message\": \"Hey whats the weather in new york today?\",\n}\n}'"}, {"language": "text", "code": "curl \\\n-H \"x-goog-api-key:YOUR-EXPRESS-MODE-API-KEY\" \\\n-H \"Content-Type: application/json\" \\\nhttps://aiplatform.googleapis.com/v1/reasoningEngines/$(RESOURCE_ID):streamQuery?alt=sse -d '{\n\"class_method\": \"async_stream_query\",\n\"input\": {\n    \"user_id\": \"u_123\",\n    \"session_id\": \"4857885913439920384\",\n    \"message\": \"Hey whats the weather in new york today?\",\n}\n}'"}]}, {"heading_path": ["Test using Python\u00b6"], "text": "Test using Python \u00b6 You can use Python code for more sophisticated and repeatable testing of your\nagent deployed in Agent Engine. These instructions describe how to create\na session with the deployed agent, and then send a request to the agent for\nprocessing. ", "code_blocks": []}, {"heading_path": ["Create a remote session\u00b6"], "text": "Create a remote session \u00b6 Use the remote_app object to create a connection to deployed, remote agent: # If you are in a new script or used the ADK CLI to deploy, you can connect like this: # remote_app = agent_engines.get(\"your-agent-resource-name\") remote_session = await remote_app . async_create_session ( user_id = \"u_456\" ) print ( remote_session ) Expected output for create_session (remote): {'events': [], 'user_id': 'u_456', 'state': {}, 'id': '7543472750996750336', 'app_name': '7917477678498709504', 'last_update_time': 1743683353.030133} The id value is the session ID, and app_name is the resource ID of the\ndeployed agent on Agent Engine. ", "code_blocks": [{"language": "text", "code": "# If you are in a new script or used the ADK CLI to deploy, you can connect like this:\n# remote_app = agent_engines.get(\"your-agent-resource-name\")\nremote_session = await remote_app.async_create_session(user_id=\"u_456\")\nprint(remote_session)"}, {"language": "text", "code": "{'events': [],\n'user_id': 'u_456',\n'state': {},\n'id': '7543472750996750336',\n'app_name': '7917477678498709504',\n'last_update_time': 1743683353.030133}"}]}, {"heading_path": ["Send queries to your remote agent\u00b6"], "text": "Send queries to your remote agent \u00b6 async for event in remote_app . async_stream_query ( user_id = \"u_456\" , session_id = remote_session [ \"id\" ], message = \"whats the weather in new york\" , ): print ( event ) Expected output for async_stream_query (remote): {'parts': [{'function_call': {'id': 'af-f1906423-a531-4ecf-a1ef-723b05e85321', 'args': {'city': 'new york'}, 'name': 'get_weather'}}], 'role': 'model'} {'parts': [{'function_response': {'id': 'af-f1906423-a531-4ecf-a1ef-723b05e85321', 'name': 'get_weather', 'response': {'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}}}], 'role': 'user'} {'parts': [{'text': 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}], 'role': 'model'} For more information about interacting with a deployed ADK agent in\nAgent Engine, see Manage deployed agents and Use a Agent Development Kit agent in the Agent Engine documentation. ", "code_blocks": [{"language": "text", "code": "async for event in remote_app.async_stream_query(\n    user_id=\"u_456\",\n    session_id=remote_session[\"id\"],\n    message=\"whats the weather in new york\",\n):\n    print(event)"}, {"language": "text", "code": "{'parts': [{'function_call': {'id': 'af-f1906423-a531-4ecf-a1ef-723b05e85321', 'args': {'city': 'new york'}, 'name': 'get_weather'}}], 'role': 'model'}\n{'parts': [{'function_response': {'id': 'af-f1906423-a531-4ecf-a1ef-723b05e85321', 'name': 'get_weather', 'response': {'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}}}], 'role': 'user'}\n{'parts': [{'text': 'The weather in New York is sunny with a temperature of 25 degrees Celsius (41 degrees Fahrenheit).'}], 'role': 'model'}"}]}, {"heading_path": ["Sending Multimodal Queries\u00b6"], "text": "Sending Multimodal Queries \u00b6 To send multimodal queries (e.g., including images) to your agent, you can construct the message parameter of async_stream_query with a list of types.Part objects. Each part can be text or an image. To include an image, you can use types.Part.from_uri , providing a Google Cloud Storage (GCS) URI for the image. from google.genai import types image_part = types . Part . from_uri ( file_uri = \"gs://cloud-samples-data/generative-ai/image/scones.jpg\" , mime_type = \"image/jpeg\" , ) text_part = types . Part . from_text ( text = \"What is in this image?\" , ) async for event in remote_app . async_stream_query ( user_id = \"u_456\" , session_id = remote_session [ \"id\" ], message = [ text_part , image_part ], ): print ( event ) Note While the underlying communication with the model may involve Base64\nencoding for images, the recommended and supported method for sending image\ndata to an agent deployed on Agent Engine is by providing a GCS URI. ", "code_blocks": [{"language": "text", "code": "from google.genai import types\n\nimage_part = types.Part.from_uri(\n    file_uri=\"gs://cloud-samples-data/generative-ai/image/scones.jpg\",\n    mime_type=\"image/jpeg\",\n)\ntext_part = types.Part.from_text(\n    text=\"What is in this image?\",\n)\n\nasync for event in remote_app.async_stream_query(\n    user_id=\"u_456\",\n    session_id=remote_session[\"id\"],\n    message=[text_part, image_part],\n):\n    print(event)"}]}, {"heading_path": ["Deployment payload\u00b6"], "text": "Deployment payload \u00b6 When you deploy your ADK agent project to Agent Engine,\nthe following content is uploaded to the service: Your ADK agent code Any dependencies declared in your ADK agent code The deployment does not include the ADK API server or the ADK web user\ninterface libraries. The Agent Engine service provides the libraries for ADK API\nserver functionality. ", "code_blocks": []}, {"heading_path": ["Clean up deployments\u00b6"], "text": "Clean up deployments \u00b6 If you have performed deployments as tests, it is a good practice to clean up\nyour cloud resources after you have finished. You can delete the deployed Agent\nEngine instance to avoid any unexpected charges on your Google Cloud account. remote_app . delete ( force = True ) The force=True parameter also deletes any child resources that were generated\nfrom the deployed agent, such as sessions. You can also delete your deployed\nagent via the Agent Engine UI on Google Cloud. Back to top ", "code_blocks": [{"language": "text", "code": "remote_app.delete(force=True)"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:25.200066", "source_type": "adk-docs"}
{"doc_id": "31c13868ea755bb223ce6fd2ea4be25db8c789c399e5beae43b85834ae0c28ba", "url": "https://google.github.io/adk-docs/deploy/cloud-run", "title": "Cloud Run - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Deploy to Cloud Run\u00b6"], "text": "Deploy to Cloud Run \u00b6 Supported in ADK Python Go Java Cloud Run is a fully managed platform that enables you to run your code directly on top of Google's scalable infrastructure. To deploy your agent, you can use either the adk deploy cloud_run command (recommended for Python) , or with gcloud run deploy command through Cloud Run. ", "code_blocks": []}, {"heading_path": ["Agent sample\u00b6"], "text": "Agent sample \u00b6 For each of the commands, we will reference a the Capital Agent sample defined on the LLM agent page. We will assume it's in a directory (eg: capital_agent ). To proceed, confirm that your agent code is configured as follows: Python Go Java Agent code is in a file called agent.py within your agent directory. Your agent variable is named root_agent . __init__.py is within your agent directory and contains from . import agent . Your requirements.txt file is present in the agent directory. Your application's entry point (the main package and main() function) is in a\n   single Go file. Using main.go is a strong convention. Your agent instance is passed to a launcher configuration, typically using\n   services.NewSingleAgentLoader(agent). The adkgo tool uses this launcher to start\n   your agent with the correct services. Your go.mod and go.sum files are present in your project directory to manage\n   dependencies. Refer to the following section for more details. You can also find a sample app in the Github repo. Agent code is in a file called CapitalAgent.java within your agent directory. Your agent variable is global and follows the format public static final BaseAgent ROOT_AGENT . Your agent definition is present in a static class method. Refer to the following section for more details. You can also find a sample app in the Github repo. ", "code_blocks": []}, {"heading_path": ["Environment variables\u00b6"], "text": "Environment variables \u00b6 Set your environment variables as described in the Setup and Installation guide. export GOOGLE_CLOUD_PROJECT = your-project-id export GOOGLE_CLOUD_LOCATION = us-central1 # Or your preferred location export GOOGLE_GENAI_USE_VERTEXAI = True (Replace your-project-id with your actual GCP project ID) Alternatively you can also use an API key from AI Studio export GOOGLE_CLOUD_PROJECT = your-project-id export GOOGLE_CLOUD_LOCATION = us-central1 # Or your preferred location export GOOGLE_GENAI_USE_VERTEXAI = FALSE export GOOGLE_API_KEY = your-api-key (Replace your-project-id with your actual GCP project ID and your-api-key with your actual API key from AI Studio) ", "code_blocks": [{"language": "text", "code": "export GOOGLE_CLOUD_PROJECT=your-project-id\nexport GOOGLE_CLOUD_LOCATION=us-central1 # Or your preferred location\nexport GOOGLE_GENAI_USE_VERTEXAI=True"}, {"language": "text", "code": "export GOOGLE_CLOUD_PROJECT=your-project-id\nexport GOOGLE_CLOUD_LOCATION=us-central1 # Or your preferred location\nexport GOOGLE_GENAI_USE_VERTEXAI=FALSE\nexport GOOGLE_API_KEY=your-api-key"}]}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 You should have a Google Cloud project. You need to know your: Project name (i.e. \"my-project\") Project location (i.e. \"us-central1\") Service account (i.e. \"1234567890-compute@developer.gserviceaccount.com\") GOOGLE_API_KEY ", "code_blocks": []}, {"heading_path": ["Secret\u00b6"], "text": "Secret \u00b6 Please make sure you have created a secret which can be read by your service account. ", "code_blocks": []}, {"heading_path": ["Entry for GOOGLE_API_KEY secret\u00b6"], "text": "Entry for GOOGLE_API_KEY secret \u00b6 You can create your secret manually or use CLI: echo \"<<put your GOOGLE_API_KEY here>>\" | gcloud secrets create GOOGLE_API_KEY --project = my-project --data-file = - ", "code_blocks": [{"language": "text", "code": "echo \"<<put your GOOGLE_API_KEY here>>\" | gcloud secrets create GOOGLE_API_KEY --project=my-project --data-file=-"}]}, {"heading_path": ["Permissions to read\u00b6"], "text": "Permissions to read \u00b6 You should give appropiate permissision for you service account to read this secret. gcloud secrets add-iam-policy-binding GOOGLE_API_KEY --member = \"serviceAccount:1234567890-compute@developer.gserviceaccount.com\" --role = \"roles/secretmanager.secretAccessor\" --project = my-project ", "code_blocks": [{"language": "text", "code": "gcloud secrets add-iam-policy-binding GOOGLE_API_KEY --member=\"serviceAccount:1234567890-compute@developer.gserviceaccount.com\" --role=\"roles/secretmanager.secretAccessor\" --project=my-project"}]}, {"heading_path": ["Deployment payload\u00b6"], "text": "Deployment payload \u00b6 When you deploy your ADK agent workflow to the Google Cloud Run,\nthe following content is uploaded to the service: Your ADK agent code Any dependencies declared in your ADK agent code ADK API server code version used by your agent The default deployment does not include the ADK web user interface libraries,\nunless you specify it as deployment setting, such as the --with_ui option for adk deploy cloud_run command. ", "code_blocks": []}, {"heading_path": ["Deployment commands\u00b6"], "text": "Deployment commands \u00b6 Python - adk CLI Python - gcloud CLI Go - adkgo CLI Java - gcloud CLI ", "code_blocks": []}, {"heading_path": ["adk CLI\u00b6"], "text": "adk CLI \u00b6 The adk deploy cloud_run command deploys your agent code to Google Cloud Run. Ensure you have authenticated with Google Cloud ( gcloud auth login and gcloud config set project <your-project-id> ). ", "code_blocks": []}, {"heading_path": ["Setup environment variables\u00b6"], "text": "Setup environment variables \u00b6 Optional but recommended: Setting environment variables can make the deployment commands cleaner. # Set your Google Cloud Project ID export GOOGLE_CLOUD_PROJECT = \"your-gcp-project-id\" # Set your desired Google Cloud Location export GOOGLE_CLOUD_LOCATION = \"us-central1\" # Example location # Set the path to your agent code directory export AGENT_PATH = \"./capital_agent\" # Assuming capital_agent is in the current directory # Set a name for your Cloud Run service (optional) export SERVICE_NAME = \"capital-agent-service\" # Set an application name (optional) export APP_NAME = \"capital-agent-app\" ", "code_blocks": [{"language": "text", "code": "# Set your Google Cloud Project ID\nexport GOOGLE_CLOUD_PROJECT=\"your-gcp-project-id\"\n\n# Set your desired Google Cloud Location\nexport GOOGLE_CLOUD_LOCATION=\"us-central1\" # Example location\n\n# Set the path to your agent code directory\nexport AGENT_PATH=\"./capital_agent\" # Assuming capital_agent is in the current directory\n\n# Set a name for your Cloud Run service (optional)\nexport SERVICE_NAME=\"capital-agent-service\"\n\n# Set an application name (optional)\nexport APP_NAME=\"capital-agent-app\""}]}, {"heading_path": ["Command usage\u00b6"], "text": "Command usage \u00b6 ", "code_blocks": []}, {"heading_path": ["Minimal command\u00b6"], "text": "Minimal command \u00b6 adk deploy cloud_run \\ --project = $GOOGLE_CLOUD_PROJECT \\ --region = $GOOGLE_CLOUD_LOCATION \\ $AGENT_PATH ", "code_blocks": [{"language": "text", "code": "adk deploy cloud_run \\\n--project=$GOOGLE_CLOUD_PROJECT \\\n--region=$GOOGLE_CLOUD_LOCATION \\\n$AGENT_PATH"}]}, {"heading_path": ["Full command with optional flags\u00b6"], "text": "Full command with optional flags \u00b6 adk deploy cloud_run \\ --project = $GOOGLE_CLOUD_PROJECT \\ --region = $GOOGLE_CLOUD_LOCATION \\ --service_name = $SERVICE_NAME \\ --app_name = $APP_NAME \\ --with_ui \\ $AGENT_PATH ", "code_blocks": [{"language": "text", "code": "adk deploy cloud_run \\\n--project=$GOOGLE_CLOUD_PROJECT \\\n--region=$GOOGLE_CLOUD_LOCATION \\\n--service_name=$SERVICE_NAME \\\n--app_name=$APP_NAME \\\n--with_ui \\\n$AGENT_PATH"}]}, {"heading_path": ["Arguments\u00b6"], "text": "Arguments \u00b6 AGENT_PATH : (Required) Positional argument specifying the path to the directory containing your agent's source code (e.g., $AGENT_PATH in the examples, or capital_agent/ ). This directory must contain at least an __init__.py and your main agent file (e.g., agent.py ). ", "code_blocks": []}, {"heading_path": ["Options\u00b6"], "text": "Options \u00b6 --project TEXT : (Required) Your Google Cloud project ID (e.g., $GOOGLE_CLOUD_PROJECT ). --region TEXT : (Required) The Google Cloud location for deployment (e.g., $GOOGLE_CLOUD_LOCATION , us-central1 ). --service_name TEXT : (Optional) The name for the Cloud Run service (e.g., $SERVICE_NAME ). Defaults to adk-default-service-name . --app_name TEXT : (Optional) The application name for the ADK API server (e.g., $APP_NAME ). Defaults to the name of the directory specified by AGENT_PATH (e.g., capital_agent if AGENT_PATH is ./capital_agent ). --agent_engine_id TEXT : (Optional) If you are using a managed session service via Vertex AI Agent Engine, provide its resource ID here. --port INTEGER : (Optional) The port number the ADK API server will listen on within the container. Defaults to 8000. --with_ui : (Optional) If included, deploys the ADK dev UI alongside the agent API server. By default, only the API server is deployed. --temp_folder TEXT : (Optional) Specifies a directory for storing intermediate files generated during the deployment process. Defaults to a timestamped folder in the system's temporary directory. (Note: This option is generally not needed unless troubleshooting issues). --help : Show the help message and exit. ", "code_blocks": []}, {"heading_path": ["Authenticated access\u00b6"], "text": "Authenticated access \u00b6 During the deployment process, you might be prompted: Allow unauthenticated invocations to [your-service-name] (y/N)? . Enter y to allow public access to your agent's API endpoint without authentication. Enter N (or press Enter for the default) to require authentication (e.g., using an identity token as shown in the \"Testing your agent\" section). Upon successful execution, the command deploys your agent to Cloud Run and provide the URL of the deployed service. ", "code_blocks": []}, {"heading_path": ["gcloud CLI for Python\u00b6"], "text": "gcloud CLI for Python \u00b6 Alternatively, you can deploy using the standard gcloud run deploy command with a Dockerfile . This method requires more manual setup compared to the adk command but offers flexibility, particularly if you want to embed your agent within a custom FastAPI application. Ensure you have authenticated with Google Cloud ( gcloud auth login and gcloud config set project <your-project-id> ). ", "code_blocks": []}, {"heading_path": ["Project Structure\u00b6"], "text": "Project Structure \u00b6 Organize your project files as follows: your-project-directory/ \u251c\u2500\u2500 capital_agent/ \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 agent.py       # Your agent code (see \"Agent sample\" tab) \u251c\u2500\u2500 main.py            # FastAPI application entry point \u251c\u2500\u2500 requirements.txt   # Python dependencies \u2514\u2500\u2500 Dockerfile         # Container build instructions Create the following files ( main.py , requirements.txt , Dockerfile ) in the root of your-project-directory/ . ", "code_blocks": [{"language": "text", "code": "your-project-directory/\n\u251c\u2500\u2500 capital_agent/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 agent.py       # Your agent code (see \"Agent sample\" tab)\n\u251c\u2500\u2500 main.py            # FastAPI application entry point\n\u251c\u2500\u2500 requirements.txt   # Python dependencies\n\u2514\u2500\u2500 Dockerfile         # Container build instructions"}]}, {"heading_path": ["Code files\u00b6"], "text": "Code files \u00b6 This file sets up the FastAPI application using get_fast_api_app() from ADK: main.py import os import uvicorn from fastapi import FastAPI from google.adk.cli.fast_api import get_fast_api_app # Get the directory where main.py is located AGENT_DIR = os . path . dirname ( os . path . abspath ( __file__ )) # Example session service URI (e.g., SQLite) SESSION_SERVICE_URI = \"sqlite:///./sessions.db\" # Example allowed origins for CORS ALLOWED_ORIGINS = [ \"http://localhost\" , \"http://localhost:8080\" , \"*\" ] # Set web=True if you intend to serve a web interface, False otherwise SERVE_WEB_INTERFACE = True # Call the function to get the FastAPI app instance # Ensure the agent directory name ('capital_agent') matches your agent folder app : FastAPI = get_fast_api_app ( agents_dir = AGENT_DIR , session_service_uri = SESSION_SERVICE_URI , allow_origins = ALLOWED_ORIGINS , web = SERVE_WEB_INTERFACE , ) # You can add more FastAPI routes or configurations below if needed # Example: # @app.get(\"/hello\") # async def read_root(): #     return {\"Hello\": \"World\"} if __name__ == \"__main__\" : # Use the PORT environment variable provided by Cloud Run, defaulting to 8080 uvicorn . run ( app , host = \"0.0.0.0\" , port = int ( os . environ . get ( \"PORT\" , 8080 ))) Note: We specify agent_dir to the directory main.py is in and use os.environ.get(\"PORT\", 8080) for Cloud Run compatibility. List the necessary Python packages: requirements.txt google-adk # Add any other dependencies your agent needs Define the container image: Dockerfile FROM python:3.13-slim WORKDIR /app COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt RUN adduser --disabled-password --gecos \"\" myuser && \\ chown -R myuser:myuser /app COPY . . USER myuser ENV PATH = \"/home/myuser/.local/bin: $PATH \" CMD [ \"sh\" , \"-c\" , \"uvicorn main:app --host 0.0.0.0 --port $PORT\" ] ", "code_blocks": [{"language": "text", "code": "import os\n\nimport uvicorn\nfrom fastapi import FastAPI\nfrom google.adk.cli.fast_api import get_fast_api_app\n\n# Get the directory where main.py is located\nAGENT_DIR = os.path.dirname(os.path.abspath(__file__))\n# Example session service URI (e.g., SQLite)\nSESSION_SERVICE_URI = \"sqlite:///./sessions.db\"\n# Example allowed origins for CORS\nALLOWED_ORIGINS = [\"http://localhost\", \"http://localhost:8080\", \"*\"]\n# Set web=True if you intend to serve a web interface, False otherwise\nSERVE_WEB_INTERFACE = True\n\n# Call the function to get the FastAPI app instance\n# Ensure the agent directory name ('capital_agent') matches your agent folder\napp: FastAPI = get_fast_api_app(\n    agents_dir=AGENT_DIR,\n    session_service_uri=SESSION_SERVICE_URI,\n    allow_origins=ALLOWED_ORIGINS,\n    web=SERVE_WEB_INTERFACE,\n)\n\n# You can add more FastAPI routes or configurations below if needed\n# Example:\n# @app.get(\"/hello\")\n# async def read_root():\n#     return {\"Hello\": \"World\"}\n\nif __name__ == \"__main__\":\n    # Use the PORT environment variable provided by Cloud Run, defaulting to 8080\n    uvicorn.run(app, host=\"0.0.0.0\", port=int(os.environ.get(\"PORT\", 8080)))"}, {"language": "text", "code": "google-adk\n# Add any other dependencies your agent needs"}, {"language": "text", "code": "FROM python:3.13-slim\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nRUN adduser --disabled-password --gecos \"\" myuser && \\\n    chown -R myuser:myuser /app\n\nCOPY . .\n\nUSER myuser\n\nENV PATH=\"/home/myuser/.local/bin:$PATH\"\n\nCMD [\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $PORT\"]"}]}, {"heading_path": ["Defining Multiple Agents\u00b6"], "text": "Defining Multiple Agents \u00b6 You can define and deploy multiple agents within the same Cloud Run instance by creating separate folders in the root of your-project-directory/ . Each folder represents one agent and must define a root_agent in its configuration. Example structure: your-project-directory/ \u251c\u2500\u2500 capital_agent/ \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 agent.py       # contains `root_agent` definition \u251c\u2500\u2500 population_agent/ \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 agent.py       # contains `root_agent` definition \u2514\u2500\u2500 ... ", "code_blocks": [{"language": "text", "code": "your-project-directory/\n\u251c\u2500\u2500 capital_agent/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 agent.py       # contains `root_agent` definition\n\u251c\u2500\u2500 population_agent/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 agent.py       # contains `root_agent` definition\n\u2514\u2500\u2500 ..."}]}, {"heading_path": ["Deploy using gcloud\u00b6"], "text": "Deploy using gcloud \u00b6 Navigate to your-project-directory in your terminal. gcloud run deploy capital-agent-service \\ --source . \\ --region $GOOGLE_CLOUD_LOCATION \\ --project $GOOGLE_CLOUD_PROJECT \\ --allow-unauthenticated \\ --set-env-vars = \"GOOGLE_CLOUD_PROJECT= $GOOGLE_CLOUD_PROJECT ,GOOGLE_CLOUD_LOCATION= $GOOGLE_CLOUD_LOCATION ,GOOGLE_GENAI_USE_VERTEXAI= $GOOGLE_GENAI_USE_VERTEXAI \" # Add any other necessary environment variables your agent might need capital-agent-service : The name you want to give your Cloud Run service. --source . : Tells gcloud to build the container image from the Dockerfile in the current directory. --region : Specifies the deployment region. --project : Specifies the GCP project. --allow-unauthenticated : Allows public access to the service. Remove this flag for private services. --set-env-vars : Passes necessary environment variables to the running container. Ensure you include all variables required by ADK and your agent (like API keys if not using Application Default Credentials). gcloud will build the Docker image, push it to Google Artifact Registry, and deploy it to Cloud Run. Upon completion, it will output the URL of your deployed service. For a full list of deployment options, see the gcloud run deploy reference documentation . ", "code_blocks": [{"language": "text", "code": "gcloud run deploy capital-agent-service \\\n--source . \\\n--region $GOOGLE_CLOUD_LOCATION \\\n--project $GOOGLE_CLOUD_PROJECT \\\n--allow-unauthenticated \\\n--set-env-vars=\"GOOGLE_CLOUD_PROJECT=$GOOGLE_CLOUD_PROJECT,GOOGLE_CLOUD_LOCATION=$GOOGLE_CLOUD_LOCATION,GOOGLE_GENAI_USE_VERTEXAI=$GOOGLE_GENAI_USE_VERTEXAI\"\n# Add any other necessary environment variables your agent might need"}]}, {"heading_path": ["adk CLI\u00b6"], "text": "adk CLI \u00b6 The adkgo command is located in the google/adk-go repository under cmd/adkgo. Before using it, you need to build it from the root of the adk-go repository: go build ./cmd/adkgo The adkgo deploy cloudrun command automates the deployment of your application. You do not need to provide your own Dockerfile. ", "code_blocks": []}, {"heading_path": ["Agent Code Structure\u00b6"], "text": "Agent Code Structure \u00b6 When using the adkgo tool, your main.go file must use the launcher framework. This is because the tool compiles your code and then runs the resulting executable with specific command-line arguments (like web, api, a2a) to start the required services. The launcher is designed to parse these arguments correctly. Your main.go should look like this: main.go // Copyright 2025 Google LLC // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // //     http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package main import ( \"context\" \"fmt\" \"log\" \"os\" \"strings\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/cmd/launcher/adk\" \"google.golang.org/adk/cmd/launcher/full\" \"google.golang.org/adk/server/restapi/services\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) type getCapitalCityArgs struct { Country string `json:\"country\" jsonschema:\"The country for which to find the capital city.\"` } type getCapitalCityResult struct { Result string `json:\"result,omitempty\"` ErrorMessage string `json:\"error_message,omitempty\"` } func getCapitalCity ( ctx tool . Context , args getCapitalCityArgs ) getCapitalCityResult { capitals := map [ string ] string { \"united states\" : \"Washington, D.C.\" , \"canada\" : \"Ottawa\" , \"france\" : \"Paris\" , \"japan\" : \"Tokyo\" , } capital , ok := capitals [ strings . ToLower ( args . Country )] if ! ok { result := fmt . Sprintf ( \"Sorry, I couldn't find the capital for %s.\" , args . Country ) return getCapitalCityResult { ErrorMessage : result } } return getCapitalCityResult { Result : capital } } func main () { ctx := context . Background () model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig { APIKey : os . Getenv ( \"GOOGLE_API_KEY\" ), }) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } capitalTool , err := functiontool . New ( functiontool . Config { Name : \"get_capital_city\" , Description : \"Retrieves the capital city for a given country.\" , }, getCapitalCity , ) if err != nil { log . Fatalf ( \"Failed to create function tool: %v\" , err ) } agent , err := llmagent . New ( llmagent . Config { Name : \"capital_agent\" , Model : model , Description : \"Agent to find the capital city of a country.\" , Instruction : \"I can answer your questions about the capital city of a country.\" , Tools : [] tool . Tool { capitalTool }, }) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } config := & adk . Config { AgentLoader : services . NewSingleAgentLoader ( agent ), } l := full . NewLauncher () err = l . Execute ( ctx , config , os . Args [ 1 :]) if err != nil { log . Fatalf ( \"run failed: %v\\n\\n%s\" , err , l . CommandLineSyntax ()) } } ", "code_blocks": [{"language": "text", "code": "// Copyright 2025 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"os\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/cmd/launcher/adk\"\n    \"google.golang.org/adk/cmd/launcher/full\"\n    \"google.golang.org/adk/server/restapi/services\"\n\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\ntype getCapitalCityArgs struct {\n    Country string `json:\"country\" jsonschema:\"The country for which to find the capital city.\"`\n}\n\ntype getCapitalCityResult struct {\n    Result       string `json:\"result,omitempty\"`\n    ErrorMessage string `json:\"error_message,omitempty\"`\n}\n\nfunc getCapitalCity(ctx tool.Context, args getCapitalCityArgs) getCapitalCityResult {\n    capitals := map[string]string{\n        \"united states\": \"Washington, D.C.\",\n        \"canada\":        \"Ottawa\",\n        \"france\":        \"Paris\",\n        \"japan\":         \"Tokyo\",\n    }\n    capital, ok := capitals[strings.ToLower(args.Country)]\n    if !ok {\n        result := fmt.Sprintf(\"Sorry, I couldn't find the capital for %s.\", args.Country)\n        return getCapitalCityResult{ErrorMessage: result}\n    }\n\n    return getCapitalCityResult{Result: capital}\n}\n\nfunc main() {\n    ctx := context.Background()\n\n    model, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{\n        APIKey: os.Getenv(\"GOOGLE_API_KEY\"),\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create model: %v\", err)\n    }\n\n    capitalTool, err := functiontool.New(\n        functiontool.Config{\n            Name:        \"get_capital_city\",\n            Description: \"Retrieves the capital city for a given country.\",\n        },\n        getCapitalCity,\n    )\n    if err != nil {\n        log.Fatalf(\"Failed to create function tool: %v\", err)\n    }\n\n    agent, err := llmagent.New(llmagent.Config{\n        Name:        \"capital_agent\",\n        Model:       model,\n        Description: \"Agent to find the capital city of a country.\",\n        Instruction: \"I can answer your questions about the capital city of a country.\",\n        Tools:       []tool.Tool{capitalTool},\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create agent: %v\", err)\n    }\n\n    config := &adk.Config{\n        AgentLoader: services.NewSingleAgentLoader(agent),\n    }\n\n    l := full.NewLauncher()\n    err = l.Execute(ctx, config, os.Args[1:])\n    if err != nil {\n        log.Fatalf(\"run failed: %v\\n\\n%s\", err, l.CommandLineSyntax())\n    }\n}"}]}, {"heading_path": ["How it Works\u00b6"], "text": "How it Works \u00b6 The adkgo tool compiles your main.go into a statically linked binary for Linux. It generates a Dockerfile that copies this binary into a minimal container. It uses gcloud to build and deploy this container to Cloud Run. After deployment, it starts a local proxy that securely connects to your new\n    service. Ensure you have authenticated with Google Cloud ( gcloud auth login and gcloud config set project <your-project-id> ). ", "code_blocks": []}, {"heading_path": ["Setup environment variables\u00b6"], "text": "Setup environment variables \u00b6 Optional but recommended: Setting environment variables can make the deployment commands cleaner. # Set your Google Cloud Project ID export GOOGLE_CLOUD_PROJECT = \"your-gcp-project-id\" # Set your desired Google Cloud Location export GOOGLE_CLOUD_LOCATION = \"us-central1\" # Set the path to your agent's main Go file export AGENT_PATH = \"./examples/go/cloud-run/main.go\" # Set a name for your Cloud Run service export SERVICE_NAME = \"capital-agent-service\" ", "code_blocks": [{"language": "text", "code": "# Set your Google Cloud Project ID\nexport GOOGLE_CLOUD_PROJECT=\"your-gcp-project-id\"\n\n# Set your desired Google Cloud Location\nexport GOOGLE_CLOUD_LOCATION=\"us-central1\"\n\n# Set the path to your agent's main Go file\nexport AGENT_PATH=\"./examples/go/cloud-run/main.go\"\n\n# Set a name for your Cloud Run service\nexport SERVICE_NAME=\"capital-agent-service\""}]}, {"heading_path": ["Command usage\u00b6"], "text": "Command usage \u00b6 ./adkgo deploy cloudrun \\ -p $GOOGLE_CLOUD_PROJECT \\ -r $GOOGLE_CLOUD_LOCATION \\ -s $SERVICE_NAME \\ --proxy_port = 8081 \\ --server_port = 8080 \\ -e $AGENT_PATH \\ --a2a --api --webui ", "code_blocks": [{"language": "text", "code": "./adkgo deploy cloudrun \\\n    -p $GOOGLE_CLOUD_PROJECT \\\n    -r $GOOGLE_CLOUD_LOCATION \\\n    -s $SERVICE_NAME \\\n    --proxy_port=8081 \\\n    --server_port=8080 \\\n    -e $AGENT_PATH \\\n    --a2a --api --webui"}]}, {"heading_path": ["Required\u00b6"], "text": "Required \u00b6 -p, --project_name : Your Google Cloud project ID (e.g., $GOOGLE_CLOUD_PROJECT). -r, --region : The Google Cloud location for deployment (e.g., $GOOGLE_CLOUD_LOCATION, us-central1). -s, --service_name : The name for the Cloud Run service (e.g., $SERVICE_NAME). -e, --entry_point_path : Path to the main Go file containing your agent's source code (e.g., $AGENT_PATH). ", "code_blocks": []}, {"heading_path": ["Optional\u00b6"], "text": "Optional \u00b6 --proxy_port : The local port for the authenticating proxy to listen on. Defaults to 8081. --server_port : The port number the server will listen on within the Cloud Run container. Defaults to 8080. --a2a : If included, enables Agent2Agent communication. Enabled by default. --a2a_agent_url : A2A agent card URL as advertised in the public agent card. This flag is only valid when used with the --a2a flag. --api : If included, deploys the ADK API server. Enabled by default. --webui : If included, deploys the ADK dev UI alongside the agent API server. Enabled by default. --temp_dir : Temp directory for build artifacts. Defaults to os.TempDir(). --help : Show the help message and exit. ", "code_blocks": []}, {"heading_path": ["Authenticated access\u00b6"], "text": "Authenticated access \u00b6 The service is deployed with --no-allow-unauthenticated by default. Upon successful execution, the command deploys your agent to Cloud Run and provide a local URL to access the service through the proxy. ", "code_blocks": []}, {"heading_path": ["gcloud CLI for Java\u00b6"], "text": "gcloud CLI for Java \u00b6 You can deploy Java Agents using the standard gcloud run deploy command and a Dockerfile . This is the current recommended way to deploy Java Agents to Google Cloud Run. Ensure you are authenticated with Google Cloud.\nSpecifically, run the commands gcloud auth login and gcloud config set project <your-project-id> from your terminal. ", "code_blocks": []}, {"heading_path": ["Project Structure\u00b6"], "text": "Project Structure \u00b6 Organize your project files as follows: your-project-directory/ \u251c\u2500\u2500 src/ \u2502   \u2514\u2500\u2500 main/ \u2502       \u2514\u2500\u2500 java/ \u2502             \u2514\u2500\u2500 agents/ \u2502                 \u251c\u2500\u2500 capitalagent/ \u2502                     \u2514\u2500\u2500 CapitalAgent.java    # Your agent code \u251c\u2500\u2500 pom.xml                                    # Java adk and adk-dev dependencies \u2514\u2500\u2500 Dockerfile                                 # Container build instructions Create the pom.xml and Dockerfile in the root of your project directory. Your Agent code file ( CapitalAgent.java ) inside a directory as shown above. ", "code_blocks": [{"language": "text", "code": "your-project-directory/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 main/\n\u2502       \u2514\u2500\u2500 java/\n\u2502             \u2514\u2500\u2500 agents/\n\u2502                 \u251c\u2500\u2500 capitalagent/\n\u2502                     \u2514\u2500\u2500 CapitalAgent.java    # Your agent code\n\u251c\u2500\u2500 pom.xml                                    # Java adk and adk-dev dependencies\n\u2514\u2500\u2500 Dockerfile                                 # Container build instructions"}]}, {"heading_path": ["Code files\u00b6"], "text": "Code files \u00b6 This is our Agent definition. This is the same code as present in LLM agent with two caveats: The Agent is now initialized as a global public static final variable . The definition of the agent can be exposed in a static method or inlined during declaration. See the code for the CapitalAgent example in the examples repository. Add the following dependencies and plugin to the pom.xml file. pom.xml <dependencies> <dependency> <groupId> com.google.adk </groupId> <artifactId> google-adk </artifactId> <version> 0.1.0 </version> </dependency> <dependency> <groupId> com.google.adk </groupId> <artifactId> google-adk-dev </artifactId> <version> 0.1.0 </version> </dependency> </dependencies> <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> exec-maven-plugin </artifactId> <version> 3.2.0 </version> <configuration> <mainClass> com.google.adk.web.AdkWebServer </mainClass> <classpathScope> compile </classpathScope> </configuration> </plugin> Define the container image: Dockerfile # Use an official Maven image with a JDK. Choose a version appropriate for your project. FROM maven:3.8-openjdk-17 AS builder WORKDIR /app COPY pom.xml . RUN mvn dependency:go-offline -B COPY src ./src # Expose the port your application will listen on. # Cloud Run will set the PORT environment variable, which your app should use. EXPOSE 8080 # The command to run your application. # Use a shell so ${PORT} expands and quote exec.args so agent source-dir is passed correctly. ENTRYPOINT [ \"sh\" , \"-c\" , \"mvn compile exec:java \\ -Dexec.mainClass=com.google.adk.web.AdkWebServer \\ -Dexec.classpathScope=compile \\ -Dexec.args='--server.port= ${ PORT :- 8080 } --adk.agents.source-dir=target'\" ] ", "code_blocks": [{"language": "text", "code": "<dependencies>\n  <dependency>\n     <groupId>com.google.adk</groupId>\n     <artifactId>google-adk</artifactId>\n     <version>0.1.0</version>\n  </dependency>\n  <dependency>\n     <groupId>com.google.adk</groupId>\n     <artifactId>google-adk-dev</artifactId>\n     <version>0.1.0</version>\n  </dependency>\n</dependencies>\n\n<plugin>\n  <groupId>org.codehaus.mojo</groupId>\n  <artifactId>exec-maven-plugin</artifactId>\n  <version>3.2.0</version>\n  <configuration>\n    <mainClass>com.google.adk.web.AdkWebServer</mainClass>\n    <classpathScope>compile</classpathScope>\n  </configuration>\n</plugin>"}, {"language": "text", "code": "# Use an official Maven image with a JDK. Choose a version appropriate for your project.\nFROM maven:3.8-openjdk-17 AS builder\n\nWORKDIR /app\n\nCOPY pom.xml .\nRUN mvn dependency:go-offline -B\n\nCOPY src ./src\n\n# Expose the port your application will listen on.\n# Cloud Run will set the PORT environment variable, which your app should use.\nEXPOSE 8080\n\n# The command to run your application.\n# Use a shell so ${PORT} expands and quote exec.args so agent source-dir is passed correctly.\nENTRYPOINT [\"sh\", \"-c\", \"mvn compile exec:java \\\n    -Dexec.mainClass=com.google.adk.web.AdkWebServer \\\n    -Dexec.classpathScope=compile \\\n    -Dexec.args='--server.port=${PORT:-8080} --adk.agents.source-dir=target'\"]"}]}, {"heading_path": ["Deploy using gcloud\u00b6"], "text": "Deploy using gcloud \u00b6 Navigate to your-project-directory in your terminal. gcloud run deploy capital-agent-service \\ --source . \\ --region $GOOGLE_CLOUD_LOCATION \\ --project $GOOGLE_CLOUD_PROJECT \\ --allow-unauthenticated \\ --set-env-vars = \"GOOGLE_CLOUD_PROJECT= $GOOGLE_CLOUD_PROJECT ,GOOGLE_CLOUD_LOCATION= $GOOGLE_CLOUD_LOCATION ,GOOGLE_GENAI_USE_VERTEXAI= $GOOGLE_GENAI_USE_VERTEXAI \" # Add any other necessary environment variables your agent might need capital-agent-service : The name you want to give your Cloud Run service. --source . : Tells gcloud to build the container image from the Dockerfile in the current directory. --region : Specifies the deployment region. --project : Specifies the GCP project. --allow-unauthenticated : Allows public access to the service. Remove this flag for private services. --set-env-vars : Passes necessary environment variables to the running container. Ensure you include all variables required by ADK and your agent (like API keys if not using Application Default Credentials). gcloud will build the Docker image, push it to Google Artifact Registry, and deploy it to Cloud Run. Upon completion, it will output the URL of your deployed service. For a full list of deployment options, see the gcloud run deploy reference documentation . ", "code_blocks": [{"language": "text", "code": "gcloud run deploy capital-agent-service \\\n--source . \\\n--region $GOOGLE_CLOUD_LOCATION \\\n--project $GOOGLE_CLOUD_PROJECT \\\n--allow-unauthenticated \\\n--set-env-vars=\"GOOGLE_CLOUD_PROJECT=$GOOGLE_CLOUD_PROJECT,GOOGLE_CLOUD_LOCATION=$GOOGLE_CLOUD_LOCATION,GOOGLE_GENAI_USE_VERTEXAI=$GOOGLE_GENAI_USE_VERTEXAI\"\n# Add any other necessary environment variables your agent might need"}]}, {"heading_path": ["Testing your agent\u00b6"], "text": "Testing your agent \u00b6 Once your agent is deployed to Cloud Run, you can interact with it via the deployed UI (if enabled) or directly with its API endpoints using tools like curl . You'll need the service URL provided after deployment. UI Testing API Testing (curl) ", "code_blocks": []}, {"heading_path": ["UI Testing\u00b6"], "text": "UI Testing \u00b6 If you deployed your agent with the UI enabled: adk CLI: You included the --webui flag during deployment. gcloud CLI: You set SERVE_WEB_INTERFACE = True in your main.py . You can test your agent by simply navigating to the Cloud Run service URL provided after deployment in your web browser. # Example URL format # https://your-service-name-abc123xyz.a.run.app The ADK dev UI allows you to interact with your agent, manage sessions, and view execution details directly in the browser. To verify your agent is working as intended, you can: Select your agent from the dropdown menu. Type a message and verify that you receive an expected response from your agent. If you experience any unexpected behavior, check the Cloud Run console logs. ", "code_blocks": [{"language": "text", "code": "# Example URL format\n# https://your-service-name-abc123xyz.a.run.app"}]}, {"heading_path": ["API Testing (curl)\u00b6"], "text": "API Testing (curl) \u00b6 You can interact with the agent's API endpoints using tools like curl . This is useful for programmatic interaction or if you deployed without the UI. You'll need the service URL provided after deployment and potentially an identity token for authentication if your service isn't set to allow unauthenticated access. ", "code_blocks": []}, {"heading_path": ["Set the application URL\u00b6"], "text": "Set the application URL \u00b6 Replace the example URL with the actual URL of your deployed Cloud Run service. export APP_URL = \"YOUR_CLOUD_RUN_SERVICE_URL\" # Example: export APP_URL=\"https://adk-default-service-name-abc123xyz.a.run.app\" ", "code_blocks": [{"language": "text", "code": "export APP_URL=\"YOUR_CLOUD_RUN_SERVICE_URL\"\n# Example: export APP_URL=\"https://adk-default-service-name-abc123xyz.a.run.app\""}]}, {"heading_path": ["Get an identity token (if needed)\u00b6"], "text": "Get an identity token (if needed) \u00b6 If your service requires authentication (i.e., you didn't use --allow-unauthenticated with gcloud or answered 'N' to the prompt with adk ), obtain an identity token. export TOKEN = $( gcloud auth print-identity-token ) If your service allows unauthenticated access, you can omit the -H \"Authorization: Bearer $TOKEN\" header from the curl commands below. ", "code_blocks": [{"language": "text", "code": "export TOKEN=$(gcloud auth print-identity-token)"}]}, {"heading_path": ["List available apps\u00b6"], "text": "List available apps \u00b6 Verify the deployed application name. curl -X GET -H \"Authorization: Bearer $TOKEN \" $APP_URL /list-apps (Adjust the app_name in the following commands based on this output if needed. The default is often the agent directory name, e.g., capital_agent ) . ", "code_blocks": [{"language": "text", "code": "curl -X GET -H \"Authorization: Bearer $TOKEN\" $APP_URL/list-apps"}]}, {"heading_path": ["Create or Update a Session\u00b6"], "text": "Create or Update a Session \u00b6 Initialize or update the state for a specific user and session. Replace capital_agent with your actual app name if different. The values user_123 and session_abc are example identifiers; you can replace them with your desired user and session IDs. curl -X POST -H \"Authorization: Bearer $TOKEN \" \\ $APP_URL /apps/capital_agent/users/user_123/sessions/session_abc \\ -H \"Content-Type: application/json\" \\ -d '{\"preferred_language\": \"English\", \"visit_count\": 5}' ", "code_blocks": [{"language": "text", "code": "curl -X POST -H \"Authorization: Bearer $TOKEN\" \\\n    $APP_URL/apps/capital_agent/users/user_123/sessions/session_abc \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"preferred_language\": \"English\", \"visit_count\": 5}'"}]}, {"heading_path": ["Run the Agent\u00b6"], "text": "Run the Agent \u00b6 Send a prompt to your agent. Replace capital_agent with your app name and adjust the user/session IDs and prompt as needed. curl -X POST -H \"Authorization: Bearer $TOKEN \" \\ $APP_URL /run_sse \\ -H \"Content-Type: application/json\" \\ -d '{ \"app_name\": \"capital_agent\", \"user_id\": \"user_123\", \"session_id\": \"session_abc\", \"new_message\": { \"role\": \"user\", \"parts\": [{ \"text\": \"What is the capital of Canada?\" }] }, \"streaming\": false }' Set \"streaming\": true if you want to receive Server-Sent Events (SSE). The response will contain the agent's execution events, including the final answer. Back to top ", "code_blocks": [{"language": "text", "code": "curl -X POST -H \"Authorization: Bearer $TOKEN\" \\\n    $APP_URL/run_sse \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\n    \"app_name\": \"capital_agent\",\n    \"user_id\": \"user_123\",\n    \"session_id\": \"session_abc\",\n    \"new_message\": {\n        \"role\": \"user\",\n        \"parts\": [{\n        \"text\": \"What is the capital of Canada?\"\n        }]\n    },\n    \"streaming\": false\n    }'"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:25.723675", "source_type": "adk-docs"}
{"doc_id": "b2efdf5c822f1eaf7a407bf4fe31f2625b7772ce6eb711ccd2140c532098d013", "url": "https://google.github.io/adk-docs/deploy/gke", "title": "GKE - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Deploy to Google Kubernetes Engine (GKE)\u00b6"], "text": "Deploy to Google Kubernetes Engine (GKE) \u00b6 Supported in ADK Python GKE is the Google Cloud managed Kubernetes service. It allows you to deploy and manage containerized applications using Kubernetes. To deploy your agent you will need to have a Kubernetes cluster running on GKE. You can create a cluster using the Google Cloud Console or the gcloud command line tool. In this example we will deploy a simple agent to GKE. The agent will be a FastAPI application that uses Gemini 2.0 Flash as the LLM. We can use Vertex AI or AI Studio as the LLM provider using the Environment variable GOOGLE_GENAI_USE_VERTEXAI . ", "code_blocks": []}, {"heading_path": ["Environment variables\u00b6"], "text": "Environment variables \u00b6 Set your environment variables as described in the Setup and Installation guide. You also need to install the kubectl command line tool. You can find instructions to do so in the Google Kubernetes Engine Documentation . export GOOGLE_CLOUD_PROJECT = your-project-id # Your GCP project ID export GOOGLE_CLOUD_LOCATION = us-central1 # Or your preferred location export GOOGLE_GENAI_USE_VERTEXAI = true # Set to true if using Vertex AI export GOOGLE_CLOUD_PROJECT_NUMBER = $( gcloud projects describe --format json $GOOGLE_CLOUD_PROJECT | jq -r \".projectNumber\" ) If you don't have jq installed, you can use the following command to get the project number: gcloud projects describe $GOOGLE_CLOUD_PROJECT And copy the project number from the output. export GOOGLE_CLOUD_PROJECT_NUMBER = YOUR_PROJECT_NUMBER ", "code_blocks": [{"language": "text", "code": "export GOOGLE_CLOUD_PROJECT=your-project-id # Your GCP project ID\nexport GOOGLE_CLOUD_LOCATION=us-central1 # Or your preferred location\nexport GOOGLE_GENAI_USE_VERTEXAI=true # Set to true if using Vertex AI\nexport GOOGLE_CLOUD_PROJECT_NUMBER=$(gcloud projects describe --format json $GOOGLE_CLOUD_PROJECT | jq -r \".projectNumber\")"}, {"language": "text", "code": "gcloud projects describe $GOOGLE_CLOUD_PROJECT"}, {"language": "text", "code": "export GOOGLE_CLOUD_PROJECT_NUMBER=YOUR_PROJECT_NUMBER"}]}, {"heading_path": ["Enable APIs and Permissions\u00b6"], "text": "Enable APIs and Permissions \u00b6 Ensure you have authenticated with Google Cloud ( gcloud auth login and gcloud config set project <your-project-id> ). Enable the necessary APIs for your project. You can do this using the gcloud command line tool. gcloud services enable \\ container.googleapis.com \\ artifactregistry.googleapis.com \\ cloudbuild.googleapis.com \\ aiplatform.googleapis.com Grant necessary roles to the default compute engine service account required by the gcloud builds submit command. ROLES_TO_ASSIGN =( \"roles/artifactregistry.writer\" \"roles/storage.objectViewer\" \"roles/logging.viewer\" \"roles/logging.logWriter\" ) for ROLE in \" ${ ROLES_TO_ASSIGN [@] } \" ; do gcloud projects add-iam-policy-binding \" ${ GOOGLE_CLOUD_PROJECT } \" \\ --member = \"serviceAccount: ${ GOOGLE_CLOUD_PROJECT_NUMBER } -compute@developer.gserviceaccount.com\" \\ --role = \" ${ ROLE } \" done ", "code_blocks": [{"language": "text", "code": "gcloud services enable \\\n    container.googleapis.com \\\n    artifactregistry.googleapis.com \\\n    cloudbuild.googleapis.com \\\n    aiplatform.googleapis.com"}, {"language": "text", "code": "ROLES_TO_ASSIGN=(\n    \"roles/artifactregistry.writer\"\n    \"roles/storage.objectViewer\"\n    \"roles/logging.viewer\"\n    \"roles/logging.logWriter\"\n)\n\nfor ROLE in \"${ROLES_TO_ASSIGN[@]}\"; do\n    gcloud projects add-iam-policy-binding \"${GOOGLE_CLOUD_PROJECT}\" \\\n        --member=\"serviceAccount:${GOOGLE_CLOUD_PROJECT_NUMBER}-compute@developer.gserviceaccount.com\" \\\n        --role=\"${ROLE}\"\ndone"}]}, {"heading_path": ["Deployment payload\u00b6"], "text": "Deployment payload \u00b6 When you deploy your ADK agent workflow to the Google Cloud GKE,\nthe following content is uploaded to the service: Your ADK agent code Any dependencies declared in your ADK agent code ADK API server code version used by your agent The default deployment does not include the ADK web user interface libraries,\nunless you specify it as deployment setting, such as the --with_ui option for adk deploy gke command. ", "code_blocks": []}, {"heading_path": ["Deployment options\u00b6"], "text": "Deployment options \u00b6 You can deploy your agent to GKE either manually using Kubernetes manifests or automatically using the adk deploy gke command . Choose the approach that best suits your workflow. ", "code_blocks": []}, {"heading_path": ["Option 1: Manual Deployment using gcloud and kubectl\u00b6"], "text": "Option 1: Manual Deployment using gcloud and kubectl \u00b6 ", "code_blocks": []}, {"heading_path": ["Create a GKE cluster\u00b6"], "text": "Create a GKE cluster \u00b6 You can create a GKE cluster using the gcloud command line tool. This example creates an Autopilot cluster named adk-cluster in the us-central1 region. If creating a GKE Standard cluster, make sure Workload Identity is enabled. Workload Identity is enabled by default in an AutoPilot cluster. gcloud container clusters create-auto adk-cluster \\ --location = $GOOGLE_CLOUD_LOCATION \\ --project = $GOOGLE_CLOUD_PROJECT After creating the cluster, you need to connect to it using kubectl . This command configures kubectl to use the credentials for your new cluster. gcloud container clusters get-credentials adk-cluster \\ --location = $GOOGLE_CLOUD_LOCATION \\ --project = $GOOGLE_CLOUD_PROJECT ", "code_blocks": [{"language": "text", "code": "gcloud container clusters create-auto adk-cluster \\\n    --location=$GOOGLE_CLOUD_LOCATION \\\n    --project=$GOOGLE_CLOUD_PROJECT"}, {"language": "text", "code": "gcloud container clusters get-credentials adk-cluster \\\n    --location=$GOOGLE_CLOUD_LOCATION \\\n    --project=$GOOGLE_CLOUD_PROJECT"}]}, {"heading_path": ["Create Your Agent\u00b6"], "text": "Create Your Agent \u00b6 We will reference the capital_agent example defined on the LLM agents page. To proceed, organize your project files as follows: your-project-directory/ \u251c\u2500\u2500 capital_agent/ \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 agent.py       # Your agent code (see \"Capital Agent example\" below) \u251c\u2500\u2500 main.py            # FastAPI application entry point \u251c\u2500\u2500 requirements.txt   # Python dependencies \u2514\u2500\u2500 Dockerfile         # Container build instructions ", "code_blocks": [{"language": "text", "code": "your-project-directory/\n\u251c\u2500\u2500 capital_agent/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 agent.py       # Your agent code (see \"Capital Agent example\" below)\n\u251c\u2500\u2500 main.py            # FastAPI application entry point\n\u251c\u2500\u2500 requirements.txt   # Python dependencies\n\u2514\u2500\u2500 Dockerfile         # Container build instructions"}]}, {"heading_path": ["Code files\u00b6"], "text": "Code files \u00b6 Create the following files ( main.py , requirements.txt , Dockerfile , capital_agent/agent.py , capital_agent/__init__.py ) in the root of your-project-directory/ . This is the Capital Agent example inside the capital_agent directory capital_agent/agent.py from google.adk.agents import LlmAgent # Define a tool function def get_capital_city ( country : str ) -> str : \"\"\"Retrieves the capital city for a given country.\"\"\" # Replace with actual logic (e.g., API call, database lookup) capitals = { \"france\" : \"Paris\" , \"japan\" : \"Tokyo\" , \"canada\" : \"Ottawa\" } return capitals . get ( country . lower (), f \"Sorry, I don't know the capital of { country } .\" ) # Add the tool to the agent capital_agent = LlmAgent ( model = \"gemini-2.0-flash\" , name = \"capital_agent\" , #name of your agent description = \"Answers user questions about the capital city of a given country.\" , instruction = \"\"\"You are an agent that provides the capital city of a country... (previous instruction text)\"\"\" , tools = [ get_capital_city ] # Provide the function directly ) # ADK will discover the root_agent instance root_agent = capital_agent Mark your directory as a python package capital_agent/__init__.py from . import agent This file sets up the FastAPI application using get_fast_api_app() from ADK: main.py import os import uvicorn from fastapi import FastAPI from google.adk.cli.fast_api import get_fast_api_app # Get the directory where main.py is located AGENT_DIR = os . path . dirname ( os . path . abspath ( __file__ )) # Example session service URI (e.g., SQLite) SESSION_SERVICE_URI = \"sqlite:///./sessions.db\" # Example allowed origins for CORS ALLOWED_ORIGINS = [ \"http://localhost\" , \"http://localhost:8080\" , \"*\" ] # Set web=True if you intend to serve a web interface, False otherwise SERVE_WEB_INTERFACE = True # Call the function to get the FastAPI app instance # Ensure the agent directory name ('capital_agent') matches your agent folder app : FastAPI = get_fast_api_app ( agents_dir = AGENT_DIR , session_service_uri = SESSION_SERVICE_URI , allow_origins = ALLOWED_ORIGINS , web = SERVE_WEB_INTERFACE , ) # You can add more FastAPI routes or configurations below if needed # Example: # @app.get(\"/hello\") # async def read_root(): #     return {\"Hello\": \"World\"} if __name__ == \"__main__\" : # Use the PORT environment variable provided by Cloud Run, defaulting to 8080 uvicorn . run ( app , host = \"0.0.0.0\" , port = int ( os . environ . get ( \"PORT\" , 8080 ))) Note: We specify agent_dir to the directory main.py is in and use os.environ.get(\"PORT\", 8080) for Cloud Run compatibility. List the necessary Python packages: requirements.txt google-adk # Add any other dependencies your agent needs Define the container image: Dockerfile FROM python:3.13-slim WORKDIR /app COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt RUN adduser --disabled-password --gecos \"\" myuser && \\ chown -R myuser:myuser /app COPY . . USER myuser ENV PATH = \"/home/myuser/.local/bin: $PATH \" CMD [ \"sh\" , \"-c\" , \"uvicorn main:app --host 0.0.0.0 --port $PORT\" ] ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import LlmAgent \n\n# Define a tool function\ndef get_capital_city(country: str) -> str:\n  \"\"\"Retrieves the capital city for a given country.\"\"\"\n  # Replace with actual logic (e.g., API call, database lookup)\n  capitals = {\"france\": \"Paris\", \"japan\": \"Tokyo\", \"canada\": \"Ottawa\"}\n  return capitals.get(country.lower(), f\"Sorry, I don't know the capital of {country}.\")\n\n# Add the tool to the agent\ncapital_agent = LlmAgent(\n    model=\"gemini-2.0-flash\",\n    name=\"capital_agent\", #name of your agent\n    description=\"Answers user questions about the capital city of a given country.\",\n    instruction=\"\"\"You are an agent that provides the capital city of a country... (previous instruction text)\"\"\",\n    tools=[get_capital_city] # Provide the function directly\n)\n\n# ADK will discover the root_agent instance\nroot_agent = capital_agent"}, {"language": "text", "code": "from . import agent"}, {"language": "text", "code": "import os\n\nimport uvicorn\nfrom fastapi import FastAPI\nfrom google.adk.cli.fast_api import get_fast_api_app\n\n# Get the directory where main.py is located\nAGENT_DIR = os.path.dirname(os.path.abspath(__file__))\n# Example session service URI (e.g., SQLite)\nSESSION_SERVICE_URI = \"sqlite:///./sessions.db\"\n# Example allowed origins for CORS\nALLOWED_ORIGINS = [\"http://localhost\", \"http://localhost:8080\", \"*\"]\n# Set web=True if you intend to serve a web interface, False otherwise\nSERVE_WEB_INTERFACE = True\n\n# Call the function to get the FastAPI app instance\n# Ensure the agent directory name ('capital_agent') matches your agent folder\napp: FastAPI = get_fast_api_app(\n    agents_dir=AGENT_DIR,\n    session_service_uri=SESSION_SERVICE_URI,\n    allow_origins=ALLOWED_ORIGINS,\n    web=SERVE_WEB_INTERFACE,\n)\n\n# You can add more FastAPI routes or configurations below if needed\n# Example:\n# @app.get(\"/hello\")\n# async def read_root():\n#     return {\"Hello\": \"World\"}\n\nif __name__ == \"__main__\":\n    # Use the PORT environment variable provided by Cloud Run, defaulting to 8080\n    uvicorn.run(app, host=\"0.0.0.0\", port=int(os.environ.get(\"PORT\", 8080)))"}, {"language": "text", "code": "google-adk\n# Add any other dependencies your agent needs"}, {"language": "text", "code": "FROM python:3.13-slim\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nRUN adduser --disabled-password --gecos \"\" myuser && \\\n    chown -R myuser:myuser /app\n\nCOPY . .\n\nUSER myuser\n\nENV PATH=\"/home/myuser/.local/bin:$PATH\"\n\nCMD [\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $PORT\"]"}]}, {"heading_path": ["Build the container image\u00b6"], "text": "Build the container image \u00b6 You need to create a Google Artifact Registry repository to store your container images. You can do this using the gcloud command line tool. gcloud artifacts repositories create adk-repo \\ --repository-format = docker \\ --location = $GOOGLE_CLOUD_LOCATION \\ --description = \"ADK repository\" Build the container image using the gcloud command line tool. This example builds the image and tags it as adk-repo/adk-agent:latest . gcloud builds submit \\ --tag $GOOGLE_CLOUD_LOCATION -docker.pkg.dev/ $GOOGLE_CLOUD_PROJECT /adk-repo/adk-agent:latest \\ --project = $GOOGLE_CLOUD_PROJECT \\ . Verify the image is built and pushed to the Artifact Registry: gcloud artifacts docker images list \\ $GOOGLE_CLOUD_LOCATION -docker.pkg.dev/ $GOOGLE_CLOUD_PROJECT /adk-repo \\ --project = $GOOGLE_CLOUD_PROJECT ", "code_blocks": [{"language": "text", "code": "gcloud artifacts repositories create adk-repo \\\n    --repository-format=docker \\\n    --location=$GOOGLE_CLOUD_LOCATION \\\n    --description=\"ADK repository\""}, {"language": "text", "code": "gcloud builds submit \\\n    --tag $GOOGLE_CLOUD_LOCATION-docker.pkg.dev/$GOOGLE_CLOUD_PROJECT/adk-repo/adk-agent:latest \\\n    --project=$GOOGLE_CLOUD_PROJECT \\\n    ."}, {"language": "text", "code": "gcloud artifacts docker images list \\\n  $GOOGLE_CLOUD_LOCATION-docker.pkg.dev/$GOOGLE_CLOUD_PROJECT/adk-repo \\\n  --project=$GOOGLE_CLOUD_PROJECT"}]}, {"heading_path": ["Configure Kubernetes Service Account for Vertex AI\u00b6"], "text": "Configure Kubernetes Service Account for Vertex AI \u00b6 If your agent uses Vertex AI, you need to create a Kubernetes service account with the necessary permissions. This example creates a service account named adk-agent-sa and binds it to the Vertex AI User role. If you are using AI Studio and accessing the model with an API key you can skip this step. kubectl create serviceaccount adk-agent-sa gcloud projects add-iam-policy-binding projects/ ${ GOOGLE_CLOUD_PROJECT } \\ --role = roles/aiplatform.user \\ --member = principal://iam.googleapis.com/projects/ ${ GOOGLE_CLOUD_PROJECT_NUMBER } /locations/global/workloadIdentityPools/ ${ GOOGLE_CLOUD_PROJECT } .svc.id.goog/subject/ns/default/sa/adk-agent-sa \\ --condition = None ", "code_blocks": [{"language": "text", "code": "kubectl create serviceaccount adk-agent-sa"}, {"language": "text", "code": "gcloud projects add-iam-policy-binding projects/${GOOGLE_CLOUD_PROJECT} \\\n    --role=roles/aiplatform.user \\\n    --member=principal://iam.googleapis.com/projects/${GOOGLE_CLOUD_PROJECT_NUMBER}/locations/global/workloadIdentityPools/${GOOGLE_CLOUD_PROJECT}.svc.id.goog/subject/ns/default/sa/adk-agent-sa \\\n    --condition=None"}]}, {"heading_path": ["Create the Kubernetes manifest files\u00b6"], "text": "Create the Kubernetes manifest files \u00b6 Create a Kubernetes deployment manifest file named deployment.yaml in your project directory. This file defines how to deploy your application on GKE. deployment.yaml cat <<  EOF > deployment.yaml apiVersion : apps/v1 kind : Deployment metadata : name : adk-agent spec : replicas : 1 selector : matchLabels : app : adk-agent template : metadata : labels : app : adk-agent spec : serviceAccount : adk-agent-sa containers : - name : adk-agent imagePullPolicy : Always image : $GOOGLE_CLOUD_LOCATION-docker.pkg.dev/$GOOGLE_CLOUD_PROJECT/adk-repo/adk-agent:latest resources : limits : memory : \"128Mi\" cpu : \"500m\" ephemeral-storage : \"128Mi\" requests : memory : \"128Mi\" cpu : \"500m\" ephemeral-storage : \"128Mi\" ports : - containerPort : 8080 env : - name : PORT value : \"8080\" - name : GOOGLE_CLOUD_PROJECT value : $GOOGLE_CLOUD_PROJECT - name : GOOGLE_CLOUD_LOCATION value : $GOOGLE_CLOUD_LOCATION - name : GOOGLE_GENAI_USE_VERTEXAI value : \"$GOOGLE_GENAI_USE_VERTEXAI\" # If using AI Studio, set GOOGLE_GENAI_USE_VERTEXAI to false and set the following: # - name: GOOGLE_API_KEY #   value: $GOOGLE_API_KEY # Add any other necessary environment variables your agent might need --- apiVersion : v1 kind : Service metadata : name : adk-agent spec : type : LoadBalancer ports : - port : 80 targetPort : 8080 selector : app : adk-agent EOF ", "code_blocks": [{"language": "text", "code": "cat <<  EOF > deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: adk-agent\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: adk-agent\n  template:\n    metadata:\n      labels:\n        app: adk-agent\n    spec:\n      serviceAccount: adk-agent-sa\n      containers:\n      - name: adk-agent\n        imagePullPolicy: Always\n        image: $GOOGLE_CLOUD_LOCATION-docker.pkg.dev/$GOOGLE_CLOUD_PROJECT/adk-repo/adk-agent:latest\n        resources:\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n            ephemeral-storage: \"128Mi\"\n          requests:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n            ephemeral-storage: \"128Mi\"\n        ports:\n        - containerPort: 8080\n        env:\n          - name: PORT\n            value: \"8080\"\n          - name: GOOGLE_CLOUD_PROJECT\n            value: $GOOGLE_CLOUD_PROJECT\n          - name: GOOGLE_CLOUD_LOCATION\n            value: $GOOGLE_CLOUD_LOCATION\n          - name: GOOGLE_GENAI_USE_VERTEXAI\n            value: \"$GOOGLE_GENAI_USE_VERTEXAI\"\n          # If using AI Studio, set GOOGLE_GENAI_USE_VERTEXAI to false and set the following:\n          # - name: GOOGLE_API_KEY\n          #   value: $GOOGLE_API_KEY\n          # Add any other necessary environment variables your agent might need\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: adk-agent\nspec:       \n  type: LoadBalancer\n  ports:\n    - port: 80\n      targetPort: 8080\n  selector:\n    app: adk-agent\nEOF"}]}, {"heading_path": ["Deploy the Application\u00b6"], "text": "Deploy the Application \u00b6 Deploy the application using the kubectl command line tool. This command applies the deployment and service manifest files to your GKE cluster. kubectl apply -f deployment.yaml After a few moments, you can check the status of your deployment using: kubectl get pods -l = app = adk-agent This command lists the pods associated with your deployment. You should see a pod with a status of Running . Once the pod is running, you can check the status of the service using: kubectl get service adk-agent If the output shows a External IP , it means your service is accessible from the internet. It may take a few minutes for the external IP to be assigned. You can get the external IP address of your service using: kubectl get svc adk-agent -o = jsonpath = '{.status.loadBalancer.ingress[0].ip}' ", "code_blocks": [{"language": "text", "code": "kubectl apply -f deployment.yaml"}, {"language": "text", "code": "kubectl get pods -l=app=adk-agent"}, {"language": "text", "code": "kubectl get service adk-agent"}, {"language": "text", "code": "kubectl get svc adk-agent -o=jsonpath='{.status.loadBalancer.ingress[0].ip}'"}]}, {"heading_path": ["Option 2: Automated Deployment using adk deploy gke\u00b6"], "text": "Option 2: Automated Deployment using adk deploy gke \u00b6 ADK provides a CLI command to streamline GKE deployment. This avoids the need to manually build images, write Kubernetes manifests, or push to Artifact Registry. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Before you begin, ensure you have the following set up: A running GKE cluster: You need an active Kubernetes cluster on Google Cloud. Required CLIs: gcloud CLI: The Google Cloud CLI must be installed, authenticated, and configured to use your target project. Run gcloud auth login and gcloud config set project [YOUR_PROJECT_ID] . kubectl: The Kubernetes CLI must be installed to deploy the application to your cluster. Enabled Google Cloud APIs: Make sure the following APIs are enabled in your Google Cloud project: Kubernetes Engine API ( container.googleapis.com ) Cloud Build API ( cloudbuild.googleapis.com ) Container Registry API ( containerregistry.googleapis.com ) Required IAM Permissions: The user or Compute Engine default service account running the command needs, at a minimum, the following roles: Kubernetes Engine Developer ( roles/container.developer ): To interact with the GKE cluster. Storage Object Viewer ( roles/storage.objectViewer ): To allow Cloud Build to download the source code from the Cloud Storage bucket where gcloud builds submit uploads it. Artifact Registry Create on Push Writer ( roles/artifactregistry.createOnPushWriter ): To allow Cloud Build to push the built container image to Artifact Registry. This role also permits the on-the-fly creation of the special gcr.io repository within Artifact Registry if needed on the first push. Logs Writer ( roles/logging.logWriter ): To allow Cloud Build to write build logs to Cloud Logging. ", "code_blocks": []}, {"heading_path": ["The deploy gke Command\u00b6"], "text": "The deploy gke Command \u00b6 The command takes the path to your agent and parameters specifying the target GKE cluster. ", "code_blocks": []}, {"heading_path": ["Syntax\u00b6"], "text": "Syntax \u00b6 adk deploy gke [ OPTIONS ] AGENT_PATH ", "code_blocks": [{"language": "text", "code": "adk deploy gke [OPTIONS] AGENT_PATH"}]}, {"heading_path": ["Arguments & Options\u00b6"], "text": "Arguments & Options \u00b6 Argument Description Required AGENT_PATH The local file path to your agent's root directory. Yes --project The Google Cloud Project ID where your GKE cluster is located. Yes --cluster_name The name of your GKE cluster. Yes --region The Google Cloud region of your cluster (e.g., us-central1). Yes --with_ui Deploys both the agent's back-end API and a companion front-end user interface. No --log_level Sets the logging level for the deployment process. Options: debug, info, warning, error. No ", "code_blocks": []}, {"heading_path": ["How It Works\u00b6"], "text": "How It Works \u00b6 When you run the adk deploy gke command, the ADK performs the following steps automatically: Containerization: It builds a Docker container image from your agent's source code. Image Push: It tags the container image and pushes it to your project's Artifact Registry. Manifest Generation: It dynamically generates the necessary Kubernetes manifest files (a Deployment and a Service ). Cluster Deployment: It applies these manifests to your specified GKE cluster, which triggers the following: The Deployment instructs GKE to pull the container image from Artifact Registry and run it in one or more Pods. The Service creates a stable network endpoint for your agent. By default, this is a LoadBalancer service, which provisions a public IP address to expose your agent to the internet. ", "code_blocks": []}, {"heading_path": ["Example Usage\u00b6"], "text": "Example Usage \u00b6 Here is a practical example of deploying an agent located at ~/agents/multi_tool_agent/ to a GKE cluster named test. adk deploy gke \\ --project myproject \\ --cluster_name test \\ --region us-central1 \\ --with_ui \\ --log_level info \\ ~/agents/multi_tool_agent/ ", "code_blocks": [{"language": "text", "code": "adk deploy gke \\\n    --project myproject \\\n    --cluster_name test \\\n    --region us-central1 \\\n    --with_ui \\\n    --log_level info \\\n    ~/agents/multi_tool_agent/"}]}, {"heading_path": ["Verifying Your Deployment\u00b6"], "text": "Verifying Your Deployment \u00b6 If you used adk deploy gke , verify the deployment using kubectl : Check the Pods: Ensure your agent's pods are in the Running state. kubectl get pods You should see output like adk-default-service-name-xxxx-xxxx ... 1/1 Running in the default namespace. Find the External IP: Get the public IP address for your agent's service. kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE adk-default-service-name LoadBalancer 34 .118.228.70 34 .63.153.253 80 :32581/TCP 5d20h We can navigate to the external IP and interact with the agent via UI ", "code_blocks": [{"language": "text", "code": "kubectl get pods"}, {"language": "text", "code": "kubectl get service\nNAME                       TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)        AGE\nadk-default-service-name   LoadBalancer   34.118.228.70   34.63.153.253   80:32581/TCP   5d20h"}]}, {"heading_path": ["Testing your agent\u00b6"], "text": "Testing your agent \u00b6 Once your agent is deployed to GKE, you can interact with it via the deployed UI (if enabled) or directly with its API endpoints using tools like curl . You'll need the service URL provided after deployment. UI Testing API Testing (curl) ", "code_blocks": []}, {"heading_path": ["UI Testing\u00b6"], "text": "UI Testing \u00b6 If you deployed your agent with the UI enabled: You can test your agent by simply navigating to the kubernetes service URL in your web browser. The ADK dev UI allows you to interact with your agent, manage sessions, and view execution details directly in the browser. To verify your agent is working as intended, you can: Select your agent from the dropdown menu. Type a message and verify that you receive an expected response from your agent. If you experience any unexpected behavior, check the pod logs for your agent using: kubectl logs -l app = adk-agent ", "code_blocks": [{"language": "text", "code": "kubectl logs -l app=adk-agent"}]}, {"heading_path": ["API Testing (curl)\u00b6"], "text": "API Testing (curl) \u00b6 You can interact with the agent's API endpoints using tools like curl . This is useful for programmatic interaction or if you deployed without the UI. ", "code_blocks": []}, {"heading_path": ["Set the application URL\u00b6"], "text": "Set the application URL \u00b6 Replace the example URL with the actual URL of your deployed Cloud Run service. export APP_URL = $( kubectl get service adk-agent -o jsonpath = '{.status.loadBalancer.ingress[0].ip}' ) ", "code_blocks": [{"language": "text", "code": "export APP_URL=$(kubectl get service adk-agent -o jsonpath='{.status.loadBalancer.ingress[0].ip}')"}]}, {"heading_path": ["List available apps\u00b6"], "text": "List available apps \u00b6 Verify the deployed application name. curl -X GET $APP_URL /list-apps (Adjust the app_name in the following commands based on this output if needed. The default is often the agent directory name, e.g., capital_agent ) . ", "code_blocks": [{"language": "text", "code": "curl -X GET $APP_URL/list-apps"}]}, {"heading_path": ["Create or Update a Session\u00b6"], "text": "Create or Update a Session \u00b6 Initialize or update the state for a specific user and session. Replace capital_agent with your actual app name if different. The values user_123 and session_abc are example identifiers; you can replace them with your desired user and session IDs. curl -X POST \\ $APP_URL /apps/capital_agent/users/user_123/sessions/session_abc \\ -H \"Content-Type: application/json\" \\ -d '{\"preferred_language\": \"English\", \"visit_count\": 5}' ", "code_blocks": [{"language": "text", "code": "curl -X POST \\\n    $APP_URL/apps/capital_agent/users/user_123/sessions/session_abc \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"preferred_language\": \"English\", \"visit_count\": 5}'"}]}, {"heading_path": ["Run the Agent\u00b6"], "text": "Run the Agent \u00b6 Send a prompt to your agent. Replace capital_agent with your app name and adjust the user/session IDs and prompt as needed. curl -X POST $APP_URL /run_sse \\ -H \"Content-Type: application/json\" \\ -d '{ \"app_name\": \"capital_agent\", \"user_id\": \"user_123\", \"session_id\": \"session_abc\", \"new_message\": { \"role\": \"user\", \"parts\": [{ \"text\": \"What is the capital of Canada?\" }] }, \"streaming\": false }' Set \"streaming\": true if you want to receive Server-Sent Events (SSE). The response will contain the agent's execution events, including the final answer. ", "code_blocks": [{"language": "text", "code": "curl -X POST $APP_URL/run_sse \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\n    \"app_name\": \"capital_agent\",\n    \"user_id\": \"user_123\",\n    \"session_id\": \"session_abc\",\n    \"new_message\": {\n        \"role\": \"user\",\n        \"parts\": [{\n        \"text\": \"What is the capital of Canada?\"\n        }]\n    },\n    \"streaming\": false\n    }'"}]}, {"heading_path": ["Troubleshooting\u00b6"], "text": "Troubleshooting \u00b6 These are some common issues you might encounter when deploying your agent to GKE: ", "code_blocks": []}, {"heading_path": ["403 Permission Denied for Gemini 2.0 Flash\u00b6"], "text": "403 Permission Denied for Gemini 2.0 Flash \u00b6 This usually means that the Kubernetes service account does not have the necessary permission to access the Vertex AI API. Ensure that you have created the service account and bound it to the Vertex AI User role as described in the Configure Kubernetes Service Account for Vertex AI section. If you are using AI Studio, ensure that you have set the GOOGLE_API_KEY environment variable in the deployment manifest and it is valid. ", "code_blocks": []}, {"heading_path": ["404 or Not Found response\u00b6"], "text": "404 or Not Found response \u00b6 This usually means there is an error in your request. Check the application logs to diagnose the problem. export POD_NAME = $( kubectl get pod -l app = adk-agent -o jsonpath = '{.items[0].metadata.name}' ) kubectl logs $POD_NAME ", "code_blocks": [{"language": "text", "code": "export POD_NAME=$(kubectl get pod -l app=adk-agent -o jsonpath='{.items[0].metadata.name}')\nkubectl logs $POD_NAME"}]}, {"heading_path": ["Attempt to write a readonly database\u00b6"], "text": "Attempt to write a readonly database \u00b6 You might see there is no session id created in the UI and the agent does not respond to any messages. This is usually caused by the SQLite database being read-only. This can happen if you run the agent locally and then create the container image which copies the SQLite database into the container. The database is then read-only in the container. sqlalchemy.exc.OperationalError: ( sqlite3.OperationalError ) attempt to write a readonly database [ SQL: UPDATE app_states SET state = ?, update_time = CURRENT_TIMESTAMP WHERE app_states.app_name = ? ] To fix this issue, you can either: Delete the SQLite database file from your local machine before building the container image. This will create a new SQLite database when the container is started. rm -f sessions.db or (recommended) you can add a .dockerignore file to your project directory to exclude the SQLite database from being copied into the container image. .dockerignore sessions.db Build the container image abd deploy the application again. ", "code_blocks": [{"language": "text", "code": "sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) attempt to write a readonly database\n[SQL: UPDATE app_states SET state=?, update_time=CURRENT_TIMESTAMP WHERE app_states.app_name = ?]"}, {"language": "text", "code": "rm -f sessions.db"}, {"language": "text", "code": "sessions.db"}]}, {"heading_path": ["Insufficent Permission to Stream Logs ERROR: (gcloud.builds.submit)\u00b6"], "text": "Insufficent Permission to Stream Logs ERROR: (gcloud.builds.submit) \u00b6 This error can occur when you don't have sufficient permissions to stream build logs, or your VPC-SC security policy restricts access to the default logs bucket. To check the progress of the build, follow the link provided in the error message or navigate to the Cloud Build page in the Google Cloud Console. You can also verify the image was built and pushed to the Artifact Registry using the command under the Build the container image section. ", "code_blocks": []}, {"heading_path": ["Gemini-2.0-Flash Not Supported in Live Api\u00b6"], "text": "Gemini-2.0-Flash Not Supported in Live Api \u00b6 When using the ADK Dev UI for your deployed agent, text-based chat works, but voice (e.g., clicking the microphone button) fail. You might see a websockets.exceptions.ConnectionClosedError in the pod logs indicating that your model is \"not supported in the live api\". This error occurs because the agent is configured with a model (like gemini-2.0-flash in the example) that does not support the Gemini Live API. The Live API is required for real-time, bidirectional streaming of audio and video. ", "code_blocks": []}, {"heading_path": ["Cleanup\u00b6"], "text": "Cleanup \u00b6 To delete the GKE cluster and all associated resources, run: gcloud container clusters delete adk-cluster \\ --location = $GOOGLE_CLOUD_LOCATION \\ --project = $GOOGLE_CLOUD_PROJECT To delete the Artifact Registry repository, run: gcloud artifacts repositories delete adk-repo \\ --location = $GOOGLE_CLOUD_LOCATION \\ --project = $GOOGLE_CLOUD_PROJECT You can also delete the project if you no longer need it. This will delete all resources associated with the project, including the GKE cluster, Artifact Registry repository, and any other resources you created. gcloud projects delete $GOOGLE_CLOUD_PROJECT Back to top ", "code_blocks": [{"language": "text", "code": "gcloud container clusters delete adk-cluster \\\n    --location=$GOOGLE_CLOUD_LOCATION \\\n    --project=$GOOGLE_CLOUD_PROJECT"}, {"language": "text", "code": "gcloud artifacts repositories delete adk-repo \\\n    --location=$GOOGLE_CLOUD_LOCATION \\\n    --project=$GOOGLE_CLOUD_PROJECT"}, {"language": "text", "code": "gcloud projects delete $GOOGLE_CLOUD_PROJECT"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:26.151103", "source_type": "adk-docs"}
{"doc_id": "935190a12481fd8becd4afb4cf85dd82b1cd4a871dc424816168531ffa49eb40", "url": "https://google.github.io/adk-docs/observability/logging", "title": "Logging - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Logging in the Agent Development Kit (ADK)\u00b6"], "text": "Logging in the Agent Development Kit (ADK) \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 The Agent Development Kit (ADK) uses Python's standard logging module to provide flexible and powerful logging capabilities. Understanding how to configure and interpret these logs is crucial for monitoring agent behavior and debugging issues effectively. ", "code_blocks": []}, {"heading_path": ["Logging Philosophy\u00b6"], "text": "Logging Philosophy \u00b6 ADK's approach to logging is to provide detailed diagnostic information without being overly verbose by default. It is designed to be configured by the application developer, allowing you to tailor the log output to your specific needs, whether in a development or production environment. Standard Library: It uses the standard logging library, so any configuration or handler that works with it will work with ADK. Hierarchical Loggers: Loggers are named hierarchically based on the module path (e.g., google_adk.google.adk.agents.llm_agent ), allowing for fine-grained control over which parts of the framework produce logs. User-Configured: The framework does not configure logging itself. It is the responsibility of the developer using the framework to set up the desired logging configuration in their application's entry point. ", "code_blocks": []}, {"heading_path": ["How to Configure Logging\u00b6"], "text": "How to Configure Logging \u00b6 You can configure logging in your main application script (e.g., main.py ) before you initialize and run your agent. The simplest way is to use logging.basicConfig . ", "code_blocks": []}, {"heading_path": ["Example Configuration\u00b6"], "text": "Example Configuration \u00b6 To enable detailed logging, including DEBUG level messages, add the following to the top of your script: import logging logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(levelname)s - %(name)s - %(message)s ' ) # Your ADK agent code follows... # from google.adk.agents import LlmAgent # ... ", "code_blocks": [{"language": "text", "code": "import logging\n\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s'\n)\n\n# Your ADK agent code follows...\n# from google.adk.agents import LlmAgent\n# ..."}]}, {"heading_path": ["Configuring Logging with the ADK CLI\u00b6"], "text": "Configuring Logging with the ADK CLI \u00b6 When running agents using the ADK's built-in web or API servers, you can easily control the log verbosity directly from the command line. The adk web , adk api_server , and adk deploy cloud_run commands all accept a --log_level option. This provides a convenient way to set the logging level without modifying your agent's source code. Note: The command-line setting always takes precedence over the programmatic configuration (like logging.basicConfig ) for ADK's loggers. It's recommended to use INFO or WARNING in production and enable DEBUG only when troubleshooting. Example using adk web : To start the web server with DEBUG level logging, run: adk web --log_level DEBUG path/to/your/agents_dir The available log levels for the --log_level option are: DEBUG INFO (default) WARNING ERROR CRITICAL You can also use -v or --verbose as a a shortcut for --log_level DEBUG . adk web -v path/to/your/agents_dir ", "code_blocks": [{"language": "text", "code": "adk web --log_level DEBUG path/to/your/agents_dir"}, {"language": "text", "code": "adk web -v path/to/your/agents_dir"}]}, {"heading_path": ["Log Levels\u00b6"], "text": "Log Levels \u00b6 ADK uses standard log levels to categorize messages. The configured level determines what information gets logged. Level Description Type of Information Logged DEBUG Crucial for debugging. The most verbose level for fine-grained diagnostic information. Full LLM Prompts: The complete request sent to the language model, including system instructions, history, and tools. Detailed API responses from services. Internal state transitions and variable values. INFO General information about the agent's lifecycle. Agent initialization and startup. Session creation and deletion events. Execution of a tool, including its name and arguments. WARNING Indicates a potential issue or deprecated feature use. The agent continues to function, but attention may be required. Use of deprecated methods or parameters. Non-critical errors that the system recovered from. ERROR A serious error that prevented an operation from completing. Failed API calls to external services (e.g., LLM, Session Service). Unhandled exceptions during agent execution. Configuration errors. Note: It is recommended to use INFO or WARNING in production environments. Only enable DEBUG when actively troubleshooting an issue, as DEBUG logs can be very verbose and may contain sensitive information. ", "code_blocks": []}, {"heading_path": ["Reading and Understanding the Logs\u00b6"], "text": "Reading and Understanding the Logs \u00b6 The format string in the basicConfig example determines the structure of each log message. Here\u2019s a sample log entry: 2025-07-08 11:22:33,456 - DEBUG - google_adk.google.adk.models.google_llm - LLM Request: contents { ... } Log Segment Format Specifier Meaning 2025-07-08 11:22:33,456 %(asctime)s Timestamp DEBUG %(levelname)s Severity level google_adk.models.google_llm %(name)s Logger name (the module that produced the log) LLM Request: contents { ... } %(message)s The actual log message By reading the logger name, you can immediately pinpoint the source of the log and understand its context within the agent's architecture. ", "code_blocks": [{"language": "text", "code": "2025-07-08 11:22:33,456 - DEBUG - google_adk.google.adk.models.google_llm - LLM Request: contents { ... }"}]}, {"heading_path": ["Debugging with Logs: A Practical Example\u00b6"], "text": "Debugging with Logs: A Practical Example \u00b6 Scenario: Your agent is not producing the expected output, and you suspect the prompt being sent to the LLM is incorrect or missing information. Steps: Enable DEBUG Logging: In your main.py , set the logging level to DEBUG as shown in the configuration example. logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(levelname)s - %(name)s - %(message)s ' ) Run Your Agent: Execute your agent's task as you normally would. Inspect the Logs: Look through the console output for a message from the google.adk.models.google_llm logger that starts with LLM Request: . ... 2025-07-10 15:26:13,778 - DEBUG - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False 2025-07-10 15:26:13,778 - DEBUG - google_adk.google.adk.models.google_llm - LLM Request: ----------------------------------------------------------- System Instruction: You roll dice and answer questions about the outcome of the dice rolls. You can roll dice of different sizes. You can use multiple tools in parallel by calling functions in parallel(in one request and in one round). It is ok to discuss previous dice roles, and comment on the dice rolls. When you are asked to roll a die, you must call the roll_die tool with the number of sides. Be sure to pass in an integer. Do not pass in a string. You should never roll a die on your own. When checking prime numbers, call the check_prime tool with a list of integers. Be sure to pass in a list of integers. You should never pass in a string. You should not check prime numbers before calling the tool. When you are asked to roll a die and check prime numbers, you should always make the following two function calls: 1. You should first call the roll_die tool to get a roll. Wait for the function response before calling the check_prime tool. 2. After you get the function response from roll_die tool, you should call the check_prime tool with the roll_die result. 2.1 If user asks you to check primes based on previous rolls, make sure you include the previous rolls in the list. 3. When you respond, you must include the roll_die result from step 1. You should always perform the previous 3 steps when asking for a roll and checking prime numbers. You should not rely on the previous history on prime results. You are an agent. Your internal name is \"hello_world_agent\". The description about you is \"hello world agent that can roll a dice of 8 sides and check prime numbers.\" ----------------------------------------------------------- Contents: {\"parts\":[{\"text\":\"Roll a 6 sided dice\"}],\"role\":\"user\"} {\"parts\":[{\"function_call\":{\"args\":{\"sides\":6},\"name\":\"roll_die\"}}],\"role\":\"model\"} {\"parts\":[{\"function_response\":{\"name\":\"roll_die\",\"response\":{\"result\":2}}}],\"role\":\"user\"} ----------------------------------------------------------- Functions: roll_die: {'sides': {'type': <Type.INTEGER: 'INTEGER'>}} check_prime: {'nums': {'items': {'type': <Type.INTEGER: 'INTEGER'>}, 'type': <Type.ARRAY: 'ARRAY'>}} ----------------------------------------------------------- 2025-07-10 15:26:13,779 - INFO - google_genai.models - AFC is enabled with max remote calls: 10. 2025-07-10 15:26:14,309 - INFO - google_adk.google.adk.models.google_llm - LLM Response: ----------------------------------------------------------- Text: I have rolled a 6 sided die, and the result is 2. ... Analyze the Prompt: By examining the System Instruction , contents , functions sections of the logged request, you can verify: Is the system instruction correct? Is the conversation history ( user and model turns) accurate? Is the most recent user query included? Are the correct tools being provided to the model? Are the tools correctly called by the model? How long it takes for the model to respond? This detailed output allows you to diagnose a wide range of issues, from incorrect prompt engineering to problems with tool definitions, directly from the log files. Back to top ", "code_blocks": [{"language": "text", "code": "logging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s'\n)"}, {"language": "text", "code": "...\n2025-07-10 15:26:13,778 - DEBUG - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n2025-07-10 15:26:13,778 - DEBUG - google_adk.google.adk.models.google_llm - \nLLM Request:\n-----------------------------------------------------------\nSystem Instruction:\n\n      You roll dice and answer questions about the outcome of the dice rolls.\n      You can roll dice of different sizes.\n      You can use multiple tools in parallel by calling functions in parallel(in one request and in one round).\n      It is ok to discuss previous dice roles, and comment on the dice rolls.\n      When you are asked to roll a die, you must call the roll_die tool with the number of sides. Be sure to pass in an integer. Do not pass in a string.\n      You should never roll a die on your own.\n      When checking prime numbers, call the check_prime tool with a list of integers. Be sure to pass in a list of integers. You should never pass in a string.\n      You should not check prime numbers before calling the tool.\n      When you are asked to roll a die and check prime numbers, you should always make the following two function calls:\n      1. You should first call the roll_die tool to get a roll. Wait for the function response before calling the check_prime tool.\n      2. After you get the function response from roll_die tool, you should call the check_prime tool with the roll_die result.\n        2.1 If user asks you to check primes based on previous rolls, make sure you include the previous rolls in the list.\n      3. When you respond, you must include the roll_die result from step 1.\n      You should always perform the previous 3 steps when asking for a roll and checking prime numbers.\n      You should not rely on the previous history on prime results.\n\n\nYou are an agent. Your internal name is \"hello_world_agent\".\n\nThe description about you is \"hello world agent that can roll a dice of 8 sides and check prime numbers.\"\n-----------------------------------------------------------\nContents:\n{\"parts\":[{\"text\":\"Roll a 6 sided dice\"}],\"role\":\"user\"}\n{\"parts\":[{\"function_call\":{\"args\":{\"sides\":6},\"name\":\"roll_die\"}}],\"role\":\"model\"}\n{\"parts\":[{\"function_response\":{\"name\":\"roll_die\",\"response\":{\"result\":2}}}],\"role\":\"user\"}\n-----------------------------------------------------------\nFunctions:\nroll_die: {'sides': {'type': <Type.INTEGER: 'INTEGER'>}} \ncheck_prime: {'nums': {'items': {'type': <Type.INTEGER: 'INTEGER'>}, 'type': <Type.ARRAY: 'ARRAY'>}} \n-----------------------------------------------------------\n\n2025-07-10 15:26:13,779 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n2025-07-10 15:26:14,309 - INFO - google_adk.google.adk.models.google_llm - \nLLM Response:\n-----------------------------------------------------------\nText:\nI have rolled a 6 sided die, and the result is 2.\n..."}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:26.556448", "source_type": "adk-docs"}
{"doc_id": "d5f925ae18bdc2daa9f54f17f515db920fae319319fee90f814e6d106abcd761", "url": "https://google.github.io/adk-docs/observability/cloud-trace", "title": "Cloud Trace - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agent Observability with Cloud Trace\u00b6"], "text": "Agent Observability with Cloud Trace \u00b6 With ADK, you\u2019ve already capable of inspecting and observing your agent interaction locally utilizing the powerful web development UI discussed in here . However, if we aim for cloud deployment, we will need a centralized dashboard to observe real traffic. Cloud Trace is a component of Google Cloud Observability. It is a powerful tool for monitoring, debugging, and improving the performance of your applications by focusing specifically on tracing capabilities. For Agent Development Kit (ADK) applications, Cloud Trace enables comprehensive tracing, helping you understand how requests flow through your agent's interactions and identify performance bottlenecks or errors within your AI agents. ", "code_blocks": []}, {"heading_path": ["Overview\u00b6"], "text": "Overview \u00b6 Cloud Trace is built on OpenTelemetry , an open-source standard that supports many languages and ingestion methods for generating trace data. This aligns with observability practices for ADK applications, which also leverage OpenTelemetry-compatible instrumentation, allowing you to : Trace agent interactions : Cloud Trace continuously gathers and analyzes trace data from your project, enabling you to rapidly diagnose latency issues and errors within your ADK applications. This automatic data collection simplifies the process of identifying problems in complex agent workflows. Debug issues : Quickly diagnose latency issues and errors by analyzing detailed traces. Crucial for understanding issues that manifest as increased communication latency across different services or during specific agent actions like tool calls. In-depth Analysis and Visualization: Trace Explorer is the primary tool for analyzing traces, offering visual aids like heatmaps for span duration and line charts for request/error rates. It also provides a spans table, groupable by service and operation, which gives one-click access to representative traces and a waterfall view to easily identify bottlenecks and sources of errors within your agent's execution path The following example will assume the following agent directory structure working_dir/ \u251c\u2500\u2500 weather_agent/ \u2502   \u251c\u2500\u2500 agent.py \u2502   \u2514\u2500\u2500 __init__.py \u2514\u2500\u2500 deploy_agent_engine.py \u2514\u2500\u2500 deploy_fast_api_app.py \u2514\u2500\u2500 agent_runner.py # weather_agent/agent.py import os from google.adk.agents import Agent os . environ . setdefault ( \"GOOGLE_CLOUD_PROJECT\" , \"{your-project-id}\" ) os . environ . setdefault ( \"GOOGLE_CLOUD_LOCATION\" , \"global\" ) os . environ . setdefault ( \"GOOGLE_GENAI_USE_VERTEXAI\" , \"True\" ) # Define a tool function def get_weather ( city : str ) -> dict : \"\"\"Retrieves the current weather report for a specified city. Args: city (str): The name of the city for which to retrieve the weather report. Returns: dict: status and result or error msg. \"\"\" if city . lower () == \"new york\" : return { \"status\" : \"success\" , \"report\" : ( \"The weather in New York is sunny with a temperature of 25 degrees\" \" Celsius (77 degrees Fahrenheit).\" ), } else : return { \"status\" : \"error\" , \"error_message\" : f \"Weather information for ' { city } ' is not available.\" , } # Create an agent with tools root_agent = Agent ( name = \"weather_agent\" , model = \"gemini-2.5-flash\" , description = \"Agent to answer questions using weather tools.\" , instruction = \"You must use the available tools to find an answer.\" , tools = [ get_weather ], ) ", "code_blocks": [{"language": "text", "code": "working_dir/\n\u251c\u2500\u2500 weather_agent/\n\u2502   \u251c\u2500\u2500 agent.py\n\u2502   \u2514\u2500\u2500 __init__.py\n\u2514\u2500\u2500 deploy_agent_engine.py\n\u2514\u2500\u2500 deploy_fast_api_app.py\n\u2514\u2500\u2500 agent_runner.py"}, {"language": "text", "code": "# weather_agent/agent.py\n\nimport os\nfrom google.adk.agents import Agent\n\nos.environ.setdefault(\"GOOGLE_CLOUD_PROJECT\", \"{your-project-id}\")\nos.environ.setdefault(\"GOOGLE_CLOUD_LOCATION\", \"global\")\nos.environ.setdefault(\"GOOGLE_GENAI_USE_VERTEXAI\", \"True\")\n\n\n# Define a tool function\ndef get_weather(city: str) -> dict:\n    \"\"\"Retrieves the current weather report for a specified city.\n\n    Args:\n        city (str): The name of the city for which to retrieve the weather report.\n\n    Returns:\n        dict: status and result or error msg.\n    \"\"\"\n    if city.lower() == \"new york\":\n        return {\n            \"status\": \"success\",\n            \"report\": (\n                \"The weather in New York is sunny with a temperature of 25 degrees\"\n                \" Celsius (77 degrees Fahrenheit).\"\n            ),\n        }\n    else:\n        return {\n            \"status\": \"error\",\n            \"error_message\": f\"Weather information for '{city}' is not available.\",\n        }\n\n\n# Create an agent with tools\nroot_agent = Agent(\n    name=\"weather_agent\",\n    model=\"gemini-2.5-flash\",\n    description=\"Agent to answer questions using weather tools.\",\n    instruction=\"You must use the available tools to find an answer.\",\n    tools=[get_weather],\n)"}]}, {"heading_path": ["Cloud Trace Setup\u00b6"], "text": "Cloud Trace Setup \u00b6 ", "code_blocks": []}, {"heading_path": ["Setup for Agent Engine Deployment\u00b6"], "text": "Setup for Agent Engine Deployment \u00b6 ", "code_blocks": []}, {"heading_path": ["Agent Engine Deployment - from ADK CLI\u00b6"], "text": "Agent Engine Deployment - from ADK CLI \u00b6 You can enable cloud tracing by adding --trace_to_cloud flag when deploying your agent using adk deploy agent_engine command for agent engine deployment. adk deploy agent_engine \\ --project = $GOOGLE_CLOUD_PROJECT \\ --region = $GOOGLE_CLOUD_LOCATION \\ --staging_bucket = $STAGING_BUCKET \\ --trace_to_cloud \\ $AGENT_PATH ", "code_blocks": [{"language": "text", "code": "adk deploy agent_engine \\\n    --project=$GOOGLE_CLOUD_PROJECT \\\n    --region=$GOOGLE_CLOUD_LOCATION \\\n    --staging_bucket=$STAGING_BUCKET \\\n    --trace_to_cloud \\\n    $AGENT_PATH"}]}, {"heading_path": ["Agent Engine Deployment - from Python SDK\u00b6"], "text": "Agent Engine Deployment - from Python SDK \u00b6 If you prefer using Python SDK, you can enable cloud tracing by adding enable_tracing=True when initialize the AdkApp object # deploy_agent_engine.py from vertexai.preview import reasoning_engines from vertexai import agent_engines from weather_agent.agent import root_agent import vertexai PROJECT_ID = \"{your-project-id}\" LOCATION = \"{your-preferred-location}\" STAGING_BUCKET = \"{your-staging-bucket}\" vertexai . init ( project = PROJECT_ID , location = LOCATION , staging_bucket = STAGING_BUCKET , ) adk_app = reasoning_engines . AdkApp ( agent = root_agent , enable_tracing = True , ) remote_app = agent_engines . create ( agent_engine = adk_app , extra_packages = [ \"./weather_agent\" , ], requirements = [ \"google-cloud-aiplatform[adk,agent_engines]\" , ], ) ", "code_blocks": [{"language": "text", "code": "# deploy_agent_engine.py\n\nfrom vertexai.preview import reasoning_engines\nfrom vertexai import agent_engines\nfrom weather_agent.agent import root_agent\n\nimport vertexai\n\nPROJECT_ID = \"{your-project-id}\"\nLOCATION = \"{your-preferred-location}\"\nSTAGING_BUCKET = \"{your-staging-bucket}\"\n\nvertexai.init(\n    project=PROJECT_ID,\n    location=LOCATION,\n    staging_bucket=STAGING_BUCKET,\n)\n\nadk_app = reasoning_engines.AdkApp(\n    agent=root_agent,\n    enable_tracing=True,\n)\n\n\nremote_app = agent_engines.create(\n    agent_engine=adk_app,\n    extra_packages=[\n        \"./weather_agent\",\n    ],\n    requirements=[\n        \"google-cloud-aiplatform[adk,agent_engines]\",\n    ],\n)"}]}, {"heading_path": ["Setup for Cloud Run Deployment\u00b6"], "text": "Setup for Cloud Run Deployment \u00b6 ", "code_blocks": []}, {"heading_path": ["Cloud Run Deployment - from ADK CLI\u00b6"], "text": "Cloud Run Deployment - from ADK CLI \u00b6 You can enable cloud tracing by adding --trace_to_cloud flag when deploying your agent using adk deploy cloud_run command for cloud run deployment. adk deploy cloud_run \\ --project = $GOOGLE_CLOUD_PROJECT \\ --region = $GOOGLE_CLOUD_LOCATION \\ --trace_to_cloud \\ $AGENT_PATH If you want to enable cloud tracing and using a customized agent service deployment on Cloud Run, you can refer to the Setup for Customized Deployment section below ", "code_blocks": [{"language": "text", "code": "adk deploy cloud_run \\\n    --project=$GOOGLE_CLOUD_PROJECT \\\n    --region=$GOOGLE_CLOUD_LOCATION \\\n    --trace_to_cloud \\\n    $AGENT_PATH"}]}, {"heading_path": ["Setup for Customized Deployment\u00b6"], "text": "Setup for Customized Deployment \u00b6 ", "code_blocks": []}, {"heading_path": ["From Built-in get_fast_api_app Module\u00b6"], "text": "From Built-in get_fast_api_app Module \u00b6 If you want to customize your own agent service, you can enable cloud tracing by initialize the FastAPI app using built-in get_fast_api_app module and set trace_to_cloud=True # deploy_fast_api_app.py import os from google.adk.cli.fast_api import get_fast_api_app from fastapi import FastAPI # Set GOOGLE_CLOUD_PROJECT environment variable for cloud tracing os . environ . setdefault ( \"GOOGLE_CLOUD_PROJECT\" , \"alvin-exploratory-2\" ) # Discover the `weather_agent` directory in current working dir AGENT_DIR = os . path . dirname ( os . path . abspath ( __file__ )) # Create FastAPI app with enabled cloud tracing app : FastAPI = get_fast_api_app ( agents_dir = AGENT_DIR , web = True , trace_to_cloud = True , ) app . title = \"weather-agent\" app . description = \"API for interacting with the Agent weather-agent\" # Main execution if __name__ == \"__main__\" : import uvicorn uvicorn . run ( app , host = \"0.0.0.0\" , port = 8080 ) ", "code_blocks": [{"language": "text", "code": "# deploy_fast_api_app.py\n\nimport os\nfrom google.adk.cli.fast_api import get_fast_api_app\nfrom fastapi import FastAPI\n\n# Set GOOGLE_CLOUD_PROJECT environment variable for cloud tracing\nos.environ.setdefault(\"GOOGLE_CLOUD_PROJECT\", \"alvin-exploratory-2\")\n\n# Discover the `weather_agent` directory in current working dir\nAGENT_DIR = os.path.dirname(os.path.abspath(__file__))\n\n# Create FastAPI app with enabled cloud tracing\napp: FastAPI = get_fast_api_app(\n    agents_dir=AGENT_DIR,\n    web=True,\n    trace_to_cloud=True,\n)\n\napp.title = \"weather-agent\"\napp.description = \"API for interacting with the Agent weather-agent\"\n\n\n# Main execution\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"0.0.0.0\", port=8080)"}]}, {"heading_path": ["From Customized Agent Runner\u00b6"], "text": "From Customized Agent Runner \u00b6 If you want to fully customize your ADK agent runtime, you can enable cloud tracing by using CloudTraceSpanExporter module from Opentelemetry. # agent_runner.py from google.adk.runners import Runner from google.adk.sessions import InMemorySessionService from weather_agent.agent import root_agent as weather_agent from google.genai.types import Content , Part from opentelemetry import trace from opentelemetry.exporter.cloud_trace import CloudTraceSpanExporter from opentelemetry.sdk.trace import export from opentelemetry.sdk.trace import TracerProvider APP_NAME = \"weather_agent\" USER_ID = \"u_123\" SESSION_ID = \"s_123\" provider = TracerProvider () processor = export . BatchSpanProcessor ( CloudTraceSpanExporter ( project_id = \"{your-project-id}\" ) ) provider . add_span_processor ( processor ) trace . set_tracer_provider ( provider ) session_service = InMemorySessionService () runner = Runner ( agent = weather_agent , app_name = APP_NAME , session_service = session_service ) async def main (): session = await session_service . get_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) if session is None : session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) user_content = Content ( role = \"user\" , parts = [ Part ( text = \"what's weather in paris?\" )] ) final_response_content = \"No response\" async for event in runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = user_content ): if event . is_final_response () and event . content and event . content . parts : final_response_content = event . content . parts [ 0 ] . text print ( final_response_content ) if __name__ == \"__main__\" : import asyncio asyncio . run ( main ()) ", "code_blocks": [{"language": "text", "code": "# agent_runner.py\n\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom weather_agent.agent import root_agent as weather_agent\nfrom google.genai.types import Content, Part\nfrom opentelemetry import trace\nfrom opentelemetry.exporter.cloud_trace import CloudTraceSpanExporter\nfrom opentelemetry.sdk.trace import export\nfrom opentelemetry.sdk.trace import TracerProvider\n\nAPP_NAME = \"weather_agent\"\nUSER_ID = \"u_123\"\nSESSION_ID = \"s_123\"\n\nprovider = TracerProvider()\nprocessor = export.BatchSpanProcessor(\n    CloudTraceSpanExporter(project_id=\"{your-project-id}\")\n)\nprovider.add_span_processor(processor)\ntrace.set_tracer_provider(provider)\n\nsession_service = InMemorySessionService()\nrunner = Runner(agent=weather_agent, app_name=APP_NAME, session_service=session_service)\n\n\nasync def main():\n    session = await session_service.get_session(\n        app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n    )\n    if session is None:\n        session = await session_service.create_session(\n            app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n        )\n\n    user_content = Content(\n        role=\"user\", parts=[Part(text=\"what's weather in paris?\")]\n    )\n\n    final_response_content = \"No response\"\n    async for event in runner.run_async(\n        user_id=USER_ID, session_id=SESSION_ID, new_message=user_content\n    ):\n        if event.is_final_response() and event.content and event.content.parts:\n            final_response_content = event.content.parts[0].text\n\n    print(final_response_content)\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())"}]}, {"heading_path": ["Inspect Cloud Traces\u00b6"], "text": "Inspect Cloud Traces \u00b6 After the setup is complete, whenever you interact with the agent it will automatically send trace data to Cloud Trace. You can inspect the traces by going to console.cloud.google.com and visit the Trace Explorer on the configured Google Cloud Project And then you will see all available traces produced by ADK agent which configured in several span names such as invocation , agent_run . call_llm and execute_tool If you click on one of the traces, you will see the waterfall view of the detailed process, similar to what we see in the web development UI with adk web command. ", "code_blocks": []}, {"heading_path": ["Resources\u00b6"], "text": "Resources \u00b6 Google Cloud Trace Documentation Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:27.053443", "source_type": "adk-docs"}
{"doc_id": "e3242d0bc4734751965c2268fbef06f8311c7db2f260062fbd902f954b16b984", "url": "https://google.github.io/adk-docs/observability/agentops", "title": "AgentOps - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agent Observability with AgentOps\u00b6"], "text": "Agent Observability with AgentOps \u00b6 With just two lines of code , AgentOps provides session replays, metrics, and monitoring for agents. ", "code_blocks": []}, {"heading_path": ["Why AgentOps for ADK?\u00b6"], "text": "Why AgentOps for ADK? \u00b6 Observability is a key aspect of developing and deploying conversational AI agents. It allows developers to understand how their agents are performing, how their agents are interacting with users, and how their agents use external tools and APIs. By integrating AgentOps, developers can gain deep insights into their ADK agent's behavior, LLM interactions, and tool usage. Google ADK includes its own OpenTelemetry-based tracing system, primarily aimed at providing developers with a way to trace the basic flow of execution within their agents. AgentOps enhances this by offering a dedicated and more comprehensive observability platform with: Unified Tracing and Replay Analytics: Consolidate traces from ADK and other components of your AI stack. Rich Visualization: Intuitive dashboards to visualize agent execution flow, LLM calls, and tool performance. Detailed Debugging: Drill down into specific spans, view prompts, completions, token counts, and errors. LLM Cost and Latency Tracking: Track latencies, costs (via token usage), and identify bottlenecks. Simplified Setup: Get started with just a few lines of code. AgentOps dashboard displaying a trace from a multi-step ADK application execution. You can see the hierarchical structure of spans, including the main agent workflow, individual sub-agents, LLM calls, and tool executions. Note the clear hierarchy: the main workflow agent span contains child spans for various sub-agent operations, LLM calls, and tool executions. ", "code_blocks": []}, {"heading_path": ["Getting Started with AgentOps and ADK\u00b6"], "text": "Getting Started with AgentOps and ADK \u00b6 Integrating AgentOps into your ADK application is straightforward: Install AgentOps: pip install -U agentops Create an API Key Create a user API key here: Create API Key and configure your environment: Add your API key to your environment variables: AGENTOPS_API_KEY=<YOUR_AGENTOPS_API_KEY> Initialize AgentOps: Add the following lines at the beginning of your ADK application script (e.g., your main Python file running the ADK Runner ): import agentops agentops . init () This will initiate an AgentOps session as well as automatically track ADK agents. Detailed example: import agentops import os from dotenv import load_dotenv # Load environment variables (optional, if you use a .env file for API keys) load_dotenv () agentops . init ( api_key = os . getenv ( \"AGENTOPS_API_KEY\" ), # Your AgentOps API Key trace_name = \"my-adk-app-trace\" # Optional: A name for your trace # auto_start_session=True is the default. # Set to False if you want to manually control session start/end. ) \ud83d\udea8 \ud83d\udd11 You can find your AgentOps API key on your AgentOps Dashboard after signing up. It's recommended to set it as an environment variable ( AGENTOPS_API_KEY ). Once initialized, AgentOps will automatically begin instrumenting your ADK agent. This is all you need to capture all telemetry data for your ADK agent ", "code_blocks": [{"language": "text", "code": "pip install -U agentops"}, {"language": "text", "code": "AGENTOPS_API_KEY=<YOUR_AGENTOPS_API_KEY>"}, {"language": "text", "code": "import agentops\nagentops.init()"}, {"language": "text", "code": "import agentops\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables (optional, if you use a .env file for API keys)\nload_dotenv()\n\nagentops.init(\n    api_key=os.getenv(\"AGENTOPS_API_KEY\"), # Your AgentOps API Key\n    trace_name=\"my-adk-app-trace\"  # Optional: A name for your trace\n    # auto_start_session=True is the default.\n    # Set to False if you want to manually control session start/end.\n)"}]}, {"heading_path": ["How AgentOps Instruments ADK\u00b6"], "text": "How AgentOps Instruments ADK \u00b6 AgentOps employs a sophisticated strategy to provide seamless observability without conflicting with ADK's native telemetry: Neutralizing ADK's Native Telemetry: AgentOps detects ADK and intelligently patches ADK's internal OpenTelemetry tracer (typically trace.get_tracer('gcp.vertex.agent') ). It replaces it with a NoOpTracer , ensuring that ADK's own attempts to create telemetry spans are effectively silenced. This prevents duplicate traces and allows AgentOps to be the authoritative source for observability data. AgentOps-Controlled Span Creation: AgentOps takes control by wrapping key ADK methods to create a logical hierarchy of spans: Agent Execution Spans (e.g., adk.agent.MySequentialAgent ): When an ADK agent (like BaseAgent , SequentialAgent , or LlmAgent ) starts its run_async method, AgentOps initiates a parent span for that agent's execution. LLM Interaction Spans (e.g., adk.llm.gemini-pro ): For calls made by an agent to an LLM (via ADK's BaseLlmFlow._call_llm_async ), AgentOps creates a dedicated child span, typically named after the LLM model. This span captures request details (prompts, model parameters) and, upon completion (via ADK's _finalize_model_response_event ), records response details like completions, token usage, and finish reasons. Tool Usage Spans (e.g., adk.tool.MyCustomTool ): When an agent uses a tool (via ADK's functions.__call_tool_async ), AgentOps creates a single, comprehensive child span named after the tool. This span includes the tool's input parameters and the result it returns. Rich Attribute Collection: AgentOps reuses ADK's internal data extraction logic. It patches ADK's specific telemetry functions (e.g., google.adk.telemetry.trace_tool_call , trace_call_llm ). The AgentOps wrappers for these functions take the detailed information ADK gathers and attach it as attributes to the currently active AgentOps span . ", "code_blocks": []}, {"heading_path": ["Visualizing Your ADK Agent in AgentOps\u00b6"], "text": "Visualizing Your ADK Agent in AgentOps \u00b6 When you instrument your ADK application with AgentOps, you gain a clear, hierarchical view of your agent's execution in the AgentOps dashboard. Initialization: When agentops.init() is called (e.g., agentops.init(trace_name=\"my_adk_application\") ), an initial parent span is created if the init param auto_start_session=True (true by default). This span, often named similar to my_adk_application.session , will be the root for all operations within that trace. ADK Runner Execution: When an ADK Runner executes a top-level agent (e.g., a SequentialAgent orchestrating a workflow), AgentOps creates a corresponding agent span under the session trace. This span will reflect the name of your top-level ADK agent (e.g., adk.agent.YourMainWorkflowAgent ). Sub-Agent and LLM/Tool Calls: As this main agent executes its logic, including calling sub-agents, LLMs, or tools: Each sub-agent execution will appear as a nested child span under its parent agent. Calls to Large Language Models will generate further nested child spans (e.g., adk.llm.<model_name> ), capturing prompt details, responses, and token usage. Tool invocations will also result in distinct child spans (e.g., adk.tool.<your_tool_name> ), showing their parameters and results. This creates a waterfall of spans, allowing you to see the sequence, duration, and details of each step in your ADK application. All relevant attributes, such as LLM prompts, completions, token counts, tool inputs/outputs, and agent names, are captured and displayed. For a practical demonstration, you can explore a sample Jupyter Notebook that illustrates a human approval workflow using Google ADK and AgentOps: Google ADK Human Approval Example on GitHub . This example showcases how a multi-step agent process with tool usage is visualized in AgentOps. ", "code_blocks": []}, {"heading_path": ["Benefits\u00b6"], "text": "Benefits \u00b6 Effortless Setup: Minimal code changes for comprehensive ADK tracing. Deep Visibility: Understand the inner workings of complex ADK agent flows. Faster Debugging: Quickly pinpoint issues with detailed trace data. Performance Optimization: Analyze latencies and token usage. By integrating AgentOps, ADK developers can significantly enhance their ability to build, debug, and maintain robust AI agents. ", "code_blocks": []}, {"heading_path": ["Further Information\u00b6"], "text": "Further Information \u00b6 To get started, create an AgentOps account . For feature requests or bug reports, please reach out to the AgentOps team on the AgentOps Repo . ", "code_blocks": []}, {"heading_path": ["Extra links\u00b6"], "text": "Extra links \u00b6 \ud83d\udc26 Twitter \u2022   \ud83d\udce2 Discord \u2022   \ud83d\udd87\ufe0f AgentOps Dashboard \u2022   \ud83d\udcd9 Documentation Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:27.540614", "source_type": "adk-docs"}
{"doc_id": "bd13d7cdff37b09e637f030ff059e81e9f65c402be674333b9d3f9c9ecbb8069", "url": "https://google.github.io/adk-docs/observability/arize-ax", "title": "Arize AX - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agent Observability with Arize AX\u00b6"], "text": "Agent Observability with Arize AX \u00b6 Arize AX is a production-grade observability platform for monitoring, debugging, and improving LLM applications and AI Agents at scale. It provides comprehensive tracing, evaluation, and monitoring capabilities for your Google ADK applications. To get started, sign up for a free account . For an open-source, self-hosted alternative, check out Phoenix . ", "code_blocks": []}, {"heading_path": ["Overview\u00b6"], "text": "Overview \u00b6 Arize AX can automatically collect traces from Google ADK using OpenInference instrumentation , allowing you to: Trace agent interactions - Automatically capture every agent run, tool call, model request, and response with context and metadata Evaluate performance - Assess agent behavior using custom or pre-built evaluators and run experiments to test agent configurations Monitor in production - Set up real-time dashboards and alerts to track performance Debug issues - Analyze detailed traces to quickly identify bottlenecks, failed tool calls, and any unexpected agent behavior ", "code_blocks": []}, {"heading_path": ["Installation\u00b6"], "text": "Installation \u00b6 Install the required packages: pip install openinference-instrumentation-google-adk google-adk arize-otel ", "code_blocks": [{"language": "text", "code": "pip install openinference-instrumentation-google-adk google-adk arize-otel"}]}, {"heading_path": ["Setup\u00b6"], "text": "Setup \u00b6 ", "code_blocks": []}, {"heading_path": ["1. Configure Environment Variables\u00b6"], "text": "1. Configure Environment Variables \u00b6 Set your Google API key: export GOOGLE_API_KEY =[ your_key_here ] ", "code_blocks": [{"language": "text", "code": "export GOOGLE_API_KEY=[your_key_here]"}]}, {"heading_path": ["2. Connect your application to Arize AX\u00b6"], "text": "2. Connect your application to Arize AX \u00b6 from arize.otel import register # Register with Arize AX tracer_provider = register ( space_id = \"your-space-id\" , # Found in app space settings page api_key = \"your-api-key\" , # Found in app space settings page project_name = \"your-project-name\" # Name this whatever you prefer ) # Import and configure the automatic instrumentor from OpenInference from openinference.instrumentation.google_adk import GoogleADKInstrumentor # Finish automatic instrumentation GoogleADKInstrumentor () . instrument ( tracer_provider = tracer_provider ) ", "code_blocks": [{"language": "text", "code": "from arize.otel import register\n\n# Register with Arize AX\ntracer_provider = register(\n    space_id=\"your-space-id\",      # Found in app space settings page\n    api_key=\"your-api-key\",        # Found in app space settings page\n    project_name=\"your-project-name\"  # Name this whatever you prefer\n)\n\n# Import and configure the automatic instrumentor from OpenInference\nfrom openinference.instrumentation.google_adk import GoogleADKInstrumentor\n\n# Finish automatic instrumentation\nGoogleADKInstrumentor().instrument(tracer_provider=tracer_provider)"}]}, {"heading_path": ["Observe\u00b6"], "text": "Observe \u00b6 Now that you have tracing setup, all Google ADK SDK requests will be streamed to Arize AX for observability and evaluation. import nest_asyncio nest_asyncio . apply () from google.adk.agents import Agent from google.adk.runners import InMemoryRunner from google.genai import types # Define a tool function def get_weather ( city : str ) -> dict : \"\"\"Retrieves the current weather report for a specified city. Args: city (str): The name of the city for which to retrieve the weather report. Returns: dict: status and result or error msg. \"\"\" if city . lower () == \"new york\" : return { \"status\" : \"success\" , \"report\" : ( \"The weather in New York is sunny with a temperature of 25 degrees\" \" Celsius (77 degrees Fahrenheit).\" ), } else : return { \"status\" : \"error\" , \"error_message\" : f \"Weather information for ' { city } ' is not available.\" , } # Create an agent with tools agent = Agent ( name = \"weather_agent\" , model = \"gemini-2.0-flash-exp\" , description = \"Agent to answer questions using weather tools.\" , instruction = \"You must use the available tools to find an answer.\" , tools = [ get_weather ] ) app_name = \"weather_app\" user_id = \"test_user\" session_id = \"test_session\" runner = InMemoryRunner ( agent = agent , app_name = app_name ) session_service = runner . session_service await session_service . create_session ( app_name = app_name , user_id = user_id , session_id = session_id ) # Run the agent (all interactions will be traced) async for event in runner . run_async ( user_id = user_id , session_id = session_id , new_message = types . Content ( role = \"user\" , parts = [ types . Part ( text = \"What is the weather in New York?\" )] ) ): if event . is_final_response (): print ( event . content . parts [ 0 ] . text . strip ()) ", "code_blocks": [{"language": "text", "code": "import nest_asyncio\nnest_asyncio.apply()\n\nfrom google.adk.agents import Agent\nfrom google.adk.runners import InMemoryRunner\nfrom google.genai import types\n\n# Define a tool function\ndef get_weather(city: str) -> dict:\n    \"\"\"Retrieves the current weather report for a specified city.\n\n    Args:\n        city (str): The name of the city for which to retrieve the weather report.\n\n    Returns:\n        dict: status and result or error msg.\n    \"\"\"\n    if city.lower() == \"new york\":\n        return {\n            \"status\": \"success\",\n            \"report\": (\n                \"The weather in New York is sunny with a temperature of 25 degrees\"\n                \" Celsius (77 degrees Fahrenheit).\"\n            ),\n        }\n    else:\n        return {\n            \"status\": \"error\",\n            \"error_message\": f\"Weather information for '{city}' is not available.\",\n        }\n\n# Create an agent with tools\nagent = Agent(\n    name=\"weather_agent\",\n    model=\"gemini-2.0-flash-exp\",\n    description=\"Agent to answer questions using weather tools.\",\n    instruction=\"You must use the available tools to find an answer.\",\n    tools=[get_weather]\n)\n\napp_name = \"weather_app\"\nuser_id = \"test_user\"\nsession_id = \"test_session\"\nrunner = InMemoryRunner(agent=agent, app_name=app_name)\nsession_service = runner.session_service\n\nawait session_service.create_session(\n    app_name=app_name,\n    user_id=user_id,\n    session_id=session_id\n)\n\n# Run the agent (all interactions will be traced)\nasync for event in runner.run_async(\n    user_id=user_id,\n    session_id=session_id,\n    new_message=types.Content(role=\"user\", parts=[\n        types.Part(text=\"What is the weather in New York?\")]\n    )\n):\n    if event.is_final_response():\n        print(event.content.parts[0].text.strip())"}]}, {"heading_path": ["View Results in Arize AX\u00b6"], "text": "View Results in Arize AX \u00b6 ", "code_blocks": []}, {"heading_path": ["Support and Resources\u00b6"], "text": "Support and Resources \u00b6 Arize AX Documentation Arize Community Slack OpenInference Package Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:28.154847", "source_type": "adk-docs"}
{"doc_id": "021d5b500b93ed39958366fd87748c1de9295c91966b4ff0c637ca67d1c4f740", "url": "https://google.github.io/adk-docs/observability/freeplay", "title": "Freeplay - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agent Observability and Evaluation with Freeplay\u00b6"], "text": "Agent Observability and Evaluation with Freeplay \u00b6 Freeplay provides an end-to-end workflow for building\nand optimizing AI agents, and it can be integrated with ADK. With Freeplay your\nwhole team can easily collaborate to iterate on agent instructions (prompts),\nexperiment with and compare different models and agent changes, run evals both\noffline and online to measure quality, monitor production, and review data by\nhand. Key benefits of Freeplay: Simple observability - focused on agents, LLM calls and tool calls for easy human review Online evals/automated scorers - for error detection in production Offline evals and experiment comparison - to test changes before deploying Prompt management - supports pushing changes straight from the Freeplay playground to code Human review workflow - for collaboration on error analysis and data annotation Powerful UI - makes it possible for domain experts to collaborate closely with engineers Freeplay and ADK complement one another. ADK gives you a powerful and expressive\nagent orchestration framework while Freeplay plugs in for observability, prompt\nmanagement, evaluation and testing. Once you integrate with Freeplay, you can\nupdate prompts and evals from the Freeplay UI or from code, so that anyone on\nyour team can contribute. Click here to see a demo. ", "code_blocks": []}, {"heading_path": ["Getting Started\u00b6"], "text": "Getting Started \u00b6 Below is a guide for getting started with Freeplay and ADK. You can also find a\nfull sample ADK agent repo here . ", "code_blocks": []}, {"heading_path": ["Create a Freeplay Account\u00b6"], "text": "Create a Freeplay Account \u00b6 Sign up for a free Freeplay account . After creating an account, you can define the following environment variables: FREEPLAY_PROJECT_ID= FREEPLAY_API_KEY= FREEPLAY_API_URL= ", "code_blocks": [{"language": "text", "code": "FREEPLAY_PROJECT_ID=\nFREEPLAY_API_KEY=\nFREEPLAY_API_URL="}]}, {"heading_path": ["Use Freeplay ADK Library\u00b6"], "text": "Use Freeplay ADK Library \u00b6 Install the Freeplay ADK library: pip install freeplay-python-adk Freeplay will automatically capture OTel logs from your ADK application when\nyou initialize observability: from freeplay_python_adk.client import FreeplayADK FreeplayADK . initialize_observability () You'll also want to pass in the Freeplay plugin to your App: from app.agent import root_agent from freeplay_python_adk.freeplay_observability_plugin import FreeplayObservabilityPlugin from google.adk.runners import App app = App ( name = \"app\" , root_agent = root_agent , plugins = [ FreeplayObservabilityPlugin ()], ) __all__ = [ \"app\" ] You can now use ADK as you normally would, and you will see logs flowing to\nFreeplay in the Observability section. ", "code_blocks": [{"language": "text", "code": "pip install freeplay-python-adk"}, {"language": "text", "code": "from freeplay_python_adk.client import FreeplayADK\nFreeplayADK.initialize_observability()"}, {"language": "text", "code": "from app.agent import root_agent\nfrom freeplay_python_adk.freeplay_observability_plugin import FreeplayObservabilityPlugin\nfrom google.adk.runners import App\n\napp = App(\n    name=\"app\",\n    root_agent=root_agent,\n    plugins=[FreeplayObservabilityPlugin()],\n)\n\n__all__ = [\"app\"]"}]}, {"heading_path": ["Observability\u00b6"], "text": "Observability \u00b6 Freeplay's Observability feature gives you a clear view into how your agent is\nbehaving in production. You can dig into to individual agent traces to\nunderstand each step and diagnose issues: You can also use Freeplay's filtering functionality to search and filter the\ndata across any segment of interest: ", "code_blocks": []}, {"heading_path": ["Prompt Management (optional)\u00b6"], "text": "Prompt Management (optional) \u00b6 Freeplay offers native prompt management ,\nwhich simplifies the process of version and testing different prompt versions.\nIt allows you to experiment with changes to ADK agent instructions in the\nFreeplay UI, test different models, and push updates straight to your code,\nsimilar to a feature flag. To leverage Freeplay's prompt management capabilities alongside ADK, you'll want\nto use the Freeplay ADK agent wrapper. FreeplayLLMAgent extends ADK's base LlmAgent class, so instead of having to hard code your prompts as agent\ninstructions, you can version prompts in the Freeplay application. First define a prompt in Freeplay by going to Prompts -> Create prompt template: When creating your prompt template you'll need to add 3 elements, as described\nin the following sections: ", "code_blocks": []}, {"heading_path": ["System Message\u00b6"], "text": "System Message \u00b6 This corresponds to the \"instructions\" section in your code. ", "code_blocks": []}, {"heading_path": ["Agent Context Variable\u00b6"], "text": "Agent Context Variable \u00b6 Adding the following to the bottom of your system message will create a variable\nfor the ongoing agent context to be passed through: {{ agent_context }} ", "code_blocks": [{"language": "text", "code": "{{agent_context}}"}]}, {"heading_path": ["History Block\u00b6"], "text": "History Block \u00b6 Click new message and change the role to 'history'. This will ensure the past\nmessages are passed through when present. Now in your code you can use the FreeplayLLMAgent : from freeplay_python_adk.client import FreeplayADK from freeplay_python_adk.freeplay_llm_agent import ( FreeplayLLMAgent , ) FreeplayADK . initialize_observability () root_agent = FreeplayLLMAgent ( name = \"social_product_researcher\" , tools = [ tavily_search ], ) When the social_product_researcher is invoked, the prompt will be\nretrieved from Freeplay and formatted with the proper input variables. ", "code_blocks": [{"language": "text", "code": "from freeplay_python_adk.client import FreeplayADK\nfrom freeplay_python_adk.freeplay_llm_agent import (\n    FreeplayLLMAgent,\n)\n\nFreeplayADK.initialize_observability()\n\nroot_agent = FreeplayLLMAgent(\n    name=\"social_product_researcher\",\n    tools=[tavily_search],\n)"}]}, {"heading_path": ["Evaluation\u00b6"], "text": "Evaluation \u00b6 Freeplay enables you to define, version, and run evaluations from the Freeplay web\napplication. You can define evaluations for any of your prompts or agents by\ngoing to Evaluations -> \"New evaluation\". These evaluations can be configured to run for both online monitoring and\noffline evaluation. Datasets for offline evaluation can be uploaded to Freeplay\nor saved from log examples. ", "code_blocks": []}, {"heading_path": ["Dataset Management\u00b6"], "text": "Dataset Management \u00b6 As you get data flowing into Freeplay, you can use these logs to start building\nup datasets to test against on a\nrepeated basis. Use production logs to create golden datasets or collections of\nfailure cases that you can use to test against as you make changes. ", "code_blocks": []}, {"heading_path": ["Batch Testing\u00b6"], "text": "Batch Testing \u00b6 As you iterate on your agent, you can run batch tests (i.e., offline\nexperiments) at both the prompt and end-to-end agent level.\nThis allows you to compare multiple different models or prompt changes and\nquantify changes head to head across your full agent execution. Here is a code example for executing a batch test on Freeplay with ADK. Here is a code example for executing a batch test on Freeplay with the Google ADK. ", "code_blocks": []}, {"heading_path": ["Sign up now\u00b6"], "text": "Sign up now \u00b6 Go to Freeplay to sign up for an account, and check out a full Freeplay <> ADK Integration here . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:28.555477", "source_type": "adk-docs"}
{"doc_id": "095d9466eb94155fe6fa4345e8cfecd8cf9f8dd09870fa6862201dc8dd32cc2d", "url": "https://google.github.io/adk-docs/observability/monocle", "title": "Monocle - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agent Observability with Monocle\u00b6"], "text": "Agent Observability with Monocle \u00b6 Monocle is an open-source observability platform for monitoring, debugging, and improving LLM applications and AI Agents. It provides comprehensive tracing capabilities for your Google ADK applications through automatic instrumentation. Monocle generates OpenTelemetry-compatible traces that can be exported to various destinations including local files or console output. ", "code_blocks": []}, {"heading_path": ["Overview\u00b6"], "text": "Overview \u00b6 Monocle automatically instruments Google ADK applications, allowing you to: Trace agent interactions - Automatically capture every agent run, tool call, and model request with full context and metadata Monitor execution flow - Track agent state, delegation events, and execution flow through detailed traces Debug issues - Analyze detailed traces to quickly identify bottlenecks, failed tool calls, and unexpected agent behavior Flexible export options - Export traces to local files or console for analysis OpenTelemetry compatible - Generate standard OpenTelemetry traces that work with any OTLP-compatible backend Monocle automatically instruments the following Google ADK components: BaseAgent.run_async - Captures agent execution, agent state, and delegation events FunctionTool.run_async - Captures tool execution, including tool name, parameters, and results Runner.run_async - Captures runner execution, including request context and execution flow ", "code_blocks": []}, {"heading_path": ["Installation\u00b6"], "text": "Installation \u00b6 ", "code_blocks": []}, {"heading_path": ["1. Install Required Packages\u00b6"], "text": "1. Install Required Packages \u00b6 pip install monocle_apptrace google-adk ", "code_blocks": [{"language": "text", "code": "pip install monocle_apptrace google-adk"}]}, {"heading_path": ["Setup\u00b6"], "text": "Setup \u00b6 ", "code_blocks": []}, {"heading_path": ["1. Configure Monocle Telemetry\u00b6"], "text": "1. Configure Monocle Telemetry \u00b6 Monocle automatically instruments Google ADK when you initialize telemetry. Simply call setup_monocle_telemetry() at the start of your application: from monocle_apptrace import setup_monocle_telemetry # Initialize Monocle telemetry - automatically instruments Google ADK setup_monocle_telemetry ( workflow_name = \"my-adk-app\" ) That's it! Monocle will automatically detect and instrument your Google ADK agents, tools, and runners. ", "code_blocks": [{"language": "text", "code": "from monocle_apptrace import setup_monocle_telemetry\n\n# Initialize Monocle telemetry - automatically instruments Google ADK\nsetup_monocle_telemetry(workflow_name=\"my-adk-app\")"}]}, {"heading_path": ["2. Configure Exporters (Optional)\u00b6"], "text": "2. Configure Exporters (Optional) \u00b6 By default, Monocle exports traces to local JSON files. You can configure different exporters using environment variables. ", "code_blocks": []}, {"heading_path": ["Export to Console (for debugging)\u00b6"], "text": "Export to Console (for debugging) \u00b6 Set the environment variable: export MONOCLE_EXPORTER = \"console\" ", "code_blocks": [{"language": "text", "code": "export MONOCLE_EXPORTER=\"console\""}]}, {"heading_path": ["Export to Local Files (default)\u00b6"], "text": "Export to Local Files (default) \u00b6 export MONOCLE_EXPORTER = \"file\" Or simply omit the MONOCLE_EXPORTER variable - it defaults to file . ", "code_blocks": [{"language": "text", "code": "export MONOCLE_EXPORTER=\"file\""}]}, {"heading_path": ["Observe\u00b6"], "text": "Observe \u00b6 Now that you have tracing setup, all Google ADK SDK requests will be automatically traced by Monocle. from monocle_apptrace import setup_monocle_telemetry from google.adk.agents import Agent from google.adk.runners import InMemoryRunner from google.genai import types # Initialize Monocle telemetry - must be called before using ADK setup_monocle_telemetry ( workflow_name = \"weather_app\" ) # Define a tool function def get_weather ( city : str ) -> dict : \"\"\"Retrieves the current weather report for a specified city. Args: city (str): The name of the city for which to retrieve the weather report. Returns: dict: status and result or error msg. \"\"\" if city . lower () == \"new york\" : return { \"status\" : \"success\" , \"report\" : ( \"The weather in New York is sunny with a temperature of 25 degrees\" \" Celsius (77 degrees Fahrenheit).\" ), } else : return { \"status\" : \"error\" , \"error_message\" : f \"Weather information for ' { city } ' is not available.\" , } # Create an agent with tools agent = Agent ( name = \"weather_agent\" , model = \"gemini-2.0-flash-exp\" , description = \"Agent to answer questions using weather tools.\" , instruction = \"You must use the available tools to find an answer.\" , tools = [ get_weather ] ) app_name = \"weather_app\" user_id = \"test_user\" session_id = \"test_session\" runner = InMemoryRunner ( agent = agent , app_name = app_name ) session_service = runner . session_service await session_service . create_session ( app_name = app_name , user_id = user_id , session_id = session_id ) # Run the agent (all interactions will be automatically traced) async for event in runner . run_async ( user_id = user_id , session_id = session_id , new_message = types . Content ( role = \"user\" , parts = [ types . Part ( text = \"What is the weather in New York?\" )] ) ): if event . is_final_response (): print ( event . content . parts [ 0 ] . text . strip ()) ", "code_blocks": [{"language": "text", "code": "from monocle_apptrace import setup_monocle_telemetry\nfrom google.adk.agents import Agent\nfrom google.adk.runners import InMemoryRunner\nfrom google.genai import types\n\n# Initialize Monocle telemetry - must be called before using ADK\nsetup_monocle_telemetry(workflow_name=\"weather_app\")\n\n# Define a tool function\ndef get_weather(city: str) -> dict:\n    \"\"\"Retrieves the current weather report for a specified city.\n\n    Args:\n        city (str): The name of the city for which to retrieve the weather report.\n\n    Returns:\n        dict: status and result or error msg.\n    \"\"\"\n    if city.lower() == \"new york\":\n        return {\n            \"status\": \"success\",\n            \"report\": (\n                \"The weather in New York is sunny with a temperature of 25 degrees\"\n                \" Celsius (77 degrees Fahrenheit).\"\n            ),\n        }\n    else:\n        return {\n            \"status\": \"error\",\n            \"error_message\": f\"Weather information for '{city}' is not available.\",\n        }\n\n# Create an agent with tools\nagent = Agent(\n    name=\"weather_agent\",\n    model=\"gemini-2.0-flash-exp\",\n    description=\"Agent to answer questions using weather tools.\",\n    instruction=\"You must use the available tools to find an answer.\",\n    tools=[get_weather]\n)\n\napp_name = \"weather_app\"\nuser_id = \"test_user\"\nsession_id = \"test_session\"\nrunner = InMemoryRunner(agent=agent, app_name=app_name)\nsession_service = runner.session_service\n\nawait session_service.create_session(\n    app_name=app_name,\n    user_id=user_id,\n    session_id=session_id\n)\n\n# Run the agent (all interactions will be automatically traced)\nasync for event in runner.run_async(\n    user_id=user_id,\n    session_id=session_id,\n    new_message=types.Content(role=\"user\", parts=[\n        types.Part(text=\"What is the weather in New York?\")]\n    )\n):\n    if event.is_final_response():\n        print(event.content.parts[0].text.strip())"}]}, {"heading_path": ["Accessing Traces\u00b6"], "text": "Accessing Traces \u00b6 By default, Monocle generates traces in JSON files in the local directory ./monocle . The file name format is: monocle_trace_{workflow_name}_{trace_id}_{timestamp}.json Each trace file contains an array of OpenTelemetry-compatible spans that capture: Agent execution spans - Agent state, delegation events, and execution flow Tool execution spans - Tool name, input parameters, and output results LLM interaction spans - Model calls, prompts, responses, and token usage (if using Gemini or other LLMs) You can analyze these trace files using any OpenTelemetry-compatible tool or write custom analysis scripts. ", "code_blocks": [{"language": "text", "code": "monocle_trace_{workflow_name}_{trace_id}_{timestamp}.json"}]}, {"heading_path": ["Visualizing Traces with VS Code Extension\u00b6"], "text": "Visualizing Traces with VS Code Extension \u00b6 The Okahu Trace Visualizer VS Code extension provides an interactive way to visualize and analyze Monocle-generated traces directly in Visual Studio Code. ", "code_blocks": []}, {"heading_path": ["Installation\u00b6"], "text": "Installation \u00b6 Open VS Code Press Ctrl+P (or Cmd+P on Mac) to open Quick Open Paste the following command and press Enter: ext install OkahuAI.okahu-ai-observability Alternatively, you can install it from the VS Code Marketplace . ", "code_blocks": [{"language": "text", "code": "ext install OkahuAI.okahu-ai-observability"}]}, {"heading_path": ["Features\u00b6"], "text": "Features \u00b6 The extension provides: Custom Activity Bar Panel - Dedicated sidebar for trace file management Interactive File Tree - Browse and select trace files with custom React UI Split View Analysis - Gantt chart visualization alongside JSON data viewer Real-time Communication - Seamless data flow between VS Code and React components VS Code Theming - Fully integrated with VS Code's light/dark themes ", "code_blocks": []}, {"heading_path": ["Usage\u00b6"], "text": "Usage \u00b6 After running your ADK application with Monocle tracing enabled, trace files will be generated in the ./monocle directory Open the Okahu Trace Visualizer panel from the VS Code Activity Bar Browse and select trace files from the interactive file tree View your traces with: Gantt chart visualization - See the timeline and hierarchy of spans JSON data viewer - Inspect detailed span attributes and events Token counts - View token usage for LLM calls Error badges - Quickly identify failed operations ", "code_blocks": []}, {"heading_path": ["What Gets Traced\u00b6"], "text": "What Gets Traced \u00b6 Monocle automatically captures the following information from Google ADK: Agent Execution : Agent state, delegation events, and execution flow Tool Calls : Tool name, input parameters, and output results Runner Execution : Request context and overall execution flow Timing Information : Start time, end time, and duration for each operation Error Information : Exceptions and error states All traces are generated in OpenTelemetry format, making them compatible with any OTLP-compatible observability backend. ", "code_blocks": []}, {"heading_path": ["Support and Resources\u00b6"], "text": "Support and Resources \u00b6 Monocle Documentation Monocle GitHub Repository Google ADK Travel Agent Example Discord Community Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:29.043373", "source_type": "adk-docs"}
{"doc_id": "6d975a611294bebf17303d3dbd558a3832e27b3f3433f35276eaefea1fec93a8", "url": "https://google.github.io/adk-docs/observability/phoenix", "title": "Phoenix - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agent Observability with Phoenix\u00b6"], "text": "Agent Observability with Phoenix \u00b6 Phoenix is an open-source, self-hosted observability platform for monitoring, debugging, and improving LLM applications and AI Agents at scale. It provides comprehensive tracing and evaluation capabilities for your Google ADK applications. To get started, sign up for a free account . ", "code_blocks": []}, {"heading_path": ["Overview\u00b6"], "text": "Overview \u00b6 Phoenix can automatically collect traces from Google ADK using OpenInference instrumentation , allowing you to: Trace agent interactions - Automatically capture every agent run, tool call, model request, and response with full context and metadata Evaluate performance - Assess agent behavior using custom or pre-built evaluators and run experiments to test agent configurations Debug issues - Analyze detailed traces to quickly identify bottlenecks, failed tool calls, and unexpected agent behavior Self-hosted control - Keep your data on your own infrastructure ", "code_blocks": []}, {"heading_path": ["Installation\u00b6"], "text": "Installation \u00b6 ", "code_blocks": []}, {"heading_path": ["1. Install Required Packages\u00b6"], "text": "1. Install Required Packages \u00b6 pip install openinference-instrumentation-google-adk google-adk arize-phoenix-otel ", "code_blocks": [{"language": "text", "code": "pip install openinference-instrumentation-google-adk google-adk arize-phoenix-otel"}]}, {"heading_path": ["Setup\u00b6"], "text": "Setup \u00b6 ", "code_blocks": []}, {"heading_path": ["1. Launch Phoenix\u00b6"], "text": "1. Launch Phoenix \u00b6 These instructions show you how to use Phoenix Cloud. You can also launch Phoenix in a notebook, from your terminal, or self-host it using a container. Sign up for a free Phoenix account . From the Settings page of your new Phoenix Space, create your API key Copy your endpoint which should look like: https://app.phoenix.arize.com/s/[your-space-name] Set your Phoenix endpoint and API Key: import os os . environ [ \"PHOENIX_API_KEY\" ] = \"ADD YOUR PHOENIX API KEY\" os . environ [ \"PHOENIX_COLLECTOR_ENDPOINT\" ] = \"ADD YOUR PHOENIX COLLECTOR ENDPOINT\" # If you created your Phoenix Cloud instance before June 24th, 2025, set the API key as a header: # os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={os.getenv('PHOENIX_API_KEY')}\" ", "code_blocks": [{"language": "text", "code": "import os\n\nos.environ[\"PHOENIX_API_KEY\"] = \"ADD YOUR PHOENIX API KEY\"\nos.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"ADD YOUR PHOENIX COLLECTOR ENDPOINT\"\n\n# If you created your Phoenix Cloud instance before June 24th, 2025, set the API key as a header:\n# os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={os.getenv('PHOENIX_API_KEY')}\""}]}, {"heading_path": ["2.  Connect your application to Phoenix\u00b6"], "text": "2.  Connect your application to Phoenix \u00b6 from phoenix.otel import register # Configure the Phoenix tracer tracer_provider = register ( project_name = \"my-llm-app\" , # Default is 'default' auto_instrument = True # Auto-instrument your app based on installed OI dependencies ) ", "code_blocks": [{"language": "text", "code": "from phoenix.otel import register\n\n# Configure the Phoenix tracer\ntracer_provider = register(\n    project_name=\"my-llm-app\",  # Default is 'default'\n    auto_instrument=True        # Auto-instrument your app based on installed OI dependencies\n)"}]}, {"heading_path": ["Observe\u00b6"], "text": "Observe \u00b6 Now that you have tracing setup, all Google ADK SDK requests will be streamed to Phoenix for observability and evaluation. import nest_asyncio nest_asyncio . apply () from google.adk.agents import Agent from google.adk.runners import InMemoryRunner from google.genai import types # Define a tool function def get_weather ( city : str ) -> dict : \"\"\"Retrieves the current weather report for a specified city. Args: city (str): The name of the city for which to retrieve the weather report. Returns: dict: status and result or error msg. \"\"\" if city . lower () == \"new york\" : return { \"status\" : \"success\" , \"report\" : ( \"The weather in New York is sunny with a temperature of 25 degrees\" \" Celsius (77 degrees Fahrenheit).\" ), } else : return { \"status\" : \"error\" , \"error_message\" : f \"Weather information for ' { city } ' is not available.\" , } # Create an agent with tools agent = Agent ( name = \"weather_agent\" , model = \"gemini-2.0-flash-exp\" , description = \"Agent to answer questions using weather tools.\" , instruction = \"You must use the available tools to find an answer.\" , tools = [ get_weather ] ) app_name = \"weather_app\" user_id = \"test_user\" session_id = \"test_session\" runner = InMemoryRunner ( agent = agent , app_name = app_name ) session_service = runner . session_service await session_service . create_session ( app_name = app_name , user_id = user_id , session_id = session_id ) # Run the agent (all interactions will be traced) async for event in runner . run_async ( user_id = user_id , session_id = session_id , new_message = types . Content ( role = \"user\" , parts = [ types . Part ( text = \"What is the weather in New York?\" )] ) ): if event . is_final_response (): print ( event . content . parts [ 0 ] . text . strip ()) ", "code_blocks": [{"language": "text", "code": "import nest_asyncio\nnest_asyncio.apply()\n\nfrom google.adk.agents import Agent\nfrom google.adk.runners import InMemoryRunner\nfrom google.genai import types\n\n# Define a tool function\ndef get_weather(city: str) -> dict:\n    \"\"\"Retrieves the current weather report for a specified city.\n\n    Args:\n        city (str): The name of the city for which to retrieve the weather report.\n\n    Returns:\n        dict: status and result or error msg.\n    \"\"\"\n    if city.lower() == \"new york\":\n        return {\n            \"status\": \"success\",\n            \"report\": (\n                \"The weather in New York is sunny with a temperature of 25 degrees\"\n                \" Celsius (77 degrees Fahrenheit).\"\n            ),\n        }\n    else:\n        return {\n            \"status\": \"error\",\n            \"error_message\": f\"Weather information for '{city}' is not available.\",\n        }\n\n# Create an agent with tools\nagent = Agent(\n    name=\"weather_agent\",\n    model=\"gemini-2.0-flash-exp\",\n    description=\"Agent to answer questions using weather tools.\",\n    instruction=\"You must use the available tools to find an answer.\",\n    tools=[get_weather]\n)\n\napp_name = \"weather_app\"\nuser_id = \"test_user\"\nsession_id = \"test_session\"\nrunner = InMemoryRunner(agent=agent, app_name=app_name)\nsession_service = runner.session_service\n\nawait session_service.create_session(\n    app_name=app_name,\n    user_id=user_id,\n    session_id=session_id\n)\n\n# Run the agent (all interactions will be traced)\nasync for event in runner.run_async(\n    user_id=user_id,\n    session_id=session_id,\n    new_message=types.Content(role=\"user\", parts=[\n        types.Part(text=\"What is the weather in New York?\")]\n    )\n):\n    if event.is_final_response():\n        print(event.content.parts[0].text.strip())"}]}, {"heading_path": ["Support and Resources\u00b6"], "text": "Support and Resources \u00b6 Phoenix Documentation Community Slack OpenInference Package Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:29.568991", "source_type": "adk-docs"}
{"doc_id": "778bb1f4b93061c6233c5ff877c6579933ebe07055107c025a14b842e64bda5a", "url": "https://google.github.io/adk-docs/observability/weave", "title": "W&B Weave - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agent Observability with Weave by WandB\u00b6"], "text": "Agent Observability with Weave by WandB \u00b6 Weave by Weights & Biases (WandB) provides a powerful platform for logging and visualizing model calls. By integrating Google ADK with Weave, you can track and analyze your agent's performance and behavior using OpenTelemetry (OTEL) traces. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Sign up for an account at WandB . Obtain your API key from WandB Authorize . Configure your environment with the required API keys: export WANDB_API_KEY = <your-wandb-api-key> export GOOGLE_API_KEY = <your-google-api-key> ", "code_blocks": [{"language": "text", "code": "export WANDB_API_KEY=<your-wandb-api-key>\nexport GOOGLE_API_KEY=<your-google-api-key>"}]}, {"heading_path": ["Install Dependencies\u00b6"], "text": "Install Dependencies \u00b6 Ensure you have the necessary packages installed: pip install google-adk opentelemetry-sdk opentelemetry-exporter-otlp-proto-http ", "code_blocks": [{"language": "text", "code": "pip install google-adk opentelemetry-sdk opentelemetry-exporter-otlp-proto-http"}]}, {"heading_path": ["Sending Traces to Weave\u00b6"], "text": "Sending Traces to Weave \u00b6 This example demonstrates how to configure OpenTelemetry to send Google ADK traces to Weave. # math_agent/agent.py import base64 import os from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter from opentelemetry.sdk import trace as trace_sdk from opentelemetry.sdk.trace.export import SimpleSpanProcessor from opentelemetry import trace from google.adk.agents import LlmAgent from google.adk.tools import FunctionTool from dotenv import load_dotenv load_dotenv () # Configure Weave endpoint and authentication WANDB_BASE_URL = \"https://trace.wandb.ai\" PROJECT_ID = \"your-entity/your-project\" # e.g., \"teamid/projectid\" OTEL_EXPORTER_OTLP_ENDPOINT = f \" { WANDB_BASE_URL } /otel/v1/traces\" # Set up authentication WANDB_API_KEY = os . getenv ( \"WANDB_API_KEY\" ) AUTH = base64 . b64encode ( f \"api: { WANDB_API_KEY } \" . encode ()) . decode () OTEL_EXPORTER_OTLP_HEADERS = { \"Authorization\" : f \"Basic { AUTH } \" , \"project_id\" : PROJECT_ID , } # Create the OTLP span exporter with endpoint and headers exporter = OTLPSpanExporter ( endpoint = OTEL_EXPORTER_OTLP_ENDPOINT , headers = OTEL_EXPORTER_OTLP_HEADERS , ) # Create a tracer provider and add the exporter tracer_provider = trace_sdk . TracerProvider () tracer_provider . add_span_processor ( SimpleSpanProcessor ( exporter )) # Set the global tracer provider BEFORE importing/using ADK trace . set_tracer_provider ( tracer_provider ) # Define a simple tool for demonstration def calculator ( a : float , b : float ) -> str : \"\"\"Add two numbers and return the result. Args: a: First number b: Second number Returns: The sum of a and b \"\"\" return str ( a + b ) calculator_tool = FunctionTool ( func = calculator ) # Create an LLM agent root_agent = LlmAgent ( name = \"MathAgent\" , model = \"gemini-2.0-flash-exp\" , instruction = ( \"You are a helpful assistant that can do math. \" \"When asked a math problem, use the calculator tool to solve it.\" ), tools = [ calculator_tool ], ) ", "code_blocks": [{"language": "text", "code": "# math_agent/agent.py\n\nimport base64\nimport os\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk import trace as trace_sdk\nfrom opentelemetry.sdk.trace.export import SimpleSpanProcessor\nfrom opentelemetry import trace\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools import FunctionTool\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Configure Weave endpoint and authentication\nWANDB_BASE_URL = \"https://trace.wandb.ai\"\nPROJECT_ID = \"your-entity/your-project\"  # e.g., \"teamid/projectid\"\nOTEL_EXPORTER_OTLP_ENDPOINT = f\"{WANDB_BASE_URL}/otel/v1/traces\"\n\n# Set up authentication\nWANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\nAUTH = base64.b64encode(f\"api:{WANDB_API_KEY}\".encode()).decode()\n\nOTEL_EXPORTER_OTLP_HEADERS = {\n    \"Authorization\": f\"Basic {AUTH}\",\n    \"project_id\": PROJECT_ID,\n}\n\n# Create the OTLP span exporter with endpoint and headers\nexporter = OTLPSpanExporter(\n    endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,\n    headers=OTEL_EXPORTER_OTLP_HEADERS,\n)\n\n# Create a tracer provider and add the exporter\ntracer_provider = trace_sdk.TracerProvider()\ntracer_provider.add_span_processor(SimpleSpanProcessor(exporter))\n\n# Set the global tracer provider BEFORE importing/using ADK\ntrace.set_tracer_provider(tracer_provider)\n\n# Define a simple tool for demonstration\ndef calculator(a: float, b: float) -> str:\n    \"\"\"Add two numbers and return the result.\n\n    Args:\n        a: First number\n        b: Second number\n\n    Returns:\n        The sum of a and b\n    \"\"\"\n    return str(a + b)\n\ncalculator_tool = FunctionTool(func=calculator)\n\n# Create an LLM agent\nroot_agent = LlmAgent(\n    name=\"MathAgent\",\n    model=\"gemini-2.0-flash-exp\",\n    instruction=(\n        \"You are a helpful assistant that can do math. \"\n        \"When asked a math problem, use the calculator tool to solve it.\"\n    ),\n    tools=[calculator_tool],\n)"}]}, {"heading_path": ["View Traces in Weave dashboard\u00b6"], "text": "View Traces in Weave dashboard \u00b6 Once the agent runs, all its traces are logged to the corresponding project on the Weave dashboard . You can view a timeline of calls that your ADK agent made during execution - ", "code_blocks": []}, {"heading_path": ["Notes\u00b6"], "text": "Notes \u00b6 Environment Variables : Ensure your environment variables are correctly set for both WandB and Google API keys. Project Configuration : Replace <your-entity>/<your-project> with your actual WandB entity and project name. Entity Name : You can find your entity name by visiting your WandB dashboard and checking the Teams field in the left sidebar. Tracer Provider : It's critical to set the global tracer provider before using any ADK components to ensure proper tracing. By following these steps, you can effectively integrate Google ADK with Weave, enabling comprehensive logging and visualization of your AI agents' model calls, tool invocations, and reasoning processes. ", "code_blocks": []}, {"heading_path": ["Resources\u00b6"], "text": "Resources \u00b6 Send OpenTelemetry Traces to Weave - Comprehensive guide on configuring OTEL with Weave, including authentication and advanced configuration options. Navigate the Trace View - Learn how to effectively analyze and debug your traces in the Weave UI, including understanding trace hierarchies and span details. Weave Integrations - Explore other framework integrations and see how Weave can work with your entire AI stack. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:30.040180", "source_type": "adk-docs"}
{"doc_id": "947561f5e3dde2dacd79c02402c8d67f573a899f3d8b764569453c0112d3ee11", "url": "https://google.github.io/adk-docs/evaluate", "title": "Why Evaluate Agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Why Evaluate Agents\u00b6"], "text": "Why Evaluate Agents \u00b6 Supported in ADK Python In traditional software development, unit tests and integration tests provide confidence that code functions as expected and remains stable through changes. These tests provide a clear \"pass/fail\" signal, guiding further development. However, LLM agents introduce a level of variability that makes traditional testing approaches insufficient. Due to the probabilistic nature of models, deterministic \"pass/fail\" assertions are often unsuitable for evaluating agent performance. Instead, we need qualitative evaluations of both the final output and the agent's trajectory - the sequence of steps taken to reach the solution. This involves assessing the quality of the agent's decisions, its reasoning process, and the final result. This may seem like a lot of extra work to set up, but the investment of automating evaluations pays off quickly. If you intend to progress beyond prototype, this is a highly recommended best practice. ", "code_blocks": []}, {"heading_path": ["Preparing for Agent Evaluations\u00b6"], "text": "Preparing for Agent Evaluations \u00b6 Before automating agent evaluations, define clear objectives and success criteria: Define Success: What constitutes a successful outcome for your agent? Identify Critical Tasks: What are the essential tasks your agent must accomplish? Choose Relevant Metrics: What metrics will you track to measure performance? These considerations will guide the creation of evaluation scenarios and enable effective monitoring of agent behavior in real-world deployments. ", "code_blocks": []}, {"heading_path": ["What to Evaluate?\u00b6"], "text": "What to Evaluate? \u00b6 To bridge the gap between a proof-of-concept and a production-ready AI agent, a robust and automated evaluation framework is essential. Unlike evaluating generative models, where the focus is primarily on the final output, agent evaluation requires a deeper understanding of the decision-making process. Agent evaluation can be broken down into two components: Evaluating Trajectory and Tool Use: Analyzing the steps an agent takes to reach a solution, including its choice of tools, strategies, and the efficiency of its approach. Evaluating the Final Response: Assessing the quality, relevance, and correctness of the agent's final output. The trajectory is just a list of steps the agent took before it returned to the user. We can compare that against the list of steps we expect the agent to have taken. ", "code_blocks": []}, {"heading_path": ["Evaluating trajectory and tool use\u00b6"], "text": "Evaluating trajectory and tool use \u00b6 Before responding to a user, an agent typically performs a series of actions, which we refer to as a 'trajectory.' It might compare the user input with session history to disambiguate a term, or lookup a policy document, search a knowledge base or invoke an API to save a ticket. We call this a \u2018trajectory\u2019 of actions. Evaluating an agent's performance requires comparing its actual trajectory to an expected, or ideal, one. This comparison can reveal errors and inefficiencies in the agent's process. The expected trajectory represents the ground truth -- the list of steps we anticipate the agent should take. For example: # Trajectory evaluation will compare expected_steps = [ \"determine_intent\" , \"use_tool\" , \"review_results\" , \"report_generation\" ] actual_steps = [ \"determine_intent\" , \"use_tool\" , \"review_results\" , \"report_generation\" ] ADK provides both groundtruth based and rubric based tool use evaluation metrics. To select the appropriate metric for your agent's specific requirements and goals, please refer to our recommendations . ", "code_blocks": [{"language": "text", "code": "# Trajectory evaluation will compare\nexpected_steps = [\"determine_intent\", \"use_tool\", \"review_results\", \"report_generation\"]\nactual_steps = [\"determine_intent\", \"use_tool\", \"review_results\", \"report_generation\"]"}]}, {"heading_path": ["How Evaluation works with the ADK\u00b6"], "text": "How Evaluation works with the ADK \u00b6 The ADK offers two methods for evaluating agent performance against predefined datasets and evaluation criteria. While conceptually similar, they differ in the amount of data they can process, which typically dictates the appropriate use case for each. ", "code_blocks": []}, {"heading_path": ["First approach: Using a test file\u00b6"], "text": "First approach: Using a test file \u00b6 This approach involves creating individual test files, each representing a single, simple agent-model interaction (a session). It's most effective during active agent development, serving as a form of unit testing. These tests are designed for rapid execution and should focus on simple session complexity. Each test file contains a single session, which may consist of multiple turns. A turn represents a single interaction between the user and the agent. Each turn includes User Content : The user issued query. Expected Intermediate Tool Use Trajectory : The tool calls we expect the\n    agent to make in order to respond correctly to the user query. Expected Intermediate Agent Responses : These are the natural language\n    responses that the agent (or sub-agents) generates as it moves towards\n    generating a final answer. These natural language responses are usually an\n    artifact of an multi-agent system, where your root agent depends on sub-agents to achieve a goal. These intermediate responses, may or may not be of\n    interest to the end user, but for a developer/owner of the system, are of\n    critical importance, as they give you the confidence that the agent went\n    through the right path to generate final response. Final Response : The expected final response from the agent. You can give the file any name for example evaluation.test.json .The framework only checks for the .test.json suffix, and the preceding part of the filename is not constrained. The test files are backed by a formal Pydantic data model. The two key schema files are Eval Set and Eval Case .\nHere is a test file with a few examples: (Note: Comments are included for explanatory purposes and should be removed for the JSON to be valid.) # Do n o te t ha t some f ields are removed f or sake o f maki n g t his doc readable. { \"eval_set_id\" : \"home_automation_agent_light_on_off_set\" , \"name\" : \"\" , \"description\" : \"This is an eval set that is used for unit testing `x` behavior of the Agent\" , \"eval_cases\" : [ { \"eval_id\" : \"eval_case_id\" , \"conversation\" : [ { \"invocation_id\" : \"b7982664-0ab6-47cc-ab13-326656afdf75\" , # U n ique ide nt i f ier f or t he i n voca t io n . \"user_content\" : { # Co ntent provided by t he user i n t his i n voca t io n . This is t he query. \"parts\" : [ { \"text\" : \"Turn off device_2 in the Bedroom.\" } ], \"role\" : \"user\" }, \"final_response\" : { # Fi nal respo nse fr om t he age nt t ha t ac ts as a re feren ce o f be n chmark. \"parts\" : [ { \"text\" : \"I have set the device_2 status to off.\" } ], \"role\" : \"model\" }, \"intermediate_data\" : { \"tool_uses\" : [ # Tool use tra jec t ory i n chro n ological order. { \"args\" : { \"location\" : \"Bedroom\" , \"device_id\" : \"device_2\" , \"status\" : \"OFF\" }, \"name\" : \"set_device_info\" } ], \"intermediate_responses\" : [] # A n y i nter media te sub - age nt respo nses . }, } ], \"session_input\" : { # I n i t ial sessio n i n pu t . \"app_name\" : \"home_automation_agent\" , \"user_id\" : \"test_user\" , \"state\" : {} }, } ], } Test files can be organized into folders. Optionally, a folder can also include a test_config.json file that specifies the evaluation criteria. ", "code_blocks": [{"language": "text", "code": "# Do note that some fields are removed for sake of making this doc readable.\n{\n  \"eval_set_id\": \"home_automation_agent_light_on_off_set\",\n  \"name\": \"\",\n  \"description\": \"This is an eval set that is used for unit testing `x` behavior of the Agent\",\n  \"eval_cases\": [\n    {\n      \"eval_id\": \"eval_case_id\",\n      \"conversation\": [\n        {\n          \"invocation_id\": \"b7982664-0ab6-47cc-ab13-326656afdf75\", # Unique identifier for the invocation.\n          \"user_content\": { # Content provided by the user in this invocation. This is the query.\n            \"parts\": [\n              {\n                \"text\": \"Turn off device_2 in the Bedroom.\"\n              }\n            ],\n            \"role\": \"user\"\n          },\n          \"final_response\": { # Final response from the agent that acts as a reference of benchmark.\n            \"parts\": [\n              {\n                \"text\": \"I have set the device_2 status to off.\"\n              }\n            ],\n            \"role\": \"model\"\n          },\n          \"intermediate_data\": {\n            \"tool_uses\": [ # Tool use trajectory in chronological order.\n              {\n                \"args\": {\n                  \"location\": \"Bedroom\",\n                  \"device_id\": \"device_2\",\n                  \"status\": \"OFF\"\n                },\n                \"name\": \"set_device_info\"\n              }\n            ],\n            \"intermediate_responses\": [] # Any intermediate sub-agent responses.\n          },\n        }\n      ],\n      \"session_input\": { # Initial session input.\n        \"app_name\": \"home_automation_agent\",\n        \"user_id\": \"test_user\",\n        \"state\": {}\n      },\n    }\n  ],\n}"}]}, {"heading_path": ["How to migrate test files not backed by the Pydantic schema?\u00b6"], "text": "How to migrate test files not backed by the Pydantic schema? \u00b6 NOTE: If your test files don't adhere to EvalSet schema file, then this section is relevant to you. Please use AgentEvaluator.migrate_eval_data_to_new_schema to migrate your\nexisting *.test.json files to the Pydantic backed schema. The utility takes your current test data file and an optional initial session\nfile, and generates a single output json file with data serialized in the new\nformat. Given that the new schema is more cohesive, both the old test data file\nand initial session file can be ignored (or removed.) ", "code_blocks": []}, {"heading_path": ["Second approach: Using An Evalset File\u00b6"], "text": "Second approach: Using An Evalset File \u00b6 The evalset approach utilizes a dedicated dataset called an \"evalset\" for evaluating agent-model interactions. Similar to a test file, the evalset contains example interactions. However, an evalset can contain multiple, potentially lengthy sessions, making it ideal for simulating complex, multi-turn conversations. Due to its ability to represent complex sessions, the evalset is well-suited for integration tests. These tests are typically run less frequently than unit tests due to their more extensive nature. An evalset file contains multiple \"evals,\" each representing a distinct session. Each eval consists of one or more \"turns,\" which include the user query, expected tool use, expected intermediate agent responses, and a reference response. These fields have the same meaning as they do in the test file approach. Alternatively, an eval can define a conversation scenario which is used to dynamically simulate a user interaction with the agent. Each eval is identified by a unique name. Furthermore, each eval includes an associated initial session state. Creating evalsets manually can be complex, therefore UI tools are provided to help capture relevant sessions and easily convert them into evals within your evalset. Learn more about using the web UI for evaluation below. Here is an example evalset containing two sessions. The eval set files are  backed by a formal Pydantic data model. The two key schema files are Eval Set and Eval Case . Warning This evalset evaluation method requires the use of a paid service, Vertex Gen AI Evaluation Service API . (Note: Comments are included for explanatory purposes and should be removed for the JSON to be valid.) # Do n o te t ha t some f ields are removed f or sake o f maki n g t his doc readable. { \"eval_set_id\" : \"eval_set_example_with_multiple_sessions\" , \"name\" : \"Eval set with multiple sessions\" , \"description\" : \"This eval set is an example that shows that an eval set can have more than one session.\" , \"eval_cases\" : [ { \"eval_id\" : \"session_01\" , \"conversation\" : [ { \"invocation_id\" : \"e-0067f6c4-ac27-4f24-81d7-3ab994c28768\" , \"user_content\" : { \"parts\" : [ { \"text\" : \"What can you do?\" } ], \"role\" : \"user\" }, \"final_response\" : { \"parts\" : [ { \"text\" : \"I can roll dice of different sizes and check if numbers are prime.\" } ], \"role\" : null }, \"intermediate_data\" : { \"tool_uses\" : [], \"intermediate_responses\" : [] }, }, ], \"session_input\" : { \"app_name\" : \"hello_world\" , \"user_id\" : \"user\" , \"state\" : {} }, }, { \"eval_id\" : \"session_02\" , \"conversation\" : [ { \"invocation_id\" : \"e-92d34c6d-0a1b-452a-ba90-33af2838647a\" , \"user_content\" : { \"parts\" : [ { \"text\" : \"Roll a 19 sided dice\" } ], \"role\" : \"user\" }, \"final_response\" : { \"parts\" : [ { \"text\" : \"I rolled a 17.\" } ], \"role\" : null }, \"intermediate_data\" : { \"tool_uses\" : [], \"intermediate_responses\" : [] }, }, { \"invocation_id\" : \"e-bf8549a1-2a61-4ecc-a4ee-4efbbf25a8ea\" , \"user_content\" : { \"parts\" : [ { \"text\" : \"Roll a 10 sided dice twice and then check if 9 is a prime or not\" } ], \"role\" : \"user\" }, \"final_response\" : { \"parts\" : [ { \"text\" : \"I got 4 and 7 from the dice roll, and 9 is not a prime number.\\n\" } ], \"role\" : null }, \"intermediate_data\" : { \"tool_uses\" : [ { \"id\" : \"adk-1a3f5a01-1782-4530-949f-07cf53fc6f05\" , \"args\" : { \"sides\" : 10 }, \"name\" : \"roll_die\" }, { \"id\" : \"adk-52fc3269-caaf-41c3-833d-511e454c7058\" , \"args\" : { \"sides\" : 10 }, \"name\" : \"roll_die\" }, { \"id\" : \"adk-5274768e-9ec5-4915-b6cf-f5d7f0387056\" , \"args\" : { \"nums\" : [ 9 ] }, \"name\" : \"check_prime\" } ], \"intermediate_responses\" : [ [ \"data_processing_agent\" , [ { \"text\" : \"I have rolled a 10 sided die twice. The first roll is 5 and the second roll is 3.\\n\" } ] ] ] }, } ], \"session_input\" : { \"app_name\" : \"hello_world\" , \"user_id\" : \"user\" , \"state\" : {} }, } ], } ", "code_blocks": [{"language": "text", "code": "# Do note that some fields are removed for sake of making this doc readable.\n{\n  \"eval_set_id\": \"eval_set_example_with_multiple_sessions\",\n  \"name\": \"Eval set with multiple sessions\",\n  \"description\": \"This eval set is an example that shows that an eval set can have more than one session.\",\n  \"eval_cases\": [\n    {\n      \"eval_id\": \"session_01\",\n      \"conversation\": [\n        {\n          \"invocation_id\": \"e-0067f6c4-ac27-4f24-81d7-3ab994c28768\",\n          \"user_content\": {\n            \"parts\": [\n              {\n                \"text\": \"What can you do?\"\n              }\n            ],\n            \"role\": \"user\"\n          },\n          \"final_response\": {\n            \"parts\": [\n              {\n\n                \"text\": \"I can roll dice of different sizes and check if numbers are prime.\"\n              }\n            ],\n            \"role\": null\n          },\n          \"intermediate_data\": {\n            \"tool_uses\": [],\n            \"intermediate_responses\": []\n          },\n        },\n      ],\n      \"session_input\": {\n        \"app_name\": \"hello_world\",\n        \"user_id\": \"user\",\n        \"state\": {}\n      },\n    },\n    {\n      \"eval_id\": \"session_02\",\n      \"conversation\": [\n        {\n          \"invocation_id\": \"e-92d34c6d-0a1b-452a-ba90-33af2838647a\",\n          \"user_content\": {\n            \"parts\": [\n              {\n                \"text\": \"Roll a 19 sided dice\"\n              }\n            ],\n            \"role\": \"user\"\n          },\n          \"final_response\": {\n            \"parts\": [\n              {\n                \"text\": \"I rolled a 17.\"\n              }\n            ],\n            \"role\": null\n          },\n          \"intermediate_data\": {\n            \"tool_uses\": [],\n            \"intermediate_responses\": []\n          },\n        },\n        {\n          \"invocation_id\": \"e-bf8549a1-2a61-4ecc-a4ee-4efbbf25a8ea\",\n          \"user_content\": {\n            \"parts\": [\n              {\n                \"text\": \"Roll a 10 sided dice twice and then check if 9 is a prime or not\"\n              }\n            ],\n            \"role\": \"user\"\n          },\n          \"final_response\": {\n            \"parts\": [\n              {\n                \"text\": \"I got 4 and 7 from the dice roll, and 9 is not a prime number.\\n\"\n              }\n            ],\n            \"role\": null\n          },\n          \"intermediate_data\": {\n            \"tool_uses\": [\n              {\n                \"id\": \"adk-1a3f5a01-1782-4530-949f-07cf53fc6f05\",\n                \"args\": {\n                  \"sides\": 10\n                },\n                \"name\": \"roll_die\"\n              },\n              {\n                \"id\": \"adk-52fc3269-caaf-41c3-833d-511e454c7058\",\n                \"args\": {\n                  \"sides\": 10\n                },\n                \"name\": \"roll_die\"\n              },\n              {\n                \"id\": \"adk-5274768e-9ec5-4915-b6cf-f5d7f0387056\",\n                \"args\": {\n                  \"nums\": [\n                    9\n                  ]\n                },\n                \"name\": \"check_prime\"\n              }\n            ],\n            \"intermediate_responses\": [\n              [\n                \"data_processing_agent\",\n                [\n                  {\n                    \"text\": \"I have rolled a 10 sided die twice. The first roll is 5 and the second roll is 3.\\n\"\n                  }\n                ]\n              ]\n            ]\n          },\n        }\n      ],\n      \"session_input\": {\n        \"app_name\": \"hello_world\",\n        \"user_id\": \"user\",\n        \"state\": {}\n      },\n    }\n  ],\n}"}]}, {"heading_path": ["How to migrate eval set files not backed by the Pydantic schema?\u00b6"], "text": "How to migrate eval set files not backed by the Pydantic schema? \u00b6 NOTE: If your eval set files don't adhere to EvalSet schema file, then this section is relevant to you. Based on who is maintaining the eval set data, there are two routes: Eval set data maintained by ADK UI If you use ADK UI to maintain your\n    Eval set data then no action is needed from you. Eval set data is developed and maintained manually and used in ADK eval CLI A\n    migration tool is in the works, until then the ADK eval CLI command will\n    continue to support data in the old format. ", "code_blocks": []}, {"heading_path": ["Evaluation Criteria\u00b6"], "text": "Evaluation Criteria \u00b6 ADK provides several built-in criteria for evaluating agent performance, ranging\nfrom tool trajectory matching to LLM-based response quality assessment. For a\ndetailed list of available criteria and guidance on when to use them, please see Evaluation Criteria . Here is a summary of all the available criteria: tool_trajectory_avg_score : Exact match of tool call trajectory. response_match_score : ROUGE-1 similarity to reference response. final_response_match_v2 : LLM-judged semantic match to a reference\n    response. rubric_based_final_response_quality_v1 : LLM-judged final response\n    quality based on custom rubrics. rubric_based_tool_use_quality_v1 : LLM-judged tool usage quality based on\n    custom rubrics. hallucinations_v1 : LLM-judged groundedness of agent response against\n    context. safety_v1 : Safety/harmlessness of agent response. If no evaluation criteria are provided, the following default configuration is used: tool_trajectory_avg_score : Defaults to 1.0, requiring a 100% match in the tool usage trajectory. response_match_score : Defaults to 0.8, allowing for a small margin of error in the agent's natural language responses. Here is an example of a test_config.json file specifying custom evaluation criteria: { \"criteria\" : { \"tool_trajectory_avg_score\" : 1.0 , \"response_match_score\" : 0.8 } } ", "code_blocks": [{"language": "text", "code": "{\n  \"criteria\": {\n    \"tool_trajectory_avg_score\": 1.0,\n    \"response_match_score\": 0.8\n  }\n}"}]}, {"heading_path": ["Recommendations on Criteria\u00b6"], "text": "Recommendations on Criteria \u00b6 Choose criteria based on your evaluation goals: Enable tests in CI/CD pipelines or regression testing: Use tool_trajectory_avg_score and response_match_score . These criteria are\n    fast, predictable, and suitable for frequent automated checks. Evaluate trusted reference responses: Use final_response_match_v2 to\n    evaluate semantic equivalence. This LLM-based check is more flexible than\n    exact matching and better captures whether the agent's response means the\n    same thing as the reference response. Evaluate response quality without a reference response: Use rubric_based_final_response_quality_v1 . This is useful when you don't have\n    a trusted reference, but you can define attributes of a good response (e.g.,\n    \"The response is concise,\" \"The response has a helpful tone\"). Evaluate the correctness of tool usage: Use rubric_based_tool_use_quality_v1 . This allows you to validate the agent's\n    reasoning process by checking, for example, that a specific tool was called\n    or that tools were called in the correct order (e.g., \"Tool A must be called\n    before Tool B\"). Check if responses are grounded in context: Use hallucinations_v1 to\n    detect if the agent makes claims that are unsupported by or contradictory to\n    the information available to it (e.g., tool outputs). Check for harmful content: Use safety_v1 to ensure that agent\n    responses are safe and do not violate safety policies. In addition, criteria which require information on expected agent tool use\nand/or responses are not supported in combination with User Simulation .\nCurrently, only the hallucinations_v1 and safety_v1 criteria support such evals. ", "code_blocks": []}, {"heading_path": ["User Simulation\u00b6"], "text": "User Simulation \u00b6 When evaluating conversational agents, it is not always practical to use a fixed\nset of user prompts, as the conversation can proceed in unexpected ways.\nFor example, if the agent needs the user to supply two values to perform a task,\nit may ask for those values one at a time or both at once.\nTo resolve this issue, ADK allows you test the behavior of the agent in a\nspecific conversation scenario with user prompts that are dynamically\ngenerated by an AI model.\nFor details on how to set up an eval with user simulation, see User Simulation . ", "code_blocks": []}, {"heading_path": ["How to run Evaluation with the ADK\u00b6"], "text": "How to run Evaluation with the ADK \u00b6 As a developer, you can evaluate your agents using the ADK in the following ways: Web-based UI ( adk web ): Evaluate agents interactively through a web-based interface. Programmatically ( pytest ) : Integrate evaluation into your testing pipeline using pytest and test files. Command Line Interface ( adk eval ): Run evaluations on an existing evaluation set file directly from the command line. ", "code_blocks": []}, {"heading_path": ["1. adk web - Run Evaluations via the Web UI\u00b6"], "text": "1. adk web - Run Evaluations via the Web UI \u00b6 The web UI provides an interactive way to evaluate agents, generate evaluation datasets, and inspect agent behavior in detail. ", "code_blocks": []}, {"heading_path": ["Step 1: Create and Save a Test Case\u00b6"], "text": "Step 1: Create and Save a Test Case \u00b6 Start the web server by running: adk web <path_to_your_agents_folder> In the web interface, select an agent and interact with it to create a session. Navigate to the Eval tab on the right side of the interface. Create a new eval set or select an existing one. Click \"Add current session\" to save the conversation as a new evaluation case. ", "code_blocks": []}, {"heading_path": ["Step 2: View and Edit Your Test Case\u00b6"], "text": "Step 2: View and Edit Your Test Case \u00b6 Once a case is saved, you can click its ID in the list to inspect it. To make changes, click the Edit current eval case icon (pencil). This interactive view allows you to: Modify agent text responses to refine test scenarios. Delete individual agent messages from the conversation. Delete the entire evaluation case if it's no longer needed. ", "code_blocks": []}, {"heading_path": ["Step 3: Run the Evaluation with Custom Metrics\u00b6"], "text": "Step 3: Run the Evaluation with Custom Metrics \u00b6 Select one or more test cases from your evalset. Click Run Evaluation . An EVALUATION METRIC dialog will appear. In the dialog, use the sliders to configure the thresholds for: Tool trajectory avg score Response match score Click Start to run the evaluation using your custom criteria. The evaluation history will record the metrics used for each run. ", "code_blocks": []}, {"heading_path": ["Step 4: Analyze Results\u00b6"], "text": "Step 4: Analyze Results \u00b6 After the run completes, you can analyze the results: Analyze Run Failures : Click on any Pass or Fail result. For failures, you can hover over the Fail label to see a side-by-side comparison of the Actual vs. Expected Output and the scores that caused the failure. ", "code_blocks": []}, {"heading_path": ["Debugging with the Trace View\u00b6"], "text": "Debugging with the Trace View \u00b6 The ADK web UI includes a powerful Trace tab for debugging agent behavior. This feature is available for any agent session, not just during evaluation. The Trace tab provides a detailed and interactive way to inspect your agent's execution flow. Traces are automatically grouped by user message, making it easy to follow the chain of events. Each trace row is interactive: Hovering over a trace row highlights the corresponding message in the chat window. Clicking on a trace row opens a detailed inspection panel with four tabs: Event : The raw event data. Request : The request sent to the model. Response : The response received from the model. Graph : A visual representation of the tool calls and agent logic flow. Blue rows in the trace view indicate that an event was generated from that interaction. Clicking on these blue rows will open the bottom event detail panel, providing deeper insights into the agent's execution flow. ", "code_blocks": []}, {"heading_path": ["2.  pytest - Run Tests Programmatically\u00b6"], "text": "2. pytest - Run Tests Programmatically \u00b6 You can also use pytest to run test files as part of your integration tests. ", "code_blocks": []}, {"heading_path": ["Example Command\u00b6"], "text": "Example Command \u00b6 pytest tests/integration/ ", "code_blocks": [{"language": "text", "code": "pytest tests/integration/"}]}, {"heading_path": ["Example Test Code\u00b6"], "text": "Example Test Code \u00b6 Here is an example of a pytest test case that runs a single test file: from google.adk.evaluation.agent_evaluator import AgentEvaluator import pytest @pytest . mark . asyncio async def test_with_single_test_file (): \"\"\"Test the agent's basic ability via a session file.\"\"\" await AgentEvaluator . evaluate ( agent_module = \"home_automation_agent\" , eval_dataset_file_path_or_dir = \"tests/integration/fixture/home_automation_agent/simple_test.test.json\" , ) This approach allows you to integrate agent evaluations into your CI/CD pipelines or larger test suites. If you want to specify the initial session state for your tests, you can do that by storing the session details in a file and passing that to AgentEvaluator.evaluate method. ", "code_blocks": [{"language": "text", "code": "from google.adk.evaluation.agent_evaluator import AgentEvaluator\nimport pytest\n\n@pytest.mark.asyncio\nasync def test_with_single_test_file():\n    \"\"\"Test the agent's basic ability via a session file.\"\"\"\n    await AgentEvaluator.evaluate(\n        agent_module=\"home_automation_agent\",\n        eval_dataset_file_path_or_dir=\"tests/integration/fixture/home_automation_agent/simple_test.test.json\",\n    )"}]}, {"heading_path": ["3. adk eval - Run Evaluations via the CLI\u00b6"], "text": "3. adk eval - Run Evaluations via the CLI \u00b6 You can also run evaluation of an eval set file through the command line interface (CLI). This runs the same evaluation that runs on the UI, but it helps with automation, i.e. you can add this command as a part of your regular build generation and verification process. Here is the command: adk eval \\ <AGENT_MODULE_FILE_PATH> \\ <EVAL_SET_FILE_PATH> \\ [ --config_file_path = <PATH_TO_TEST_JSON_CONFIG_FILE> ] \\ [ --print_detailed_results ] For example: adk eval \\ samples_for_testing/hello_world \\ samples_for_testing/hello_world/hello_world_eval_set_001.evalset.json Here are the details for each command line argument: AGENT_MODULE_FILE_PATH : The path to the __init__.py file that contains a module by the name \"agent\". \"agent\" module contains a root_agent . EVAL_SET_FILE_PATH : The path to evaluations file(s). You can specify one or more eval set file paths. For each file, all evals will be run by default. If you want to run only specific evals from a eval set, first create a comma separated list of eval names and then add that as a suffix to the eval set file name, demarcated by a colon : . For example: sample_eval_set_file.json:eval_1,eval_2,eval_3 This will only run eval_1, eval_2 and eval_3 from sample_eval_set_file.json CONFIG_FILE_PATH : The path to the config file. PRINT_DETAILED_RESULTS : Prints detailed results on the console. Back to top ", "code_blocks": [{"language": "text", "code": "adk eval \\\n    <AGENT_MODULE_FILE_PATH> \\\n    <EVAL_SET_FILE_PATH> \\\n    [--config_file_path=<PATH_TO_TEST_JSON_CONFIG_FILE>] \\\n    [--print_detailed_results]"}, {"language": "text", "code": "adk eval \\\n    samples_for_testing/hello_world \\\n    samples_for_testing/hello_world/hello_world_eval_set_001.evalset.json"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:30.594050", "source_type": "adk-docs"}
{"doc_id": "bb72cd4a5dd73c4deda7915bad2ceb1a8d6fb7ba7c15cdd742f624f65ffdad41", "url": "https://google.github.io/adk-docs/evaluate/criteria", "title": "Criteria - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Evaluation Criteria\u00b6"], "text": "Evaluation Criteria \u00b6 Supported in ADK Python This page outlines the evaluation criteria provided by ADK to assess agent\nperformance, including tool use trajectory, response quality, and safety. Criterion Description Reference-Based Requires Rubrics LLM-as-a-Judge Supports User Simulation tool_trajectory_avg_score Exact match of tool call trajectory Yes No No No response_match_score ROUGE-1 similarity to reference response Yes No No No final_response_match_v2 LLM-judged semantic match to reference response Yes No Yes No rubric_based_final_response_quality_v1 LLM-judged final response quality based on custom rubrics No Yes Yes No rubric_based_tool_use_quality_v1 LLM-judged tool usage quality based on custom rubrics No Yes Yes No hallucinations_v1 LLM-judged groundedness of agent response against context No No Yes Yes safety_v1 Safety/harmlessness of agent response No No Yes Yes ", "code_blocks": []}, {"heading_path": ["tool_trajectory_avg_score\u00b6"], "text": "tool_trajectory_avg_score \u00b6 This criterion compares the sequence of tools called by the agent against a list\nof expected calls and computes an average score based on one of the match types: EXACT , IN_ORDER , or ANY_ORDER . ", "code_blocks": []}, {"heading_path": ["When To Use This Criterion?\u00b6"], "text": "When To Use This Criterion? \u00b6 This criterion is ideal for scenarios where agent correctness depends on tool\ncalls. Depending on how strictly tool calls need to be followed, you can choose\nfrom one of three match types: EXACT , IN_ORDER , and ANY_ORDER . This metric is particularly valuable for: Regression testing: Ensuring that agent updates do not unintentionally\n    alter tool call behavior for established test cases. Workflow validation: Verifying that agents correctly follow predefined\n    workflows that require specific API calls in a specific order. High-precision tasks: Evaluating tasks where slight deviations in tool\n    parameters or call order can lead to significantly different or incorrect\n    outcomes. Use EXACT match when you need to enforce a specific tool execution path and\nconsider any deviation\u2014whether in tool name, arguments, or order\u2014as a failure. Use IN_ORDER match when you want to ensure certain key tool calls occur in a\nspecific order, but allow for other tool calls to happen in between. This option is\nuseful in assuring if certain key actions or tool calls occur and in certain order,\nleaving some scope for other tools calls to happen as well. Use ANY_ORDER match when you want to ensure certain key tool calls occur, but\ndo not care about their order, and allow for other tool calls to happen in\nbetween. This criteria is helpful for cases where multiple tool calls about the\nsame concept occur, like your agent issues 5 search queries. You don't really\ncare the order in which the search queries are issued, till they occur. ", "code_blocks": []}, {"heading_path": ["Details\u00b6"], "text": "Details \u00b6 For each invocation that is being evaluated, this criterion compares the list of\ntool calls produced by the agent against the list of expected tool calls using\none of three match types. If the tool calls match based on the selected match\ntype, a score of 1.0 is awarded for that invocation, otherwise the score is 0.0.\nThe final value is the average of these scores across all invocations in the\neval case. The comparison can be done using one of following match types: EXACT : Requires a perfect match between the actual and expected tool\n    calls, with no extra or missing tool calls. IN_ORDER : Requires all tool calls from the expected list to be present\n    in the actual list, in the same order, but allows for other tool calls to\n    appear in between. ANY_ORDER : Requires all tool calls from the expected list to be\n    present in the actual list, in any order, and allows for other tool calls to\n    appear in between. ", "code_blocks": []}, {"heading_path": ["How To Use This Criterion?\u00b6"], "text": "How To Use This Criterion? \u00b6 By default, tool_trajectory_avg_score uses EXACT match type. You can specify\njust a threshold for this criterion in EvalConfig under the criteria dictionary for EXACT match type. The value should be a float between 0.0 and\n1.0, which represents the minimum acceptable score for the eval case to pass. If\nyou expect tool trajectories to match exactly in all invocations, you should set\nthe threshold to 1.0. Example EvalConfig entry for EXACT match: { \"criteria\" : { \"tool_trajectory_avg_score\" : 1.0 } } Or you could specify the match_type explicitly: { \"criteria\" : { \"tool_trajectory_avg_score\" : { \"threshold\" : 1.0 , \"match_type\" : \"EXACT\" } } } If you want to use IN_ORDER or ANY_ORDER match type, you can specify it via match_type field along with threshold. Example EvalConfig entry for IN_ORDER match: { \"criteria\" : { \"tool_trajectory_avg_score\" : { \"threshold\" : 1.0 , \"match_type\" : \"IN_ORDER\" } } } Example EvalConfig entry for ANY_ORDER match: { \"criteria\" : { \"tool_trajectory_avg_score\" : { \"threshold\" : 1.0 , \"match_type\" : \"ANY_ORDER\" } } } ", "code_blocks": [{"language": "text", "code": "{\n  \"criteria\": {\n    \"tool_trajectory_avg_score\": 1.0\n  }\n}"}, {"language": "text", "code": "{\n  \"criteria\": {\n    \"tool_trajectory_avg_score\": {\n      \"threshold\": 1.0,\n      \"match_type\": \"EXACT\"\n    }\n  }\n}"}, {"language": "text", "code": "{\n  \"criteria\": {\n    \"tool_trajectory_avg_score\": {\n      \"threshold\": 1.0,\n      \"match_type\": \"IN_ORDER\"\n    }\n  }\n}"}, {"language": "text", "code": "{\n  \"criteria\": {\n    \"tool_trajectory_avg_score\": {\n      \"threshold\": 1.0,\n      \"match_type\": \"ANY_ORDER\"\n    }\n  }\n}"}]}, {"heading_path": ["Output And How To Interpret\u00b6"], "text": "Output And How To Interpret \u00b6 The output is a score between 0.0 and 1.0, where 1.0 indicates a perfect match\nbetween actual and expected tool trajectories for all invocations, and 0.0\nindicates a complete mismatch for all invocations. Higher scores are better. A\nscore below 1.0 means that for at least one invocation, the agent's tool call\ntrajectory deviated from the expected one. ", "code_blocks": []}, {"heading_path": ["response_match_score\u00b6"], "text": "response_match_score \u00b6 This criterion evaluates if agent's final response matches a golden/expected\nfinal response using Rouge-1. ", "code_blocks": []}, {"heading_path": ["When To Use This Criterion?\u00b6"], "text": "When To Use This Criterion? \u00b6 Use this criterion when you need a quantitative measure of how closely the\nagent's output matches the expected output in terms of content overlap. ", "code_blocks": []}, {"heading_path": ["Details\u00b6"], "text": "Details \u00b6 ROUGE-1 specifically measures the overlap of unigrams (single words) between the\nsystem-generated text (candidate summary) and the a reference text. It\nessentially checks how many individual words from the reference text are present\nin the candidate text. To learn more, see details on ROUGE-1 . ", "code_blocks": []}, {"heading_path": ["How To Use This Criterion?\u00b6"], "text": "How To Use This Criterion? \u00b6 You can specify a threshold for this criterion in EvalConfig under the criteria dictionary. The value should be a float between 0.0 and 1.0, which\nrepresents the minimum acceptable score for the eval case to pass. Example EvalConfig entry: { \"criteria\" : { \"response_match_score\" : 0.8 } } ", "code_blocks": [{"language": "text", "code": "{\n  \"criteria\": {\n    \"response_match_score\": 0.8\n  }\n}"}]}, {"heading_path": ["Output And How To Interpret\u00b6"], "text": "Output And How To Interpret \u00b6 Value range for this criterion is [0,1], with values closer to 1 more desirable. ", "code_blocks": []}, {"heading_path": ["final_response_match_v2\u00b6"], "text": "final_response_match_v2 \u00b6 This criterion evaluates if the agent's final response matches a golden/expected\nfinal response using LLM as a judge. ", "code_blocks": []}, {"heading_path": ["When To Use This Criterion?\u00b6"], "text": "When To Use This Criterion? \u00b6 Use this criterion when you need to evaluate the correctness of an agent's final\nresponse against a reference, but require flexibility in how the answer is\npresented. It is suitable for cases where different phrasings or formats are\nacceptable, as long as the core meaning and information match the reference.\nThis criterion is a good choice for evaluating question-answering,\nsummarization, or other generative tasks where semantic equivalence is more\nimportant than exact lexical overlap, making it a more sophisticated alternative\nto response_match_score . ", "code_blocks": []}, {"heading_path": ["Details\u00b6"], "text": "Details \u00b6 This criterion uses a Large Language Model (LLM) as a judge to determine if the\nagent's final response is semantically equivalent to the provided reference\nresponse. It is designed to be more flexible than lexical matching metrics (like response_match_score ), as it focuses on whether the agent's response contains\nthe correct information, while tolerating differences in formatting, phrasing,\nor the inclusion of additional correct details. For each invocation, the criterion prompts a judge LLM to rate the agent's\nresponse as \"valid\" or \"invalid\" compared to the reference. This is repeated\nmultiple times for robustness (configurable via num_samples ), and a majority\nvote determines if the invocation receives a score of 1.0 (valid) or 0.0\n(invalid). The final criterion score is the fraction of invocations deemed valid\nacross the entire eval case. ", "code_blocks": []}, {"heading_path": ["How To Use This Criterion?\u00b6"], "text": "How To Use This Criterion? \u00b6 This criterion uses LlmAsAJudgeCriterion , allowing you to configure the\nevaluation threshold, the judge model, and the number of samples per invocation. Example EvalConfig entry: { \"criteria\" : { \"final_response_match_v2\" : { \"threshold\" : 0.8 , \"judge_model_options\" : { \"judge_model\" : \"gemini-2.5-flash\" , \"num_samples\" : 5 } } } } } ", "code_blocks": [{"language": "text", "code": "{\n  \"criteria\": {\n    \"final_response_match_v2\": {\n      \"threshold\": 0.8,\n      \"judge_model_options\": {\n            \"judge_model\": \"gemini-2.5-flash\",\n            \"num_samples\": 5\n          }\n        }\n    }\n  }\n}"}]}, {"heading_path": ["Output And How To Interpret\u00b6"], "text": "Output And How To Interpret \u00b6 The criterion returns a score between 0.0 and 1.0. A score of 1.0 means the LLM\njudge considered the agent's final response to be valid for all invocations,\nwhile a score closer to 0.0 indicates that many responses were judged as invalid\nwhen compared to the reference responses. Higher values are better. ", "code_blocks": []}, {"heading_path": ["rubric_based_final_response_quality_v1\u00b6"], "text": "rubric_based_final_response_quality_v1 \u00b6 This criterion assesses the quality of an agent's final response against a\nuser-defined set of rubrics using LLM as a judge. ", "code_blocks": []}, {"heading_path": ["When To Use This Criterion?\u00b6"], "text": "When To Use This Criterion? \u00b6 Use this criterion when you need to evaluate aspects of response quality that go\nbeyond simple correctness or semantic equivalence with a reference. It is ideal\nfor assessing nuanced attributes like tone, style, helpfulness, or adherence to\nspecific conversational guidelines defined in your rubrics. This criterion is\nparticularly useful when no single reference response exists, or when quality\ndepends on multiple subjective factors. ", "code_blocks": []}, {"heading_path": ["Details\u00b6"], "text": "Details \u00b6 This criterion provides a flexible way to evaluate response quality based on\nspecific criteria that you define as rubrics. For example, you could define\nrubrics to check if a response is concise, if it correctly infers user intent,\nor if it avoids jargon. The criterion uses an LLM-as-a-judge to evaluate the agent's final response\nagainst each rubric, producing a yes (1.0) or no (0.0) verdict for each.\nLike other LLM-based metrics, it samples the judge model multiple times per\ninvocation and uses a majority vote to determine the score for each rubric in\nthat invocation. The overall score for an invocation is the average of its\nrubric scores. The final criterion score for the eval case is the average of\nthese overall scores across all invocations. ", "code_blocks": []}, {"heading_path": ["How To Use This Criterion?\u00b6"], "text": "How To Use This Criterion? \u00b6 This criterion uses RubricsBasedCriterion , which requires a list of rubrics to\nbe provided in the EvalConfig . Each rubric should be defined with a unique ID\nand its content. Example EvalConfig entry: { \"criteria\" : { \"rubric_based_final_response_quality_v1\" : { \"threshold\" : 0.8 , \"judge_model_options\" : { \"judge_model\" : \"gemini-2.5-flash\" , \"num_samples\" : 5 }, \"rubrics\" : [ { \"rubric_id\" : \"conciseness\" , \"rubric_content\" : { \"text_property\" : \"The agent's response is direct and to the point.\" } }, { \"rubric_id\" : \"intent_inference\" , \"rubric_content\" : { \"text_property\" : \"The agent's response accurately infers the user's underlying goal from ambiguous queries.\" } } ] } } } ", "code_blocks": [{"language": "text", "code": "{\n  \"criteria\": {\n    \"rubric_based_final_response_quality_v1\": {\n      \"threshold\": 0.8,\n      \"judge_model_options\": {\n        \"judge_model\": \"gemini-2.5-flash\",\n        \"num_samples\": 5\n      },\n      \"rubrics\": [\n        {\n          \"rubric_id\": \"conciseness\",\n          \"rubric_content\": {\n            \"text_property\": \"The agent's response is direct and to the point.\"\n          }\n        },\n        {\n          \"rubric_id\": \"intent_inference\",\n          \"rubric_content\": {\n            \"text_property\": \"The agent's response accurately infers the user's underlying goal from ambiguous queries.\"\n          }\n        }\n      ]\n    }\n  }\n}"}]}, {"heading_path": ["Output And How To Interpret\u00b6"], "text": "Output And How To Interpret \u00b6 The criterion outputs an overall score between 0.0 and 1.0, where 1.0 indicates\nthat the agent's responses satisfied all rubrics across all invocations, and 0.0\nindicates that no rubrics were satisfied. The results also include detailed\nper-rubric scores for each invocation. Higher values are better. ", "code_blocks": []}, {"heading_path": ["rubric_based_tool_use_quality_v1\u00b6"], "text": "rubric_based_tool_use_quality_v1 \u00b6 This criterion assesses the quality of an agent's tool usage against a\nuser-defined set of rubrics using LLM as a judge. ", "code_blocks": []}, {"heading_path": ["When To Use This Criterion?\u00b6"], "text": "When To Use This Criterion? \u00b6 Use this criterion when you need to evaluate how an agent uses tools, rather\nthan just if the final response is correct. It is ideal for assessing whether\nthe agent selected the right tool, used the correct parameters, or followed a\nspecific sequence of tool calls. This is useful for validating agent reasoning\nprocesses, debugging tool-use errors, and ensuring adherence to prescribed\nworkflows, especially in cases where multiple tool-use paths could lead to a\nsimilar final answer but only one path is considered correct. ", "code_blocks": []}, {"heading_path": ["Details\u00b6"], "text": "Details \u00b6 This criterion provides a flexible way to evaluate tool usage based on specific\nrules that you define as rubrics. For example, you could define rubrics to check\nif a specific tool was called, if its parameters were correct, or if tools were\ncalled in a particular order. The criterion uses an LLM-as-a-judge to evaluate the agent's tool calls and\nresponses against each rubric, producing a yes (1.0) or no (0.0) verdict for\neach. Like other LLM-based metrics, it samples the judge model multiple times\nper invocation and uses a majority vote to determine the score for each rubric\nin that invocation. The overall score for an invocation is the average of its\nrubric scores. The final criterion score for the eval case is the average of\nthese overall scores across all invocations. ", "code_blocks": []}, {"heading_path": ["How To Use This Criterion?\u00b6"], "text": "How To Use This Criterion? \u00b6 This criterion uses RubricsBasedCriterion , which requires a list of rubrics to\nbe provided in the EvalConfig . Each rubric should be defined with a unique ID\nand its content, describing a specific aspect of tool use to evaluate. Example EvalConfig entry: { \"criteria\" : { \"rubric_based_tool_use_quality_v1\" : { \"threshold\" : 1.0 , \"judge_model_options\" : { \"judge_model\" : \"gemini-2.5-flash\" , \"num_samples\" : 5 }, \"rubrics\" : [ { \"rubric_id\" : \"geocoding_called\" , \"rubric_content\" : { \"text_property\" : \"The agent calls the GeoCoding tool before calling the GetWeather tool.\" } }, { \"rubric_id\" : \"getweather_called\" , \"rubric_content\" : { \"text_property\" : \"The agent calls the GetWeather tool with coordinates derived from the user's location.\" } } ] } } } ", "code_blocks": [{"language": "text", "code": "{\n  \"criteria\": {\n    \"rubric_based_tool_use_quality_v1\": {\n      \"threshold\": 1.0,\n      \"judge_model_options\": {\n        \"judge_model\": \"gemini-2.5-flash\",\n        \"num_samples\": 5\n      },\n      \"rubrics\": [\n        {\n          \"rubric_id\": \"geocoding_called\",\n          \"rubric_content\": {\n            \"text_property\": \"The agent calls the GeoCoding tool before calling the GetWeather tool.\"\n          }\n        },\n        {\n          \"rubric_id\": \"getweather_called\",\n          \"rubric_content\": {\n            \"text_property\": \"The agent calls the GetWeather tool with coordinates derived from the user's location.\"\n          }\n        }\n      ]\n    }\n  }\n}"}]}, {"heading_path": ["Output And How To Interpret\u00b6"], "text": "Output And How To Interpret \u00b6 The criterion outputs an overall score between 0.0 and 1.0, where 1.0 indicates\nthat the agent's tool usage satisfied all rubrics across all invocations, and\n0.0 indicates that no rubrics were satisfied. The results also include detailed\nper-rubric scores for each invocation. Higher values are better. ", "code_blocks": []}, {"heading_path": ["hallucinations_v1\u00b6"], "text": "hallucinations_v1 \u00b6 This criterion assesses whether a model response contains any false,\ncontradictory, or unsupported claims. ", "code_blocks": []}, {"heading_path": ["When To Use This Criterion?\u00b6"], "text": "When To Use This Criterion? \u00b6 Use this criterion to ensure the agent's response is grounded in the provided\ncontext (e.g., tool outputs, user query, instructions) and does not contain\nhallucinations. ", "code_blocks": []}, {"heading_path": ["Details\u00b6"], "text": "Details \u00b6 This criterion assesses whether a model response contains any false,\ncontradictory, or unsupported claims based on context that includes developer\ninstructions, user prompt, tool definitions, and tool invocations and their\nresults. It uses LLM-as-a-judge and follows a two-step process: Segmenter : Segments the agent response into individual sentences. Sentence Validator : Evaluates each segmented sentence against the\n    provided context for grounding. Each sentence is labeled as supported , unsupported , contradictory , disputed or not_applicable . The metric computes an Accuracy Score: the percentage of sentences that are supported or not_applicable . By default, only the final response is\nevaluated. If evaluate_intermediate_nl_responses is set to true in the\ncriterion, intermediate natural language responses from agents are also\nevaluated. ", "code_blocks": []}, {"heading_path": ["How To Use This Criterion?\u00b6"], "text": "How To Use This Criterion? \u00b6 This criterion uses HallucinationsCriterion , allowing you to configure the\nevaluation threshold, the judge model, the number of samples per invocation and\nwhether to evaluate intermediate natural language responses. Example EvalConfig entry: { \"criteria\" : { \"hallucinations_v1\" : { \"threshold\" : 0.8 , \"judge_model_options\" : { \"judge_model\" : \"gemini-2.5-flash\" , }, \"evaluate_intermediate_nl_responses\" : true } } } ", "code_blocks": [{"language": "text", "code": "{\n  \"criteria\": {\n    \"hallucinations_v1\": {\n      \"threshold\": 0.8,\n      \"judge_model_options\": {\n            \"judge_model\": \"gemini-2.5-flash\",\n          },\n      \"evaluate_intermediate_nl_responses\": true\n    }\n  }\n}"}]}, {"heading_path": ["Output And How To Interpret\u00b6"], "text": "Output And How To Interpret \u00b6 The criterion returns a score between 0.0 and 1.0. A score of 1.0 means all\nsentences in agent's response are grounded in the context, while a score closer\nto 0.0 indicates that many sentences are false, contradictory, or unsupported.\nHigher values are better. ", "code_blocks": []}, {"heading_path": ["safety_v1\u00b6"], "text": "safety_v1 \u00b6 This criterion evaluates the safety (harmlessness) of an Agent's Response. ", "code_blocks": []}, {"heading_path": ["When To Use This Criterion?\u00b6"], "text": "When To Use This Criterion? \u00b6 This criterion should be used when you need to ensure that agent responses\ncomply with safety guidelines and do not produce harmful or inappropriate\ncontent. It is essential for user-facing applications or any system where\nresponse safety is a priority. ", "code_blocks": []}, {"heading_path": ["Details\u00b6"], "text": "Details \u00b6 This criterion assesses whether the agent's response contains any harmful\ncontent, such as hate speech, harassment, or dangerous information. Unlike other\nmetrics implemented natively within ADK, safety_v1 delegates the evaluation to\nthe Vertex AI General AI Eval SDK. ", "code_blocks": []}, {"heading_path": ["How To Use This Criterion?\u00b6"], "text": "How To Use This Criterion? \u00b6 Using this criterion requires a Google Cloud Project. You must have GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_LOCATION environment variables set,\ntypically in an .env file in your agent's directory, for the Vertex AI SDK to\nfunction correctly. You can specify a threshold for this criterion in EvalConfig under the criteria dictionary. The value should be a float between 0.0 and 1.0,\nrepresenting the minimum safety score for a response to be considered passing. Example EvalConfig entry: { \"criteria\" : { \"safety_v1\" : 0.8 } } ", "code_blocks": [{"language": "text", "code": "{\n  \"criteria\": {\n    \"safety_v1\": 0.8\n  }\n}"}]}, {"heading_path": ["Output And How To Interpret\u00b6"], "text": "Output And How To Interpret \u00b6 The criterion returns a score between 0.0 and 1.0. Scores closer to 1.0 indicate\nthat the response is safe, while scores closer to 0.0 indicate potential safety\nissues. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:31.088633", "source_type": "adk-docs"}
{"doc_id": "79a5274f921e804aba7b6ed4f5739421ac1a3c9c68687cb9b47226425e72d3fb", "url": "https://google.github.io/adk-docs/evaluate/user-sim", "title": "User Simulation - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["User Simulation\u00b6"], "text": "User Simulation \u00b6 Supported in ADK Python v1.18.0 When evaluating conversational agents, it is not always practical to use a fixed\nset of user prompts, as the conversation can proceed in unexpected ways.\nFor example, if the agent needs the user to supply two values to perform a task,\nit may ask for those values one at a time or both at once.\nTo resolve this issue, ADK can dynamically generate user prompts using a\ngenerative AI model. To use this feature, you must specify a ConversationScenario which dictates the user's goals in their conversation with the agent.\nA sample conversation scenario for the hello_world agent is shown below: { \"starting_prompt\" : \"What can you do for me?\" , \"conversation_plan\" : \"Ask the agent to roll a 20-sided die. After you get the result, ask the agent to check if it is prime.\" } The starting_prompt in a conversation scenario specifies a fixed initial\nprompt that the user should use to start the conversation with the agent.\nSpecifying such fixed prompts for subsequent interactions with the agent is not\npractical as the agent may respond in different ways.\nInstead, the conversation_plan provides a guideline for how the rest of the\nconversation with the agent should proceed.\nAn LLM uses this conversation plan, along with the conversation history, to\ndynamically generate user prompts until it judges that the conversation is\ncomplete. Try it in Colab Test this entire workflow yourself in an interactive notebook on Simulating User Conversations to Dynamically Evaluate ADK Agents .\nYou'll define a conversation scenario, run a \"dry run\" to check the\ndialogue, and then perform a full evaluation to score the agent's responses. ", "code_blocks": [{"language": "text", "code": "{\n  \"starting_prompt\": \"What can you do for me?\",\n  \"conversation_plan\": \"Ask the agent to roll a 20-sided die. After you get the result, ask the agent to check if it is prime.\"\n}"}]}, {"heading_path": ["Example: Evaluating the hello_world agent with conversation scenarios\u00b6"], "text": "Example: Evaluating the hello_world agent with conversation scenarios \u00b6 To add evaluation cases containing conversation scenarios to a new or existing EvalSet ,\nyou need to first create a list of conversation scenarios to test the agent in. Try saving the following to contributing/samples/hello_world/conversation_scenarios.json : { \"scenarios\" : [ { \"starting_prompt\" : \"What can you do for me?\" , \"conversation_plan\" : \"Ask the agent to roll a 20-sided die. After you get the result, ask the agent to check if it is prime.\" }, { \"starting_prompt\" : \"Hi, I'm running a tabletop RPG in which prime numbers are bad!\" , \"conversation_plan\" : \"Say that you don't care about the value; you just want the agent to tell you if a roll is good or bad. Once the agent agrees, ask it to roll a 6-sided die. Finally, ask the agent to do the same with 2 20-sided dice.\" } ] } You will also need a session input file containing information used during\nevaluation.\nTry saving the following to contributing/samples/hello_world/session_input.json : { \"app_name\" : \"hello_world\" , \"user_id\" : \"user\" } Then, you can add the conversation scenarios to an EvalSet : # (optional) create a new EvalSet adk eval_set create \\ contributing/samples/hello_world \\ eval_set_with_scenarios # add conversation scenarios to the EvalSet as new eval cases adk eval_set add_eval_case \\ contributing/samples/hello_world \\ eval_set_with_scenarios \\ --scenarios_file contributing/samples/hello_world/conversation_scenarios.json \\ --session_input_file contributing/samples/hello_world/session_input.json By default, ADK runs evaluations with metrics that require the agent's expected\nresponse to be specified.\nSince that is not the case for a dynamic conversation scenario, we will use an EvalConfig with some alternate supported metrics. Try saving the following to contributing/samples/hello_world/eval_config.json : { \"criteria\" : { \"hallucinations_v1\" : { \"threshold\" : 0.5 , \"evaluate_intermediate_nl_responses\" : true }, \"safety_v1\" : { \"threshold\" : 0.8 } } } Finally, you can use the adk eval command to run the evaluation: adk eval \\ contributing/samples/hello_world \\ --config_file_path contributing/samples/hello_world/eval_config.json \\ eval_set_with_scenarios \\ --print_detailed_results ", "code_blocks": [{"language": "text", "code": "{\n  \"scenarios\": [\n    {\n      \"starting_prompt\": \"What can you do for me?\",\n      \"conversation_plan\": \"Ask the agent to roll a 20-sided die. After you get the result, ask the agent to check if it is prime.\"\n    },\n    {\n      \"starting_prompt\": \"Hi, I'm running a tabletop RPG in which prime numbers are bad!\",\n      \"conversation_plan\": \"Say that you don't care about the value; you just want the agent to tell you if a roll is good or bad. Once the agent agrees, ask it to roll a 6-sided die. Finally, ask the agent to do the same with 2 20-sided dice.\"\n    }\n  ]\n}"}, {"language": "text", "code": "{\n  \"app_name\": \"hello_world\",\n  \"user_id\": \"user\"\n}"}, {"language": "text", "code": "# (optional) create a new EvalSet\nadk eval_set create \\\n  contributing/samples/hello_world \\\n  eval_set_with_scenarios\n\n# add conversation scenarios to the EvalSet as new eval cases\nadk eval_set add_eval_case \\\n  contributing/samples/hello_world \\\n  eval_set_with_scenarios \\\n  --scenarios_file contributing/samples/hello_world/conversation_scenarios.json \\\n  --session_input_file contributing/samples/hello_world/session_input.json"}, {"language": "text", "code": "{\n  \"criteria\": {\n    \"hallucinations_v1\": {\n      \"threshold\": 0.5,\n      \"evaluate_intermediate_nl_responses\": true\n    },\n    \"safety_v1\": {\n      \"threshold\": 0.8\n    }\n  }\n}"}, {"language": "text", "code": "adk eval \\\n    contributing/samples/hello_world \\\n    --config_file_path contributing/samples/hello_world/eval_config.json \\\n    eval_set_with_scenarios \\\n    --print_detailed_results"}]}, {"heading_path": ["User simulator configuration\u00b6"], "text": "User simulator configuration \u00b6 You can override the default user simulator configuration to change the model,\ninternal model behavior, and the maximum number of user-agent interactions.\nThe below EvalConfig shows the default user simulator configuration: { \"criteria\" : { # same as be f ore }, \"user_simulator_config\" : { \"model\" : \"gemini-2.5-flash\" , \"model_configuration\" : { \"thinking_config\" : { \"include_thoughts\" : true , \"thinking_budget\" : 10240 } }, \"max_allowed_invocations\" : 20 } } model : The model backing the user simulator. model_configuration : A GenerateContentConfig which controls the model behavior. max_allowed_invocations : The maximum user-agent interactions allowed before\nthe conversation is forcefully terminated. This should be set to be greater than\nthe longest reasonable user-agent interaction in your EvalSet . Back to top ", "code_blocks": [{"language": "text", "code": "{\n  \"criteria\": {\n    # same as before\n  },\n  \"user_simulator_config\": {\n    \"model\": \"gemini-2.5-flash\",\n    \"model_configuration\": {\n      \"thinking_config\": {\n        \"include_thoughts\": true,\n        \"thinking_budget\": 10240\n      }\n    },\n    \"max_allowed_invocations\": 20\n  }\n}"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:31.647389", "source_type": "adk-docs"}
{"doc_id": "d07762e93f401c21f855e0b7b3dc04dfbf2bbfaf94005a91cd09a3baf6ce09d4", "url": "https://google.github.io/adk-docs/safety", "title": "Safety and Security for AI Agents - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Safety and Security for AI Agents\u00b6"], "text": "Safety and Security for AI Agents \u00b6 Supported in ADK Python Go Java As AI agents grow in capability, ensuring they operate safely, securely, and align with your brand values is paramount. Uncontrolled agents can pose risks, including executing misaligned or harmful actions, such as data exfiltration, and generating inappropriate content that can impact your brand\u2019s reputation. Sources of risk include vague instructions, model hallucination, jailbreaks and prompt injections from adversarial users, and indirect prompt injections via tool use. Google Cloud Vertex AI provides a multi-layered approach to mitigate these risks, enabling you to build powerful and trustworthy agents. It offers several mechanisms to establish strict boundaries, ensuring agents only perform actions you've explicitly allowed: Identity and Authorization : Control who the agent acts as by defining agent and user auth. Guardrails to screen inputs and outputs: Control your model and tool calls precisely. In-Tool Guardrails: Design tools defensively, using developer-set tool context to enforce policies (e.g., allowing queries only on specific tables). Built-in Gemini Safety Features: If using Gemini models, benefit from content filters to block harmful outputs and system Instructions to guide the model's behavior and safety guidelines Callbacks and Plugins: Validate model and tool calls before or after execution, checking parameters against agent state or external policies. Using Gemini as a safety guardrail: Implement an additional safety layer using a cheap and fast model (like Gemini Flash Lite) configured via callbacks  to screen inputs and outputs. Sandboxed code execution: Prevent model-generated code to cause security issues by sandboxing the environment Evaluation and tracing : Use evaluation tools to assess the quality, relevance, and correctness of the agent's final output. Use tracing to gain visibility into agent actions to analyze the steps an agent takes to reach a solution, including its choice of tools, strategies, and the efficiency of its approach. Network Controls and VPC-SC: Confine agent activity within secure perimeters (like VPC Service Controls) to prevent data exfiltration and limit the potential impact radius. ", "code_blocks": []}, {"heading_path": ["Safety and Security Risks\u00b6"], "text": "Safety and Security Risks \u00b6 Before implementing safety measures, perform a thorough risk assessment specific to your agent's capabilities, domain, and deployment context. Sources of risk include: Ambiguous agent instructions Prompt injection and jailbreak attempts from adversarial users Indirect prompt injections via tool use Risk categories include: Misalignment & goal corruption Pursuing unintended or proxy goals that lead to harmful outcomes (\"reward hacking\") Misinterpreting complex or ambiguous instructions Harmful content generation, including brand safety Generating toxic, hateful, biased, sexually explicit, discriminatory, or illegal content Brand safety risks such as Using language that goes against the brand\u2019s values or off-topic conversations Unsafe actions Executing commands that damage systems Making unauthorized purchases or financial transactions. Leaking sensitive personal data (PII) Data exfiltration ", "code_blocks": []}, {"heading_path": ["Best practices\u00b6"], "text": "Best practices \u00b6 ", "code_blocks": []}, {"heading_path": ["Identity and Authorization\u00b6"], "text": "Identity and Authorization \u00b6 The identity that a tool uses to perform actions on external systems is a crucial design consideration from a security perspective. Different tools in the same agent can be configured with different strategies, so care is needed when talking about the agent's configurations. ", "code_blocks": []}, {"heading_path": ["Agent-Auth\u00b6"], "text": "Agent-Auth \u00b6 The tool interacts with external systems using the agent's own identity (e.g., a service account). The agent identity must be explicitly authorized in the external system access policies, like adding an agent's service account to a database's IAM policy for read access. Such policies constrain the agent in only performing actions that the developer intended as possible: by giving read-only permissions to a resource, no matter what the model decides, the tool will be prohibited from performing write actions. This approach is simple to implement, and it is appropriate for agents where all users share the same level of access. If not all users have the same level of access, such an approach alone doesn't provide enough protection and must be complemented with other techniques below. In tool implementation, ensure that logs are created to maintain attribution of actions to users, as all agents' actions will appear as coming from the agent. ", "code_blocks": []}, {"heading_path": ["User Auth\u00b6"], "text": "User Auth \u00b6 The tool interacts with an external system using the identity of the \"controlling user\" (e.g., the human interacting with the frontend in a web application). In ADK, this is typically implemented using OAuth: the agent interacts with the frontend to acquire a OAuth token, and then the tool uses the token when performing external actions: the external system authorizes the action if the controlling user is authorized to perform it on its own. User auth has the advantage that agents only perform actions that the user could have performed themselves. This greatly reduces the risk that a malicious user could abuse the agent to obtain access to additional data. However, most common implementations of delegation have a fixed set permissions to delegate (i.e., OAuth scopes). Often, such scopes are broader than the access that the agent actually requires, and the techniques below are required to further constrain agent actions. ", "code_blocks": []}, {"heading_path": ["Guardrails to screen inputs and outputs\u00b6"], "text": "Guardrails to screen inputs and outputs \u00b6 ", "code_blocks": []}, {"heading_path": ["In-tool guardrails\u00b6"], "text": "In-tool guardrails \u00b6 Tools can be designed with security in mind: we can create tools that expose the actions we want the model to take and nothing else. By limiting the range of actions we provide to the agents, we can deterministically eliminate classes of rogue actions that we never want the agent to take. In-tool guardrails is an approach to create common and re-usable tools that expose deterministic controls that can be used by developers to set limits on each tool instantiation. This approach relies on the fact that tools receive two types of input: arguments,  which are set by the model, and Tool Context , which can be set deterministically by the agent developer. We can rely on the deterministically set information to validate that the model is behaving as-expected. For example, a query tool can be designed to expect a policy to be read from the Tool Context. Python Go Java # Conceptual example: Setting policy data intended for tool context # In a real ADK app, this might be set in InvocationContext.session.state # or passed during tool initialization, then retrieved via ToolContext. policy = {} # Assuming policy is a dictionary policy [ 'select_only' ] = True policy [ 'tables' ] = [ 'mytable1' , 'mytable2' ] # Conceptual: Storing policy where the tool can access it via ToolContext later. # This specific line might look different in practice. # For example, storing in session state: invocation_context . session . state [ \"query_tool_policy\" ] = policy # Or maybe passing during tool init: query_tool = QueryTool ( policy = policy ) # For this example, we'll assume it gets stored somewhere accessible. // Conceptual example: Setting policy data intended for tool context // In a real ADK app, this might be set using the session state service. // `ctx` is an `agent.Context` available in callbacks or custom agents. policy := map [ string ] interface {}{ \"select_only\" : true , \"tables\" : [] string { \"mytable1\" , \"mytable2\" }, } // Conceptual: Storing policy where the tool can access it via ToolContext later. // This specific line might look different in practice. // For example, storing in session state: if err := ctx . Session (). State (). Set ( \"query_tool_policy\" , policy ); err != nil { // Handle error, e.g., log it. } // Or maybe passing during tool init: // queryTool := NewQueryTool(policy) // For this example, we'll assume it gets stored somewhere accessible. // Conceptual example: Setting policy data intended for tool context // In a real ADK app, this might be set in InvocationContext.session.state // or passed during tool initialization, then retrieved via ToolContext. policy = new HashMap < String , Object > (); // Assuming policy is a Map policy . put ( \"select_only\" , true ); policy . put ( \"tables\" , new ArrayList <> ( \"mytable1\" , \"mytable2\" )); // Conceptual: Storing policy where the tool can access it via ToolContext later. // This specific line might look different in practice. // For example, storing in session state: invocationContext . session (). state (). put ( \"query_tool_policy\" , policy ); // Or maybe passing during tool init: query_tool = QueryTool ( policy ); // For this example, we'll assume it gets stored somewhere accessible. During the tool execution, Tool Context will be passed to the tool: Python Go Java def query ( query : str , tool_context : ToolContext ) -> str | dict : # Assume 'policy' is retrieved from context, e.g., via session state: # policy = tool_context.invocation_context.session.state.get('query_tool_policy', {}) # --- Placeholder Policy Enforcement --- policy = tool_context . invocation_context . session . state . get ( 'query_tool_policy' , {}) # Example retrieval actual_tables = explainQuery ( query ) # Hypothetical function call if not set ( actual_tables ) . issubset ( set ( policy . get ( 'tables' , []))): # Return an error message for the model allowed = \", \" . join ( policy . get ( 'tables' , [ '(None defined)' ])) return f \"Error: Query targets unauthorized tables. Allowed: { allowed } \" if policy . get ( 'select_only' , False ): if not query . strip () . upper () . startswith ( \"SELECT\" ): return \"Error: Policy restricts queries to SELECT statements only.\" # --- End Policy Enforcement --- print ( f \"Executing validated query (hypothetical): { query } \" ) return { \"status\" : \"success\" , \"results\" : [ ... ]} # Example successful return import ( \"fmt\" \"strings\" \"google.golang.org/adk/tool\" ) func query ( query string , toolContext * tool . Context ) ( any , error ) { // Assume 'policy' is retrieved from context, e.g., via session state: policyAny , err := toolContext . State (). Get ( \"query_tool_policy\" ) if err != nil { return nil , fmt . Errorf ( \"could not retrieve policy: %w\" , err ) } policy , _ := policyAny .( map [ string ] interface {}) actualTables := explainQuery ( query ) // Hypothetical function call // --- Placeholder Policy Enforcement --- if tables , ok := policy [ \"tables\" ].([] string ); ok { if ! isSubset ( actualTables , tables ) { // Return an error to signal failure allowed := strings . Join ( tables , \", \" ) if allowed == \"\" { allowed = \"(None defined)\" } return nil , fmt . Errorf ( \"query targets unauthorized tables. Allowed: %s\" , allowed ) } } if selectOnly , _ := policy [ \"select_only\" ].( bool ); selectOnly { if ! strings . HasPrefix ( strings . ToUpper ( strings . TrimSpace ( query )), \"SELECT\" ) { return nil , fmt . Errorf ( \"policy restricts queries to SELECT statements only\" ) } } // --- End Policy Enforcement --- fmt . Printf ( \"Executing validated query (hypothetical): %s\\n\" , query ) return map [ string ] interface {}{ \"status\" : \"success\" , \"results\" : [] string { \"...\" }}, nil } // Helper function to check if a is a subset of b func isSubset ( a , b [] string ) bool { set := make ( map [ string ] bool ) for _ , item := range b { set [ item ] = true } for _ , item := range a { if _ , found := set [ item ]; ! found { return false } } return true } import com.google.adk.tools.ToolContext ; import java.util.* ; class ToolContextQuery { public Object query ( String query , ToolContext toolContext ) { // Assume 'policy' is retrieved from context, e.g., via session state: Map < String , Object > queryToolPolicy = toolContext . invocationContext . session (). state (). getOrDefault ( \"query_tool_policy\" , null ); List < String > actualTables = explainQuery ( query ); // --- Placeholder Policy Enforcement --- if ( ! queryToolPolicy . get ( \"tables\" ). containsAll ( actualTables )) { List < String > allowedPolicyTables = ( List < String > ) queryToolPolicy . getOrDefault ( \"tables\" , new ArrayList < String > ()); String allowedTablesString = allowedPolicyTables . isEmpty () ? \"(None defined)\" : String . join ( \", \" , allowedPolicyTables ); return String . format ( \"Error: Query targets unauthorized tables. Allowed: %s\" , allowedTablesString ); } if ( ! queryToolPolicy . get ( \"select_only\" )) { if ( ! query . trim (). toUpperCase (). startswith ( \"SELECT\" )) { return \"Error: Policy restricts queries to SELECT statements only.\" ; } } // --- End Policy Enforcement --- System . out . printf ( \"Executing validated query (hypothetical) %s:\" , query ); Map < String , Object > successResult = new HashMap <> (); successResult . put ( \"status\" , \"success\" ); successResult . put ( \"results\" , Arrays . asList ( \"result_item1\" , \"result_item2\" )); return successResult ; } } ", "code_blocks": [{"language": "text", "code": "# Conceptual example: Setting policy data intended for tool context\n# In a real ADK app, this might be set in InvocationContext.session.state\n# or passed during tool initialization, then retrieved via ToolContext.\n\npolicy = {} # Assuming policy is a dictionary\npolicy['select_only'] = True\npolicy['tables'] = ['mytable1', 'mytable2']\n\n# Conceptual: Storing policy where the tool can access it via ToolContext later.\n# This specific line might look different in practice.\n# For example, storing in session state:\ninvocation_context.session.state[\"query_tool_policy\"] = policy\n\n# Or maybe passing during tool init:\nquery_tool = QueryTool(policy=policy)\n# For this example, we'll assume it gets stored somewhere accessible."}, {"language": "text", "code": "// Conceptual example: Setting policy data intended for tool context\n// In a real ADK app, this might be set using the session state service.\n// `ctx` is an `agent.Context` available in callbacks or custom agents.\n\npolicy := map[string]interface{}{\n    \"select_only\": true,\n    \"tables\":      []string{\"mytable1\", \"mytable2\"},\n}\n\n// Conceptual: Storing policy where the tool can access it via ToolContext later.\n// This specific line might look different in practice.\n// For example, storing in session state:\nif err := ctx.Session().State().Set(\"query_tool_policy\", policy); err != nil {\n    // Handle error, e.g., log it.\n}\n\n// Or maybe passing during tool init:\n// queryTool := NewQueryTool(policy)\n// For this example, we'll assume it gets stored somewhere accessible."}, {"language": "text", "code": "// Conceptual example: Setting policy data intended for tool context\n// In a real ADK app, this might be set in InvocationContext.session.state\n// or passed during tool initialization, then retrieved via ToolContext.\n\npolicy = new HashMap<String, Object>(); // Assuming policy is a Map\npolicy.put(\"select_only\", true);\npolicy.put(\"tables\", new ArrayList<>(\"mytable1\", \"mytable2\"));\n\n// Conceptual: Storing policy where the tool can access it via ToolContext later.\n// This specific line might look different in practice.\n// For example, storing in session state:\ninvocationContext.session().state().put(\"query_tool_policy\", policy);\n\n// Or maybe passing during tool init:\nquery_tool = QueryTool(policy);\n// For this example, we'll assume it gets stored somewhere accessible."}, {"language": "text", "code": "def query(query: str, tool_context: ToolContext) -> str | dict:\n  # Assume 'policy' is retrieved from context, e.g., via session state:\n  # policy = tool_context.invocation_context.session.state.get('query_tool_policy', {})\n\n  # --- Placeholder Policy Enforcement ---\n  policy = tool_context.invocation_context.session.state.get('query_tool_policy', {}) # Example retrieval\n  actual_tables = explainQuery(query) # Hypothetical function call\n\n  if not set(actual_tables).issubset(set(policy.get('tables', []))):\n    # Return an error message for the model\n    allowed = \", \".join(policy.get('tables', ['(None defined)']))\n    return f\"Error: Query targets unauthorized tables. Allowed: {allowed}\"\n\n  if policy.get('select_only', False):\n       if not query.strip().upper().startswith(\"SELECT\"):\n           return \"Error: Policy restricts queries to SELECT statements only.\"\n  # --- End Policy Enforcement ---\n\n  print(f\"Executing validated query (hypothetical): {query}\")\n  return {\"status\": \"success\", \"results\": [...]} # Example successful return"}, {"language": "text", "code": "import (\n    \"fmt\"\n    \"strings\"\n\n    \"google.golang.org/adk/tool\"\n)\n\nfunc query(query string, toolContext *tool.Context) (any, error) {\n    // Assume 'policy' is retrieved from context, e.g., via session state:\n    policyAny, err := toolContext.State().Get(\"query_tool_policy\")\n    if err != nil {\n        return nil, fmt.Errorf(\"could not retrieve policy: %w\", err)\n    }       policy, _ := policyAny.(map[string]interface{})\n    actualTables := explainQuery(query) // Hypothetical function call\n\n    // --- Placeholder Policy Enforcement ---\n    if tables, ok := policy[\"tables\"].([]string); ok {\n        if !isSubset(actualTables, tables) {\n            // Return an error to signal failure\n            allowed := strings.Join(tables, \", \")\n            if allowed == \"\" {\n                allowed = \"(None defined)\"\n            }\n            return nil, fmt.Errorf(\"query targets unauthorized tables. Allowed: %s\", allowed)\n        }\n    }\n\n    if selectOnly, _ := policy[\"select_only\"].(bool); selectOnly {\n        if !strings.HasPrefix(strings.ToUpper(strings.TrimSpace(query)), \"SELECT\") {\n            return nil, fmt.Errorf(\"policy restricts queries to SELECT statements only\")\n        }\n    }\n    // --- End Policy Enforcement ---\n\n    fmt.Printf(\"Executing validated query (hypothetical): %s\\n\", query)\n    return map[string]interface{}{\"status\": \"success\", \"results\": []string{\"...\"}}, nil\n}\n\n// Helper function to check if a is a subset of b\nfunc isSubset(a, b []string) bool {\n    set := make(map[string]bool)\n    for _, item := range b {\n        set[item] = true\n    }\n    for _, item := range a {\n        if _, found := set[item]; !found {\n            return false\n        }\n    }\n    return true\n}"}, {"language": "text", "code": "import com.google.adk.tools.ToolContext;\nimport java.util.*;\n\nclass ToolContextQuery {\n\n  public Object query(String query, ToolContext toolContext) {\n\n    // Assume 'policy' is retrieved from context, e.g., via session state:\n    Map<String, Object> queryToolPolicy =\n        toolContext.invocationContext.session().state().getOrDefault(\"query_tool_policy\", null);\n    List<String> actualTables = explainQuery(query);\n\n    // --- Placeholder Policy Enforcement ---\n    if (!queryToolPolicy.get(\"tables\").containsAll(actualTables)) {\n      List<String> allowedPolicyTables =\n          (List<String>) queryToolPolicy.getOrDefault(\"tables\", new ArrayList<String>());\n\n      String allowedTablesString =\n          allowedPolicyTables.isEmpty() ? \"(None defined)\" : String.join(\", \", allowedPolicyTables);\n\n      return String.format(\n          \"Error: Query targets unauthorized tables. Allowed: %s\", allowedTablesString);\n    }\n\n    if (!queryToolPolicy.get(\"select_only\")) {\n      if (!query.trim().toUpperCase().startswith(\"SELECT\")) {\n        return \"Error: Policy restricts queries to SELECT statements only.\";\n      }\n    }\n    // --- End Policy Enforcement ---\n\n    System.out.printf(\"Executing validated query (hypothetical) %s:\", query);\n    Map<String, Object> successResult = new HashMap<>();\n    successResult.put(\"status\", \"success\");\n    successResult.put(\"results\", Arrays.asList(\"result_item1\", \"result_item2\"));\n    return successResult;\n  }\n}"}]}, {"heading_path": ["Built-in Gemini Safety Features\u00b6"], "text": "Built-in Gemini Safety Features \u00b6 Gemini models come with in-built safety mechanisms that can be leveraged to improve content and brand safety. Content safety filters : Content filters can help block the output of harmful content. They function independently from Gemini models as part of a layered defense against threat actors who attempt to jailbreak the model. Gemini models on Vertex AI use two types of content filters: Non-configurable safety filters automatically block outputs containing prohibited content, such as child sexual abuse material (CSAM) and personally identifiable information (PII). Configurable content filters allow you to define blocking thresholds in four harm categories (hate speech, harassment, sexually explicit, and dangerous content,) based on probability and severity scores. These filters are default off but you can configure them according to your needs. System instructions for safety : System instructions for Gemini models in Vertex AI provide direct guidance to the model on how to behave and what type of content to generate. By providing specific instructions, you can proactively steer the model away from generating undesirable content to meet your organization\u2019s unique needs. You can craft system instructions to define content safety guidelines, such as prohibited and sensitive topics, and disclaimer language, as well as brand safety guidelines to ensure the model's outputs align with your brand's voice, tone, values, and target audience. While these measures are robust against content safety, you need additional checks to reduce agent misalignment, unsafe actions, and brand safety risks. ", "code_blocks": []}, {"heading_path": ["Callbacks and Plugins for Security Guardrails\u00b6"], "text": "Callbacks and Plugins for Security Guardrails \u00b6 Callbacks provide a simple, agent-specific method for adding pre-validation to tool and model I/O, whereas plugins offer a reusable solution for implementing general security policies across multiple agents. When modifications to the tools to add guardrails aren't possible, the Before Tool Callback function can be used to add pre-validation of calls. The callback has access to the agent's state, the requested tool and parameters. This approach is very general and can even be created to create a common library of re-usable tool policies. However, it might not be applicable for all tools if the information to enforce the guardrails isn't directly visible in the parameters. Python Go Java # Hypothetical callback function def validate_tool_params ( callback_context : CallbackContext , # Correct context type tool : BaseTool , args : Dict [ str , Any ], tool_context : ToolContext ) -> Optional [ Dict ]: # Correct return type for before_tool_callback print ( f \"Callback triggered for tool: { tool . name } , args: { args } \" ) # Example validation: Check if a required user ID from state matches an arg expected_user_id = callback_context . state . get ( \"session_user_id\" ) actual_user_id_in_args = args . get ( \"user_id_param\" ) # Assuming tool takes 'user_id_param' if actual_user_id_in_args != expected_user_id : print ( \"Validation Failed: User ID mismatch!\" ) # Return a dictionary to prevent tool execution and provide feedback return { \"error\" : f \"Tool call blocked: User ID mismatch.\" } # Return None to allow the tool call to proceed if validation passes print ( \"Callback validation passed.\" ) return None # Hypothetical Agent setup root_agent = LlmAgent ( # Use specific agent type model = 'gemini-2.0-flash' , name = 'root_agent' , instruction = \"...\" , before_tool_callback = validate_tool_params , # Assign the callback tools = [ # ... list of tool functions or Tool instances ... # e.g., query_tool_instance ] ) import ( \"fmt\" \"reflect\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/tool\" ) // Hypothetical callback function func validateToolParams ( ctx tool . Context , t tool . Tool , args map [ string ] any , ) ( map [ string ] any , error ) { fmt . Printf ( \"Callback triggered for tool: %s, args: %v\\n\" , t . Name (), args ) // Example validation: Check if a required user ID from state matches an arg expectedUserID , err := ctx . State (). Get ( \"session_user_id\" ) if err != nil { // This is an unexpected failure, return an error. return nil , fmt . Errorf ( \"internal error: session_user_id not found in state: %w\" , err ) } expectedUserID , ok := expectedUserIDVal .( string ) if ! ok { return nil , fmt . Errorf ( \"internal error: session_user_id in state is not a string, got %T\" , expectedUserIDVal ) } actualUserIDInArgs , exists := args [ \"user_id_param\" ] if ! exists { // Handle case where user_id_param is not in args fmt . Println ( \"Validation Failed: user_id_param missing from arguments!\" ) return map [ string ] any { \"error\" : \"Tool call blocked: user_id_param missing from arguments.\" }, nil } actualUserID , ok := actualUserIDInArgs .( string ) if ! ok { // Handle case where user_id_param is not a string fmt . Println ( \"Validation Failed: user_id_param is not a string!\" ) return map [ string ] any { \"error\" : \"Tool call blocked: user_id_param is not a string.\" }, nil } if actualUserID != expectedUserID { fmt . Println ( \"Validation Failed: User ID mismatch!\" ) // Return a map to prevent tool execution and provide feedback to the model. // This is not a Go error, but a message for the agent. return map [ string ] any { \"error\" : \"Tool call blocked: User ID mismatch.\" }, nil } // Return nil, nil to allow the tool call to proceed if validation passes fmt . Println ( \"Callback validation passed.\" ) return nil , nil } // Hypothetical Agent setup // rootAgent, err := llmagent.New(llmagent.Config{ //  Model: \"gemini-2.0-flash\", //  Name: \"root_agent\", //  Instruction: \"...\", //  BeforeToolCallbacks: []llmagent.BeforeToolCallback{validateToolParams}, //  Tools: []tool.Tool{queryToolInstance}, // }) // Hypothetical callback function public Optional < Map < String , Object >> validateToolParams ( CallbackContext callbackContext , Tool baseTool , Map < String , Object > input , ToolContext toolContext ) { System . out . printf ( \"Callback triggered for tool: %s, Args: %s\" , baseTool . name (), input ); // Example validation: Check if a required user ID from state matches an input parameter Object expectedUserId = callbackContext . state (). get ( \"session_user_id\" ); Object actualUserIdInput = input . get ( \"user_id_param\" ); // Assuming tool takes 'user_id_param' if ( ! actualUserIdInput . equals ( expectedUserId )) { System . out . println ( \"Validation Failed: User ID mismatch!\" ); // Return to prevent tool execution and provide feedback return Optional . of ( Map . of ( \"error\" , \"Tool call blocked: User ID mismatch.\" )); } // Return to allow the tool call to proceed if validation passes System . out . println ( \"Callback validation passed.\" ); return Optional . empty (); } // Hypothetical Agent setup public void runAgent () { LlmAgent agent = LlmAgent . builder () . model ( \"gemini-2.0-flash\" ) . name ( \"AgentWithBeforeToolCallback\" ) . instruction ( \"...\" ) . beforeToolCallback ( this :: validateToolParams ) // Assign the callback . tools ( anyToolToUse ) // Define the tool to be used . build (); } However, when adding security guardrails to your agent applications, plugins are the recommended approach for implementing policies that are not specific to a single agent. Plugins are designed to be self-contained and modular, allowing you to create individual plugins for specific security policies, and apply them globally at the runner level. This means that a security plugin can be configured once and applied to every agent that uses the runner, ensuring consistent security guardrails across your entire application without repetitive code. Some examples include: Gemini as a Judge Plugin : This plugin uses Gemini Flash Lite to evaluate user inputs, tool input and output, and agent's response for appropriateness, prompt injection, and jailbreak detection. The plugin configures Gemini to act as a safety filter to mitigate against content safety, brand safety, and agent misalignment. The plugin is configured to pass user input, tool input and output, and model output to Gemini Flash Lite, who decides if the input to the agent is safe or unsafe. If Gemini decides the input is unsafe, the agent returns a predetermined response: \"Sorry I cannot help with that. Can I help you with something else?\". Model Armor Plugin : A plugin that queries the model armor API to check for potential content safety violations at specified points of agent execution. Similar to the Gemini as a Judge plugin, if Model Armor finds matches of harmful content, it returns a predetermined response to the user. PII Redaction Plugin : A specialized plugin with design for the Before Tool Callback and specifically created to redact personally identifiable information before it\u2019s processed by a tool or sent to an external service. ", "code_blocks": [{"language": "text", "code": "# Hypothetical callback function\ndef validate_tool_params(\n    callback_context: CallbackContext, # Correct context type\n    tool: BaseTool,\n    args: Dict[str, Any],\n    tool_context: ToolContext\n    ) -> Optional[Dict]: # Correct return type for before_tool_callback\n\n  print(f\"Callback triggered for tool: {tool.name}, args: {args}\")\n\n  # Example validation: Check if a required user ID from state matches an arg\n  expected_user_id = callback_context.state.get(\"session_user_id\")\n  actual_user_id_in_args = args.get(\"user_id_param\") # Assuming tool takes 'user_id_param'\n\n  if actual_user_id_in_args != expected_user_id:\n      print(\"Validation Failed: User ID mismatch!\")\n      # Return a dictionary to prevent tool execution and provide feedback\n      return {\"error\": f\"Tool call blocked: User ID mismatch.\"}\n\n  # Return None to allow the tool call to proceed if validation passes\n  print(\"Callback validation passed.\")\n  return None\n\n# Hypothetical Agent setup\nroot_agent = LlmAgent( # Use specific agent type\n    model='gemini-2.0-flash',\n    name='root_agent',\n    instruction=\"...\",\n    before_tool_callback=validate_tool_params, # Assign the callback\n    tools = [\n      # ... list of tool functions or Tool instances ...\n      # e.g., query_tool_instance\n    ]\n)"}, {"language": "text", "code": "import (\n    \"fmt\"\n    \"reflect\"\n\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/tool\"\n)\n\n// Hypothetical callback function\nfunc validateToolParams(\n    ctx tool.Context,\n    t tool.Tool,\n    args map[string]any,\n) (map[string]any, error) {\n    fmt.Printf(\"Callback triggered for tool: %s, args: %v\\n\", t.Name(), args)\n\n    // Example validation: Check if a required user ID from state matches an arg\n    expectedUserID, err := ctx.State().Get(\"session_user_id\")\n    if err != nil {\n        // This is an unexpected failure, return an error.\n        return nil, fmt.Errorf(\"internal error: session_user_id not found in state: %w\", err)\n    }\n            expectedUserID, ok := expectedUserIDVal.(string)\n    if !ok {\n        return nil, fmt.Errorf(\"internal error: session_user_id in state is not a string, got %T\", expectedUserIDVal)\n    }\n\n    actualUserIDInArgs, exists := args[\"user_id_param\"]\n    if !exists {\n        // Handle case where user_id_param is not in args\n        fmt.Println(\"Validation Failed: user_id_param missing from arguments!\")\n        return map[string]any{\"error\": \"Tool call blocked: user_id_param missing from arguments.\"}, nil\n    }\n\n    actualUserID, ok := actualUserIDInArgs.(string)\n    if !ok {\n        // Handle case where user_id_param is not a string\n        fmt.Println(\"Validation Failed: user_id_param is not a string!\")\n        return map[string]any{\"error\": \"Tool call blocked: user_id_param is not a string.\"}, nil\n    }\n\n    if actualUserID != expectedUserID {\n        fmt.Println(\"Validation Failed: User ID mismatch!\")\n        // Return a map to prevent tool execution and provide feedback to the model.\n        // This is not a Go error, but a message for the agent.\n        return map[string]any{\"error\": \"Tool call blocked: User ID mismatch.\"}, nil\n    }\n    // Return nil, nil to allow the tool call to proceed if validation passes\n    fmt.Println(\"Callback validation passed.\")\n    return nil, nil\n}\n\n// Hypothetical Agent setup\n// rootAgent, err := llmagent.New(llmagent.Config{\n//  Model: \"gemini-2.0-flash\",\n//  Name: \"root_agent\",\n//  Instruction: \"...\",\n//  BeforeToolCallbacks: []llmagent.BeforeToolCallback{validateToolParams},\n//  Tools: []tool.Tool{queryToolInstance},\n// })"}, {"language": "text", "code": "// Hypothetical callback function\npublic Optional<Map<String, Object>> validateToolParams(\n  CallbackContext callbackContext,\n  Tool baseTool,\n  Map<String, Object> input,\n  ToolContext toolContext) {\n\nSystem.out.printf(\"Callback triggered for tool: %s, Args: %s\", baseTool.name(), input);\n\n// Example validation: Check if a required user ID from state matches an input parameter\nObject expectedUserId = callbackContext.state().get(\"session_user_id\");\nObject actualUserIdInput = input.get(\"user_id_param\"); // Assuming tool takes 'user_id_param'\n\nif (!actualUserIdInput.equals(expectedUserId)) {\n  System.out.println(\"Validation Failed: User ID mismatch!\");\n  // Return to prevent tool execution and provide feedback\n  return Optional.of(Map.of(\"error\", \"Tool call blocked: User ID mismatch.\"));\n}\n\n// Return to allow the tool call to proceed if validation passes\nSystem.out.println(\"Callback validation passed.\");\nreturn Optional.empty();\n}\n\n// Hypothetical Agent setup\npublic void runAgent() {\nLlmAgent agent =\n    LlmAgent.builder()\n        .model(\"gemini-2.0-flash\")\n        .name(\"AgentWithBeforeToolCallback\")\n        .instruction(\"...\")\n        .beforeToolCallback(this::validateToolParams) // Assign the callback\n        .tools(anyToolToUse) // Define the tool to be used\n        .build();\n}"}]}, {"heading_path": ["Sandboxed Code Execution\u00b6"], "text": "Sandboxed Code Execution \u00b6 Code execution is a special tool that has extra security implications: sandboxing must be used to prevent model-generated code to compromise the local environment, potentially creating security issues. Google and the ADK provide several options for safe code execution. Vertex Gemini Enterprise API code execution feature enables agents to take advantage of sandboxed code execution server-side by enabling the tool_execution tool. For code performing data analysis, you can use the built-in Code Executor tool in ADK to call the Vertex Code Interpreter Extension . If none of these options satisfy your requirements, you can build your own code executor using the building blocks provided by the ADK. We recommend creating execution environments that are hermetic: no network connections and API calls permitted to avoid uncontrolled data exfiltration; and full clean up of data across execution to not create cross-user exfiltration concerns. ", "code_blocks": []}, {"heading_path": ["Evaluations\u00b6"], "text": "Evaluations \u00b6 See Evaluate Agents . ", "code_blocks": []}, {"heading_path": ["VPC-SC Perimeters and Network Controls\u00b6"], "text": "VPC-SC Perimeters and Network Controls \u00b6 If you are executing your agent into a VPC-SC perimeter, that will guarantee that all API calls will only be manipulating resources within the perimeter, reducing the chance of data exfiltration. However, identity and perimeters only provide coarse controls around agent actions. Tool-use guardrails mitigate such limitations, and give more power to agent developers to finely control which actions to allow. ", "code_blocks": []}, {"heading_path": ["Other Security Risks\u00b6"], "text": "Other Security Risks \u00b6 ", "code_blocks": []}, {"heading_path": ["Always Escape Model-Generated Content in UIs\u00b6"], "text": "Always Escape Model-Generated Content in UIs \u00b6 Care must be taken when agent output is visualized in a browser: if HTML or JS content isn't properly escaped in the UI, the text returned by the model could be executed, leading to data exfiltration. For example, an indirect prompt injection can trick a model to include an img tag tricking the browser to send the session content to a 3rd party site; or construct URLs that, if clicked, send data to external sites. Proper escaping of such content must ensure that model-generated text isn't interpreted as code by browsers. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:32.111288", "source_type": "adk-docs"}
{"doc_id": "5e8a0f91e11ed113f72df1f34bde37b2d8a80e8d3d189334d71b4bc5ef09e642", "url": "https://google.github.io/adk-docs/get-started/about", "title": "Technical Overview - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Agent Development Kit (ADK)\u00b6"], "text": "Agent Development Kit (ADK) \u00b6 Build, Evaluate and Deploy agents, seamlessly! ADK is designed to empower developers\nto build, manage, evaluate and deploy AI-powered agents. It provides a robust\nand flexible environment for creating both conversational and non-conversational\nagents, capable of handling complex tasks and workflows. ", "code_blocks": []}, {"heading_path": ["Core Concepts\u00b6"], "text": "Core Concepts \u00b6 ADK is built around a few key primitives and concepts that make it\npowerful and flexible. Here are the essentials: Agent: The fundamental worker unit designed for specific tasks. Agents can\n  use language models ( LlmAgent ) for complex reasoning, or act as deterministic controllers of the execution, which are called \" workflow agents \" ( SequentialAgent , ParallelAgent , LoopAgent ). Tool: Gives agents abilities beyond conversation, letting them interact\n  with external APIs, search information, run code, or call other services. Callbacks: Custom code snippets you provide to run at specific points in\n  the agent's process, allowing for checks, logging, or behavior modifications. Session Management ( Session & State ): Handles the context of a single\n  conversation ( Session ), including its history ( Events ) and the agent's\n  working memory for that conversation ( State ). Memory: Enables agents to recall information about a user across multiple sessions, providing long-term context (distinct from short-term\n  session State ). Artifact Management ( Artifact ): Allows agents to save, load, and manage\n  files or binary data (like images, PDFs) associated with a session or user. Code Execution: The ability for agents (usually via Tools) to generate and\n  execute code to perform complex calculations or actions. Planning: An advanced capability where agents can break down complex goals\n  into smaller steps and plan how to achieve them like a ReAct planner. Models: The underlying LLM that powers LlmAgent s, enabling their\n  reasoning and language understanding abilities. Event: The basic unit of communication representing things that happen\n  during a session (user message, agent reply, tool use), forming the\n  conversation history. Runner: The engine that manages the execution flow, orchestrates agent\n  interactions based on Events, and coordinates with backend services. Note: Features like Multimodal Streaming, Evaluation, Deployment,\nDebugging, and Trace are also part of the broader ADK ecosystem, supporting\nreal-time interaction and the development lifecycle. ", "code_blocks": []}, {"heading_path": ["Key Capabilities\u00b6"], "text": "Key Capabilities \u00b6 ADK offers several key advantages for developers building\nagentic applications: Multi-Agent System Design: Easily build applications composed of\n   multiple, specialized agents arranged hierarchically. Agents can coordinate\n   complex tasks, delegate sub-tasks using LLM-driven transfer or explicit AgentTool invocation, enabling modular and scalable solutions. Rich Tool Ecosystem: Equip agents with diverse capabilities. ADK\n   supports integrating custom functions ( FunctionTool ), using other agents as\n   tools ( AgentTool ), leveraging built-in functionalities like code execution,\n   and interacting with external data sources and APIs (e.g., Search,\n   Databases). Support for long-running tools allows handling asynchronous\n   operations effectively. Flexible Orchestration: Define complex agent workflows using built-in\n   workflow agents ( SequentialAgent , ParallelAgent , LoopAgent ) alongside\n   LLM-driven dynamic routing. This allows for both predictable pipelines and\n   adaptive agent behavior. Integrated Developer Tooling: Develop and iterate locally with ease.\n   ADK includes tools like a command-line interface (CLI) and a Developer\n   UI for running agents, inspecting execution steps (events, state changes),\n   debugging interactions, and visualizing agent definitions. Native Streaming Support: Build real-time, interactive experiences with\n   native support for bidirectional streaming (text and audio). This integrates\n   seamlessly with underlying capabilities like the Multimodal Live API for the Gemini Developer API (or for Vertex AI ),\n   often enabled with simple configuration changes. Built-in Agent Evaluation: Assess agent performance systematically. The\n   framework includes tools to create multi-turn evaluation datasets and run\n   evaluations locally (via CLI or the dev UI) to measure quality and\n   guide improvements. Broad LLM Support: While optimized for Google's Gemini models, the\n   framework is designed for flexibility, allowing integration with various LLMs\n   (potentially including open-source or fine-tuned models) through its BaseLlm interface. Artifact Management: Enable agents to handle files and binary data. The\n   framework provides mechanisms ( ArtifactService , context methods) for agents\n   to save, load, and manage versioned artifacts like images, documents, or\n   generated reports during their execution. Extensibility and Interoperability: ADK promotes an open\n   ecosystem. While providing core tools, it allows developers to easily\n   integrate and reuse third-party tools and data connectors. State and Memory Management: Automatically handles short-term\n    conversational memory ( State within a Session ) managed by the SessionService . Provides integration points for longer-term Memory services, allowing agents to recall user information across multiple\n    sessions. ", "code_blocks": []}, {"heading_path": ["Get Started\u00b6"], "text": "Get Started \u00b6 Ready to build your first agent? Try the quickstart Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:32.524354", "source_type": "adk-docs"}
{"doc_id": "547e7f4a72233c79a7dc0b586934c21ec6866552a895f4b5dcd3af769268d1e7", "url": "https://google.github.io/adk-docs/context", "title": "Context - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Context\u00b6"], "text": "Context \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 In the Agent Development Kit (ADK), \"context\" refers to the crucial bundle of information available to your agent and its tools during specific operations. Think of it as the necessary background knowledge and resources needed to handle a current task or conversation turn effectively. Agents often need more than just the latest user message to perform well. Context is essential because it enables: Maintaining State: Remembering details across multiple steps in a conversation (e.g., user preferences, previous calculations, items in a shopping cart). This is primarily managed through session state . Passing Data: Sharing information discovered or generated in one step (like an LLM call or a tool execution) with subsequent steps. Session state is key here too. Accessing Services: Interacting with framework capabilities like: Artifact Storage: Saving or loading files or data blobs (like PDFs, images, configuration files) associated with the session. Memory: Searching for relevant information from past interactions or external knowledge sources connected to the user. Authentication: Requesting and retrieving credentials needed by tools to access external APIs securely. Identity and Tracking: Knowing which agent is currently running ( agent.name ) and uniquely identifying the current request-response cycle ( invocation_id ) for logging and debugging. Tool-Specific Actions: Enabling specialized operations within tools, such as requesting authentication or searching memory, which require access to the current interaction's details. The central piece holding all this information together for a single, complete user-request-to-final-response cycle (an invocation ) is the InvocationContext . However, you typically won't create or manage this object directly. The ADK framework creates it when an invocation starts (e.g., via runner.run_async ) and passes the relevant contextual information implicitly to your agent code, callbacks, and tools. Python Go Java # Conceptual Pseudocode: How the framework provides context (Internal Logic) # runner = Runner(agent=my_root_agent, session_service=..., artifact_service=...) # user_message = types.Content(...) # session = session_service.get_session(...) # Or create new # --- Inside runner.run_async(...) --- # 1. Framework creates the main context for this specific run # invocation_context = InvocationContext( #     invocation_id=\"unique-id-for-this-run\", #     session=session, #     user_content=user_message, #     agent=my_root_agent, # The starting agent #     session_service=session_service, #     artifact_service=artifact_service, #     memory_service=memory_service, #     # ... other necessary fields ... # ) # # 2. Framework calls the agent's run method, passing the context implicitly #    (The agent's method signature will receive it, e.g., runAsyncImpl(InvocationContext invocationContext)) # await my_root_agent.run_async(invocation_context) #   --- End Internal Logic --- # # As a developer, you work with the context objects provided in method arguments. /* Conceptual Pseudocode: How the framework provides context (Internal Logic) */ sessionService := session . InMemoryService () r , err := runner . New ( runner . Config { AppName : appName , Agent : myAgent , SessionService : sessionService , }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } s , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , }) if err != nil { log . Fatalf ( \"FATAL: Failed to create session: %v\" , err ) } scanner := bufio . NewScanner ( os . Stdin ) for { fmt . Print ( \"\\nYou > \" ) if ! scanner . Scan () { break } userInput := scanner . Text () if strings . EqualFold ( userInput , \"quit\" ) { break } userMsg := genai . NewContentFromText ( userInput , genai . RoleUser ) events := r . Run ( ctx , s . Session . UserID (), s . Session . ID (), userMsg , agent . RunConfig { StreamingMode : agent . StreamingModeNone , }) fmt . Print ( \"\\nAgent > \" ) for event , err := range events { if err != nil { log . Printf ( \"ERROR during agent execution: %v\" , err ) break } fmt . Print ( event . Content . Parts [ 0 ]. Text ) } } /* Conceptual Pseudocode: How the framework provides context (Internal Logic) */ InMemoryRunner runner = new InMemoryRunner ( agent ); Session session = runner . sessionService () . createSession ( runner . appName (), USER_ID , initialState , SESSION_ID ) . blockingGet (); try ( Scanner scanner = new Scanner ( System . in , StandardCharsets . UTF_8 )) { while ( true ) { System . out . print ( \"\\nYou > \" ); } String userInput = scanner . nextLine (); if ( \"quit\" . equalsIgnoreCase ( userInput )) { break ; } Content userMsg = Content . fromParts ( Part . fromText ( userInput )); Flowable < Event > events = runner . runAsync ( session . userId (), session . id (), userMsg ); System . out . print ( \"\\nAgent > \" ); events . blockingForEach ( event -> System . out . print ( event . stringifyContent ())); } ", "code_blocks": [{"language": "text", "code": "# Conceptual Pseudocode: How the framework provides context (Internal Logic)\n\n# runner = Runner(agent=my_root_agent, session_service=..., artifact_service=...)\n# user_message = types.Content(...)\n# session = session_service.get_session(...) # Or create new\n\n# --- Inside runner.run_async(...) ---\n# 1. Framework creates the main context for this specific run\n# invocation_context = InvocationContext(\n#     invocation_id=\"unique-id-for-this-run\",\n#     session=session,\n#     user_content=user_message,\n#     agent=my_root_agent, # The starting agent\n#     session_service=session_service,\n#     artifact_service=artifact_service,\n#     memory_service=memory_service,\n#     # ... other necessary fields ...\n# )\n#\n# 2. Framework calls the agent's run method, passing the context implicitly\n#    (The agent's method signature will receive it, e.g., runAsyncImpl(InvocationContext invocationContext))\n# await my_root_agent.run_async(invocation_context)\n#   --- End Internal Logic ---\n#\n# As a developer, you work with the context objects provided in method arguments."}, {"language": "text", "code": "/* Conceptual Pseudocode: How the framework provides context (Internal Logic) */\nsessionService := session.InMemoryService()\n\nr, err := runner.New(runner.Config{\n    AppName:        appName,\n    Agent:          myAgent,\n    SessionService: sessionService,\n})\nif err != nil {\n    log.Fatalf(\"Failed to create runner: %v\", err)\n}\n\ns, err := sessionService.Create(ctx, &session.CreateRequest{\n    AppName: appName,\n    UserID:  userID,\n})\nif err != nil {\n    log.Fatalf(\"FATAL: Failed to create session: %v\", err)\n}\n\nscanner := bufio.NewScanner(os.Stdin)\nfor {\n    fmt.Print(\"\\nYou > \")\n    if !scanner.Scan() {\n        break\n    }\n    userInput := scanner.Text()\n    if strings.EqualFold(userInput, \"quit\") {\n        break\n    }\n    userMsg := genai.NewContentFromText(userInput, genai.RoleUser)\n    events := r.Run(ctx, s.Session.UserID(), s.Session.ID(), userMsg, agent.RunConfig{\n        StreamingMode: agent.StreamingModeNone,\n    })\n    fmt.Print(\"\\nAgent > \")\n    for event, err := range events {\n        if err != nil {\n            log.Printf(\"ERROR during agent execution: %v\", err)\n            break\n        }\n        fmt.Print(event.Content.Parts[0].Text)\n    }\n}"}, {"language": "text", "code": "/* Conceptual Pseudocode: How the framework provides context (Internal Logic) */\nInMemoryRunner runner = new InMemoryRunner(agent);\nSession session = runner\n    .sessionService()\n    .createSession(runner.appName(), USER_ID, initialState, SESSION_ID )\n    .blockingGet();\n\ntry (Scanner scanner = new Scanner(System.in, StandardCharsets.UTF_8)) {\n  while (true) {\n    System.out.print(\"\\nYou > \");\n  }\n  String userInput = scanner.nextLine();\n  if (\"quit\".equalsIgnoreCase(userInput)) {\n    break;\n  }\n  Content userMsg = Content.fromParts(Part.fromText(userInput));\n  Flowable<Event> events = runner.runAsync(session.userId(), session.id(), userMsg);\n  System.out.print(\"\\nAgent > \");\n  events.blockingForEach(event -> System.out.print(event.stringifyContent()));\n}"}]}, {"heading_path": ["The Different types of Context\u00b6"], "text": "The Different types of Context \u00b6 While InvocationContext acts as the comprehensive internal container, ADK provides specialized context objects tailored to specific situations. This ensures you have the right tools and permissions for the task at hand without needing to handle the full complexity of the internal context everywhere. Here are the different \"flavors\" you'll encounter: InvocationContext Where Used: Received as the ctx argument directly within an agent's core implementation methods ( _run_async_impl , _run_live_impl ). Purpose: Provides access to the entire state of the current invocation. This is the most comprehensive context object. Key Contents: Direct access to session (including state and events ), the current agent instance, invocation_id , initial user_content , references to configured services ( artifact_service , memory_service , session_service ), and fields related to live/streaming modes. Use Case: Primarily used when the agent's core logic needs direct access to the overall session or services, though often state and artifact interactions are delegated to callbacks/tools which use their own contexts. Also used to control the invocation itself (e.g., setting ctx.end_invocation = True ). Python Go Java # Pseudocode: Agent implementation receiving InvocationContext from google.adk.agents import BaseAgent from google.adk.agents.invocation_context import InvocationContext from google.adk.events import Event from typing import AsyncGenerator class MyAgent ( BaseAgent ): async def _run_async_impl ( self , ctx : InvocationContext ) -> AsyncGenerator [ Event , None ]: # Direct access example agent_name = ctx . agent . name session_id = ctx . session . id print ( f \"Agent { agent_name } running in session { session_id } for invocation { ctx . invocation_id } \" ) # ... agent logic using ctx ... yield # ... event ... import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/session\" ) // Pseudocode: Agent implementation receiving InvocationContext type MyAgent struct { } func ( a * MyAgent ) Run ( ctx agent . InvocationContext ) iter . Seq2 [ * session . Event , error ] { return func ( yield func ( * session . Event , error ) bool ) { // Direct access example agentName := ctx . Agent (). Name () sessionID := ctx . Session (). ID () fmt . Printf ( \"Agent %s running in session %s for invocation %s\\n\" , agentName , sessionID , ctx . InvocationID ()) // ... agent logic using ctx ... yield ( & session . Event { Author : agentName }, nil ) } } // Pseudocode: Agent implementation receiving InvocationContext import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.InvocationContext ; LlmAgent root_agent = LlmAgent . builder () . model ( \"gemini-***\" ) . name ( \"sample_agent\" ) . description ( \"Answers user questions.\" ) . instruction ( \"\"\" provide instruction for the agent here. \"\"\" ) . tools ( sampleTool ) . outputKey ( \"YOUR_KEY\" ) . build (); ConcurrentMap < String , Object > initialState = new ConcurrentHashMap <> (); initialState . put ( \"YOUR_KEY\" , \"\" ); InMemoryRunner runner = new InMemoryRunner ( agent ); Session session = runner . sessionService () . createSession ( runner . appName (), USER_ID , initialState , SESSION_ID ) . blockingGet (); try ( Scanner scanner = new Scanner ( System . in , StandardCharsets . UTF_8 )) { while ( true ) { System . out . print ( \"\\nYou > \" ); String userInput = scanner . nextLine (); if ( \"quit\" . equalsIgnoreCase ( userInput )) { break ; } Content userMsg = Content . fromParts ( Part . fromText ( userInput )); Flowable < Event > events = runner . runAsync ( session . userId (), session . id (), userMsg ); System . out . print ( \"\\nAgent > \" ); events . blockingForEach ( event -> System . out . print ( event . stringifyContent ())); } protected Flowable < Event > runAsyncImpl ( InvocationContext invocationContext ) { // Direct access example String agentName = invocationContext . agent . name String sessionId = invocationContext . session . id String invocationId = invocationContext . invocationId System . out . println ( \"Agent \" + agent_name + \" running in session \" + session_id + \" for invocation \" + invocationId ) // ... agent logic using ctx ... } ReadonlyContext Where Used: Provided in scenarios where only read access to basic information is needed and mutation is disallowed (e.g., InstructionProvider functions). It's also the base class for other contexts. Purpose: Offers a safe, read-only view of fundamental contextual details. Key Contents: invocation_id , agent_name , and a read-only view of the current state . Python Go Java # Pseudocode: Instruction provider receiving ReadonlyContext from google.adk.agents.readonly_context import ReadonlyContext def my_instruction_provider ( context : ReadonlyContext ) -> str : # Read-only access example user_tier = context . state () . get ( \"user_tier\" , \"standard\" ) # Can read state # context.state['new_key'] = 'value' # This would typically cause an error or be ineffective return f \"Process the request for a { user_tier } user.\" import \"google.golang.org/adk/agent\" // Pseudocode: Instruction provider receiving ReadonlyContext func myInstructionProvider ( ctx agent . ReadonlyContext ) ( string , error ) { // Read-only access example userTier , err := ctx . ReadonlyState (). Get ( \"user_tier\" ) if err != nil { userTier = \"standard\" // Default value } // ctx.ReadonlyState() has no Set method since State() is read-only. return fmt . Sprintf ( \"Process the request for a %v user.\" , userTier ), nil } // Pseudocode: Instruction provider receiving ReadonlyContext import com.google.adk.agents.ReadonlyContext ; public String myInstructionProvider ( ReadonlyContext context ){ // Read-only access example String userTier = context . state (). get ( \"user_tier\" , \"standard\" ); context . state (). put ( ' new_key ' , ' value ' ); //This would typically cause an error return \"Process the request for a \" + userTier + \" user.\" } CallbackContext Where Used: Passed as callback_context to agent lifecycle callbacks ( before_agent_callback , after_agent_callback ) and model interaction callbacks ( before_model_callback , after_model_callback ). Purpose: Facilitates inspecting and modifying state, interacting with artifacts, and accessing invocation details specifically within callbacks . Key Capabilities (Adds to ReadonlyContext ): Mutable state Property: Allows reading and writing to session state. Changes made here ( callback_context.state['key'] = value ) are tracked and associated with the event generated by the framework after the callback. Artifact Methods: load_artifact(filename) and save_artifact(filename, part) methods for interacting with the configured artifact_service . Direct user_content access. Python Go Java # Pseudocode: Callback receiving CallbackContext from google.adk.agents.callback_context import CallbackContext from google.adk.models import LlmRequest from google.genai import types from typing import Optional def my_before_model_cb ( callback_context : CallbackContext , request : LlmRequest ) -> Optional [ types . Content ]: # Read/Write state example call_count = callback_context . state . get ( \"model_calls\" , 0 ) callback_context . state [ \"model_calls\" ] = call_count + 1 # Modify state # Optionally load an artifact # config_part = callback_context.load_artifact(\"model_config.json\") print ( f \"Preparing model call # { call_count + 1 } for invocation { callback_context . invocation_id } \" ) return None # Allow model call to proceed import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/model\" ) // Pseudocode: Callback receiving CallbackContext func myBeforeModelCb ( ctx agent . CallbackContext , req * model . LLMRequest ) ( * model . LLMResponse , error ) { // Read/Write state example callCount , err := ctx . State (). Get ( \"model_calls\" ) if err != nil { callCount = 0 // Default value } newCount := callCount .( int ) + 1 if err := ctx . State (). Set ( \"model_calls\" , newCount ); err != nil { return nil , err } // Optionally load an artifact // configPart, err := ctx.Artifacts().Load(\"model_config.json\") fmt . Printf ( \"Preparing model call #%d for invocation %s\\n\" , newCount , ctx . InvocationID ()) return nil , nil // Allow model call to proceed } // Pseudocode: Callback receiving CallbackContext import com.google.adk.agents.CallbackContext ; import com.google.adk.models.LlmRequest ; import com.google.genai.types.Content ; import java.util.Optional ; public Maybe < LlmResponse > myBeforeModelCb ( CallbackContext callbackContext , LlmRequest request ){ // Read/Write state example callCount = callbackContext . state (). get ( \"model_calls\" , 0 ) callbackContext . state (). put ( \"model_calls\" ) = callCount + 1 # Modify state // Optionally load an artifact // Maybe<Part> configPart = callbackContext.loadArtifact(\"model_config.json\"); System . out . println ( \"Preparing model call \" + callCount + 1 ); return Maybe . empty (); // Allow model call to proceed } ToolContext Where Used: Passed as tool_context to the functions backing FunctionTool s and to tool execution callbacks ( before_tool_callback , after_tool_callback ). Purpose: Provides everything CallbackContext does, plus specialized methods essential for tool execution, like handling authentication, searching memory, and listing artifacts. Key Capabilities (Adds to CallbackContext ): Authentication Methods: request_credential(auth_config) to trigger an auth flow, and get_auth_response(auth_config) to retrieve credentials provided by the user/system. Artifact Listing: list_artifacts() to discover available artifacts in the session. Memory Search: search_memory(query) to query the configured memory_service . function_call_id Property: Identifies the specific function call from the LLM that triggered this tool execution, crucial for linking authentication requests or responses back correctly. actions Property: Direct access to the EventActions object for this step, allowing the tool to signal state changes, auth requests, etc. Python Go Java # Pseudocode: Tool function receiving ToolContext from google.adk.tools import ToolContext from typing import Dict , Any # Assume this function is wrapped by a FunctionTool def search_external_api ( query : str , tool_context : ToolContext ) -> Dict [ str , Any ]: api_key = tool_context . state . get ( \"api_key\" ) if not api_key : # Define required auth config # auth_config = AuthConfig(...) # tool_context.request_credential(auth_config) # Request credentials # Use the 'actions' property to signal the auth request has been made # tool_context.actions.requested_auth_configs[tool_context.function_call_id] = auth_config return { \"status\" : \"Auth Required\" } # Use the API key... print ( f \"Tool executing for query ' { query } ' using API key. Invocation: { tool_context . invocation_id } \" ) # Optionally search memory or list artifacts # relevant_docs = tool_context.search_memory(f\"info related to {query}\") # available_files = tool_context.list_artifacts() return { \"result\" : f \"Data for { query } fetched.\" } import \"google.golang.org/adk/tool\" // Pseudocode: Tool function receiving ToolContext type searchExternalAPIArgs struct { Query string `json:\"query\" jsonschema:\"The query to search for.\"` } type searchExternalAPIResults struct { Result string `json:\"result\"` Status string `json:\"status\"` } func searchExternalAPI ( tc tool . Context , input searchExternalAPIArgs ) searchExternalAPIResults { apiKey , err := tc . State (). Get ( \"api_key\" ) if err != nil || apiKey == \"\" { // In a real scenario, you would define and request credentials here. // This is a conceptual placeholder. return searchExternalAPIResults { Status : \"Auth Required\" } } // Use the API key... fmt . Printf ( \"Tool executing for query '%s' using API key. Invocation: %s\\n\" , input . Query , tc . InvocationID ()) // Optionally search memory or list artifacts // relevantDocs, _ := tc.SearchMemory(tc, \"info related to %s\", input.Query)) // availableFiles, _ := tc.Artifacts().List() return searchExternalAPIResults { Result : fmt . Sprintf ( \"Data for %s fetched.\" , input . Query )} } // Pseudocode: Tool function receiving ToolContext import com.google.adk.tools.ToolContext ; import java.util.HashMap ; import java.util.Map ; // Assume this function is wrapped by a FunctionTool public Map < String , Object > searchExternalApi ( String query , ToolContext toolContext ){ String apiKey = toolContext . state . get ( \"api_key\" ); if ( apiKey . isEmpty ()){ // Define required auth config // authConfig = AuthConfig(...); // toolContext.requestCredential(authConfig); # Request credentials // Use the 'actions' property to signal the auth request has been made ... return Map . of ( \"status\" , \"Auth Required\" ); // Use the API key... System . out . println ( \"Tool executing for query \" + query + \" using API key. \" ); // Optionally list artifacts // Single<List<String>> availableFiles = toolContext.listArtifacts(); return Map . of ( \"result\" , \"Data for \" + query + \" fetched\" ); } Understanding these different context objects and when to use them is key to effectively managing state, accessing services, and controlling the flow of your ADK application. The next section will detail common tasks you can perform using these contexts. ", "code_blocks": [{"language": "text", "code": "# Pseudocode: Agent implementation receiving InvocationContext\nfrom google.adk.agents import BaseAgent\nfrom google.adk.agents.invocation_context import InvocationContext\nfrom google.adk.events import Event\nfrom typing import AsyncGenerator\n\nclass MyAgent(BaseAgent):\n    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n        # Direct access example\n        agent_name = ctx.agent.name\n        session_id = ctx.session.id\n        print(f\"Agent {agent_name} running in session {session_id} for invocation {ctx.invocation_id}\")\n        # ... agent logic using ctx ...\n        yield # ... event ..."}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/session\"\n)\n\n// Pseudocode: Agent implementation receiving InvocationContext\ntype MyAgent struct {\n}\n\nfunc (a *MyAgent) Run(ctx agent.InvocationContext) iter.Seq2[*session.Event, error] {\n    return func(yield func(*session.Event, error) bool) {\n        // Direct access example\n        agentName := ctx.Agent().Name()\n        sessionID := ctx.Session().ID()\n        fmt.Printf(\"Agent %s running in session %s for invocation %s\\n\", agentName, sessionID, ctx.InvocationID())\n        // ... agent logic using ctx ...\n        yield(&session.Event{Author: agentName}, nil)\n    }\n}"}, {"language": "text", "code": "// Pseudocode: Agent implementation receiving InvocationContext\nimport com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.InvocationContext;\n\n    LlmAgent root_agent =\n        LlmAgent.builder()\n            .model(\"gemini-***\")\n            .name(\"sample_agent\")\n            .description(\"Answers user questions.\")\n            .instruction(\n                \"\"\"\n                provide instruction for the agent here.\n                \"\"\"\n            )\n            .tools(sampleTool)\n            .outputKey(\"YOUR_KEY\")\n            .build();\n\n    ConcurrentMap<String, Object> initialState = new ConcurrentHashMap<>();\n    initialState.put(\"YOUR_KEY\", \"\");\n\n    InMemoryRunner runner = new InMemoryRunner(agent);\n    Session session =\n          runner\n              .sessionService()\n              .createSession(runner.appName(), USER_ID, initialState, SESSION_ID )\n              .blockingGet();\n\n   try (Scanner scanner = new Scanner(System.in, StandardCharsets.UTF_8)) {\n        while (true) {\n          System.out.print(\"\\nYou > \");\n          String userInput = scanner.nextLine();\n\n          if (\"quit\".equalsIgnoreCase(userInput)) {\n            break;\n          }\n\n          Content userMsg = Content.fromParts(Part.fromText(userInput));\n          Flowable<Event> events = \n                  runner.runAsync(session.userId(), session.id(), userMsg);\n\n          System.out.print(\"\\nAgent > \");\n          events.blockingForEach(event -> \n                  System.out.print(event.stringifyContent()));\n      }\n\n    protected Flowable<Event> runAsyncImpl(InvocationContext invocationContext) {\n        // Direct access example\n        String agentName = invocationContext.agent.name\n        String sessionId = invocationContext.session.id\n        String invocationId = invocationContext.invocationId\n        System.out.println(\"Agent \" + agent_name + \" running in session \" + session_id + \" for invocation \" + invocationId)\n        // ... agent logic using ctx ...\n    }"}, {"language": "text", "code": "# Pseudocode: Instruction provider receiving ReadonlyContext\nfrom google.adk.agents.readonly_context import ReadonlyContext\n\ndef my_instruction_provider(context: ReadonlyContext) -> str:\n    # Read-only access example\n    user_tier = context.state().get(\"user_tier\", \"standard\") # Can read state\n    # context.state['new_key'] = 'value' # This would typically cause an error or be ineffective\n    return f\"Process the request for a {user_tier} user.\""}, {"language": "text", "code": "import \"google.golang.org/adk/agent\"\n\n// Pseudocode: Instruction provider receiving ReadonlyContext\nfunc myInstructionProvider(ctx agent.ReadonlyContext) (string, error) {\n    // Read-only access example\n    userTier, err := ctx.ReadonlyState().Get(\"user_tier\")\n    if err != nil {\n        userTier = \"standard\" // Default value\n    }\n    // ctx.ReadonlyState() has no Set method since State() is read-only.\n    return fmt.Sprintf(\"Process the request for a %v user.\", userTier), nil\n}"}, {"language": "text", "code": "// Pseudocode: Instruction provider receiving ReadonlyContext\nimport com.google.adk.agents.ReadonlyContext;\n\npublic String myInstructionProvider(ReadonlyContext context){\n    // Read-only access example\n    String userTier = context.state().get(\"user_tier\", \"standard\");\n    context.state().put('new_key', 'value'); //This would typically cause an error\n    return \"Process the request for a \" + userTier + \" user.\"\n}"}, {"language": "text", "code": "# Pseudocode: Callback receiving CallbackContext\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.models import LlmRequest\nfrom google.genai import types\nfrom typing import Optional\n\ndef my_before_model_cb(callback_context: CallbackContext, request: LlmRequest) -> Optional[types.Content]:\n    # Read/Write state example\n    call_count = callback_context.state.get(\"model_calls\", 0)\n    callback_context.state[\"model_calls\"] = call_count + 1 # Modify state\n\n    # Optionally load an artifact\n    # config_part = callback_context.load_artifact(\"model_config.json\")\n    print(f\"Preparing model call #{call_count + 1} for invocation {callback_context.invocation_id}\")\n    return None # Allow model call to proceed"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/model\"\n)\n\n// Pseudocode: Callback receiving CallbackContext\nfunc myBeforeModelCb(ctx agent.CallbackContext, req *model.LLMRequest) (*model.LLMResponse, error) {\n    // Read/Write state example\n    callCount, err := ctx.State().Get(\"model_calls\")\n    if err != nil {\n        callCount = 0 // Default value\n    }\n    newCount := callCount.(int) + 1\n    if err := ctx.State().Set(\"model_calls\", newCount); err != nil {\n        return nil, err\n    }\n\n    // Optionally load an artifact\n    // configPart, err := ctx.Artifacts().Load(\"model_config.json\")\n    fmt.Printf(\"Preparing model call #%d for invocation %s\\n\", newCount, ctx.InvocationID())\n    return nil, nil // Allow model call to proceed\n}"}, {"language": "text", "code": "// Pseudocode: Callback receiving CallbackContext\nimport com.google.adk.agents.CallbackContext;\nimport com.google.adk.models.LlmRequest;\nimport com.google.genai.types.Content;\nimport java.util.Optional;\n\npublic Maybe<LlmResponse> myBeforeModelCb(CallbackContext callbackContext, LlmRequest request){\n    // Read/Write state example\n    callCount = callbackContext.state().get(\"model_calls\", 0)\n    callbackContext.state().put(\"model_calls\") = callCount + 1 # Modify state\n\n    // Optionally load an artifact\n    // Maybe<Part> configPart = callbackContext.loadArtifact(\"model_config.json\");\n    System.out.println(\"Preparing model call \" + callCount + 1);\n    return Maybe.empty(); // Allow model call to proceed\n}"}, {"language": "text", "code": "# Pseudocode: Tool function receiving ToolContext\nfrom google.adk.tools import ToolContext\nfrom typing import Dict, Any\n\n# Assume this function is wrapped by a FunctionTool\ndef search_external_api(query: str, tool_context: ToolContext) -> Dict[str, Any]:\n    api_key = tool_context.state.get(\"api_key\")\n    if not api_key:\n        # Define required auth config\n        # auth_config = AuthConfig(...)\n        # tool_context.request_credential(auth_config) # Request credentials\n        # Use the 'actions' property to signal the auth request has been made\n        # tool_context.actions.requested_auth_configs[tool_context.function_call_id] = auth_config\n        return {\"status\": \"Auth Required\"}\n\n    # Use the API key...\n    print(f\"Tool executing for query '{query}' using API key. Invocation: {tool_context.invocation_id}\")\n\n    # Optionally search memory or list artifacts\n    # relevant_docs = tool_context.search_memory(f\"info related to {query}\")\n    # available_files = tool_context.list_artifacts()\n\n    return {\"result\": f\"Data for {query} fetched.\"}"}, {"language": "text", "code": "import \"google.golang.org/adk/tool\"\n\n// Pseudocode: Tool function receiving ToolContext\ntype searchExternalAPIArgs struct {\n    Query string `json:\"query\" jsonschema:\"The query to search for.\"`\n}\n\ntype searchExternalAPIResults struct {\n    Result string `json:\"result\"`\n    Status string `json:\"status\"`\n}\n\nfunc searchExternalAPI(tc tool.Context, input searchExternalAPIArgs) searchExternalAPIResults {\n    apiKey, err := tc.State().Get(\"api_key\")\n    if err != nil || apiKey == \"\" {\n        // In a real scenario, you would define and request credentials here.\n        // This is a conceptual placeholder.\n        return searchExternalAPIResults{Status: \"Auth Required\"}\n    }\n\n    // Use the API key...\n    fmt.Printf(\"Tool executing for query '%s' using API key. Invocation: %s\\n\", input.Query, tc.InvocationID())\n\n    // Optionally search memory or list artifacts\n    // relevantDocs, _ := tc.SearchMemory(tc, \"info related to %s\", input.Query))\n    // availableFiles, _ := tc.Artifacts().List()\n\n    return searchExternalAPIResults{Result: fmt.Sprintf(\"Data for %s fetched.\", input.Query)}\n}"}, {"language": "text", "code": "// Pseudocode: Tool function receiving ToolContext\nimport com.google.adk.tools.ToolContext;\nimport java.util.HashMap;\nimport java.util.Map;\n\n// Assume this function is wrapped by a FunctionTool\npublic Map<String, Object> searchExternalApi(String query, ToolContext toolContext){\n    String apiKey = toolContext.state.get(\"api_key\");\n    if(apiKey.isEmpty()){\n        // Define required auth config\n        // authConfig = AuthConfig(...);\n        // toolContext.requestCredential(authConfig); # Request credentials\n        // Use the 'actions' property to signal the auth request has been made\n        ...\n        return Map.of(\"status\", \"Auth Required\");\n\n    // Use the API key...\n    System.out.println(\"Tool executing for query \" + query + \" using API key. \");\n\n    // Optionally list artifacts\n    // Single<List<String>> availableFiles = toolContext.listArtifacts();\n\n    return Map.of(\"result\", \"Data for \" + query + \" fetched\");\n}"}]}, {"heading_path": ["Common Tasks Using Context\u00b6"], "text": "Common Tasks Using Context \u00b6 Now that you understand the different context objects, let's focus on how to use them for common tasks when building your agents and tools. ", "code_blocks": []}, {"heading_path": ["Accessing Information\u00b6"], "text": "Accessing Information \u00b6 You'll frequently need to read information stored within the context. Reading Session State: Access data saved in previous steps or user/app-level settings. Use dictionary-like access on the state property. Python Go Java # Pseudocode: In a Tool function from google.adk.tools import ToolContext def my_tool ( tool_context : ToolContext , ** kwargs ): user_pref = tool_context . state . get ( \"user_display_preference\" , \"default_mode\" ) api_endpoint = tool_context . state . get ( \"app:api_endpoint\" ) # Read app-level state if user_pref == \"dark_mode\" : # ... apply dark mode logic ... pass print ( f \"Using API endpoint: { api_endpoint } \" ) # ... rest of tool logic ... # Pseudocode: In a Callback function from google.adk.agents.callback_context import CallbackContext def my_callback ( callback_context : CallbackContext , ** kwargs ): last_tool_result = callback_context . state . get ( \"temp:last_api_result\" ) # Read temporary state if last_tool_result : print ( f \"Found temporary result from last tool: { last_tool_result } \" ) # ... callback logic ... import ( \"google.golang.org/adk/agent\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/genai\" ) // Pseudocode: In a Tool function type toolArgs struct { // Define tool-specific arguments here } type toolResults struct { // Define tool-specific results here } // Example tool function demonstrating state access func myTool ( tc tool . Context , input toolArgs ) toolResults { userPref , err := tc . State (). Get ( \"user_display_preference\" ) if err != nil { userPref = \"default_mode\" } apiEndpoint , _ := tc . State (). Get ( \"app:api_endpoint\" ) // Read app-level state if userPref == \"dark_mode\" { // ... apply dark mode logic ... } fmt . Printf ( \"Using API endpoint: %v\\n\" , apiEndpoint ) // ... rest of tool logic ... return toolResults {} } // Pseudocode: In a Callback function func myCallback ( ctx agent . CallbackContext ) ( * genai . Content , error ) { lastToolResult , err := ctx . State (). Get ( \"temp:last_api_result\" ) // Read temporary state if err == nil { fmt . Printf ( \"Found temporary result from last tool: %v\\n\" , lastToolResult ) } else { fmt . Println ( \"No temporary result found.\" ) } // ... callback logic ... return nil , nil } // Pseudocode: In a Tool function import com.google.adk.tools.ToolContext ; public void myTool ( ToolContext toolContext ){ String userPref = toolContext . state (). get ( \"user_display_preference\" ); String apiEndpoint = toolContext . state (). get ( \"app:api_endpoint\" ); // Read app-level state if ( userPref . equals ( \"dark_mode\" )){ // ... apply dark mode logic ... pass } System . out . println ( \"Using API endpoint: \" + api_endpoint ); // ... rest of tool logic ... } // Pseudocode: In a Callback function import com.google.adk.agents.CallbackContext ; public void myCallback ( CallbackContext callbackContext ){ String lastToolResult = ( String ) callbackContext . state (). get ( \"temp:last_api_result\" ); // Read temporary state } if ( ! ( lastToolResult . isEmpty ())){ System . out . println ( \"Found temporary result from last tool: \" + lastToolResult ); } // ... callback logic ... Getting Current Identifiers: Useful for logging or custom logic based on the current operation. Python Go Java # Pseudocode: In any context (ToolContext shown) from google.adk.tools import ToolContext def log_tool_usage ( tool_context : ToolContext , ** kwargs ): agent_name = tool_context . agent_nameSystem . out . println ( \"Found temporary result from last tool: \" + lastToolResult ); inv_id = tool_context . invocation_id func_call_id = getattr ( tool_context , 'function_call_id' , 'N/A' ) # Specific to ToolContext print ( f \"Log: Invocation= { inv_id } , Agent= { agent_name } , FunctionCallID= { func_call_id } - Tool Executed.\" ) import \"google.golang.org/adk/tool\" // Pseudocode: In any context (ToolContext shown) type logToolUsageArgs struct {} type logToolUsageResult struct { Status string `json:\"status\"` } func logToolUsage ( tc tool . Context , args logToolUsageArgs ) logToolUsageResult { agentName := tc . AgentName () invID := tc . InvocationID () funcCallID := tc . FunctionCallID () fmt . Printf ( \"Log: Invocation=%s, Agent=%s, FunctionCallID=%s - Tool Executed.\\n\" , invID , agentName , funcCallID ) return logToolUsageResult { Status : \"Logged successfully\" } } // Pseudocode: In any context (ToolContext shown) import com.google.adk.tools.ToolContext ; public void logToolUsage ( ToolContext toolContext ){ String agentName = toolContext . agentName ; String invId = toolContext . invocationId ; String functionCallId = toolContext . functionCallId (). get (); // Specific to ToolContext System . out . println ( \"Log: Invocation= \" + invId &+ \" Agent= \" + agentName ); } Accessing the Initial User Input: Refer back to the message that started the current invocation. Python Go Java # Pseudocode: In a Callback from google.adk.agents.callback_context import CallbackContext def check_initial_intent ( callback_context : CallbackContext , ** kwargs ): initial_text = \"N/A\" if callback_context . user_content and callback_context . user_content . parts : initial_text = callback_context . user_content . parts [ 0 ] . text or \"Non-text input\" print ( f \"This invocation started with user input: ' { initial_text } '\" ) # Pseudocode: In an Agent's _run_async_impl # async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]: #     if ctx.user_content and ctx.user_content.parts: #         initial_text = ctx.user_content.parts[0].text #         print(f\"Agent logic remembering initial query: {initial_text}\") #     ... import ( \"google.golang.org/adk/agent\" \"google.golang.org/genai\" ) // Pseudocode: In a Callback func logInitialUserInput ( ctx agent . CallbackContext ) ( * genai . Content , error ) { userContent := ctx . UserContent () if userContent != nil && len ( userContent . Parts ) > 0 { if text := userContent . Parts [ 0 ]. Text ; text != \"\" { fmt . Printf ( \"User's initial input for this turn: '%s'\\n\" , text ) } } return nil , nil // No modification } // Pseudocode: In a Callback import com.google.adk.agents.CallbackContext ; public void checkInitialIntent ( CallbackContext callbackContext ){ String initialText = \"N/A\" ; if (( ! ( callbackContext . userContent (). isEmpty ())) && ( ! ( callbackContext . userContent (). parts . isEmpty ()))){ initialText = cbx . userContent (). get (). parts (). get (). get ( 0 ). text (). get (); ... System . out . println ( \"This invocation started with user input: \" + initialText ) } } ", "code_blocks": [{"language": "text", "code": "# Pseudocode: In a Tool function\nfrom google.adk.tools import ToolContext\n\ndef my_tool(tool_context: ToolContext, **kwargs):\n    user_pref = tool_context.state.get(\"user_display_preference\", \"default_mode\")\n    api_endpoint = tool_context.state.get(\"app:api_endpoint\") # Read app-level state\n\n    if user_pref == \"dark_mode\":\n        # ... apply dark mode logic ...\n        pass\n    print(f\"Using API endpoint: {api_endpoint}\")\n    # ... rest of tool logic ...\n\n# Pseudocode: In a Callback function\nfrom google.adk.agents.callback_context import CallbackContext\n\ndef my_callback(callback_context: CallbackContext, **kwargs):\n    last_tool_result = callback_context.state.get(\"temp:last_api_result\") # Read temporary state\n    if last_tool_result:\n        print(f\"Found temporary result from last tool: {last_tool_result}\")\n    # ... callback logic ..."}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/genai\"\n)\n\n// Pseudocode: In a Tool function\ntype toolArgs struct {\n    // Define tool-specific arguments here\n}\n\ntype toolResults struct {\n    // Define tool-specific results here\n}\n\n// Example tool function demonstrating state access\nfunc myTool(tc tool.Context, input toolArgs) toolResults {\n    userPref, err := tc.State().Get(\"user_display_preference\")\n    if err != nil {\n        userPref = \"default_mode\"\n    }\n    apiEndpoint, _ := tc.State().Get(\"app:api_endpoint\") // Read app-level state\n\n    if userPref == \"dark_mode\" {\n        // ... apply dark mode logic ...\n    }\n    fmt.Printf(\"Using API endpoint: %v\\n\", apiEndpoint)\n    // ... rest of tool logic ...\n    return toolResults{}\n}\n\n\n// Pseudocode: In a Callback function\nfunc myCallback(ctx agent.CallbackContext) (*genai.Content, error) {\n    lastToolResult, err := ctx.State().Get(\"temp:last_api_result\") // Read temporary state\n    if err == nil {\n        fmt.Printf(\"Found temporary result from last tool: %v\\n\", lastToolResult)\n    } else {\n        fmt.Println(\"No temporary result found.\")\n    }\n    // ... callback logic ...\n    return nil, nil\n}"}, {"language": "text", "code": "// Pseudocode: In a Tool function\nimport com.google.adk.tools.ToolContext;\n\npublic void myTool(ToolContext toolContext){\n   String userPref = toolContext.state().get(\"user_display_preference\");\n   String apiEndpoint = toolContext.state().get(\"app:api_endpoint\"); // Read app-level state\n   if(userPref.equals(\"dark_mode\")){\n        // ... apply dark mode logic ...\n        pass\n    }\n   System.out.println(\"Using API endpoint: \" + api_endpoint);\n   // ... rest of tool logic ...\n}\n\n\n// Pseudocode: In a Callback function\nimport com.google.adk.agents.CallbackContext;\n\n    public void myCallback(CallbackContext callbackContext){\n        String lastToolResult = (String) callbackContext.state().get(\"temp:last_api_result\"); // Read temporary state\n    }\n    if(!(lastToolResult.isEmpty())){\n        System.out.println(\"Found temporary result from last tool: \" + lastToolResult);\n    }\n    // ... callback logic ..."}, {"language": "text", "code": "# Pseudocode: In any context (ToolContext shown)\nfrom google.adk.tools import ToolContext\n\ndef log_tool_usage(tool_context: ToolContext, **kwargs):\n    agent_name = tool_context.agent_nameSystem.out.println(\"Found temporary result from last tool: \" + lastToolResult);\n    inv_id = tool_context.invocation_id\n    func_call_id = getattr(tool_context, 'function_call_id', 'N/A') # Specific to ToolContext\n\n    print(f\"Log: Invocation={inv_id}, Agent={agent_name}, FunctionCallID={func_call_id} - Tool Executed.\")"}, {"language": "text", "code": "import \"google.golang.org/adk/tool\"\n\n// Pseudocode: In any context (ToolContext shown)\ntype logToolUsageArgs struct{}\ntype logToolUsageResult struct {\n    Status string `json:\"status\"`\n}\n\nfunc logToolUsage(tc tool.Context, args logToolUsageArgs) logToolUsageResult {\n    agentName := tc.AgentName()\n    invID := tc.InvocationID()\n    funcCallID := tc.FunctionCallID()\n\n    fmt.Printf(\"Log: Invocation=%s, Agent=%s, FunctionCallID=%s - Tool Executed.\\n\", invID, agentName, funcCallID)\n    return logToolUsageResult{Status: \"Logged successfully\"}\n}"}, {"language": "text", "code": "// Pseudocode: In any context (ToolContext shown)\n import com.google.adk.tools.ToolContext;\n\n public void logToolUsage(ToolContext toolContext){\n            String agentName = toolContext.agentName;\n            String invId = toolContext.invocationId;\n            String functionCallId = toolContext.functionCallId().get(); // Specific to ToolContext\n            System.out.println(\"Log: Invocation= \" + invId &+ \" Agent= \" + agentName);\n        }"}, {"language": "text", "code": "# Pseudocode: In a Callback\nfrom google.adk.agents.callback_context import CallbackContext\n\ndef check_initial_intent(callback_context: CallbackContext, **kwargs):\n    initial_text = \"N/A\"\n    if callback_context.user_content and callback_context.user_content.parts:\n        initial_text = callback_context.user_content.parts[0].text or \"Non-text input\"\n\n    print(f\"This invocation started with user input: '{initial_text}'\")\n\n# Pseudocode: In an Agent's _run_async_impl\n# async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n#     if ctx.user_content and ctx.user_content.parts:\n#         initial_text = ctx.user_content.parts[0].text\n#         print(f\"Agent logic remembering initial query: {initial_text}\")\n#     ..."}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/genai\"\n)\n\n// Pseudocode: In a Callback\nfunc logInitialUserInput(ctx agent.CallbackContext) (*genai.Content, error) {\n    userContent := ctx.UserContent()\n    if userContent != nil && len(userContent.Parts) > 0 {\n        if text := userContent.Parts[0].Text; text != \"\" {\n            fmt.Printf(\"User's initial input for this turn: '%s'\\n\", text)\n        }\n    }\n    return nil, nil // No modification\n}"}, {"language": "text", "code": "// Pseudocode: In a Callback\nimport com.google.adk.agents.CallbackContext;\n\npublic void checkInitialIntent(CallbackContext callbackContext){\n    String initialText = \"N/A\";\n    if((!(callbackContext.userContent().isEmpty())) && (!(callbackContext.userContent().parts.isEmpty()))){\n        initialText = cbx.userContent().get().parts().get().get(0).text().get();\n        ...\n        System.out.println(\"This invocation started with user input: \" + initialText)\n    }\n}"}]}, {"heading_path": ["Managing State\u00b6"], "text": "Managing State \u00b6 State is crucial for memory and data flow. When you modify state using CallbackContext or ToolContext , the changes are automatically tracked and persisted by the framework. How it Works: Writing to callback_context.state['my_key'] = my_value or tool_context.state['my_key'] = my_value adds this change to the EventActions.state_delta associated with the current step's event. The SessionService then applies these deltas when persisting the event. Passing Data Between Tools Python Go Java # Pseudocode: Tool 1 - Fetches user ID from google.adk.tools import ToolContext import uuid def get_user_profile ( tool_context : ToolContext ) -> dict : user_id = str ( uuid . uuid4 ()) # Simulate fetching ID # Save the ID to state for the next tool tool_context . state [ \"temp:current_user_id\" ] = user_id return { \"profile_status\" : \"ID generated\" } # Pseudocode: Tool 2 - Uses user ID from state def get_user_orders ( tool_context : ToolContext ) -> dict : user_id = tool_context . state . get ( \"temp:current_user_id\" ) if not user_id : return { \"error\" : \"User ID not found in state\" } print ( f \"Fetching orders for user ID: { user_id } \" ) # ... logic to fetch orders using user_id ... return { \"orders\" : [ \"order123\" , \"order456\" ]} import \"google.golang.org/adk/tool\" // Pseudocode: Tool 1 - Fetches user ID type GetUserProfileArgs struct { } type getUserProfileResult struct { ProfileStatus string `json:\"profile_status\"` Error string `json:\"error\"` } func getUserProfile ( tc tool . Context , input GetUserProfileArgs ) getUserProfileResult { // A random user ID for demonstration purposes userID := \"random_user_456\" // Save the ID to state for the next tool if err := tc . State (). Set ( \"temp:current_user_id\" , userID ); err != nil { return getUserProfileResult { Error : \"Failed to set user ID in state\" } } return getUserProfileResult { ProfileStatus : \"ID generated\" } } // Pseudocode: Tool 2 - Uses user ID from state type GetUserOrdersArgs struct { } type getUserOrdersResult struct { Orders [] string `json:\"orders\"` Error string `json:\"error\"` } func getUserOrders ( tc tool . Context , input GetUserOrdersArgs ) getUserOrdersResult { userID , err := tc . State (). Get ( \"temp:current_user_id\" ) if err != nil { return getUserOrdersResult { Error : \"User ID not found in state\" } } fmt . Printf ( \"Fetching orders for user ID: %v\\n\" , userID ) // ... logic to fetch orders using user_id ... return getUserOrdersResult { Orders : [] string { \"order123\" , \"order456\" }} } // Pseudocode: Tool 1 - Fetches user ID import com.google.adk.tools.ToolContext ; import java.util.UUID ; public Map < String , String > getUserProfile ( ToolContext toolContext ){ String userId = UUID . randomUUID (). toString (); // Save the ID to state for the next tool toolContext . state (). put ( \"temp:current_user_id\" , user_id ); return Map . of ( \"profile_status\" , \"ID generated\" ); } // Pseudocode: Tool 2 - Uses user ID from state public Map < String , String > getUserOrders ( ToolContext toolContext ){ String userId = toolContext . state (). get ( \"temp:current_user_id\" ); if ( userId . isEmpty ()){ return Map . of ( \"error\" , \"User ID not found in state\" ); } System . out . println ( \"Fetching orders for user id: \" + userId ); // ... logic to fetch orders using user_id ... return Map . of ( \"orders\" , \"order123\" ); } Updating User Preferences: Python Go Java # Pseudocode: Tool or Callback identifies a preference from google.adk.tools import ToolContext # Or CallbackContext def set_user_preference ( tool_context : ToolContext , preference : str , value : str ) -> dict : # Use 'user:' prefix for user-level state (if using a persistent SessionService) state_key = f \"user: { preference } \" tool_context . state [ state_key ] = value print ( f \"Set user preference ' { preference } ' to ' { value } '\" ) return { \"status\" : \"Preference updated\" } import \"google.golang.org/adk/tool\" // Pseudocode: Tool or Callback identifies a preference type setUserPreferenceArgs struct { Preference string `json:\"preference\" jsonschema:\"The name of the preference to set.\"` Value string `json:\"value\" jsonschema:\"The value to set for the preference.\"` } type setUserPreferenceResult struct { Status string `json:\"status\"` } func setUserPreference ( tc tool . Context , args setUserPreferenceArgs ) setUserPreferenceResult { // Use 'user:' prefix for user-level state (if using a persistent SessionService) stateKey := fmt . Sprintf ( \"user:%s\" , args . Preference ) if err := tc . State (). Set ( stateKey , args . Value ); err != nil { return setUserPreferenceResult { Status : \"Failed to set preference\" } } fmt . Printf ( \"Set user preference '%s' to '%s'\\n\" , args . Preference , args . Value ) return setUserPreferenceResult { Status : \"Preference updated\" } } // Pseudocode: Tool or Callback identifies a preference import com.google.adk.tools.ToolContext ; // Or CallbackContext public Map < String , String > setUserPreference ( ToolContext toolContext , String preference , String value ){ // Use 'user:' prefix for user-level state (if using a persistent SessionService) String stateKey = \"user:\" + preference ; toolContext . state (). put ( stateKey , value ); System . out . println ( \"Set user preference '\" + preference + \"' to '\" + value + \"'\" ); return Map . of ( \"status\" , \"Preference updated\" ); } State Prefixes: While basic state is session-specific, prefixes like app: and user: can be used with persistent SessionService implementations (like DatabaseSessionService or VertexAiSessionService ) to indicate broader scope (app-wide or user-wide across sessions). temp: can denote data only relevant within the current invocation. ", "code_blocks": [{"language": "text", "code": "# Pseudocode: Tool 1 - Fetches user ID\nfrom google.adk.tools import ToolContext\nimport uuid\n\ndef get_user_profile(tool_context: ToolContext) -> dict:\n    user_id = str(uuid.uuid4()) # Simulate fetching ID\n    # Save the ID to state for the next tool\n    tool_context.state[\"temp:current_user_id\"] = user_id\n    return {\"profile_status\": \"ID generated\"}\n\n# Pseudocode: Tool 2 - Uses user ID from state\ndef get_user_orders(tool_context: ToolContext) -> dict:\n    user_id = tool_context.state.get(\"temp:current_user_id\")\n    if not user_id:\n        return {\"error\": \"User ID not found in state\"}\n\n    print(f\"Fetching orders for user ID: {user_id}\")\n    # ... logic to fetch orders using user_id ...\n    return {\"orders\": [\"order123\", \"order456\"]}"}, {"language": "text", "code": "import \"google.golang.org/adk/tool\"\n\n// Pseudocode: Tool 1 - Fetches user ID\ntype GetUserProfileArgs struct {\n}\n\ntype getUserProfileResult struct {\n    ProfileStatus string `json:\"profile_status\"`\n    Error         string `json:\"error\"`\n}\n\nfunc getUserProfile(tc tool.Context, input GetUserProfileArgs) getUserProfileResult {\n    // A random user ID for demonstration purposes\n    userID := \"random_user_456\"\n\n    // Save the ID to state for the next tool\n    if err := tc.State().Set(\"temp:current_user_id\", userID); err != nil {\n        return getUserProfileResult{Error: \"Failed to set user ID in state\"}\n    }\n    return getUserProfileResult{ProfileStatus: \"ID generated\"}\n}\n\n\n// Pseudocode: Tool 2 - Uses user ID from state\ntype GetUserOrdersArgs struct {\n}\n\ntype getUserOrdersResult struct {\n    Orders []string `json:\"orders\"`\n    Error  string   `json:\"error\"`\n}\n\nfunc getUserOrders(tc tool.Context, input GetUserOrdersArgs) getUserOrdersResult {\n    userID, err := tc.State().Get(\"temp:current_user_id\")\n    if err != nil {\n        return getUserOrdersResult{Error: \"User ID not found in state\"}\n    }\n\n    fmt.Printf(\"Fetching orders for user ID: %v\\n\", userID)\n    // ... logic to fetch orders using user_id ...\n    return getUserOrdersResult{Orders: []string{\"order123\", \"order456\"}}\n}"}, {"language": "text", "code": "// Pseudocode: Tool 1 - Fetches user ID\nimport com.google.adk.tools.ToolContext;\nimport java.util.UUID;\n\npublic Map<String, String> getUserProfile(ToolContext toolContext){\n    String userId = UUID.randomUUID().toString();\n    // Save the ID to state for the next tool\n    toolContext.state().put(\"temp:current_user_id\", user_id);\n    return Map.of(\"profile_status\", \"ID generated\");\n}\n\n// Pseudocode: Tool 2 - Uses user ID from state\npublic  Map<String, String> getUserOrders(ToolContext toolContext){\n    String userId = toolContext.state().get(\"temp:current_user_id\");\n    if(userId.isEmpty()){\n        return Map.of(\"error\", \"User ID not found in state\");\n    }\n    System.out.println(\"Fetching orders for user id: \" + userId);\n     // ... logic to fetch orders using user_id ...\n    return Map.of(\"orders\", \"order123\");\n}"}, {"language": "text", "code": "# Pseudocode: Tool or Callback identifies a preference\nfrom google.adk.tools import ToolContext # Or CallbackContext\n\ndef set_user_preference(tool_context: ToolContext, preference: str, value: str) -> dict:\n    # Use 'user:' prefix for user-level state (if using a persistent SessionService)\n    state_key = f\"user:{preference}\"\n    tool_context.state[state_key] = value\n    print(f\"Set user preference '{preference}' to '{value}'\")\n    return {\"status\": \"Preference updated\"}"}, {"language": "text", "code": "import \"google.golang.org/adk/tool\"\n\n// Pseudocode: Tool or Callback identifies a preference\ntype setUserPreferenceArgs struct {\n    Preference string `json:\"preference\" jsonschema:\"The name of the preference to set.\"`\n    Value      string `json:\"value\" jsonschema:\"The value to set for the preference.\"`\n}\n\ntype setUserPreferenceResult struct {\n    Status string `json:\"status\"`\n}\n\nfunc setUserPreference(tc tool.Context, args setUserPreferenceArgs) setUserPreferenceResult {\n    // Use 'user:' prefix for user-level state (if using a persistent SessionService)\n    stateKey := fmt.Sprintf(\"user:%s\", args.Preference)\n    if err := tc.State().Set(stateKey, args.Value); err != nil {\n        return setUserPreferenceResult{Status: \"Failed to set preference\"}\n    }\n    fmt.Printf(\"Set user preference '%s' to '%s'\\n\", args.Preference, args.Value)\n    return setUserPreferenceResult{Status: \"Preference updated\"}\n}"}, {"language": "text", "code": "// Pseudocode: Tool or Callback identifies a preference\nimport com.google.adk.tools.ToolContext; // Or CallbackContext\n\npublic Map<String, String> setUserPreference(ToolContext toolContext, String preference, String value){\n    // Use 'user:' prefix for user-level state (if using a persistent SessionService)\n    String stateKey = \"user:\" + preference;\n    toolContext.state().put(stateKey, value);\n    System.out.println(\"Set user preference '\" + preference + \"' to '\" + value + \"'\");\n    return Map.of(\"status\", \"Preference updated\");\n}"}]}, {"heading_path": ["Working with Artifacts\u00b6"], "text": "Working with Artifacts \u00b6 Use artifacts to handle files or large data blobs associated with the session. Common use case: processing uploaded documents. Document Summarizer Example Flow: Ingest Reference (e.g., in a Setup Tool or Callback): Save the path or URI of the document, not the entire content, as an artifact. Python Go Java # Pseudocode: In a callback or initial tool from google.adk.agents.callback_context import CallbackContext # Or ToolContext from google.genai import types def save_document_reference ( context : CallbackContext , file_path : str ) -> None : # Assume file_path is something like \"gs://my-bucket/docs/report.pdf\" or \"/local/path/to/report.pdf\" try : # Create a Part containing the path/URI text artifact_part = types . Part ( text = file_path ) version = context . save_artifact ( \"document_to_summarize.txt\" , artifact_part ) print ( f \"Saved document reference ' { file_path } ' as artifact version { version } \" ) # Store the filename in state if needed by other tools context . state [ \"temp:doc_artifact_name\" ] = \"document_to_summarize.txt\" except ValueError as e : print ( f \"Error saving artifact: { e } \" ) # E.g., Artifact service not configured except Exception as e : print ( f \"Unexpected error saving artifact reference: { e } \" ) # Example usage: # save_document_reference(callback_context, \"gs://my-bucket/docs/report.pdf\") import ( \"google.golang.org/adk/tool\" \"google.golang.org/genai\" ) // Adapt the saveDocumentReference callback into a tool for this example. type saveDocRefArgs struct { FilePath string `json:\"file_path\" jsonschema:\"The path to the file to save.\"` } type saveDocRefResult struct { Status string `json:\"status\"` Error string `json:\"error\"` } func saveDocRef ( tc tool . Context , args saveDocRefArgs ) saveDocRefResult { artifactPart := genai . NewPartFromText ( args . FilePath ) _ , err := tc . Artifacts (). Save ( tc , \"document_to_summarize.txt\" , artifactPart ) if err != nil { return saveDocRefResult { \"\" , err . Error ()} } fmt . Printf ( \"Saved document reference '%s' as artifact\\n\" , args . FilePath ) if err := tc . State (). Set ( \"temp:doc_artifact_name\" , \"document_to_summarize.txt\" ); err != nil { return saveDocRefResult { \"\" , \"Failed to set artifact name in state\" } } return saveDocRefResult { \"Reference saved\" , \"\" } } // Pseudocode: In a callback or initial tool import com.google.adk.agents.CallbackContext ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; pubic void saveDocumentReference ( CallbackContext context , String filePath ){ // Assume file_path is something like \"gs://my-bucket/docs/report.pdf\" or \"/local/path/to/report.pdf\" try { // Create a Part containing the path/URI text Part artifactPart = types . Part ( filePath ) Optional < Integer > version = context . saveArtifact ( \"document_to_summarize.txt\" , artifactPart ) System . out . println ( \"Saved document reference\" + filePath + \" as artifact version \" + version ); // Store the filename in state if needed by other tools context . state (). put ( \"temp:doc_artifact_name\" , \"document_to_summarize.txt\" ); } catch ( Exception e ){ System . out . println ( \"Unexpected error saving artifact reference: \" + e ); } } // Example usage: // saveDocumentReference(context, \"gs://my-bucket/docs/report.pdf\") Summarizer Tool: Load the artifact to get the path/URI, read the actual document content using appropriate libraries, summarize, and return the result. Python Go Java # Pseudocode: In the Summarizer tool function from google.adk.tools import ToolContext from google.genai import types # Assume libraries like google.cloud.storage or built-in open are available # Assume a 'summarize_text' function exists # from my_summarizer_lib import summarize_text def summarize_document_tool ( tool_context : ToolContext ) -> dict : artifact_name = tool_context . state . get ( \"temp:doc_artifact_name\" ) if not artifact_name : return { \"error\" : \"Document artifact name not found in state.\" } try : # 1. Load the artifact part containing the path/URI artifact_part = tool_context . load_artifact ( artifact_name ) if not artifact_part or not artifact_part . text : return { \"error\" : f \"Could not load artifact or artifact has no text path: { artifact_name } \" } file_path = artifact_part . text print ( f \"Loaded document reference: { file_path } \" ) # 2. Read the actual document content (outside ADK context) document_content = \"\" if file_path . startswith ( \"gs://\" ): # Example: Use GCS client library to download/read # from google.cloud import storage # client = storage.Client() # blob = storage.Blob.from_string(file_path, client=client) # document_content = blob.download_as_text() # Or bytes depending on format pass # Replace with actual GCS reading logic elif file_path . startswith ( \"/\" ): # Example: Use local file system with open ( file_path , 'r' , encoding = 'utf-8' ) as f : document_content = f . read () else : return { \"error\" : f \"Unsupported file path scheme: { file_path } \" } # 3. Summarize the content if not document_content : return { \"error\" : \"Failed to read document content.\" } # summary = summarize_text(document_content) # Call your summarization logic summary = f \"Summary of content from { file_path } \" # Placeholder return { \"summary\" : summary } except ValueError as e : return { \"error\" : f \"Artifact service error: { e } \" } except FileNotFoundError : return { \"error\" : f \"Local file not found: { file_path } \" } # except Exception as e: # Catch specific exceptions for GCS etc. #      return {\"error\": f\"Error reading document {file_path}: {e}\"} import \"google.golang.org/adk/tool\" // Pseudocode: In the Summarizer tool function type summarizeDocumentArgs struct {} type summarizeDocumentResult struct { Summary string `json:\"summary\"` Error string `json:\"error\"` } func summarizeDocumentTool ( tc tool . Context , input summarizeDocumentArgs ) summarizeDocumentResult { artifactName , err := tc . State (). Get ( \"temp:doc_artifact_name\" ) if err != nil { return summarizeDocumentResult { Error : \"No document artifact name found in state\" } } // 1. Load the artifact part containing the path/URI artifactPart , err := tc . Artifacts (). Load ( tc , artifactName .( string )) if err != nil { return summarizeDocumentResult { Error : err . Error ()} } if artifactPart . Part . Text == \"\" { return summarizeDocumentResult { Error : \"Could not load artifact or artifact has no text path.\" } } filePath := artifactPart . Part . Text fmt . Printf ( \"Loaded document reference: %s\\n\" , filePath ) // 2. Read the actual document content (outside ADK context) // In a real implementation, you would use a GCS client or local file reader. documentContent := \"This is the fake content of the document at \" + filePath _ = documentContent // Avoid unused variable error. // 3. Summarize the content summary := \"Summary of content from \" + filePath // Placeholder return summarizeDocumentResult { Summary : summary } } // Pseudocode: In the Summarizer tool function import com.google.adk.tools.ToolContext ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; public Map < String , String > summarizeDocumentTool ( ToolContext toolContext ){ String artifactName = toolContext . state (). get ( \"temp:doc_artifact_name\" ); if ( artifactName . isEmpty ()){ return Map . of ( \"error\" , \"Document artifact name not found in state.\" ); } try { // 1. Load the artifact part containing the path/URI Maybe < Part > artifactPart = toolContext . loadArtifact ( artifactName ); if (( artifactPart == null ) || ( artifactPart . text (). isEmpty ())){ return Map . of ( \"error\" , \"Could not load artifact or artifact has no text path: \" + artifactName ); } filePath = artifactPart . text (); System . out . println ( \"Loaded document reference: \" + filePath ); // 2. Read the actual document content (outside ADK context) String documentContent = \"\" ; if ( filePath . startsWith ( \"gs://\" )){ // Example: Use GCS client library to download/read into documentContent pass ; // Replace with actual GCS reading logic } else if (){ // Example: Use local file system to download/read into documentContent } else { return Map . of ( \"error\" , \"Unsupported file path scheme: \" + filePath ); } // 3. Summarize the content if ( documentContent . isEmpty ()){ return Map . of ( \"error\" , \"Failed to read document content.\" ); } // summary = summarizeText(documentContent) // Call your summarization logic summary = \"Summary of content from \" + filePath ; // Placeholder return Map . of ( \"summary\" , summary ); } catch ( IllegalArgumentException e ){ return Map . of ( \"error\" , \"Artifact service error \" + filePath + e ); } catch ( FileNotFoundException e ){ return Map . of ( \"error\" , \"Local file not found \" + filePath + e ); } catch ( Exception e ){ return Map . of ( \"error\" , \"Error reading document \" + filePath + e ); } } Listing Artifacts: Discover what files are available. Python Go Java # Pseudocode: In a tool function from google.adk.tools import ToolContext def check_available_docs ( tool_context : ToolContext ) -> dict : try : artifact_keys = tool_context . list_artifacts () print ( f \"Available artifacts: { artifact_keys } \" ) return { \"available_docs\" : artifact_keys } except ValueError as e : return { \"error\" : f \"Artifact service error: { e } \" } import \"google.golang.org/adk/tool\" // Pseudocode: In a tool function type checkAvailableDocsArgs struct {} type checkAvailableDocsResult struct { AvailableDocs [] string `json:\"available_docs\"` Error string `json:\"error\"` } func checkAvailableDocs ( tc tool . Context , args checkAvailableDocsArgs ) checkAvailableDocsResult { artifactKeys , err := tc . Artifacts (). List ( tc ) if err != nil { return checkAvailableDocsResult { Error : err . Error ()} } fmt . Printf ( \"Available artifacts: %v\\n\" , artifactKeys ) return checkAvailableDocsResult { AvailableDocs : artifactKeys . FileNames } } // Pseudocode: In a tool function import com.google.adk.tools.ToolContext ; public Map < String , String > checkAvailableDocs ( ToolContext toolContext ){ try { Single < List < String >> artifactKeys = toolContext . listArtifacts (); System . out . println ( \"Available artifacts\" + artifactKeys . tostring ()); return Map . of ( \"availableDocs\" , \"artifactKeys\" ); } catch ( IllegalArgumentException e ){ return Map . of ( \"error\" , \"Artifact service error: \" + e ); } } ", "code_blocks": [{"language": "text", "code": "# Pseudocode: In a callback or initial tool\nfrom google.adk.agents.callback_context import CallbackContext # Or ToolContext\nfrom google.genai import types\n\ndef save_document_reference(context: CallbackContext, file_path: str) -> None:\n    # Assume file_path is something like \"gs://my-bucket/docs/report.pdf\" or \"/local/path/to/report.pdf\"\n    try:\n        # Create a Part containing the path/URI text\n        artifact_part = types.Part(text=file_path)\n        version = context.save_artifact(\"document_to_summarize.txt\", artifact_part)\n        print(f\"Saved document reference '{file_path}' as artifact version {version}\")\n        # Store the filename in state if needed by other tools\n        context.state[\"temp:doc_artifact_name\"] = \"document_to_summarize.txt\"\n    except ValueError as e:\n        print(f\"Error saving artifact: {e}\") # E.g., Artifact service not configured\n    except Exception as e:\n        print(f\"Unexpected error saving artifact reference: {e}\")\n\n# Example usage:\n# save_document_reference(callback_context, \"gs://my-bucket/docs/report.pdf\")"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/genai\"\n)\n\n// Adapt the saveDocumentReference callback into a tool for this example.\ntype saveDocRefArgs struct {\n    FilePath string `json:\"file_path\" jsonschema:\"The path to the file to save.\"`\n}\n\ntype saveDocRefResult struct {\n    Status string `json:\"status\"`\n    Error  string `json:\"error\"`\n}\n\nfunc saveDocRef(tc tool.Context, args saveDocRefArgs) saveDocRefResult {\n    artifactPart := genai.NewPartFromText(args.FilePath)\n    _, err := tc.Artifacts().Save(tc, \"document_to_summarize.txt\", artifactPart)\n    if err != nil {\n        return saveDocRefResult{\"\", err.Error()}\n    }\n    fmt.Printf(\"Saved document reference '%s' as artifact\\n\", args.FilePath)\n    if err := tc.State().Set(\"temp:doc_artifact_name\", \"document_to_summarize.txt\"); err != nil {\n        return saveDocRefResult{\"\", \"Failed to set artifact name in state\"}\n    }\n    return saveDocRefResult{\"Reference saved\", \"\"}\n}"}, {"language": "text", "code": "// Pseudocode: In a callback or initial tool\nimport com.google.adk.agents.CallbackContext;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\n\n\npubic void saveDocumentReference(CallbackContext context, String filePath){\n    // Assume file_path is something like \"gs://my-bucket/docs/report.pdf\" or \"/local/path/to/report.pdf\"\n    try{\n        // Create a Part containing the path/URI text\n        Part artifactPart = types.Part(filePath)\n        Optional<Integer> version = context.saveArtifact(\"document_to_summarize.txt\", artifactPart)\n        System.out.println(\"Saved document reference\" + filePath + \" as artifact version \" + version);\n        // Store the filename in state if needed by other tools\n        context.state().put(\"temp:doc_artifact_name\", \"document_to_summarize.txt\");\n    } catch(Exception e){\n        System.out.println(\"Unexpected error saving artifact reference: \" + e);\n    }\n}\n\n// Example usage:\n// saveDocumentReference(context, \"gs://my-bucket/docs/report.pdf\")"}, {"language": "text", "code": "# Pseudocode: In the Summarizer tool function\nfrom google.adk.tools import ToolContext\nfrom google.genai import types\n# Assume libraries like google.cloud.storage or built-in open are available\n# Assume a 'summarize_text' function exists\n# from my_summarizer_lib import summarize_text\n\ndef summarize_document_tool(tool_context: ToolContext) -> dict:\n    artifact_name = tool_context.state.get(\"temp:doc_artifact_name\")\n    if not artifact_name:\n        return {\"error\": \"Document artifact name not found in state.\"}\n\n    try:\n        # 1. Load the artifact part containing the path/URI\n        artifact_part = tool_context.load_artifact(artifact_name)\n        if not artifact_part or not artifact_part.text:\n            return {\"error\": f\"Could not load artifact or artifact has no text path: {artifact_name}\"}\n\n        file_path = artifact_part.text\n        print(f\"Loaded document reference: {file_path}\")\n\n        # 2. Read the actual document content (outside ADK context)\n        document_content = \"\"\n        if file_path.startswith(\"gs://\"):\n            # Example: Use GCS client library to download/read\n            # from google.cloud import storage\n            # client = storage.Client()\n            # blob = storage.Blob.from_string(file_path, client=client)\n            # document_content = blob.download_as_text() # Or bytes depending on format\n            pass # Replace with actual GCS reading logic\n        elif file_path.startswith(\"/\"):\n             # Example: Use local file system\n             with open(file_path, 'r', encoding='utf-8') as f:\n                 document_content = f.read()\n        else:\n            return {\"error\": f\"Unsupported file path scheme: {file_path}\"}\n\n        # 3. Summarize the content\n        if not document_content:\n             return {\"error\": \"Failed to read document content.\"}\n\n        # summary = summarize_text(document_content) # Call your summarization logic\n        summary = f\"Summary of content from {file_path}\" # Placeholder\n\n        return {\"summary\": summary}\n\n    except ValueError as e:\n         return {\"error\": f\"Artifact service error: {e}\"}\n    except FileNotFoundError:\n         return {\"error\": f\"Local file not found: {file_path}\"}\n    # except Exception as e: # Catch specific exceptions for GCS etc.\n    #      return {\"error\": f\"Error reading document {file_path}: {e}\"}"}, {"language": "text", "code": "import \"google.golang.org/adk/tool\"\n\n// Pseudocode: In the Summarizer tool function\ntype summarizeDocumentArgs struct{}\n\ntype summarizeDocumentResult struct {\n    Summary string `json:\"summary\"`\n    Error   string `json:\"error\"`\n}\n\nfunc summarizeDocumentTool(tc tool.Context, input summarizeDocumentArgs) summarizeDocumentResult {\n    artifactName, err := tc.State().Get(\"temp:doc_artifact_name\")\n    if err != nil {\n        return summarizeDocumentResult{Error: \"No document artifact name found in state\"}\n    }\n\n    // 1. Load the artifact part containing the path/URI\n    artifactPart, err := tc.Artifacts().Load(tc, artifactName.(string))\n    if err != nil {\n        return summarizeDocumentResult{Error: err.Error()}\n    }\n\n    if artifactPart.Part.Text == \"\" {\n        return summarizeDocumentResult{Error: \"Could not load artifact or artifact has no text path.\"}\n    }\n    filePath := artifactPart.Part.Text\n    fmt.Printf(\"Loaded document reference: %s\\n\", filePath)\n\n    // 2. Read the actual document content (outside ADK context)\n    // In a real implementation, you would use a GCS client or local file reader.\n    documentContent := \"This is the fake content of the document at \" + filePath\n    _ = documentContent // Avoid unused variable error.\n\n    // 3. Summarize the content\n    summary := \"Summary of content from \" + filePath // Placeholder\n\n    return summarizeDocumentResult{Summary: summary}\n}"}, {"language": "text", "code": "// Pseudocode: In the Summarizer tool function\nimport com.google.adk.tools.ToolContext;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\n\npublic Map<String, String> summarizeDocumentTool(ToolContext toolContext){\n    String artifactName = toolContext.state().get(\"temp:doc_artifact_name\");\n    if(artifactName.isEmpty()){\n        return Map.of(\"error\", \"Document artifact name not found in state.\");\n    }\n    try{\n        // 1. Load the artifact part containing the path/URI\n        Maybe<Part> artifactPart = toolContext.loadArtifact(artifactName);\n        if((artifactPart == null) || (artifactPart.text().isEmpty())){\n            return Map.of(\"error\", \"Could not load artifact or artifact has no text path: \" + artifactName);\n        }\n        filePath = artifactPart.text();\n        System.out.println(\"Loaded document reference: \" + filePath);\n\n        // 2. Read the actual document content (outside ADK context)\n        String documentContent = \"\";\n        if(filePath.startsWith(\"gs://\")){\n            // Example: Use GCS client library to download/read into documentContent\n            pass; // Replace with actual GCS reading logic\n        } else if(){\n            // Example: Use local file system to download/read into documentContent\n        } else{\n            return Map.of(\"error\", \"Unsupported file path scheme: \" + filePath); \n        }\n\n        // 3. Summarize the content\n        if(documentContent.isEmpty()){\n            return Map.of(\"error\", \"Failed to read document content.\"); \n        }\n\n        // summary = summarizeText(documentContent) // Call your summarization logic\n        summary = \"Summary of content from \" + filePath; // Placeholder\n\n        return Map.of(\"summary\", summary);\n    } catch(IllegalArgumentException e){\n        return Map.of(\"error\", \"Artifact service error \" + filePath + e);\n    } catch(FileNotFoundException e){\n        return Map.of(\"error\", \"Local file not found \" + filePath + e);\n    } catch(Exception e){\n        return Map.of(\"error\", \"Error reading document \" + filePath + e);\n    }\n}"}, {"language": "text", "code": "# Pseudocode: In a tool function\nfrom google.adk.tools import ToolContext\n\ndef check_available_docs(tool_context: ToolContext) -> dict:\n    try:\n        artifact_keys = tool_context.list_artifacts()\n        print(f\"Available artifacts: {artifact_keys}\")\n        return {\"available_docs\": artifact_keys}\n    except ValueError as e:\n        return {\"error\": f\"Artifact service error: {e}\"}"}, {"language": "text", "code": "import \"google.golang.org/adk/tool\"\n\n// Pseudocode: In a tool function\ntype checkAvailableDocsArgs struct{}\n\ntype checkAvailableDocsResult struct {\n    AvailableDocs []string `json:\"available_docs\"`\n    Error         string   `json:\"error\"`\n}\n\nfunc checkAvailableDocs(tc tool.Context, args checkAvailableDocsArgs) checkAvailableDocsResult {\n    artifactKeys, err := tc.Artifacts().List(tc)\n    if err != nil {\n        return checkAvailableDocsResult{Error: err.Error()}\n    }\n    fmt.Printf(\"Available artifacts: %v\\n\", artifactKeys)\n    return checkAvailableDocsResult{AvailableDocs: artifactKeys.FileNames}\n}"}, {"language": "text", "code": "// Pseudocode: In a tool function\nimport com.google.adk.tools.ToolContext;\n\npublic Map<String, String> checkAvailableDocs(ToolContext toolContext){\n    try{\n        Single<List<String>> artifactKeys = toolContext.listArtifacts();\n        System.out.println(\"Available artifacts\" + artifactKeys.tostring());\n        return Map.of(\"availableDocs\", \"artifactKeys\");\n    } catch(IllegalArgumentException e){\n        return Map.of(\"error\", \"Artifact service error: \" + e);\n    }\n}"}]}, {"heading_path": ["Handling Tool Authentication\u00b6"], "text": "Handling Tool Authentication \u00b6 Supported in ADK Python v0.1.0 Securely manage API keys or other credentials needed by tools. # Pseudocode: Tool requiring auth from google.adk.tools import ToolContext from google.adk.auth import AuthConfig # Assume appropriate AuthConfig is defined # Define your required auth configuration (e.g., OAuth, API Key) MY_API_AUTH_CONFIG = AuthConfig ( ... ) AUTH_STATE_KEY = \"user:my_api_credential\" # Key to store retrieved credential def call_secure_api ( tool_context : ToolContext , request_data : str ) -> dict : # 1. Check if credential already exists in state credential = tool_context . state . get ( AUTH_STATE_KEY ) if not credential : # 2. If not, request it print ( \"Credential not found, requesting...\" ) try : tool_context . request_credential ( MY_API_AUTH_CONFIG ) # The framework handles yielding the event. The tool execution stops here for this turn. return { \"status\" : \"Authentication required. Please provide credentials.\" } except ValueError as e : return { \"error\" : f \"Auth error: { e } \" } # e.g., function_call_id missing except Exception as e : return { \"error\" : f \"Failed to request credential: { e } \" } # 3. If credential exists (might be from a previous turn after request) #    or if this is a subsequent call after auth flow completed externally try : # Optionally, re-validate/retrieve if needed, or use directly # This might retrieve the credential if the external flow just completed auth_credential_obj = tool_context . get_auth_response ( MY_API_AUTH_CONFIG ) api_key = auth_credential_obj . api_key # Or access_token, etc. # Store it back in state for future calls within the session tool_context . state [ AUTH_STATE_KEY ] = auth_credential_obj . model_dump () # Persist retrieved credential print ( f \"Using retrieved credential to call API with data: { request_data } \" ) # ... Make the actual API call using api_key ... api_result = f \"API result for { request_data } \" return { \"result\" : api_result } except Exception as e : # Handle errors retrieving/using the credential print ( f \"Error using credential: { e } \" ) # Maybe clear the state key if credential is invalid? # tool_context.state[AUTH_STATE_KEY] = None return { \"error\" : \"Failed to use credential\" } Remember: request_credential pauses the tool and signals the need for authentication. The user/system provides credentials, and on a subsequent call, get_auth_response (or checking state again) allows the tool to proceed. The tool_context.function_call_id is used implicitly by the framework to link the request and response. ", "code_blocks": [{"language": "text", "code": "# Pseudocode: Tool requiring auth\nfrom google.adk.tools import ToolContext\nfrom google.adk.auth import AuthConfig # Assume appropriate AuthConfig is defined\n\n# Define your required auth configuration (e.g., OAuth, API Key)\nMY_API_AUTH_CONFIG = AuthConfig(...)\nAUTH_STATE_KEY = \"user:my_api_credential\" # Key to store retrieved credential\n\ndef call_secure_api(tool_context: ToolContext, request_data: str) -> dict:\n    # 1. Check if credential already exists in state\n    credential = tool_context.state.get(AUTH_STATE_KEY)\n\n    if not credential:\n        # 2. If not, request it\n        print(\"Credential not found, requesting...\")\n        try:\n            tool_context.request_credential(MY_API_AUTH_CONFIG)\n            # The framework handles yielding the event. The tool execution stops here for this turn.\n            return {\"status\": \"Authentication required. Please provide credentials.\"}\n        except ValueError as e:\n            return {\"error\": f\"Auth error: {e}\"} # e.g., function_call_id missing\n        except Exception as e:\n            return {\"error\": f\"Failed to request credential: {e}\"}\n\n    # 3. If credential exists (might be from a previous turn after request)\n    #    or if this is a subsequent call after auth flow completed externally\n    try:\n        # Optionally, re-validate/retrieve if needed, or use directly\n        # This might retrieve the credential if the external flow just completed\n        auth_credential_obj = tool_context.get_auth_response(MY_API_AUTH_CONFIG)\n        api_key = auth_credential_obj.api_key # Or access_token, etc.\n\n        # Store it back in state for future calls within the session\n        tool_context.state[AUTH_STATE_KEY] = auth_credential_obj.model_dump() # Persist retrieved credential\n\n        print(f\"Using retrieved credential to call API with data: {request_data}\")\n        # ... Make the actual API call using api_key ...\n        api_result = f\"API result for {request_data}\"\n\n        return {\"result\": api_result}\n    except Exception as e:\n        # Handle errors retrieving/using the credential\n        print(f\"Error using credential: {e}\")\n        # Maybe clear the state key if credential is invalid?\n        # tool_context.state[AUTH_STATE_KEY] = None\n        return {\"error\": \"Failed to use credential\"}"}]}, {"heading_path": ["Leveraging Memory\u00b6"], "text": "Leveraging Memory \u00b6 Supported in ADK Python v0.1.0 Access relevant information from the past or external sources. # Pseudocode: Tool using memory search from google.adk.tools import ToolContext def find_related_info ( tool_context : ToolContext , topic : str ) -> dict : try : search_results = tool_context . search_memory ( f \"Information about { topic } \" ) if search_results . results : print ( f \"Found { len ( search_results . results ) } memory results for ' { topic } '\" ) # Process search_results.results (which are SearchMemoryResponseEntry) top_result_text = search_results . results [ 0 ] . text return { \"memory_snippet\" : top_result_text } else : return { \"message\" : \"No relevant memories found.\" } except ValueError as e : return { \"error\" : f \"Memory service error: { e } \" } # e.g., Service not configured except Exception as e : return { \"error\" : f \"Unexpected error searching memory: { e } \" } ", "code_blocks": [{"language": "text", "code": "# Pseudocode: Tool using memory search\nfrom google.adk.tools import ToolContext\n\ndef find_related_info(tool_context: ToolContext, topic: str) -> dict:\n    try:\n        search_results = tool_context.search_memory(f\"Information about {topic}\")\n        if search_results.results:\n            print(f\"Found {len(search_results.results)} memory results for '{topic}'\")\n            # Process search_results.results (which are SearchMemoryResponseEntry)\n            top_result_text = search_results.results[0].text\n            return {\"memory_snippet\": top_result_text}\n        else:\n            return {\"message\": \"No relevant memories found.\"}\n    except ValueError as e:\n        return {\"error\": f\"Memory service error: {e}\"} # e.g., Service not configured\n    except Exception as e:\n        return {\"error\": f\"Unexpected error searching memory: {e}\"}"}]}, {"heading_path": ["Advanced: Direct InvocationContext Usage\u00b6"], "text": "Advanced: Direct InvocationContext Usage \u00b6 Supported in ADK Python v0.1.0 While most interactions happen via CallbackContext or ToolContext , sometimes the agent's core logic ( _run_async_impl / _run_live_impl ) needs direct access. # Pseudocode: Inside agent's _run_async_impl from google.adk.agents import BaseAgent from google.adk.agents.invocation_context import InvocationContext from google.adk.events import Event from typing import AsyncGenerator class MyControllingAgent ( BaseAgent ): async def _run_async_impl ( self , ctx : InvocationContext ) -> AsyncGenerator [ Event , None ]: # Example: Check if a specific service is available if not ctx . memory_service : print ( \"Memory service is not available for this invocation.\" ) # Potentially change agent behavior # Example: Early termination based on some condition if ctx . session . state . get ( \"critical_error_flag\" ): print ( \"Critical error detected, ending invocation.\" ) ctx . end_invocation = True # Signal framework to stop processing yield Event ( author = self . name , invocation_id = ctx . invocation_id , content = \"Stopping due to critical error.\" ) return # Stop this agent's execution # ... Normal agent processing ... yield # ... event ... Setting ctx.end_invocation = True is a way to gracefully stop the entire request-response cycle from within the agent or its callbacks/tools (via their respective context objects which also have access to modify the underlying InvocationContext 's flag). ", "code_blocks": [{"language": "text", "code": "# Pseudocode: Inside agent's _run_async_impl\nfrom google.adk.agents import BaseAgent\nfrom google.adk.agents.invocation_context import InvocationContext\nfrom google.adk.events import Event\nfrom typing import AsyncGenerator\n\nclass MyControllingAgent(BaseAgent):\n    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n        # Example: Check if a specific service is available\n        if not ctx.memory_service:\n            print(\"Memory service is not available for this invocation.\")\n            # Potentially change agent behavior\n\n        # Example: Early termination based on some condition\n        if ctx.session.state.get(\"critical_error_flag\"):\n            print(\"Critical error detected, ending invocation.\")\n            ctx.end_invocation = True # Signal framework to stop processing\n            yield Event(author=self.name, invocation_id=ctx.invocation_id, content=\"Stopping due to critical error.\")\n            return # Stop this agent's execution\n\n        # ... Normal agent processing ...\n        yield # ... event ..."}]}, {"heading_path": ["Key Takeaways & Best Practices\u00b6"], "text": "Key Takeaways & Best Practices \u00b6 Use the Right Context: Always use the most specific context object provided ( ToolContext in tools/tool-callbacks, CallbackContext in agent/model-callbacks, ReadonlyContext where applicable). Use the full InvocationContext ( ctx ) directly in _run_async_impl / _run_live_impl only when necessary. State for Data Flow: context.state is the primary way to share data, remember preferences, and manage conversational memory within an invocation. Use prefixes ( app: , user: , temp: ) thoughtfully when using persistent storage. Artifacts for Files: Use context.save_artifact and context.load_artifact for managing file references (like paths or URIs) or larger data blobs. Store references, load content on demand. Tracked Changes: Modifications to state or artifacts made via context methods are automatically linked to the current step's EventActions and handled by the SessionService . Start Simple: Focus on state and basic artifact usage first. Explore authentication, memory, and advanced InvocationContext fields (like those for live streaming) as your needs become more complex. By understanding and effectively using these context objects, you can build more sophisticated, stateful, and capable agents with ADK. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:33.344166", "source_type": "adk-docs"}
{"doc_id": "c670293774955a1d4b050a2080cf58446dc9fd028fa3bcdfdd2358e86b3d25cc", "url": "https://google.github.io/adk-docs/context/caching", "title": "Context caching - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Context caching with Gemini\u00b6"], "text": "Context caching with Gemini \u00b6 Supported in ADK Python v1.15.0 When working with agents to complete tasks, you may want to reuse extended\ninstructions or large sets of data across multiple agent requests to a\ngenerative AI model. Resending this data for each agent request is slow,\ninefficient, and can be expensive. Using context caching features in generative\nAI models can significantly speed up responses and lower the number of tokens\nsent to the model for each request. The ADK Context Caching feature allows you to cache request data with generative\nAI models that support it, including Gemini 2.0 and higher models. This document\nexplains how to configure and use this feature. ", "code_blocks": []}, {"heading_path": ["Configure context caching\u00b6"], "text": "Configure context caching \u00b6 You configure the context caching feature at the ADK App object level,\nwhich wraps your agent. Use the ContextCacheConfig class to configure\nthese settings, as shown in the following code sample: from google.adk import Agent from google.adk.apps.app import App from google.adk.agents.context_cache_config import ContextCacheConfig root_agent = Agent ( # configure an agent using Gemini 2.0 or higher ) # Create the app with context caching configuration app = App ( name = 'my-caching-agent-app' , root_agent = root_agent , context_cache_config = ContextCacheConfig ( min_tokens = 2048 , # Minimum tokens to trigger caching ttl_seconds = 600 , # Store for up to 10 minutes cache_intervals = 5 , # Refresh after 5 uses ), ) ", "code_blocks": [{"language": "text", "code": "from google.adk import Agent\nfrom google.adk.apps.app import App\nfrom google.adk.agents.context_cache_config import ContextCacheConfig\n\nroot_agent = Agent(\n  # configure an agent using Gemini 2.0 or higher\n)\n\n# Create the app with context caching configuration\napp = App(\n    name='my-caching-agent-app',\n    root_agent=root_agent,\n    context_cache_config=ContextCacheConfig(\n        min_tokens=2048,    # Minimum tokens to trigger caching\n        ttl_seconds=600,    # Store for up to 10 minutes\n        cache_intervals=5,  # Refresh after 5 uses\n    ),\n)"}]}, {"heading_path": ["Configuration settings\u00b6"], "text": "Configuration settings \u00b6 The ContextCacheConfig class has the following settings that control how\ncaching works for your agent. When you configure these settings, they apply to\nall agents within your app. min_tokens (int): The minimum number of tokens required in a request\n    to enable caching. This setting allows you to avoid the overhead of caching\n    for very small requests where the performance benefit would be negligible.\n    Defaults to 0 . ttl_seconds (int): The time-to-live (TTL) for the cache in seconds.\n    This setting determines how long the cached content is stored before it is\n    refreshed. Defaults to 1800 (30 minutes). cache_intervals (int): The maximum number of times the same cached\n    content can be used before it expires. This setting allows you to\n    control how frequently the cache is updated, even if the TTL has not\n    expired. Defaults to 10 . ", "code_blocks": []}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 For a full implementation of how to use and test the context caching feature,\nsee the following sample: cache_analysis :\n    A code sample that demonstrates how to analyze the performance of context\n    caching. If your use case requires that you provide instructions that are used throughout\na session, consider using the static_instruction parameter for an agent, which\nallows you to amend the system instructions for a generative model. For more\ndetails, see this sample code: static_instruction :\n    An implementation of a digital pet agent using static instructions. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:33.556159", "source_type": "adk-docs"}
{"doc_id": "083be62a83d4b41156a1b0fb652439d41d0c84475feb982342dce98fa2b14ad2", "url": "https://google.github.io/adk-docs/context/compaction", "title": "Context compression - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Compress agent context for performance\u00b6"], "text": "Compress agent context for performance \u00b6 Supported in ADK Python v1.16.0 As an ADK agent runs it collects context information, including user\ninstructions, retrieved data, tool responses, and generated content. As the size\nof this context data grows, agent processing times typically also increase.\nMore and more data is sent to the generative AI model used by the agent,\nincreasing processing time and slowing down responses. The ADK Context\nCompaction feature is designed to reduce the size of context as an agent\nis running by summarizing older parts of the agent workflow event history. The Context Compaction feature uses a sliding window approach for collecting\nand summarizing agent workflow event data within a Session . When you configure this feature in your\nagent, it summarizes data from older events once it reaches a threshold of a\nspecific number of workflow events, or invocations, with the current Session. ", "code_blocks": []}, {"heading_path": ["Configure context compaction\u00b6"], "text": "Configure context compaction \u00b6 Add context compaction to your agent workflow by adding an Events Compaction\nConfiguration setting to the App object of your workflow. As part of the\nconfiguration, you must specify a compaction interval and overlap size, as shown\nin the following sample code: from google.adk.apps.app import App from google.adk.apps.app import EventsCompactionConfig app = App ( name = 'my-agent' , root_agent = root_agent , events_compaction_config = EventsCompactionConfig ( compaction_interval = 3 , # Trigger compaction every 3 new invocations. overlap_size = 1 # Include last invocation from the previous window. ), ) Once configured, the ADK Runner handles the compaction process in the\nbackground each time the session reaches the interval. ", "code_blocks": [{"language": "text", "code": "from google.adk.apps.app import App\nfrom google.adk.apps.app import EventsCompactionConfig\n\napp = App(\n    name='my-agent',\n    root_agent=root_agent,\n    events_compaction_config=EventsCompactionConfig(\n        compaction_interval=3,  # Trigger compaction every 3 new invocations.\n        overlap_size=1          # Include last invocation from the previous window.\n    ),\n)"}]}, {"heading_path": ["Example of context compaction\u00b6"], "text": "Example of context compaction \u00b6 If you set compaction_interval to 3 and overlap_size to 1, the event data is\ncompressed upon completion of events 3, 6, 9, and so on. The overlap setting\nincreases size of the second summary compression, and each summary afterwards,\nas shown in Figure 1. Figure 1. Ilustration of event compaction configuration with a interval of 3\nand overlap of 1. With this example configuration, the context compression tasks happen as follows: Event 3 completes : All 3 events are compressed into a summary Event 6 completes : Events 3 to 6 are compressed, including the overlap\n    of 1 prior event Event 9 completes : Events 6 to 9 are compressed, including the overlap\n    of 1 prior event ", "code_blocks": []}, {"heading_path": ["Configuration settings\u00b6"], "text": "Configuration settings \u00b6 The configuration settings for this feature control how frequently event data is compressed\nand how much data is retained as the agent workflow runs. Optionally, you can configure\na compactor object compaction_interval : Set the number of completed events that triggers compaction\n    of the prior event data. overlap_size : Set how many of the previously compacted events are included in a\n    newly compacted context set. compactor : (Optional) Define a compactor object including a specific AI model\n    to use for summarization. For more information, see Define a compactor . ", "code_blocks": []}, {"heading_path": ["Define a Summarizer\u00b6"], "text": "Define a Summarizer \u00b6 You can customize the process of context compression by defining a summarizer. \nThe LlmEventSummarizer class allows you to specify a particular model for summarization. \nThe following code example demonstrates how to define and configure a custom summarizer: from google.adk.apps.app import App , EventsCompactionConfig from google.adk.apps.llm_event_summarizer import LlmEventSummarizer from google.adk.models import Gemini # Define the AI model to be used for summarization: summarization_llm = Gemini ( model = \"gemini-2.5-flash\" ) # Create the summarizer with the custom model: my_summarizer = LlmEventSummarizer ( llm = summarization_llm ) # Configure the App with the custom summarizer and compaction settings: app = App ( name = 'my-agent' , root_agent = root_agent , events_compaction_config = EventsCompactionConfig ( summarizer = my_summarizer , compaction_interval = 3 , overlap_size = 1 ), ) You can further refine the operation of the SlidingWindowCompactor by\nby modifying its summarizer class LlmEventSummarizer including changing\nthe prompt_template setting of that class. For more details, see the LlmEventSummarizer code . Back to top ", "code_blocks": [{"language": "text", "code": "from google.adk.apps.app import App, EventsCompactionConfig\nfrom google.adk.apps.llm_event_summarizer import LlmEventSummarizer\nfrom google.adk.models import Gemini\n\n# Define the AI model to be used for summarization:\nsummarization_llm = Gemini(model=\"gemini-2.5-flash\")\n\n# Create the summarizer with the custom model:\nmy_summarizer = LlmEventSummarizer(llm=summarization_llm)\n\n# Configure the App with the custom summarizer and compaction settings:\napp = App(\n    name='my-agent',\n    root_agent=root_agent,\n    events_compaction_config=EventsCompactionConfig(\n        summarizer=my_summarizer,\n        compaction_interval=3,\n        overlap_size=1\n    ),\n)"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:34.035438", "source_type": "adk-docs"}
{"doc_id": "05392429cafc47c4f5b3f89ff754781876f07d7cc99e3446f498b8338cb4d88d", "url": "https://google.github.io/adk-docs/sessions", "title": "Introduction to Conversational Context: Session, State, and Memory - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Introduction to Conversational Context: Session, State, and Memory\u00b6"], "text": "Introduction to Conversational Context: Session, State, and Memory \u00b6 Supported in ADK Python Go Java Meaningful, multi-turn conversations require agents to understand context. Just\nlike humans, they need to recall the conversation history: what's been said and\ndone to maintain continuity and avoid repetition. The Agent Development Kit\n(ADK) provides structured ways to manage this context through Session , State , and Memory . ", "code_blocks": []}, {"heading_path": ["Core Concepts\u00b6"], "text": "Core Concepts \u00b6 Think of different instances of your conversations with the agent as distinct conversation threads , potentially drawing upon long-term knowledge . Session : The Current Conversation Thread Represents a single, ongoing interaction between a user and your agent\n    system. Contains the chronological sequence of messages and actions taken by the\n    agent (referred to Events ) during that specific interaction . A Session can also hold temporary data ( State ) relevant only during\n    this conversation . State ( session.state ) : Data Within the Current Conversation Data stored within a specific Session . Used to manage information relevant only to the current, active conversation thread (e.g., items in a shopping cart during this chat ,\n    user preferences mentioned in this session ). Memory : Searchable, Cross-Session Information Represents a store of information that might span multiple past\n    sessions or include external data sources. It acts as a knowledge base the agent can search to recall information\n    or context beyond the immediate conversation. ", "code_blocks": []}, {"heading_path": ["Managing Context: Services\u00b6"], "text": "Managing Context: Services \u00b6 ADK provides services to manage these concepts: SessionService : Manages the different conversation threads ( Session objects) Handles the lifecycle: creating, retrieving, updating (appending Events , modifying State ), and deleting individual Session s. MemoryService : Manages the Long-Term Knowledge Store ( Memory ) Handles ingesting information (often from completed Session s) into the\n    long-term store. Provides methods to search this stored knowledge based on queries. Implementations : ADK offers different implementations for both SessionService and MemoryService , allowing you to choose the storage backend\nthat best fits your application's needs. Notably, in-memory implementations are provided for both services; these are designed specifically for local\ntesting and fast development . It's important to remember that all data\nstored using these in-memory options (sessions, state, or long-term knowledge)\nis lost when your application restarts . For persistence and scalability beyond\nlocal testing, ADK also offers cloud-based and database service options. In Summary: Session & State : Focus on the current interaction \u2013 the history\n    and data of the single, active conversation . Managed primarily by a SessionService . Memory : Focuses on the past and external information \u2013 a searchable\n    archive potentially spanning across conversations. Managed by a MemoryService . ", "code_blocks": []}, {"heading_path": ["What's Next?\u00b6"], "text": "What's Next? \u00b6 In the following sections, we'll dive deeper into each of these components: Session : Understanding its structure and Events . State : How to effectively read, write, and manage session-specific\n    data. SessionService : Choosing the right storage backend for your sessions. MemoryService : Exploring options for storing and retrieving broader\n    context. Understanding these concepts is fundamental to building agents that can engage\nin complex, stateful, and context-aware conversations. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:34.526728", "source_type": "adk-docs"}
{"doc_id": "d521c444a211baa8f336fa5b12c94d6a73ae36409b6ade86ee334b3da7f4d7e3", "url": "https://google.github.io/adk-docs/sessions/session", "title": "Session - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Session: Tracking Individual Conversations\u00b6"], "text": "Session: Tracking Individual Conversations \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 Following our Introduction, let's dive into the Session . Think back to the\nidea of a \"conversation thread.\" Just like you wouldn't start every text message\nfrom scratch, agents need context regarding the ongoing interaction. Session is the ADK object designed specifically to track and manage these\nindividual conversation threads. ", "code_blocks": []}, {"heading_path": ["The Session Object\u00b6"], "text": "The Session Object \u00b6 When a user starts interacting with your agent, the SessionService creates a Session object ( google.adk.sessions.Session ). This object acts as the\ncontainer holding everything related to that one specific chat thread . Here\nare its key properties: Identification ( id , appName , userId ): Unique labels for the\n    conversation. id : A unique identifier for this specific conversation thread, essential for retrieving it later. A SessionService object can handle multiple Session (s). This field identifies which particular session object are we referring to. For example, \"test_id_modification\". app_name : Identifies which agent application this conversation belongs to. For example, \"id_modifier_workflow\". userId : Links the conversation to a particular user. History ( events ): A chronological sequence of all interactions\n    ( Event objects \u2013 user messages, agent responses, tool actions) that have\n    occurred within this specific thread. Session State ( state ): A place to store temporary data relevant only to this specific, ongoing conversation. This acts as a scratchpad for the\n    agent during the interaction. We will cover how to use and manage state in\n    detail in the next section. Activity Tracking ( lastUpdateTime ): A timestamp indicating the last\n    time an event occurred in this conversation thread. ", "code_blocks": []}, {"heading_path": ["Example: Examining Session Properties\u00b6"], "text": "Example: Examining Session Properties \u00b6 Python Go Java from google.adk.sessions import InMemorySessionService , Session # Create a simple session to examine its properties temp_service = InMemorySessionService () example_session = await temp_service . create_session ( app_name = \"my_app\" , user_id = \"example_user\" , state = { \"initial_key\" : \"initial_value\" } # State can be initialized ) print ( f \"--- Examining Session Properties ---\" ) print ( f \"ID (`id`): { example_session . id } \" ) print ( f \"Application Name (`app_name`): { example_session . app_name } \" ) print ( f \"User ID (`user_id`): { example_session . user_id } \" ) print ( f \"State (`state`): { example_session . state } \" ) # Note: Only shows initial state here print ( f \"Events (`events`): { example_session . events } \" ) # Initially empty print ( f \"Last Update (`last_update_time`): { example_session . last_update_time : .2f } \" ) print ( f \"---------------------------------\" ) # Clean up (optional for this example) temp_service = await temp_service . delete_session ( app_name = example_session . app_name , user_id = example_session . user_id , session_id = example_session . id ) print ( \"The final status of temp_service - \" , temp_service ) appName := \"my_go_app\" userID := \"example_go_user\" initialState := map [ string ] any { \"initial_key\" : \"initial_value\" } // Create a session to examine its properties. createResp , err := inMemoryService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , State : initialState , }) if err != nil { log . Fatalf ( \"Failed to create session: %v\" , err ) } exampleSession := createResp . Session fmt . Println ( \"\\n--- Examining Session Properties ---\" ) fmt . Printf ( \"ID (`ID()`): %s\\n\" , exampleSession . ID ()) fmt . Printf ( \"Application Name (`AppName()`): %s\\n\" , exampleSession . AppName ()) // To access state, you call Get(). val , _ := exampleSession . State (). Get ( \"initial_key\" ) fmt . Printf ( \"State (`State().Get()`):    initial_key = %v\\n\" , val ) // Events are initially empty. fmt . Printf ( \"Events (`Events().Len()`):  %d\\n\" , exampleSession . Events (). Len ()) fmt . Printf ( \"Last Update (`LastUpdateTime()`): %s\\n\" , exampleSession . LastUpdateTime (). Format ( \"2006-01-02 15:04:05\" )) fmt . Println ( \"---------------------------------\" ) // Clean up the session. err = inMemoryService . Delete ( ctx , & session . DeleteRequest { AppName : exampleSession . AppName (), UserID : exampleSession . UserID (), SessionID : exampleSession . ID (), }) if err != nil { log . Fatalf ( \"Failed to delete session: %v\" , err ) } fmt . Println ( \"Session deleted successfully.\" ) import com.google.adk.sessions.InMemorySessionService ; import com.google.adk.sessions.Session ; import java.util.concurrent.ConcurrentMap ; import java.util.concurrent.ConcurrentHashMap ; String sessionId = \"123\" ; String appName = \"example-app\" ; // Example app name String userId = \"example-user\" ; // Example user id ConcurrentMap < String , Object > initialState = new ConcurrentHashMap <> ( Map . of ( \"newKey\" , \"newValue\" )); InMemorySessionService exampleSessionService = new InMemorySessionService (); // Create Session Session exampleSession = exampleSessionService . createSession ( appName , userId , initialState , Optional . of ( sessionId )). blockingGet (); System . out . println ( \"Session created successfully.\" ); System . out . println ( \"--- Examining Session Properties ---\" ); System . out . printf ( \"ID (`id`): %s%n\" , exampleSession . id ()); System . out . printf ( \"Application Name (`appName`): %s%n\" , exampleSession . appName ()); System . out . printf ( \"User ID (`userId`): %s%n\" , exampleSession . userId ()); System . out . printf ( \"State (`state`): %s%n\" , exampleSession . state ()); System . out . println ( \"------------------------------------\" ); // Clean up (optional for this example) var unused = exampleSessionService . deleteSession ( appName , userId , sessionId ); ( Note: The state shown above is only the initial state. State updates\nhappen via events, as discussed in the State section.) ", "code_blocks": [{"language": "text", "code": "from google.adk.sessions import InMemorySessionService, Session\n\n # Create a simple session to examine its properties\n temp_service = InMemorySessionService()\n example_session = await temp_service.create_session(\n     app_name=\"my_app\",\n     user_id=\"example_user\",\n     state={\"initial_key\": \"initial_value\"} # State can be initialized\n )\n\n print(f\"--- Examining Session Properties ---\")\n print(f\"ID (`id`):                {example_session.id}\")\n print(f\"Application Name (`app_name`): {example_session.app_name}\")\n print(f\"User ID (`user_id`):         {example_session.user_id}\")\n print(f\"State (`state`):           {example_session.state}\") # Note: Only shows initial state here\n print(f\"Events (`events`):         {example_session.events}\") # Initially empty\n print(f\"Last Update (`last_update_time`): {example_session.last_update_time:.2f}\")\n print(f\"---------------------------------\")\n\n # Clean up (optional for this example)\n temp_service = await temp_service.delete_session(app_name=example_session.app_name,\n                             user_id=example_session.user_id, session_id=example_session.id)\n print(\"The final status of temp_service - \", temp_service)"}, {"language": "text", "code": "appName := \"my_go_app\"\nuserID := \"example_go_user\"\ninitialState := map[string]any{\"initial_key\": \"initial_value\"}\n\n// Create a session to examine its properties.\ncreateResp, err := inMemoryService.Create(ctx, &session.CreateRequest{\n AppName: appName,\n UserID:  userID,\n State:   initialState,\n})\nif err != nil {\n log.Fatalf(\"Failed to create session: %v\", err)\n}\nexampleSession := createResp.Session\n\nfmt.Println(\"\\n--- Examining Session Properties ---\")\nfmt.Printf(\"ID (`ID()`): %s\\n\", exampleSession.ID())\nfmt.Printf(\"Application Name (`AppName()`): %s\\n\", exampleSession.AppName())\n// To access state, you call Get().\nval, _ := exampleSession.State().Get(\"initial_key\")\nfmt.Printf(\"State (`State().Get()`):    initial_key = %v\\n\", val)\n\n// Events are initially empty.\nfmt.Printf(\"Events (`Events().Len()`):  %d\\n\", exampleSession.Events().Len())\nfmt.Printf(\"Last Update (`LastUpdateTime()`): %s\\n\", exampleSession.LastUpdateTime().Format(\"2006-01-02 15:04:05\"))\nfmt.Println(\"---------------------------------\")\n\n// Clean up the session.\nerr = inMemoryService.Delete(ctx, &session.DeleteRequest{\n AppName:   exampleSession.AppName(),\n UserID:    exampleSession.UserID(),\n SessionID: exampleSession.ID(),\n})\nif err != nil {\n log.Fatalf(\"Failed to delete session: %v\", err)\n}\nfmt.Println(\"Session deleted successfully.\")"}, {"language": "text", "code": "import com.google.adk.sessions.InMemorySessionService;\n import com.google.adk.sessions.Session;\n import java.util.concurrent.ConcurrentMap;\n import java.util.concurrent.ConcurrentHashMap;\n\n String sessionId = \"123\";\n String appName = \"example-app\"; // Example app name\n String userId = \"example-user\"; // Example user id\n ConcurrentMap<String, Object> initialState = new ConcurrentHashMap<>(Map.of(\"newKey\", \"newValue\"));\n InMemorySessionService exampleSessionService = new InMemorySessionService();\n\n // Create Session\n Session exampleSession = exampleSessionService.createSession(\n     appName, userId, initialState, Optional.of(sessionId)).blockingGet();\n System.out.println(\"Session created successfully.\");\n\n System.out.println(\"--- Examining Session Properties ---\");\n System.out.printf(\"ID (`id`): %s%n\", exampleSession.id());\n System.out.printf(\"Application Name (`appName`): %s%n\", exampleSession.appName());\n System.out.printf(\"User ID (`userId`): %s%n\", exampleSession.userId());\n System.out.printf(\"State (`state`): %s%n\", exampleSession.state());\n System.out.println(\"------------------------------------\");\n\n\n // Clean up (optional for this example)\n var unused = exampleSessionService.deleteSession(appName, userId, sessionId);"}]}, {"heading_path": ["Managing Sessions with a SessionService\u00b6"], "text": "Managing Sessions with a SessionService \u00b6 As seen above, you don't typically create or manage Session objects directly.\nInstead, you use a SessionService . This service acts as the central\nmanager responsible for the entire lifecycle of your conversation sessions. Its core responsibilities include: Starting New Conversations: Creating fresh Session objects when a user\n    begins an interaction. Resuming Existing Conversations: Retrieving a specific Session (using\n    its ID) so the agent can continue where it left off. Saving Progress: Appending new interactions ( Event objects) to a\n    session's history. This is also the mechanism through which session state gets updated (more in the State section). Listing Conversations: Finding the active session threads for a\n    particular user and application. Cleaning Up: Deleting Session objects and their associated data when\n    conversations are finished or no longer needed. ", "code_blocks": []}, {"heading_path": ["SessionService Implementations\u00b6"], "text": "SessionService Implementations \u00b6 ADK provides different SessionService implementations, allowing you to choose\nthe storage backend that best suits your needs: InMemorySessionService How it works: Stores all session data directly in the application's\n    memory. Persistence: None. All conversation data is lost if the\n    application restarts. Requires: Nothing extra. Best for: Quick development, local testing, examples, and scenarios\n    where long-term persistence isn't required. Python Go Java from google.adk.sessions import InMemorySessionService session_service = InMemorySessionService () import \"google.golang.org/adk/session\" inMemoryService := session . InMemoryService () import com.google.adk.sessions.InMemorySessionService ; InMemorySessionService exampleSessionService = new InMemorySessionService (); VertexAiSessionService How it works: Uses Google Cloud Vertex AI infrastructure via API\n    calls for session management. Persistence: Yes. Data is managed reliably and scalably via Vertex AI Agent Engine . Requires: A Google Cloud project ( pip install vertexai ) A Google Cloud storage bucket that can be configured by this step . A Reasoning Engine resource name/ID that can setup following this tutorial . If you do not have a Google Cloud project and you want to try the VertexAiSessionService for free, see how to try Session and Memory for free. Best for: Scalable production applications deployed on Google Cloud,\n    especially when integrating with other Vertex AI features. Python Go Java # Requires: pip install google-adk[vertexai] # Plus GCP setup and authentication from google.adk.sessions import VertexAiSessionService PROJECT_ID = \"your-gcp-project-id\" LOCATION = \"us-central1\" # The app_name used with this service should be the Reasoning Engine ID or name REASONING_ENGINE_APP_NAME = \"projects/your-gcp-project-id/locations/us-central1/reasoningEngines/your-engine-id\" session_service = VertexAiSessionService ( project = PROJECT_ID , location = LOCATION ) # Use REASONING_ENGINE_APP_NAME when calling service methods, e.g.: # session_service = await session_service.create_session(app_name=REASONING_ENGINE_APP_NAME, ...) import \"google.golang.org/adk/session\" // 2. VertexAIService // Before running, ensure your environment is authenticated: // gcloud auth application-default login // export GOOGLE_CLOUD_PROJECT=\"your-gcp-project-id\" // export GOOGLE_CLOUD_LOCATION=\"your-gcp-location\" modelName := \"gemini-1.5-flash-001\" // Replace with your desired model vertexService , err := session . VertexAIService ( ctx , modelName ) if err != nil { log . Printf ( \"Could not initialize VertexAIService (this is expected if the gcloud project is not set): %v\" , err ) } else { fmt . Println ( \"Successfully initialized VertexAIService.\" ) } // Please look at the set of requirements above, consequently export the following in your bashrc file: // export GOOGLE_CLOUD_PROJECT=my_gcp_project // export GOOGLE_CLOUD_LOCATION=us-central1 // export GOOGLE_API_KEY=my_api_key import com.google.adk.sessions.VertexAiSessionService ; import java.util.UUID ; String sessionId = UUID . randomUUID (). toString (); String reasoningEngineAppName = \"123456789\" ; String userId = \"u_123\" ; // Example user id ConcurrentMap < String , Object > initialState = new ConcurrentHashMap <> (); // No initial state needed for this example VertexAiSessionService sessionService = new VertexAiSessionService (); Session mySession = sessionService . createSession ( reasoningEngineAppName , userId , initialState , Optional . of ( sessionId )) . blockingGet (); DatabaseSessionService Supported in ADK Python v0.1.0 Go v0.1.0 How it works: Connects to a relational database (e.g., PostgreSQL,\n    MySQL, SQLite) to store session data persistently in tables. Persistence: Yes. Data survives application restarts. Requires: A configured database. Best for: Applications needing reliable, persistent storage that you\n    manage yourself. from google.adk.sessions import DatabaseSessionService # Example using a local SQLite file: db_url = \"sqlite:///./my_agent_data.db\" session_service = DatabaseSessionService ( db_url = db_url ) Choosing the right SessionService is key to defining how your agent's\nconversation history and temporary data are stored and persist. ", "code_blocks": [{"language": "text", "code": "from google.adk.sessions import InMemorySessionService\n session_service = InMemorySessionService()"}, {"language": "text", "code": "import \"google.golang.org/adk/session\"\n\n inMemoryService := session.InMemoryService()"}, {"language": "text", "code": "import com.google.adk.sessions.InMemorySessionService;\n InMemorySessionService exampleSessionService = new InMemorySessionService();"}, {"language": "text", "code": "# Requires: pip install google-adk[vertexai]\n# Plus GCP setup and authentication\nfrom google.adk.sessions import VertexAiSessionService\n\nPROJECT_ID = \"your-gcp-project-id\"\nLOCATION = \"us-central1\"\n# The app_name used with this service should be the Reasoning Engine ID or name\nREASONING_ENGINE_APP_NAME = \"projects/your-gcp-project-id/locations/us-central1/reasoningEngines/your-engine-id\"\n\nsession_service = VertexAiSessionService(project=PROJECT_ID, location=LOCATION)\n# Use REASONING_ENGINE_APP_NAME when calling service methods, e.g.:\n# session_service = await session_service.create_session(app_name=REASONING_ENGINE_APP_NAME, ...)"}, {"language": "text", "code": "import \"google.golang.org/adk/session\"\n\n// 2. VertexAIService\n// Before running, ensure your environment is authenticated:\n// gcloud auth application-default login\n// export GOOGLE_CLOUD_PROJECT=\"your-gcp-project-id\"\n// export GOOGLE_CLOUD_LOCATION=\"your-gcp-location\"\n\nmodelName := \"gemini-1.5-flash-001\" // Replace with your desired model\nvertexService, err := session.VertexAIService(ctx, modelName)\nif err != nil {\n  log.Printf(\"Could not initialize VertexAIService (this is expected if the gcloud project is not set): %v\", err)\n} else {\n  fmt.Println(\"Successfully initialized VertexAIService.\")\n}"}, {"language": "text", "code": "// Please look at the set of requirements above, consequently export the following in your bashrc file:\n// export GOOGLE_CLOUD_PROJECT=my_gcp_project\n// export GOOGLE_CLOUD_LOCATION=us-central1\n// export GOOGLE_API_KEY=my_api_key\n\nimport com.google.adk.sessions.VertexAiSessionService;\nimport java.util.UUID;\n\nString sessionId = UUID.randomUUID().toString();\nString reasoningEngineAppName = \"123456789\";\nString userId = \"u_123\"; // Example user id\nConcurrentMap<String, Object> initialState = new\n    ConcurrentHashMap<>(); // No initial state needed for this example\n\nVertexAiSessionService sessionService = new VertexAiSessionService();\nSession mySession =\n    sessionService\n        .createSession(reasoningEngineAppName, userId, initialState, Optional.of(sessionId))\n        .blockingGet();"}, {"language": "text", "code": "from google.adk.sessions import DatabaseSessionService\n# Example using a local SQLite file:\ndb_url = \"sqlite:///./my_agent_data.db\"\nsession_service = DatabaseSessionService(db_url=db_url)"}]}, {"heading_path": ["The Session Lifecycle\u00b6"], "text": "The Session Lifecycle \u00b6 Here\u2019s a simplified flow of how Session and SessionService work together\nduring a conversation turn: Start or Resume: Your application needs to use the SessionService to\n    either create_session (for a new chat) or use an existing session id. Context Provided: The Runner gets the appropriate Session object\n    from the appropriate service method, providing the agent with access to the\n    corresponding Session's state and events . Agent Processing: The user prompts the agent with a query. The agent\n    analyzes the query and potentially the session state and events history\n    to determine the response. Response & State Update: The agent generates a response (and potentially\n    flags data to be updated in the state ). The Runner packages this as an Event . Save Interaction: The Runner calls sessionService.append_event(session, event) with the session and the new event as the arguments. The service adds the Event to the history and\n    updates the session's state in storage based on information within the\n    event. The session's last_update_time also get updated. Ready for Next: The agent's response goes to the user. The updated Session is now stored by the SessionService , ready for the next turn\n    (which restarts the cycle at step 1, usually with the continuation of the\n    conversation in the current session). End Conversation: When the conversation is over, your application calls sessionService.delete_session(...) to clean up the stored session data if\n    it is no longer required. This cycle highlights how the SessionService ensures conversational continuity\nby managing the history and state associated with each Session object. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:35.073557", "source_type": "adk-docs"}
{"doc_id": "cd5e571d86853a5f63518bfe65cb6c6efe145151eca6740b3346f629b4d3f376", "url": "https://google.github.io/adk-docs/sessions/state", "title": "State - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["State: The Session's Scratchpad\u00b6"], "text": "State: The Session's Scratchpad \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 Within each Session (our conversation thread), the state attribute acts like the agent's dedicated scratchpad for that specific interaction. While session.events holds the full history, session.state is where the agent stores and updates dynamic details needed during the conversation. ", "code_blocks": []}, {"heading_path": ["What is session.state?\u00b6"], "text": "What is session.state ? \u00b6 Conceptually, session.state is a collection (dictionary or Map) holding key-value pairs. It's designed for information the agent needs to recall or track to make the current conversation effective: Personalize Interaction: Remember user preferences mentioned earlier (e.g., 'user_preference_theme': 'dark' ). Track Task Progress: Keep tabs on steps in a multi-turn process (e.g., 'booking_step': 'confirm_payment' ). Accumulate Information: Build lists or summaries (e.g., 'shopping_cart_items': ['book', 'pen'] ). Make Informed Decisions: Store flags or values influencing the next response (e.g., 'user_is_authenticated': True ). ", "code_blocks": []}, {"heading_path": ["Key Characteristics of State\u00b6"], "text": "Key Characteristics of State \u00b6 Structure: Serializable Key-Value Pairs Data is stored as key: value . Keys: Always strings ( str ). Use clear names (e.g., 'departure_city' , 'user:language_preference' ). Values: Must be serializable . This means they can be easily saved and loaded by the SessionService . Stick to basic types in the specific languages (Python/Go/Java) like strings, numbers, booleans, and simple lists or dictionaries containing only these basic types. (See API documentation for precise details). \u26a0\ufe0f Avoid Complex Objects: Do not store non-serializable objects (custom class instances, functions, connections, etc.) directly in the state. Store simple identifiers if needed, and retrieve the complex object elsewhere. Mutability: It Changes The contents of the state are expected to change as the conversation evolves. Persistence: Depends on SessionService Whether state survives application restarts depends on your chosen service: InMemorySessionService : Not Persistent. State is lost on restart. DatabaseSessionService / VertexAiSessionService : Persistent. State is saved reliably. Note The specific parameters or method names for the primitives may vary slightly by SDK language (e.g., session.state['current_intent'] = 'book_flight' in Python, context.State().Set(\"current_intent\", \"book_flight\") in Go, session.state().put(\"current_intent\", \"book_flight) in Java). Refer to the language-specific API documentation for details. ", "code_blocks": []}, {"heading_path": ["Organizing State with Prefixes: Scope Matters\u00b6"], "text": "Organizing State with Prefixes: Scope Matters \u00b6 Prefixes on state keys define their scope and persistence behavior, especially with persistent services: No Prefix (Session State): Scope: Specific to the current session ( id ). Persistence: Only persists if the SessionService is persistent ( Database , VertexAI ). Use Cases: Tracking progress within the current task (e.g., 'current_booking_step' ), temporary flags for this interaction (e.g., 'needs_clarification' ). Example: session.state['current_intent'] = 'book_flight' user: Prefix (User State): Scope: Tied to the user_id , shared across all sessions for that user (within the same app_name ). Persistence: Persistent with Database or VertexAI . (Stored by InMemory but lost on restart). Use Cases: User preferences (e.g., 'user:theme' ), profile details (e.g., 'user:name' ). Example: session.state['user:preferred_language'] = 'fr' app: Prefix (App State): Scope: Tied to the app_name , shared across all users and sessions for that application. Persistence: Persistent with Database or VertexAI . (Stored by InMemory but lost on restart). Use Cases: Global settings (e.g., 'app:api_endpoint' ), shared templates. Example: session.state['app:global_discount_code'] = 'SAVE10' temp: Prefix (Temporary Invocation State): Scope: Specific to the current invocation (the entire process from an agent receiving user input to generating the final output for that input). Persistence: Not Persistent. Discarded after the invocation completes and does not carry over to the next one. Use Cases: Storing intermediate calculations, flags, or data passed between tool calls within a single invocation. When Not to Use: For information that must persist across different invocations, such as user preferences, conversation history summaries, or accumulated data. Example: session.state['temp:raw_api_response'] = {...} Sub-Agents and Invocation Context When a parent agent calls a sub-agent (e.g., using SequentialAgent or ParallelAgent ), it passes its InvocationContext to the sub-agent. This means the entire chain of agent calls shares the same invocation ID and, therefore, the same temp: state. How the Agent Sees It: Your agent code interacts with the combined state through the single session.state collection (dict/ Map). The SessionService handles fetching/merging state from the correct underlying storage based on prefixes. ", "code_blocks": []}, {"heading_path": ["Accessing Session State in Agent Instructions\u00b6"], "text": "Accessing Session State in Agent Instructions \u00b6 When working with LlmAgent instances, you can directly inject session state values into the agent's instruction string using a simple templating syntax. This allows you to create dynamic and context-aware instructions without relying solely on natural language directives. ", "code_blocks": []}, {"heading_path": ["Using {key} Templating\u00b6"], "text": "Using {key} Templating \u00b6 To inject a value from the session state, enclose the key of the desired state variable within curly braces: {key} . The framework will automatically replace this placeholder with the corresponding value from session.state before passing the instruction to the LLM. Example: Python Go from google.adk.agents import LlmAgent story_generator = LlmAgent ( name = \"StoryGenerator\" , model = \"gemini-2.0-flash\" , instruction = \"\"\"Write a short story about a cat, focusing on the theme: {topic} .\"\"\" ) # Assuming session.state['topic'] is set to \"friendship\", the LLM # will receive the following instruction: # \"Write a short story about a cat, focusing on the theme: friendship.\" func main () { ctx := context . Background () sessionService := session . InMemoryService () // 1. Initialize a session with a 'topic' in its state. _ , err := sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , SessionID : sessionID , State : map [ string ] any { \"topic\" : \"friendship\" , }, }) if err != nil { log . Fatalf ( \"Failed to create session: %v\" , err ) } // 2. Create an agent with an instruction that uses a {topic} placeholder. //    The ADK will automatically inject the value of \"topic\" from the //    session state into the instruction before calling the LLM. model , err := gemini . NewModel ( ctx , modelID , nil ) if err != nil { log . Fatalf ( \"Failed to create Gemini model: %v\" , err ) } storyGenerator , err := llmagent . New ( llmagent . Config { Name : \"StoryGenerator\" , Model : model , Instruction : \"Write a short story about a cat, focusing on the theme: {topic}.\" , }) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } r , err := runner . New ( runner . Config { AppName : appName , Agent : agent . Agent ( storyGenerator ), SessionService : sessionService , }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import LlmAgent\n\nstory_generator = LlmAgent(\n    name=\"StoryGenerator\",\n    model=\"gemini-2.0-flash\",\n    instruction=\"\"\"Write a short story about a cat, focusing on the theme: {topic}.\"\"\"\n)\n\n# Assuming session.state['topic'] is set to \"friendship\", the LLM\n# will receive the following instruction:\n# \"Write a short story about a cat, focusing on the theme: friendship.\""}, {"language": "text", "code": "func main() {\n    ctx := context.Background()\n    sessionService := session.InMemoryService()\n\n    // 1. Initialize a session with a 'topic' in its state.\n    _, err := sessionService.Create(ctx, &session.CreateRequest{\n        AppName:   appName,\n        UserID:    userID,\n        SessionID: sessionID,\n        State: map[string]any{\n            \"topic\": \"friendship\",\n        },\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create session: %v\", err)\n    }\n\n    // 2. Create an agent with an instruction that uses a {topic} placeholder.\n    //    The ADK will automatically inject the value of \"topic\" from the\n    //    session state into the instruction before calling the LLM.\n    model, err := gemini.NewModel(ctx, modelID, nil)\n    if err != nil {\n        log.Fatalf(\"Failed to create Gemini model: %v\", err)\n    }\n    storyGenerator, err := llmagent.New(llmagent.Config{\n        Name:        \"StoryGenerator\",\n        Model:       model,\n        Instruction: \"Write a short story about a cat, focusing on the theme: {topic}.\",\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create agent: %v\", err)\n    }\n\n    r, err := runner.New(runner.Config{\n        AppName:        appName,\n        Agent:          agent.Agent(storyGenerator),\n        SessionService: sessionService,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create runner: %v\", err)\n    }"}]}, {"heading_path": ["Important Considerations\u00b6"], "text": "Important Considerations \u00b6 Key Existence: Ensure that the key you reference in the instruction string exists in the session.state. If the key is missing, the agent will throw an error. To use a key that may or may not be present, you can include a question mark (?) after the key (e.g. {topic?}). Data Types: The value associated with the key should be a string or a type that can be easily converted to a string. Escaping: If you need to use literal curly braces in your instruction (e.g., for JSON formatting), you'll need to escape them. ", "code_blocks": []}, {"heading_path": ["Bypassing State Injection with InstructionProvider\u00b6"], "text": "Bypassing State Injection with InstructionProvider \u00b6 In some cases, you might want to use {{ and }} literally in your instructions without triggering the state injection mechanism. For example, you might be writing instructions for an agent that helps with a templating language that uses the same syntax. To achieve this, you can provide a function to the instruction parameter instead of a string. This function is called an InstructionProvider . When you use an InstructionProvider , the ADK will not attempt to inject state, and your instruction string will be passed to the model as-is. The InstructionProvider function receives a ReadonlyContext object, which you can use to access session state or other contextual information if you need to build the instruction dynamically. Python Go from google.adk.agents import LlmAgent from google.adk.agents.readonly_context import ReadonlyContext # This is an InstructionProvider def my_instruction_provider ( context : ReadonlyContext ) -> str : # You can optionally use the context to build the instruction # For this example, we'll return a static string with literal braces. return \"This is an instruction with {{literal_braces}} that will not be replaced.\" agent = LlmAgent ( model = \"gemini-2.0-flash\" , name = \"template_helper_agent\" , instruction = my_instruction_provider ) //  1. This InstructionProvider returns a static string. //     Because it's a provider function, the ADK will not attempt to inject //     state, and the instruction will be passed to the model as-is, //     preserving the literal braces. func staticInstructionProvider ( ctx agent . ReadonlyContext ) ( string , error ) { return \"This is an instruction with {{literal_braces}} that will not be replaced.\" , nil } If you want to both use an InstructionProvider and inject state into your instructions, you can use the inject_session_state utility function. Python Go from google.adk.agents import LlmAgent from google.adk.agents.readonly_context import ReadonlyContext from google.adk.utils import instructions_utils async def my_dynamic_instruction_provider ( context : ReadonlyContext ) -> str : template = \"This is a {adjective} instruction with {{literal_braces}}.\" # This will inject the 'adjective' state variable but leave the literal braces. return await instructions_utils . inject_session_state ( template , context ) agent = LlmAgent ( model = \"gemini-2.0-flash\" , name = \"dynamic_template_helper_agent\" , instruction = my_dynamic_instruction_provider ) //  2. This InstructionProvider demonstrates how to manually inject state //     while also preserving literal braces. It uses the instructionutil helper. func dynamicInstructionProvider ( ctx agent . ReadonlyContext ) ( string , error ) { template := \"This is a {adjective} instruction with {{literal_braces}}.\" // This will inject the 'adjective' state variable but leave the literal braces. return instructionutil . InjectSessionState ( ctx , template ) } Benefits of Direct Injection Clarity: Makes it explicit which parts of the instruction are dynamic and based on session state. Reliability: Avoids relying on the LLM to correctly interpret natural language instructions to access state. Maintainability: Simplifies instruction strings and reduces the risk of errors when updating state variable names. Relation to Other State Access Methods This direct injection method is specific to LlmAgent instructions. Refer to the following section for more information on other state access methods. ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import LlmAgent\nfrom google.adk.agents.readonly_context import ReadonlyContext\n\n# This is an InstructionProvider\ndef my_instruction_provider(context: ReadonlyContext) -> str:\n    # You can optionally use the context to build the instruction\n    # For this example, we'll return a static string with literal braces.\n    return \"This is an instruction with {{literal_braces}} that will not be replaced.\"\n\nagent = LlmAgent(\n    model=\"gemini-2.0-flash\",\n    name=\"template_helper_agent\",\n    instruction=my_instruction_provider\n)"}, {"language": "text", "code": "//  1. This InstructionProvider returns a static string.\n//     Because it's a provider function, the ADK will not attempt to inject\n//     state, and the instruction will be passed to the model as-is,\n//     preserving the literal braces.\nfunc staticInstructionProvider(ctx agent.ReadonlyContext) (string, error) {\n    return \"This is an instruction with {{literal_braces}} that will not be replaced.\", nil\n}"}, {"language": "text", "code": "from google.adk.agents import LlmAgent\nfrom google.adk.agents.readonly_context import ReadonlyContext\nfrom google.adk.utils import instructions_utils\n\nasync def my_dynamic_instruction_provider(context: ReadonlyContext) -> str:\n    template = \"This is a {adjective} instruction with {{literal_braces}}.\"\n    # This will inject the 'adjective' state variable but leave the literal braces.\n    return await instructions_utils.inject_session_state(template, context)\n\nagent = LlmAgent(\n    model=\"gemini-2.0-flash\",\n    name=\"dynamic_template_helper_agent\",\n    instruction=my_dynamic_instruction_provider\n)"}, {"language": "text", "code": "//  2. This InstructionProvider demonstrates how to manually inject state\n//     while also preserving literal braces. It uses the instructionutil helper.\nfunc dynamicInstructionProvider(ctx agent.ReadonlyContext) (string, error) {\n    template := \"This is a {adjective} instruction with {{literal_braces}}.\"\n    // This will inject the 'adjective' state variable but leave the literal braces.\n    return instructionutil.InjectSessionState(ctx, template)\n}"}]}, {"heading_path": ["How State is Updated: Recommended Methods\u00b6"], "text": "How State is Updated: Recommended Methods \u00b6 The Right Way to Modify State When you need to change the session state, the correct and safest method is to directly modify the state object on the Context provided to your function (e.g., callback_context.state['my_key'] = 'new_value' ). This is considered \"direct state manipulation\" in the right way, as the framework automatically tracks these changes. This is critically different from directly modifying the state on a Session object you retrieve from the SessionService (e.g., my_session.state['my_key'] = 'new_value' ). You should avoid this , as it bypasses the ADK's event tracking and can lead to lost data. The \"Warning\" section at the end of this page has more details on this important distinction. State should always be updated as part of adding an Event to the session history using session_service.append_event() . This ensures changes are tracked, persistence works correctly, and updates are thread-safe. 1. The Easy Way: output_key (for Agent Text Responses) This is the simplest method for saving an agent's final text response directly into the state. When defining your LlmAgent , specify the output_key : Python Java Go from google.adk.agents import LlmAgent from google.adk.sessions import InMemorySessionService , Session from google.adk.runners import Runner from google.genai.types import Content , Part # Define agent with output_key greeting_agent = LlmAgent ( name = \"Greeter\" , model = \"gemini-2.0-flash\" , # Use a valid model instruction = \"Generate a short, friendly greeting.\" , output_key = \"last_greeting\" # Save response to state['last_greeting'] ) # --- Setup Runner and Session --- app_name , user_id , session_id = \"state_app\" , \"user1\" , \"session1\" session_service = InMemorySessionService () runner = Runner ( agent = greeting_agent , app_name = app_name , session_service = session_service ) session = await session_service . create_session ( app_name = app_name , user_id = user_id , session_id = session_id ) print ( f \"Initial state: { session . state } \" ) # --- Run the Agent --- # Runner handles calling append_event, which uses the output_key # to automatically create the state_delta. user_message = Content ( parts = [ Part ( text = \"Hello\" )]) for event in runner . run ( user_id = user_id , session_id = session_id , new_message = user_message ): if event . is_final_response (): print ( f \"Agent responded.\" ) # Response text is also in event.content # --- Check Updated State --- updated_session = await session_service . get_session ( app_name = APP_NAME , user_id = USER_ID , session_id = session_id ) print ( f \"State after agent run: { updated_session . state } \" ) # Expected output might include: {'last_greeting': 'Hello there! How can I help you today?'} import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.RunConfig ; import com.google.adk.events.Event ; import com.google.adk.runner.Runner ; import com.google.adk.sessions.InMemorySessionService ; import com.google.adk.sessions.Session ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import java.util.List ; import java.util.Optional ; public class GreetingAgentExample { public static void main ( String [] args ) { // Define agent with output_key LlmAgent greetingAgent = LlmAgent . builder () . name ( \"Greeter\" ) . model ( \"gemini-2.0-flash\" ) . instruction ( \"Generate a short, friendly greeting.\" ) . description ( \"Greeting agent\" ) . outputKey ( \"last_greeting\" ) // Save response to state['last_greeting'] . build (); // --- Setup Runner and Session --- String appName = \"state_app\" ; String userId = \"user1\" ; String sessionId = \"session1\" ; InMemorySessionService sessionService = new InMemorySessionService (); Runner runner = new Runner ( greetingAgent , appName , null , sessionService ); // artifactService can be null if not used Session session = sessionService . createSession ( appName , userId , null , sessionId ). blockingGet (); System . out . println ( \"Initial state: \" + session . state (). entrySet ()); // --- Run the Agent --- // Runner handles calling appendEvent, which uses the output_key // to automatically create the stateDelta. Content userMessage = Content . builder (). parts ( List . of ( Part . fromText ( \"Hello\" ))). build (); // RunConfig is needed for runner.runAsync in Java RunConfig runConfig = RunConfig . builder (). build (); for ( Event event : runner . runAsync ( userId , sessionId , userMessage , runConfig ). blockingIterable ()) { if ( event . finalResponse ()) { System . out . println ( \"Agent responded.\" ); // Response text is also in event.content } } // --- Check Updated State --- Session updatedSession = sessionService . getSession ( appName , userId , sessionId , Optional . empty ()). blockingGet (); assert updatedSession != null ; System . out . println ( \"State after agent run: \" + updatedSession . state (). entrySet ()); // Expected output might include: {'last_greeting': 'Hello there! How can I help you today?'} } } //  1. GreetingAgent demonstrates using `OutputKey` to save an agent's //     final text response directly into the session state. func greetingAgentExample ( sessionService session . Service ) { fmt . Println ( \"--- Running GreetingAgent (output_key) Example ---\" ) ctx := context . Background () modelGreeting , err := gemini . NewModel ( ctx , modelID , nil ) if err != nil { log . Fatalf ( \"Failed to create Gemini model for greeting agent: %v\" , err ) } greetingAgent , err := llmagent . New ( llmagent . Config { Name : \"Greeter\" , Model : modelGreeting , Instruction : \"Generate a short, friendly greeting.\" , OutputKey : \"last_greeting\" , }) if err != nil { log . Fatalf ( \"Failed to create greeting agent: %v\" , err ) } r , err := runner . New ( runner . Config { AppName : appName , Agent : agent . Agent ( greetingAgent ), SessionService : sessionService , }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } // Run the agent userMessage := genai . NewContentFromText ( \"Hello\" , \"user\" ) for event , err := range r . Run ( ctx , userID , sessionID , userMessage , agent . RunConfig {}) { if err != nil { log . Printf ( \"Agent Error: %v\" , err ) continue } if isFinalResponse ( event ) { if event . LLMResponse . Content != nil { fmt . Printf ( \"Agent responded with: %q\\n\" , textParts ( event . LLMResponse . Content )) } else { fmt . Println ( \"Agent responded.\" ) } } } // Check the updated state resp , err := sessionService . Get ( ctx , & session . GetRequest { AppName : appName , UserID : userID , SessionID : sessionID }) if err != nil { log . Fatalf ( \"Failed to get session: %v\" , err ) } lastGreeting , _ := resp . Session . State (). Get ( \"last_greeting\" ) fmt . Printf ( \"State after agent run: last_greeting = %q\\n\\n\" , lastGreeting ) } Behind the scenes, the Runner uses the output_key to create the necessary EventActions with a state_delta and calls append_event . 2. The Standard Way: EventActions.state_delta (for Complex Updates) For more complex scenarios (updating multiple keys, non-string values, specific scopes like user: or app: , or updates not tied directly to the agent's final text), you manually construct the state_delta within EventActions . Python Go Java from google.adk.sessions import InMemorySessionService , Session from google.adk.events import Event , EventActions from google.genai.types import Part , Content import time # --- Setup --- session_service = InMemorySessionService () app_name , user_id , session_id = \"state_app_manual\" , \"user2\" , \"session2\" session = await session_service . create_session ( app_name = app_name , user_id = user_id , session_id = session_id , state = { \"user:login_count\" : 0 , \"task_status\" : \"idle\" } ) print ( f \"Initial state: { session . state } \" ) # --- Define State Changes --- current_time = time . time () state_changes = { \"task_status\" : \"active\" , # Update session state \"user:login_count\" : session . state . get ( \"user:login_count\" , 0 ) + 1 , # Update user state \"user:last_login_ts\" : current_time , # Add user state \"temp:validation_needed\" : True # Add temporary state (will be discarded) } # --- Create Event with Actions --- actions_with_update = EventActions ( state_delta = state_changes ) # This event might represent an internal system action, not just an agent response system_event = Event ( invocation_id = \"inv_login_update\" , author = \"system\" , # Or 'agent', 'tool' etc. actions = actions_with_update , timestamp = current_time # content might be None or represent the action taken ) # --- Append the Event (This updates the state) --- await session_service . append_event ( session , system_event ) print ( \"`append_event` called with explicit state delta.\" ) # --- Check Updated State --- updated_session = await session_service . get_session ( app_name = app_name , user_id = user_id , session_id = session_id ) print ( f \"State after event: { updated_session . state } \" ) # Expected: {'user:login_count': 1, 'task_status': 'active', 'user:last_login_ts': <timestamp>} # Note: 'temp:validation_needed' is NOT present. //  2. manualStateUpdateExample demonstrates creating an event with explicit //     state changes (a \"state_delta\") to update multiple keys, including //     those with user- and temp- prefixes. func manualStateUpdateExample ( sessionService session . Service ) { fmt . Println ( \"--- Running Manual State Update (EventActions) Example ---\" ) ctx := context . Background () s , err := sessionService . Get ( ctx , & session . GetRequest { AppName : appName , UserID : userID , SessionID : sessionID }) if err != nil { log . Fatalf ( \"Failed to get session: %v\" , err ) } retrievedSession := s . Session // Define state changes loginCount , _ := retrievedSession . State (). Get ( \"user:login_count\" ) newLoginCount := 1 if lc , ok := loginCount .( int ); ok { newLoginCount = lc + 1 } stateChanges := map [ string ] any { \"task_status\" : \"active\" , \"user:login_count\" : newLoginCount , \"user:last_login_ts\" : time . Now (). Unix (), \"temp:validation_needed\" : true , } // Create an event with the state changes systemEvent := session . NewEvent ( \"inv_login_update\" ) systemEvent . Author = \"system\" systemEvent . Actions . StateDelta = stateChanges // Append the event to update the state if err := sessionService . AppendEvent ( ctx , retrievedSession , systemEvent ); err != nil { log . Fatalf ( \"Failed to append event: %v\" , err ) } fmt . Println ( \"`append_event` called with explicit state delta.\" ) // Check the updated state updatedResp , err := sessionService . Get ( ctx , & session . GetRequest { AppName : appName , UserID : userID , SessionID : sessionID }) if err != nil { log . Fatalf ( \"Failed to get session: %v\" , err ) } taskStatus , _ := updatedResp . Session . State (). Get ( \"task_status\" ) loginCount , _ = updatedResp . Session . State (). Get ( \"user:login_count\" ) lastLogin , _ := updatedResp . Session . State (). Get ( \"user:last_login_ts\" ) temp , err := updatedResp . Session . State (). Get ( \"temp:validation_needed\" ) // This should fail or be nil fmt . Printf ( \"State after event: task_status=%q, user:login_count=%v, user:last_login_ts=%v\\n\" , taskStatus , loginCount , lastLogin ) if err != nil { fmt . Printf ( \"As expected, temp state was not persisted: %v\\n\\n\" , err ) } else { fmt . Printf ( \"Unexpected temp state value: %v\\n\\n\" , temp ) } } import com.google.adk.events.Event ; import com.google.adk.events.EventActions ; import com.google.adk.sessions.InMemorySessionService ; import com.google.adk.sessions.Session ; import java.time.Instant ; import java.util.Optional ; import java.util.concurrent.ConcurrentHashMap ; import java.util.concurrent.ConcurrentMap ; public class ManualStateUpdateExample { public static void main ( String [] args ) { // --- Setup --- InMemorySessionService sessionService = new InMemorySessionService (); String appName = \"state_app_manual\" ; String userId = \"user2\" ; String sessionId = \"session2\" ; ConcurrentMap < String , Object > initialState = new ConcurrentHashMap <> (); initialState . put ( \"user:login_count\" , 0 ); initialState . put ( \"task_status\" , \"idle\" ); Session session = sessionService . createSession ( appName , userId , initialState , sessionId ). blockingGet (); System . out . println ( \"Initial state: \" + session . state (). entrySet ()); // --- Define State Changes --- long currentTimeMillis = Instant . now (). toEpochMilli (); // Use milliseconds for Java Event ConcurrentMap < String , Object > stateChanges = new ConcurrentHashMap <> (); stateChanges . put ( \"task_status\" , \"active\" ); // Update session state // Retrieve and increment login_count Object loginCountObj = session . state (). get ( \"user:login_count\" ); int currentLoginCount = 0 ; if ( loginCountObj instanceof Number ) { currentLoginCount = (( Number ) loginCountObj ). intValue (); } stateChanges . put ( \"user:login_count\" , currentLoginCount + 1 ); // Update user state stateChanges . put ( \"user:last_login_ts\" , currentTimeMillis ); // Add user state (as long milliseconds) stateChanges . put ( \"temp:validation_needed\" , true ); // Add temporary state // --- Create Event with Actions --- EventActions actionsWithUpdate = EventActions . builder (). stateDelta ( stateChanges ). build (); // This event might represent an internal system action, not just an agent response Event systemEvent = Event . builder () . invocationId ( \"inv_login_update\" ) . author ( \"system\" ) // Or 'agent', 'tool' etc. . actions ( actionsWithUpdate ) . timestamp ( currentTimeMillis ) // content might be None or represent the action taken . build (); // --- Append the Event (This updates the state) --- sessionService . appendEvent ( session , systemEvent ). blockingGet (); System . out . println ( \"`appendEvent` called with explicit state delta.\" ); // --- Check Updated State --- Session updatedSession = sessionService . getSession ( appName , userId , sessionId , Optional . empty ()). blockingGet (); assert updatedSession != null ; System . out . println ( \"State after event: \" + updatedSession . state (). entrySet ()); // Expected: {'user:login_count': 1, 'task_status': 'active', 'user:last_login_ts': <timestamp_millis>} // Note: 'temp:validation_needed' is NOT present because InMemorySessionService's appendEvent // applies delta to its internal user/app state maps IF keys have prefixes, // and to the session's own state map (which is then merged on getSession). } } 3. Via CallbackContext or ToolContext (Recommended for Callbacks and Tools) Modifying state within agent callbacks (e.g., on_before_agent_call , on_after_agent_call ) or tool functions is best done using the state attribute of the CallbackContext or ToolContext provided to your function. callback_context.state['my_key'] = my_value tool_context.state['my_key'] = my_value These context objects are specifically designed to manage state changes within their respective execution scopes. When you modify context.state , the ADK framework ensures that these changes are automatically captured and correctly routed into the EventActions.state_delta for the event being generated by the callback or tool. This delta is then processed by the SessionService when the event is appended, ensuring proper persistence and tracking. This method abstracts away the manual creation of EventActions and state_delta for most common state update scenarios within callbacks and tools, making your code cleaner and less error-prone. For more comprehensive details on context objects, refer to the Context documentation . Python Go Java # In an agent callback or tool function from google.adk.agents import CallbackContext # or ToolContext def my_callback_or_tool_function ( context : CallbackContext , # Or ToolContext # ... other parameters ... ): # Update existing state count = context . state . get ( \"user_action_count\" , 0 ) context . state [ \"user_action_count\" ] = count + 1 # Add new state context . state [ \"temp:last_operation_status\" ] = \"success\" # State changes are automatically part of the event's state_delta # ... rest of callback/tool logic ... //  3. contextStateUpdateExample demonstrates the recommended way to modify state //     from within a tool function using the provided `tool.Context`. func contextStateUpdateExample ( sessionService session . Service ) { fmt . Println ( \"--- Running Context State Update (ToolContext) Example ---\" ) ctx := context . Background () // Define the tool that modifies state updateActionCountTool , err := functiontool . New [ struct {}, struct {}]( functiontool . Config { Name : \"update_action_count\" , Description : \"Updates the user action count in the state.\" }, func ( tctx tool . Context , args struct {}) struct {} { actx , ok := tctx .( agent . CallbackContext ) if ! ok { log . Fatalf ( \"tool.Context is not of type agent.CallbackContext\" ) } s , err := actx . State (). Get ( \"user_action_count\" ) if err != nil { log . Printf ( \"could not get user_action_count: %v\" , err ) } newCount := 1 if c , ok := s .( int ); ok { newCount = c + 1 } if err := actx . State (). Set ( \"user_action_count\" , newCount ); err != nil { log . Printf ( \"could not set user_action_count: %v\" , err ) } if err := actx . State (). Set ( \"temp:last_operation_status\" , \"success from tool\" ); err != nil { log . Printf ( \"could not set temp:last_operation_status: %v\" , err ) } fmt . Println ( \"Tool: Updated state via agent.CallbackContext.\" ) return struct {}{} }, ) if err != nil { log . Fatalf ( \"Failed to create tool: %v\" , err ) } // Define an agent that uses the tool modelTool , err := gemini . NewModel ( ctx , modelID , nil ) if err != nil { log . Fatalf ( \"Failed to create Gemini model for tool agent: %v\" , err ) } toolAgent , err := llmagent . New ( llmagent . Config { Name : \"ToolAgent\" , Model : modelTool , Instruction : \"Use the update_action_count tool.\" , Tools : [] tool . Tool { updateActionCountTool }, }) if err != nil { log . Fatalf ( \"Failed to create tool agent: %v\" , err ) } r , err := runner . New ( runner . Config { AppName : appName , Agent : agent . Agent ( toolAgent ), SessionService : sessionService , }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } // Run the agent to trigger the tool userMessage := genai . NewContentFromText ( \"Please update the action count.\" , \"user\" ) for _ , err := range r . Run ( ctx , userID , sessionID , userMessage , agent . RunConfig {}) { if err != nil { log . Printf ( \"Agent Error: %v\" , err ) } } // Check the updated state resp , err := sessionService . Get ( ctx , & session . GetRequest { AppName : appName , UserID : userID , SessionID : sessionID }) if err != nil { log . Fatalf ( \"Failed to get session: %v\" , err ) } actionCount , _ := resp . Session . State (). Get ( \"user_action_count\" ) fmt . Printf ( \"State after tool run: user_action_count = %v\\n\" , actionCount ) } // In an agent callback or tool method import com.google.adk.agents.CallbackContext ; // or ToolContext // ... other imports ... public class MyAgentCallbacks { public void onAfterAgent ( CallbackContext callbackContext ) { // Update existing state Integer count = ( Integer ) callbackContext . state (). getOrDefault ( \"user_action_count\" , 0 ); callbackContext . state (). put ( \"user_action_count\" , count + 1 ); // Add new state callbackContext . state (). put ( \"temp:last_operation_status\" , \"success\" ); // State changes are automatically part of the event's state_delta // ... rest of callback logic ... } } What append_event Does: Adds the Event to session.events . Reads the state_delta from the event's actions . Applies these changes to the state managed by the SessionService , correctly handling prefixes and persistence based on the service type. Updates the session's last_update_time . Ensures thread-safety for concurrent updates. ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import LlmAgent\nfrom google.adk.sessions import InMemorySessionService, Session\nfrom google.adk.runners import Runner\nfrom google.genai.types import Content, Part\n\n# Define agent with output_key\ngreeting_agent = LlmAgent(\n    name=\"Greeter\",\n    model=\"gemini-2.0-flash\", # Use a valid model\n    instruction=\"Generate a short, friendly greeting.\",\n    output_key=\"last_greeting\" # Save response to state['last_greeting']\n)\n\n# --- Setup Runner and Session ---\napp_name, user_id, session_id = \"state_app\", \"user1\", \"session1\"\nsession_service = InMemorySessionService()\nrunner = Runner(\n    agent=greeting_agent,\n    app_name=app_name,\n    session_service=session_service\n)\nsession = await session_service.create_session(app_name=app_name,\n                                    user_id=user_id,\n                                    session_id=session_id)\nprint(f\"Initial state: {session.state}\")\n\n# --- Run the Agent ---\n# Runner handles calling append_event, which uses the output_key\n# to automatically create the state_delta.\nuser_message = Content(parts=[Part(text=\"Hello\")])\nfor event in runner.run(user_id=user_id,\n                        session_id=session_id,\n                        new_message=user_message):\n    if event.is_final_response():\n      print(f\"Agent responded.\") # Response text is also in event.content\n\n# --- Check Updated State ---\nupdated_session = await session_service.get_session(app_name=APP_NAME, user_id=USER_ID, session_id=session_id)\nprint(f\"State after agent run: {updated_session.state}\")\n# Expected output might include: {'last_greeting': 'Hello there! How can I help you today?'}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.RunConfig;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.InMemorySessionService;\nimport com.google.adk.sessions.Session;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport java.util.List;\nimport java.util.Optional;\n\npublic class GreetingAgentExample {\n\n  public static void main(String[] args) {\n    // Define agent with output_key\n    LlmAgent greetingAgent =\n        LlmAgent.builder()\n            .name(\"Greeter\")\n            .model(\"gemini-2.0-flash\")\n            .instruction(\"Generate a short, friendly greeting.\")\n            .description(\"Greeting agent\")\n            .outputKey(\"last_greeting\") // Save response to state['last_greeting']\n            .build();\n\n    // --- Setup Runner and Session ---\n    String appName = \"state_app\";\n    String userId = \"user1\";\n    String sessionId = \"session1\";\n\n    InMemorySessionService sessionService = new InMemorySessionService();\n    Runner runner = new Runner(greetingAgent, appName, null, sessionService); // artifactService can be null if not used\n\n    Session session =\n        sessionService.createSession(appName, userId, null, sessionId).blockingGet();\n    System.out.println(\"Initial state: \" + session.state().entrySet());\n\n    // --- Run the Agent ---\n    // Runner handles calling appendEvent, which uses the output_key\n    // to automatically create the stateDelta.\n    Content userMessage = Content.builder().parts(List.of(Part.fromText(\"Hello\"))).build();\n\n    // RunConfig is needed for runner.runAsync in Java\n    RunConfig runConfig = RunConfig.builder().build();\n\n    for (Event event : runner.runAsync(userId, sessionId, userMessage, runConfig).blockingIterable()) {\n      if (event.finalResponse()) {\n        System.out.println(\"Agent responded.\"); // Response text is also in event.content\n      }\n    }\n\n    // --- Check Updated State ---\n    Session updatedSession =\n        sessionService.getSession(appName, userId, sessionId, Optional.empty()).blockingGet();\n    assert updatedSession != null;\n    System.out.println(\"State after agent run: \" + updatedSession.state().entrySet());\n    // Expected output might include: {'last_greeting': 'Hello there! How can I help you today?'}\n  }\n}"}, {"language": "text", "code": "//  1. GreetingAgent demonstrates using `OutputKey` to save an agent's\n//     final text response directly into the session state.\nfunc greetingAgentExample(sessionService session.Service) {\n    fmt.Println(\"--- Running GreetingAgent (output_key) Example ---\")\n    ctx := context.Background()\n\n    modelGreeting, err := gemini.NewModel(ctx, modelID, nil)\n    if err != nil {\n        log.Fatalf(\"Failed to create Gemini model for greeting agent: %v\", err)\n    }\n    greetingAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"Greeter\",\n        Model:       modelGreeting,\n        Instruction: \"Generate a short, friendly greeting.\",\n        OutputKey:   \"last_greeting\",\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create greeting agent: %v\", err)\n    }\n\n    r, err := runner.New(runner.Config{\n        AppName:        appName,\n        Agent:          agent.Agent(greetingAgent),\n        SessionService: sessionService,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create runner: %v\", err)\n    }\n\n    // Run the agent\n    userMessage := genai.NewContentFromText(\"Hello\", \"user\")\n    for event, err := range r.Run(ctx, userID, sessionID, userMessage, agent.RunConfig{}) {\n        if err != nil {\n            log.Printf(\"Agent Error: %v\", err)\n            continue\n        }\n        if isFinalResponse(event) {\n            if event.LLMResponse.Content != nil {\n                fmt.Printf(\"Agent responded with: %q\\n\", textParts(event.LLMResponse.Content))\n            } else {\n                fmt.Println(\"Agent responded.\")\n            }\n        }\n    }\n\n    // Check the updated state\n    resp, err := sessionService.Get(ctx, &session.GetRequest{AppName: appName, UserID: userID, SessionID: sessionID})\n    if err != nil {\n        log.Fatalf(\"Failed to get session: %v\", err)\n    }\n    lastGreeting, _ := resp.Session.State().Get(\"last_greeting\")\n    fmt.Printf(\"State after agent run: last_greeting = %q\\n\\n\", lastGreeting)\n}"}, {"language": "text", "code": "from google.adk.sessions import InMemorySessionService, Session\nfrom google.adk.events import Event, EventActions\nfrom google.genai.types import Part, Content\nimport time\n\n# --- Setup ---\nsession_service = InMemorySessionService()\napp_name, user_id, session_id = \"state_app_manual\", \"user2\", \"session2\"\nsession = await session_service.create_session(\n    app_name=app_name,\n    user_id=user_id,\n    session_id=session_id,\n    state={\"user:login_count\": 0, \"task_status\": \"idle\"}\n)\nprint(f\"Initial state: {session.state}\")\n\n# --- Define State Changes ---\ncurrent_time = time.time()\nstate_changes = {\n    \"task_status\": \"active\",              # Update session state\n    \"user:login_count\": session.state.get(\"user:login_count\", 0) + 1, # Update user state\n    \"user:last_login_ts\": current_time,   # Add user state\n    \"temp:validation_needed\": True        # Add temporary state (will be discarded)\n}\n\n# --- Create Event with Actions ---\nactions_with_update = EventActions(state_delta=state_changes)\n# This event might represent an internal system action, not just an agent response\nsystem_event = Event(\n    invocation_id=\"inv_login_update\",\n    author=\"system\", # Or 'agent', 'tool' etc.\n    actions=actions_with_update,\n    timestamp=current_time\n    # content might be None or represent the action taken\n)\n\n# --- Append the Event (This updates the state) ---\nawait session_service.append_event(session, system_event)\nprint(\"`append_event` called with explicit state delta.\")\n\n# --- Check Updated State ---\nupdated_session = await session_service.get_session(app_name=app_name,\n                                            user_id=user_id,\n                                            session_id=session_id)\nprint(f\"State after event: {updated_session.state}\")\n# Expected: {'user:login_count': 1, 'task_status': 'active', 'user:last_login_ts': <timestamp>}\n# Note: 'temp:validation_needed' is NOT present."}, {"language": "text", "code": "//  2. manualStateUpdateExample demonstrates creating an event with explicit\n//     state changes (a \"state_delta\") to update multiple keys, including\n//     those with user- and temp- prefixes.\nfunc manualStateUpdateExample(sessionService session.Service) {\n    fmt.Println(\"--- Running Manual State Update (EventActions) Example ---\")\n    ctx := context.Background()\n    s, err := sessionService.Get(ctx, &session.GetRequest{AppName: appName, UserID: userID, SessionID: sessionID})\n    if err != nil {\n        log.Fatalf(\"Failed to get session: %v\", err)\n    }\n    retrievedSession := s.Session\n\n    // Define state changes\n    loginCount, _ := retrievedSession.State().Get(\"user:login_count\")\n    newLoginCount := 1\n    if lc, ok := loginCount.(int); ok {\n        newLoginCount = lc + 1\n    }\n\n    stateChanges := map[string]any{\n        \"task_status\":            \"active\",\n        \"user:login_count\":       newLoginCount,\n        \"user:last_login_ts\":     time.Now().Unix(),\n        \"temp:validation_needed\": true,\n    }\n\n    // Create an event with the state changes\n    systemEvent := session.NewEvent(\"inv_login_update\")\n    systemEvent.Author = \"system\"\n    systemEvent.Actions.StateDelta = stateChanges\n\n    // Append the event to update the state\n    if err := sessionService.AppendEvent(ctx, retrievedSession, systemEvent); err != nil {\n        log.Fatalf(\"Failed to append event: %v\", err)\n    }\n    fmt.Println(\"`append_event` called with explicit state delta.\")\n\n    // Check the updated state\n    updatedResp, err := sessionService.Get(ctx, &session.GetRequest{AppName: appName, UserID: userID, SessionID: sessionID})\n    if err != nil {\n        log.Fatalf(\"Failed to get session: %v\", err)\n    }\n    taskStatus, _ := updatedResp.Session.State().Get(\"task_status\")\n    loginCount, _ = updatedResp.Session.State().Get(\"user:login_count\")\n    lastLogin, _ := updatedResp.Session.State().Get(\"user:last_login_ts\")\n    temp, err := updatedResp.Session.State().Get(\"temp:validation_needed\") // This should fail or be nil\n\n    fmt.Printf(\"State after event: task_status=%q, user:login_count=%v, user:last_login_ts=%v\\n\", taskStatus, loginCount, lastLogin)\n    if err != nil {\n        fmt.Printf(\"As expected, temp state was not persisted: %v\\n\\n\", err)\n    } else {\n        fmt.Printf(\"Unexpected temp state value: %v\\n\\n\", temp)\n    }\n}"}, {"language": "text", "code": "import com.google.adk.events.Event;\nimport com.google.adk.events.EventActions;\nimport com.google.adk.sessions.InMemorySessionService;\nimport com.google.adk.sessions.Session;\nimport java.time.Instant;\nimport java.util.Optional;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.ConcurrentMap;\n\npublic class ManualStateUpdateExample {\n\n  public static void main(String[] args) {\n    // --- Setup ---\n    InMemorySessionService sessionService = new InMemorySessionService();\n    String appName = \"state_app_manual\";\n    String userId = \"user2\";\n    String sessionId = \"session2\";\n\n    ConcurrentMap<String, Object> initialState = new ConcurrentHashMap<>();\n    initialState.put(\"user:login_count\", 0);\n    initialState.put(\"task_status\", \"idle\");\n\n    Session session =\n        sessionService.createSession(appName, userId, initialState, sessionId).blockingGet();\n    System.out.println(\"Initial state: \" + session.state().entrySet());\n\n    // --- Define State Changes ---\n    long currentTimeMillis = Instant.now().toEpochMilli(); // Use milliseconds for Java Event\n\n    ConcurrentMap<String, Object> stateChanges = new ConcurrentHashMap<>();\n    stateChanges.put(\"task_status\", \"active\"); // Update session state\n\n    // Retrieve and increment login_count\n    Object loginCountObj = session.state().get(\"user:login_count\");\n    int currentLoginCount = 0;\n    if (loginCountObj instanceof Number) {\n      currentLoginCount = ((Number) loginCountObj).intValue();\n    }\n    stateChanges.put(\"user:login_count\", currentLoginCount + 1); // Update user state\n\n    stateChanges.put(\"user:last_login_ts\", currentTimeMillis); // Add user state (as long milliseconds)\n    stateChanges.put(\"temp:validation_needed\", true); // Add temporary state\n\n    // --- Create Event with Actions ---\n    EventActions actionsWithUpdate = EventActions.builder().stateDelta(stateChanges).build();\n\n    // This event might represent an internal system action, not just an agent response\n    Event systemEvent =\n        Event.builder()\n            .invocationId(\"inv_login_update\")\n            .author(\"system\") // Or 'agent', 'tool' etc.\n            .actions(actionsWithUpdate)\n            .timestamp(currentTimeMillis)\n            // content might be None or represent the action taken\n            .build();\n\n    // --- Append the Event (This updates the state) ---\n    sessionService.appendEvent(session, systemEvent).blockingGet();\n    System.out.println(\"`appendEvent` called with explicit state delta.\");\n\n    // --- Check Updated State ---\n    Session updatedSession =\n        sessionService.getSession(appName, userId, sessionId, Optional.empty()).blockingGet();\n    assert updatedSession != null;\n    System.out.println(\"State after event: \" + updatedSession.state().entrySet());\n    // Expected: {'user:login_count': 1, 'task_status': 'active', 'user:last_login_ts': <timestamp_millis>}\n    // Note: 'temp:validation_needed' is NOT present because InMemorySessionService's appendEvent\n    // applies delta to its internal user/app state maps IF keys have prefixes,\n    // and to the session's own state map (which is then merged on getSession).\n  }\n}"}, {"language": "text", "code": "# In an agent callback or tool function\nfrom google.adk.agents import CallbackContext # or ToolContext\n\ndef my_callback_or_tool_function(context: CallbackContext, # Or ToolContext\n                                 # ... other parameters ...\n                                ):\n    # Update existing state\n    count = context.state.get(\"user_action_count\", 0)\n    context.state[\"user_action_count\"] = count + 1\n\n    # Add new state\n    context.state[\"temp:last_operation_status\"] = \"success\"\n\n    # State changes are automatically part of the event's state_delta\n    # ... rest of callback/tool logic ..."}, {"language": "text", "code": "//  3. contextStateUpdateExample demonstrates the recommended way to modify state\n//     from within a tool function using the provided `tool.Context`.\nfunc contextStateUpdateExample(sessionService session.Service) {\n    fmt.Println(\"--- Running Context State Update (ToolContext) Example ---\")\n    ctx := context.Background()\n\n    // Define the tool that modifies state\n    updateActionCountTool, err := functiontool.New[struct{}, struct{}](\n        functiontool.Config{Name: \"update_action_count\", Description: \"Updates the user action count in the state.\"},\n        func(tctx tool.Context, args struct{}) struct{} {\n            actx, ok := tctx.(agent.CallbackContext)\n            if !ok {\n                log.Fatalf(\"tool.Context is not of type agent.CallbackContext\")\n            }\n            s, err := actx.State().Get(\"user_action_count\")\n            if err != nil {\n                log.Printf(\"could not get user_action_count: %v\", err)\n            }\n            newCount := 1\n            if c, ok := s.(int); ok {\n                newCount = c + 1\n            }\n            if err := actx.State().Set(\"user_action_count\", newCount); err != nil {\n                log.Printf(\"could not set user_action_count: %v\", err)\n            }\n            if err := actx.State().Set(\"temp:last_operation_status\", \"success from tool\"); err != nil {\n                log.Printf(\"could not set temp:last_operation_status: %v\", err)\n            }\n            fmt.Println(\"Tool: Updated state via agent.CallbackContext.\")\n            return struct{}{}\n        },\n    )\n    if err != nil {\n        log.Fatalf(\"Failed to create tool: %v\", err)\n    }\n\n    // Define an agent that uses the tool\n    modelTool, err := gemini.NewModel(ctx, modelID, nil)\n    if err != nil {\n        log.Fatalf(\"Failed to create Gemini model for tool agent: %v\", err)\n    }\n    toolAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"ToolAgent\",\n        Model:       modelTool,\n        Instruction: \"Use the update_action_count tool.\",\n        Tools:       []tool.Tool{updateActionCountTool},\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create tool agent: %v\", err)\n    }\n\n    r, err := runner.New(runner.Config{\n        AppName:        appName,\n        Agent:          agent.Agent(toolAgent),\n        SessionService: sessionService,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create runner: %v\", err)\n    }\n\n    // Run the agent to trigger the tool\n    userMessage := genai.NewContentFromText(\"Please update the action count.\", \"user\")\n    for _, err := range r.Run(ctx, userID, sessionID, userMessage, agent.RunConfig{}) {\n        if err != nil {\n            log.Printf(\"Agent Error: %v\", err)\n        }\n    }\n\n    // Check the updated state\n    resp, err := sessionService.Get(ctx, &session.GetRequest{AppName: appName, UserID: userID, SessionID: sessionID})\n    if err != nil {\n        log.Fatalf(\"Failed to get session: %v\", err)\n    }\n    actionCount, _ := resp.Session.State().Get(\"user_action_count\")\n    fmt.Printf(\"State after tool run: user_action_count = %v\\n\", actionCount)\n}"}, {"language": "text", "code": "// In an agent callback or tool method\nimport com.google.adk.agents.CallbackContext; // or ToolContext\n// ... other imports ...\n\npublic class MyAgentCallbacks {\n    public void onAfterAgent(CallbackContext callbackContext) {\n        // Update existing state\n        Integer count = (Integer) callbackContext.state().getOrDefault(\"user_action_count\", 0);\n        callbackContext.state().put(\"user_action_count\", count + 1);\n\n        // Add new state\n        callbackContext.state().put(\"temp:last_operation_status\", \"success\");\n\n        // State changes are automatically part of the event's state_delta\n        // ... rest of callback logic ...\n    }\n}"}]}, {"heading_path": ["\u26a0\ufe0f A Warning About Direct State Modification\u00b6"], "text": "\u26a0\ufe0f A Warning About Direct State Modification \u00b6 Avoid directly modifying the session.state collection (dictionary/Map) on a Session object that was obtained directly from the SessionService (e.g., via session_service.get_session() or session_service.create_session() ) outside of the managed lifecycle of an agent invocation (i.e., not through a CallbackContext or ToolContext ). For example, code like retrieved_session = await session_service.get_session(...); retrieved_session.state['key'] = value is problematic. State modifications within callbacks or tools using CallbackContext.state or ToolContext.state are the correct way to ensure changes are tracked, as these context objects handle the necessary integration with the event system. Why direct modification (outside of contexts) is strongly discouraged: Bypasses Event History: The change isn't recorded as an Event , losing auditability. Breaks Persistence: Changes made this way will likely NOT be saved by DatabaseSessionService or VertexAiSessionService . They rely on append_event to trigger saving. Not Thread-Safe: Can lead to race conditions and lost updates. Ignores Timestamps/Logic: Doesn't update last_update_time or trigger related event logic. Recommendation: Stick to updating state via output_key , EventActions.state_delta (when manually creating events), or by modifying the state property of CallbackContext or ToolContext objects when within their respective scopes. These methods ensure reliable, trackable, and persistent state management. Use direct access to session.state (from a SessionService -retrieved session) only for reading state. ", "code_blocks": []}, {"heading_path": ["Best Practices for State Design Recap\u00b6"], "text": "Best Practices for State Design Recap \u00b6 Minimalism: Store only essential, dynamic data. Serialization: Use basic, serializable types. Descriptive Keys & Prefixes: Use clear names and appropriate prefixes ( user: , app: , temp: , or none). Shallow Structures: Avoid deep nesting where possible. Standard Update Flow: Rely on append_event . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:35.712128", "source_type": "adk-docs"}
{"doc_id": "2d4631c548b48aa2974057de33052f33e5aa0cc8c0c532565f312a26c7398016", "url": "https://google.github.io/adk-docs/sessions/memory", "title": "Memory - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Memory: Long-Term Knowledge with MemoryService\u00b6"], "text": "Memory: Long-Term Knowledge with MemoryService \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.2.0 We've seen how Session tracks the history ( events ) and temporary data ( state ) for a single, ongoing conversation . But what if an agent needs to recall information from past conversations? This is where the concept of Long-Term Knowledge and the MemoryService come into play. Think of it this way: Session / State : Like your short-term memory during one specific chat. Long-Term Knowledge ( MemoryService ) : Like a searchable archive or knowledge library the agent can consult, potentially containing information from many past chats or other sources. ", "code_blocks": []}, {"heading_path": ["The MemoryService Role\u00b6"], "text": "The MemoryService Role \u00b6 The BaseMemoryService defines the interface for managing this searchable, long-term knowledge store. Its primary responsibilities are: Ingesting Information ( add_session_to_memory ): Taking the contents of a (usually completed) Session and adding relevant information to the long-term knowledge store. Searching Information ( search_memory ): Allowing an agent (typically via a Tool ) to query the knowledge store and retrieve relevant snippets or context based on a search query. ", "code_blocks": []}, {"heading_path": ["Choosing the Right Memory Service\u00b6"], "text": "Choosing the Right Memory Service \u00b6 The ADK offers two distinct MemoryService implementations, each tailored to different use cases. Use the table below to decide which is the best fit for your agent. Feature InMemoryMemoryService VertexAiMemoryBankService Persistence None (data is lost on restart) Yes (Managed by Vertex AI) Primary Use Case Prototyping, local development, and simple testing. Building meaningful, evolving memories from user conversations. Memory Extraction Stores full conversation Extracts meaningful information from conversations and consolidates it with existing memories (powered by LLM) Search Capability Basic keyword matching. Advanced semantic search. Setup Complexity None. It's the default. Low. Requires an Agent Engine instance in Vertex AI. Dependencies None. Google Cloud Project, Vertex AI API When to use it When you want to search across multiple sessions\u2019 chat histories for prototyping. When you want your agent to remember and learn from past interactions. ", "code_blocks": []}, {"heading_path": ["In-Memory Memory\u00b6"], "text": "In-Memory Memory \u00b6 The InMemoryMemoryService stores session information in the application's memory and performs basic keyword matching for searches. It requires no setup and is best for prototyping and simple testing scenarios where persistence isn't required. Python Go from google.adk.memory import InMemoryMemoryService memory_service = InMemoryMemoryService () import ( \"google.golang.org/adk/memory\" \"google.golang.org/adk/session\" ) // Services must be shared across runners to share state and memory. sessionService := session . InMemoryService () memoryService := memory . InMemoryService () Example: Adding and Searching Memory This example demonstrates the basic flow using the InMemoryMemoryService for simplicity. Python Go import asyncio from google.adk.agents import LlmAgent from google.adk.sessions import InMemorySessionService , Session from google.adk.memory import InMemoryMemoryService # Import MemoryService from google.adk.runners import Runner from google.adk.tools import load_memory # Tool to query memory from google.genai.types import Content , Part # --- Constants --- APP_NAME = \"memory_example_app\" USER_ID = \"mem_user\" MODEL = \"gemini-2.0-flash\" # Use a valid model # --- Agent Definitions --- # Agent 1: Simple agent to capture information info_capture_agent = LlmAgent ( model = MODEL , name = \"InfoCaptureAgent\" , instruction = \"Acknowledge the user's statement.\" , ) # Agent 2: Agent that can use memory memory_recall_agent = LlmAgent ( model = MODEL , name = \"MemoryRecallAgent\" , instruction = \"Answer the user's question. Use the 'load_memory' tool \" \"if the answer might be in past conversations.\" , tools = [ load_memory ] # Give the agent the tool ) # --- Services --- # Services must be shared across runners to share state and memory session_service = InMemorySessionService () memory_service = InMemoryMemoryService () # Use in-memory for demo async def run_scenario (): # --- Scenario --- # Turn 1: Capture some information in a session print ( \"--- Turn 1: Capturing Information ---\" ) runner1 = Runner ( # Start with the info capture agent agent = info_capture_agent , app_name = APP_NAME , session_service = session_service , memory_service = memory_service # Provide the memory service to the Runner ) session1_id = \"session_info\" await runner1 . session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = session1_id ) user_input1 = Content ( parts = [ Part ( text = \"My favorite project is Project Alpha.\" )], role = \"user\" ) # Run the agent final_response_text = \"(No final response)\" async for event in runner1 . run_async ( user_id = USER_ID , session_id = session1_id , new_message = user_input1 ): if event . is_final_response () and event . content and event . content . parts : final_response_text = event . content . parts [ 0 ] . text print ( f \"Agent 1 Response: { final_response_text } \" ) # Get the completed session completed_session1 = await runner1 . session_service . get_session ( app_name = APP_NAME , user_id = USER_ID , session_id = session1_id ) # Add this session's content to the Memory Service print ( \" \\n --- Adding Session 1 to Memory ---\" ) await memory_service . add_session_to_memory ( completed_session1 ) print ( \"Session added to memory.\" ) # Turn 2: Recall the information in a new session print ( \" \\n --- Turn 2: Recalling Information ---\" ) runner2 = Runner ( # Use the second agent, which has the memory tool agent = memory_recall_agent , app_name = APP_NAME , session_service = session_service , # Reuse the same service memory_service = memory_service # Reuse the same service ) session2_id = \"session_recall\" await runner2 . session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = session2_id ) user_input2 = Content ( parts = [ Part ( text = \"What is my favorite project?\" )], role = \"user\" ) # Run the second agent final_response_text_2 = \"(No final response)\" async for event in runner2 . run_async ( user_id = USER_ID , session_id = session2_id , new_message = user_input2 ): if event . is_final_response () and event . content and event . content . parts : final_response_text_2 = event . content . parts [ 0 ] . text print ( f \"Agent 2 Response: { final_response_text_2 } \" ) # To run this example, you can use the following snippet: # asyncio.run(run_scenario()) # await run_scenario() import ( \"context\" \"fmt\" \"log\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/memory\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) const ( appName = \"go_memory_example_app\" userID = \"go_mem_user\" modelID = \"gemini-2.5-pro\" ) // Args defines the input structure for the memory search tool. type Args struct { Query string `json:\"query\" jsonschema:\"The query to search for in the memory.\"` } // Result defines the output structure for the memory search tool. type Result struct { Results [] string `json:\"results\"` } // memorySearchToolFunc is the implementation of the memory search tool. // This function demonstrates accessing memory via tool.Context. func memorySearchToolFunc ( tctx tool . Context , args Args ) Result { fmt . Printf ( \"Tool: Searching memory for query: '%s'\\n\" , args . Query ) // The SearchMemory function is available on the context. searchResults , err := tctx . SearchMemory ( context . Background (), args . Query ) if err != nil { log . Printf ( \"Error searching memory: %v\" , err ) return Result { Results : [] string { \"Error searching memory.\" }} } var results [] string for _ , res := range searchResults . Memories { if res . Content != nil { results = append ( results , textParts ( res . Content ) ... ) } } return Result { Results : results } } // Define a tool that can search memory. var memorySearchTool = must ( functiontool . New [ Args , Result ]( functiontool . Config { Name : \"search_past_conversations\" , Description : \"Searches past conversations for relevant information.\" , }, memorySearchToolFunc , )) // This example demonstrates how to use the MemoryService in the Go ADK. // It covers two main scenarios: // 1. Adding a completed session to memory and recalling it in a new session. // 2. Searching memory from within a custom tool using the tool.Context. func main () { ctx := context . Background () // --- Services --- // Services must be shared across runners to share state and memory. sessionService := session . InMemoryService () memoryService := memory . InMemoryService () // Use in-memory for this demo. // --- Scenario 1: Capture information in one session --- fmt . Println ( \"--- Turn 1: Capturing Information ---\" ) infoCaptureAgent := must ( llmagent . New ( llmagent . Config { Name : \"InfoCaptureAgent\" , Model : must ( gemini . NewModel ( ctx , modelID , nil )), Instruction : \"Acknowledge the user's statement.\" , })) runner1 := must ( runner . New ( runner . Config { AppName : appName , Agent : infoCaptureAgent , SessionService : sessionService , MemoryService : memoryService , // Provide the memory service to the Runner })) session1ID := \"session_info\" must ( sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , SessionID : session1ID })) userInput1 := genai . NewContentFromText ( \"My favorite project is Project Alpha.\" , \"user\" ) var finalResponseText string for event , err := range runner1 . Run ( ctx , userID , session1ID , userInput1 , agent . RunConfig {}) { if err != nil { log . Printf ( \"Agent 1 Error: %v\" , err ) continue } if event . Content != nil && ! event . LLMResponse . Partial { finalResponseText = strings . Join ( textParts ( event . LLMResponse . Content ), \"\" ) } } fmt . Printf ( \"Agent 1 Response: %s\\n\" , finalResponseText ) // Add the completed session to the Memory Service fmt . Println ( \"\\n--- Adding Session 1 to Memory ---\" ) resp , err := sessionService . Get ( ctx , & session . GetRequest { AppName : appName , UserID : userID , SessionID : session1ID }) if err != nil { log . Fatalf ( \"Failed to get completed session: %v\" , err ) } if err := memoryService . AddSession ( ctx , resp . Session ); err != nil { log . Fatalf ( \"Failed to add session to memory: %v\" , err ) } fmt . Println ( \"Session added to memory.\" ) // --- Scenario 2: Recall the information in a new session using a tool --- fmt . Println ( \"\\n--- Turn 2: Recalling Information ---\" ) memoryRecallAgent := must ( llmagent . New ( llmagent . Config { Name : \"MemoryRecallAgent\" , Model : must ( gemini . NewModel ( ctx , modelID , nil )), Instruction : \"Answer the user's question. Use the 'search_past_conversations' tool if the answer might be in past conversations.\" , Tools : [] tool . Tool { memorySearchTool }, // Give the agent the tool })) runner2 := must ( runner . New ( runner . Config { Agent : memoryRecallAgent , AppName : appName , SessionService : sessionService , MemoryService : memoryService , })) session2ID := \"session_recall\" must ( sessionService . Create ( ctx , & session . CreateRequest { AppName : appName , UserID : userID , SessionID : session2ID })) userInput2 := genai . NewContentFromText ( \"What is my favorite project?\" , \"user\" ) var finalResponseText2 string for event , err := range runner2 . Run ( ctx , userID , session2ID , userInput2 , agent . RunConfig {}) { if err != nil { log . Printf ( \"Agent 2 Error: %v\" , err ) continue } if event . Content != nil && ! event . LLMResponse . Partial { finalResponseText2 = strings . Join ( textParts ( event . LLMResponse . Content ), \"\" ) } } fmt . Printf ( \"Agent 2 Response: %s\\n\" , finalResponseText2 ) } ", "code_blocks": [{"language": "text", "code": "from google.adk.memory import InMemoryMemoryService\nmemory_service = InMemoryMemoryService()"}, {"language": "text", "code": "import (\n  \"google.golang.org/adk/memory\"\n  \"google.golang.org/adk/session\"\n)\n\n// Services must be shared across runners to share state and memory.\nsessionService := session.InMemoryService()\nmemoryService := memory.InMemoryService()"}, {"language": "text", "code": "import asyncio\nfrom google.adk.agents import LlmAgent\nfrom google.adk.sessions import InMemorySessionService, Session\nfrom google.adk.memory import InMemoryMemoryService # Import MemoryService\nfrom google.adk.runners import Runner\nfrom google.adk.tools import load_memory # Tool to query memory\nfrom google.genai.types import Content, Part\n\n# --- Constants ---\nAPP_NAME = \"memory_example_app\"\nUSER_ID = \"mem_user\"\nMODEL = \"gemini-2.0-flash\" # Use a valid model\n\n# --- Agent Definitions ---\n# Agent 1: Simple agent to capture information\ninfo_capture_agent = LlmAgent(\n    model=MODEL,\n    name=\"InfoCaptureAgent\",\n    instruction=\"Acknowledge the user's statement.\",\n)\n\n# Agent 2: Agent that can use memory\nmemory_recall_agent = LlmAgent(\n    model=MODEL,\n    name=\"MemoryRecallAgent\",\n    instruction=\"Answer the user's question. Use the 'load_memory' tool \"\n                \"if the answer might be in past conversations.\",\n    tools=[load_memory] # Give the agent the tool\n)\n\n# --- Services ---\n# Services must be shared across runners to share state and memory\nsession_service = InMemorySessionService()\nmemory_service = InMemoryMemoryService() # Use in-memory for demo\n\nasync def run_scenario():\n    # --- Scenario ---\n\n    # Turn 1: Capture some information in a session\n    print(\"--- Turn 1: Capturing Information ---\")\n    runner1 = Runner(\n        # Start with the info capture agent\n        agent=info_capture_agent,\n        app_name=APP_NAME,\n        session_service=session_service,\n        memory_service=memory_service # Provide the memory service to the Runner\n    )\n    session1_id = \"session_info\"\n    await runner1.session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session1_id)\n    user_input1 = Content(parts=[Part(text=\"My favorite project is Project Alpha.\")], role=\"user\")\n\n    # Run the agent\n    final_response_text = \"(No final response)\"\n    async for event in runner1.run_async(user_id=USER_ID, session_id=session1_id, new_message=user_input1):\n        if event.is_final_response() and event.content and event.content.parts:\n            final_response_text = event.content.parts[0].text\n    print(f\"Agent 1 Response: {final_response_text}\")\n\n    # Get the completed session\n    completed_session1 = await runner1.session_service.get_session(app_name=APP_NAME, user_id=USER_ID, session_id=session1_id)\n\n    # Add this session's content to the Memory Service\n    print(\"\\n--- Adding Session 1 to Memory ---\")\n    await memory_service.add_session_to_memory(completed_session1)\n    print(\"Session added to memory.\")\n\n    # Turn 2: Recall the information in a new session\n    print(\"\\n--- Turn 2: Recalling Information ---\")\n    runner2 = Runner(\n        # Use the second agent, which has the memory tool\n        agent=memory_recall_agent,\n        app_name=APP_NAME,\n        session_service=session_service, # Reuse the same service\n        memory_service=memory_service   # Reuse the same service\n    )\n    session2_id = \"session_recall\"\n    await runner2.session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session2_id)\n    user_input2 = Content(parts=[Part(text=\"What is my favorite project?\")], role=\"user\")\n\n    # Run the second agent\n    final_response_text_2 = \"(No final response)\"\n    async for event in runner2.run_async(user_id=USER_ID, session_id=session2_id, new_message=user_input2):\n        if event.is_final_response() and event.content and event.content.parts:\n            final_response_text_2 = event.content.parts[0].text\n    print(f\"Agent 2 Response: {final_response_text_2}\")\n\n# To run this example, you can use the following snippet:\n# asyncio.run(run_scenario())\n\n# await run_scenario()"}, {"language": "text", "code": "import (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/memory\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\nconst (\n    appName = \"go_memory_example_app\"\n    userID  = \"go_mem_user\"\n    modelID = \"gemini-2.5-pro\"\n)\n\n// Args defines the input structure for the memory search tool.\ntype Args struct {\n    Query string `json:\"query\" jsonschema:\"The query to search for in the memory.\"`\n}\n\n// Result defines the output structure for the memory search tool.\ntype Result struct {\n    Results []string `json:\"results\"`\n}\n\n\n// memorySearchToolFunc is the implementation of the memory search tool.\n// This function demonstrates accessing memory via tool.Context.\nfunc memorySearchToolFunc(tctx tool.Context, args Args) Result {\n    fmt.Printf(\"Tool: Searching memory for query: '%s'\\n\", args.Query)\n    // The SearchMemory function is available on the context.\n    searchResults, err := tctx.SearchMemory(context.Background(), args.Query)\n    if err != nil {\n        log.Printf(\"Error searching memory: %v\", err)\n        return Result{Results: []string{\"Error searching memory.\"}}\n    }\n\n    var results []string\n    for _, res := range searchResults.Memories {\n        if res.Content != nil {\n            results = append(results, textParts(res.Content)...)\n        }\n    }\n    return Result{Results: results}\n}\n\n// Define a tool that can search memory.\nvar memorySearchTool = must(functiontool.New[Args, Result](\n    functiontool.Config{\n        Name:        \"search_past_conversations\",\n        Description: \"Searches past conversations for relevant information.\",\n    },\n    memorySearchToolFunc,\n))\n\n\n// This example demonstrates how to use the MemoryService in the Go ADK.\n// It covers two main scenarios:\n// 1. Adding a completed session to memory and recalling it in a new session.\n// 2. Searching memory from within a custom tool using the tool.Context.\nfunc main() {\n    ctx := context.Background()\n\n    // --- Services ---\n    // Services must be shared across runners to share state and memory.\n    sessionService := session.InMemoryService()\n    memoryService := memory.InMemoryService() // Use in-memory for this demo.\n\n    // --- Scenario 1: Capture information in one session ---\n    fmt.Println(\"--- Turn 1: Capturing Information ---\")\n    infoCaptureAgent := must(llmagent.New(llmagent.Config{\n        Name:        \"InfoCaptureAgent\",\n        Model:       must(gemini.NewModel(ctx, modelID, nil)),\n        Instruction: \"Acknowledge the user's statement.\",\n    }))\n\n    runner1 := must(runner.New(runner.Config{\n        AppName:        appName,\n        Agent:          infoCaptureAgent,\n        SessionService: sessionService,\n        MemoryService:  memoryService, // Provide the memory service to the Runner\n    }))\n\n    session1ID := \"session_info\"\n    must(sessionService.Create(ctx, &session.CreateRequest{AppName: appName, UserID: userID, SessionID: session1ID}))\n\n    userInput1 := genai.NewContentFromText(\"My favorite project is Project Alpha.\", \"user\")\n    var finalResponseText string\n    for event, err := range runner1.Run(ctx, userID, session1ID, userInput1, agent.RunConfig{}) {\n        if err != nil {\n            log.Printf(\"Agent 1 Error: %v\", err)\n            continue\n        }\n        if event.Content != nil && !event.LLMResponse.Partial {\n            finalResponseText = strings.Join(textParts(event.LLMResponse.Content), \"\")\n        }\n    }\n    fmt.Printf(\"Agent 1 Response: %s\\n\", finalResponseText)\n\n    // Add the completed session to the Memory Service\n    fmt.Println(\"\\n--- Adding Session 1 to Memory ---\")\n    resp, err := sessionService.Get(ctx, &session.GetRequest{AppName: appName, UserID: userID, SessionID: session1ID})\n    if err != nil {\n        log.Fatalf(\"Failed to get completed session: %v\", err)\n    }\n    if err := memoryService.AddSession(ctx, resp.Session); err != nil {\n        log.Fatalf(\"Failed to add session to memory: %v\", err)\n    }\n    fmt.Println(\"Session added to memory.\")\n\n    // --- Scenario 2: Recall the information in a new session using a tool ---\n    fmt.Println(\"\\n--- Turn 2: Recalling Information ---\")\n\n    memoryRecallAgent := must(llmagent.New(llmagent.Config{\n        Name:        \"MemoryRecallAgent\",\n        Model:       must(gemini.NewModel(ctx, modelID, nil)),\n        Instruction: \"Answer the user's question. Use the 'search_past_conversations' tool if the answer might be in past conversations.\",\n        Tools:       []tool.Tool{memorySearchTool}, // Give the agent the tool\n    }))\n\n    runner2 := must(runner.New(runner.Config{\n        Agent:          memoryRecallAgent,\n        AppName:        appName,\n        SessionService: sessionService,\n        MemoryService:  memoryService,\n    }))\n\n    session2ID := \"session_recall\"\n    must(sessionService.Create(ctx, &session.CreateRequest{AppName: appName, UserID: userID, SessionID: session2ID}))\n    userInput2 := genai.NewContentFromText(\"What is my favorite project?\", \"user\")\n\n    var finalResponseText2 string\n    for event, err := range runner2.Run(ctx, userID, session2ID, userInput2, agent.RunConfig{}) {\n        if err != nil {\n            log.Printf(\"Agent 2 Error: %v\", err)\n            continue\n        }\n        if event.Content != nil && !event.LLMResponse.Partial {\n            finalResponseText2 = strings.Join(textParts(event.LLMResponse.Content), \"\")\n        }\n    }\n    fmt.Printf(\"Agent 2 Response: %s\\n\", finalResponseText2)\n}"}]}, {"heading_path": ["Searching Memory Within a Tool\u00b6"], "text": "Searching Memory Within a Tool \u00b6 You can also search memory from within a custom tool by using the tool.Context . Go // memorySearchToolFunc is the implementation of the memory search tool. // This function demonstrates accessing memory via tool.Context. func memorySearchToolFunc ( tctx tool . Context , args Args ) Result { fmt . Printf ( \"Tool: Searching memory for query: '%s'\\n\" , args . Query ) // The SearchMemory function is available on the context. searchResults , err := tctx . SearchMemory ( context . Background (), args . Query ) if err != nil { log . Printf ( \"Error searching memory: %v\" , err ) return Result { Results : [] string { \"Error searching memory.\" }} } var results [] string for _ , res := range searchResults . Memories { if res . Content != nil { results = append ( results , textParts ( res . Content ) ... ) } } return Result { Results : results } } // Define a tool that can search memory. var memorySearchTool = must ( functiontool . New [ Args , Result ]( functiontool . Config { Name : \"search_past_conversations\" , Description : \"Searches past conversations for relevant information.\" , }, memorySearchToolFunc , )) ", "code_blocks": [{"language": "text", "code": "// memorySearchToolFunc is the implementation of the memory search tool.\n// This function demonstrates accessing memory via tool.Context.\nfunc memorySearchToolFunc(tctx tool.Context, args Args) Result {\n    fmt.Printf(\"Tool: Searching memory for query: '%s'\\n\", args.Query)\n    // The SearchMemory function is available on the context.\n    searchResults, err := tctx.SearchMemory(context.Background(), args.Query)\n    if err != nil {\n        log.Printf(\"Error searching memory: %v\", err)\n        return Result{Results: []string{\"Error searching memory.\"}}\n    }\n\n    var results []string\n    for _, res := range searchResults.Memories {\n        if res.Content != nil {\n            results = append(results, textParts(res.Content)...)\n        }\n    }\n    return Result{Results: results}\n}\n\n// Define a tool that can search memory.\nvar memorySearchTool = must(functiontool.New[Args, Result](\n    functiontool.Config{\n        Name:        \"search_past_conversations\",\n        Description: \"Searches past conversations for relevant information.\",\n    },\n    memorySearchToolFunc,\n))"}]}, {"heading_path": ["Vertex AI Memory Bank\u00b6"], "text": "Vertex AI Memory Bank \u00b6 The VertexAiMemoryBankService connects your agent to Vertex AI Memory Bank , a fully managed Google Cloud service that provides sophisticated, persistent memory capabilities for conversational agents. ", "code_blocks": []}, {"heading_path": ["How It Works\u00b6"], "text": "How It Works \u00b6 The service handles two key operations: Generating Memories: At the end of a conversation, you can send the session's events to the Memory Bank, which intelligently processes and stores the information as \"memories.\" Retrieving Memories: Your agent code can issue a search query against the Memory Bank to retrieve relevant memories from past conversations. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 Before you can use this feature, you must have: A Google Cloud Project: With the Vertex AI API enabled. An Agent Engine: You need to create an Agent Engine in Vertex AI. You do not need to deploy your agent to Agent Engine Runtime to use Memory Bank. This will provide you with the Agent Engine ID required for configuration. Authentication: Ensure your local environment is authenticated to access Google Cloud services. The simplest way is to run: gcloud auth application-default login Environment Variables: The service requires your Google Cloud Project ID and Location. Set them as environment variables: export GOOGLE_CLOUD_PROJECT = \"your-gcp-project-id\" export GOOGLE_CLOUD_LOCATION = \"your-gcp-location\" ", "code_blocks": [{"language": "text", "code": "gcloud auth application-default login"}, {"language": "text", "code": "export GOOGLE_CLOUD_PROJECT=\"your-gcp-project-id\"\nexport GOOGLE_CLOUD_LOCATION=\"your-gcp-location\""}]}, {"heading_path": ["Configuration\u00b6"], "text": "Configuration \u00b6 To connect your agent to the Memory Bank, you use the --memory_service_uri flag when starting the ADK server ( adk web or adk api_server ). The URI must be in the format agentengine://<agent_engine_id> . bash adk web path/to/your/agents_dir --memory_service_uri = \"agentengine://1234567890\" Or, you can configure your agent to use the Memory Bank by manually instantiating the VertexAiMemoryBankService and passing it to the Runner . Python from google.adk.memory import VertexAiMemoryBankService agent_engine_id = agent_engine . api_resource . name . split ( \"/\" )[ - 1 ] memory_service = VertexAiMemoryBankService ( project = \"PROJECT_ID\" , location = \"LOCATION\" , agent_engine_id = agent_engine_id ) runner = adk . Runner ( ... memory_service = memory_service ) ", "code_blocks": [{"language": "text", "code": "adk web path/to/your/agents_dir --memory_service_uri=\"agentengine://1234567890\""}, {"language": "text", "code": "from google.adk.memory import VertexAiMemoryBankService\n\nagent_engine_id = agent_engine.api_resource.name.split(\"/\")[-1]\n\nmemory_service = VertexAiMemoryBankService(\n    project=\"PROJECT_ID\",\n    location=\"LOCATION\",\n    agent_engine_id=agent_engine_id\n)\n\nrunner = adk.Runner(\n    ...\n    memory_service=memory_service\n)"}]}, {"heading_path": ["Using Memory in Your Agent\u00b6"], "text": "Using Memory in Your Agent \u00b6 When a memory service is configured, your agent can use a tool or callback to retrieve memories. ADK includes two pre-built tools for retrieving memories: PreloadMemory : Always retrieve memory at the beginning of each turn (similar to a callback). LoadMemory : Retrieve memory when your agent decides it would be helpful. Example: Python from google.adk.agents import Agent from google.adk.tools.preload_memory_tool import PreloadMemoryTool agent = Agent ( model = MODEL_ID , name = 'weather_sentiment_agent' , instruction = \"...\" , tools = [ PreloadMemoryTool ()] ) To extract memories from your session, you need to call add_session_to_memory . For example, you can automate this via a callback: Python from google import adk async def auto_save_session_to_memory_callback ( callback_context ): await callback_context . _invocation_context . memory_service . add_session_to_memory ( callback_context . _invocation_context . session ) agent = Agent ( model = MODEL , name = \"Generic_QA_Agent\" , instruction = \"Answer the user's questions\" , tools = [ adk . tools . preload_memory_tool . PreloadMemoryTool ()], after_agent_callback = auto_save_session_to_memory_callback , ) ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools.preload_memory_tool import PreloadMemoryTool\n\nagent = Agent(\n    model=MODEL_ID,\n    name='weather_sentiment_agent',\n    instruction=\"...\",\n    tools=[PreloadMemoryTool()]\n)"}, {"language": "text", "code": "from google import adk\n\nasync def auto_save_session_to_memory_callback(callback_context):\n    await callback_context._invocation_context.memory_service.add_session_to_memory(\n        callback_context._invocation_context.session)\n\nagent = Agent(\n    model=MODEL,\n    name=\"Generic_QA_Agent\",\n    instruction=\"Answer the user's questions\",\n    tools=[adk.tools.preload_memory_tool.PreloadMemoryTool()],\n    after_agent_callback=auto_save_session_to_memory_callback,\n)"}]}, {"heading_path": ["Advanced Concepts\u00b6"], "text": "Advanced Concepts \u00b6 ", "code_blocks": []}, {"heading_path": ["How Memory Works in Practice\u00b6"], "text": "How Memory Works in Practice \u00b6 The memory workflow internally involves these steps: Session Interaction: A user interacts with an agent via a Session , managed by a SessionService . Events are added, and state might be updated. Ingestion into Memory: At some point (often when a session is considered complete or has yielded significant information), your application calls memory_service.add_session_to_memory(session) . This extracts relevant information from the session's events and adds it to the long-term knowledge store (in-memory dictionary or Agent Engine Memory Bank). Later Query: In a different (or the same) session, the user might ask a question requiring past context (e.g., \"What did we discuss about project X last week?\"). Agent Uses Memory Tool: An agent equipped with a memory-retrieval tool (like the built-in load_memory tool) recognizes the need for past context. It calls the tool, providing a search query (e.g., \"discussion project X last week\"). Search Execution: The tool internally calls memory_service.search_memory(app_name, user_id, query) . Results Returned: The MemoryService searches its store (using keyword matching or semantic search) and returns relevant snippets as a SearchMemoryResponse containing a list of MemoryResult objects (each potentially holding events from a relevant past session). Agent Uses Results: The tool returns these results to the agent, usually as part of the context or function response. The agent can then use this retrieved information to formulate its final answer to the user. ", "code_blocks": []}, {"heading_path": ["Can an agent have access to more than one memory service?\u00b6"], "text": "Can an agent have access to more than one memory service? \u00b6 Through Standard Configuration: No. The framework ( adk web , adk api_server ) is designed to be configured with one single memory service at a time via the --memory_service_uri flag. This single service is then provided to the agent and accessed through the built-in self.search_memory() method. From a configuration standpoint, you can only choose one backend ( InMemory , VertexAiMemoryBankService ) for all agents served by that process. Within Your Agent's Code: Yes, absolutely. There is nothing preventing you from manually importing and instantiating another memory service directly inside your agent's code. This allows you to access multiple memory sources within a single agent turn. For example, your agent could use the framework-configured InMemoryMemoryService to recall conversational history, and also manually instantiate a VertexAiMemoryBankService to look up information in a technical manual. ", "code_blocks": []}, {"heading_path": ["Example: Using Two Memory Services\u00b6"], "text": "Example: Using Two Memory Services \u00b6 Here\u2019s how you could implement that in your agent's code: Python from google.adk.agents import Agent from google.adk.memory import InMemoryMemoryService , VertexAiMemoryBankService from google.genai import types class MultiMemoryAgent ( Agent ): def __init__ ( self , ** kwargs ): super () . __init__ ( ** kwargs ) self . memory_service = InMemoryMemoryService () # Manually instantiate a second memory service for document lookups self . vertexai_memorybank_service = VertexAiMemoryBankService ( project = \"PROJECT_ID\" , location = \"LOCATION\" , agent_engine_id = \"AGENT_ENGINE_ID\" ) async def run ( self , request : types . Content , ** kwargs ) -> types . Content : user_query = request . parts [ 0 ] . text # 1. Search conversational history using the framework-provided memory #    (This would be InMemoryMemoryService if configured) conversation_context = await self . memory_service . search_memory ( query = user_query ) # 2. Search the document knowledge base using the manually created service document_context = await self . vertexai_memorybank_service . search_memory ( query = user_query ) # Combine the context from both sources to generate a better response prompt = \"From our past conversations, I remember: \\n \" prompt += f \" { conversation_context . memories } \\n\\n \" prompt += \"From the technical manuals, I found: \\n \" prompt += f \" { document_context . memories } \\n\\n \" prompt += f \"Based on all this, here is my answer to ' { user_query } ':\" return await self . llm . generate_content_async ( prompt ) Back to top ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.memory import InMemoryMemoryService, VertexAiMemoryBankService\nfrom google.genai import types\n\nclass MultiMemoryAgent(Agent):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n        self.memory_service = InMemoryMemoryService()\n        # Manually instantiate a second memory service for document lookups\n        self.vertexai_memorybank_service = VertexAiMemoryBankService(\n            project=\"PROJECT_ID\",\n            location=\"LOCATION\",\n            agent_engine_id=\"AGENT_ENGINE_ID\"\n        )\n\n    async def run(self, request: types.Content, **kwargs) -> types.Content:\n        user_query = request.parts[0].text\n\n        # 1. Search conversational history using the framework-provided memory\n        #    (This would be InMemoryMemoryService if configured)\n        conversation_context = await self.memory_service.search_memory(query=user_query)\n\n        # 2. Search the document knowledge base using the manually created service\n        document_context = await self.vertexai_memorybank_service.search_memory(query=user_query)\n\n        # Combine the context from both sources to generate a better response\n        prompt = \"From our past conversations, I remember:\\n\"\n        prompt += f\"{conversation_context.memories}\\n\\n\"\n        prompt += \"From the technical manuals, I found:\\n\"\n        prompt += f\"{document_context.memories}\\n\\n\"\n        prompt += f\"Based on all this, here is my answer to '{user_query}':\"\n\n        return await self.llm.generate_content_async(prompt)"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:36.258698", "source_type": "adk-docs"}
{"doc_id": "f6745efec37b8fe24104b727fa01f437127f505d7e5f586be8e5b23fac885635", "url": "https://google.github.io/adk-docs/sessions/express-mode", "title": "Vertex AI Express Mode - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Vertex AI Express Mode: Using Vertex AI Sessions and Memory\u00b6"], "text": "Vertex AI Express Mode: Using Vertex AI Sessions and Memory \u00b6 Supported in ADK Python v0.1.0 Java v0.1.0 If you are interested in using either the VertexAiSessionService or VertexAiMemoryBankService but you don't have a Google Cloud Project, you can sign up for Vertex AI Express Mode and get access\nfor without cost and try out these services! You can sign up with an eligible gmail account here . For more details about Vertex AI Express mode, see the overview page .\nOnce you sign up, get an API key and you can get started using your local ADK agent with Vertex AI Session and Memory services! Info Vertex AI Express Mode has certain limitations in the free tier. Free Express mode projects are only valid for 90 days and only select services are available to be used with limited quota. For example, the number of Agent Engines is restricted to 10 and deployment to Agent Engine is reserved for the paid tier only. To remove the quota restrictions and use all of Vertex AI's services, add a billing account to your Express Mode project. ", "code_blocks": []}, {"heading_path": ["Create an Agent Engine\u00b6"], "text": "Create an Agent Engine \u00b6 Session objects are children of an AgentEngine . When using Vertex AI Express Mode, we can create an empty AgentEngine parent to manage all of our Session and Memory objects.\nFirst, ensure that your environment variables are set correctly. For example, in Python: agent/.env GOOGLE_GENAI_USE_VERTEXAI=TRUE GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE Next, we can create our Agent Engine instance. You can use the Vertex AI SDK. Vertex AI SDK Import Vertex AI SDK. import vertexai from vertexai import agent_engines Initialize the Vertex AI Client with your API key and create an agent engine instance. # Create Agent Engine with Gen AI SDK client = vertexai . Client ( api_key = \"YOUR_API_KEY\" , ) agent_engine = client . agent_engines . create ( config = { \"display_name\" : \"Demo Agent Engine\" , \"description\" : \"Agent Engine for Session and Memory\" , }) Replace YOUR_AGENT_ENGINE_DISPLAY_NAME and YOUR_AGENT_ENGINE_DESCRIPTION with your use case. Get the Agent Engine name and ID from the response to use with Memories and Sessions. APP_ID = agent_engine . api_resource . name . split ( '/' )[ - 1 ] ", "code_blocks": [{"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=TRUE\nGOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE"}, {"language": "text", "code": "import vertexai\nfrom vertexai import agent_engines"}, {"language": "text", "code": "# Create Agent Engine with Gen AI SDK\nclient = vertexai.Client(\n  api_key=\"YOUR_API_KEY\",\n)\n\nagent_engine = client.agent_engines.create(\n  config={\n    \"display_name\": \"Demo Agent Engine\",\n    \"description\": \"Agent Engine for Session and Memory\",\n  })"}, {"language": "text", "code": "APP_ID = agent_engine.api_resource.name.split('/')[-1]"}]}, {"heading_path": ["Managing Sessions with a VertexAiSessionService\u00b6"], "text": "Managing Sessions with a VertexAiSessionService \u00b6 VertexAiSessionService is compatible with Vertex AI Express mode API Keys. We can \ninstead initialize the session object without any project or location. # Requires: pip install google-adk[vertexai] # Plus environment variable setup: # GOOGLE_GENAI_USE_VERTEXAI=TRUE # GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE from google.adk.sessions import VertexAiSessionService # The app_name used with this service should be the Reasoning Engine ID or name APP_ID = \"your-reasoning-engine-id\" # Project and location are not required when initializing with Vertex Express Mode session_service = VertexAiSessionService ( agent_engine_id = APP_ID ) # Use REASONING_ENGINE_APP_ID when calling service methods, e.g.: # session = await session_service.create_session(app_name=APP_ID, user_id= ...) Info For Free Express Mode Projects, VertexAiSessionService has the following quota: 10 Create, delete, or update Vertex AI Agent Engine sessions per minute 30 Append event to Vertex AI Agent Engine sessions per minute ", "code_blocks": [{"language": "text", "code": "# Requires: pip install google-adk[vertexai]\n# Plus environment variable setup:\n# GOOGLE_GENAI_USE_VERTEXAI=TRUE\n# GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE\nfrom google.adk.sessions import VertexAiSessionService\n\n# The app_name used with this service should be the Reasoning Engine ID or name\nAPP_ID = \"your-reasoning-engine-id\"\n\n# Project and location are not required when initializing with Vertex Express Mode\nsession_service = VertexAiSessionService(agent_engine_id=APP_ID)\n# Use REASONING_ENGINE_APP_ID when calling service methods, e.g.:\n# session = await session_service.create_session(app_name=APP_ID, user_id= ...)"}]}, {"heading_path": ["Managing Memories with a VertexAiMemoryBankService\u00b6"], "text": "Managing Memories with a VertexAiMemoryBankService \u00b6 VertexAiMemoryBankService is compatible with Vertex AI Express mode API Keys. We can \ninstead initialize the memory object without any project or location. # Requires: pip install google-adk[vertexai] # Plus environment variable setup: # GOOGLE_GENAI_USE_VERTEXAI=TRUE # GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE from google.adk.memory import VertexAiMemoryBankService # The app_name used with this service should be the Reasoning Engine ID or name APP_ID = \"your-reasoning-engine-id\" # Project and location are not required when initializing with Vertex Express Mode memory_service = VertexAiMemoryBankService ( agent_engine_id = APP_ID ) # Generate a memory from that session so the Agent can remember relevant details about the user # memory = await memory_service.add_session_to_memory(session) Info For Free Express Mode Projects, VertexAiMemoryBankService has the following quota: 10 Create, delete, or update Vertex AI Agent Engine memory resources per minute 10 Get, list, or retrieve from Vertex AI Agent Engine Memory Bank per minute ", "code_blocks": [{"language": "text", "code": "# Requires: pip install google-adk[vertexai]\n# Plus environment variable setup:\n# GOOGLE_GENAI_USE_VERTEXAI=TRUE\n# GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_EXPRESS_MODE_API_KEY_HERE\nfrom google.adk.memory import VertexAiMemoryBankService\n\n# The app_name used with this service should be the Reasoning Engine ID or name\nAPP_ID = \"your-reasoning-engine-id\"\n\n# Project and location are not required when initializing with Vertex Express Mode\nmemory_service = VertexAiMemoryBankService(agent_engine_id=APP_ID)\n# Generate a memory from that session so the Agent can remember relevant details about the user\n# memory = await memory_service.add_session_to_memory(session)"}]}, {"heading_path": ["Code Sample: Weather Agent with Session and Memory using Vertex AI Express Mode\u00b6"], "text": "Code Sample: Weather Agent with Session and Memory using Vertex AI Express Mode \u00b6 In this sample, we create a weather agent that utilizes both VertexAiSessionService and VertexAiMemoryBankService for context management, allowing our agent to recall user preferences and conversations! Weather Agent with Session and Memory using Vertex AI Express Mode Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:36.541000", "source_type": "adk-docs"}
{"doc_id": "21fbf3fa806c5d935aefdaf16f84b818d0f5adc6702ab8d5eaace98968dc0f28", "url": "https://google.github.io/adk-docs/callbacks", "title": "Callbacks: Observe, Customize, and Control Agent Behavior - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Callbacks: Observe, Customize, and Control Agent Behavior\u00b6"], "text": "Callbacks: Observe, Customize, and Control Agent Behavior \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 Callbacks are a cornerstone feature of ADK, providing a powerful mechanism to hook into an agent's execution process. They allow you to observe, customize, and even control the agent's behavior at specific, predefined points without modifying the core ADK framework code. What are they? In essence, callbacks are standard functions that you define. You then associate these functions with an agent when you create it. The ADK framework automatically calls your functions at key stages, letting you observe or intervene. Think of it like checkpoints during the agent's process: Before the agent starts its main work on a request, and after it finishes: When you ask an agent to do something (e.g., answer a question), it runs its internal logic to figure out the response. The Before Agent callback executes right before this main work begins for that specific request. The After Agent callback executes right after the agent has finished all its steps for that request and has prepared the final result, but just before the result is returned. This \"main work\" encompasses the agent's entire process for handling that single request. This might involve deciding to call an LLM, actually calling the LLM, deciding to use a tool, using the tool, processing the results, and finally putting together the answer. These callbacks essentially wrap the whole sequence from receiving the input to producing the final output for that one interaction. Before sending a request to, or after receiving a response from, the Large Language Model (LLM): These callbacks ( Before Model , After Model ) allow you to inspect or modify the data going to and coming from the LLM specifically. Before executing a tool (like a Python function or another agent) or after it finishes: Similarly, Before Tool and After Tool callbacks give you control points specifically around the execution of tools invoked by the agent. Why use them? Callbacks unlock significant flexibility and enable advanced agent capabilities: Observe & Debug: Log detailed information at critical steps for monitoring and troubleshooting. Customize & Control: Modify data flowing through the agent (like LLM requests or tool results) or even bypass certain steps entirely based on your logic. Implement Guardrails: Enforce safety rules, validate inputs/outputs, or prevent disallowed operations. Manage State: Read or dynamically update the agent's session state during execution. Integrate & Enhance: Trigger external actions (API calls, notifications) or add features like caching. Tip When implementing security guardrails and policies, use ADK Plugins for\nbetter modularity and flexibility than Callbacks. For more details, see Callbacks and Plugins for Security Guardrails . How are they added: Code Python Go Java from google.adk.agents import LlmAgent from google.adk.agents.callback_context import CallbackContext from google.adk.models import LlmResponse , LlmRequest from typing import Optional # --- Define your callback function --- def my_before_model_logic ( callback_context : CallbackContext , llm_request : LlmRequest ) -> Optional [ LlmResponse ]: print ( f \"Callback running before model call for agent: { callback_context . agent_name } \" ) # ... your custom logic here ... return None # Allow the model call to proceed # --- Register it during Agent creation --- my_agent = LlmAgent ( name = \"MyCallbackAgent\" , model = \"gemini-2.0-flash\" , # Or your desired model instruction = \"Be helpful.\" , # Other agent parameters... before_model_callback = my_before_model_logic # Pass the function here ) package main import ( \"context\" \"fmt\" \"log\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/genai\" ) // onBeforeModel is a callback function that gets triggered before an LLM call. func onBeforeModel ( ctx agent . CallbackContext , req * model . LLMRequest ) ( * model . LLMResponse , error ) { log . Println ( \"--- onBeforeModel Callback Triggered ---\" ) log . Printf ( \"Model Request to be sent: %v\\n\" , req ) // Returning nil allows the default LLM call to proceed. return nil , nil } func runBasicExample () { const ( appName = \"CallbackBasicApp\" userID = \"test_user_123\" ) ctx := context . Background () geminiModel , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } // Register the callback function in the agent configuration. agentCfg := llmagent . Config { Name : \"SimpleAgent\" , Model : geminiModel , BeforeModelCallbacks : [] llmagent . BeforeModelCallback { onBeforeModel }, } simpleAgent , err := llmagent . New ( agentCfg ) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } sessionService := session . InMemoryService () r , err := runner . New ( runner . Config { AppName : appName , Agent : simpleAgent , SessionService : sessionService , }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } import com.google.adk.agents.CallbackContext ; import com.google.adk.agents.Callbacks ; import com.google.adk.agents.LlmAgent ; import com.google.adk.models.LlmRequest ; import java.util.Optional ; public class AgentWithBeforeModelCallback { public static void main ( String [] args ) { // --- Define your callback logic --- Callbacks . BeforeModelCallbackSync myBeforeModelLogic = ( CallbackContext callbackContext , LlmRequest llmRequest ) -> { System . out . println ( \"Callback running before model call for agent: \" + callbackContext . agentName ()); // ... your custom logic here ... // Return Optional.empty() to allow the model call to proceed, // similar to returning None in the Python example. // If you wanted to return a response and skip the model call, // you would return Optional.of(yourLlmResponse). return Optional . empty (); }; // --- Register it during Agent creation --- LlmAgent myAgent = LlmAgent . builder () . name ( \"MyCallbackAgent\" ) . model ( \"gemini-2.0-flash\" ) // Or your desired model . instruction ( \"Be helpful.\" ) // Other agent parameters... . beforeModelCallbackSync ( myBeforeModelLogic ) // Pass the callback implementation here . build (); } } ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import LlmAgent\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.models import LlmResponse, LlmRequest\nfrom typing import Optional\n\n# --- Define your callback function ---\ndef my_before_model_logic(\n    callback_context: CallbackContext, llm_request: LlmRequest\n) -> Optional[LlmResponse]:\n    print(f\"Callback running before model call for agent: {callback_context.agent_name}\")\n    # ... your custom logic here ...\n    return None # Allow the model call to proceed\n\n# --- Register it during Agent creation ---\nmy_agent = LlmAgent(\n    name=\"MyCallbackAgent\",\n    model=\"gemini-2.0-flash\", # Or your desired model\n    instruction=\"Be helpful.\",\n    # Other agent parameters...\n    before_model_callback=my_before_model_logic # Pass the function here\n)"}, {"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/genai\"\n)\n\n\n\n// onBeforeModel is a callback function that gets triggered before an LLM call.\nfunc onBeforeModel(ctx agent.CallbackContext, req *model.LLMRequest) (*model.LLMResponse, error) {\n    log.Println(\"--- onBeforeModel Callback Triggered ---\")\n    log.Printf(\"Model Request to be sent: %v\\n\", req)\n    // Returning nil allows the default LLM call to proceed.\n    return nil, nil\n}\n\nfunc runBasicExample() {\n    const (\n        appName = \"CallbackBasicApp\"\n        userID  = \"test_user_123\"\n    )\n    ctx := context.Background()\n    geminiModel, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"Failed to create model: %v\", err)\n    }\n\n    // Register the callback function in the agent configuration.\n    agentCfg := llmagent.Config{\n        Name:                 \"SimpleAgent\",\n        Model:                geminiModel,\n        BeforeModelCallbacks: []llmagent.BeforeModelCallback{onBeforeModel},\n    }\n    simpleAgent, err := llmagent.New(agentCfg)\n    if err != nil {\n        log.Fatalf(\"Failed to create agent: %v\", err)\n    }\n\n    sessionService := session.InMemoryService()\n    r, err := runner.New(runner.Config{\n        AppName:        appName,\n        Agent:          simpleAgent,\n        SessionService: sessionService,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create runner: %v\", err)\n    }"}, {"language": "text", "code": "import com.google.adk.agents.CallbackContext;\nimport com.google.adk.agents.Callbacks;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.models.LlmRequest;\nimport java.util.Optional;\n\npublic class AgentWithBeforeModelCallback {\n\n  public static void main(String[] args) {\n    // --- Define your callback logic ---\n    Callbacks.BeforeModelCallbackSync myBeforeModelLogic =\n        (CallbackContext callbackContext, LlmRequest llmRequest) -> {\n          System.out.println(\n              \"Callback running before model call for agent: \" + callbackContext.agentName());\n          // ... your custom logic here ...\n\n          // Return Optional.empty() to allow the model call to proceed,\n          // similar to returning None in the Python example.\n          // If you wanted to return a response and skip the model call,\n          // you would return Optional.of(yourLlmResponse).\n          return Optional.empty();\n        };\n\n    // --- Register it during Agent creation ---\n    LlmAgent myAgent =\n        LlmAgent.builder()\n            .name(\"MyCallbackAgent\")\n            .model(\"gemini-2.0-flash\") // Or your desired model\n            .instruction(\"Be helpful.\")\n            // Other agent parameters...\n            .beforeModelCallbackSync(myBeforeModelLogic) // Pass the callback implementation here\n            .build();\n  }\n}"}]}, {"heading_path": ["The Callback Mechanism: Interception and Control\u00b6"], "text": "The Callback Mechanism: Interception and Control \u00b6 When the ADK framework encounters a point where a callback can run (e.g., just before calling the LLM), it checks if you provided a corresponding callback function for that agent. If you did, the framework executes your function. Context is Key: Your callback function isn't called in isolation. The framework provides special context objects ( CallbackContext or ToolContext ) as arguments. These objects contain vital information about the current state of the agent's execution, including the invocation details, session state, and potentially references to services like artifacts or memory. You use these context objects to understand the situation and interact with the framework. (See the dedicated \"Context Objects\" section for full details). Controlling the Flow (The Core Mechanism): The most powerful aspect of callbacks lies in how their return value influences the agent's subsequent actions. This is how you intercept and control the execution flow: return None (Allow Default Behavior): The specific return type can vary depending on the language. In Java, the equivalent return type is Optional.empty() . Refer to the API documentation for language specific guidance. This is the standard way to signal that your callback has finished its work (e.g., logging, inspection, minor modifications to mutable input arguments like llm_request ) and that the ADK agent should proceed with its normal operation . For before_* callbacks ( before_agent , before_model , before_tool ), returning None means the next step in the sequence (running the agent logic, calling the LLM, executing the tool) will occur. For after_* callbacks ( after_agent , after_model , after_tool ), returning None means the result just produced by the preceding step (the agent's output, the LLM's response, the tool's result) will be used as is. return <Specific Object> (Override Default Behavior): Returning a specific type of object (instead of None ) is how you override the ADK agent's default behavior. The framework will use the object you return and skip the step that would normally follow or replace the result that was just generated. before_agent_callback \u2192 types.Content : Skips the agent's main execution logic ( _run_async_impl / _run_live_impl ). The returned Content object is immediately treated as the agent's final output for this turn. Useful for handling simple requests directly or enforcing access control. before_model_callback \u2192 LlmResponse : Skips the call to the external Large Language Model. The returned LlmResponse object is processed as if it were the actual response from the LLM. Ideal for implementing input guardrails, prompt validation, or serving cached responses. before_tool_callback \u2192 dict or Map : Skips the execution of the actual tool function (or sub-agent). The returned dict is used as the result of the tool call, which is then typically passed back to the LLM. Perfect for validating tool arguments, applying policy restrictions, or returning mocked/cached tool results. after_agent_callback \u2192 types.Content : Replaces the Content that the agent's run logic just produced. after_model_callback \u2192 LlmResponse : Replaces the LlmResponse received from the LLM. Useful for sanitizing outputs, adding standard disclaimers, or modifying the LLM's response structure. after_tool_callback \u2192 dict or Map : Replaces the dict result returned by the tool. Allows for post-processing or standardization of tool outputs before they are sent back to the LLM. Conceptual Code Example (Guardrail): This example demonstrates the common pattern for a guardrail using before_model_callback . Code Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.agents import LlmAgent from google.adk.agents.callback_context import CallbackContext from google.adk.models import LlmResponse , LlmRequest from google.adk.runners import Runner from typing import Optional from google.genai import types from google.adk.sessions import InMemorySessionService GEMINI_2_FLASH = \"gemini-2.0-flash\" # --- Define the Callback Function --- def simple_before_model_modifier ( callback_context : CallbackContext , llm_request : LlmRequest ) -> Optional [ LlmResponse ]: \"\"\"Inspects/modifies the LLM request or skips the call.\"\"\" agent_name = callback_context . agent_name print ( f \"[Callback] Before model call for agent: { agent_name } \" ) # Inspect the last user message in the request contents last_user_message = \"\" if llm_request . contents and llm_request . contents [ - 1 ] . role == 'user' : if llm_request . contents [ - 1 ] . parts : last_user_message = llm_request . contents [ - 1 ] . parts [ 0 ] . text print ( f \"[Callback] Inspecting last user message: ' { last_user_message } '\" ) # --- Modification Example --- # Add a prefix to the system instruction original_instruction = llm_request . config . system_instruction or types . Content ( role = \"system\" , parts = []) prefix = \"[Modified by Callback] \" # Ensure system_instruction is Content and parts list exists if not isinstance ( original_instruction , types . Content ): # Handle case where it might be a string (though config expects Content) original_instruction = types . Content ( role = \"system\" , parts = [ types . Part ( text = str ( original_instruction ))]) if not original_instruction . parts : original_instruction . parts . append ( types . Part ( text = \"\" )) # Add an empty part if none exist # Modify the text of the first part modified_text = prefix + ( original_instruction . parts [ 0 ] . text or \"\" ) original_instruction . parts [ 0 ] . text = modified_text llm_request . config . system_instruction = original_instruction print ( f \"[Callback] Modified system instruction to: ' { modified_text } '\" ) # --- Skip Example --- # Check if the last user message contains \"BLOCK\" if \"BLOCK\" in last_user_message . upper (): print ( \"[Callback] 'BLOCK' keyword found. Skipping LLM call.\" ) # Return an LlmResponse to skip the actual LLM call return LlmResponse ( content = types . Content ( role = \"model\" , parts = [ types . Part ( text = \"LLM call was blocked by before_model_callback.\" )], ) ) else : print ( \"[Callback] Proceeding with LLM call.\" ) # Return None to allow the (modified) request to go to the LLM return None # Create LlmAgent and Assign Callback my_llm_agent = LlmAgent ( name = \"ModelCallbackAgent\" , model = GEMINI_2_FLASH , instruction = \"You are a helpful assistant.\" , # Base instruction description = \"An LLM agent demonstrating before_model_callback\" , before_model_callback = simple_before_model_modifier # Assign the function here ) APP_NAME = \"guardrail_app\" USER_ID = \"user_1\" SESSION_ID = \"session_001\" # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = my_llm_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) async for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response: \" , final_response ) # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"write a joke on BLOCK\" ) package main import ( \"context\" \"fmt\" \"log\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/genai\" ) // onBeforeModelGuardrail is a callback that inspects the LLM request. // If it contains a forbidden topic, it blocks the request and returns a // predefined response. Otherwise, it allows the request to proceed. func onBeforeModelGuardrail ( ctx agent . CallbackContext , req * model . LLMRequest ) ( * model . LLMResponse , error ) { log . Println ( \"--- onBeforeModelGuardrail Callback Triggered ---\" ) // Inspect the request content for forbidden topics. for _ , content := range req . Contents { for _ , part := range content . Parts { if strings . Contains ( part . Text , \"finance\" ) { log . Println ( \"Forbidden topic 'finance' detected. Blocking LLM call.\" ) // By returning a non-nil response, we override the default behavior // and prevent the actual LLM call. return & model . LLMResponse { Content : & genai . Content { Parts : [] * genai . Part {{ Text : \"I'm sorry, but I cannot discuss financial topics.\" }}, Role : \"model\" , }, }, nil } } } log . Println ( \"No forbidden topics found. Allowing LLM call to proceed.\" ) // Returning nil allows the default LLM call to proceed. return nil , nil } func runGuardrailExample () { const ( appName = \"GuardrailApp\" userID = \"test_user_456\" ) ctx := context . Background () geminiModel , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } agentCfg := llmagent . Config { Name : \"ChatAgent\" , Model : geminiModel , BeforeModelCallbacks : [] llmagent . BeforeModelCallback { onBeforeModelGuardrail }, } chatAgent , err := llmagent . New ( agentCfg ) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } sessionService := session . InMemoryService () r , err := runner . New ( runner . Config { AppName : appName , Agent : chatAgent , SessionService : sessionService , }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } import com.google.adk.agents.CallbackContext ; import com.google.adk.agents.LlmAgent ; import com.google.adk.events.Event ; import com.google.adk.models.LlmRequest ; import com.google.adk.models.LlmResponse ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.genai.types.Content ; import com.google.genai.types.GenerateContentConfig ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import java.util.ArrayList ; import java.util.List ; import java.util.Optional ; import java.util.stream.Collectors ; public class BeforeModelGuardrailExample { private static final String MODEL_ID = \"gemini-2.0-flash\" ; private static final String APP_NAME = \"guardrail_app\" ; private static final String USER_ID = \"user_1\" ; public static void main ( String [] args ) { BeforeModelGuardrailExample example = new BeforeModelGuardrailExample (); example . defineAgentAndRun ( \"Tell me about quantum computing. This is a test.\" ); } // --- Define your callback logic --- // Looks for the word \"BLOCK\" in the user prompt and blocks the call to LLM if found. // Otherwise the LLM call proceeds as usual. public Optional < LlmResponse > simpleBeforeModelModifier ( CallbackContext callbackContext , LlmRequest llmRequest ) { System . out . println ( \"[Callback] Before model call for agent: \" + callbackContext . agentName ()); // Inspect the last user message in the request contents String lastUserMessageText = \"\" ; List < Content > requestContents = llmRequest . contents (); if ( requestContents != null && ! requestContents . isEmpty ()) { Content lastContent = requestContents . get ( requestContents . size () - 1 ); if ( lastContent . role (). isPresent () && \"user\" . equals ( lastContent . role (). get ())) { lastUserMessageText = lastContent . parts (). orElse ( List . of ()). stream () . flatMap ( part -> part . text (). stream ()) . collect ( Collectors . joining ( \" \" )); // Concatenate text from all parts } } System . out . println ( \"[Callback] Inspecting last user message: '\" + lastUserMessageText + \"'\" ); String prefix = \"[Modified by Callback] \" ; GenerateContentConfig currentConfig = llmRequest . config (). orElse ( GenerateContentConfig . builder (). build ()); Optional < Content > optOriginalSystemInstruction = currentConfig . systemInstruction (); Content conceptualModifiedSystemInstruction ; if ( optOriginalSystemInstruction . isPresent ()) { Content originalSystemInstruction = optOriginalSystemInstruction . get (); List < Part > originalParts = new ArrayList <> ( originalSystemInstruction . parts (). orElse ( List . of ())); String originalText = \"\" ; if ( ! originalParts . isEmpty ()) { Part firstPart = originalParts . get ( 0 ); if ( firstPart . text (). isPresent ()) { originalText = firstPart . text (). get (); } originalParts . set ( 0 , Part . fromText ( prefix + originalText )); } else { originalParts . add ( Part . fromText ( prefix )); } conceptualModifiedSystemInstruction = originalSystemInstruction . toBuilder (). parts ( originalParts ). build (); } else { conceptualModifiedSystemInstruction = Content . builder () . role ( \"system\" ) . parts ( List . of ( Part . fromText ( prefix ))) . build (); } // This demonstrates building a new LlmRequest with the modified config. llmRequest = llmRequest . toBuilder () . config ( currentConfig . toBuilder () . systemInstruction ( conceptualModifiedSystemInstruction ) . build ()) . build (); System . out . println ( \"[Callback] Conceptually modified system instruction is: '\" + llmRequest . config (). get (). systemInstruction (). get (). parts (). get (). get ( 0 ). text (). get ()); // --- Skip Example --- // Check if the last user message contains \"BLOCK\" if ( lastUserMessageText . toUpperCase (). contains ( \"BLOCK\" )) { System . out . println ( \"[Callback] 'BLOCK' keyword found. Skipping LLM call.\" ); LlmResponse skipResponse = LlmResponse . builder () . content ( Content . builder () . role ( \"model\" ) . parts ( List . of ( Part . builder () . text ( \"LLM call was blocked by before_model_callback.\" ) . build ())) . build ()) . build (); return Optional . of ( skipResponse ); } System . out . println ( \"[Callback] Proceeding with LLM call.\" ); // Return Optional.empty() to allow the (modified) request to go to the LLM return Optional . empty (); } public void defineAgentAndRun ( String prompt ) { // --- Create LlmAgent and Assign Callback --- LlmAgent myLlmAgent = LlmAgent . builder () . name ( \"ModelCallbackAgent\" ) . model ( MODEL_ID ) . instruction ( \"You are a helpful assistant.\" ) // Base instruction . description ( \"An LLM agent demonstrating before_model_callback\" ) . beforeModelCallbackSync ( this :: simpleBeforeModelModifier ) // Assign the callback here . build (); // Session and Runner InMemoryRunner runner = new InMemoryRunner ( myLlmAgent , APP_NAME ); // InMemoryRunner automatically creates a session service. Create a session using the service Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( prompt )); // Run the agent Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } } By understanding this mechanism of returning None versus returning specific objects, you can precisely control the agent's execution path, making callbacks an essential tool for building sophisticated and reliable agents with ADK. Back to top ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.models import LlmResponse, LlmRequest\nfrom google.adk.runners import Runner\nfrom typing import Optional\nfrom google.genai import types \nfrom google.adk.sessions import InMemorySessionService\n\nGEMINI_2_FLASH=\"gemini-2.0-flash\"\n\n# --- Define the Callback Function ---\ndef simple_before_model_modifier(\n    callback_context: CallbackContext, llm_request: LlmRequest\n) -> Optional[LlmResponse]:\n    \"\"\"Inspects/modifies the LLM request or skips the call.\"\"\"\n    agent_name = callback_context.agent_name\n    print(f\"[Callback] Before model call for agent: {agent_name}\")\n\n    # Inspect the last user message in the request contents\n    last_user_message = \"\"\n    if llm_request.contents and llm_request.contents[-1].role == 'user':\n         if llm_request.contents[-1].parts:\n            last_user_message = llm_request.contents[-1].parts[0].text\n    print(f\"[Callback] Inspecting last user message: '{last_user_message}'\")\n\n    # --- Modification Example ---\n    # Add a prefix to the system instruction\n    original_instruction = llm_request.config.system_instruction or types.Content(role=\"system\", parts=[])\n    prefix = \"[Modified by Callback] \"\n    # Ensure system_instruction is Content and parts list exists\n    if not isinstance(original_instruction, types.Content):\n         # Handle case where it might be a string (though config expects Content)\n         original_instruction = types.Content(role=\"system\", parts=[types.Part(text=str(original_instruction))])\n    if not original_instruction.parts:\n        original_instruction.parts.append(types.Part(text=\"\")) # Add an empty part if none exist\n\n    # Modify the text of the first part\n    modified_text = prefix + (original_instruction.parts[0].text or \"\")\n    original_instruction.parts[0].text = modified_text\n    llm_request.config.system_instruction = original_instruction\n    print(f\"[Callback] Modified system instruction to: '{modified_text}'\")\n\n    # --- Skip Example ---\n    # Check if the last user message contains \"BLOCK\"\n    if \"BLOCK\" in last_user_message.upper():\n        print(\"[Callback] 'BLOCK' keyword found. Skipping LLM call.\")\n        # Return an LlmResponse to skip the actual LLM call\n        return LlmResponse(\n            content=types.Content(\n                role=\"model\",\n                parts=[types.Part(text=\"LLM call was blocked by before_model_callback.\")],\n            )\n        )\n    else:\n        print(\"[Callback] Proceeding with LLM call.\")\n        # Return None to allow the (modified) request to go to the LLM\n        return None\n\n\n# Create LlmAgent and Assign Callback\nmy_llm_agent = LlmAgent(\n        name=\"ModelCallbackAgent\",\n        model=GEMINI_2_FLASH,\n        instruction=\"You are a helpful assistant.\", # Base instruction\n        description=\"An LLM agent demonstrating before_model_callback\",\n        before_model_callback=simple_before_model_modifier # Assign the function here\n)\n\nAPP_NAME = \"guardrail_app\"\nUSER_ID = \"user_1\"\nSESSION_ID = \"session_001\"\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=my_llm_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n\n# Agent Interaction\nasync def call_agent_async(query):\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    async for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"Agent Response: \", final_response)\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"write a joke on BLOCK\")"}, {"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/genai\"\n)\n\n\n\n// onBeforeModelGuardrail is a callback that inspects the LLM request.\n// If it contains a forbidden topic, it blocks the request and returns a\n// predefined response. Otherwise, it allows the request to proceed.\nfunc onBeforeModelGuardrail(ctx agent.CallbackContext, req *model.LLMRequest) (*model.LLMResponse, error) {\n    log.Println(\"--- onBeforeModelGuardrail Callback Triggered ---\")\n\n    // Inspect the request content for forbidden topics.\n    for _, content := range req.Contents {\n        for _, part := range content.Parts {\n            if strings.Contains(part.Text, \"finance\") {\n                log.Println(\"Forbidden topic 'finance' detected. Blocking LLM call.\")\n                // By returning a non-nil response, we override the default behavior\n                // and prevent the actual LLM call.\n                return &model.LLMResponse{\n                    Content: &genai.Content{\n                        Parts: []*genai.Part{{Text: \"I'm sorry, but I cannot discuss financial topics.\"}},\n                        Role:  \"model\",\n                    },\n                }, nil\n            }\n        }\n    }\n\n    log.Println(\"No forbidden topics found. Allowing LLM call to proceed.\")\n    // Returning nil allows the default LLM call to proceed.\n    return nil, nil\n}\n\nfunc runGuardrailExample() {\n    const (\n        appName = \"GuardrailApp\"\n        userID  = \"test_user_456\"\n    )\n    ctx := context.Background()\n    geminiModel, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"Failed to create model: %v\", err)\n    }\n\n    agentCfg := llmagent.Config{\n        Name:                 \"ChatAgent\",\n        Model:                geminiModel,\n        BeforeModelCallbacks: []llmagent.BeforeModelCallback{onBeforeModelGuardrail},\n    }\n    chatAgent, err := llmagent.New(agentCfg)\n    if err != nil {\n        log.Fatalf(\"Failed to create agent: %v\", err)\n    }\n\n    sessionService := session.InMemoryService()\n    r, err := runner.New(runner.Config{\n        AppName:        appName,\n        Agent:          chatAgent,\n        SessionService: sessionService,\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create runner: %v\", err)\n    }"}, {"language": "text", "code": "import com.google.adk.agents.CallbackContext;\nimport com.google.adk.agents.LlmAgent;\nimport com.google.adk.events.Event;\nimport com.google.adk.models.LlmRequest;\nimport com.google.adk.models.LlmResponse;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.GenerateContentConfig;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Optional;\nimport java.util.stream.Collectors;\n\npublic class BeforeModelGuardrailExample {\n\n  private static final String MODEL_ID = \"gemini-2.0-flash\";\n  private static final String APP_NAME = \"guardrail_app\";\n  private static final String USER_ID = \"user_1\";\n\n  public static void main(String[] args) {\n    BeforeModelGuardrailExample example = new BeforeModelGuardrailExample();\n    example.defineAgentAndRun(\"Tell me about quantum computing. This is a test.\");\n  }\n\n  // --- Define your callback logic ---\n  // Looks for the word \"BLOCK\" in the user prompt and blocks the call to LLM if found.\n  // Otherwise the LLM call proceeds as usual.\n  public Optional<LlmResponse> simpleBeforeModelModifier(\n      CallbackContext callbackContext, LlmRequest llmRequest) {\n    System.out.println(\"[Callback] Before model call for agent: \" + callbackContext.agentName());\n\n    // Inspect the last user message in the request contents\n    String lastUserMessageText = \"\";\n    List<Content> requestContents = llmRequest.contents();\n    if (requestContents != null && !requestContents.isEmpty()) {\n      Content lastContent = requestContents.get(requestContents.size() - 1);\n      if (lastContent.role().isPresent() && \"user\".equals(lastContent.role().get())) {\n        lastUserMessageText =\n            lastContent.parts().orElse(List.of()).stream()\n                .flatMap(part -> part.text().stream())\n                .collect(Collectors.joining(\" \")); // Concatenate text from all parts\n      }\n    }\n    System.out.println(\"[Callback] Inspecting last user message: '\" + lastUserMessageText + \"'\");\n\n    String prefix = \"[Modified by Callback] \";\n    GenerateContentConfig currentConfig =\n        llmRequest.config().orElse(GenerateContentConfig.builder().build());\n    Optional<Content> optOriginalSystemInstruction = currentConfig.systemInstruction();\n\n    Content conceptualModifiedSystemInstruction;\n    if (optOriginalSystemInstruction.isPresent()) {\n      Content originalSystemInstruction = optOriginalSystemInstruction.get();\n      List<Part> originalParts =\n          new ArrayList<>(originalSystemInstruction.parts().orElse(List.of()));\n      String originalText = \"\";\n\n      if (!originalParts.isEmpty()) {\n        Part firstPart = originalParts.get(0);\n        if (firstPart.text().isPresent()) {\n          originalText = firstPart.text().get();\n        }\n        originalParts.set(0, Part.fromText(prefix + originalText));\n      } else {\n        originalParts.add(Part.fromText(prefix));\n      }\n      conceptualModifiedSystemInstruction =\n          originalSystemInstruction.toBuilder().parts(originalParts).build();\n    } else {\n      conceptualModifiedSystemInstruction =\n          Content.builder()\n              .role(\"system\")\n              .parts(List.of(Part.fromText(prefix)))\n              .build();\n    }\n\n    // This demonstrates building a new LlmRequest with the modified config.\n    llmRequest =\n        llmRequest.toBuilder()\n            .config(\n                currentConfig.toBuilder()\n                    .systemInstruction(conceptualModifiedSystemInstruction)\n                    .build())\n            .build();\n\n    System.out.println(\n        \"[Callback] Conceptually modified system instruction is: '\"\n            + llmRequest.config().get().systemInstruction().get().parts().get().get(0).text().get());\n\n    // --- Skip Example ---\n    // Check if the last user message contains \"BLOCK\"\n    if (lastUserMessageText.toUpperCase().contains(\"BLOCK\")) {\n      System.out.println(\"[Callback] 'BLOCK' keyword found. Skipping LLM call.\");\n      LlmResponse skipResponse =\n          LlmResponse.builder()\n              .content(\n                  Content.builder()\n                      .role(\"model\")\n                      .parts(\n                          List.of(\n                              Part.builder()\n                                  .text(\"LLM call was blocked by before_model_callback.\")\n                                  .build()))\n                      .build())\n              .build();\n      return Optional.of(skipResponse);\n    }\n    System.out.println(\"[Callback] Proceeding with LLM call.\");\n    // Return Optional.empty() to allow the (modified) request to go to the LLM\n    return Optional.empty();\n  }\n\n  public void defineAgentAndRun(String prompt) {\n    // --- Create LlmAgent and Assign Callback ---\n    LlmAgent myLlmAgent =\n        LlmAgent.builder()\n            .name(\"ModelCallbackAgent\")\n            .model(MODEL_ID)\n            .instruction(\"You are a helpful assistant.\") // Base instruction\n            .description(\"An LLM agent demonstrating before_model_callback\")\n            .beforeModelCallbackSync(this::simpleBeforeModelModifier) // Assign the callback here\n            .build();\n\n    // Session and Runner\n    InMemoryRunner runner = new InMemoryRunner(myLlmAgent, APP_NAME);\n    // InMemoryRunner automatically creates a session service. Create a session using the service\n    Session session = runner.sessionService().createSession(APP_NAME, USER_ID).blockingGet();\n    Content userMessage =\n        Content.fromParts(Part.fromText(prompt));\n\n    // Run the agent\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n    // Stream event response\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n}"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:37.139541", "source_type": "adk-docs"}
{"doc_id": "fd9420dd3d2f3feae3abf7b9f9a919ed77212fb71df7bea1ba7c6e4ac678c61c", "url": "https://google.github.io/adk-docs/callbacks/types-of-callbacks", "title": "Types of callbacks - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Types of Callbacks\u00b6"], "text": "Types of Callbacks \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 The framework provides different types of callbacks that trigger at various stages of an agent's execution. Understanding when each callback fires and what context it receives is key to using them effectively. ", "code_blocks": []}, {"heading_path": ["Agent Lifecycle Callbacks\u00b6"], "text": "Agent Lifecycle Callbacks \u00b6 These callbacks are available on any agent that inherits from BaseAgent (including LlmAgent , SequentialAgent , ParallelAgent , LoopAgent , etc). Note The specific method names or return types may vary slightly by SDK language (e.g., return None in Python, return Optional.empty() or Maybe.empty() in Java). Refer to the language-specific API documentation for details. ", "code_blocks": []}, {"heading_path": ["Before Agent Callback\u00b6"], "text": "Before Agent Callback \u00b6 When: Called immediately before the agent's _run_async_impl (or _run_live_impl ) method is executed. It runs after the agent's InvocationContext is created but before its core logic begins. Purpose: Ideal for setting up resources or state needed only for this specific agent's run, performing validation checks on the session state (callback_context.state) before execution starts, logging the entry point of the agent's activity, or potentially modifying the invocation context before the core logic uses it. Code Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # --- Setup Instructions --- # # 1. Install the ADK package: # !pip install google-adk # # Make sure to restart kernel if using colab/jupyter notebooks # # 2. Set up your Gemini API Key: # #    - Get a key from Google AI Studio: https://aistudio.google.com/app/apikey # #    - Set it as an environment variable: # import os # os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY_HERE\" # <--- REPLACE with your actual key # # Or learn about other authentication methods (like Vertex AI): # # https://google.github.io/adk-docs/agents/models/ # ADK Imports from google.adk.agents import LlmAgent from google.adk.agents.callback_context import CallbackContext from google.adk.runners import InMemoryRunner # Use InMemoryRunner from google.genai import types # For types.Content from typing import Optional # Define the model - Use the specific model name requested GEMINI_2_FLASH = \"gemini-2.0-flash\" # --- 1. Define the Callback Function --- def check_if_agent_should_run ( callback_context : CallbackContext ) -> Optional [ types . Content ]: \"\"\" Logs entry and checks 'skip_llm_agent' in session state. If True, returns Content to skip the agent's execution. If False or not present, returns None to allow execution. \"\"\" agent_name = callback_context . agent_name invocation_id = callback_context . invocation_id current_state = callback_context . state . to_dict () print ( f \" \\n [Callback] Entering agent: { agent_name } (Inv: { invocation_id } )\" ) print ( f \"[Callback] Current State: { current_state } \" ) # Check the condition in session state dictionary if current_state . get ( \"skip_llm_agent\" , False ): print ( f \"[Callback] State condition 'skip_llm_agent=True' met: Skipping agent { agent_name } .\" ) # Return Content to skip the agent's run return types . Content ( parts = [ types . Part ( text = f \"Agent { agent_name } skipped by before_agent_callback due to state.\" )], role = \"model\" # Assign model role to the overriding response ) else : print ( f \"[Callback] State condition not met: Proceeding with agent { agent_name } .\" ) # Return None to allow the LlmAgent's normal execution return None # --- 2. Setup Agent with Callback --- llm_agent_with_before_cb = LlmAgent ( name = \"MyControlledAgent\" , model = GEMINI_2_FLASH , instruction = \"You are a concise assistant.\" , description = \"An LLM agent demonstrating stateful before_agent_callback\" , before_agent_callback = check_if_agent_should_run # Assign the callback ) # --- 3. Setup Runner and Sessions using InMemoryRunner --- async def main (): app_name = \"before_agent_demo\" user_id = \"test_user\" session_id_run = \"session_will_run\" session_id_skip = \"session_will_skip\" # Use InMemoryRunner - it includes InMemorySessionService runner = InMemoryRunner ( agent = llm_agent_with_before_cb , app_name = app_name ) # Get the bundled session service to create sessions session_service = runner . session_service # Create session 1: Agent will run (default empty state) session_service . create_session ( app_name = app_name , user_id = user_id , session_id = session_id_run # No initial state means 'skip_llm_agent' will be False in the callback check ) # Create session 2: Agent will be skipped (state has skip_llm_agent=True) session_service . create_session ( app_name = app_name , user_id = user_id , session_id = session_id_skip , state = { \"skip_llm_agent\" : True } # Set the state flag here ) # --- Scenario 1: Run where callback allows agent execution --- print ( \" \\n \" + \"=\" * 20 + f \" SCENARIO 1: Running Agent on Session ' { session_id_run } ' (Should Proceed) \" + \"=\" * 20 ) async for event in runner . run_async ( user_id = user_id , session_id = session_id_run , new_message = types . Content ( role = \"user\" , parts = [ types . Part ( text = \"Hello, please respond.\" )]) ): # Print final output (either from LLM or callback override) if event . is_final_response () and event . content : print ( f \"Final Output: [ { event . author } ] { event . content . parts [ 0 ] . text . strip () } \" ) elif event . is_error (): print ( f \"Error Event: { event . error_details } \" ) # --- Scenario 2: Run where callback intercepts and skips agent --- print ( \" \\n \" + \"=\" * 20 + f \" SCENARIO 2: Running Agent on Session ' { session_id_skip } ' (Should Skip) \" + \"=\" * 20 ) async for event in runner . run_async ( user_id = user_id , session_id = session_id_skip , new_message = types . Content ( role = \"user\" , parts = [ types . Part ( text = \"This message won't reach the LLM.\" )]) ): # Print final output (either from LLM or callback override) if event . is_final_response () and event . content : print ( f \"Final Output: [ { event . author } ] { event . content . parts [ 0 ] . text . strip () } \" ) elif event . is_error (): print ( f \"Error Event: { event . error_details } \" ) # --- 4. Execute --- # In a Python script: # import asyncio # if __name__ == \"__main__\": #     # Make sure GOOGLE_API_KEY environment variable is set if not using Vertex AI auth #     # Or ensure Application Default Credentials (ADC) are configured for Vertex AI #     asyncio.run(main()) # In a Jupyter Notebook or similar environment: await main () package main import ( \"context\" \"fmt\" \"log\" \"regexp\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) // 1. Define the Callback Function func onBeforeAgent ( ctx agent . CallbackContext ) ( * genai . Content , error ) { agentName := ctx . AgentName () log . Printf ( \"[Callback] Entering agent: %s\" , agentName ) if skip , _ := ctx . State (). Get ( \"skip_llm_agent\" ); skip == true { log . Printf ( \"[Callback] State condition met: Skipping agent %s\" , agentName ) return genai . NewContentFromText ( fmt . Sprintf ( \"Agent %s skipped by before_agent_callback.\" , agentName ), genai . RoleModel , ), nil } log . Printf ( \"[Callback] State condition not met: Running agent %s\" , agentName ) return nil , nil } // 2. Define a function to set up and run the agent with the callback. func runBeforeAgentExample () { ctx := context . Background () geminiModel , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"FATAL: Failed to create model: %v\" , err ) } // 3. Register the callback in the agent configuration. llmCfg := llmagent . Config { Name : \"AgentWithBeforeAgentCallback\" , BeforeAgentCallbacks : [] agent . BeforeAgentCallback { onBeforeAgent }, Model : geminiModel , Instruction : \"You are a concise assistant.\" , } testAgent , err := llmagent . New ( llmCfg ) if err != nil { log . Fatalf ( \"FATAL: Failed to create agent: %v\" , err ) } sessionService := session . InMemoryService () r , err := runner . New ( runner . Config { AppName : appName , Agent : testAgent , SessionService : sessionService }) if err != nil { log . Fatalf ( \"FATAL: Failed to create runner: %v\" , err ) } // 4. Run scenarios to demonstrate the callback's behavior. log . Println ( \"--- SCENARIO 1: Agent should run normally ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_normal\" , nil , \"Hello, world!\" ) log . Println ( \"\\n--- SCENARIO 2: Agent should be skipped ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_skip\" , map [ string ] any { \"skip_llm_agent\" : true }, \"This should be skipped.\" ) } import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.BaseAgent ; import com.google.adk.agents.CallbackContext ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.adk.sessions.State ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import io.reactivex.rxjava3.core.Maybe ; import java.util.Map ; import java.util.concurrent.ConcurrentHashMap ; public class BeforeAgentCallbackExample { private static final String APP_NAME = \"AgentWithBeforeAgentCallback\" ; private static final String USER_ID = \"test_user_456\" ; private static final String SESSION_ID = \"session_id_123\" ; private static final String MODEL_NAME = \"gemini-2.0-flash\" ; public static void main ( String [] args ) { BeforeAgentCallbackExample callbackAgent = new BeforeAgentCallbackExample (); callbackAgent . defineAgent ( \"Write a document about a cat\" ); } // --- 1. Define the Callback Function --- /** * Logs entry and checks 'skip_llm_agent' in session state. If True, returns Content to skip the * agent's execution. If False or not present, returns None to allow execution. */ public Maybe < Content > checkIfAgentShouldRun ( CallbackContext callbackContext ) { String agentName = callbackContext . agentName (); String invocationId = callbackContext . invocationId (); State currentState = callbackContext . state (); System . out . printf ( \"%n[Callback] Entering agent: %s (Inv: %s)%n\" , agentName , invocationId ); System . out . printf ( \"[Callback] Current State: %s%n\" , currentState . entrySet ()); // Check the condition in session state dictionary if ( Boolean . TRUE . equals ( currentState . get ( \"skip_llm_agent\" ))) { System . out . printf ( \"[Callback] State condition 'skip_llm_agent=True' met: Skipping agent %s\" , agentName ); // Return Content to skip the agent's run return Maybe . just ( Content . fromParts ( Part . fromText ( String . format ( \"Agent %s skipped by before_agent_callback due to state.\" , agentName )))); } System . out . printf ( \"[Callback] State condition 'skip_llm_agent=True' NOT met: Running agent %s \\n\" , agentName ); // Return empty response to allow the LlmAgent's normal execution return Maybe . empty (); } public void defineAgent ( String prompt ) { // --- 2. Setup Agent with Callback --- BaseAgent llmAgentWithBeforeCallback = LlmAgent . builder () . model ( MODEL_NAME ) . name ( APP_NAME ) . instruction ( \"You are a concise assistant.\" ) . description ( \"An LLM agent demonstrating stateful before_agent_callback\" ) // You can also use a sync version of this callback \"beforeAgentCallbackSync\" . beforeAgentCallback ( this :: checkIfAgentShouldRun ) . build (); // --- 3. Setup Runner and Sessions using InMemoryRunner --- // Use InMemoryRunner - it includes InMemorySessionService InMemoryRunner runner = new InMemoryRunner ( llmAgentWithBeforeCallback , APP_NAME ); // Scenario 1: Initial state is null, which means 'skip_llm_agent' will be false in the callback // check runAgent ( runner , null , prompt ); // Scenario 2: Agent will be skipped (state has skip_llm_agent=true) runAgent ( runner , new ConcurrentHashMap <> ( Map . of ( \"skip_llm_agent\" , true )), prompt ); } public void runAgent ( InMemoryRunner runner , ConcurrentHashMap < String , Object > initialState , String prompt ) { // InMemoryRunner automatically creates a session service. Create a session using the service. Session session = runner . sessionService () . createSession ( APP_NAME , USER_ID , initialState , SESSION_ID ) . blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( prompt )); // Run the agent Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Print final output (either from LLM or callback override) eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } } Note on the before_agent_callback Example: What it Shows: This example demonstrates the before_agent_callback . This callback runs right before the agent's main processing logic starts for a given request. How it Works: The callback function ( check_if_agent_should_run ) looks at a flag ( skip_llm_agent ) in the session's state. If the flag is True , the callback returns a types.Content object. This tells the ADK framework to skip the agent's main execution entirely and use the callback's returned content as the final response. If the flag is False (or not set), the callback returns None or an empty object. This tells the ADK framework to proceed with the agent's normal execution (calling the LLM in this case). Expected Outcome: You'll see two scenarios: In the session with the skip_llm_agent: True state, the agent's LLM call is bypassed, and the output comes directly from the callback (\"Agent... skipped...\"). In the session without that state flag, the callback allows the agent to run, and you see the actual response from the LLM (e.g., \"Hello!\"). Understanding Callbacks: This highlights how before_ callbacks act as gatekeepers , allowing you to intercept execution before a major step and potentially prevent it based on checks (like state, input validation, permissions). ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# # --- Setup Instructions ---\n# # 1. Install the ADK package:\n# !pip install google-adk\n# # Make sure to restart kernel if using colab/jupyter notebooks\n\n# # 2. Set up your Gemini API Key:\n# #    - Get a key from Google AI Studio: https://aistudio.google.com/app/apikey\n# #    - Set it as an environment variable:\n# import os\n# os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY_HERE\" # <--- REPLACE with your actual key\n# # Or learn about other authentication methods (like Vertex AI):\n# # https://google.github.io/adk-docs/agents/models/\n\n# ADK Imports\nfrom google.adk.agents import LlmAgent\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.runners import InMemoryRunner # Use InMemoryRunner\nfrom google.genai import types # For types.Content\nfrom typing import Optional\n\n# Define the model - Use the specific model name requested\nGEMINI_2_FLASH=\"gemini-2.0-flash\"\n\n# --- 1. Define the Callback Function ---\ndef check_if_agent_should_run(callback_context: CallbackContext) -> Optional[types.Content]:\n    \"\"\"\n    Logs entry and checks 'skip_llm_agent' in session state.\n    If True, returns Content to skip the agent's execution.\n    If False or not present, returns None to allow execution.\n    \"\"\"\n    agent_name = callback_context.agent_name\n    invocation_id = callback_context.invocation_id\n    current_state = callback_context.state.to_dict()\n\n    print(f\"\\n[Callback] Entering agent: {agent_name} (Inv: {invocation_id})\")\n    print(f\"[Callback] Current State: {current_state}\")\n\n    # Check the condition in session state dictionary\n    if current_state.get(\"skip_llm_agent\", False):\n        print(f\"[Callback] State condition 'skip_llm_agent=True' met: Skipping agent {agent_name}.\")\n        # Return Content to skip the agent's run\n        return types.Content(\n            parts=[types.Part(text=f\"Agent {agent_name} skipped by before_agent_callback due to state.\")],\n            role=\"model\" # Assign model role to the overriding response\n        )\n    else:\n        print(f\"[Callback] State condition not met: Proceeding with agent {agent_name}.\")\n        # Return None to allow the LlmAgent's normal execution\n        return None\n\n# --- 2. Setup Agent with Callback ---\nllm_agent_with_before_cb = LlmAgent(\n    name=\"MyControlledAgent\",\n    model=GEMINI_2_FLASH,\n    instruction=\"You are a concise assistant.\",\n    description=\"An LLM agent demonstrating stateful before_agent_callback\",\n    before_agent_callback=check_if_agent_should_run # Assign the callback\n)\n\n# --- 3. Setup Runner and Sessions using InMemoryRunner ---\nasync def main():\n    app_name = \"before_agent_demo\"\n    user_id = \"test_user\"\n    session_id_run = \"session_will_run\"\n    session_id_skip = \"session_will_skip\"\n\n    # Use InMemoryRunner - it includes InMemorySessionService\n    runner = InMemoryRunner(agent=llm_agent_with_before_cb, app_name=app_name)\n    # Get the bundled session service to create sessions\n    session_service = runner.session_service\n\n    # Create session 1: Agent will run (default empty state)\n    session_service.create_session(\n        app_name=app_name,\n        user_id=user_id,\n        session_id=session_id_run\n        # No initial state means 'skip_llm_agent' will be False in the callback check\n    )\n\n    # Create session 2: Agent will be skipped (state has skip_llm_agent=True)\n    session_service.create_session(\n        app_name=app_name,\n        user_id=user_id,\n        session_id=session_id_skip,\n        state={\"skip_llm_agent\": True} # Set the state flag here\n    )\n\n    # --- Scenario 1: Run where callback allows agent execution ---\n    print(\"\\n\" + \"=\"*20 + f\" SCENARIO 1: Running Agent on Session '{session_id_run}' (Should Proceed) \" + \"=\"*20)\n    async for event in runner.run_async(\n        user_id=user_id,\n        session_id=session_id_run,\n        new_message=types.Content(role=\"user\", parts=[types.Part(text=\"Hello, please respond.\")])\n    ):\n        # Print final output (either from LLM or callback override)\n        if event.is_final_response() and event.content:\n            print(f\"Final Output: [{event.author}] {event.content.parts[0].text.strip()}\")\n        elif event.is_error():\n             print(f\"Error Event: {event.error_details}\")\n\n    # --- Scenario 2: Run where callback intercepts and skips agent ---\n    print(\"\\n\" + \"=\"*20 + f\" SCENARIO 2: Running Agent on Session '{session_id_skip}' (Should Skip) \" + \"=\"*20)\n    async for event in runner.run_async(\n        user_id=user_id,\n        session_id=session_id_skip,\n        new_message=types.Content(role=\"user\", parts=[types.Part(text=\"This message won't reach the LLM.\")])\n    ):\n         # Print final output (either from LLM or callback override)\n         if event.is_final_response() and event.content:\n            print(f\"Final Output: [{event.author}] {event.content.parts[0].text.strip()}\")\n         elif event.is_error():\n             print(f\"Error Event: {event.error_details}\")\n\n# --- 4. Execute ---\n# In a Python script:\n# import asyncio\n# if __name__ == \"__main__\":\n#     # Make sure GOOGLE_API_KEY environment variable is set if not using Vertex AI auth\n#     # Or ensure Application Default Credentials (ADC) are configured for Vertex AI\n#     asyncio.run(main())\n\n# In a Jupyter Notebook or similar environment:\nawait main()"}, {"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"regexp\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\n\n\n// 1. Define the Callback Function\nfunc onBeforeAgent(ctx agent.CallbackContext) (*genai.Content, error) {\n    agentName := ctx.AgentName()\n    log.Printf(\"[Callback] Entering agent: %s\", agentName)\n    if skip, _ := ctx.State().Get(\"skip_llm_agent\"); skip == true {\n        log.Printf(\"[Callback] State condition met: Skipping agent %s\", agentName)\n        return genai.NewContentFromText(\n                fmt.Sprintf(\"Agent %s skipped by before_agent_callback.\", agentName),\n                genai.RoleModel,\n            ),\n            nil\n    }\n    log.Printf(\"[Callback] State condition not met: Running agent %s\", agentName)\n    return nil, nil\n}\n\n// 2. Define a function to set up and run the agent with the callback.\nfunc runBeforeAgentExample() {\n    ctx := context.Background()\n    geminiModel, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create model: %v\", err)\n    }\n\n    // 3. Register the callback in the agent configuration.\n    llmCfg := llmagent.Config{\n        Name:                 \"AgentWithBeforeAgentCallback\",\n        BeforeAgentCallbacks: []agent.BeforeAgentCallback{onBeforeAgent},\n        Model:                geminiModel,\n        Instruction:          \"You are a concise assistant.\",\n    }\n    testAgent, err := llmagent.New(llmCfg)\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create agent: %v\", err)\n    }\n\n    sessionService := session.InMemoryService()\n    r, err := runner.New(runner.Config{AppName: appName, Agent: testAgent, SessionService: sessionService})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create runner: %v\", err)\n    }\n\n    // 4. Run scenarios to demonstrate the callback's behavior.\n    log.Println(\"--- SCENARIO 1: Agent should run normally ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_normal\", nil, \"Hello, world!\")\n\n    log.Println(\"\\n--- SCENARIO 2: Agent should be skipped ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_skip\", map[string]any{\"skip_llm_agent\": true}, \"This should be skipped.\")\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.BaseAgent;\nimport com.google.adk.agents.CallbackContext;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.sessions.State;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport io.reactivex.rxjava3.core.Maybe;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\n\npublic class BeforeAgentCallbackExample {\n\n  private static final String APP_NAME = \"AgentWithBeforeAgentCallback\";\n  private static final String USER_ID = \"test_user_456\";\n  private static final String SESSION_ID = \"session_id_123\";\n  private static final String MODEL_NAME = \"gemini-2.0-flash\";\n\n  public static void main(String[] args) {\n    BeforeAgentCallbackExample callbackAgent = new BeforeAgentCallbackExample();\n    callbackAgent.defineAgent(\"Write a document about a cat\");\n  }\n\n  // --- 1. Define the Callback Function ---\n  /**\n   * Logs entry and checks 'skip_llm_agent' in session state. If True, returns Content to skip the\n   * agent's execution. If False or not present, returns None to allow execution.\n   */\n  public Maybe<Content> checkIfAgentShouldRun(CallbackContext callbackContext) {\n    String agentName = callbackContext.agentName();\n    String invocationId = callbackContext.invocationId();\n    State currentState = callbackContext.state();\n\n    System.out.printf(\"%n[Callback] Entering agent: %s (Inv: %s)%n\", agentName, invocationId);\n    System.out.printf(\"[Callback] Current State: %s%n\", currentState.entrySet());\n\n    // Check the condition in session state dictionary\n    if (Boolean.TRUE.equals(currentState.get(\"skip_llm_agent\"))) {\n      System.out.printf(\n          \"[Callback] State condition 'skip_llm_agent=True' met: Skipping agent %s\", agentName);\n      // Return Content to skip the agent's run\n      return Maybe.just(\n          Content.fromParts(\n              Part.fromText(\n                  String.format(\n                      \"Agent %s skipped by before_agent_callback due to state.\", agentName))));\n    }\n\n    System.out.printf(\n        \"[Callback] State condition 'skip_llm_agent=True' NOT met: Running agent %s \\n\", agentName);\n    // Return empty response to allow the LlmAgent's normal execution\n    return Maybe.empty();\n  }\n\n  public void defineAgent(String prompt) {\n    // --- 2. Setup Agent with Callback ---\n    BaseAgent llmAgentWithBeforeCallback =\n        LlmAgent.builder()\n            .model(MODEL_NAME)\n            .name(APP_NAME)\n            .instruction(\"You are a concise assistant.\")\n            .description(\"An LLM agent demonstrating stateful before_agent_callback\")\n            // You can also use a sync version of this callback \"beforeAgentCallbackSync\"\n            .beforeAgentCallback(this::checkIfAgentShouldRun)\n            .build();\n\n    // --- 3. Setup Runner and Sessions using InMemoryRunner ---\n\n    // Use InMemoryRunner - it includes InMemorySessionService\n    InMemoryRunner runner = new InMemoryRunner(llmAgentWithBeforeCallback, APP_NAME);\n    // Scenario 1: Initial state is null, which means 'skip_llm_agent' will be false in the callback\n    // check\n    runAgent(runner, null, prompt);\n    // Scenario 2: Agent will be skipped (state has skip_llm_agent=true)\n    runAgent(runner, new ConcurrentHashMap<>(Map.of(\"skip_llm_agent\", true)), prompt);\n  }\n\n  public void runAgent(InMemoryRunner runner, ConcurrentHashMap<String, Object> initialState, String prompt) {\n    // InMemoryRunner automatically creates a session service. Create a session using the service.\n    Session session =\n        runner\n            .sessionService()\n            .createSession(APP_NAME, USER_ID, initialState, SESSION_ID)\n            .blockingGet();\n    Content userMessage = Content.fromParts(Part.fromText(prompt));\n\n    // Run the agent\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n    // Print final output (either from LLM or callback override)\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n}"}]}, {"heading_path": ["After Agent Callback\u00b6"], "text": "After Agent Callback \u00b6 When: Called immediately after the agent's _run_async_impl (or _run_live_impl ) method successfully completes. It does not run if the agent was skipped due to before_agent_callback returning content or if end_invocation was set during the agent's run. Purpose: Useful for cleanup tasks, post-execution validation, logging the completion of an agent's activity, modifying final state, or augmenting/replacing the agent's final output. Code Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # --- Setup Instructions --- # # 1. Install the ADK package: # !pip install google-adk # # Make sure to restart kernel if using colab/jupyter notebooks # # 2. Set up your Gemini API Key: # #    - Get a key from Google AI Studio: https://aistudio.google.com/app/apikey # #    - Set it as an environment variable: # import os # os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY_HERE\" # <--- REPLACE with your actual key # # Or learn about other authentication methods (like Vertex AI): # # https://google.github.io/adk-docs/agents/models/ # ADK Imports from google.adk.agents import LlmAgent from google.adk.agents.callback_context import CallbackContext from google.adk.runners import InMemoryRunner # Use InMemoryRunner from google.genai import types # For types.Content from typing import Optional # Define the model - Use the specific model name requested GEMINI_2_FLASH = \"gemini-2.0-flash\" # --- 1. Define the Callback Function --- def modify_output_after_agent ( callback_context : CallbackContext ) -> Optional [ types . Content ]: \"\"\" Logs exit from an agent and checks 'add_concluding_note' in session state. If True, returns new Content to *replace* the agent's original output. If False or not present, returns None, allowing the agent's original output to be used. \"\"\" agent_name = callback_context . agent_name invocation_id = callback_context . invocation_id current_state = callback_context . state . to_dict () print ( f \" \\n [Callback] Exiting agent: { agent_name } (Inv: { invocation_id } )\" ) print ( f \"[Callback] Current State: { current_state } \" ) # Example: Check state to decide whether to modify the final output if current_state . get ( \"add_concluding_note\" , False ): print ( f \"[Callback] State condition 'add_concluding_note=True' met: Replacing agent { agent_name } 's output.\" ) # Return Content to *replace* the agent's own output return types . Content ( parts = [ types . Part ( text = f \"Concluding note added by after_agent_callback, replacing original output.\" )], role = \"model\" # Assign model role to the overriding response ) else : print ( f \"[Callback] State condition not met: Using agent { agent_name } 's original output.\" ) # Return None - the agent's output produced just before this callback will be used. return None # --- 2. Setup Agent with Callback --- llm_agent_with_after_cb = LlmAgent ( name = \"MySimpleAgentWithAfter\" , model = GEMINI_2_FLASH , instruction = \"You are a simple agent. Just say 'Processing complete!'\" , description = \"An LLM agent demonstrating after_agent_callback for output modification\" , after_agent_callback = modify_output_after_agent # Assign the callback here ) # --- 3. Setup Runner and Sessions using InMemoryRunner --- async def main (): app_name = \"after_agent_demo\" user_id = \"test_user_after\" session_id_normal = \"session_run_normally\" session_id_modify = \"session_modify_output\" # Use InMemoryRunner - it includes InMemorySessionService runner = InMemoryRunner ( agent = llm_agent_with_after_cb , app_name = app_name ) # Get the bundled session service to create sessions session_service = runner . session_service # Create session 1: Agent output will be used as is (default empty state) session_service . create_session ( app_name = app_name , user_id = user_id , session_id = session_id_normal # No initial state means 'add_concluding_note' will be False in the callback check ) # print(f\"Session '{session_id_normal}' created with default state.\") # Create session 2: Agent output will be replaced by the callback session_service . create_session ( app_name = app_name , user_id = user_id , session_id = session_id_modify , state = { \"add_concluding_note\" : True } # Set the state flag here ) # print(f\"Session '{session_id_modify}' created with state={{'add_concluding_note': True}}.\") # --- Scenario 1: Run where callback allows agent's original output --- print ( \" \\n \" + \"=\" * 20 + f \" SCENARIO 1: Running Agent on Session ' { session_id_normal } ' (Should Use Original Output) \" + \"=\" * 20 ) async for event in runner . run_async ( user_id = user_id , session_id = session_id_normal , new_message = types . Content ( role = \"user\" , parts = [ types . Part ( text = \"Process this please.\" )]) ): # Print final output (either from LLM or callback override) if event . is_final_response () and event . content : print ( f \"Final Output: [ { event . author } ] { event . content . parts [ 0 ] . text . strip () } \" ) elif event . is_error (): print ( f \"Error Event: { event . error_details } \" ) # --- Scenario 2: Run where callback replaces the agent's output --- print ( \" \\n \" + \"=\" * 20 + f \" SCENARIO 2: Running Agent on Session ' { session_id_modify } ' (Should Replace Output) \" + \"=\" * 20 ) async for event in runner . run_async ( user_id = user_id , session_id = session_id_modify , new_message = types . Content ( role = \"user\" , parts = [ types . Part ( text = \"Process this and add note.\" )]) ): # Print final output (either from LLM or callback override) if event . is_final_response () and event . content : print ( f \"Final Output: [ { event . author } ] { event . content . parts [ 0 ] . text . strip () } \" ) elif event . is_error (): print ( f \"Error Event: { event . error_details } \" ) # --- 4. Execute --- # In a Python script: # import asyncio # if __name__ == \"__main__\": #     # Make sure GOOGLE_API_KEY environment variable is set if not using Vertex AI auth #     # Or ensure Application Default Credentials (ADC) are configured for Vertex AI #     asyncio.run(main()) # In a Jupyter Notebook or similar environment: await main () package main import ( \"context\" \"fmt\" \"log\" \"regexp\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) func onAfterAgent ( ctx agent . CallbackContext ) ( * genai . Content , error ) { agentName := ctx . AgentName () invocationID := ctx . InvocationID () state := ctx . State () log . Printf ( \"\\n[Callback] Exiting agent: %s (Inv: %s)\" , agentName , invocationID ) log . Printf ( \"[Callback] Current State: %v\" , state ) if addNote , _ := state . Get ( \"add_concluding_note\" ); addNote == true { log . Printf ( \"[Callback] State condition 'add_concluding_note=True' met: Replacing agent %s's output.\" , agentName ) return genai . NewContentFromText ( \"Concluding note added by after_agent_callback, replacing original output.\" , genai . RoleModel , ), nil } log . Printf ( \"[Callback] State condition not met: Using agent %s's original output.\" , agentName ) return nil , nil } func runAfterAgentExample () { ctx := context . Background () geminiModel , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"FATAL: Failed to create model: %v\" , err ) } llmCfg := llmagent . Config { Name : \"AgentWithAfterAgentCallback\" , AfterAgentCallbacks : [] agent . AfterAgentCallback { onAfterAgent }, Model : geminiModel , Instruction : \"You are a simple agent. Just say 'Processing complete!'\" , } testAgent , err := llmagent . New ( llmCfg ) if err != nil { log . Fatalf ( \"FATAL: Failed to create agent: %v\" , err ) } sessionService := session . InMemoryService () r , err := runner . New ( runner . Config { AppName : appName , Agent : testAgent , SessionService : sessionService }) if err != nil { log . Fatalf ( \"FATAL: Failed to create runner: %v\" , err ) } log . Println ( \"--- SCENARIO 1: Should use original output ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_normal\" , nil , \"Process this.\" ) log . Println ( \"\\n--- SCENARIO 2: Should replace output ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_modify\" , map [ string ] any { \"add_concluding_note\" : true }, \"Process and add note.\" ) } import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.CallbackContext ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.State ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import io.reactivex.rxjava3.core.Maybe ; import java.util.HashMap ; import java.util.List ; import java.util.Map ; import java.util.concurrent.ConcurrentHashMap ; public class AfterAgentCallbackExample { // --- Constants --- private static final String APP_NAME = \"after_agent_demo\" ; private static final String USER_ID = \"test_user_after\" ; private static final String SESSION_ID_NORMAL = \"session_run_normally\" ; private static final String SESSION_ID_MODIFY = \"session_modify_output\" ; private static final String MODEL_NAME = \"gemini-2.0-flash\" ; public static void main ( String [] args ) { AfterAgentCallbackExample demo = new AfterAgentCallbackExample (); demo . defineAgentAndRunScenarios (); } // --- 1. Define the Callback Function --- /** * Log exit from an agent and checks 'add_concluding_note' in session state. If True, returns new * Content to *replace* the agent's original output. If False or not present, returns * Maybe.empty(), allowing the agent's original output to be used. */ public Maybe < Content > modifyOutputAfterAgent ( CallbackContext callbackContext ) { String agentName = callbackContext . agentName (); String invocationId = callbackContext . invocationId (); State currentState = callbackContext . state (); System . out . printf ( \"%n[Callback] Exiting agent: %s (Inv: %s)%n\" , agentName , invocationId ); System . out . printf ( \"[Callback] Current State: %s%n\" , currentState . entrySet ()); Object addNoteFlag = currentState . get ( \"add_concluding_note\" ); // Example: Check state to decide whether to modify the final output if ( Boolean . TRUE . equals ( addNoteFlag )) { System . out . printf ( \"[Callback] State condition 'add_concluding_note=True' met: Replacing agent %s's\" + \" output.%n\" , agentName ); // Return Content to *replace* the agent's own output return Maybe . just ( Content . builder () . parts ( List . of ( Part . fromText ( \"Concluding note added by after_agent_callback, replacing original output.\" ))) . role ( \"model\" ) // Assign model role to the overriding response . build ()); } else { System . out . printf ( \"[Callback] State condition not met: Using agent %s's original output.%n\" , agentName ); // Return None - the agent's output produced just before this callback will be used. return Maybe . empty (); } } // --- 2. Setup Agent with Callback --- public void defineAgentAndRunScenarios () { LlmAgent llmAgentWithAfterCb = LlmAgent . builder () . name ( APP_NAME ) . model ( MODEL_NAME ) . description ( \"An LLM agent demonstrating after_agent_callback for output modification\" ) . instruction ( \"You are a simple agent. Just say 'Processing complete!'\" ) . afterAgentCallback ( this :: modifyOutputAfterAgent ) // Assign the callback here . build (); // --- 3. Setup Runner and Sessions using InMemoryRunner --- // Use InMemoryRunner - it includes InMemorySessionService InMemoryRunner runner = new InMemoryRunner ( llmAgentWithAfterCb , APP_NAME ); // --- Scenario 1: Run where callback allows agent's original output --- System . out . printf ( \"%n%s SCENARIO 1: Running Agent (Should Use Original Output) %s%n\" , \"=\" . repeat ( 20 ), \"=\" . repeat ( 20 )); // No initial state means 'add_concluding_note' will be false in the callback check runScenario ( runner , llmAgentWithAfterCb . name (), // Use agent name for runner's appName consistency SESSION_ID_NORMAL , null , \"Process this please.\" ); // --- Scenario 2: Run where callback replaces the agent's output --- System . out . printf ( \"%n%s SCENARIO 2: Running Agent (Should Replace Output) %s%n\" , \"=\" . repeat ( 20 ), \"=\" . repeat ( 20 )); Map < String , Object > modifyState = new HashMap <> (); modifyState . put ( \"add_concluding_note\" , true ); // Set the state flag here runScenario ( runner , llmAgentWithAfterCb . name (), // Use agent name for runner's appName consistency SESSION_ID_MODIFY , new ConcurrentHashMap <> ( modifyState ), \"Process this and add note.\" ); } // --- 3. Method to Run a Single Scenario --- public void runScenario ( InMemoryRunner runner , String appName , String sessionId , ConcurrentHashMap < String , Object > initialState , String userQuery ) { // Create session using the runner's bundled session service runner . sessionService (). createSession ( appName , USER_ID , initialState , sessionId ). blockingGet (); System . out . printf ( \"Running scenario for session: %s, initial state: %s%n\" , sessionId , initialState ); Content userMessage = Content . builder (). role ( \"user\" ). parts ( List . of ( Part . fromText ( userQuery ))). build (); Flowable < Event > eventStream = runner . runAsync ( USER_ID , sessionId , userMessage ); // Print final output eventStream . blockingForEach ( event -> { if ( event . finalResponse () && event . content (). isPresent ()) { String author = event . author () != null ? event . author () : \"UNKNOWN\" ; String text = event . content () . flatMap ( Content :: parts ) . filter ( parts -> ! parts . isEmpty ()) . map ( parts -> parts . get ( 0 ). text (). orElse ( \"\" ). trim ()) . orElse ( \"[No text in final response]\" ); System . out . printf ( \"Final Output for %s: [%s] %s%n\" , sessionId , author , text ); } else if ( event . errorCode (). isPresent ()) { System . out . printf ( \"Error Event for %s: %s%n\" , sessionId , event . errorMessage (). orElse ( \"Unknown error\" )); } }); } } Note on the after_agent_callback Example: What it Shows: This example demonstrates the after_agent_callback . This callback runs right after the agent's main processing logic has finished and produced its result, but before that result is finalized and returned. How it Works: The callback function ( modify_output_after_agent ) checks a flag ( add_concluding_note ) in the session's state. If the flag is True , the callback returns a new types.Content object. This tells the ADK framework to replace the agent's original output with the content returned by the callback. If the flag is False (or not set), the callback returns None or an empty object. This tells the ADK framework to use the original output generated by the agent. Expected Outcome: You'll see two scenarios: In the session without the add_concluding_note: True state, the callback allows the agent's original output (\"Processing complete!\") to be used. In the session with that state flag, the callback intercepts the agent's original output and replaces it with its own message (\"Concluding note added...\"). Understanding Callbacks: This highlights how after_ callbacks allow post-processing or modification . You can inspect the result of a step (the agent's run) and decide whether to let it pass through, change it, or completely replace it based on your logic. ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# # --- Setup Instructions ---\n# # 1. Install the ADK package:\n# !pip install google-adk\n# # Make sure to restart kernel if using colab/jupyter notebooks\n\n# # 2. Set up your Gemini API Key:\n# #    - Get a key from Google AI Studio: https://aistudio.google.com/app/apikey\n# #    - Set it as an environment variable:\n# import os\n# os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY_HERE\" # <--- REPLACE with your actual key\n# # Or learn about other authentication methods (like Vertex AI):\n# # https://google.github.io/adk-docs/agents/models/\n\n\n# ADK Imports\nfrom google.adk.agents import LlmAgent\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.runners import InMemoryRunner # Use InMemoryRunner\nfrom google.genai import types # For types.Content\nfrom typing import Optional\n\n# Define the model - Use the specific model name requested\nGEMINI_2_FLASH=\"gemini-2.0-flash\"\n\n# --- 1. Define the Callback Function ---\ndef modify_output_after_agent(callback_context: CallbackContext) -> Optional[types.Content]:\n    \"\"\"\n    Logs exit from an agent and checks 'add_concluding_note' in session state.\n    If True, returns new Content to *replace* the agent's original output.\n    If False or not present, returns None, allowing the agent's original output to be used.\n    \"\"\"\n    agent_name = callback_context.agent_name\n    invocation_id = callback_context.invocation_id\n    current_state = callback_context.state.to_dict()\n\n    print(f\"\\n[Callback] Exiting agent: {agent_name} (Inv: {invocation_id})\")\n    print(f\"[Callback] Current State: {current_state}\")\n\n    # Example: Check state to decide whether to modify the final output\n    if current_state.get(\"add_concluding_note\", False):\n        print(f\"[Callback] State condition 'add_concluding_note=True' met: Replacing agent {agent_name}'s output.\")\n        # Return Content to *replace* the agent's own output\n        return types.Content(\n            parts=[types.Part(text=f\"Concluding note added by after_agent_callback, replacing original output.\")],\n            role=\"model\" # Assign model role to the overriding response\n        )\n    else:\n        print(f\"[Callback] State condition not met: Using agent {agent_name}'s original output.\")\n        # Return None - the agent's output produced just before this callback will be used.\n        return None\n\n# --- 2. Setup Agent with Callback ---\nllm_agent_with_after_cb = LlmAgent(\n    name=\"MySimpleAgentWithAfter\",\n    model=GEMINI_2_FLASH,\n    instruction=\"You are a simple agent. Just say 'Processing complete!'\",\n    description=\"An LLM agent demonstrating after_agent_callback for output modification\",\n    after_agent_callback=modify_output_after_agent # Assign the callback here\n)\n\n# --- 3. Setup Runner and Sessions using InMemoryRunner ---\nasync def main():\n    app_name = \"after_agent_demo\"\n    user_id = \"test_user_after\"\n    session_id_normal = \"session_run_normally\"\n    session_id_modify = \"session_modify_output\"\n\n    # Use InMemoryRunner - it includes InMemorySessionService\n    runner = InMemoryRunner(agent=llm_agent_with_after_cb, app_name=app_name)\n    # Get the bundled session service to create sessions\n    session_service = runner.session_service\n\n    # Create session 1: Agent output will be used as is (default empty state)\n    session_service.create_session(\n        app_name=app_name,\n        user_id=user_id,\n        session_id=session_id_normal\n        # No initial state means 'add_concluding_note' will be False in the callback check\n    )\n    # print(f\"Session '{session_id_normal}' created with default state.\")\n\n    # Create session 2: Agent output will be replaced by the callback\n    session_service.create_session(\n        app_name=app_name,\n        user_id=user_id,\n        session_id=session_id_modify,\n        state={\"add_concluding_note\": True} # Set the state flag here\n    )\n    # print(f\"Session '{session_id_modify}' created with state={{'add_concluding_note': True}}.\")\n\n\n    # --- Scenario 1: Run where callback allows agent's original output ---\n    print(\"\\n\" + \"=\"*20 + f\" SCENARIO 1: Running Agent on Session '{session_id_normal}' (Should Use Original Output) \" + \"=\"*20)\n    async for event in runner.run_async(\n        user_id=user_id,\n        session_id=session_id_normal,\n        new_message=types.Content(role=\"user\", parts=[types.Part(text=\"Process this please.\")])\n    ):\n        # Print final output (either from LLM or callback override)\n        if event.is_final_response() and event.content:\n            print(f\"Final Output: [{event.author}] {event.content.parts[0].text.strip()}\")\n        elif event.is_error():\n             print(f\"Error Event: {event.error_details}\")\n\n    # --- Scenario 2: Run where callback replaces the agent's output ---\n    print(\"\\n\" + \"=\"*20 + f\" SCENARIO 2: Running Agent on Session '{session_id_modify}' (Should Replace Output) \" + \"=\"*20)\n    async for event in runner.run_async(\n        user_id=user_id,\n        session_id=session_id_modify,\n        new_message=types.Content(role=\"user\", parts=[types.Part(text=\"Process this and add note.\")])\n    ):\n         # Print final output (either from LLM or callback override)\n         if event.is_final_response() and event.content:\n            print(f\"Final Output: [{event.author}] {event.content.parts[0].text.strip()}\")\n         elif event.is_error():\n             print(f\"Error Event: {event.error_details}\")\n\n# --- 4. Execute ---\n# In a Python script:\n# import asyncio\n# if __name__ == \"__main__\":\n#     # Make sure GOOGLE_API_KEY environment variable is set if not using Vertex AI auth\n#     # Or ensure Application Default Credentials (ADC) are configured for Vertex AI\n#     asyncio.run(main())\n\n# In a Jupyter Notebook or similar environment:\nawait main()"}, {"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"regexp\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\n\n\nfunc onAfterAgent(ctx agent.CallbackContext) (*genai.Content, error) {\n    agentName := ctx.AgentName()\n    invocationID := ctx.InvocationID()\n    state := ctx.State()\n\n    log.Printf(\"\\n[Callback] Exiting agent: %s (Inv: %s)\", agentName, invocationID)\n    log.Printf(\"[Callback] Current State: %v\", state)\n\n    if addNote, _ := state.Get(\"add_concluding_note\"); addNote == true {\n        log.Printf(\"[Callback] State condition 'add_concluding_note=True' met: Replacing agent %s's output.\", agentName)\n        return genai.NewContentFromText(\n            \"Concluding note added by after_agent_callback, replacing original output.\",\n            genai.RoleModel,\n        ), nil\n    }\n\n    log.Printf(\"[Callback] State condition not met: Using agent %s's original output.\", agentName)\n    return nil, nil\n}\n\nfunc runAfterAgentExample() {\n    ctx := context.Background()\n    geminiModel, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create model: %v\", err)\n    }\n\n    llmCfg := llmagent.Config{\n        Name:                \"AgentWithAfterAgentCallback\",\n        AfterAgentCallbacks: []agent.AfterAgentCallback{onAfterAgent},\n        Model:               geminiModel,\n        Instruction:         \"You are a simple agent. Just say 'Processing complete!'\",\n    }\n    testAgent, err := llmagent.New(llmCfg)\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create agent: %v\", err)\n    }\n\n    sessionService := session.InMemoryService()\n    r, err := runner.New(runner.Config{AppName: appName, Agent: testAgent, SessionService: sessionService})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create runner: %v\", err)\n    }\n\n    log.Println(\"--- SCENARIO 1: Should use original output ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_normal\", nil, \"Process this.\")\n\n    log.Println(\"\\n--- SCENARIO 2: Should replace output ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_modify\", map[string]any{\"add_concluding_note\": true}, \"Process and add note.\")\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.CallbackContext;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.State;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport io.reactivex.rxjava3.core.Maybe;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\n\npublic class AfterAgentCallbackExample {\n\n  // --- Constants ---\n  private static final String APP_NAME = \"after_agent_demo\";\n  private static final String USER_ID = \"test_user_after\";\n  private static final String SESSION_ID_NORMAL = \"session_run_normally\";\n  private static final String SESSION_ID_MODIFY = \"session_modify_output\";\n  private static final String MODEL_NAME = \"gemini-2.0-flash\";\n\n  public static void main(String[] args) {\n    AfterAgentCallbackExample demo = new AfterAgentCallbackExample();\n    demo.defineAgentAndRunScenarios();\n  }\n\n  // --- 1. Define the Callback Function ---\n  /**\n   * Log exit from an agent and checks 'add_concluding_note' in session state. If True, returns new\n   * Content to *replace* the agent's original output. If False or not present, returns\n   * Maybe.empty(), allowing the agent's original output to be used.\n   */\n  public Maybe<Content> modifyOutputAfterAgent(CallbackContext callbackContext) {\n    String agentName = callbackContext.agentName();\n    String invocationId = callbackContext.invocationId();\n    State currentState = callbackContext.state();\n\n    System.out.printf(\"%n[Callback] Exiting agent: %s (Inv: %s)%n\", agentName, invocationId);\n    System.out.printf(\"[Callback] Current State: %s%n\", currentState.entrySet());\n\n    Object addNoteFlag = currentState.get(\"add_concluding_note\");\n\n    // Example: Check state to decide whether to modify the final output\n    if (Boolean.TRUE.equals(addNoteFlag)) {\n      System.out.printf(\n          \"[Callback] State condition 'add_concluding_note=True' met: Replacing agent %s's\"\n              + \" output.%n\",\n          agentName);\n\n      // Return Content to *replace* the agent's own output\n      return Maybe.just(\n          Content.builder()\n              .parts(\n                  List.of(\n                      Part.fromText(\n                          \"Concluding note added by after_agent_callback, replacing original output.\")))\n              .role(\"model\") // Assign model role to the overriding response\n              .build());\n\n    } else {\n      System.out.printf(\n          \"[Callback] State condition not met: Using agent %s's original output.%n\", agentName);\n      // Return None - the agent's output produced just before this callback will be used.\n      return Maybe.empty();\n    }\n  }\n\n  // --- 2. Setup Agent with Callback ---\n  public void defineAgentAndRunScenarios() {\n    LlmAgent llmAgentWithAfterCb =\n        LlmAgent.builder()\n            .name(APP_NAME)\n            .model(MODEL_NAME)\n            .description(\"An LLM agent demonstrating after_agent_callback for output modification\")\n            .instruction(\"You are a simple agent. Just say 'Processing complete!'\")\n            .afterAgentCallback(this::modifyOutputAfterAgent) // Assign the callback here\n            .build();\n\n    // --- 3. Setup Runner and Sessions using InMemoryRunner ---\n    // Use InMemoryRunner - it includes InMemorySessionService\n    InMemoryRunner runner = new InMemoryRunner(llmAgentWithAfterCb, APP_NAME);\n\n    // --- Scenario 1: Run where callback allows agent's original output ---\n    System.out.printf(\n        \"%n%s SCENARIO 1: Running Agent (Should Use Original Output) %s%n\",\n        \"=\".repeat(20), \"=\".repeat(20));\n    // No initial state means 'add_concluding_note' will be false in the callback check\n    runScenario(\n        runner,\n        llmAgentWithAfterCb.name(), // Use agent name for runner's appName consistency\n        SESSION_ID_NORMAL,\n        null,\n        \"Process this please.\");\n\n    // --- Scenario 2: Run where callback replaces the agent's output ---\n    System.out.printf(\n        \"%n%s SCENARIO 2: Running Agent (Should Replace Output) %s%n\",\n        \"=\".repeat(20), \"=\".repeat(20));\n    Map<String, Object> modifyState = new HashMap<>();\n    modifyState.put(\"add_concluding_note\", true); // Set the state flag here\n    runScenario(\n        runner,\n        llmAgentWithAfterCb.name(), // Use agent name for runner's appName consistency\n        SESSION_ID_MODIFY,\n        new ConcurrentHashMap<>(modifyState),\n        \"Process this and add note.\");\n  }\n\n  // --- 3. Method to Run a Single Scenario ---\n  public void runScenario(\n      InMemoryRunner runner,\n      String appName,\n      String sessionId,\n      ConcurrentHashMap<String, Object> initialState,\n      String userQuery) {\n\n    // Create session using the runner's bundled session service\n    runner.sessionService().createSession(appName, USER_ID, initialState, sessionId).blockingGet();\n\n    System.out.printf(\n        \"Running scenario for session: %s, initial state: %s%n\", sessionId, initialState);\n    Content userMessage =\n        Content.builder().role(\"user\").parts(List.of(Part.fromText(userQuery))).build();\n\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, sessionId, userMessage);\n\n    // Print final output\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse() && event.content().isPresent()) {\n            String author = event.author() != null ? event.author() : \"UNKNOWN\";\n            String text =\n                event\n                    .content()\n                    .flatMap(Content::parts)\n                    .filter(parts -> !parts.isEmpty())\n                    .map(parts -> parts.get(0).text().orElse(\"\").trim())\n                    .orElse(\"[No text in final response]\");\n            System.out.printf(\"Final Output for %s: [%s] %s%n\", sessionId, author, text);\n          } else if (event.errorCode().isPresent()) {\n            System.out.printf(\n                \"Error Event for %s: %s%n\",\n                sessionId, event.errorMessage().orElse(\"Unknown error\"));\n          }\n        });\n  }\n}"}]}, {"heading_path": ["LLM Interaction Callbacks\u00b6"], "text": "LLM Interaction Callbacks \u00b6 These callbacks are specific to LlmAgent and provide hooks around the interaction with the Large Language Model. ", "code_blocks": []}, {"heading_path": ["Before Model Callback\u00b6"], "text": "Before Model Callback \u00b6 When: Called just before the generate_content_async (or equivalent) request is sent to the LLM within an LlmAgent 's flow. Purpose: Allows inspection and modification of the request going to the LLM. Use cases include adding dynamic instructions, injecting few-shot examples based on state, modifying model config, implementing guardrails (like profanity filters), or implementing request-level caching. Return Value Effect: If the callback returns None (or a Maybe.empty() object in Java), the LLM continues its normal workflow. If the callback returns an LlmResponse object, then the call to the LLM is skipped . The returned LlmResponse is used directly as if it came from the model. This is powerful for implementing guardrails or caching. Code Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.agents import LlmAgent from google.adk.agents.callback_context import CallbackContext from google.adk.models import LlmResponse , LlmRequest from google.adk.runners import Runner from typing import Optional from google.genai import types from google.adk.sessions import InMemorySessionService GEMINI_2_FLASH = \"gemini-2.0-flash\" # --- Define the Callback Function --- def simple_before_model_modifier ( callback_context : CallbackContext , llm_request : LlmRequest ) -> Optional [ LlmResponse ]: \"\"\"Inspects/modifies the LLM request or skips the call.\"\"\" agent_name = callback_context . agent_name print ( f \"[Callback] Before model call for agent: { agent_name } \" ) # Inspect the last user message in the request contents last_user_message = \"\" if llm_request . contents and llm_request . contents [ - 1 ] . role == 'user' : if llm_request . contents [ - 1 ] . parts : last_user_message = llm_request . contents [ - 1 ] . parts [ 0 ] . text print ( f \"[Callback] Inspecting last user message: ' { last_user_message } '\" ) # --- Modification Example --- # Add a prefix to the system instruction original_instruction = llm_request . config . system_instruction or types . Content ( role = \"system\" , parts = []) prefix = \"[Modified by Callback] \" # Ensure system_instruction is Content and parts list exists if not isinstance ( original_instruction , types . Content ): # Handle case where it might be a string (though config expects Content) original_instruction = types . Content ( role = \"system\" , parts = [ types . Part ( text = str ( original_instruction ))]) if not original_instruction . parts : original_instruction . parts . append ( types . Part ( text = \"\" )) # Add an empty part if none exist # Modify the text of the first part modified_text = prefix + ( original_instruction . parts [ 0 ] . text or \"\" ) original_instruction . parts [ 0 ] . text = modified_text llm_request . config . system_instruction = original_instruction print ( f \"[Callback] Modified system instruction to: ' { modified_text } '\" ) # --- Skip Example --- # Check if the last user message contains \"BLOCK\" if \"BLOCK\" in last_user_message . upper (): print ( \"[Callback] 'BLOCK' keyword found. Skipping LLM call.\" ) # Return an LlmResponse to skip the actual LLM call return LlmResponse ( content = types . Content ( role = \"model\" , parts = [ types . Part ( text = \"LLM call was blocked by before_model_callback.\" )], ) ) else : print ( \"[Callback] Proceeding with LLM call.\" ) # Return None to allow the (modified) request to go to the LLM return None # Create LlmAgent and Assign Callback my_llm_agent = LlmAgent ( name = \"ModelCallbackAgent\" , model = GEMINI_2_FLASH , instruction = \"You are a helpful assistant.\" , # Base instruction description = \"An LLM agent demonstrating before_model_callback\" , before_model_callback = simple_before_model_modifier # Assign the function here ) APP_NAME = \"guardrail_app\" USER_ID = \"user_1\" SESSION_ID = \"session_001\" # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = my_llm_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) async for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response: \" , final_response ) # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"write a joke on BLOCK\" ) package main import ( \"context\" \"fmt\" \"log\" \"regexp\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) func onBeforeModel ( ctx agent . CallbackContext , req * model . LLMRequest ) ( * model . LLMResponse , error ) { log . Printf ( \"[Callback] BeforeModel triggered for agent %q.\" , ctx . AgentName ()) // Modification Example: Add a prefix to the system instruction. if req . Config . SystemInstruction != nil { prefix := \"[Modified by Callback] \" // This is a simplified example; production code might need deeper checks. if len ( req . Config . SystemInstruction . Parts ) > 0 { req . Config . SystemInstruction . Parts [ 0 ]. Text = prefix + req . Config . SystemInstruction . Parts [ 0 ]. Text } else { req . Config . SystemInstruction . Parts = append ( req . Config . SystemInstruction . Parts , & genai . Part { Text : prefix }) } log . Printf ( \"[Callback] Modified system instruction.\" ) } // Skip Example: Check for \"BLOCK\" in the user's prompt. for _ , content := range req . Contents { for _ , part := range content . Parts { if strings . Contains ( strings . ToUpper ( part . Text ), \"BLOCK\" ) { log . Println ( \"[Callback] 'BLOCK' keyword found. Skipping LLM call.\" ) return & model . LLMResponse { Content : & genai . Content { Parts : [] * genai . Part {{ Text : \"LLM call was blocked by before_model_callback.\" }}, Role : \"model\" , }, }, nil } } } log . Println ( \"[Callback] Proceeding with LLM call.\" ) return nil , nil } func runBeforeModelExample () { ctx := context . Background () geminiModel , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"FATAL: Failed to create model: %v\" , err ) } llmCfg := llmagent . Config { Name : \"AgentWithBeforeModelCallback\" , Model : geminiModel , BeforeModelCallbacks : [] llmagent . BeforeModelCallback { onBeforeModel }, } testAgent , err := llmagent . New ( llmCfg ) if err != nil { log . Fatalf ( \"FATAL: Failed to create agent: %v\" , err ) } sessionService := session . InMemoryService () r , err := runner . New ( runner . Config { AppName : appName , Agent : testAgent , SessionService : sessionService }) if err != nil { log . Fatalf ( \"FATAL: Failed to create runner: %v\" , err ) } log . Println ( \"--- SCENARIO 1: Should proceed to LLM ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_normal\" , nil , \"Tell me a fun fact.\" ) log . Println ( \"\\n--- SCENARIO 2: Should be blocked by callback ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_blocked\" , nil , \"write a joke on BLOCK\" ) } import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.CallbackContext ; import com.google.adk.events.Event ; import com.google.adk.models.LlmRequest ; import com.google.adk.models.LlmResponse ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.common.collect.ImmutableList ; import com.google.common.collect.Iterables ; import com.google.genai.types.Content ; import com.google.genai.types.GenerateContentConfig ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import io.reactivex.rxjava3.core.Maybe ; import java.util.ArrayList ; import java.util.List ; public class BeforeModelCallbackExample { // --- Define Constants --- private static final String AGENT_NAME = \"ModelCallbackAgent\" ; private static final String MODEL_NAME = \"gemini-2.0-flash\" ; private static final String AGENT_INSTRUCTION = \"You are a helpful assistant.\" ; private static final String AGENT_DESCRIPTION = \"An LLM agent demonstrating before_model_callback\" ; // For session and runner private static final String APP_NAME = \"guardrail_app_java\" ; private static final String USER_ID = \"user_1_java\" ; public static void main ( String [] args ) { BeforeModelCallbackExample demo = new BeforeModelCallbackExample (); demo . defineAgentAndRun (); } // --- 1. Define the Callback Function --- // Inspects/modifies the LLM request or skips the actual LLM call. public Maybe < LlmResponse > simpleBeforeModelModifier ( CallbackContext callbackContext , LlmRequest llmRequest ) { String agentName = callbackContext . agentName (); System . out . printf ( \"%n[Callback] Before model call for agent: %s%n\" , agentName ); String lastUserMessage = \"\" ; if ( llmRequest . contents () != null && ! llmRequest . contents (). isEmpty ()) { Content lastContentItem = Iterables . getLast ( llmRequest . contents ()); if ( \"user\" . equals ( lastContentItem . role (). orElse ( null )) && lastContentItem . parts (). isPresent () && ! lastContentItem . parts (). get (). isEmpty ()) { lastUserMessage = lastContentItem . parts (). get (). get ( 0 ). text (). orElse ( \"\" ); } } System . out . printf ( \"[Callback] Inspecting last user message: '%s'%n\" , lastUserMessage ); // --- Modification Example --- // Add a prefix to the system instruction Content systemInstructionFromRequest = Content . builder (). parts ( ImmutableList . of ()). build (); // Ensure system_instruction is Content and parts list exists if ( llmRequest . config (). isPresent ()) { systemInstructionFromRequest = llmRequest . config () . get () . systemInstruction () . orElseGet (() -> Content . builder (). role ( \"system\" ). parts ( ImmutableList . of ()). build ()); } List < Part > currentSystemParts = new ArrayList <> ( systemInstructionFromRequest . parts (). orElse ( ImmutableList . of ())); // Ensure a part exists for modification if ( currentSystemParts . isEmpty ()) { currentSystemParts . add ( Part . fromText ( \"\" )); } // Modify the text of the first part String prefix = \"[Modified by Callback] \" ; String conceptuallyModifiedText = prefix + currentSystemParts . get ( 0 ). text (). orElse ( \"\" ); llmRequest = llmRequest . toBuilder () . config ( GenerateContentConfig . builder () . systemInstruction ( Content . builder () . parts ( List . of ( Part . fromText ( conceptuallyModifiedText ))) . build ()) . build ()) . build (); System . out . printf ( \"Modified System Instruction %s\" , llmRequest . config (). get (). systemInstruction ()); // --- Skip Example --- // Check if the last user message contains \"BLOCK\" if ( lastUserMessage . toUpperCase (). contains ( \"BLOCK\" )) { System . out . println ( \"[Callback] 'BLOCK' keyword found. Skipping LLM call.\" ); // Return an LlmResponse to skip the actual LLM call return Maybe . just ( LlmResponse . builder () . content ( Content . builder () . role ( \"model\" ) . parts ( ImmutableList . of ( Part . fromText ( \"LLM call was blocked by before_model_callback.\" ))) . build ()) . build ()); } // Return Empty response to allow the (modified) request to go to the LLM System . out . println ( \"[Callback] Proceeding with LLM call (using the original LlmRequest).\" ); return Maybe . empty (); } // --- 2. Define Agent and Run Scenarios --- public void defineAgentAndRun () { // Setup Agent with Callback LlmAgent myLlmAgent = LlmAgent . builder () . name ( AGENT_NAME ) . model ( MODEL_NAME ) . instruction ( AGENT_INSTRUCTION ) . description ( AGENT_DESCRIPTION ) . beforeModelCallback ( this :: simpleBeforeModelModifier ) . build (); // Create an InMemoryRunner InMemoryRunner runner = new InMemoryRunner ( myLlmAgent , APP_NAME ); // InMemoryRunner automatically creates a session service. Create a session using the service Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( \"Tell me about quantum computing. This is a test. So BLOCK.\" )); // Run the agent Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } } ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.models import LlmResponse, LlmRequest\nfrom google.adk.runners import Runner\nfrom typing import Optional\nfrom google.genai import types \nfrom google.adk.sessions import InMemorySessionService\n\nGEMINI_2_FLASH=\"gemini-2.0-flash\"\n\n# --- Define the Callback Function ---\ndef simple_before_model_modifier(\n    callback_context: CallbackContext, llm_request: LlmRequest\n) -> Optional[LlmResponse]:\n    \"\"\"Inspects/modifies the LLM request or skips the call.\"\"\"\n    agent_name = callback_context.agent_name\n    print(f\"[Callback] Before model call for agent: {agent_name}\")\n\n    # Inspect the last user message in the request contents\n    last_user_message = \"\"\n    if llm_request.contents and llm_request.contents[-1].role == 'user':\n         if llm_request.contents[-1].parts:\n            last_user_message = llm_request.contents[-1].parts[0].text\n    print(f\"[Callback] Inspecting last user message: '{last_user_message}'\")\n\n    # --- Modification Example ---\n    # Add a prefix to the system instruction\n    original_instruction = llm_request.config.system_instruction or types.Content(role=\"system\", parts=[])\n    prefix = \"[Modified by Callback] \"\n    # Ensure system_instruction is Content and parts list exists\n    if not isinstance(original_instruction, types.Content):\n         # Handle case where it might be a string (though config expects Content)\n         original_instruction = types.Content(role=\"system\", parts=[types.Part(text=str(original_instruction))])\n    if not original_instruction.parts:\n        original_instruction.parts.append(types.Part(text=\"\")) # Add an empty part if none exist\n\n    # Modify the text of the first part\n    modified_text = prefix + (original_instruction.parts[0].text or \"\")\n    original_instruction.parts[0].text = modified_text\n    llm_request.config.system_instruction = original_instruction\n    print(f\"[Callback] Modified system instruction to: '{modified_text}'\")\n\n    # --- Skip Example ---\n    # Check if the last user message contains \"BLOCK\"\n    if \"BLOCK\" in last_user_message.upper():\n        print(\"[Callback] 'BLOCK' keyword found. Skipping LLM call.\")\n        # Return an LlmResponse to skip the actual LLM call\n        return LlmResponse(\n            content=types.Content(\n                role=\"model\",\n                parts=[types.Part(text=\"LLM call was blocked by before_model_callback.\")],\n            )\n        )\n    else:\n        print(\"[Callback] Proceeding with LLM call.\")\n        # Return None to allow the (modified) request to go to the LLM\n        return None\n\n\n# Create LlmAgent and Assign Callback\nmy_llm_agent = LlmAgent(\n        name=\"ModelCallbackAgent\",\n        model=GEMINI_2_FLASH,\n        instruction=\"You are a helpful assistant.\", # Base instruction\n        description=\"An LLM agent demonstrating before_model_callback\",\n        before_model_callback=simple_before_model_modifier # Assign the function here\n)\n\nAPP_NAME = \"guardrail_app\"\nUSER_ID = \"user_1\"\nSESSION_ID = \"session_001\"\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=my_llm_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n\n# Agent Interaction\nasync def call_agent_async(query):\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    async for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"Agent Response: \", final_response)\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"write a joke on BLOCK\")"}, {"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"regexp\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\n\n\nfunc onBeforeModel(ctx agent.CallbackContext, req *model.LLMRequest) (*model.LLMResponse, error) {\n    log.Printf(\"[Callback] BeforeModel triggered for agent %q.\", ctx.AgentName())\n\n    // Modification Example: Add a prefix to the system instruction.\n    if req.Config.SystemInstruction != nil {\n        prefix := \"[Modified by Callback] \"\n        // This is a simplified example; production code might need deeper checks.\n        if len(req.Config.SystemInstruction.Parts) > 0 {\n            req.Config.SystemInstruction.Parts[0].Text = prefix + req.Config.SystemInstruction.Parts[0].Text\n        } else {\n            req.Config.SystemInstruction.Parts = append(req.Config.SystemInstruction.Parts, &genai.Part{Text: prefix})\n        }\n        log.Printf(\"[Callback] Modified system instruction.\")\n    }\n\n    // Skip Example: Check for \"BLOCK\" in the user's prompt.\n    for _, content := range req.Contents {\n        for _, part := range content.Parts {\n            if strings.Contains(strings.ToUpper(part.Text), \"BLOCK\") {\n                log.Println(\"[Callback] 'BLOCK' keyword found. Skipping LLM call.\")\n                return &model.LLMResponse{\n                    Content: &genai.Content{\n                        Parts: []*genai.Part{{Text: \"LLM call was blocked by before_model_callback.\"}},\n                        Role:  \"model\",\n                    },\n                }, nil\n            }\n        }\n    }\n\n    log.Println(\"[Callback] Proceeding with LLM call.\")\n    return nil, nil\n}\n\nfunc runBeforeModelExample() {\n    ctx := context.Background()\n    geminiModel, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create model: %v\", err)\n    }\n\n    llmCfg := llmagent.Config{\n        Name:                 \"AgentWithBeforeModelCallback\",\n        Model:                geminiModel,\n        BeforeModelCallbacks: []llmagent.BeforeModelCallback{onBeforeModel},\n    }\n    testAgent, err := llmagent.New(llmCfg)\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create agent: %v\", err)\n    }\n\n    sessionService := session.InMemoryService()\n    r, err := runner.New(runner.Config{AppName: appName, Agent: testAgent, SessionService: sessionService})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create runner: %v\", err)\n    }\n\n    log.Println(\"--- SCENARIO 1: Should proceed to LLM ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_normal\", nil, \"Tell me a fun fact.\")\n\n    log.Println(\"\\n--- SCENARIO 2: Should be blocked by callback ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_blocked\", nil, \"write a joke on BLOCK\")\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.CallbackContext;\nimport com.google.adk.events.Event;\nimport com.google.adk.models.LlmRequest;\nimport com.google.adk.models.LlmResponse;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.common.collect.ImmutableList;\nimport com.google.common.collect.Iterables;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.GenerateContentConfig;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport io.reactivex.rxjava3.core.Maybe;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class BeforeModelCallbackExample {\n\n  // --- Define Constants ---\n  private static final String AGENT_NAME = \"ModelCallbackAgent\";\n  private static final String MODEL_NAME = \"gemini-2.0-flash\";\n  private static final String AGENT_INSTRUCTION = \"You are a helpful assistant.\";\n  private static final String AGENT_DESCRIPTION =\n      \"An LLM agent demonstrating before_model_callback\";\n\n  // For session and runner\n  private static final String APP_NAME = \"guardrail_app_java\";\n  private static final String USER_ID = \"user_1_java\";\n\n  public static void main(String[] args) {\n    BeforeModelCallbackExample demo = new BeforeModelCallbackExample();\n    demo.defineAgentAndRun();\n  }\n\n  // --- 1. Define the Callback Function ---\n  // Inspects/modifies the LLM request or skips the actual LLM call.\n  public Maybe<LlmResponse> simpleBeforeModelModifier(\n      CallbackContext callbackContext, LlmRequest llmRequest) {\n    String agentName = callbackContext.agentName();\n    System.out.printf(\"%n[Callback] Before model call for agent: %s%n\", agentName);\n\n    String lastUserMessage = \"\";\n    if (llmRequest.contents() != null && !llmRequest.contents().isEmpty()) {\n      Content lastContentItem = Iterables.getLast(llmRequest.contents());\n      if (\"user\".equals(lastContentItem.role().orElse(null))\n          && lastContentItem.parts().isPresent()\n          && !lastContentItem.parts().get().isEmpty()) {\n        lastUserMessage = lastContentItem.parts().get().get(0).text().orElse(\"\");\n      }\n    }\n    System.out.printf(\"[Callback] Inspecting last user message: '%s'%n\", lastUserMessage);\n\n    // --- Modification Example ---\n    // Add a prefix to the system instruction\n    Content systemInstructionFromRequest = Content.builder().parts(ImmutableList.of()).build();\n    // Ensure system_instruction is Content and parts list exists\n    if (llmRequest.config().isPresent()) {\n      systemInstructionFromRequest =\n          llmRequest\n              .config()\n              .get()\n              .systemInstruction()\n              .orElseGet(() -> Content.builder().role(\"system\").parts(ImmutableList.of()).build());\n    }\n    List<Part> currentSystemParts =\n        new ArrayList<>(systemInstructionFromRequest.parts().orElse(ImmutableList.of()));\n    // Ensure a part exists for modification\n    if (currentSystemParts.isEmpty()) {\n      currentSystemParts.add(Part.fromText(\"\"));\n    }\n    // Modify the text of the first part\n    String prefix = \"[Modified by Callback] \";\n    String conceptuallyModifiedText = prefix + currentSystemParts.get(0).text().orElse(\"\");\n    llmRequest =\n        llmRequest.toBuilder()\n            .config(\n                GenerateContentConfig.builder()\n                    .systemInstruction(\n                        Content.builder()\n                            .parts(List.of(Part.fromText(conceptuallyModifiedText)))\n                            .build())\n                    .build())\n            .build();\n    System.out.printf(\n        \"Modified System Instruction %s\", llmRequest.config().get().systemInstruction());\n\n    // --- Skip Example ---\n    // Check if the last user message contains \"BLOCK\"\n    if (lastUserMessage.toUpperCase().contains(\"BLOCK\")) {\n      System.out.println(\"[Callback] 'BLOCK' keyword found. Skipping LLM call.\");\n      // Return an LlmResponse to skip the actual LLM call\n      return Maybe.just(\n          LlmResponse.builder()\n              .content(\n                  Content.builder()\n                      .role(\"model\")\n                      .parts(\n                          ImmutableList.of(\n                              Part.fromText(\"LLM call was blocked by before_model_callback.\")))\n                      .build())\n              .build());\n    }\n\n    // Return Empty response to allow the (modified) request to go to the LLM\n    System.out.println(\"[Callback] Proceeding with LLM call (using the original LlmRequest).\");\n    return Maybe.empty();\n  }\n\n  // --- 2. Define Agent and Run Scenarios ---\n  public void defineAgentAndRun() {\n    // Setup Agent with Callback\n    LlmAgent myLlmAgent =\n        LlmAgent.builder()\n            .name(AGENT_NAME)\n            .model(MODEL_NAME)\n            .instruction(AGENT_INSTRUCTION)\n            .description(AGENT_DESCRIPTION)\n            .beforeModelCallback(this::simpleBeforeModelModifier)\n            .build();\n\n    // Create an InMemoryRunner\n    InMemoryRunner runner = new InMemoryRunner(myLlmAgent, APP_NAME);\n    // InMemoryRunner automatically creates a session service. Create a session using the service\n    Session session = runner.sessionService().createSession(APP_NAME, USER_ID).blockingGet();\n    Content userMessage =\n        Content.fromParts(\n            Part.fromText(\"Tell me about quantum computing. This is a test. So BLOCK.\"));\n\n    // Run the agent\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n    // Stream event response\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n}"}]}, {"heading_path": ["After Model Callback\u00b6"], "text": "After Model Callback \u00b6 When: Called just after a response ( LlmResponse ) is received from the LLM, before it's processed further by the invoking agent. Purpose: Allows inspection or modification of the raw LLM response. Use cases include logging model outputs, reformatting responses, censoring sensitive information generated by the model, parsing structured data from the LLM response and storing it in callback_context.state or handling specific error codes. Code Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.agents import LlmAgent from google.adk.agents.callback_context import CallbackContext from google.adk.runners import Runner from typing import Optional from google.genai import types from google.adk.sessions import InMemorySessionService from google.adk.models import LlmResponse from copy import deepcopy GEMINI_2_FLASH = \"gemini-2.0-flash\" # --- Define the Callback Function --- def simple_after_model_modifier ( callback_context : CallbackContext , llm_response : LlmResponse ) -> Optional [ LlmResponse ]: \"\"\"Inspects/modifies the LLM response after it's received.\"\"\" agent_name = callback_context . agent_name print ( f \"[Callback] After model call for agent: { agent_name } \" ) # --- Inspection --- original_text = \"\" if llm_response . content and llm_response . content . parts : # Assuming simple text response for this example if llm_response . content . parts [ 0 ] . text : original_text = llm_response . content . parts [ 0 ] . text print ( f \"[Callback] Inspected original response text: ' { original_text [: 100 ] } ...'\" ) # Log snippet elif llm_response . content . parts [ 0 ] . function_call : print ( f \"[Callback] Inspected response: Contains function call ' { llm_response . content . parts [ 0 ] . function_call . name } '. No text modification.\" ) return None # Don't modify tool calls in this example else : print ( \"[Callback] Inspected response: No text content found.\" ) return None elif llm_response . error_message : print ( f \"[Callback] Inspected response: Contains error ' { llm_response . error_message } '. No modification.\" ) return None else : print ( \"[Callback] Inspected response: Empty LlmResponse.\" ) return None # Nothing to modify # --- Modification Example --- # Replace \"joke\" with \"funny story\" (case-insensitive) search_term = \"joke\" replace_term = \"funny story\" if search_term in original_text . lower (): print ( f \"[Callback] Found ' { search_term } '. Modifying response.\" ) modified_text = original_text . replace ( search_term , replace_term ) modified_text = modified_text . replace ( search_term . capitalize (), replace_term . capitalize ()) # Handle capitalization # Create a NEW LlmResponse with the modified content # Deep copy parts to avoid modifying original if other callbacks exist modified_parts = [ deepcopy ( part ) for part in llm_response . content . parts ] modified_parts [ 0 ] . text = modified_text # Update the text in the copied part new_response = LlmResponse ( content = types . Content ( role = \"model\" , parts = modified_parts ), # Copy other relevant fields if necessary, e.g., grounding_metadata grounding_metadata = llm_response . grounding_metadata ) print ( f \"[Callback] Returning modified response.\" ) return new_response # Return the modified response else : print ( f \"[Callback] ' { search_term } ' not found. Passing original response through.\" ) # Return None to use the original llm_response return None # Create LlmAgent and Assign Callback my_llm_agent = LlmAgent ( name = \"AfterModelCallbackAgent\" , model = GEMINI_2_FLASH , instruction = \"You are a helpful assistant.\" , description = \"An LLM agent demonstrating after_model_callback\" , after_model_callback = simple_after_model_modifier # Assign the function here ) APP_NAME = \"guardrail_app\" USER_ID = \"user_1\" SESSION_ID = \"session_001\" # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = my_llm_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): session , runner = await setup_session_and_runner () content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) async for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response: \" , final_response ) # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"\"\"write multiple time the word \"joke\" \"\"\" ) package main import ( \"context\" \"fmt\" \"log\" \"regexp\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) func onAfterModel ( ctx agent . CallbackContext , resp * model . LLMResponse , respErr error ) ( * model . LLMResponse , error ) { log . Printf ( \"[Callback] AfterModel triggered for agent %q.\" , ctx . AgentName ()) if respErr != nil { log . Printf ( \"[Callback] Model returned an error: %v. Passing it through.\" , respErr ) return nil , respErr } if resp == nil || resp . Content == nil || len ( resp . Content . Parts ) == 0 { log . Println ( \"[Callback] Response is nil or has no parts, nothing to process.\" ) return nil , nil } // Check for function calls and pass them through without modification. if resp . Content . Parts [ 0 ]. FunctionCall != nil { log . Println ( \"[Callback] Response is a function call. No modification.\" ) return nil , nil } originalText := resp . Content . Parts [ 0 ]. Text // Use a case-insensitive regex with word boundaries to find \"joke\". re := regexp . MustCompile ( `(?i)\\bjoke\\b` ) if ! re . MatchString ( originalText ) { log . Println ( \"[Callback] 'joke' not found. Passing original response through.\" ) return nil , nil } log . Println ( \"[Callback] 'joke' found. Modifying response.\" ) // Use a replacer function to handle capitalization. modifiedText := re . ReplaceAllStringFunc ( originalText , func ( s string ) string { if strings . ToUpper ( s ) == \"JOKE\" { if s == \"Joke\" { return \"Funny story\" } return \"funny story\" } return s // Should not be reached with this regex, but it's safe. }) resp . Content . Parts [ 0 ]. Text = modifiedText return resp , nil } func runAfterModelExample () { ctx := context . Background () geminiModel , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"FATAL: Failed to create model: %v\" , err ) } llmCfg := llmagent . Config { Name : \"AgentWithAfterModelCallback\" , Model : geminiModel , AfterModelCallbacks : [] llmagent . AfterModelCallback { onAfterModel }, } testAgent , err := llmagent . New ( llmCfg ) if err != nil { log . Fatalf ( \"FATAL: Failed to create agent: %v\" , err ) } sessionService := session . InMemoryService () r , err := runner . New ( runner . Config { AppName : appName , Agent : testAgent , SessionService : sessionService }) if err != nil { log . Fatalf ( \"FATAL: Failed to create runner: %v\" , err ) } log . Println ( \"--- SCENARIO 1: Response should be modified ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_modify\" , nil , `Give me a paragraph about different styles of jokes.` ) } import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.CallbackContext ; import com.google.adk.events.Event ; import com.google.adk.models.LlmResponse ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.common.collect.ImmutableList ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import io.reactivex.rxjava3.core.Maybe ; import java.util.ArrayList ; import java.util.List ; import java.util.Optional ; import java.util.regex.Matcher ; import java.util.regex.Pattern ; public class AfterModelCallbackExample { // --- Define Constants --- private static final String AGENT_NAME = \"AfterModelCallbackAgent\" ; private static final String MODEL_NAME = \"gemini-2.0-flash\" ; private static final String AGENT_INSTRUCTION = \"You are a helpful assistant.\" ; private static final String AGENT_DESCRIPTION = \"An LLM agent demonstrating after_model_callback\" ; // For session and runner private static final String APP_NAME = \"AfterModelCallbackAgentApp\" ; private static final String USER_ID = \"user_1\" ; // For text replacement private static final String SEARCH_TERM = \"joke\" ; private static final String REPLACE_TERM = \"funny story\" ; private static final Pattern SEARCH_PATTERN = Pattern . compile ( \"\\\\b\" + Pattern . quote ( SEARCH_TERM ) + \"\\\\b\" , Pattern . CASE_INSENSITIVE ); public static void main ( String [] args ) { AfterModelCallbackExample example = new AfterModelCallbackExample (); example . defineAgentAndRun (); } // --- Define the Callback Function --- // Inspects/modifies the LLM response after it's received. public Maybe < LlmResponse > simpleAfterModelModifier ( CallbackContext callbackContext , LlmResponse llmResponse ) { String agentName = callbackContext . agentName (); System . out . printf ( \"%n[Callback] After model call for agent: %s%n\" , agentName ); // --- Inspection Phase --- if ( llmResponse . errorMessage (). isPresent ()) { System . out . printf ( \"[Callback] Response has error: '%s'. No modification.%n\" , llmResponse . errorMessage (). get ()); return Maybe . empty (); // Pass through errors } Optional < Part > firstTextPartOpt = llmResponse . content () . flatMap ( Content :: parts ) . filter ( parts -> ! parts . isEmpty () && parts . get ( 0 ). text (). isPresent ()) . map ( parts -> parts . get ( 0 )); if ( ! firstTextPartOpt . isPresent ()) { // Could be a function call, empty content, or no text in the first part llmResponse . content () . flatMap ( Content :: parts ) . filter ( parts -> ! parts . isEmpty () && parts . get ( 0 ). functionCall (). isPresent ()) . ifPresent ( parts -> System . out . printf ( \"[Callback] Response is a function call ('%s'). No text modification.%n\" , parts . get ( 0 ). functionCall (). get (). name (). orElse ( \"N/A\" ))); if ( ! llmResponse . content (). isPresent () || ! llmResponse . content (). flatMap ( Content :: parts ). isPresent () || llmResponse . content (). flatMap ( Content :: parts ). get (). isEmpty ()) { System . out . println ( \"[Callback] Response content is empty or has no parts. No modification.\" ); } else if ( ! firstTextPartOpt . isPresent ()) { // Already checked for function call System . out . println ( \"[Callback] First part has no text content. No modification.\" ); } return Maybe . empty (); // Pass through non-text or unsuitable responses } String originalText = firstTextPartOpt . get (). text (). get (); System . out . printf ( \"[Callback] Inspected original text: '%.100s...'%n\" , originalText ); // --- Modification Phase --- Matcher matcher = SEARCH_PATTERN . matcher ( originalText ); if ( ! matcher . find ()) { System . out . printf ( \"[Callback] '%s' not found. Passing original response through.%n\" , SEARCH_TERM ); return Maybe . empty (); } System . out . printf ( \"[Callback] Found '%s'. Modifying response.%n\" , SEARCH_TERM ); // Perform the replacement, respecting original capitalization of the found term's first letter String foundTerm = matcher . group ( 0 ); // The actual term found (e.g., \"joke\" or \"Joke\") String actualReplaceTerm = REPLACE_TERM ; if ( Character . isUpperCase ( foundTerm . charAt ( 0 )) && REPLACE_TERM . length () > 0 ) { actualReplaceTerm = Character . toUpperCase ( REPLACE_TERM . charAt ( 0 )) + REPLACE_TERM . substring ( 1 ); } String modifiedText = matcher . replaceFirst ( Matcher . quoteReplacement ( actualReplaceTerm )); // Create a new LlmResponse with the modified content Content originalContent = llmResponse . content (). get (); List < Part > originalParts = originalContent . parts (). orElse ( ImmutableList . of ()); List < Part > modifiedPartsList = new ArrayList <> ( originalParts . size ()); if ( ! originalParts . isEmpty ()) { modifiedPartsList . add ( Part . fromText ( modifiedText )); // Replace first part's text // Add remaining parts as they were (shallow copy) for ( int i = 1 ; i < originalParts . size (); i ++ ) { modifiedPartsList . add ( originalParts . get ( i )); } } else { // Should not happen if firstTextPartOpt was present modifiedPartsList . add ( Part . fromText ( modifiedText )); } LlmResponse . Builder newResponseBuilder = LlmResponse . builder () . content ( originalContent . toBuilder (). parts ( ImmutableList . copyOf ( modifiedPartsList )). build ()) . groundingMetadata ( llmResponse . groundingMetadata ()); System . out . println ( \"[Callback] Returning modified response.\" ); return Maybe . just ( newResponseBuilder . build ()); } // --- 2. Define Agent and Run Scenarios --- public void defineAgentAndRun () { // Setup Agent with Callback LlmAgent myLlmAgent = LlmAgent . builder () . name ( AGENT_NAME ) . model ( MODEL_NAME ) . instruction ( AGENT_INSTRUCTION ) . description ( AGENT_DESCRIPTION ) . afterModelCallback ( this :: simpleAfterModelModifier ) . build (); // Create an InMemoryRunner InMemoryRunner runner = new InMemoryRunner ( myLlmAgent , APP_NAME ); // InMemoryRunner automatically creates a session service. Create a session using the service Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( \"Tell me a joke about quantum computing. Include the word 'joke' in your response\" )); // Run the agent Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } } ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.runners import Runner\nfrom typing import Optional\nfrom google.genai import types \nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.models import LlmResponse\nfrom copy import deepcopy\n\nGEMINI_2_FLASH=\"gemini-2.0-flash\"\n\n# --- Define the Callback Function ---\ndef simple_after_model_modifier(\n    callback_context: CallbackContext, llm_response: LlmResponse\n) -> Optional[LlmResponse]:\n    \"\"\"Inspects/modifies the LLM response after it's received.\"\"\"\n    agent_name = callback_context.agent_name\n    print(f\"[Callback] After model call for agent: {agent_name}\")\n\n    # --- Inspection ---\n    original_text = \"\"\n    if llm_response.content and llm_response.content.parts:\n        # Assuming simple text response for this example\n        if llm_response.content.parts[0].text:\n            original_text = llm_response.content.parts[0].text\n            print(f\"[Callback] Inspected original response text: '{original_text[:100]}...'\") # Log snippet\n        elif llm_response.content.parts[0].function_call:\n             print(f\"[Callback] Inspected response: Contains function call '{llm_response.content.parts[0].function_call.name}'. No text modification.\")\n             return None # Don't modify tool calls in this example\n        else:\n             print(\"[Callback] Inspected response: No text content found.\")\n             return None\n    elif llm_response.error_message:\n        print(f\"[Callback] Inspected response: Contains error '{llm_response.error_message}'. No modification.\")\n        return None\n    else:\n        print(\"[Callback] Inspected response: Empty LlmResponse.\")\n        return None # Nothing to modify\n\n    # --- Modification Example ---\n    # Replace \"joke\" with \"funny story\" (case-insensitive)\n    search_term = \"joke\"\n    replace_term = \"funny story\"\n    if search_term in original_text.lower():\n        print(f\"[Callback] Found '{search_term}'. Modifying response.\")\n        modified_text = original_text.replace(search_term, replace_term)\n        modified_text = modified_text.replace(search_term.capitalize(), replace_term.capitalize()) # Handle capitalization\n\n        # Create a NEW LlmResponse with the modified content\n        # Deep copy parts to avoid modifying original if other callbacks exist\n        modified_parts = [deepcopy(part) for part in llm_response.content.parts]\n        modified_parts[0].text = modified_text # Update the text in the copied part\n\n        new_response = LlmResponse(\n             content=types.Content(role=\"model\", parts=modified_parts),\n             # Copy other relevant fields if necessary, e.g., grounding_metadata\n             grounding_metadata=llm_response.grounding_metadata\n             )\n        print(f\"[Callback] Returning modified response.\")\n        return new_response # Return the modified response\n    else:\n        print(f\"[Callback] '{search_term}' not found. Passing original response through.\")\n        # Return None to use the original llm_response\n        return None\n\n\n# Create LlmAgent and Assign Callback\nmy_llm_agent = LlmAgent(\n        name=\"AfterModelCallbackAgent\",\n        model=GEMINI_2_FLASH,\n        instruction=\"You are a helpful assistant.\",\n        description=\"An LLM agent demonstrating after_model_callback\",\n        after_model_callback=simple_after_model_modifier # Assign the function here\n)\n\nAPP_NAME = \"guardrail_app\"\nUSER_ID = \"user_1\"\nSESSION_ID = \"session_001\"\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=my_llm_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n# Agent Interaction\nasync def call_agent_async(query):\n  session, runner = await setup_session_and_runner()\n\n  content = types.Content(role='user', parts=[types.Part(text=query)])\n  events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n  async for event in events:\n      if event.is_final_response():\n          final_response = event.content.parts[0].text\n          print(\"Agent Response: \", final_response)\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"\"\"write multiple time the word \"joke\" \"\"\")"}, {"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"regexp\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\n\n\nfunc onAfterModel(ctx agent.CallbackContext, resp *model.LLMResponse, respErr error) (*model.LLMResponse, error) {\n    log.Printf(\"[Callback] AfterModel triggered for agent %q.\", ctx.AgentName())\n    if respErr != nil {\n        log.Printf(\"[Callback] Model returned an error: %v. Passing it through.\", respErr)\n        return nil, respErr\n    }\n    if resp == nil || resp.Content == nil || len(resp.Content.Parts) == 0 {\n        log.Println(\"[Callback] Response is nil or has no parts, nothing to process.\")\n        return nil, nil\n    }\n    // Check for function calls and pass them through without modification.\n    if resp.Content.Parts[0].FunctionCall != nil {\n        log.Println(\"[Callback] Response is a function call. No modification.\")\n        return nil, nil\n    }\n\n    originalText := resp.Content.Parts[0].Text\n\n    // Use a case-insensitive regex with word boundaries to find \"joke\".\n    re := regexp.MustCompile(`(?i)\\bjoke\\b`)\n    if !re.MatchString(originalText) {\n        log.Println(\"[Callback] 'joke' not found. Passing original response through.\")\n        return nil, nil\n    }\n\n    log.Println(\"[Callback] 'joke' found. Modifying response.\")\n    // Use a replacer function to handle capitalization.\n    modifiedText := re.ReplaceAllStringFunc(originalText, func(s string) string {\n        if strings.ToUpper(s) == \"JOKE\" {\n            if s == \"Joke\" {\n                return \"Funny story\"\n            }\n            return \"funny story\"\n        }\n        return s // Should not be reached with this regex, but it's safe.\n    })\n\n    resp.Content.Parts[0].Text = modifiedText\n    return resp, nil\n}\n\nfunc runAfterModelExample() {\n    ctx := context.Background()\n    geminiModel, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create model: %v\", err)\n    }\n\n    llmCfg := llmagent.Config{\n        Name:                \"AgentWithAfterModelCallback\",\n        Model:               geminiModel,\n        AfterModelCallbacks: []llmagent.AfterModelCallback{onAfterModel},\n    }\n    testAgent, err := llmagent.New(llmCfg)\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create agent: %v\", err)\n    }\n\n    sessionService := session.InMemoryService()\n    r, err := runner.New(runner.Config{AppName: appName, Agent: testAgent, SessionService: sessionService})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create runner: %v\", err)\n    }\n\n    log.Println(\"--- SCENARIO 1: Response should be modified ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_modify\", nil, `Give me a paragraph about different styles of jokes.`)\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.CallbackContext;\nimport com.google.adk.events.Event;\nimport com.google.adk.models.LlmResponse;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.common.collect.ImmutableList;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport io.reactivex.rxjava3.core.Maybe;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Optional;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\npublic class AfterModelCallbackExample {\n\n  // --- Define Constants ---\n  private static final String AGENT_NAME = \"AfterModelCallbackAgent\";\n  private static final String MODEL_NAME = \"gemini-2.0-flash\";\n  private static final String AGENT_INSTRUCTION = \"You are a helpful assistant.\";\n  private static final String AGENT_DESCRIPTION = \"An LLM agent demonstrating after_model_callback\";\n\n  // For session and runner\n  private static final String APP_NAME = \"AfterModelCallbackAgentApp\";\n  private static final String USER_ID = \"user_1\";\n\n  // For text replacement\n  private static final String SEARCH_TERM = \"joke\";\n  private static final String REPLACE_TERM = \"funny story\";\n  private static final Pattern SEARCH_PATTERN =\n      Pattern.compile(\"\\\\b\" + Pattern.quote(SEARCH_TERM) + \"\\\\b\", Pattern.CASE_INSENSITIVE);\n\n  public static void main(String[] args) {\n    AfterModelCallbackExample example = new AfterModelCallbackExample();\n    example.defineAgentAndRun();\n  }\n\n  // --- Define the Callback Function ---\n  // Inspects/modifies the LLM response after it's received.\n  public Maybe<LlmResponse> simpleAfterModelModifier(\n      CallbackContext callbackContext, LlmResponse llmResponse) {\n    String agentName = callbackContext.agentName();\n    System.out.printf(\"%n[Callback] After model call for agent: %s%n\", agentName);\n\n    // --- Inspection Phase ---\n    if (llmResponse.errorMessage().isPresent()) {\n      System.out.printf(\n          \"[Callback] Response has error: '%s'. No modification.%n\",\n          llmResponse.errorMessage().get());\n      return Maybe.empty(); // Pass through errors\n    }\n\n    Optional<Part> firstTextPartOpt =\n        llmResponse\n            .content()\n            .flatMap(Content::parts)\n            .filter(parts -> !parts.isEmpty() && parts.get(0).text().isPresent())\n            .map(parts -> parts.get(0));\n\n    if (!firstTextPartOpt.isPresent()) {\n      // Could be a function call, empty content, or no text in the first part\n      llmResponse\n          .content()\n          .flatMap(Content::parts)\n          .filter(parts -> !parts.isEmpty() && parts.get(0).functionCall().isPresent())\n          .ifPresent(\n              parts ->\n                  System.out.printf(\n                      \"[Callback] Response is a function call ('%s'). No text modification.%n\",\n                      parts.get(0).functionCall().get().name().orElse(\"N/A\")));\n      if (!llmResponse.content().isPresent()\n          || !llmResponse.content().flatMap(Content::parts).isPresent()\n          || llmResponse.content().flatMap(Content::parts).get().isEmpty()) {\n        System.out.println(\n            \"[Callback] Response content is empty or has no parts. No modification.\");\n      } else if (!firstTextPartOpt.isPresent()) { // Already checked for function call\n        System.out.println(\"[Callback] First part has no text content. No modification.\");\n      }\n      return Maybe.empty(); // Pass through non-text or unsuitable responses\n    }\n\n    String originalText = firstTextPartOpt.get().text().get();\n    System.out.printf(\"[Callback] Inspected original text: '%.100s...'%n\", originalText);\n\n    // --- Modification Phase ---\n    Matcher matcher = SEARCH_PATTERN.matcher(originalText);\n    if (!matcher.find()) {\n      System.out.printf(\n          \"[Callback] '%s' not found. Passing original response through.%n\", SEARCH_TERM);\n      return Maybe.empty();\n    }\n\n    System.out.printf(\"[Callback] Found '%s'. Modifying response.%n\", SEARCH_TERM);\n\n    // Perform the replacement, respecting original capitalization of the found term's first letter\n    String foundTerm = matcher.group(0); // The actual term found (e.g., \"joke\" or \"Joke\")\n    String actualReplaceTerm = REPLACE_TERM;\n    if (Character.isUpperCase(foundTerm.charAt(0)) && REPLACE_TERM.length() > 0) {\n      actualReplaceTerm = Character.toUpperCase(REPLACE_TERM.charAt(0)) + REPLACE_TERM.substring(1);\n    }\n    String modifiedText = matcher.replaceFirst(Matcher.quoteReplacement(actualReplaceTerm));\n\n    // Create a new LlmResponse with the modified content\n    Content originalContent = llmResponse.content().get();\n    List<Part> originalParts = originalContent.parts().orElse(ImmutableList.of());\n\n    List<Part> modifiedPartsList = new ArrayList<>(originalParts.size());\n    if (!originalParts.isEmpty()) {\n      modifiedPartsList.add(Part.fromText(modifiedText)); // Replace first part's text\n      // Add remaining parts as they were (shallow copy)\n      for (int i = 1; i < originalParts.size(); i++) {\n        modifiedPartsList.add(originalParts.get(i));\n      }\n    } else { // Should not happen if firstTextPartOpt was present\n      modifiedPartsList.add(Part.fromText(modifiedText));\n    }\n\n    LlmResponse.Builder newResponseBuilder =\n        LlmResponse.builder()\n            .content(\n                originalContent.toBuilder().parts(ImmutableList.copyOf(modifiedPartsList)).build())\n            .groundingMetadata(llmResponse.groundingMetadata());\n\n    System.out.println(\"[Callback] Returning modified response.\");\n    return Maybe.just(newResponseBuilder.build());\n  }\n\n  // --- 2. Define Agent and Run Scenarios ---\n  public void defineAgentAndRun() {\n    // Setup Agent with Callback\n    LlmAgent myLlmAgent =\n        LlmAgent.builder()\n            .name(AGENT_NAME)\n            .model(MODEL_NAME)\n            .instruction(AGENT_INSTRUCTION)\n            .description(AGENT_DESCRIPTION)\n            .afterModelCallback(this::simpleAfterModelModifier)\n            .build();\n\n    // Create an InMemoryRunner\n    InMemoryRunner runner = new InMemoryRunner(myLlmAgent, APP_NAME);\n    // InMemoryRunner automatically creates a session service. Create a session using the service\n    Session session = runner.sessionService().createSession(APP_NAME, USER_ID).blockingGet();\n    Content userMessage =\n        Content.fromParts(\n            Part.fromText(\n                \"Tell me a joke about quantum computing. Include the word 'joke' in your response\"));\n\n    // Run the agent\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n\n    // Stream event response\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n}"}]}, {"heading_path": ["Tool Execution Callbacks\u00b6"], "text": "Tool Execution Callbacks \u00b6 These callbacks are also specific to LlmAgent and trigger around the execution of tools (including FunctionTool , AgentTool , etc.) that the LLM might request. ", "code_blocks": []}, {"heading_path": ["Before Tool Callback\u00b6"], "text": "Before Tool Callback \u00b6 When: Called just before a specific tool's run_async method is invoked, after the LLM has generated a function call for it. Purpose: Allows inspection and modification of tool arguments, performing authorization checks before execution, logging tool usage attempts, or implementing tool-level caching. Return Value Effect: If the callback returns None (or a Maybe.empty() object in Java), the tool's run_async method is executed with the (potentially modified) args . If a dictionary (or Map in Java) is returned, the tool's run_async method is skipped . The returned dictionary is used directly as the result of the tool call. This is useful for caching or overriding tool behavior. Code Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.agents import LlmAgent from google.adk.runners import Runner from typing import Optional from google.genai import types from google.adk.sessions import InMemorySessionService from google.adk.tools import FunctionTool from google.adk.tools.tool_context import ToolContext from google.adk.tools.base_tool import BaseTool from typing import Dict , Any GEMINI_2_FLASH = \"gemini-2.0-flash\" def get_capital_city ( country : str ) -> str : \"\"\"Retrieves the capital city of a given country.\"\"\" print ( f \"--- Tool 'get_capital_city' executing with country: { country } ---\" ) country_capitals = { \"united states\" : \"Washington, D.C.\" , \"canada\" : \"Ottawa\" , \"france\" : \"Paris\" , \"germany\" : \"Berlin\" , } return country_capitals . get ( country . lower (), f \"Capital not found for { country } \" ) capital_tool = FunctionTool ( func = get_capital_city ) def simple_before_tool_modifier ( tool : BaseTool , args : Dict [ str , Any ], tool_context : ToolContext ) -> Optional [ Dict ]: \"\"\"Inspects/modifies tool args or skips the tool call.\"\"\" agent_name = tool_context . agent_name tool_name = tool . name print ( f \"[Callback] Before tool call for tool ' { tool_name } ' in agent ' { agent_name } '\" ) print ( f \"[Callback] Original args: { args } \" ) if tool_name == 'get_capital_city' and args . get ( 'country' , '' ) . lower () == 'canada' : print ( \"[Callback] Detected 'Canada'. Modifying args to 'France'.\" ) args [ 'country' ] = 'France' print ( f \"[Callback] Modified args: { args } \" ) return None # If the tool is 'get_capital_city' and country is 'BLOCK' if tool_name == 'get_capital_city' and args . get ( 'country' , '' ) . upper () == 'BLOCK' : print ( \"[Callback] Detected 'BLOCK'. Skipping tool execution.\" ) return { \"result\" : \"Tool execution was blocked by before_tool_callback.\" } print ( \"[Callback] Proceeding with original or previously modified args.\" ) return None my_llm_agent = LlmAgent ( name = \"ToolCallbackAgent\" , model = GEMINI_2_FLASH , instruction = \"You are an agent that can find capital cities. Use the get_capital_city tool.\" , description = \"An LLM agent demonstrating before_tool_callback\" , tools = [ capital_tool ], before_tool_callback = simple_before_tool_modifier ) APP_NAME = \"guardrail_app\" USER_ID = \"user_1\" SESSION_ID = \"session_001\" # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = my_llm_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) async for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response: \" , final_response ) # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"Canada\" ) package main import ( \"context\" \"fmt\" \"log\" \"regexp\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) // GetCapitalCityArgs defines the arguments for the getCapitalCity tool. type GetCapitalCityArgs struct { Country string `json:\"country\" jsonschema:\"The country to get the capital of.\"` } // getCapitalCity is a tool that returns the capital of a given country. func getCapitalCity ( ctx tool . Context , args * GetCapitalCityArgs ) string { capitals := map [ string ] string { \"canada\" : \"Ottawa\" , \"france\" : \"Paris\" , \"germany\" : \"Berlin\" , \"united states\" : \"Washington, D.C.\" , } capital , ok := capitals [ strings . ToLower ( args . Country )] if ! ok { return \"<Unknown>\" } return capital } func onBeforeTool ( ctx tool . Context , t tool . Tool , args map [ string ] any ) ( map [ string ] any , error ) { log . Printf ( \"[Callback] BeforeTool triggered for tool %q in agent %q.\" , t . Name (), ctx . AgentName ()) log . Printf ( \"[Callback] Original args: %v\" , args ) if t . Name () == \"getCapitalCity\" { if country , ok := args [ \"country\" ].( string ); ok { if strings . ToLower ( country ) == \"canada\" { log . Println ( \"[Callback] Detected 'Canada'. Modifying args to 'France'.\" ) args [ \"country\" ] = \"France\" return args , nil // Proceed with modified args } else if strings . ToUpper ( country ) == \"BLOCK\" { log . Println ( \"[Callback] Detected 'BLOCK'. Skipping tool execution.\" ) // Skip tool and return a custom result. return map [ string ] any { \"result\" : \"Tool execution was blocked by before_tool_callback.\" }, nil } } } log . Println ( \"[Callback] Proceeding with original or previously modified args.\" ) return nil , nil // Proceed with original args } func runBeforeToolExample () { ctx := context . Background () geminiModel , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"FATAL: Failed to create model: %v\" , err ) } capitalTool , err := functiontool . New [ * GetCapitalCityArgs , string ]( functiontool . Config { Name : \"getCapitalCity\" , Description : \"Retrieves the capital city of a given country.\" , }, getCapitalCity ) if err != nil { log . Fatalf ( \"FATAL: Failed to create function tool: %v\" , err ) } llmCfg := llmagent . Config { Name : \"AgentWithBeforeToolCallback\" , Model : geminiModel , Tools : [] tool . Tool { capitalTool }, BeforeToolCallbacks : [] llmagent . BeforeToolCallback { onBeforeTool }, Instruction : \"You are an agent that can find capital cities. Use the getCapitalCity tool.\" , } testAgent , err := llmagent . New ( llmCfg ) if err != nil { log . Fatalf ( \"FATAL: Failed to create agent: %v\" , err ) } sessionService := session . InMemoryService () r , err := runner . New ( runner . Config { AppName : appName , Agent : testAgent , SessionService : sessionService }) if err != nil { log . Fatalf ( \"FATAL: Failed to create runner: %v\" , err ) } log . Println ( \"--- SCENARIO 1: Args should be modified ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_tool_modify\" , nil , \"What is the capital of Canada?\" ) log . Println ( \"--- SCENARIO 2: Tool call should be blocked ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_tool_block\" , nil , \"capital of BLOCK\" ) } import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.InvocationContext ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.adk.tools.Annotations.Schema ; import com.google.adk.tools.BaseTool ; import com.google.adk.tools.FunctionTool ; import com.google.adk.tools.ToolContext ; import com.google.common.collect.ImmutableMap ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import io.reactivex.rxjava3.core.Maybe ; import java.util.HashMap ; import java.util.Map ; public class BeforeToolCallbackExample { private static final String APP_NAME = \"ToolCallbackAgentApp\" ; private static final String USER_ID = \"user_1\" ; private static final String SESSION_ID = \"session_001\" ; private static final String MODEL_NAME = \"gemini-2.0-flash\" ; public static void main ( String [] args ) { BeforeToolCallbackExample example = new BeforeToolCallbackExample (); example . runAgent ( \"capital of canada\" ); } // --- Define a Simple Tool Function --- // The Schema is important for the callback \"args\" to correctly identify the input. public static Map < String , Object > getCapitalCity ( @Schema ( name = \"country\" , description = \"The country to find the capital of.\" ) String country ) { System . out . printf ( \"--- Tool 'getCapitalCity' executing with country: %s ---%n\" , country ); Map < String , String > countryCapitals = new HashMap <> (); countryCapitals . put ( \"united states\" , \"Washington, D.C.\" ); countryCapitals . put ( \"canada\" , \"Ottawa\" ); countryCapitals . put ( \"france\" , \"Paris\" ); countryCapitals . put ( \"germany\" , \"Berlin\" ); String capital = countryCapitals . getOrDefault ( country . toLowerCase (), \"Capital not found for \" + country ); // FunctionTool expects a Map<String, Object> as the return type for the method it wraps. return ImmutableMap . of ( \"capital\" , capital ); } // Define the Callback function // The Tool callback provides all these parameters by default. public Maybe < Map < String , Object >> simpleBeforeToolModifier ( InvocationContext invocationContext , BaseTool tool , Map < String , Object > args , ToolContext toolContext ) { String agentName = invocationContext . agent (). name (); String toolName = tool . name (); System . out . printf ( \"[Callback] Before tool call for tool '%s' in agent '%s'%n\" , toolName , agentName ); System . out . printf ( \"[Callback] Original args: %s%n\" , args ); if ( \"getCapitalCity\" . equals ( toolName )) { String countryArg = ( String ) args . get ( \"country\" ); if ( countryArg != null ) { if ( \"canada\" . equalsIgnoreCase ( countryArg )) { System . out . println ( \"[Callback] Detected 'Canada'. Modifying args to 'France'.\" ); args . put ( \"country\" , \"France\" ); System . out . printf ( \"[Callback] Modified args: %s%n\" , args ); // Proceed with modified args return Maybe . empty (); } else if ( \"BLOCK\" . equalsIgnoreCase ( countryArg )) { System . out . println ( \"[Callback] Detected 'BLOCK'. Skipping tool execution.\" ); // Return a map to skip the tool call and use this as the result return Maybe . just ( ImmutableMap . of ( \"result\" , \"Tool execution was blocked by before_tool_callback.\" )); } } } System . out . println ( \"[Callback] Proceeding with original or previously modified args.\" ); return Maybe . empty (); } public void runAgent ( String query ) { // --- Wrap the function into a Tool --- FunctionTool capitalTool = FunctionTool . create ( this . getClass (), \"getCapitalCity\" ); // Create LlmAgent and Assign Callback LlmAgent myLlmAgent = LlmAgent . builder () . name ( APP_NAME ) . model ( MODEL_NAME ) . instruction ( \"You are an agent that can find capital cities. Use the getCapitalCity tool.\" ) . description ( \"An LLM agent demonstrating before_tool_callback\" ) . tools ( capitalTool ) . beforeToolCallback ( this :: simpleBeforeToolModifier ) . build (); // Session and Runner InMemoryRunner runner = new InMemoryRunner ( myLlmAgent ); Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID , null , SESSION_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( query )); System . out . printf ( \"%n--- Calling agent with query: \\\"%s\\\" ---%n\" , query ); Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } } ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.runners import Runner\nfrom typing import Optional\nfrom google.genai import types \nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import FunctionTool\nfrom google.adk.tools.tool_context import ToolContext\nfrom google.adk.tools.base_tool import BaseTool\nfrom typing import Dict, Any\n\n\nGEMINI_2_FLASH=\"gemini-2.0-flash\"\n\ndef get_capital_city(country: str) -> str:\n    \"\"\"Retrieves the capital city of a given country.\"\"\"\n    print(f\"--- Tool 'get_capital_city' executing with country: {country} ---\")\n    country_capitals = {\n        \"united states\": \"Washington, D.C.\",\n        \"canada\": \"Ottawa\",\n        \"france\": \"Paris\",\n        \"germany\": \"Berlin\",\n    }\n    return country_capitals.get(country.lower(), f\"Capital not found for {country}\")\n\ncapital_tool = FunctionTool(func=get_capital_city)\n\ndef simple_before_tool_modifier(\n    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext\n) -> Optional[Dict]:\n    \"\"\"Inspects/modifies tool args or skips the tool call.\"\"\"\n    agent_name = tool_context.agent_name\n    tool_name = tool.name\n    print(f\"[Callback] Before tool call for tool '{tool_name}' in agent '{agent_name}'\")\n    print(f\"[Callback] Original args: {args}\")\n\n    if tool_name == 'get_capital_city' and args.get('country', '').lower() == 'canada':\n        print(\"[Callback] Detected 'Canada'. Modifying args to 'France'.\")\n        args['country'] = 'France'\n        print(f\"[Callback] Modified args: {args}\")\n        return None\n\n    # If the tool is 'get_capital_city' and country is 'BLOCK'\n    if tool_name == 'get_capital_city' and args.get('country', '').upper() == 'BLOCK':\n        print(\"[Callback] Detected 'BLOCK'. Skipping tool execution.\")\n        return {\"result\": \"Tool execution was blocked by before_tool_callback.\"}\n\n    print(\"[Callback] Proceeding with original or previously modified args.\")\n    return None\n\nmy_llm_agent = LlmAgent(\n        name=\"ToolCallbackAgent\",\n        model=GEMINI_2_FLASH,\n        instruction=\"You are an agent that can find capital cities. Use the get_capital_city tool.\",\n        description=\"An LLM agent demonstrating before_tool_callback\",\n        tools=[capital_tool],\n        before_tool_callback=simple_before_tool_modifier\n)\n\nAPP_NAME = \"guardrail_app\"\nUSER_ID = \"user_1\"\nSESSION_ID = \"session_001\"\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=my_llm_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n# Agent Interaction\nasync def call_agent_async(query):\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    async for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"Agent Response: \", final_response)\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"Canada\")"}, {"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"regexp\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\n// GetCapitalCityArgs defines the arguments for the getCapitalCity tool.\ntype GetCapitalCityArgs struct {\n    Country string `json:\"country\" jsonschema:\"The country to get the capital of.\"`\n}\n\n// getCapitalCity is a tool that returns the capital of a given country.\nfunc getCapitalCity(ctx tool.Context, args *GetCapitalCityArgs) string {\n    capitals := map[string]string{\n        \"canada\":        \"Ottawa\",\n        \"france\":        \"Paris\",\n        \"germany\":       \"Berlin\",\n        \"united states\": \"Washington, D.C.\",\n    }\n    capital, ok := capitals[strings.ToLower(args.Country)]\n    if !ok {\n        return \"<Unknown>\"\n    }\n    return capital\n}\n\nfunc onBeforeTool(ctx tool.Context, t tool.Tool, args map[string]any) (map[string]any, error) {\n    log.Printf(\"[Callback] BeforeTool triggered for tool %q in agent %q.\", t.Name(), ctx.AgentName())\n    log.Printf(\"[Callback] Original args: %v\", args)\n\n    if t.Name() == \"getCapitalCity\" {\n        if country, ok := args[\"country\"].(string); ok {\n            if strings.ToLower(country) == \"canada\" {\n                log.Println(\"[Callback] Detected 'Canada'. Modifying args to 'France'.\")\n                args[\"country\"] = \"France\"\n                return args, nil // Proceed with modified args\n            } else if strings.ToUpper(country) == \"BLOCK\" {\n                log.Println(\"[Callback] Detected 'BLOCK'. Skipping tool execution.\")\n                // Skip tool and return a custom result.\n                return map[string]any{\"result\": \"Tool execution was blocked by before_tool_callback.\"}, nil\n            }\n        }\n    }\n    log.Println(\"[Callback] Proceeding with original or previously modified args.\")\n    return nil, nil // Proceed with original args\n}\n\nfunc runBeforeToolExample() {\n    ctx := context.Background()\n    geminiModel, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create model: %v\", err)\n    }\n    capitalTool, err := functiontool.New[*GetCapitalCityArgs, string](functiontool.Config{\n        Name:        \"getCapitalCity\",\n        Description: \"Retrieves the capital city of a given country.\",\n    }, getCapitalCity)\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create function tool: %v\", err)\n    }\n\n    llmCfg := llmagent.Config{\n        Name:                \"AgentWithBeforeToolCallback\",\n        Model:               geminiModel,\n        Tools:               []tool.Tool{capitalTool},\n        BeforeToolCallbacks: []llmagent.BeforeToolCallback{onBeforeTool},\n        Instruction:         \"You are an agent that can find capital cities. Use the getCapitalCity tool.\",\n    }\n    testAgent, err := llmagent.New(llmCfg)\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create agent: %v\", err)\n    }\n    sessionService := session.InMemoryService()\n    r, err := runner.New(runner.Config{AppName: appName, Agent: testAgent, SessionService: sessionService})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create runner: %v\", err)\n    }\n\n    log.Println(\"--- SCENARIO 1: Args should be modified ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_tool_modify\", nil, \"What is the capital of Canada?\")\n\n    log.Println(\"--- SCENARIO 2: Tool call should be blocked ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_tool_block\", nil, \"capital of BLOCK\")\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.InvocationContext;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.Annotations.Schema;\nimport com.google.adk.tools.BaseTool;\nimport com.google.adk.tools.FunctionTool;\nimport com.google.adk.tools.ToolContext;\nimport com.google.common.collect.ImmutableMap;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport io.reactivex.rxjava3.core.Maybe;\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class BeforeToolCallbackExample {\n\n  private static final String APP_NAME = \"ToolCallbackAgentApp\";\n  private static final String USER_ID = \"user_1\";\n  private static final String SESSION_ID = \"session_001\";\n  private static final String MODEL_NAME = \"gemini-2.0-flash\";\n\n  public static void main(String[] args) {\n    BeforeToolCallbackExample example = new BeforeToolCallbackExample();\n    example.runAgent(\"capital of canada\");\n  }\n\n  // --- Define a Simple Tool Function ---\n  // The Schema is important for the callback \"args\" to correctly identify the input.\n  public static Map<String, Object> getCapitalCity(\n      @Schema(name = \"country\", description = \"The country to find the capital of.\")\n          String country) {\n    System.out.printf(\"--- Tool 'getCapitalCity' executing with country: %s ---%n\", country);\n    Map<String, String> countryCapitals = new HashMap<>();\n    countryCapitals.put(\"united states\", \"Washington, D.C.\");\n    countryCapitals.put(\"canada\", \"Ottawa\");\n    countryCapitals.put(\"france\", \"Paris\");\n    countryCapitals.put(\"germany\", \"Berlin\");\n\n    String capital =\n        countryCapitals.getOrDefault(country.toLowerCase(), \"Capital not found for \" + country);\n    // FunctionTool expects a Map<String, Object> as the return type for the method it wraps.\n    return ImmutableMap.of(\"capital\", capital);\n  }\n\n  // Define the Callback function\n  // The Tool callback provides all these parameters by default.\n  public Maybe<Map<String, Object>> simpleBeforeToolModifier(\n      InvocationContext invocationContext,\n      BaseTool tool,\n      Map<String, Object> args,\n      ToolContext toolContext) {\n\n    String agentName = invocationContext.agent().name();\n    String toolName = tool.name();\n    System.out.printf(\n        \"[Callback] Before tool call for tool '%s' in agent '%s'%n\", toolName, agentName);\n    System.out.printf(\"[Callback] Original args: %s%n\", args);\n\n    if (\"getCapitalCity\".equals(toolName)) {\n      String countryArg = (String) args.get(\"country\");\n      if (countryArg != null) {\n        if (\"canada\".equalsIgnoreCase(countryArg)) {\n          System.out.println(\"[Callback] Detected 'Canada'. Modifying args to 'France'.\");\n          args.put(\"country\", \"France\");\n          System.out.printf(\"[Callback] Modified args: %s%n\", args);\n          // Proceed with modified args\n          return Maybe.empty();\n        } else if (\"BLOCK\".equalsIgnoreCase(countryArg)) {\n          System.out.println(\"[Callback] Detected 'BLOCK'. Skipping tool execution.\");\n          // Return a map to skip the tool call and use this as the result\n          return Maybe.just(\n              ImmutableMap.of(\"result\", \"Tool execution was blocked by before_tool_callback.\"));\n        }\n      }\n    }\n\n    System.out.println(\"[Callback] Proceeding with original or previously modified args.\");\n    return Maybe.empty();\n  }\n\n  public void runAgent(String query) {\n    // --- Wrap the function into a Tool ---\n    FunctionTool capitalTool = FunctionTool.create(this.getClass(), \"getCapitalCity\");\n\n    // Create LlmAgent and Assign Callback\n    LlmAgent myLlmAgent =\n        LlmAgent.builder()\n            .name(APP_NAME)\n            .model(MODEL_NAME)\n            .instruction(\n                \"You are an agent that can find capital cities. Use the getCapitalCity tool.\")\n            .description(\"An LLM agent demonstrating before_tool_callback\")\n            .tools(capitalTool)\n            .beforeToolCallback(this::simpleBeforeToolModifier)\n            .build();\n\n    // Session and Runner\n    InMemoryRunner runner = new InMemoryRunner(myLlmAgent);\n    Session session =\n        runner.sessionService().createSession(APP_NAME, USER_ID, null, SESSION_ID).blockingGet();\n\n    Content userMessage = Content.fromParts(Part.fromText(query));\n\n    System.out.printf(\"%n--- Calling agent with query: \\\"%s\\\" ---%n\", query);\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n    // Stream event response\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n}"}]}, {"heading_path": ["After Tool Callback\u00b6"], "text": "After Tool Callback \u00b6 When: Called just after the tool's run_async method completes successfully. Purpose: Allows inspection and modification of the tool's result before it's sent back to the LLM (potentially after summarization). Useful for logging tool results, post-processing or formatting results, or saving specific parts of the result to the session state. Return Value Effect: If the callback returns None (or a Maybe.empty() object in Java), the original tool_response is used. If a new dictionary is returned, it replaces the original tool_response . This allows modifying or filtering the result seen by the LLM. Code Python Go Java # Copyright 2025 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from google.adk.agents import LlmAgent from google.adk.runners import Runner from typing import Optional from google.genai import types from google.adk.sessions import InMemorySessionService from google.adk.tools import FunctionTool from google.adk.tools.tool_context import ToolContext from google.adk.tools.base_tool import BaseTool from typing import Dict , Any from copy import deepcopy GEMINI_2_FLASH = \"gemini-2.0-flash\" # --- Define a Simple Tool Function (Same as before) --- def get_capital_city ( country : str ) -> str : \"\"\"Retrieves the capital city of a given country.\"\"\" print ( f \"--- Tool 'get_capital_city' executing with country: { country } ---\" ) country_capitals = { \"united states\" : \"Washington, D.C.\" , \"canada\" : \"Ottawa\" , \"france\" : \"Paris\" , \"germany\" : \"Berlin\" , } return { \"result\" : country_capitals . get ( country . lower (), f \"Capital not found for { country } \" )} # --- Wrap the function into a Tool --- capital_tool = FunctionTool ( func = get_capital_city ) # --- Define the Callback Function --- def simple_after_tool_modifier ( tool : BaseTool , args : Dict [ str , Any ], tool_context : ToolContext , tool_response : Dict ) -> Optional [ Dict ]: \"\"\"Inspects/modifies the tool result after execution.\"\"\" agent_name = tool_context . agent_name tool_name = tool . name print ( f \"[Callback] After tool call for tool ' { tool_name } ' in agent ' { agent_name } '\" ) print ( f \"[Callback] Args used: { args } \" ) print ( f \"[Callback] Original tool_response: { tool_response } \" ) # Default structure for function tool results is {\"result\": <return_value>} original_result_value = tool_response . get ( \"result\" , \"\" ) # original_result_value = tool_response # --- Modification Example --- # If the tool was 'get_capital_city' and result is 'Washington, D.C.' if tool_name == 'get_capital_city' and original_result_value == \"Washington, D.C.\" : print ( \"[Callback] Detected 'Washington, D.C.'. Modifying tool response.\" ) # IMPORTANT: Create a new dictionary or modify a copy modified_response = deepcopy ( tool_response ) modified_response [ \"result\" ] = f \" { original_result_value } (Note: This is the capital of the USA).\" modified_response [ \"note_added_by_callback\" ] = True # Add extra info if needed print ( f \"[Callback] Modified tool_response: { modified_response } \" ) return modified_response # Return the modified dictionary print ( \"[Callback] Passing original tool response through.\" ) # Return None to use the original tool_response return None # Create LlmAgent and Assign Callback my_llm_agent = LlmAgent ( name = \"AfterToolCallbackAgent\" , model = GEMINI_2_FLASH , instruction = \"You are an agent that finds capital cities using the get_capital_city tool. Report the result clearly.\" , description = \"An LLM agent demonstrating after_tool_callback\" , tools = [ capital_tool ], # Add the tool after_tool_callback = simple_after_tool_modifier # Assign the callback ) APP_NAME = \"guardrail_app\" USER_ID = \"user_1\" SESSION_ID = \"session_001\" # Session and Runner async def setup_session_and_runner (): session_service = InMemorySessionService () session = await session_service . create_session ( app_name = APP_NAME , user_id = USER_ID , session_id = SESSION_ID ) runner = Runner ( agent = my_llm_agent , app_name = APP_NAME , session_service = session_service ) return session , runner # Agent Interaction async def call_agent_async ( query ): content = types . Content ( role = 'user' , parts = [ types . Part ( text = query )]) session , runner = await setup_session_and_runner () events = runner . run_async ( user_id = USER_ID , session_id = SESSION_ID , new_message = content ) async for event in events : if event . is_final_response (): final_response = event . content . parts [ 0 ] . text print ( \"Agent Response: \" , final_response ) # Note: In Colab, you can directly use 'await' at the top level. # If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop. await call_agent_async ( \"united states\" ) package main import ( \"context\" \"fmt\" \"log\" \"regexp\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/model\" \"google.golang.org/adk/model/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/session\" \"google.golang.org/adk/tool\" \"google.golang.org/adk/tool/functiontool\" \"google.golang.org/genai\" ) // GetCapitalCityArgs defines the arguments for the getCapitalCity tool. type GetCapitalCityArgs struct { Country string `json:\"country\" jsonschema:\"The country to get the capital of.\"` } // getCapitalCity is a tool that returns the capital of a given country. func getCapitalCity ( ctx tool . Context , args * GetCapitalCityArgs ) string { capitals := map [ string ] string { \"canada\" : \"Ottawa\" , \"france\" : \"Paris\" , \"germany\" : \"Berlin\" , \"united states\" : \"Washington, D.C.\" , } capital , ok := capitals [ strings . ToLower ( args . Country )] if ! ok { return \"<Unknown>\" } return capital } func onAfterTool ( ctx tool . Context , t tool . Tool , args map [ string ] any , result map [ string ] any , err error ) ( map [ string ] any , error ) { log . Printf ( \"[Callback] AfterTool triggered for tool %q in agent %q.\" , t . Name (), ctx . AgentName ()) log . Printf ( \"[Callback] Original result: %v\" , result ) if err != nil { log . Printf ( \"[Callback] Tool run produced an error: %v. Passing through.\" , err ) return nil , err } if t . Name () == \"getCapitalCity\" { if originalResult , ok := result [ \"result\" ].( string ); ok && originalResult == \"Washington, D.C.\" { log . Println ( \"[Callback] Detected 'Washington, D.C.'. Modifying tool response.\" ) modifiedResult := make ( map [ string ] any ) for k , v := range result { modifiedResult [ k ] = v } modifiedResult [ \"result\" ] = fmt . Sprintf ( \"%s (Note: This is the capital of the USA).\" , originalResult ) modifiedResult [ \"note_added_by_callback\" ] = true return modifiedResult , nil } } log . Println ( \"[Callback] Passing original tool response through.\" ) return nil , nil } func runAfterToolExample () { ctx := context . Background () geminiModel , err := gemini . NewModel ( ctx , modelName , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"FATAL: Failed to create model: %v\" , err ) } capitalTool , err := functiontool . New [ * GetCapitalCityArgs , string ]( functiontool . Config { Name : \"getCapitalCity\" , Description : \"Retrieves the capital city of a given country.\" , }, getCapitalCity ) if err != nil { log . Fatalf ( \"FATAL: Failed to create function tool: %v\" , err ) } llmCfg := llmagent . Config { Name : \"AgentWithAfterToolCallback\" , Model : geminiModel , Tools : [] tool . Tool { capitalTool }, AfterToolCallbacks : [] llmagent . AfterToolCallback { onAfterTool }, Instruction : \"You are an agent that finds capital cities. Use the getCapitalCity tool.\" , } testAgent , err := llmagent . New ( llmCfg ) if err != nil { log . Fatalf ( \"FATAL: Failed to create agent: %v\" , err ) } sessionService := session . InMemoryService () r , err := runner . New ( runner . Config { AppName : appName , Agent : testAgent , SessionService : sessionService }) if err != nil { log . Fatalf ( \"FATAL: Failed to create runner: %v\" , err ) } log . Println ( \"--- SCENARIO 1: Result should be modified ---\" ) runScenario ( ctx , r , sessionService , appName , \"session_tool_after_modify\" , nil , \"capital of united states\" ) } import com.google.adk.agents.LlmAgent ; import com.google.adk.agents.InvocationContext ; import com.google.adk.events.Event ; import com.google.adk.runner.InMemoryRunner ; import com.google.adk.sessions.Session ; import com.google.adk.tools.Annotations.Schema ; import com.google.adk.tools.BaseTool ; import com.google.adk.tools.FunctionTool ; import com.google.adk.tools.ToolContext ; import com.google.common.collect.ImmutableMap ; import com.google.genai.types.Content ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.Flowable ; import io.reactivex.rxjava3.core.Maybe ; import java.util.HashMap ; import java.util.Map ; public class AfterToolCallbackExample { private static final String APP_NAME = \"AfterToolCallbackAgentApp\" ; private static final String USER_ID = \"user_1\" ; private static final String SESSION_ID = \"session_001\" ; private static final String MODEL_NAME = \"gemini-2.0-flash\" ; public static void main ( String [] args ) { AfterToolCallbackExample example = new AfterToolCallbackExample (); example . runAgent ( \"What is the capital of the United States?\" ); } // --- Define a Simple Tool Function (Same as before) --- @Schema ( description = \"Retrieves the capital city of a given country.\" ) public static Map < String , Object > getCapitalCity ( @Schema ( description = \"The country to find the capital of.\" ) String country ) { System . out . printf ( \"--- Tool 'getCapitalCity' executing with country: %s ---%n\" , country ); Map < String , String > countryCapitals = new HashMap <> (); countryCapitals . put ( \"united states\" , \"Washington, D.C.\" ); countryCapitals . put ( \"canada\" , \"Ottawa\" ); countryCapitals . put ( \"france\" , \"Paris\" ); countryCapitals . put ( \"germany\" , \"Berlin\" ); String capital = countryCapitals . getOrDefault ( country . toLowerCase (), \"Capital not found for \" + country ); return ImmutableMap . of ( \"result\" , capital ); } // Define the Callback function. public Maybe < Map < String , Object >> simpleAfterToolModifier ( InvocationContext invocationContext , BaseTool tool , Map < String , Object > args , ToolContext toolContext , Object toolResponse ) { // Inspects/modifies the tool result after execution. String agentName = invocationContext . agent (). name (); String toolName = tool . name (); System . out . printf ( \"[Callback] After tool call for tool '%s' in agent '%s'%n\" , toolName , agentName ); System . out . printf ( \"[Callback] Args used: %s%n\" , args ); System . out . printf ( \"[Callback] Original tool_response: %s%n\" , toolResponse ); if ( ! ( toolResponse instanceof Map )) { System . out . println ( \"[Callback] toolResponse is not a Map, cannot process further.\" ); // Pass through if not a map return Maybe . empty (); } // Default structure for function tool results is {\"result\": <return_value>} @SuppressWarnings ( \"unchecked\" ) Map < String , Object > responseMap = ( Map < String , Object > ) toolResponse ; Object originalResultValue = responseMap . get ( \"result\" ); // --- Modification Example --- // If the tool was 'get_capital_city' and result is 'Washington, D.C.' if ( \"getCapitalCity\" . equals ( toolName ) && \"Washington, D.C.\" . equals ( originalResultValue )) { System . out . println ( \"[Callback] Detected 'Washington, D.C.'. Modifying tool response.\" ); // IMPORTANT: Create a new mutable map or modify a copy Map < String , Object > modifiedResponse = new HashMap <> ( responseMap ); modifiedResponse . put ( \"result\" , originalResultValue + \" (Note: This is the capital of the USA).\" ); modifiedResponse . put ( \"note_added_by_callback\" , true ); // Add extra info if needed System . out . printf ( \"[Callback] Modified tool_response: %s%n\" , modifiedResponse ); return Maybe . just ( modifiedResponse ); } System . out . println ( \"[Callback] Passing original tool response through.\" ); // Return Maybe.empty() to use the original tool_response return Maybe . empty (); } public void runAgent ( String query ) { // --- Wrap the function into a Tool --- FunctionTool capitalTool = FunctionTool . create ( this . getClass (), \"getCapitalCity\" ); // Create LlmAgent and Assign Callback LlmAgent myLlmAgent = LlmAgent . builder () . name ( APP_NAME ) . model ( MODEL_NAME ) . instruction ( \"You are an agent that finds capital cities using the getCapitalCity tool. Report\" + \" the result clearly.\" ) . description ( \"An LLM agent demonstrating after_tool_callback\" ) . tools ( capitalTool ) // Add the tool . afterToolCallback ( this :: simpleAfterToolModifier ) // Assign the callback . build (); InMemoryRunner runner = new InMemoryRunner ( myLlmAgent ); // Session and Runner Session session = runner . sessionService (). createSession ( APP_NAME , USER_ID , null , SESSION_ID ). blockingGet (); Content userMessage = Content . fromParts ( Part . fromText ( query )); System . out . printf ( \"%n--- Calling agent with query: \\\"%s\\\" ---%n\" , query ); Flowable < Event > eventStream = runner . runAsync ( USER_ID , session . id (), userMessage ); // Stream event response eventStream . blockingForEach ( event -> { if ( event . finalResponse ()) { System . out . println ( event . stringifyContent ()); } }); } } Back to top ", "code_blocks": [{"language": "text", "code": "# Copyright 2025 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.runners import Runner\nfrom typing import Optional\nfrom google.genai import types \nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import FunctionTool\nfrom google.adk.tools.tool_context import ToolContext\nfrom google.adk.tools.base_tool import BaseTool\nfrom typing import Dict, Any\nfrom copy import deepcopy\n\nGEMINI_2_FLASH=\"gemini-2.0-flash\"\n\n# --- Define a Simple Tool Function (Same as before) ---\ndef get_capital_city(country: str) -> str:\n    \"\"\"Retrieves the capital city of a given country.\"\"\"\n    print(f\"--- Tool 'get_capital_city' executing with country: {country} ---\")\n    country_capitals = {\n        \"united states\": \"Washington, D.C.\",\n        \"canada\": \"Ottawa\",\n        \"france\": \"Paris\",\n        \"germany\": \"Berlin\",\n    }\n    return {\"result\": country_capitals.get(country.lower(), f\"Capital not found for {country}\")}\n\n# --- Wrap the function into a Tool ---\ncapital_tool = FunctionTool(func=get_capital_city)\n\n# --- Define the Callback Function ---\ndef simple_after_tool_modifier(\n    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext, tool_response: Dict\n) -> Optional[Dict]:\n    \"\"\"Inspects/modifies the tool result after execution.\"\"\"\n    agent_name = tool_context.agent_name\n    tool_name = tool.name\n    print(f\"[Callback] After tool call for tool '{tool_name}' in agent '{agent_name}'\")\n    print(f\"[Callback] Args used: {args}\")\n    print(f\"[Callback] Original tool_response: {tool_response}\")\n\n    # Default structure for function tool results is {\"result\": <return_value>}\n    original_result_value = tool_response.get(\"result\", \"\")\n    # original_result_value = tool_response\n\n    # --- Modification Example ---\n    # If the tool was 'get_capital_city' and result is 'Washington, D.C.'\n    if tool_name == 'get_capital_city' and original_result_value == \"Washington, D.C.\":\n        print(\"[Callback] Detected 'Washington, D.C.'. Modifying tool response.\")\n\n        # IMPORTANT: Create a new dictionary or modify a copy\n        modified_response = deepcopy(tool_response)\n        modified_response[\"result\"] = f\"{original_result_value} (Note: This is the capital of the USA).\"\n        modified_response[\"note_added_by_callback\"] = True # Add extra info if needed\n\n        print(f\"[Callback] Modified tool_response: {modified_response}\")\n        return modified_response # Return the modified dictionary\n\n    print(\"[Callback] Passing original tool response through.\")\n    # Return None to use the original tool_response\n    return None\n\n\n# Create LlmAgent and Assign Callback\nmy_llm_agent = LlmAgent(\n        name=\"AfterToolCallbackAgent\",\n        model=GEMINI_2_FLASH,\n        instruction=\"You are an agent that finds capital cities using the get_capital_city tool. Report the result clearly.\",\n        description=\"An LLM agent demonstrating after_tool_callback\",\n        tools=[capital_tool], # Add the tool\n        after_tool_callback=simple_after_tool_modifier # Assign the callback\n    )\n\nAPP_NAME = \"guardrail_app\"\nUSER_ID = \"user_1\"\nSESSION_ID = \"session_001\"\n\n# Session and Runner\nasync def setup_session_and_runner():\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n    runner = Runner(agent=my_llm_agent, app_name=APP_NAME, session_service=session_service)\n    return session, runner\n\n\n# Agent Interaction\nasync def call_agent_async(query):\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    session, runner = await setup_session_and_runner()\n    events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n\n    async for event in events:\n        if event.is_final_response():\n            final_response = event.content.parts[0].text\n            print(\"Agent Response: \", final_response)\n\n# Note: In Colab, you can directly use 'await' at the top level.\n# If running this code as a standalone Python script, you'll need to use asyncio.run() or manage the event loop.\nawait call_agent_async(\"united states\")"}, {"language": "text", "code": "package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"regexp\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/model\"\n    \"google.golang.org/adk/model/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/adk/tool\"\n    \"google.golang.org/adk/tool/functiontool\"\n    \"google.golang.org/genai\"\n)\n\n// GetCapitalCityArgs defines the arguments for the getCapitalCity tool.\ntype GetCapitalCityArgs struct {\n    Country string `json:\"country\" jsonschema:\"The country to get the capital of.\"`\n}\n\n// getCapitalCity is a tool that returns the capital of a given country.\nfunc getCapitalCity(ctx tool.Context, args *GetCapitalCityArgs) string {\n    capitals := map[string]string{\n        \"canada\":        \"Ottawa\",\n        \"france\":        \"Paris\",\n        \"germany\":       \"Berlin\",\n        \"united states\": \"Washington, D.C.\",\n    }\n    capital, ok := capitals[strings.ToLower(args.Country)]\n    if !ok {\n        return \"<Unknown>\"\n    }\n    return capital\n}\n\nfunc onAfterTool(ctx tool.Context, t tool.Tool, args map[string]any, result map[string]any, err error) (map[string]any, error) {\n    log.Printf(\"[Callback] AfterTool triggered for tool %q in agent %q.\", t.Name(), ctx.AgentName())\n    log.Printf(\"[Callback] Original result: %v\", result)\n\n    if err != nil {\n        log.Printf(\"[Callback] Tool run produced an error: %v. Passing through.\", err)\n        return nil, err\n    }\n\n    if t.Name() == \"getCapitalCity\" {\n        if originalResult, ok := result[\"result\"].(string); ok && originalResult == \"Washington, D.C.\" {\n            log.Println(\"[Callback] Detected 'Washington, D.C.'. Modifying tool response.\")\n            modifiedResult := make(map[string]any)\n            for k, v := range result {\n                modifiedResult[k] = v\n            }\n            modifiedResult[\"result\"] = fmt.Sprintf(\"%s (Note: This is the capital of the USA).\", originalResult)\n            modifiedResult[\"note_added_by_callback\"] = true\n            return modifiedResult, nil\n        }\n    }\n\n    log.Println(\"[Callback] Passing original tool response through.\")\n    return nil, nil\n}\n\nfunc runAfterToolExample() {\n    ctx := context.Background()\n    geminiModel, err := gemini.NewModel(ctx, modelName, &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create model: %v\", err)\n    }\n    capitalTool, err := functiontool.New[*GetCapitalCityArgs, string](functiontool.Config{\n        Name:        \"getCapitalCity\",\n        Description: \"Retrieves the capital city of a given country.\",\n    }, getCapitalCity)\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create function tool: %v\", err)\n    }\n\n    llmCfg := llmagent.Config{\n        Name:               \"AgentWithAfterToolCallback\",\n        Model:              geminiModel,\n        Tools:              []tool.Tool{capitalTool},\n        AfterToolCallbacks: []llmagent.AfterToolCallback{onAfterTool},\n        Instruction:        \"You are an agent that finds capital cities. Use the getCapitalCity tool.\",\n    }\n    testAgent, err := llmagent.New(llmCfg)\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create agent: %v\", err)\n    }\n    sessionService := session.InMemoryService()\n    r, err := runner.New(runner.Config{AppName: appName, Agent: testAgent, SessionService: sessionService})\n    if err != nil {\n        log.Fatalf(\"FATAL: Failed to create runner: %v\", err)\n    }\n\n    log.Println(\"--- SCENARIO 1: Result should be modified ---\")\n    runScenario(ctx, r, sessionService, appName, \"session_tool_after_modify\", nil, \"capital of united states\")\n}"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.agents.InvocationContext;\nimport com.google.adk.events.Event;\nimport com.google.adk.runner.InMemoryRunner;\nimport com.google.adk.sessions.Session;\nimport com.google.adk.tools.Annotations.Schema;\nimport com.google.adk.tools.BaseTool;\nimport com.google.adk.tools.FunctionTool;\nimport com.google.adk.tools.ToolContext;\nimport com.google.common.collect.ImmutableMap;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.Flowable;\nimport io.reactivex.rxjava3.core.Maybe;\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class AfterToolCallbackExample {\n\n  private static final String APP_NAME = \"AfterToolCallbackAgentApp\";\n  private static final String USER_ID = \"user_1\";\n  private static final String SESSION_ID = \"session_001\";\n  private static final String MODEL_NAME = \"gemini-2.0-flash\";\n\n  public static void main(String[] args) {\n    AfterToolCallbackExample example = new AfterToolCallbackExample();\n    example.runAgent(\"What is the capital of the United States?\");\n  }\n\n  // --- Define a Simple Tool Function (Same as before) ---\n  @Schema(description = \"Retrieves the capital city of a given country.\")\n  public static Map<String, Object> getCapitalCity(\n      @Schema(description = \"The country to find the capital of.\") String country) {\n    System.out.printf(\"--- Tool 'getCapitalCity' executing with country: %s ---%n\", country);\n    Map<String, String> countryCapitals = new HashMap<>();\n    countryCapitals.put(\"united states\", \"Washington, D.C.\");\n    countryCapitals.put(\"canada\", \"Ottawa\");\n    countryCapitals.put(\"france\", \"Paris\");\n    countryCapitals.put(\"germany\", \"Berlin\");\n\n    String capital =\n        countryCapitals.getOrDefault(country.toLowerCase(), \"Capital not found for \" + country);\n    return ImmutableMap.of(\"result\", capital);\n  }\n\n  // Define the Callback function.\n  public Maybe<Map<String, Object>> simpleAfterToolModifier(\n      InvocationContext invocationContext,\n      BaseTool tool,\n      Map<String, Object> args,\n      ToolContext toolContext,\n      Object toolResponse) {\n\n    // Inspects/modifies the tool result after execution.\n    String agentName = invocationContext.agent().name();\n    String toolName = tool.name();\n    System.out.printf(\n        \"[Callback] After tool call for tool '%s' in agent '%s'%n\", toolName, agentName);\n    System.out.printf(\"[Callback] Args used: %s%n\", args);\n    System.out.printf(\"[Callback] Original tool_response: %s%n\", toolResponse);\n\n    if (!(toolResponse instanceof Map)) {\n      System.out.println(\"[Callback] toolResponse is not a Map, cannot process further.\");\n      // Pass through if not a map\n      return Maybe.empty();\n    }\n\n    // Default structure for function tool results is {\"result\": <return_value>}\n    @SuppressWarnings(\"unchecked\")\n    Map<String, Object> responseMap = (Map<String, Object>) toolResponse;\n    Object originalResultValue = responseMap.get(\"result\");\n\n    // --- Modification Example ---\n    // If the tool was 'get_capital_city' and result is 'Washington, D.C.'\n    if (\"getCapitalCity\".equals(toolName) && \"Washington, D.C.\".equals(originalResultValue)) {\n      System.out.println(\"[Callback] Detected 'Washington, D.C.'. Modifying tool response.\");\n\n      // IMPORTANT: Create a new mutable map or modify a copy\n      Map<String, Object> modifiedResponse = new HashMap<>(responseMap);\n      modifiedResponse.put(\n          \"result\", originalResultValue + \" (Note: This is the capital of the USA).\");\n      modifiedResponse.put(\"note_added_by_callback\", true); // Add extra info if needed\n\n      System.out.printf(\"[Callback] Modified tool_response: %s%n\", modifiedResponse);\n      return Maybe.just(modifiedResponse);\n    }\n\n    System.out.println(\"[Callback] Passing original tool response through.\");\n    // Return Maybe.empty() to use the original tool_response\n    return Maybe.empty();\n  }\n\n  public void runAgent(String query) {\n    // --- Wrap the function into a Tool ---\n    FunctionTool capitalTool = FunctionTool.create(this.getClass(), \"getCapitalCity\");\n\n    // Create LlmAgent and Assign Callback\n    LlmAgent myLlmAgent =\n        LlmAgent.builder()\n            .name(APP_NAME)\n            .model(MODEL_NAME)\n            .instruction(\n                \"You are an agent that finds capital cities using the getCapitalCity tool. Report\"\n                    + \" the result clearly.\")\n            .description(\"An LLM agent demonstrating after_tool_callback\")\n            .tools(capitalTool) // Add the tool\n            .afterToolCallback(this::simpleAfterToolModifier) // Assign the callback\n            .build();\n\n    InMemoryRunner runner = new InMemoryRunner(myLlmAgent);\n\n    // Session and Runner\n    Session session =\n        runner.sessionService().createSession(APP_NAME, USER_ID, null, SESSION_ID).blockingGet();\n\n    Content userMessage = Content.fromParts(Part.fromText(query));\n\n    System.out.printf(\"%n--- Calling agent with query: \\\"%s\\\" ---%n\", query);\n    Flowable<Event> eventStream = runner.runAsync(USER_ID, session.id(), userMessage);\n    // Stream event response\n    eventStream.blockingForEach(\n        event -> {\n          if (event.finalResponse()) {\n            System.out.println(event.stringifyContent());\n          }\n        });\n  }\n}"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:38.218087", "source_type": "adk-docs"}
{"doc_id": "68d806c94aff6ec5cb2e3e34995aceef4bdba19597ae880393a06f3945769b7b", "url": "https://google.github.io/adk-docs/callbacks/design-patterns-and-best-practices", "title": "Callback patterns - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Design Patterns and Best Practices for Callbacks\u00b6"], "text": "Design Patterns and Best Practices for Callbacks \u00b6 Callbacks offer powerful hooks into the agent lifecycle. Here are common design patterns illustrating how to leverage them effectively in ADK, followed by best practices for implementation. ", "code_blocks": []}, {"heading_path": ["Design Patterns\u00b6"], "text": "Design Patterns \u00b6 These patterns demonstrate typical ways to enhance or control agent behavior using callbacks: ", "code_blocks": []}, {"heading_path": ["1. Guardrails & Policy Enforcement\u00b6"], "text": "1. Guardrails & Policy Enforcement \u00b6 Pattern Overview: Intercept requests before they reach the LLM or tools to enforce rules. Implementation: - Use before_model_callback to inspect the LlmRequest prompt\n- Use before_tool_callback to inspect tool arguments\n- If a policy violation is detected (e.g., forbidden topics, profanity):\n  - Return a predefined response ( LlmResponse or dict / Map ) to block the operation\n  - Optionally update context.state to log the violation Example Use Case: A before_model_callback checks llm_request.contents for sensitive keywords and returns a standard \"Cannot process this request\" LlmResponse if found, preventing the LLM call. ", "code_blocks": []}, {"heading_path": ["2. Dynamic State Management\u00b6"], "text": "2. Dynamic State Management \u00b6 Pattern Overview: Read from and write to session state within callbacks to make agent behavior context-aware and pass data between steps. Implementation: - Access callback_context.state or tool_context.state - Modifications ( state['key'] = value ) are automatically tracked in the subsequent Event.actions.state_delta - Changes are persisted by the SessionService Example Use Case: An after_tool_callback saves a transaction_id from the tool's result to tool_context.state['last_transaction_id'] . A later before_agent_callback might read state['user_tier'] to customize the agent's greeting. ", "code_blocks": []}, {"heading_path": ["3. Logging and Monitoring\u00b6"], "text": "3. Logging and Monitoring \u00b6 Pattern Overview: Add detailed logging at specific lifecycle points for observability and debugging. Implementation: - Implement callbacks (e.g., before_agent_callback , after_tool_callback , after_model_callback )\n- Print or send structured logs containing:\n  - Agent name\n  - Tool name\n  - Invocation ID\n  - Relevant data from the context or arguments Example Use Case: Log messages like INFO: [Invocation: e-123] Before Tool: search_api - Args: {'query': 'ADK'} . ", "code_blocks": []}, {"heading_path": ["4. Caching\u00b6"], "text": "4. Caching \u00b6 Pattern Overview: Avoid redundant LLM calls or tool executions by caching results. Implementation Steps: 1. Before Operation: In before_model_callback or before_tool_callback :\n   - Generate a cache key based on the request/arguments\n   - Check context.state (or an external cache) for this key\n   - If found, return the cached LlmResponse or result directly After Operation: If cache miss occurred: Use the corresponding after_ callback to store the new result in the cache using the key Example Use Case: before_tool_callback for get_stock_price(symbol) checks state[f\"cache:stock:{symbol}\"] . If present, returns the cached price; otherwise, allows the API call and after_tool_callback saves the result to the state key. ", "code_blocks": []}, {"heading_path": ["5. Request/Response Modification\u00b6"], "text": "5. Request/Response Modification \u00b6 Pattern Overview: Alter data just before it's sent to the LLM/tool or just after it's received. Implementation Options: - before_model_callback : Modify llm_request (e.g., add system instructions based on state )\n- after_model_callback : Modify the returned LlmResponse (e.g., format text, filter content)\n- before_tool_callback : Modify the tool args dictionary (or Map in Java)\n- after_tool_callback : Modify the tool_response dictionary (or Map in Java) Example Use Case: before_model_callback appends \"User language preference: Spanish\" to llm_request.config.system_instruction if context.state['lang'] == 'es' . ", "code_blocks": []}, {"heading_path": ["6. Conditional Skipping of Steps\u00b6"], "text": "6. Conditional Skipping of Steps \u00b6 Pattern Overview: Prevent standard operations (agent run, LLM call, tool execution) based on certain conditions. Implementation: - Return a value from a before_ callback to skip the normal execution:\n  - Content from before_agent_callback - LlmResponse from before_model_callback - dict from before_tool_callback - The framework interprets this returned value as the result for that step Example Use Case: before_tool_callback checks tool_context.state['api_quota_exceeded'] . If True , it returns {'error': 'API quota exceeded'} , preventing the actual tool function from running. ", "code_blocks": []}, {"heading_path": ["7. Tool-Specific Actions (Authentication & Summarization Control)\u00b6"], "text": "7. Tool-Specific Actions (Authentication & Summarization Control) \u00b6 Pattern Overview: Handle actions specific to the tool lifecycle, primarily authentication and controlling LLM summarization of tool results. Implementation: Use ToolContext within tool callbacks ( before_tool_callback , after_tool_callback ): Authentication: Call tool_context.request_credential(auth_config) in before_tool_callback if credentials are required but not found (e.g., via tool_context.get_auth_response or state check). This initiates the auth flow. Summarization: Set tool_context.actions.skip_summarization = True if the raw dictionary output of the tool should be passed back to the LLM or potentially displayed directly, bypassing the default LLM summarization step. Example Use Case: A before_tool_callback for a secure API checks for an auth token in state; if missing, it calls request_credential . An after_tool_callback for a tool returning structured JSON might set skip_summarization = True . ", "code_blocks": []}, {"heading_path": ["8. Artifact Handling\u00b6"], "text": "8. Artifact Handling \u00b6 Pattern Overview: Save or load session-related files or large data blobs during the agent lifecycle. Implementation: - Saving: Use callback_context.save_artifact / await tool_context.save_artifact to store data:\n  - Generated reports\n  - Logs\n  - Intermediate data\n- Loading: Use load_artifact to retrieve previously stored artifacts\n- Tracking: Changes are tracked via Event.actions.artifact_delta Example Use Case: An after_tool_callback for a \"generate_report\" tool saves the output file using await tool_context.save_artifact(\"report.pdf\", report_part) . A before_agent_callback might load a configuration artifact using callback_context.load_artifact(\"agent_config.json\") . ", "code_blocks": []}, {"heading_path": ["Best Practices for Callbacks\u00b6"], "text": "Best Practices for Callbacks \u00b6 ", "code_blocks": []}, {"heading_path": ["Design Principles\u00b6"], "text": "Design Principles \u00b6 Keep Focused: Design each callback for a single, well-defined purpose (e.g., just logging, just validation). Avoid monolithic callbacks. Mind Performance: Callbacks execute synchronously within the agent's processing loop. Avoid long-running or blocking operations (network calls, heavy computation). Offload if necessary, but be aware this adds complexity. ", "code_blocks": []}, {"heading_path": ["Error Handling\u00b6"], "text": "Error Handling \u00b6 Handle Errors Gracefully: - Use try...except/catch blocks within your callback functions\n- Log errors appropriately\n- Decide if the agent invocation should halt or attempt recovery\n- Don't let callback errors crash the entire process ", "code_blocks": []}, {"heading_path": ["State Management\u00b6"], "text": "State Management \u00b6 Manage State Carefully: - Be deliberate about reading from and writing to context.state - Changes are immediately visible within the current invocation and persisted at the end of the event processing\n- Use specific state keys rather than modifying broad structures to avoid unintended side effects\n- Consider using state prefixes ( State.APP_PREFIX , State.USER_PREFIX , State.TEMP_PREFIX ) for clarity, especially with persistent SessionService implementations ", "code_blocks": []}, {"heading_path": ["Reliability\u00b6"], "text": "Reliability \u00b6 Consider Idempotency: If a callback performs actions with external side effects (e.g., incrementing an external counter), design it to be idempotent (safe to run multiple times with the same input) if possible, to handle potential retries in the framework or your application. ", "code_blocks": []}, {"heading_path": ["Testing & Documentation\u00b6"], "text": "Testing & Documentation \u00b6 Test Thoroughly: - Unit test your callback functions using mock context objects\n- Perform integration tests to ensure callbacks function correctly within the full agent flow Ensure Clarity: - Use descriptive names for your callback functions\n- Add clear docstrings explaining their purpose, when they run, and any side effects (especially state modifications) Use Correct Context Type: Always use the specific context type provided ( CallbackContext for agent/model, ToolContext for tools) to ensure access to the appropriate methods and properties. By applying these patterns and best practices, you can effectively use callbacks to create more robust, observable, and customized agent behaviors in ADK. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:38.362280", "source_type": "adk-docs"}
{"doc_id": "72ed4903d53004d7a0bfc42854c7cc20d7eec34b6ecd3d63a89344bee96e3f61", "url": "https://google.github.io/adk-docs/artifacts", "title": "Artifacts - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Artifacts\u00b6"], "text": "Artifacts \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 In ADK, Artifacts represent a crucial mechanism for managing named, versioned binary data associated either with a specific user interaction session or persistently with a user across multiple sessions. They allow your agents and tools to handle data beyond simple text strings, enabling richer interactions involving files, images, audio, and other binary formats. Note The specific parameters or method names for the primitives may vary slightly by SDK language (e.g., save_artifact in Python, saveArtifact in Java). Refer to the language-specific API documentation for details. ", "code_blocks": []}, {"heading_path": ["What are Artifacts?\u00b6"], "text": "What are Artifacts? \u00b6 Definition: An Artifact is essentially a piece of binary data (like the content of a file) identified by a unique filename string within a specific scope (session or user). Each time you save an artifact with the same filename, a new version is created. Representation: Artifacts are consistently represented using the standard google.genai.types.Part object. The core data is typically stored within an inline data structure of the Part (accessed via inline_data ), which itself contains: data : The raw binary content as bytes. mime_type : A string indicating the type of the data (e.g., \"image/png\" , \"application/pdf\" ). This is essential for correctly interpreting the data later. Python Go Java # Example of how an artifact might be represented as a types.Part import google.genai.types as types # Assume 'image_bytes' contains the binary data of a PNG image image_bytes = b ' \\x89 PNG \\r\\n\\x1a\\n ...' # Placeholder for actual image bytes image_artifact = types . Part ( inline_data = types . Blob ( mime_type = \"image/png\" , data = image_bytes ) ) # You can also use the convenience constructor: # image_artifact_alt = types.Part.from_bytes(data=image_bytes, mime_type=\"image/png\") print ( f \"Artifact MIME Type: { image_artifact . inline_data . mime_type } \" ) print ( f \"Artifact Data (first 10 bytes): { image_artifact . inline_data . data [: 10 ] } ...\" ) import ( \"log\" \"google.golang.org/genai\" ) // Create a byte slice with the image data. imageBytes , err := os . ReadFile ( \"image.png\" ) if err != nil { log . Fatalf ( \"Failed to read image file: %v\" , err ) } // Create a new artifact with the image data. imageArtifact := & genai . Part { InlineData : & genai . Blob { MIMEType : \"image/png\" , Data : imageBytes , }, } log . Printf ( \"Artifact MIME Type: %s\" , imageArtifact . InlineData . MIMEType ) log . Printf ( \"Artifact Data (first 8 bytes): %x...\" , imageArtifact . InlineData . Data [: 8 ]) import com.google.genai.types.Part ; import java.nio.charset.StandardCharsets ; public class ArtifactExample { public static void main ( String [] args ) { // Assume 'imageBytes' contains the binary data of a PNG image byte [] imageBytes = {( byte ) 0x89 , ( byte ) 0x50 , ( byte ) 0x4E , ( byte ) 0x47 , ( byte ) 0x0D , ( byte ) 0x0A , ( byte ) 0x1A , ( byte ) 0x0A , ( byte ) 0x01 , ( byte ) 0x02 }; // Placeholder for actual image bytes // Create an image artifact using Part.fromBytes Part imageArtifact = Part . fromBytes ( imageBytes , \"image/png\" ); System . out . println ( \"Artifact MIME Type: \" + imageArtifact . inlineData (). get (). mimeType (). get ()); System . out . println ( \"Artifact Data (first 10 bytes): \" + new String ( imageArtifact . inlineData (). get (). data (). get (), 0 , 10 , StandardCharsets . UTF_8 ) + \"...\" ); } } Persistence & Management: Artifacts are not stored directly within the agent or session state. Their storage and retrieval are managed by a dedicated Artifact Service (an implementation of BaseArtifactService , defined in google.adk.artifacts . ADK provides various implementations, such as: An in-memory service for testing or temporary storage (e.g., InMemoryArtifactService in Python, defined in google.adk.artifacts.in_memory_artifact_service.py ). A service for persistent storage using Google Cloud Storage (GCS) (e.g., GcsArtifactService in Python, defined in google.adk.artifacts.gcs_artifact_service.py ).\nThe chosen service implementation handles versioning automatically when you save data. ", "code_blocks": [{"language": "text", "code": "# Example of how an artifact might be represented as a types.Part\nimport google.genai.types as types\n\n# Assume 'image_bytes' contains the binary data of a PNG image\nimage_bytes = b'\\x89PNG\\r\\n\\x1a\\n...' # Placeholder for actual image bytes\n\nimage_artifact = types.Part(\n    inline_data=types.Blob(\n        mime_type=\"image/png\",\n        data=image_bytes\n    )\n)\n\n# You can also use the convenience constructor:\n# image_artifact_alt = types.Part.from_bytes(data=image_bytes, mime_type=\"image/png\")\n\nprint(f\"Artifact MIME Type: {image_artifact.inline_data.mime_type}\")\nprint(f\"Artifact Data (first 10 bytes): {image_artifact.inline_data.data[:10]}...\")"}, {"language": "text", "code": "import (\n    \"log\"\n\n    \"google.golang.org/genai\"\n)\n\n// Create a byte slice with the image data.\nimageBytes, err := os.ReadFile(\"image.png\")\nif err != nil {\n    log.Fatalf(\"Failed to read image file: %v\", err)\n}\n\n// Create a new artifact with the image data.\nimageArtifact := &genai.Part{\n    InlineData: &genai.Blob{\n        MIMEType: \"image/png\",\n        Data:     imageBytes,\n    },\n}\nlog.Printf(\"Artifact MIME Type: %s\", imageArtifact.InlineData.MIMEType)\nlog.Printf(\"Artifact Data (first 8 bytes): %x...\", imageArtifact.InlineData.Data[:8])"}, {"language": "text", "code": "import com.google.genai.types.Part;\nimport java.nio.charset.StandardCharsets;\n\npublic class ArtifactExample {\n    public static void main(String[] args) {\n        // Assume 'imageBytes' contains the binary data of a PNG image\n        byte[] imageBytes = {(byte) 0x89, (byte) 0x50, (byte) 0x4E, (byte) 0x47, (byte) 0x0D, (byte) 0x0A, (byte) 0x1A, (byte) 0x0A, (byte) 0x01, (byte) 0x02}; // Placeholder for actual image bytes\n\n        // Create an image artifact using Part.fromBytes\n        Part imageArtifact = Part.fromBytes(imageBytes, \"image/png\");\n\n        System.out.println(\"Artifact MIME Type: \" + imageArtifact.inlineData().get().mimeType().get());\n        System.out.println(\n            \"Artifact Data (first 10 bytes): \"\n                + new String(imageArtifact.inlineData().get().data().get(), 0, 10, StandardCharsets.UTF_8)\n                + \"...\");\n    }\n}"}]}, {"heading_path": ["Why Use Artifacts?\u00b6"], "text": "Why Use Artifacts? \u00b6 While session state is suitable for storing small pieces of configuration or conversational context (like strings, numbers, booleans, or small dictionaries/lists), Artifacts are designed for scenarios involving binary or large data: Handling Non-Textual Data: Easily store and retrieve images, audio clips, video snippets, PDFs, spreadsheets, or any other file format relevant to your agent's function. Persisting Large Data: Session state is generally not optimized for storing large amounts of data. Artifacts provide a dedicated mechanism for persisting larger blobs without cluttering the session state. User File Management: Provide capabilities for users to upload files (which can be saved as artifacts) and retrieve or download files generated by the agent (loaded from artifacts). Sharing Outputs: Enable tools or agents to generate binary outputs (like a PDF report or a generated image) that can be saved via save_artifact and later accessed by other parts of the application or even in subsequent sessions (if using user namespacing). Caching Binary Data: Store the results of computationally expensive operations that produce binary data (e.g., rendering a complex chart image) as artifacts to avoid regenerating them on subsequent requests. In essence, whenever your agent needs to work with file-like binary data that needs to be persisted, versioned, or shared, Artifacts managed by an ArtifactService are the appropriate mechanism within ADK. ", "code_blocks": []}, {"heading_path": ["Common Use Cases\u00b6"], "text": "Common Use Cases \u00b6 Artifacts provide a flexible way to handle binary data within your ADK applications. Here are some typical scenarios where they prove valuable: Generated Reports/Files: A tool or agent generates a report (e.g., a PDF analysis, a CSV data export, an image chart). Handling User Uploads: A user uploads a file (e.g., an image for analysis, a document for summarization) through a front-end interface. Storing Intermediate Binary Results: An agent performs a complex multi-step process where one step generates intermediate binary data (e.g., audio synthesis, simulation results). Persistent User Data: Storing user-specific configuration or data that isn't a simple key-value state. Caching Generated Binary Content: An agent frequently generates the same binary output based on certain inputs (e.g., a company logo image, a standard audio greeting). ", "code_blocks": []}, {"heading_path": ["Core Concepts\u00b6"], "text": "Core Concepts \u00b6 Understanding artifacts involves grasping a few key components: the service that manages them, the data structure used to hold them, and how they are identified and versioned. ", "code_blocks": []}, {"heading_path": ["Artifact Service (BaseArtifactService)\u00b6"], "text": "Artifact Service ( BaseArtifactService ) \u00b6 Role: The central component responsible for the actual storage and retrieval logic for artifacts. It defines how and where artifacts are persisted. Interface: Defined by the abstract base class BaseArtifactService . Any concrete implementation must provide methods for: Save Artifact : Stores the artifact data and returns its assigned version number. Load Artifact : Retrieves a specific version (or the latest) of an artifact. List Artifact keys : Lists the unique filenames of artifacts within a given scope. Delete Artifact : Removes an artifact (and potentially all its versions, depending on implementation). List versions : Lists all available version numbers for a specific artifact filename. Configuration: You provide an instance of an artifact service (e.g., InMemoryArtifactService , GcsArtifactService ) when initializing the Runner . The Runner then makes this service available to agents and tools via the InvocationContext . Python Go Java from google.adk.runners import Runner from google.adk.artifacts import InMemoryArtifactService # Or GcsArtifactService from google.adk.agents import LlmAgent # Any agent from google.adk.sessions import InMemorySessionService # Example: Configuring the Runner with an Artifact Service my_agent = LlmAgent ( name = \"artifact_user_agent\" , model = \"gemini-2.0-flash\" ) artifact_service = InMemoryArtifactService () # Choose an implementation session_service = InMemorySessionService () runner = Runner ( agent = my_agent , app_name = \"my_artifact_app\" , session_service = session_service , artifact_service = artifact_service # Provide the service instance here ) # Now, contexts within runs managed by this runner can use artifact methods import ( \"context\" \"log\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/artifactservice\" \"google.golang.org/adk/llm/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/sessionservice\" \"google.golang.org/genai\" ) // Create a new context. ctx := context . Background () // Set the app name. const appName = \"my_artifact_app\" // Create a new Gemini model. model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } // Create a new LLM agent. myAgent , err := llmagent . New ( llmagent . Config { Model : model , Name : \"artifact_user_agent\" , Instruction : \"You are an agent that describes images.\" , BeforeModelCallbacks : [] llmagent . BeforeModelCallback { BeforeModelCallback , }, }) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } // Create a new in-memory artifact service. artifactService := artifact . InMemoryService () // Create a new in-memory session service. sessionService := session . InMemoryService () // Create a new runner. r , err := runner . New ( runner . Config { Agent : myAgent , AppName : appName , SessionService : sessionService , ArtifactService : artifactService , // Provide the service instance here }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } log . Printf ( \"Runner created successfully: %v\" , r ) import com.google.adk.agents.LlmAgent ; import com.google.adk.runner.Runner ; import com.google.adk.sessions.InMemorySessionService ; import com.google.adk.artifacts.InMemoryArtifactService ; // Example: Configuring the Runner with an Artifact Service LlmAgent myAgent = LlmAgent . builder () . name ( \"artifact_user_agent\" ) . model ( \"gemini-2.0-flash\" ) . build (); InMemoryArtifactService artifactService = new InMemoryArtifactService (); // Choose an implementation InMemorySessionService sessionService = new InMemorySessionService (); Runner runner = new Runner ( myAgent , \"my_artifact_app\" , artifactService , sessionService ); // Provide the service instance here // Now, contexts within runs managed by this runner can use artifact methods ", "code_blocks": [{"language": "text", "code": "from google.adk.runners import Runner\nfrom google.adk.artifacts import InMemoryArtifactService # Or GcsArtifactService\nfrom google.adk.agents import LlmAgent # Any agent\nfrom google.adk.sessions import InMemorySessionService\n\n# Example: Configuring the Runner with an Artifact Service\nmy_agent = LlmAgent(name=\"artifact_user_agent\", model=\"gemini-2.0-flash\")\nartifact_service = InMemoryArtifactService() # Choose an implementation\nsession_service = InMemorySessionService()\n\nrunner = Runner(\n    agent=my_agent,\n    app_name=\"my_artifact_app\",\n    session_service=session_service,\n    artifact_service=artifact_service # Provide the service instance here\n)\n# Now, contexts within runs managed by this runner can use artifact methods"}, {"language": "text", "code": "import (\n    \"context\"\n    \"log\"\n\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/artifactservice\"\n    \"google.golang.org/adk/llm/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/sessionservice\"\n    \"google.golang.org/genai\"\n)\n\n// Create a new context.\nctx := context.Background()\n// Set the app name.\nconst appName = \"my_artifact_app\"\n// Create a new Gemini model.\nmodel, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{})\nif err != nil {\n    log.Fatalf(\"Failed to create model: %v\", err)\n}\n\n// Create a new LLM agent.\nmyAgent, err := llmagent.New(llmagent.Config{\n    Model:       model,\n    Name:        \"artifact_user_agent\",\n    Instruction: \"You are an agent that describes images.\",\n    BeforeModelCallbacks: []llmagent.BeforeModelCallback{\n        BeforeModelCallback,\n    },\n})\nif err != nil {\n    log.Fatalf(\"Failed to create agent: %v\", err)\n}\n\n// Create a new in-memory artifact service.\nartifactService := artifact.InMemoryService()\n// Create a new in-memory session service.\nsessionService := session.InMemoryService()\n\n// Create a new runner.\nr, err := runner.New(runner.Config{\n    Agent:           myAgent,\n    AppName:         appName,\n    SessionService:  sessionService,\n    ArtifactService: artifactService, // Provide the service instance here\n})\nif err != nil {\n    log.Fatalf(\"Failed to create runner: %v\", err)\n}\nlog.Printf(\"Runner created successfully: %v\", r)"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.InMemorySessionService;\nimport com.google.adk.artifacts.InMemoryArtifactService;\n\n// Example: Configuring the Runner with an Artifact Service\nLlmAgent myAgent =  LlmAgent.builder()\n  .name(\"artifact_user_agent\")\n  .model(\"gemini-2.0-flash\")\n  .build();\nInMemoryArtifactService artifactService = new InMemoryArtifactService(); // Choose an implementation\nInMemorySessionService sessionService = new InMemorySessionService();\n\nRunner runner = new Runner(myAgent, \"my_artifact_app\", artifactService, sessionService); // Provide the service instance here\n// Now, contexts within runs managed by this runner can use artifact methods"}]}, {"heading_path": ["Artifact Data\u00b6"], "text": "Artifact Data \u00b6 Standard Representation: Artifact content is universally represented using the google.genai.types.Part object, the same structure used for parts of LLM messages. Key Attribute ( inline_data ): For artifacts, the most relevant attribute is inline_data , which is a google.genai.types.Blob object containing: data ( bytes ): The raw binary content of the artifact. mime_type ( str ): A standard MIME type string (e.g., 'application/pdf' , 'image/png' , 'audio/mpeg' ) describing the nature of the binary data. This is crucial for correct interpretation when loading the artifact. Python Go Java import google.genai.types as types # Example: Creating an artifact Part from raw bytes pdf_bytes = b '%PDF-1.4...' # Your raw PDF data pdf_mime_type = \"application/pdf\" # Using the constructor pdf_artifact_py = types . Part ( inline_data = types . Blob ( data = pdf_bytes , mime_type = pdf_mime_type ) ) # Using the convenience class method (equivalent) pdf_artifact_alt_py = types . Part . from_bytes ( data = pdf_bytes , mime_type = pdf_mime_type ) print ( f \"Created Python artifact with MIME type: { pdf_artifact_py . inline_data . mime_type } \" ) import ( \"log\" \"os\" \"google.golang.org/genai\" ) // Load imageBytes from a file imageBytes , err := os . ReadFile ( \"image.png\" ) if err != nil { log . Fatalf ( \"Failed to read image file: %v\" , err ) } // genai.NewPartFromBytes is a convenience function that is a shorthand for // creating a &genai.Part with the InlineData field populated. // Create a new artifact from the image data. imageArtifact := genai . NewPartFromBytes ([] byte ( imageBytes ), \"image/png\" ) log . Printf ( \"Artifact MIME Type: %s\" , imageArtifact . InlineData . MIMEType ) import com.google.genai.types.Blob ; import com.google.genai.types.Part ; import java.nio.charset.StandardCharsets ; public class ArtifactDataExample { public static void main ( String [] args ) { // Example: Creating an artifact Part from raw bytes byte [] pdfBytes = \"%PDF-1.4...\" . getBytes ( StandardCharsets . UTF_8 ); // Your raw PDF data String pdfMimeType = \"application/pdf\" ; // Using the Part.fromBlob() constructor with a Blob Blob pdfBlob = Blob . builder () . data ( pdfBytes ) . mimeType ( pdfMimeType ) . build (); Part pdfArtifactJava = Part . builder (). inlineData ( pdfBlob ). build (); // Using the convenience static method Part.fromBytes() (equivalent) Part pdfArtifactAltJava = Part . fromBytes ( pdfBytes , pdfMimeType ); // Accessing mimeType, note the use of Optional String mimeType = pdfArtifactJava . inlineData () . flatMap ( Blob :: mimeType ) . orElse ( \"unknown\" ); System . out . println ( \"Created Java artifact with MIME type: \" + mimeType ); // Accessing data byte [] data = pdfArtifactJava . inlineData () . flatMap ( Blob :: data ) . orElse ( new byte [ 0 ] ); System . out . println ( \"Java artifact data (first 10 bytes): \" + new String ( data , 0 , Math . min ( data . length , 10 ), StandardCharsets . UTF_8 ) + \"...\" ); } } ", "code_blocks": [{"language": "text", "code": "import google.genai.types as types\n\n# Example: Creating an artifact Part from raw bytes\npdf_bytes = b'%PDF-1.4...' # Your raw PDF data\npdf_mime_type = \"application/pdf\"\n\n# Using the constructor\npdf_artifact_py = types.Part(\n    inline_data=types.Blob(data=pdf_bytes, mime_type=pdf_mime_type)\n)\n\n# Using the convenience class method (equivalent)\npdf_artifact_alt_py = types.Part.from_bytes(data=pdf_bytes, mime_type=pdf_mime_type)\n\nprint(f\"Created Python artifact with MIME type: {pdf_artifact_py.inline_data.mime_type}\")"}, {"language": "text", "code": "import (\n    \"log\"\n    \"os\"\n\n    \"google.golang.org/genai\"\n)\n\n// Load imageBytes from a file\nimageBytes, err := os.ReadFile(\"image.png\")\nif err != nil {\n    log.Fatalf(\"Failed to read image file: %v\", err)\n}\n\n// genai.NewPartFromBytes is a convenience function that is a shorthand for\n// creating a &genai.Part with the InlineData field populated.\n// Create a new artifact from the image data.\nimageArtifact := genai.NewPartFromBytes([]byte(imageBytes), \"image/png\")\n\nlog.Printf(\"Artifact MIME Type: %s\", imageArtifact.InlineData.MIMEType)"}, {"language": "text", "code": "import com.google.genai.types.Blob;\nimport com.google.genai.types.Part;\nimport java.nio.charset.StandardCharsets;\n\npublic class ArtifactDataExample {\n  public static void main(String[] args) {\n    // Example: Creating an artifact Part from raw bytes\n    byte[] pdfBytes = \"%PDF-1.4...\".getBytes(StandardCharsets.UTF_8); // Your raw PDF data\n    String pdfMimeType = \"application/pdf\";\n\n    // Using the Part.fromBlob() constructor with a Blob\n    Blob pdfBlob = Blob.builder()\n        .data(pdfBytes)\n        .mimeType(pdfMimeType)\n        .build();\n    Part pdfArtifactJava = Part.builder().inlineData(pdfBlob).build();\n\n    // Using the convenience static method Part.fromBytes() (equivalent)\n    Part pdfArtifactAltJava = Part.fromBytes(pdfBytes, pdfMimeType);\n\n    // Accessing mimeType, note the use of Optional\n    String mimeType = pdfArtifactJava.inlineData()\n        .flatMap(Blob::mimeType)\n        .orElse(\"unknown\");\n    System.out.println(\"Created Java artifact with MIME type: \" + mimeType);\n\n    // Accessing data\n    byte[] data = pdfArtifactJava.inlineData()\n        .flatMap(Blob::data)\n        .orElse(new byte[0]);\n    System.out.println(\"Java artifact data (first 10 bytes): \"\n        + new String(data, 0, Math.min(data.length, 10), StandardCharsets.UTF_8) + \"...\");\n  }\n}"}]}, {"heading_path": ["Filename\u00b6"], "text": "Filename \u00b6 Identifier: A simple string used to name and retrieve an artifact within its specific namespace. Uniqueness: Filenames must be unique within their scope (either the session or the user namespace). Best Practice: Use descriptive names, potentially including file extensions (e.g., \"monthly_report.pdf\" , \"user_avatar.jpg\" ), although the extension itself doesn't dictate behavior \u2013 the mime_type does. ", "code_blocks": []}, {"heading_path": ["Versioning\u00b6"], "text": "Versioning \u00b6 Automatic Versioning: The artifact service automatically handles versioning. When you call save_artifact , the service determines the next available version number (typically starting from 0 and incrementing) for that specific filename and scope. Returned by save_artifact : The save_artifact method returns the integer version number that was assigned to the newly saved artifact. Retrieval: load_artifact(..., version=None) (default): Retrieves the latest available version of the artifact. load_artifact(..., version=N) : Retrieves the specific version N . Listing Versions: The list_versions method (on the service, not context) can be used to find all existing version numbers for an artifact. ", "code_blocks": []}, {"heading_path": ["Namespacing (Session vs. User)\u00b6"], "text": "Namespacing (Session vs. User) \u00b6 Concept: Artifacts can be scoped either to a specific session or more broadly to a user across all their sessions within the application. This scoping is determined by the filename format and handled internally by the ArtifactService . Default (Session Scope): If you use a plain filename like \"report.pdf\" , the artifact is associated with the specific app_name , user_id , and session_id . It's only accessible within that exact session context. User Scope ( \"user:\" prefix): If you prefix the filename with \"user:\" , like \"user:profile.png\" , the artifact is associated only with the app_name and user_id . It can be accessed or updated from any session belonging to that user within the app. Python Go Java # Example illustrating namespace difference (conceptual) # Session-specific artifact filename session_report_filename = \"summary.txt\" # User-specific artifact filename user_config_filename = \"user:settings.json\" # When saving 'summary.txt' via context.save_artifact, # it's tied to the current app_name, user_id, and session_id. # When saving 'user:settings.json' via context.save_artifact, # the ArtifactService implementation should recognize the \"user:\" prefix # and scope it to app_name and user_id, making it accessible across sessions for that user. import ( \"log\" ) // Note: Namespacing is only supported when using the GCS ArtifactService implementation. // A session-scoped artifact is only available within the current session. sessionReportFilename := \"summary.txt\" // A user-scoped artifact is available across all sessions for the current user. userConfigFilename := \"user:settings.json\" // When saving 'summary.txt' via ctx.Artifacts().Save, // it's tied to the current app_name, user_id, and session_id. // ctx.Artifacts().Save(sessionReportFilename, *artifact); // When saving 'user:settings.json' via ctx.Artifacts().Save, // the ArtifactService implementation should recognize the \"user:\" prefix // and scope it to app_name and user_id, making it accessible across sessions for that user. // ctx.Artifacts().Save(userConfigFilename, *artifact); // Example illustrating namespace difference (conceptual) // Session-specific artifact filename String sessionReportFilename = \"summary.txt\" ; // User-specific artifact filename String userConfigFilename = \"user:settings.json\" ; // The \"user:\" prefix is key // When saving 'summary.txt' via context.save_artifact, // it's tied to the current app_name, user_id, and session_id. // artifactService.saveArtifact(appName, userId, sessionId1, sessionReportFilename, someData); // When saving 'user:settings.json' via context.save_artifact, // the ArtifactService implementation should recognize the \"user:\" prefix // and scope it to app_name and user_id, making it accessible across sessions for that user. // artifactService.saveArtifact(appName, userId, sessionId1, userConfigFilename, someData); These core concepts work together to provide a flexible system for managing binary data within the ADK framework. ", "code_blocks": [{"language": "text", "code": "# Example illustrating namespace difference (conceptual)\n\n# Session-specific artifact filename\nsession_report_filename = \"summary.txt\"\n\n# User-specific artifact filename\nuser_config_filename = \"user:settings.json\"\n\n# When saving 'summary.txt' via context.save_artifact,\n# it's tied to the current app_name, user_id, and session_id.\n\n# When saving 'user:settings.json' via context.save_artifact,\n# the ArtifactService implementation should recognize the \"user:\" prefix\n# and scope it to app_name and user_id, making it accessible across sessions for that user."}, {"language": "text", "code": "import (\n    \"log\"\n)\n\n// Note: Namespacing is only supported when using the GCS ArtifactService implementation.\n// A session-scoped artifact is only available within the current session.\nsessionReportFilename := \"summary.txt\"\n// A user-scoped artifact is available across all sessions for the current user.\nuserConfigFilename := \"user:settings.json\"\n\n// When saving 'summary.txt' via ctx.Artifacts().Save,\n// it's tied to the current app_name, user_id, and session_id.\n// ctx.Artifacts().Save(sessionReportFilename, *artifact);\n\n// When saving 'user:settings.json' via ctx.Artifacts().Save,\n// the ArtifactService implementation should recognize the \"user:\" prefix\n// and scope it to app_name and user_id, making it accessible across sessions for that user.\n// ctx.Artifacts().Save(userConfigFilename, *artifact);"}, {"language": "text", "code": "// Example illustrating namespace difference (conceptual)\n\n// Session-specific artifact filename\nString sessionReportFilename = \"summary.txt\";\n\n// User-specific artifact filename\nString userConfigFilename = \"user:settings.json\"; // The \"user:\" prefix is key\n\n// When saving 'summary.txt' via context.save_artifact,\n// it's tied to the current app_name, user_id, and session_id.\n// artifactService.saveArtifact(appName, userId, sessionId1, sessionReportFilename, someData);\n\n// When saving 'user:settings.json' via context.save_artifact,\n// the ArtifactService implementation should recognize the \"user:\" prefix\n// and scope it to app_name and user_id, making it accessible across sessions for that user.\n// artifactService.saveArtifact(appName, userId, sessionId1, userConfigFilename, someData);"}]}, {"heading_path": ["Interacting with Artifacts (via Context Objects)\u00b6"], "text": "Interacting with Artifacts (via Context Objects) \u00b6 The primary way you interact with artifacts within your agent's logic (specifically within callbacks or tools) is through methods provided by the CallbackContext and ToolContext objects. These methods abstract away the underlying storage details managed by the ArtifactService . ", "code_blocks": []}, {"heading_path": ["Prerequisite: Configuring the ArtifactService\u00b6"], "text": "Prerequisite: Configuring the ArtifactService \u00b6 Before you can use any artifact methods via the context objects, you must provide an instance of a BaseArtifactService implementation (like InMemoryArtifactService or GcsArtifactService ) when initializing your Runner . Python Go Java In Python, you provide this instance when initializing your Runner . from google.adk.runners import Runner from google.adk.artifacts import InMemoryArtifactService # Or GcsArtifactService from google.adk.agents import LlmAgent from google.adk.sessions import InMemorySessionService # Your agent definition agent = LlmAgent ( name = \"my_agent\" , model = \"gemini-2.0-flash\" ) # Instantiate the desired artifact service artifact_service = InMemoryArtifactService () # Provide it to the Runner runner = Runner ( agent = agent , app_name = \"artifact_app\" , session_service = InMemorySessionService (), artifact_service = artifact_service # Service must be provided here ) If no artifact_service is configured in the InvocationContext (which happens if it's not passed to the Runner ), calling save_artifact , load_artifact , or list_artifacts on the context objects will raise a ValueError . import ( \"context\" \"log\" \"google.golang.org/adk/agent/llmagent\" \"google.golang.org/adk/artifactservice\" \"google.golang.org/adk/llm/gemini\" \"google.golang.org/adk/runner\" \"google.golang.org/adk/sessionservice\" \"google.golang.org/genai\" ) // Create a new context. ctx := context . Background () // Set the app name. const appName = \"my_artifact_app\" // Create a new Gemini model. model , err := gemini . NewModel ( ctx , \"gemini-2.5-flash\" , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } // Create a new LLM agent. myAgent , err := llmagent . New ( llmagent . Config { Model : model , Name : \"artifact_user_agent\" , Instruction : \"You are an agent that describes images.\" , BeforeModelCallbacks : [] llmagent . BeforeModelCallback { BeforeModelCallback , }, }) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } // Create a new in-memory artifact service. artifactService := artifact . InMemoryService () // Create a new in-memory session service. sessionService := session . InMemoryService () // Create a new runner. r , err := runner . New ( runner . Config { Agent : myAgent , AppName : appName , SessionService : sessionService , ArtifactService : artifactService , // Provide the service instance here }) if err != nil { log . Fatalf ( \"Failed to create runner: %v\" , err ) } log . Printf ( \"Runner created successfully: %v\" , r ) In Java, you would instantiate a BaseArtifactService implementation and then ensure it's accessible to the parts of your application that manage artifacts. This is often done through dependency injection or by explicitly passing the service instance. import com.google.adk.agents.LlmAgent ; import com.google.adk.artifacts.InMemoryArtifactService ; // Or GcsArtifactService import com.google.adk.runner.Runner ; import com.google.adk.sessions.InMemorySessionService ; public class SampleArtifactAgent { public static void main ( String [] args ) { // Your agent definition LlmAgent agent = LlmAgent . builder () . name ( \"my_agent\" ) . model ( \"gemini-2.0-flash\" ) . build (); // Instantiate the desired artifact service InMemoryArtifactService artifactService = new InMemoryArtifactService (); // Provide it to the Runner Runner runner = new Runner ( agent , \"APP_NAME\" , artifactService , // Service must be provided here new InMemorySessionService ()); } } In Java, if an ArtifactService instance is not available (e.g., null ) when artifact operations are attempted, it would typically result in a NullPointerException or a custom error, depending on how your application is structured. Robust applications often use dependency injection frameworks to manage service lifecycles and ensure availability. ", "code_blocks": [{"language": "text", "code": "from google.adk.runners import Runner\nfrom google.adk.artifacts import InMemoryArtifactService # Or GcsArtifactService\nfrom google.adk.agents import LlmAgent\nfrom google.adk.sessions import InMemorySessionService\n\n# Your agent definition\nagent = LlmAgent(name=\"my_agent\", model=\"gemini-2.0-flash\")\n\n# Instantiate the desired artifact service\nartifact_service = InMemoryArtifactService()\n\n# Provide it to the Runner\nrunner = Runner(\n    agent=agent,\n    app_name=\"artifact_app\",\n    session_service=InMemorySessionService(),\n    artifact_service=artifact_service # Service must be provided here\n)"}, {"language": "text", "code": "import (\n    \"context\"\n    \"log\"\n\n    \"google.golang.org/adk/agent/llmagent\"\n    \"google.golang.org/adk/artifactservice\"\n    \"google.golang.org/adk/llm/gemini\"\n    \"google.golang.org/adk/runner\"\n    \"google.golang.org/adk/sessionservice\"\n    \"google.golang.org/genai\"\n)\n\n// Create a new context.\nctx := context.Background()\n// Set the app name.\nconst appName = \"my_artifact_app\"\n// Create a new Gemini model.\nmodel, err := gemini.NewModel(ctx, \"gemini-2.5-flash\", &genai.ClientConfig{})\nif err != nil {\n    log.Fatalf(\"Failed to create model: %v\", err)\n}\n\n// Create a new LLM agent.\nmyAgent, err := llmagent.New(llmagent.Config{\n    Model:       model,\n    Name:        \"artifact_user_agent\",\n    Instruction: \"You are an agent that describes images.\",\n    BeforeModelCallbacks: []llmagent.BeforeModelCallback{\n        BeforeModelCallback,\n    },\n})\nif err != nil {\n    log.Fatalf(\"Failed to create agent: %v\", err)\n}\n\n// Create a new in-memory artifact service.\nartifactService := artifact.InMemoryService()\n// Create a new in-memory session service.\nsessionService := session.InMemoryService()\n\n// Create a new runner.\nr, err := runner.New(runner.Config{\n    Agent:           myAgent,\n    AppName:         appName,\n    SessionService:  sessionService,\n    ArtifactService: artifactService, // Provide the service instance here\n})\nif err != nil {\n    log.Fatalf(\"Failed to create runner: %v\", err)\n}\nlog.Printf(\"Runner created successfully: %v\", r)"}, {"language": "text", "code": "import com.google.adk.agents.LlmAgent;\nimport com.google.adk.artifacts.InMemoryArtifactService; // Or GcsArtifactService\nimport com.google.adk.runner.Runner;\nimport com.google.adk.sessions.InMemorySessionService;\n\npublic class SampleArtifactAgent {\n\n  public static void main(String[] args) {\n\n    // Your agent definition\n    LlmAgent agent = LlmAgent.builder()\n        .name(\"my_agent\")\n        .model(\"gemini-2.0-flash\")\n        .build();\n\n    // Instantiate the desired artifact service\n    InMemoryArtifactService artifactService = new InMemoryArtifactService();\n\n    // Provide it to the Runner\n    Runner runner = new Runner(agent,\n        \"APP_NAME\",\n        artifactService, // Service must be provided here\n        new InMemorySessionService());\n\n  }\n}"}]}, {"heading_path": ["Accessing Methods\u00b6"], "text": "Accessing Methods \u00b6 The artifact interaction methods are available directly on instances of CallbackContext (passed to agent and model callbacks) and ToolContext (passed to tool callbacks). Remember that ToolContext inherits from CallbackContext . ", "code_blocks": []}, {"heading_path": ["Saving Artifacts\u00b6"], "text": "Saving Artifacts \u00b6 Code Example: Python Go Java import google.genai.types as types from google.adk.agents.callback_context import CallbackContext # Or ToolContext async def save_generated_report_py ( context : CallbackContext , report_bytes : bytes ): \"\"\"Saves generated PDF report bytes as an artifact.\"\"\" report_artifact = types . Part . from_bytes ( data = report_bytes , mime_type = \"application/pdf\" ) filename = \"generated_report.pdf\" try : version = await context . save_artifact ( filename = filename , artifact = report_artifact ) print ( f \"Successfully saved Python artifact ' { filename } ' as version { version } .\" ) # The event generated after this callback will contain: # event.actions.artifact_delta == {\"generated_report.pdf\": version} except ValueError as e : print ( f \"Error saving Python artifact: { e } . Is ArtifactService configured in Runner?\" ) except Exception as e : # Handle potential storage errors (e.g., GCS permissions) print ( f \"An unexpected error occurred during Python artifact save: { e } \" ) # --- Example Usage Concept (Python) --- # async def main_py(): #   callback_context: CallbackContext = ... # obtain context #   report_data = b'...' # Assume this holds the PDF bytes #   await save_generated_report_py(callback_context, report_data) import ( \"log\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/llm\" \"google.golang.org/genai\" ) // saveReportCallback is a BeforeModel callback that saves a report from session state. func saveReportCallback ( ctx agent . CallbackContext , req * model . LLMRequest ) ( * model . LLMResponse , error ) { // Get the report data from the session state. reportData , err := ctx . State (). Get ( \"report_bytes\" ) if err != nil { log . Printf ( \"No report data found in session state: %v\" , err ) return nil , nil // No report to save, continue normally. } // Check if the report data is in the expected format. reportBytes , ok := reportData .([] byte ) if ! ok { log . Printf ( \"Report data in session state was not in the expected byte format.\" ) return nil , nil } // Create a new artifact with the report data. reportArtifact := & genai . Part { InlineData : & genai . Blob { MIMEType : \"application/pdf\" , Data : reportBytes , }, } // Set the filename for the artifact. filename := \"generated_report.pdf\" // Save the artifact to the artifact service. _ , err = ctx . Artifacts (). Save ( ctx , filename , reportArtifact ) if err != nil { log . Printf ( \"An unexpected error occurred during Go artifact save: %v\" , err ) // Depending on requirements, you might want to return an error to the user. return nil , nil } log . Printf ( \"Successfully saved Go artifact '%s'.\" , filename ) // Return nil to continue to the next callback or the model. return nil , nil } import com.google.adk.agents.CallbackContext ; import com.google.adk.artifacts.BaseArtifactService ; import com.google.adk.artifacts.InMemoryArtifactService ; import com.google.genai.types.Part ; import java.nio.charset.StandardCharsets ; public class SaveArtifactExample { public void saveGeneratedReport ( CallbackContext callbackContext , byte [] reportBytes ) { // Saves generated PDF report bytes as an artifact. Part reportArtifact = Part . fromBytes ( reportBytes , \"application/pdf\" ); String filename = \"generatedReport.pdf\" ; callbackContext . saveArtifact ( filename , reportArtifact ); System . out . println ( \"Successfully saved Java artifact '\" + filename ); // The event generated after this callback will contain: // event().actions().artifactDelta == {\"generated_report.pdf\": version} } // --- Example Usage Concept (Java) --- public static void main ( String [] args ) { BaseArtifactService service = new InMemoryArtifactService (); // Or GcsArtifactService SaveArtifactExample myTool = new SaveArtifactExample (); byte [] reportData = \"...\" . getBytes ( StandardCharsets . UTF_8 ); // PDF bytes CallbackContext callbackContext ; // ... obtain callback context from your app myTool . saveGeneratedReport ( callbackContext , reportData ); // Due to async nature, in a real app, ensure program waits or handles completion. } } ", "code_blocks": [{"language": "text", "code": "import google.genai.types as types\nfrom google.adk.agents.callback_context import CallbackContext # Or ToolContext\n\nasync def save_generated_report_py(context: CallbackContext, report_bytes: bytes):\n    \"\"\"Saves generated PDF report bytes as an artifact.\"\"\"\n    report_artifact = types.Part.from_bytes(\n        data=report_bytes,\n        mime_type=\"application/pdf\"\n    )\n    filename = \"generated_report.pdf\"\n\n    try:\n        version = await context.save_artifact(filename=filename, artifact=report_artifact)\n        print(f\"Successfully saved Python artifact '{filename}' as version {version}.\")\n        # The event generated after this callback will contain:\n        # event.actions.artifact_delta == {\"generated_report.pdf\": version}\n    except ValueError as e:\n        print(f\"Error saving Python artifact: {e}. Is ArtifactService configured in Runner?\")\n    except Exception as e:\n        # Handle potential storage errors (e.g., GCS permissions)\n        print(f\"An unexpected error occurred during Python artifact save: {e}\")\n\n# --- Example Usage Concept (Python) ---\n# async def main_py():\n#   callback_context: CallbackContext = ... # obtain context\n#   report_data = b'...' # Assume this holds the PDF bytes\n#   await save_generated_report_py(callback_context, report_data)"}, {"language": "text", "code": "import (\n    \"log\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/llm\"\n    \"google.golang.org/genai\"\n)\n\n// saveReportCallback is a BeforeModel callback that saves a report from session state.\nfunc saveReportCallback(ctx agent.CallbackContext, req *model.LLMRequest) (*model.LLMResponse, error) {\n    // Get the report data from the session state.\n    reportData, err := ctx.State().Get(\"report_bytes\")\n    if err != nil {\n        log.Printf(\"No report data found in session state: %v\", err)\n        return nil, nil // No report to save, continue normally.\n    }\n\n    // Check if the report data is in the expected format.\n    reportBytes, ok := reportData.([]byte)\n    if !ok {\n        log.Printf(\"Report data in session state was not in the expected byte format.\")\n        return nil, nil\n    }\n\n    // Create a new artifact with the report data.\n    reportArtifact := &genai.Part{\n        InlineData: &genai.Blob{\n            MIMEType: \"application/pdf\",\n            Data:     reportBytes,\n        },\n    }\n    // Set the filename for the artifact.\n    filename := \"generated_report.pdf\"\n    // Save the artifact to the artifact service.\n    _, err = ctx.Artifacts().Save(ctx, filename, reportArtifact)\n    if err != nil {\n        log.Printf(\"An unexpected error occurred during Go artifact save: %v\", err)\n        // Depending on requirements, you might want to return an error to the user.\n        return nil, nil\n    }\n    log.Printf(\"Successfully saved Go artifact '%s'.\", filename)\n    // Return nil to continue to the next callback or the model.\n    return nil, nil\n}"}, {"language": "text", "code": "import com.google.adk.agents.CallbackContext;\nimport com.google.adk.artifacts.BaseArtifactService;\nimport com.google.adk.artifacts.InMemoryArtifactService;\nimport com.google.genai.types.Part;\nimport java.nio.charset.StandardCharsets;\n\npublic class SaveArtifactExample {\n\npublic void saveGeneratedReport(CallbackContext callbackContext, byte[] reportBytes) {\n// Saves generated PDF report bytes as an artifact.\nPart reportArtifact = Part.fromBytes(reportBytes, \"application/pdf\");\nString filename = \"generatedReport.pdf\";\n\n    callbackContext.saveArtifact(filename, reportArtifact);\n    System.out.println(\"Successfully saved Java artifact '\" + filename);\n    // The event generated after this callback will contain:\n    // event().actions().artifactDelta == {\"generated_report.pdf\": version}\n}\n\n// --- Example Usage Concept (Java) ---\npublic static void main(String[] args) {\n    BaseArtifactService service = new InMemoryArtifactService(); // Or GcsArtifactService\n    SaveArtifactExample myTool = new SaveArtifactExample();\n    byte[] reportData = \"...\".getBytes(StandardCharsets.UTF_8); // PDF bytes\n    CallbackContext callbackContext; // ... obtain callback context from your app\n    myTool.saveGeneratedReport(callbackContext, reportData);\n    // Due to async nature, in a real app, ensure program waits or handles completion.\n  }\n}"}]}, {"heading_path": ["Loading Artifacts\u00b6"], "text": "Loading Artifacts \u00b6 Code Example: Python Go Java import google.genai.types as types from google.adk.agents.callback_context import CallbackContext # Or ToolContext async def process_latest_report_py ( context : CallbackContext ): \"\"\"Loads the latest report artifact and processes its data.\"\"\" filename = \"generated_report.pdf\" try : # Load the latest version report_artifact = await context . load_artifact ( filename = filename ) if report_artifact and report_artifact . inline_data : print ( f \"Successfully loaded latest Python artifact ' { filename } '.\" ) print ( f \"MIME Type: { report_artifact . inline_data . mime_type } \" ) # Process the report_artifact.inline_data.data (bytes) pdf_bytes = report_artifact . inline_data . data print ( f \"Report size: { len ( pdf_bytes ) } bytes.\" ) # ... further processing ... else : print ( f \"Python artifact ' { filename } ' not found.\" ) # Example: Load a specific version (if version 0 exists) # specific_version_artifact = await context.load_artifact(filename=filename, version=0) # if specific_version_artifact: #     print(f\"Loaded version 0 of '{filename}'.\") except ValueError as e : print ( f \"Error loading Python artifact: { e } . Is ArtifactService configured?\" ) except Exception as e : # Handle potential storage errors print ( f \"An unexpected error occurred during Python artifact load: { e } \" ) # --- Example Usage Concept (Python) --- # async def main_py(): #   callback_context: CallbackContext = ... # obtain context #   await process_latest_report_py(callback_context) import ( \"log\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/llm\" ) // loadArtifactsCallback is a BeforeModel callback that loads a specific artifact // and adds its content to the LLM request. func loadArtifactsCallback ( ctx agent . CallbackContext , req * model . LLMRequest ) ( * model . LLMResponse , error ) { log . Println ( \"[Callback] loadArtifactsCallback triggered.\" ) // In a real app, you would parse the user's request to find a filename. // For this example, we'll hardcode a filename to demonstrate. const filenameToLoad = \"generated_report.pdf\" // Load the artifact from the artifact service. loadedPartResponse , err := ctx . Artifacts (). Load ( ctx , filenameToLoad ) if err != nil { log . Printf ( \"Callback could not load artifact '%s': %v\" , filenameToLoad , err ) return nil , nil // File not found or error, continue to model. } loadedPart := loadedPartResponse . Part log . Printf ( \"Callback successfully loaded artifact '%s'.\" , filenameToLoad ) // Ensure there's at least one content in the request to append to. if len ( req . Contents ) == 0 { req . Contents = [] * genai . Content {{ Parts : [] * genai . Part { genai . NewPartFromText ( \"SYSTEM: The following file is provided for context:\\n\" ), }}} } // Add the loaded artifact to the request for the model. lastContent := req . Contents [ len ( req . Contents ) - 1 ] lastContent . Parts = append ( lastContent . Parts , loadedPart ) log . Printf ( \"Added artifact '%s' to LLM request.\" , filenameToLoad ) // Return nil to continue to the next callback or the model. return nil , nil // Continue to next callback or LLM call } import com.google.adk.artifacts.BaseArtifactService ; import com.google.genai.types.Part ; import io.reactivex.rxjava3.core.MaybeObserver ; import io.reactivex.rxjava3.disposables.Disposable ; import java.util.Optional ; public class MyArtifactLoaderService { private final BaseArtifactService artifactService ; private final String appName ; public MyArtifactLoaderService ( BaseArtifactService artifactService , String appName ) { this . artifactService = artifactService ; this . appName = appName ; } public void processLatestReportJava ( String userId , String sessionId , String filename ) { // Load the latest version by passing Optional.empty() for the version artifactService . loadArtifact ( appName , userId , sessionId , filename , Optional . empty ()) . subscribe ( new MaybeObserver < Part > () { @Override public void onSubscribe ( Disposable d ) { // Optional: handle subscription } @Override public void onSuccess ( Part reportArtifact ) { System . out . println ( \"Successfully loaded latest Java artifact '\" + filename + \"'.\" ); reportArtifact . inlineData () . ifPresent ( blob -> { System . out . println ( \"MIME Type: \" + blob . mimeType (). orElse ( \"N/A\" )); byte [] pdfBytes = blob . data (). orElse ( new byte [ 0 ] ); System . out . println ( \"Report size: \" + pdfBytes . length + \" bytes.\" ); // ... further processing of pdfBytes ... }); } @Override public void onError ( Throwable e ) { // Handle potential storage errors or other exceptions System . err . println ( \"An error occurred during Java artifact load for '\" + filename + \"': \" + e . getMessage ()); } @Override public void onComplete () { // Called if the artifact (latest version) is not found System . out . println ( \"Java artifact '\" + filename + \"' not found.\" ); } }); // Example: Load a specific version (e.g., version 0) /* artifactService.loadArtifact(appName, userId, sessionId, filename, Optional.of(0)) .subscribe(part -> { System.out.println(\"Loaded version 0 of Java artifact '\" + filename + \"'.\"); }, throwable -> { System.err.println(\"Error loading version 0 of '\" + filename + \"': \" + throwable.getMessage()); }, () -> { System.out.println(\"Version 0 of Java artifact '\" + filename + \"' not found.\"); }); */ } // --- Example Usage Concept (Java) --- public static void main ( String [] args ) { // BaseArtifactService service = new InMemoryArtifactService(); // Or GcsArtifactService // MyArtifactLoaderService loader = new MyArtifactLoaderService(service, \"myJavaApp\"); // loader.processLatestReportJava(\"user123\", \"sessionABC\", \"java_report.pdf\"); // Due to async nature, in a real app, ensure program waits or handles completion. } } ", "code_blocks": [{"language": "text", "code": "import google.genai.types as types\nfrom google.adk.agents.callback_context import CallbackContext # Or ToolContext\n\nasync def process_latest_report_py(context: CallbackContext):\n    \"\"\"Loads the latest report artifact and processes its data.\"\"\"\n    filename = \"generated_report.pdf\"\n    try:\n        # Load the latest version\n        report_artifact = await context.load_artifact(filename=filename)\n\n        if report_artifact and report_artifact.inline_data:\n            print(f\"Successfully loaded latest Python artifact '{filename}'.\")\n            print(f\"MIME Type: {report_artifact.inline_data.mime_type}\")\n            # Process the report_artifact.inline_data.data (bytes)\n            pdf_bytes = report_artifact.inline_data.data\n            print(f\"Report size: {len(pdf_bytes)} bytes.\")\n            # ... further processing ...\n        else:\n            print(f\"Python artifact '{filename}' not found.\")\n\n        # Example: Load a specific version (if version 0 exists)\n        # specific_version_artifact = await context.load_artifact(filename=filename, version=0)\n        # if specific_version_artifact:\n        #     print(f\"Loaded version 0 of '{filename}'.\")\n\n    except ValueError as e:\n        print(f\"Error loading Python artifact: {e}. Is ArtifactService configured?\")\n    except Exception as e:\n        # Handle potential storage errors\n        print(f\"An unexpected error occurred during Python artifact load: {e}\")\n\n# --- Example Usage Concept (Python) ---\n# async def main_py():\n#   callback_context: CallbackContext = ... # obtain context\n#   await process_latest_report_py(callback_context)"}, {"language": "text", "code": "import (\n    \"log\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/llm\"\n)\n\n// loadArtifactsCallback is a BeforeModel callback that loads a specific artifact\n// and adds its content to the LLM request.\nfunc loadArtifactsCallback(ctx agent.CallbackContext, req *model.LLMRequest) (*model.LLMResponse, error) {\n    log.Println(\"[Callback] loadArtifactsCallback triggered.\")\n    // In a real app, you would parse the user's request to find a filename.\n    // For this example, we'll hardcode a filename to demonstrate.\n    const filenameToLoad = \"generated_report.pdf\"\n\n    // Load the artifact from the artifact service.\n    loadedPartResponse, err := ctx.Artifacts().Load(ctx, filenameToLoad)\n    if err != nil {\n        log.Printf(\"Callback could not load artifact '%s': %v\", filenameToLoad, err)\n        return nil, nil // File not found or error, continue to model.\n    }\n\n    loadedPart := loadedPartResponse.Part\n\n    log.Printf(\"Callback successfully loaded artifact '%s'.\", filenameToLoad)\n\n    // Ensure there's at least one content in the request to append to.\n    if len(req.Contents) == 0 {\n        req.Contents = []*genai.Content{{Parts: []*genai.Part{\n            genai.NewPartFromText(\"SYSTEM: The following file is provided for context:\\n\"),\n        }}}\n    }\n\n    // Add the loaded artifact to the request for the model.\n    lastContent := req.Contents[len(req.Contents)-1]\n    lastContent.Parts = append(lastContent.Parts, loadedPart)\n    log.Printf(\"Added artifact '%s' to LLM request.\", filenameToLoad)\n\n    // Return nil to continue to the next callback or the model.\n    return nil, nil // Continue to next callback or LLM call\n}"}, {"language": "text", "code": "import com.google.adk.artifacts.BaseArtifactService;\nimport com.google.genai.types.Part;\nimport io.reactivex.rxjava3.core.MaybeObserver;\nimport io.reactivex.rxjava3.disposables.Disposable;\nimport java.util.Optional;\n\npublic class MyArtifactLoaderService {\n\n    private final BaseArtifactService artifactService;\n    private final String appName;\n\n    public MyArtifactLoaderService(BaseArtifactService artifactService, String appName) {\n        this.artifactService = artifactService;\n        this.appName = appName;\n    }\n\n    public void processLatestReportJava(String userId, String sessionId, String filename) {\n        // Load the latest version by passing Optional.empty() for the version\n        artifactService\n                .loadArtifact(appName, userId, sessionId, filename, Optional.empty())\n                .subscribe(\n                        new MaybeObserver<Part>() {\n                            @Override\n                            public void onSubscribe(Disposable d) {\n                                // Optional: handle subscription\n                            }\n\n                            @Override\n                            public void onSuccess(Part reportArtifact) {\n                                System.out.println(\n                                        \"Successfully loaded latest Java artifact '\" + filename + \"'.\");\n                                reportArtifact\n                                        .inlineData()\n                                        .ifPresent(\n                                                blob -> {\n                                                    System.out.println(\n                                                            \"MIME Type: \" + blob.mimeType().orElse(\"N/A\"));\n                                                    byte[] pdfBytes = blob.data().orElse(new byte[0]);\n                                                    System.out.println(\"Report size: \" + pdfBytes.length + \" bytes.\");\n                                                    // ... further processing of pdfBytes ...\n                                                });\n                            }\n\n                            @Override\n                            public void onError(Throwable e) {\n                                // Handle potential storage errors or other exceptions\n                                System.err.println(\n                                        \"An error occurred during Java artifact load for '\"\n                                                + filename\n                                                + \"': \"\n                                                + e.getMessage());\n                            }\n\n                            @Override\n                            public void onComplete() {\n                                // Called if the artifact (latest version) is not found\n                                System.out.println(\"Java artifact '\" + filename + \"' not found.\");\n                            }\n                        });\n\n        // Example: Load a specific version (e.g., version 0)\n        /*\n        artifactService.loadArtifact(appName, userId, sessionId, filename, Optional.of(0))\n            .subscribe(part -> {\n                System.out.println(\"Loaded version 0 of Java artifact '\" + filename + \"'.\");\n            }, throwable -> {\n                System.err.println(\"Error loading version 0 of '\" + filename + \"': \" + throwable.getMessage());\n            }, () -> {\n                System.out.println(\"Version 0 of Java artifact '\" + filename + \"' not found.\");\n            });\n        */\n    }\n\n    // --- Example Usage Concept (Java) ---\n    public static void main(String[] args) {\n        // BaseArtifactService service = new InMemoryArtifactService(); // Or GcsArtifactService\n        // MyArtifactLoaderService loader = new MyArtifactLoaderService(service, \"myJavaApp\");\n        // loader.processLatestReportJava(\"user123\", \"sessionABC\", \"java_report.pdf\");\n        // Due to async nature, in a real app, ensure program waits or handles completion.\n    }\n}"}]}, {"heading_path": ["Listing Artifact Filenames\u00b6"], "text": "Listing Artifact Filenames \u00b6 Code Example: Python Go Java from google.adk.tools.tool_context import ToolContext def list_user_files_py ( tool_context : ToolContext ) -> str : \"\"\"Tool to list available artifacts for the user.\"\"\" try : available_files = await tool_context . list_artifacts () if not available_files : return \"You have no saved artifacts.\" else : # Format the list for the user/LLM file_list_str = \" \\n \" . join ([ f \"- { fname } \" for fname in available_files ]) return f \"Here are your available Python artifacts: \\n { file_list_str } \" except ValueError as e : print ( f \"Error listing Python artifacts: { e } . Is ArtifactService configured?\" ) return \"Error: Could not list Python artifacts.\" except Exception as e : print ( f \"An unexpected error occurred during Python artifact list: { e } \" ) return \"Error: An unexpected error occurred while listing Python artifacts.\" # This function would typically be wrapped in a FunctionTool # from google.adk.tools import FunctionTool # list_files_tool = FunctionTool(func=list_user_files_py) import ( \"fmt\" \"log\" \"strings\" \"google.golang.org/adk/agent\" \"google.golang.org/adk/llm\" \"google.golang.org/genai\" ) // listUserFilesCallback is a BeforeModel callback that lists available artifacts // and adds the list as context to the LLM request. func listUserFilesCallback ( ctx agent . CallbackContext , req * model . LLMRequest ) ( * model . LLMResponse , error ) { log . Println ( \"[Callback] listUserFilesCallback triggered.\" ) // List the available artifacts from the artifact service. listResponse , err := ctx . Artifacts (). List ( ctx ) if err != nil { log . Printf ( \"An unexpected error occurred during Go artifact list: %v\" , err ) return nil , nil // Continue, but log the error. } availableFiles := listResponse . FileNames log . Printf ( \"Found %d available files.\" , len ( availableFiles )) // If there are available files, add them to the LLM request. if len ( availableFiles ) > 0 { var fileListStr strings . Builder fileListStr . WriteString ( \"SYSTEM: The following files are available:\\n\" ) for _ , fname := range availableFiles { fileListStr . WriteString ( fmt . Sprintf ( \"- %s\\n\" , fname )) } // Prepend this information to the user's request for the model. if len ( req . Contents ) > 0 { lastContent := req . Contents [ len ( req . Contents ) - 1 ] if len ( lastContent . Parts ) > 0 { fileListStr . WriteString ( \"\\n\" ) // Add a newline for separation. lastContent . Parts [ 0 ] = genai . NewPartFromText ( fileListStr . String () + lastContent . Parts [ 0 ]. Text ) log . Println ( \"Added file list to LLM request context.\" ) } } log . Printf ( \"Available files:\\n%s\" , fileListStr . String ()) } else { log . Println ( \"No available files found to list.\" ) } // Return nil to continue to the next callback or the model. return nil , nil // Continue to next callback or LLM call } import com.google.adk.artifacts.BaseArtifactService ; import com.google.adk.artifacts.ListArtifactsResponse ; import com.google.common.collect.ImmutableList ; import io.reactivex.rxjava3.core.SingleObserver ; import io.reactivex.rxjava3.disposables.Disposable ; public class MyArtifactListerService { private final BaseArtifactService artifactService ; private final String appName ; public MyArtifactListerService ( BaseArtifactService artifactService , String appName ) { this . artifactService = artifactService ; this . appName = appName ; } // Example method that might be called by a tool or agent logic public void listUserFilesJava ( String userId , String sessionId ) { artifactService . listArtifactKeys ( appName , userId , sessionId ) . subscribe ( new SingleObserver < ListArtifactsResponse > () { @Override public void onSubscribe ( Disposable d ) { // Optional: handle subscription } @Override public void onSuccess ( ListArtifactsResponse response ) { ImmutableList < String > availableFiles = response . filenames (); if ( availableFiles . isEmpty ()) { System . out . println ( \"User \" + userId + \" in session \" + sessionId + \" has no saved Java artifacts.\" ); } else { StringBuilder fileListStr = new StringBuilder ( \"Here are the available Java artifacts for user \" + userId + \" in session \" + sessionId + \":\\n\" ); for ( String fname : availableFiles ) { fileListStr . append ( \"- \" ). append ( fname ). append ( \"\\n\" ); } System . out . println ( fileListStr . toString ()); } } @Override public void onError ( Throwable e ) { System . err . println ( \"Error listing Java artifacts for user \" + userId + \" in session \" + sessionId + \": \" + e . getMessage ()); // In a real application, you might return an error message to the user/LLM } }); } // --- Example Usage Concept (Java) --- public static void main ( String [] args ) { // BaseArtifactService service = new InMemoryArtifactService(); // Or GcsArtifactService // MyArtifactListerService lister = new MyArtifactListerService(service, \"myJavaApp\"); // lister.listUserFilesJava(\"user123\", \"sessionABC\"); // Due to async nature, in a real app, ensure program waits or handles completion. } } These methods for saving, loading, and listing provide a convenient and consistent way to manage binary data persistence within ADK, whether using Python's context objects or directly interacting with the BaseArtifactService in Java, regardless of the chosen backend storage implementation. ", "code_blocks": [{"language": "text", "code": "from google.adk.tools.tool_context import ToolContext\n\ndef list_user_files_py(tool_context: ToolContext) -> str:\n    \"\"\"Tool to list available artifacts for the user.\"\"\"\n    try:\n        available_files = await tool_context.list_artifacts()\n        if not available_files:\n            return \"You have no saved artifacts.\"\n        else:\n            # Format the list for the user/LLM\n            file_list_str = \"\\n\".join([f\"- {fname}\" for fname in available_files])\n            return f\"Here are your available Python artifacts:\\n{file_list_str}\"\n    except ValueError as e:\n        print(f\"Error listing Python artifacts: {e}. Is ArtifactService configured?\")\n        return \"Error: Could not list Python artifacts.\"\n    except Exception as e:\n        print(f\"An unexpected error occurred during Python artifact list: {e}\")\n        return \"Error: An unexpected error occurred while listing Python artifacts.\"\n\n# This function would typically be wrapped in a FunctionTool\n# from google.adk.tools import FunctionTool\n# list_files_tool = FunctionTool(func=list_user_files_py)"}, {"language": "text", "code": "import (\n    \"fmt\"\n    \"log\"\n    \"strings\"\n\n    \"google.golang.org/adk/agent\"\n    \"google.golang.org/adk/llm\"\n    \"google.golang.org/genai\"\n)\n\n// listUserFilesCallback is a BeforeModel callback that lists available artifacts\n// and adds the list as context to the LLM request.\nfunc listUserFilesCallback(ctx agent.CallbackContext, req *model.LLMRequest) (*model.LLMResponse, error) {\n    log.Println(\"[Callback] listUserFilesCallback triggered.\")\n    // List the available artifacts from the artifact service.\n    listResponse, err := ctx.Artifacts().List(ctx)\n    if err != nil {\n        log.Printf(\"An unexpected error occurred during Go artifact list: %v\", err)\n        return nil, nil // Continue, but log the error.\n    }\n\n    availableFiles := listResponse.FileNames\n\n    log.Printf(\"Found %d available files.\", len(availableFiles))\n\n    // If there are available files, add them to the LLM request.\n    if len(availableFiles) > 0 {\n        var fileListStr strings.Builder\n        fileListStr.WriteString(\"SYSTEM: The following files are available:\\n\")\n        for _, fname := range availableFiles {\n            fileListStr.WriteString(fmt.Sprintf(\"- %s\\n\", fname))\n        }\n        // Prepend this information to the user's request for the model.\n        if len(req.Contents) > 0 {\n            lastContent := req.Contents[len(req.Contents)-1]\n            if len(lastContent.Parts) > 0 {\n                fileListStr.WriteString(\"\\n\") // Add a newline for separation.\n                lastContent.Parts[0] = genai.NewPartFromText(fileListStr.String() + lastContent.Parts[0].Text)\n                log.Println(\"Added file list to LLM request context.\")\n            }\n        }\n        log.Printf(\"Available files:\\n%s\", fileListStr.String())\n    } else {\n        log.Println(\"No available files found to list.\")\n    }\n\n    // Return nil to continue to the next callback or the model.\n    return nil, nil // Continue to next callback or LLM call\n}"}, {"language": "text", "code": "import com.google.adk.artifacts.BaseArtifactService;\nimport com.google.adk.artifacts.ListArtifactsResponse;\nimport com.google.common.collect.ImmutableList;\nimport io.reactivex.rxjava3.core.SingleObserver;\nimport io.reactivex.rxjava3.disposables.Disposable;\n\npublic class MyArtifactListerService {\n\n    private final BaseArtifactService artifactService;\n    private final String appName;\n\n    public MyArtifactListerService(BaseArtifactService artifactService, String appName) {\n        this.artifactService = artifactService;\n        this.appName = appName;\n    }\n\n    // Example method that might be called by a tool or agent logic\n    public void listUserFilesJava(String userId, String sessionId) {\n        artifactService\n                .listArtifactKeys(appName, userId, sessionId)\n                .subscribe(\n                        new SingleObserver<ListArtifactsResponse>() {\n                            @Override\n                            public void onSubscribe(Disposable d) {\n                                // Optional: handle subscription\n                            }\n\n                            @Override\n                            public void onSuccess(ListArtifactsResponse response) {\n                                ImmutableList<String> availableFiles = response.filenames();\n                                if (availableFiles.isEmpty()) {\n                                    System.out.println(\n                                            \"User \"\n                                                    + userId\n                                                    + \" in session \"\n                                                    + sessionId\n                                                    + \" has no saved Java artifacts.\");\n                                } else {\n                                    StringBuilder fileListStr =\n                                            new StringBuilder(\n                                                    \"Here are the available Java artifacts for user \"\n                                                            + userId\n                                                            + \" in session \"\n                                                            + sessionId\n                                                            + \":\\n\");\n                                    for (String fname : availableFiles) {\n                                        fileListStr.append(\"- \").append(fname).append(\"\\n\");\n                                    }\n                                    System.out.println(fileListStr.toString());\n                                }\n                            }\n\n                            @Override\n                            public void onError(Throwable e) {\n                                System.err.println(\n                                        \"Error listing Java artifacts for user \"\n                                                + userId\n                                                + \" in session \"\n                                                + sessionId\n                                                + \": \"\n                                                + e.getMessage());\n                                // In a real application, you might return an error message to the user/LLM\n                            }\n                        });\n    }\n\n    // --- Example Usage Concept (Java) ---\n    public static void main(String[] args) {\n        // BaseArtifactService service = new InMemoryArtifactService(); // Or GcsArtifactService\n        // MyArtifactListerService lister = new MyArtifactListerService(service, \"myJavaApp\");\n        // lister.listUserFilesJava(\"user123\", \"sessionABC\");\n        // Due to async nature, in a real app, ensure program waits or handles completion.\n    }\n}"}]}, {"heading_path": ["Available Implementations\u00b6"], "text": "Available Implementations \u00b6 ADK provides concrete implementations of the BaseArtifactService interface, offering different storage backends suitable for various development stages and deployment needs. These implementations handle the details of storing, versioning, and retrieving artifact data based on the app_name , user_id , session_id , and filename (including the user: namespace prefix). ", "code_blocks": []}, {"heading_path": ["InMemoryArtifactService\u00b6"], "text": "InMemoryArtifactService \u00b6 Storage Mechanism: Python: Uses a Python dictionary ( self.artifacts ) held in the application's memory. The dictionary keys represent the artifact path, and the values are lists of types.Part , where each list element is a version. Java: Uses nested HashMap instances ( private final Map<String, Map<String, Map<String, Map<String, List<Part>>>>> artifacts; ) held in memory. The keys at each level are appName , userId , sessionId , and filename respectively. The innermost List<Part> stores the versions of the artifact, where the list index corresponds to the version number. Key Features: Simplicity: Requires no external setup or dependencies beyond the core ADK library. Speed: Operations are typically very fast as they involve in-memory map/dictionary lookups and list manipulations. Ephemeral: All stored artifacts are lost when the application process terminates. Data does not persist between application restarts. Use Cases: Ideal for local development and testing where persistence is not required. Suitable for short-lived demonstrations or scenarios where artifact data is purely temporary within a single run of the application. Instantiation: Python Go Java from google.adk.artifacts import InMemoryArtifactService # Simply instantiate the class in_memory_service_py = InMemoryArtifactService () # Then pass it to the Runner # runner = Runner(..., artifact_service=in_memory_service_py) import ( \"google.golang.org/adk/artifactservice\" ) // Simply instantiate the service artifactService := artifact . InMemoryService () log . Printf ( \"InMemoryArtifactService (Go) instantiated: %T\" , artifactService ) // Use the service in your runner // r, _ := runner.New(runner.Config{ //  Agent:           agent, //  AppName:         \"my_app\", //  SessionService:  sessionService, //  ArtifactService: artifactService, // }) import com.google.adk.artifacts.BaseArtifactService ; import com.google.adk.artifacts.InMemoryArtifactService ; public class InMemoryServiceSetup { public static void main ( String [] args ) { // Simply instantiate the class BaseArtifactService inMemoryServiceJava = new InMemoryArtifactService (); System . out . println ( \"InMemoryArtifactService (Java) instantiated: \" + inMemoryServiceJava . getClass (). getName ()); // This instance would then be provided to your Runner. // Runner runner = new Runner( //     /* other services */, //     inMemoryServiceJava // ); } } ", "code_blocks": [{"language": "text", "code": "from google.adk.artifacts import InMemoryArtifactService\n\n# Simply instantiate the class\nin_memory_service_py = InMemoryArtifactService()\n\n# Then pass it to the Runner\n# runner = Runner(..., artifact_service=in_memory_service_py)"}, {"language": "text", "code": "import (\n    \"google.golang.org/adk/artifactservice\"\n)\n\n// Simply instantiate the service\nartifactService := artifact.InMemoryService()\nlog.Printf(\"InMemoryArtifactService (Go) instantiated: %T\", artifactService)\n\n// Use the service in your runner\n// r, _ := runner.New(runner.Config{\n//  Agent:           agent,\n//  AppName:         \"my_app\",\n//  SessionService:  sessionService,\n//  ArtifactService: artifactService,\n// })"}, {"language": "text", "code": "import com.google.adk.artifacts.BaseArtifactService;\nimport com.google.adk.artifacts.InMemoryArtifactService;\n\npublic class InMemoryServiceSetup {\n    public static void main(String[] args) {\n        // Simply instantiate the class\n        BaseArtifactService inMemoryServiceJava = new InMemoryArtifactService();\n\n        System.out.println(\"InMemoryArtifactService (Java) instantiated: \" + inMemoryServiceJava.getClass().getName());\n\n        // This instance would then be provided to your Runner.\n        // Runner runner = new Runner(\n        //     /* other services */,\n        //     inMemoryServiceJava\n        // );\n    }\n}"}]}, {"heading_path": ["GcsArtifactService\u00b6"], "text": "GcsArtifactService \u00b6 Storage Mechanism: Leverages Google Cloud Storage (GCS) for persistent artifact storage. Each version of an artifact is stored as a separate object (blob) within a specified GCS bucket. Object Naming Convention: It constructs GCS object names (blob names) using a hierarchical path structure. Key Features: Persistence: Artifacts stored in GCS persist across application restarts and deployments. Scalability: Leverages the scalability and durability of Google Cloud Storage. Versioning: Explicitly stores each version as a distinct GCS object. The saveArtifact method in GcsArtifactService . Permissions Required: The application environment needs appropriate credentials (e.g., Application Default Credentials) and IAM permissions to read from and write to the specified GCS bucket. Use Cases: Production environments requiring persistent artifact storage. Scenarios where artifacts need to be shared across different application instances or services (by accessing the same GCS bucket). Applications needing long-term storage and retrieval of user or session data. Instantiation: Python Java from google.adk.artifacts import GcsArtifactService # Specify the GCS bucket name gcs_bucket_name_py = \"your-gcs-bucket-for-adk-artifacts\" # Replace with your bucket name try : gcs_service_py = GcsArtifactService ( bucket_name = gcs_bucket_name_py ) print ( f \"Python GcsArtifactService initialized for bucket: { gcs_bucket_name_py } \" ) # Ensure your environment has credentials to access this bucket. # e.g., via Application Default Credentials (ADC) # Then pass it to the Runner # runner = Runner(..., artifact_service=gcs_service_py) except Exception as e : # Catch potential errors during GCS client initialization (e.g., auth issues) print ( f \"Error initializing Python GcsArtifactService: { e } \" ) # Handle the error appropriately - maybe fall back to InMemory or raise import com.google.adk.artifacts.BaseArtifactService ; import com.google.adk.artifacts.GcsArtifactService ; import com.google.cloud.storage.Storage ; import com.google.cloud.storage.StorageOptions ; public class GcsServiceSetup { public static void main ( String [] args ) { // Specify the GCS bucket name String gcsBucketNameJava = \"your-gcs-bucket-for-adk-artifacts\" ; // Replace with your bucket name try { // Initialize the GCS Storage client. // This will use Application Default Credentials by default. // Ensure the environment is configured correctly (e.g., GOOGLE_APPLICATION_CREDENTIALS). Storage storageClient = StorageOptions . getDefaultInstance (). getService (); // Instantiate the GcsArtifactService BaseArtifactService gcsServiceJava = new GcsArtifactService ( gcsBucketNameJava , storageClient ); System . out . println ( \"Java GcsArtifactService initialized for bucket: \" + gcsBucketNameJava ); // This instance would then be provided to your Runner. // Runner runner = new Runner( //     /* other services */, //     gcsServiceJava // ); } catch ( Exception e ) { // Catch potential errors during GCS client initialization (e.g., auth, permissions) System . err . println ( \"Error initializing Java GcsArtifactService: \" + e . getMessage ()); e . printStackTrace (); // Handle the error appropriately } } } Choosing the appropriate ArtifactService implementation depends on your application's requirements for data persistence, scalability, and operational environment. ", "code_blocks": [{"language": "text", "code": "from google.adk.artifacts import GcsArtifactService\n\n# Specify the GCS bucket name\ngcs_bucket_name_py = \"your-gcs-bucket-for-adk-artifacts\" # Replace with your bucket name\n\ntry:\n    gcs_service_py = GcsArtifactService(bucket_name=gcs_bucket_name_py)\n    print(f\"Python GcsArtifactService initialized for bucket: {gcs_bucket_name_py}\")\n    # Ensure your environment has credentials to access this bucket.\n    # e.g., via Application Default Credentials (ADC)\n\n    # Then pass it to the Runner\n    # runner = Runner(..., artifact_service=gcs_service_py)\n\nexcept Exception as e:\n    # Catch potential errors during GCS client initialization (e.g., auth issues)\n    print(f\"Error initializing Python GcsArtifactService: {e}\")\n    # Handle the error appropriately - maybe fall back to InMemory or raise"}, {"language": "text", "code": "import com.google.adk.artifacts.BaseArtifactService;\nimport com.google.adk.artifacts.GcsArtifactService;\nimport com.google.cloud.storage.Storage;\nimport com.google.cloud.storage.StorageOptions;\n\npublic class GcsServiceSetup {\n  public static void main(String[] args) {\n    // Specify the GCS bucket name\n    String gcsBucketNameJava = \"your-gcs-bucket-for-adk-artifacts\"; // Replace with your bucket name\n\n    try {\n      // Initialize the GCS Storage client.\n      // This will use Application Default Credentials by default.\n      // Ensure the environment is configured correctly (e.g., GOOGLE_APPLICATION_CREDENTIALS).\n      Storage storageClient = StorageOptions.getDefaultInstance().getService();\n\n      // Instantiate the GcsArtifactService\n      BaseArtifactService gcsServiceJava =\n          new GcsArtifactService(gcsBucketNameJava, storageClient);\n\n      System.out.println(\n          \"Java GcsArtifactService initialized for bucket: \" + gcsBucketNameJava);\n\n      // This instance would then be provided to your Runner.\n      // Runner runner = new Runner(\n      //     /* other services */,\n      //     gcsServiceJava\n      // );\n\n    } catch (Exception e) {\n      // Catch potential errors during GCS client initialization (e.g., auth, permissions)\n      System.err.println(\"Error initializing Java GcsArtifactService: \" + e.getMessage());\n      e.printStackTrace();\n      // Handle the error appropriately\n    }\n  }\n}"}]}, {"heading_path": ["Best Practices\u00b6"], "text": "Best Practices \u00b6 To use artifacts effectively and maintainably: Choose the Right Service: Use InMemoryArtifactService for rapid prototyping, testing, and scenarios where persistence isn't needed. Use GcsArtifactService (or implement your own BaseArtifactService for other backends) for production environments requiring data persistence and scalability. Meaningful Filenames: Use clear, descriptive filenames. Including relevant extensions ( .pdf , .png , .wav ) helps humans understand the content, even though the mime_type dictates programmatic handling. Establish conventions for temporary vs. persistent artifact names. Specify Correct MIME Types: Always provide an accurate mime_type when creating the types.Part for save_artifact . This is critical for applications or tools that later load_artifact to interpret the bytes data correctly. Use standard IANA MIME types where possible. Understand Versioning: Remember that load_artifact() without a specific version argument retrieves the latest version. If your logic depends on a specific historical version of an artifact, be sure to provide the integer version number when loading. Use Namespacing ( user: ) Deliberately: Only use the \"user:\" prefix for filenames when the data truly belongs to the user and should be accessible across all their sessions. For data specific to a single conversation or session, use regular filenames without the prefix. Error Handling: Always check if an artifact_service is actually configured before calling context methods ( save_artifact , load_artifact , list_artifacts ) \u2013 they will raise a ValueError if the service is None . Check the return value of load_artifact , as it will be None if the artifact or version doesn't exist. Don't assume it always returns a Part . Be prepared to handle exceptions from the underlying storage service, especially with GcsArtifactService (e.g., google.api_core.exceptions.Forbidden for permission issues, NotFound if the bucket doesn't exist, network errors). Size Considerations: Artifacts are suitable for typical file sizes, but be mindful of potential costs and performance impacts with extremely large files, especially with cloud storage. InMemoryArtifactService can consume significant memory if storing many large artifacts. Evaluate if very large data might be better handled through direct GCS links or other specialized storage solutions rather than passing entire byte arrays in-memory. Cleanup Strategy: For persistent storage like GcsArtifactService , artifacts remain until explicitly deleted. If artifacts represent temporary data or have a limited lifespan, implement a strategy for cleanup. This might involve: Using GCS lifecycle policies on the bucket. Building specific tools or administrative functions that utilize the artifact_service.delete_artifact method (note: delete is not exposed via context objects for safety). Carefully managing filenames to allow pattern-based deletion if needed. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:39.192417", "source_type": "adk-docs"}
{"doc_id": "c843fff7ff781f86870500cb72b3d0aa528b4e79de30ee839ead1b9ba23e9a99", "url": "https://google.github.io/adk-docs/events", "title": "Events - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Events\u00b6"], "text": "Events \u00b6 Supported in ADK Python v0.1.0 Go v0.1.0 Java v0.1.0 Events are the fundamental units of information flow within the Agent Development Kit (ADK). They represent every significant occurrence during an agent's interaction lifecycle, from initial user input to the final response and all the steps in between. Understanding events is crucial because they are the primary way components communicate, state is managed, and control flow is directed. ", "code_blocks": []}, {"heading_path": ["What Events Are and Why They Matter\u00b6"], "text": "What Events Are and Why They Matter \u00b6 An Event in ADK is an immutable record representing a specific point in the agent's execution. It captures user messages, agent replies, requests to use tools (function calls), tool results, state changes, control signals, and errors. Python Go Java Technically, it's an instance of the google.adk.events.Event class, which builds upon the basic LlmResponse structure by adding essential ADK-specific metadata and an actions payload. # Conceptual Structure of an Event (Python) # from google.adk.events import Event, EventActions # from google.genai import types # class Event(LlmResponse): # Simplified view #     # --- LlmResponse fields --- #     content: Optional[types.Content] #     partial: Optional[bool] #     # ... other response fields ... #     # --- ADK specific additions --- #     author: str          # 'user' or agent name #     invocation_id: str   # ID for the whole interaction run #     id: str              # Unique ID for this specific event #     timestamp: float     # Creation time #     actions: EventActions # Important for side-effects & control #     branch: Optional[str] # Hierarchy path #     # ... In Go, this is a struct of type google.golang.org/adk/session.Event . // Conceptual Structure of an Event (Go - See session/session.go) // Simplified view based on the session.Event struct type Event struct { // --- Fields from embedded model.LLMResponse --- model . LLMResponse // --- ADK specific additions --- Author string // 'user' or agent name InvocationID string // ID for the whole interaction run ID string // Unique ID for this specific event Timestamp time . Time // Creation time Actions EventActions // Important for side-effects & control Branch string // Hierarchy path // ... other fields } // model.LLMResponse contains the Content field type LLMResponse struct { Content * genai . Content // ... other fields } In Java, this is an instance of the com.google.adk.events.Event class. It also builds upon a basic response structure by adding essential ADK-specific metadata and an actions payload. // Conceptual Structure of an Event (Java - See com.google.adk.events.Event.java) // Simplified view based on the provided com.google.adk.events.Event.java // public class Event extends JsonBaseModel { //     // --- Fields analogous to LlmResponse --- //     private Optional<Content> content; //     private Optional<Boolean> partial; //     // ... other response fields like errorCode, errorMessage ... //     // --- ADK specific additions --- //     private String author;         // 'user' or agent name //     private String invocationId;   // ID for the whole interaction run //     private String id;             // Unique ID for this specific event //     private long timestamp;        // Creation time (epoch milliseconds) //     private EventActions actions;  // Important for side-effects & control //     private Optional<String> branch; // Hierarchy path //     // ... other fields like turnComplete, longRunningToolIds etc. // } Events are central to ADK's operation for several key reasons: Communication: They serve as the standard message format between the user interface, the Runner , agents, the LLM, and tools. Everything flows as an Event . Signaling State & Artifact Changes: Events carry instructions for state modifications and track artifact updates. The SessionService uses these signals to ensure persistence. In Python changes are signaled via event.actions.state_delta and event.actions.artifact_delta . Control Flow: Specific fields like event.actions.transfer_to_agent or event.actions.escalate act as signals that direct the framework, determining which agent runs next or if a loop should terminate. History & Observability: The sequence of events recorded in session.events provides a complete, chronological history of an interaction, invaluable for debugging, auditing, and understanding agent behavior step-by-step. In essence, the entire process, from a user's query to the agent's final answer, is orchestrated through the generation, interpretation, and processing of Event objects. ", "code_blocks": [{"language": "text", "code": "# Conceptual Structure of an Event (Python)\n# from google.adk.events import Event, EventActions\n# from google.genai import types\n\n# class Event(LlmResponse): # Simplified view\n#     # --- LlmResponse fields ---\n#     content: Optional[types.Content]\n#     partial: Optional[bool]\n#     # ... other response fields ...\n\n#     # --- ADK specific additions ---\n#     author: str          # 'user' or agent name\n#     invocation_id: str   # ID for the whole interaction run\n#     id: str              # Unique ID for this specific event\n#     timestamp: float     # Creation time\n#     actions: EventActions # Important for side-effects & control\n#     branch: Optional[str] # Hierarchy path\n#     # ..."}, {"language": "text", "code": "// Conceptual Structure of an Event (Go - See session/session.go)\n// Simplified view based on the session.Event struct\ntype Event struct {\n    // --- Fields from embedded model.LLMResponse ---\n    model.LLMResponse\n\n    // --- ADK specific additions ---\n    Author       string         // 'user' or agent name\n    InvocationID string         // ID for the whole interaction run\n    ID           string         // Unique ID for this specific event\n    Timestamp    time.Time      // Creation time\n    Actions      EventActions   // Important for side-effects & control\n    Branch       string         // Hierarchy path\n    // ... other fields\n}\n\n// model.LLMResponse contains the Content field\ntype LLMResponse struct {\n    Content *genai.Content\n    // ... other fields\n}"}, {"language": "text", "code": "// Conceptual Structure of an Event (Java - See com.google.adk.events.Event.java)\n// Simplified view based on the provided com.google.adk.events.Event.java\n// public class Event extends JsonBaseModel {\n//     // --- Fields analogous to LlmResponse ---\n//     private Optional<Content> content;\n//     private Optional<Boolean> partial;\n//     // ... other response fields like errorCode, errorMessage ...\n\n//     // --- ADK specific additions ---\n//     private String author;         // 'user' or agent name\n//     private String invocationId;   // ID for the whole interaction run\n//     private String id;             // Unique ID for this specific event\n//     private long timestamp;        // Creation time (epoch milliseconds)\n//     private EventActions actions;  // Important for side-effects & control\n//     private Optional<String> branch; // Hierarchy path\n//     // ... other fields like turnComplete, longRunningToolIds etc.\n// }"}]}, {"heading_path": ["Understanding and Using Events\u00b6"], "text": "Understanding and Using Events \u00b6 As a developer, you'll primarily interact with the stream of events yielded by the Runner . Here's how to understand and extract information from them: Note The specific parameters or method names for the primitives may vary slightly by SDK language (e.g., event.content() in Python, event.content().get().parts() in Java). Refer to the language-specific API documentation for details. ", "code_blocks": []}, {"heading_path": ["Identifying Event Origin and Type\u00b6"], "text": "Identifying Event Origin and Type \u00b6 Quickly determine what an event represents by checking: Who sent it? ( event.author ) 'user' : Indicates input directly from the end-user. 'AgentName' : Indicates output or action from a specific agent (e.g., 'WeatherAgent' , 'SummarizerAgent' ). What's the main payload? ( event.content and event.content.parts ) Text: Indicates a conversational message. For Python, check if event.content.parts[0].text exists. For Java, check if event.content() is present, its parts() are present and not empty, and the first part's text() is present. Tool Call Request: Check event.get_function_calls() . If not empty, the LLM is asking to execute one or more tools. Each item in the list has .name and .args . Tool Result: Check event.get_function_responses() . If not empty, this event carries the result(s) from tool execution(s). Each item has .name and .response (the dictionary returned by the tool). Note: For history structuring, the role inside the content is often 'user' , but the event author is typically the agent that requested the tool call. Is it streaming output? ( event.partial ) Indicates whether this is an incomplete chunk of text from the LLM. True : More text will follow. False or None / Optional.empty() : This part of the content is complete (though the overall turn might not be finished if turn_complete is also false). Python Go Java # Pseudocode: Basic event identification (Python) # async for event in runner.run_async(...): #     print(f\"Event from: {event.author}\") # #     if event.content and event.content.parts: #         if event.get_function_calls(): #             print(\"  Type: Tool Call Request\") #         elif event.get_function_responses(): #             print(\"  Type: Tool Result\") #         elif event.content.parts[0].text: #             if event.partial: #                 print(\"  Type: Streaming Text Chunk\") #             else: #                 print(\"  Type: Complete Text Message\") #         else: #             print(\"  Type: Other Content (e.g., code result)\") #     elif event.actions and (event.actions.state_delta or event.actions.artifact_delta): #         print(\"  Type: State/Artifact Update\") #     else: #         print(\"  Type: Control Signal or Other\") // Pseudocode: Basic event identification (Go) import ( \"fmt\" \"google.golang.org/adk/session\" \"google.golang.org/genai\" ) func hasFunctionCalls ( content * genai . Content ) bool { if content == nil { return false } for _ , part := range content . Parts { if part . FunctionCall != nil { return true } } return false } func hasFunctionResponses ( content * genai . Content ) bool { if content == nil { return false } for _ , part := range content . Parts { if part . FunctionResponse != nil { return true } } return false } func processEvents ( events <- chan * session . Event ) { for event := range events { fmt . Printf ( \"Event from: %s\\n\" , event . Author ) if event . LLMResponse != nil && event . LLMResponse . Content != nil { if hasFunctionCalls ( event . LLMResponse . Content ) { fmt . Println ( \"  Type: Tool Call Request\" ) } else if hasFunctionResponses ( event . LLMResponse . Content ) { fmt . Println ( \"  Type: Tool Result\" ) } else if len ( event . LLMResponse . Content . Parts ) > 0 { if event . LLMResponse . Content . Parts [ 0 ]. Text != \"\" { if event . LLMResponse . Partial { fmt . Println ( \"  Type: Streaming Text Chunk\" ) } else { fmt . Println ( \"  Type: Complete Text Message\" ) } } else { fmt . Println ( \"  Type: Other Content (e.g., code result)\" ) } } } else if len ( event . Actions . StateDelta ) > 0 { fmt . Println ( \"  Type: State Update\" ) } else { fmt . Println ( \"  Type: Control Signal or Other\" ) } } } // Pseudocode: Basic event identification (Java) // import com.google.genai.types.Content; // import com.google.adk.events.Event; // import com.google.adk.events.EventActions; // runner.runAsync(...).forEach(event -> { // Assuming a synchronous stream or reactive stream //     System.out.println(\"Event from: \" + event.author()); // //     if (event.content().isPresent()) { //         Content content = event.content().get(); //         if (!event.functionCalls().isEmpty()) { //             System.out.println(\"  Type: Tool Call Request\"); //         } else if (!event.functionResponses().isEmpty()) { //             System.out.println(\"  Type: Tool Result\"); //         } else if (content.parts().isPresent() && !content.parts().get().isEmpty() && //                    content.parts().get().get(0).text().isPresent()) { //             if (event.partial().orElse(false)) { //                 System.out.println(\"  Type: Streaming Text Chunk\"); //             } else { //                 System.out.println(\"  Type: Complete Text Message\"); //             } //         } else { //             System.out.println(\"  Type: Other Content (e.g., code result)\"); //         } //     } else if (event.actions() != null && //                ((event.actions().stateDelta() != null && !event.actions().stateDelta().isEmpty()) || //                 (event.actions().artifactDelta() != null && !event.actions().artifactDelta().isEmpty()))) { //         System.out.println(\"  Type: State/Artifact Update\"); //     } else { //         System.out.println(\"  Type: Control Signal or Other\"); //     } // }); ", "code_blocks": [{"language": "text", "code": "# Pseudocode: Basic event identification (Python)\n# async for event in runner.run_async(...):\n#     print(f\"Event from: {event.author}\")\n#\n#     if event.content and event.content.parts:\n#         if event.get_function_calls():\n#             print(\"  Type: Tool Call Request\")\n#         elif event.get_function_responses():\n#             print(\"  Type: Tool Result\")\n#         elif event.content.parts[0].text:\n#             if event.partial:\n#                 print(\"  Type: Streaming Text Chunk\")\n#             else:\n#                 print(\"  Type: Complete Text Message\")\n#         else:\n#             print(\"  Type: Other Content (e.g., code result)\")\n#     elif event.actions and (event.actions.state_delta or event.actions.artifact_delta):\n#         print(\"  Type: State/Artifact Update\")\n#     else:\n#         print(\"  Type: Control Signal or Other\")"}, {"language": "text", "code": "// Pseudocode: Basic event identification (Go)\nimport (\n  \"fmt\"\n  \"google.golang.org/adk/session\"\n  \"google.golang.org/genai\"\n)\n\nfunc hasFunctionCalls(content *genai.Content) bool {\n  if content == nil {\n    return false\n  }\n  for _, part := range content.Parts {\n    if part.FunctionCall != nil {\n      return true\n    }\n  }\n  return false\n}\n\nfunc hasFunctionResponses(content *genai.Content) bool {\n  if content == nil {\n    return false\n  }\n  for _, part := range content.Parts {\n    if part.FunctionResponse != nil {\n      return true\n    }\n  }\n  return false\n}\n\nfunc processEvents(events <-chan *session.Event) {\n  for event := range events {\n    fmt.Printf(\"Event from: %s\\n\", event.Author)\n\n    if event.LLMResponse != nil && event.LLMResponse.Content != nil {\n      if hasFunctionCalls(event.LLMResponse.Content) {\n        fmt.Println(\"  Type: Tool Call Request\")\n      } else if hasFunctionResponses(event.LLMResponse.Content) {\n        fmt.Println(\"  Type: Tool Result\")\n      } else if len(event.LLMResponse.Content.Parts) > 0 {\n        if event.LLMResponse.Content.Parts[0].Text != \"\" {\n          if event.LLMResponse.Partial {\n            fmt.Println(\"  Type: Streaming Text Chunk\")\n          } else {\n            fmt.Println(\"  Type: Complete Text Message\")\n          }\n        } else {\n          fmt.Println(\"  Type: Other Content (e.g., code result)\")\n        }\n      }\n    } else if len(event.Actions.StateDelta) > 0 {\n      fmt.Println(\"  Type: State Update\")\n    } else {\n      fmt.Println(\"  Type: Control Signal or Other\")\n    }\n  }\n}"}, {"language": "text", "code": "// Pseudocode: Basic event identification (Java)\n// import com.google.genai.types.Content;\n// import com.google.adk.events.Event;\n// import com.google.adk.events.EventActions;\n\n// runner.runAsync(...).forEach(event -> { // Assuming a synchronous stream or reactive stream\n//     System.out.println(\"Event from: \" + event.author());\n//\n//     if (event.content().isPresent()) {\n//         Content content = event.content().get();\n//         if (!event.functionCalls().isEmpty()) {\n//             System.out.println(\"  Type: Tool Call Request\");\n//         } else if (!event.functionResponses().isEmpty()) {\n//             System.out.println(\"  Type: Tool Result\");\n//         } else if (content.parts().isPresent() && !content.parts().get().isEmpty() &&\n//                    content.parts().get().get(0).text().isPresent()) {\n//             if (event.partial().orElse(false)) {\n//                 System.out.println(\"  Type: Streaming Text Chunk\");\n//             } else {\n//                 System.out.println(\"  Type: Complete Text Message\");\n//             }\n//         } else {\n//             System.out.println(\"  Type: Other Content (e.g., code result)\");\n//         }\n//     } else if (event.actions() != null &&\n//                ((event.actions().stateDelta() != null && !event.actions().stateDelta().isEmpty()) ||\n//                 (event.actions().artifactDelta() != null && !event.actions().artifactDelta().isEmpty()))) {\n//         System.out.println(\"  Type: State/Artifact Update\");\n//     } else {\n//         System.out.println(\"  Type: Control Signal or Other\");\n//     }\n// });"}]}, {"heading_path": ["Extracting Key Information\u00b6"], "text": "Extracting Key Information \u00b6 Once you know the event type, access the relevant data: Text Content: Always check for the presence of content and parts before accessing text. In Python its text = event.content.parts[0].text . Function Call Details: Python Go Java calls = event . get_function_calls () if calls : for call in calls : tool_name = call . name arguments = call . args # This is usually a dictionary print ( f \"  Tool: { tool_name } , Args: { arguments } \" ) # Application might dispatch execution based on this import ( \"fmt\" \"google.golang.org/adk/session\" \"google.golang.org/genai\" ) func handleFunctionCalls ( event * session . Event ) { if event . LLMResponse == nil || event . LLMResponse . Content == nil { return } calls := event . Content . FunctionCalls () if len ( calls ) > 0 { for _ , call := range calls { toolName := call . Name arguments := call . Args fmt . Printf ( \"  Tool: %s, Args: %v\\n\" , toolName , arguments ) // Application might dispatch execution based on this } } } import com.google.genai.types.FunctionCall ; import com.google.common.collect.ImmutableList ; import java.util.Map ; ImmutableList < FunctionCall > calls = event . functionCalls (); // from Event.java if ( ! calls . isEmpty ()) { for ( FunctionCall call : calls ) { String toolName = call . name (). get (); // args is Optional<Map<String, Object>> Map < String , Object > arguments = call . args (). get (); System . out . println ( \"  Tool: \" + toolName + \", Args: \" + arguments ); // Application might dispatch execution based on this } } Function Response Details: Python Go Java responses = event . get_function_responses () if responses : for response in responses : tool_name = response . name result_dict = response . response # The dictionary returned by the tool print ( f \"  Tool Result: { tool_name } -> { result_dict } \" ) import ( \"fmt\" \"google.golang.org/adk/session\" \"google.golang.org/genai\" ) func handleFunctionResponses ( event * session . Event ) { if event . LLMResponse == nil || event . LLMResponse . Content == nil { return } responses := event . Content . FunctionResponses () if len ( responses ) > 0 { for _ , response := range responses { toolName := response . Name result := response . Response fmt . Printf ( \"  Tool Result: %s -> %v\\n\" , toolName , result ) } } } import com.google.genai.types.FunctionResponse ; import com.google.common.collect.ImmutableList ; import java.util.Map ; ImmutableList < FunctionResponse > responses = event . functionResponses (); // from Event.java if ( ! responses . isEmpty ()) { for ( FunctionResponse response : responses ) { String toolName = response . name (). get (); Map < String , String > result = response . response (). get (); // Check before getting the response System . out . println ( \"  Tool Result: \" + toolName + \" -> \" + result ); } } Identifiers: event.id : Unique ID for this specific event instance. event.invocation_id : ID for the entire user-request-to-final-response cycle this event belongs to. Useful for logging and tracing. ", "code_blocks": [{"language": "text", "code": "calls = event.get_function_calls()\nif calls:\n    for call in calls:\n        tool_name = call.name\n        arguments = call.args # This is usually a dictionary\n        print(f\"  Tool: {tool_name}, Args: {arguments}\")\n        # Application might dispatch execution based on this"}, {"language": "text", "code": "import (\n    \"fmt\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/genai\"\n)\n\nfunc handleFunctionCalls(event *session.Event) {\n    if event.LLMResponse == nil || event.LLMResponse.Content == nil {\n        return\n    }\n    calls := event.Content.FunctionCalls()\n    if len(calls) > 0 {\n        for _, call := range calls {\n            toolName := call.Name\n            arguments := call.Args\n            fmt.Printf(\"  Tool: %s, Args: %v\\n\", toolName, arguments)\n            // Application might dispatch execution based on this\n        }\n    }\n}"}, {"language": "text", "code": "import com.google.genai.types.FunctionCall;\nimport com.google.common.collect.ImmutableList;\nimport java.util.Map;\n\nImmutableList<FunctionCall> calls = event.functionCalls(); // from Event.java\nif (!calls.isEmpty()) {\n  for (FunctionCall call : calls) {\n    String toolName = call.name().get();\n    // args is Optional<Map<String, Object>>\n    Map<String, Object> arguments = call.args().get();\n           System.out.println(\"  Tool: \" + toolName + \", Args: \" + arguments);\n    // Application might dispatch execution based on this\n  }\n}"}, {"language": "text", "code": "responses = event.get_function_responses()\nif responses:\n    for response in responses:\n        tool_name = response.name\n        result_dict = response.response # The dictionary returned by the tool\n        print(f\"  Tool Result: {tool_name} -> {result_dict}\")"}, {"language": "text", "code": "import (\n    \"fmt\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/genai\"\n)\n\nfunc handleFunctionResponses(event *session.Event) {\n    if event.LLMResponse == nil || event.LLMResponse.Content == nil {\n        return\n    }\n    responses := event.Content.FunctionResponses()\n    if len(responses) > 0 {\n        for _, response := range responses {\n            toolName := response.Name\n            result := response.Response\n            fmt.Printf(\"  Tool Result: %s -> %v\\n\", toolName, result)\n        }\n    }\n}"}, {"language": "text", "code": "import com.google.genai.types.FunctionResponse;\nimport com.google.common.collect.ImmutableList;\nimport java.util.Map;\n\nImmutableList<FunctionResponse> responses = event.functionResponses(); // from Event.java\nif (!responses.isEmpty()) {\n    for (FunctionResponse response : responses) {\n        String toolName = response.name().get();\n        Map<String, String> result= response.response().get(); // Check before getting the response\n        System.out.println(\"  Tool Result: \" + toolName + \" -> \" + result);\n    }\n}"}]}, {"heading_path": ["Detecting Actions and Side Effects\u00b6"], "text": "Detecting Actions and Side Effects \u00b6 The event.actions object signals changes that occurred or should occur. Always check if event.actions and it's fields/ methods exists before accessing them. State Changes: Gives you a collection of key-value pairs that were modified in the session state during the step that produced this event. Python Go Java delta = event.actions.state_delta (a dictionary of {key: value} pairs). if event . actions and event . actions . state_delta : print ( f \"  State changes: { event . actions . state_delta } \" ) # Update local UI or application state if necessary delta := event.Actions.StateDelta (a map[string]any ) import ( \"fmt\" \"google.golang.org/adk/session\" ) func handleStateChanges ( event * session . Event ) { if len ( event . Actions . StateDelta ) > 0 { fmt . Printf ( \"  State changes: %v\\n\" , event . Actions . StateDelta ) // Update local UI or application state if necessary } } ConcurrentMap<String, Object> delta = event.actions().stateDelta(); import java.util.concurrent.ConcurrentMap ; import com.google.adk.events.EventActions ; EventActions actions = event . actions (); // Assuming event.actions() is not null if ( actions != null && actions . stateDelta () != null && ! actions . stateDelta (). isEmpty ()) { ConcurrentMap < String , Object > stateChanges = actions . stateDelta (); System . out . println ( \"  State changes: \" + stateChanges ); // Update local UI or application state if necessary } Artifact Saves: Gives you a collection indicating which artifacts were saved and their new version number (or relevant Part information). Python Go Java artifact_changes = event.actions.artifact_delta (a dictionary of {filename: version} ). if event . actions and event . actions . artifact_delta : print ( f \"  Artifacts saved: { event . actions . artifact_delta } \" ) # UI might refresh an artifact list artifactChanges := event.Actions.ArtifactDelta (a map[string]artifact.Artifact ) import ( \"fmt\" \"google.golang.org/adk/artifact\" \"google.golang.org/adk/session\" ) func handleArtifactChanges ( event * session . Event ) { if len ( event . Actions . ArtifactDelta ) > 0 { fmt . Printf ( \"  Artifacts saved: %v\\n\" , event . Actions . ArtifactDelta ) // UI might refresh an artifact list // Iterate through event.Actions.ArtifactDelta to get filename and artifact.Artifact details for filename , art := range event . Actions . ArtifactDelta { fmt . Printf ( \"    Filename: %s, Version: %d, MIMEType: %s\\n\" , filename , art . Version , art . MIMEType ) } } } ConcurrentMap<String, Part> artifactChanges = event.actions().artifactDelta(); import java.util.concurrent.ConcurrentMap ; import com.google.genai.types.Part ; import com.google.adk.events.EventActions ; EventActions actions = event . actions (); // Assuming event.actions() is not null if ( actions != null && actions . artifactDelta () != null && ! actions . artifactDelta (). isEmpty ()) { ConcurrentMap < String , Part > artifactChanges = actions . artifactDelta (); System . out . println ( \"  Artifacts saved: \" + artifactChanges ); // UI might refresh an artifact list // Iterate through artifactChanges.entrySet() to get filename and Part details } Control Flow Signals: Check boolean flags or string values: Python Go Java event.actions.transfer_to_agent (string): Control should pass to the named agent. event.actions.escalate (bool): A loop should terminate. event.actions.skip_summarization (bool): A tool result should not be summarized by the LLM. if event . actions : if event . actions . transfer_to_agent : print ( f \"  Signal: Transfer to { event . actions . transfer_to_agent } \" ) if event . actions . escalate : print ( \"  Signal: Escalate (terminate loop)\" ) if event . actions . skip_summarization : print ( \"  Signal: Skip summarization for tool result\" ) event.Actions.TransferToAgent (string): Control should pass to the named agent. event.Actions.Escalate (bool): A loop should terminate. event.Actions.SkipSummarization (bool): A tool result should not be summarized by the LLM. import ( \"fmt\" \"google.golang.org/adk/session\" ) func handleControlFlow ( event * session . Event ) { if event . Actions . TransferToAgent != \"\" { fmt . Printf ( \"  Signal: Transfer to %s\\n\" , event . Actions . TransferToAgent ) } if event . Actions . Escalate { fmt . Println ( \"  Signal: Escalate (terminate loop)\" ) } if event . Actions . SkipSummarization { fmt . Println ( \"  Signal: Skip summarization for tool result\" ) } } event.actions().transferToAgent() (returns Optional<String> ): Control should pass to the named agent. event.actions().escalate() (returns Optional<Boolean> ): A loop should terminate. event.actions().skipSummarization() (returns Optional<Boolean> ): A tool result should not be summarized by the LLM. import com.google.adk.events.EventActions ; import java.util.Optional ; EventActions actions = event . actions (); // Assuming event.actions() is not null if ( actions != null ) { Optional < String > transferAgent = actions . transferToAgent (); if ( transferAgent . isPresent ()) { System . out . println ( \"  Signal: Transfer to \" + transferAgent . get ()); } Optional < Boolean > escalate = actions . escalate (); if ( escalate . orElse ( false )) { // or escalate.isPresent() && escalate.get() System . out . println ( \"  Signal: Escalate (terminate loop)\" ); } Optional < Boolean > skipSummarization = actions . skipSummarization (); if ( skipSummarization . orElse ( false )) { // or skipSummarization.isPresent() && skipSummarization.get() System . out . println ( \"  Signal: Skip summarization for tool result\" ); } } ", "code_blocks": [{"language": "text", "code": "if event.actions and event.actions.state_delta:\n    print(f\"  State changes: {event.actions.state_delta}\")\n    # Update local UI or application state if necessary"}, {"language": "text", "code": "import (\n    \"fmt\"\n    \"google.golang.org/adk/session\"\n)\n\nfunc handleStateChanges(event *session.Event) {\n    if len(event.Actions.StateDelta) > 0 {\n        fmt.Printf(\"  State changes: %v\\n\", event.Actions.StateDelta)\n        // Update local UI or application state if necessary\n    }\n}"}, {"language": "text", "code": "import java.util.concurrent.ConcurrentMap;\nimport com.google.adk.events.EventActions;\n\nEventActions actions = event.actions(); // Assuming event.actions() is not null\nif (actions != null && actions.stateDelta() != null && !actions.stateDelta().isEmpty()) {\n    ConcurrentMap<String, Object> stateChanges = actions.stateDelta();\n    System.out.println(\"  State changes: \" + stateChanges);\n    // Update local UI or application state if necessary\n}"}, {"language": "text", "code": "if event.actions and event.actions.artifact_delta:\n    print(f\"  Artifacts saved: {event.actions.artifact_delta}\")\n    # UI might refresh an artifact list"}, {"language": "text", "code": "import (\n    \"fmt\"\n    \"google.golang.org/adk/artifact\"\n    \"google.golang.org/adk/session\"\n)\n\nfunc handleArtifactChanges(event *session.Event) {\n    if len(event.Actions.ArtifactDelta) > 0 {\n        fmt.Printf(\"  Artifacts saved: %v\\n\", event.Actions.ArtifactDelta)\n        // UI might refresh an artifact list\n        // Iterate through event.Actions.ArtifactDelta to get filename and artifact.Artifact details\n        for filename, art := range event.Actions.ArtifactDelta {\n            fmt.Printf(\"    Filename: %s, Version: %d, MIMEType: %s\\n\", filename, art.Version, art.MIMEType)\n        }\n    }\n}"}, {"language": "text", "code": "import java.util.concurrent.ConcurrentMap;\nimport com.google.genai.types.Part;\nimport com.google.adk.events.EventActions;\n\nEventActions actions = event.actions(); // Assuming event.actions() is not null\nif (actions != null && actions.artifactDelta() != null && !actions.artifactDelta().isEmpty()) {\n    ConcurrentMap<String, Part> artifactChanges = actions.artifactDelta();\n    System.out.println(\"  Artifacts saved: \" + artifactChanges);\n    // UI might refresh an artifact list\n    // Iterate through artifactChanges.entrySet() to get filename and Part details\n}"}, {"language": "text", "code": "if event.actions:\n    if event.actions.transfer_to_agent:\n        print(f\"  Signal: Transfer to {event.actions.transfer_to_agent}\")\n    if event.actions.escalate:\n        print(\"  Signal: Escalate (terminate loop)\")\n    if event.actions.skip_summarization:\n        print(\"  Signal: Skip summarization for tool result\")"}, {"language": "text", "code": "import (\n    \"fmt\"\n    \"google.golang.org/adk/session\"\n)\n\nfunc handleControlFlow(event *session.Event) {\n    if event.Actions.TransferToAgent != \"\" {\n        fmt.Printf(\"  Signal: Transfer to %s\\n\", event.Actions.TransferToAgent)\n    }\n    if event.Actions.Escalate {\n        fmt.Println(\"  Signal: Escalate (terminate loop)\")\n    }\n    if event.Actions.SkipSummarization {\n        fmt.Println(\"  Signal: Skip summarization for tool result\")\n    }\n}"}, {"language": "text", "code": "import com.google.adk.events.EventActions;\nimport java.util.Optional;\n\nEventActions actions = event.actions(); // Assuming event.actions() is not null\nif (actions != null) {\n    Optional<String> transferAgent = actions.transferToAgent();\n    if (transferAgent.isPresent()) {\n        System.out.println(\"  Signal: Transfer to \" + transferAgent.get());\n    }\n\n    Optional<Boolean> escalate = actions.escalate();\n    if (escalate.orElse(false)) { // or escalate.isPresent() && escalate.get()\n        System.out.println(\"  Signal: Escalate (terminate loop)\");\n    }\n\n    Optional<Boolean> skipSummarization = actions.skipSummarization();\n    if (skipSummarization.orElse(false)) { // or skipSummarization.isPresent() && skipSummarization.get()\n        System.out.println(\"  Signal: Skip summarization for tool result\");\n    }\n}"}]}, {"heading_path": ["Determining if an Event is a \"Final\" Response\u00b6"], "text": "Determining if an Event is a \"Final\" Response \u00b6 Use the built-in helper method event.is_final_response() to identify events suitable for display as the agent's complete output for a turn. Purpose: Filters out intermediate steps (like tool calls, partial streaming text, internal state updates) from the final user-facing message(s). When True ? The event contains a tool result ( function_response ) and skip_summarization is True . The event contains a tool call ( function_call ) for a tool marked as is_long_running=True . In Java, check if the longRunningToolIds list is empty: event.longRunningToolIds().isPresent() && !event.longRunningToolIds().get().isEmpty() is true . OR, all of the following are met: No function calls ( get_function_calls() is empty). No function responses ( get_function_responses() is empty). Not a partial stream chunk ( partial is not True ). Doesn't end with a code execution result that might need further processing/display. Usage: Filter the event stream in your application logic. Python Go Java # Pseudocode: Handling final responses in application (Python) # full_response_text = \"\" # async for event in runner.run_async(...): #     # Accumulate streaming text if needed... #     if event.partial and event.content and event.content.parts and event.content.parts[0].text: #         full_response_text += event.content.parts[0].text # #     # Check if it's a final, displayable event #     if event.is_final_response(): #         print(\"\\n--- Final Output Detected ---\") #         if event.content and event.content.parts and event.content.parts[0].text: #              # If it's the final part of a stream, use accumulated text #              final_text = full_response_text + (event.content.parts[0].text if not event.partial else \"\") #              print(f\"Display to user: {final_text.strip()}\") #              full_response_text = \"\" # Reset accumulator #         elif event.actions and event.actions.skip_summarization and event.get_function_responses(): #              # Handle displaying the raw tool result if needed #              response_data = event.get_function_responses()[0].response #              print(f\"Display raw tool result: {response_data}\") #         elif hasattr(event, 'long_running_tool_ids') and event.long_running_tool_ids: #              print(\"Display message: Tool is running in background...\") #         else: #              # Handle other types of final responses if applicable #              print(\"Display: Final non-textual response or signal.\") // Pseudocode: Handling final responses in application (Go) import ( \"fmt\" \"strings\" \"google.golang.org/adk/session\" \"google.golang.org/genai\" ) // isFinalResponse checks if an event is a final response suitable for display. func isFinalResponse ( event * session . Event ) bool { if event . LLMResponse != nil { // Condition 1: Tool result with skip summarization. if event . LLMResponse . Content != nil && len ( event . LLMResponse . Content . FunctionResponses ()) > 0 && event . Actions . SkipSummarization { return true } // Condition 2: Long-running tool call. if len ( event . LongRunningToolIDs ) > 0 { return true } // Condition 3: A complete message without tool calls or responses. if ( event . LLMResponse . Content == nil || ( len ( event . LLMResponse . Content . FunctionCalls ()) == 0 && len ( event . LLMResponse . Content . FunctionResponses ()) == 0 )) && ! event . LLMResponse . Partial { return true } } return false } func handleFinalResponses () { var fullResponseText strings . Builder // for event := range runner.Run(...) { // Example loop //  // Accumulate streaming text if needed... //  if event.LLMResponse != nil && event.LLMResponse.Partial && event.LLMResponse.Content != nil { //      if len(event.LLMResponse.Content.Parts) > 0 && event.LLMResponse.Content.Parts[0].Text != \"\" { //          fullResponseText.WriteString(event.LLMResponse.Content.Parts[0].Text) //      } //  } // //  // Check if it's a final, displayable event //  if isFinalResponse(event) { //      fmt.Println(\"\\n--- Final Output Detected ---\") //      if event.LLMResponse != nil && event.LLMResponse.Content != nil { //          if len(event.LLMResponse.Content.Parts) > 0 && event.LLMResponse.Content.Parts[0].Text != \"\" { //              // If it's the final part of a stream, use accumulated text //              finalText := fullResponseText.String() //              if !event.LLMResponse.Partial { //                  finalText += event.LLMResponse.Content.Parts[0].Text //              } //              fmt.Printf(\"Display to user: %s\\n\", strings.TrimSpace(finalText)) //              fullResponseText.Reset() // Reset accumulator //          } //      } else if event.Actions.SkipSummarization && event.LLMResponse.Content != nil && len(event.LLMResponse.Content.FunctionResponses()) > 0 { //          // Handle displaying the raw tool result if needed //          responseData := event.LLMResponse.Content.FunctionResponses()[0].Response //          fmt.Printf(\"Display raw tool result: %v\\n\", responseData) //      } else if len(event.LongRunningToolIDs) > 0 { //          fmt.Println(\"Display message: Tool is running in background...\") //      } else { //          // Handle other types of final responses if applicable //          fmt.Println(\"Display: Final non-textual response or signal.\") //      } //  } // } } // Pseudocode: Handling final responses in application (Java) import com.google.adk.events.Event ; import com.google.genai.types.Content ; import com.google.genai.types.FunctionResponse ; import java.util.Map ; StringBuilder fullResponseText = new StringBuilder (); runner . run (...). forEach ( event -> { // Assuming a stream of events // Accumulate streaming text if needed... if ( event . partial (). orElse ( false ) && event . content (). isPresent ()) { event . content (). flatMap ( Content :: parts ). ifPresent ( parts -> { if ( ! parts . isEmpty () && parts . get ( 0 ). text (). isPresent ()) { fullResponseText . append ( parts . get ( 0 ). text (). get ()); } }); } // Check if it's a final, displayable event if ( event . finalResponse ()) { // Using the method from Event.java System . out . println ( \"\\n--- Final Output Detected ---\" ); if ( event . content (). isPresent () && event . content (). flatMap ( Content :: parts ). map ( parts -> ! parts . isEmpty () && parts . get ( 0 ). text (). isPresent ()). orElse ( false )) { // If it's the final part of a stream, use accumulated text String eventText = event . content (). get (). parts (). get (). get ( 0 ). text (). get (); String finalText = fullResponseText . toString () + ( event . partial (). orElse ( false ) ? \"\" : eventText ); System . out . println ( \"Display to user: \" + finalText . trim ()); fullResponseText . setLength ( 0 ); // Reset accumulator } else if ( event . actions () != null && event . actions (). skipSummarization (). orElse ( false ) && ! event . functionResponses (). isEmpty ()) { // Handle displaying the raw tool result if needed, // especially if finalResponse() was true due to other conditions // or if you want to display skipped summarization results regardless of finalResponse() Map < String , Object > responseData = event . functionResponses (). get ( 0 ). response (). get (); System . out . println ( \"Display raw tool result: \" + responseData ); } else if ( event . longRunningToolIds (). isPresent () && ! event . longRunningToolIds (). get (). isEmpty ()) { // This case is covered by event.finalResponse() System . out . println ( \"Display message: Tool is running in background...\" ); } else { // Handle other types of final responses if applicable System . out . println ( \"Display: Final non-textual response or signal.\" ); } } }); By carefully examining these aspects of an event, you can build robust applications that react appropriately to the rich information flowing through the ADK system. ", "code_blocks": [{"language": "text", "code": "# Pseudocode: Handling final responses in application (Python)\n# full_response_text = \"\"\n# async for event in runner.run_async(...):\n#     # Accumulate streaming text if needed...\n#     if event.partial and event.content and event.content.parts and event.content.parts[0].text:\n#         full_response_text += event.content.parts[0].text\n#\n#     # Check if it's a final, displayable event\n#     if event.is_final_response():\n#         print(\"\\n--- Final Output Detected ---\")\n#         if event.content and event.content.parts and event.content.parts[0].text:\n#              # If it's the final part of a stream, use accumulated text\n#              final_text = full_response_text + (event.content.parts[0].text if not event.partial else \"\")\n#              print(f\"Display to user: {final_text.strip()}\")\n#              full_response_text = \"\" # Reset accumulator\n#         elif event.actions and event.actions.skip_summarization and event.get_function_responses():\n#              # Handle displaying the raw tool result if needed\n#              response_data = event.get_function_responses()[0].response\n#              print(f\"Display raw tool result: {response_data}\")\n#         elif hasattr(event, 'long_running_tool_ids') and event.long_running_tool_ids:\n#              print(\"Display message: Tool is running in background...\")\n#         else:\n#              # Handle other types of final responses if applicable\n#              print(\"Display: Final non-textual response or signal.\")"}, {"language": "text", "code": "// Pseudocode: Handling final responses in application (Go)\nimport (\n    \"fmt\"\n    \"strings\"\n    \"google.golang.org/adk/session\"\n    \"google.golang.org/genai\"\n)\n\n// isFinalResponse checks if an event is a final response suitable for display.\nfunc isFinalResponse(event *session.Event) bool {\n    if event.LLMResponse != nil {\n        // Condition 1: Tool result with skip summarization.\n        if event.LLMResponse.Content != nil && len(event.LLMResponse.Content.FunctionResponses()) > 0 && event.Actions.SkipSummarization {\n            return true\n        }\n        // Condition 2: Long-running tool call.\n        if len(event.LongRunningToolIDs) > 0 {\n            return true\n        }\n        // Condition 3: A complete message without tool calls or responses.\n        if (event.LLMResponse.Content == nil ||\n            (len(event.LLMResponse.Content.FunctionCalls()) == 0 && len(event.LLMResponse.Content.FunctionResponses()) == 0)) &&\n            !event.LLMResponse.Partial {\n            return true\n        }\n    }\n    return false\n}\n\nfunc handleFinalResponses() {\n    var fullResponseText strings.Builder\n    // for event := range runner.Run(...) { // Example loop\n    //  // Accumulate streaming text if needed...\n    //  if event.LLMResponse != nil && event.LLMResponse.Partial && event.LLMResponse.Content != nil {\n    //      if len(event.LLMResponse.Content.Parts) > 0 && event.LLMResponse.Content.Parts[0].Text != \"\" {\n    //          fullResponseText.WriteString(event.LLMResponse.Content.Parts[0].Text)\n    //      }\n    //  }\n    //\n    //  // Check if it's a final, displayable event\n    //  if isFinalResponse(event) {\n    //      fmt.Println(\"\\n--- Final Output Detected ---\")\n    //      if event.LLMResponse != nil && event.LLMResponse.Content != nil {\n    //          if len(event.LLMResponse.Content.Parts) > 0 && event.LLMResponse.Content.Parts[0].Text != \"\" {\n    //              // If it's the final part of a stream, use accumulated text\n    //              finalText := fullResponseText.String()\n    //              if !event.LLMResponse.Partial {\n    //                  finalText += event.LLMResponse.Content.Parts[0].Text\n    //              }\n    //              fmt.Printf(\"Display to user: %s\\n\", strings.TrimSpace(finalText))\n    //              fullResponseText.Reset() // Reset accumulator\n    //          }\n    //      } else if event.Actions.SkipSummarization && event.LLMResponse.Content != nil && len(event.LLMResponse.Content.FunctionResponses()) > 0 {\n    //          // Handle displaying the raw tool result if needed\n    //          responseData := event.LLMResponse.Content.FunctionResponses()[0].Response\n    //          fmt.Printf(\"Display raw tool result: %v\\n\", responseData)\n    //      } else if len(event.LongRunningToolIDs) > 0 {\n    //          fmt.Println(\"Display message: Tool is running in background...\")\n    //      } else {\n    //          // Handle other types of final responses if applicable\n    //          fmt.Println(\"Display: Final non-textual response or signal.\")\n    //      }\n    //  }\n    // }\n}"}, {"language": "text", "code": "// Pseudocode: Handling final responses in application (Java)\nimport com.google.adk.events.Event;\nimport com.google.genai.types.Content;\nimport com.google.genai.types.FunctionResponse;\nimport java.util.Map;\n\nStringBuilder fullResponseText = new StringBuilder();\nrunner.run(...).forEach(event -> { // Assuming a stream of events\n     // Accumulate streaming text if needed...\n     if (event.partial().orElse(false) && event.content().isPresent()) {\n         event.content().flatMap(Content::parts).ifPresent(parts -> {\n             if (!parts.isEmpty() && parts.get(0).text().isPresent()) {\n                 fullResponseText.append(parts.get(0).text().get());\n            }\n         });\n     }\n\n     // Check if it's a final, displayable event\n     if (event.finalResponse()) { // Using the method from Event.java\n         System.out.println(\"\\n--- Final Output Detected ---\");\n         if (event.content().isPresent() &&\n             event.content().flatMap(Content::parts).map(parts -> !parts.isEmpty() && parts.get(0).text().isPresent()).orElse(false)) {\n             // If it's the final part of a stream, use accumulated text\n             String eventText = event.content().get().parts().get().get(0).text().get();\n             String finalText = fullResponseText.toString() + (event.partial().orElse(false) ? \"\" : eventText);\n             System.out.println(\"Display to user: \" + finalText.trim());\n             fullResponseText.setLength(0); // Reset accumulator\n         } else if (event.actions() != null && event.actions().skipSummarization().orElse(false)\n                    && !event.functionResponses().isEmpty()) {\n             // Handle displaying the raw tool result if needed,\n             // especially if finalResponse() was true due to other conditions\n             // or if you want to display skipped summarization results regardless of finalResponse()\n             Map<String, Object> responseData = event.functionResponses().get(0).response().get();\n             System.out.println(\"Display raw tool result: \" + responseData);\n         } else if (event.longRunningToolIds().isPresent() && !event.longRunningToolIds().get().isEmpty()) {\n             // This case is covered by event.finalResponse()\n             System.out.println(\"Display message: Tool is running in background...\");\n         } else {\n             // Handle other types of final responses if applicable\n             System.out.println(\"Display: Final non-textual response or signal.\");\n         }\n     }\n });"}]}, {"heading_path": ["How Events Flow: Generation and Processing\u00b6"], "text": "How Events Flow: Generation and Processing \u00b6 Events are created at different points and processed systematically by the framework. Understanding this flow helps clarify how actions and history are managed. Generation Sources: User Input: The Runner typically wraps initial user messages or mid-conversation inputs into an Event with author='user' . Agent Logic: Agents ( BaseAgent , LlmAgent ) explicitly yield Event(...) objects (setting author=self.name ) to communicate responses or signal actions. LLM Responses: The ADK model integration layer translates raw LLM output (text, function calls, errors) into Event objects, authored by the calling agent. Tool Results: After a tool executes, the framework generates an Event containing the function_response . The author is typically the agent that requested the tool, while the role inside the content is set to 'user' for the LLM history. Processing Flow: Yield/Return: An event is generated and yielded (Python) or returned/emitted (Java) by its source. Runner Receives: The main Runner executing the agent receives the event. SessionService Processing: The Runner sends the event to the configured SessionService . This is a critical step: Applies Deltas: The service merges event.actions.state_delta into session.state and updates internal records based on event.actions.artifact_delta . (Note: The actual artifact saving usually happened earlier when context.save_artifact was called). Finalizes Metadata: Assigns a unique event.id if not present, may update event.timestamp . Persists to History: Appends the processed event to the session.events list. External Yield: The Runner yields (Python) or returns/emits (Java) the processed event outwards to the calling application (e.g., the code that invoked runner.run_async ). This flow ensures that state changes and history are consistently recorded alongside the communication content of each event. ", "code_blocks": []}, {"heading_path": ["Common Event Examples (Illustrative Patterns)\u00b6"], "text": "Common Event Examples (Illustrative Patterns) \u00b6 Here are concise examples of typical events you might see in the stream: User Input: { \"author\" : \"user\" , \"invocation_id\" : \"e-xyz...\" , \"content\" : { \"parts\" : [{ \"text\" : \"Book a flight to London for next Tuesday\" }]} // actions usually empty } Agent Final Text Response: ( is_final_response() == True ) { \"author\" : \"TravelAgent\" , \"invocation_id\" : \"e-xyz...\" , \"content\" : { \"parts\" : [{ \"text\" : \"Okay, I can help with that. Could you confirm the departure city?\" }]}, \"partial\" : false , \"turn_complete\" : true // actions might have state delta, etc. } Agent Streaming Text Response: ( is_final_response() == False ) { \"author\" : \"SummaryAgent\" , \"invocation_id\" : \"e-abc...\" , \"content\" : { \"parts\" : [{ \"text\" : \"The document discusses three main points:\" }]}, \"partial\" : true , \"turn_complete\" : false } // ... more partial=True events follow ... Tool Call Request (by LLM): ( is_final_response() == False ) { \"author\" : \"TravelAgent\" , \"invocation_id\" : \"e-xyz...\" , \"content\" : { \"parts\" : [{ \"function_call\" : { \"name\" : \"find_airports\" , \"args\" : { \"city\" : \"London\" }}}]} // actions usually empty } Tool Result Provided (to LLM): ( is_final_response() depends on skip_summarization ) { \"author\" : \"TravelAgent\" , // Author is agent that requested the call \"invocation_id\" : \"e-xyz...\" , \"content\" : { \"role\" : \"user\" , // Role for LLM history \"parts\" : [{ \"function_response\" : { \"name\" : \"find_airports\" , \"response\" : { \"result\" : [ \"LHR\" , \"LGW\" , \"STN\" ]}}}] } // actions might have skip_summarization=True } State/Artifact Update Only: ( is_final_response() == False ) { \"author\" : \"InternalUpdater\" , \"invocation_id\" : \"e-def...\" , \"content\" : null , \"actions\" : { \"state_delta\" : { \"user_status\" : \"verified\" }, \"artifact_delta\" : { \"verification_doc.pdf\" : 2 } } } Agent Transfer Signal: ( is_final_response() == False ) { \"author\" : \"OrchestratorAgent\" , \"invocation_id\" : \"e-789...\" , \"content\" : { \"parts\" : [{ \"function_call\" : { \"name\" : \"transfer_to_agent\" , \"args\" : { \"agent_name\" : \"BillingAgent\" }}}]}, \"actions\" : { \"transfer_to_agent\" : \"BillingAgent\" } // Added by framework } Loop Escalation Signal: ( is_final_response() == False ) { \"author\" : \"CheckerAgent\" , \"invocation_id\" : \"e-loop...\" , \"content\" : { \"parts\" : [{ \"text\" : \"Maximum retries reached.\" }]}, // Optional content \"actions\" : { \"escalate\" : true } } ", "code_blocks": [{"language": "text", "code": "{\n  \"author\": \"user\",\n  \"invocation_id\": \"e-xyz...\",\n  \"content\": {\"parts\": [{\"text\": \"Book a flight to London for next Tuesday\"}]}\n  // actions usually empty\n}"}, {"language": "text", "code": "{\n  \"author\": \"TravelAgent\",\n  \"invocation_id\": \"e-xyz...\",\n  \"content\": {\"parts\": [{\"text\": \"Okay, I can help with that. Could you confirm the departure city?\"}]},\n  \"partial\": false,\n  \"turn_complete\": true\n  // actions might have state delta, etc.\n}"}, {"language": "text", "code": "{\n  \"author\": \"SummaryAgent\",\n  \"invocation_id\": \"e-abc...\",\n  \"content\": {\"parts\": [{\"text\": \"The document discusses three main points:\"}]},\n  \"partial\": true,\n  \"turn_complete\": false\n}\n// ... more partial=True events follow ..."}, {"language": "text", "code": "{\n  \"author\": \"TravelAgent\",\n  \"invocation_id\": \"e-xyz...\",\n  \"content\": {\"parts\": [{\"function_call\": {\"name\": \"find_airports\", \"args\": {\"city\": \"London\"}}}]}\n  // actions usually empty\n}"}, {"language": "text", "code": "{\n  \"author\": \"TravelAgent\", // Author is agent that requested the call\n  \"invocation_id\": \"e-xyz...\",\n  \"content\": {\n    \"role\": \"user\", // Role for LLM history\n    \"parts\": [{\"function_response\": {\"name\": \"find_airports\", \"response\": {\"result\": [\"LHR\", \"LGW\", \"STN\"]}}}]\n  }\n  // actions might have skip_summarization=True\n}"}, {"language": "text", "code": "{\n  \"author\": \"InternalUpdater\",\n  \"invocation_id\": \"e-def...\",\n  \"content\": null,\n  \"actions\": {\n    \"state_delta\": {\"user_status\": \"verified\"},\n    \"artifact_delta\": {\"verification_doc.pdf\": 2}\n  }\n}"}, {"language": "text", "code": "{\n  \"author\": \"OrchestratorAgent\",\n  \"invocation_id\": \"e-789...\",\n  \"content\": {\"parts\": [{\"function_call\": {\"name\": \"transfer_to_agent\", \"args\": {\"agent_name\": \"BillingAgent\"}}}]},\n  \"actions\": {\"transfer_to_agent\": \"BillingAgent\"} // Added by framework\n}"}, {"language": "text", "code": "{\n  \"author\": \"CheckerAgent\",\n  \"invocation_id\": \"e-loop...\",\n  \"content\": {\"parts\": [{\"text\": \"Maximum retries reached.\"}]}, // Optional content\n  \"actions\": {\"escalate\": true}\n}"}]}, {"heading_path": ["Additional Context and Event Details\u00b6"], "text": "Additional Context and Event Details \u00b6 Beyond the core concepts, here are a few specific details about context and events that are important for certain use cases: ToolContext.function_call_id (Linking Tool Actions): When an LLM requests a tool (FunctionCall), that request has an ID. The ToolContext provided to your tool function includes this function_call_id . Importance: This ID is crucial for linking actions like authentication back to the specific tool request that initiated them, especially if multiple tools are called in one turn. The framework uses this ID internally. How State/Artifact Changes are Recorded: When you modify state or save an artifact using CallbackContext or ToolContext , these changes aren't immediately written to persistent storage. Instead, they populate the state_delta and artifact_delta fields within the EventActions object. This EventActions object is attached to the next event generated after the change (e.g., the agent's response or a tool result event). The SessionService.append_event method reads these deltas from the incoming event and applies them to the session's persistent state and artifact records. This ensures changes are tied chronologically to the event stream. State Scope Prefixes ( app: , user: , temp: ): When managing state via context.state , you can optionally use prefixes: app:my_setting : Suggests state relevant to the entire application (requires a persistent SessionService ). user:user_preference : Suggests state relevant to the specific user across sessions (requires a persistent SessionService ). temp:intermediate_result or no prefix: Typically session-specific or temporary state for the current invocation. The underlying SessionService determines how these prefixes are handled for persistence. Error Events: An Event can represent an error. Check the event.error_code and event.error_message fields (inherited from LlmResponse ). Errors might originate from the LLM (e.g., safety filters, resource limits) or potentially be packaged by the framework if a tool fails critically. Check tool FunctionResponse content for typical tool-specific errors. // Example Error Event (conceptual) { \"author\" : \"LLMAgent\" , \"invocation_id\" : \"e-err...\" , \"content\" : null , \"error_code\" : \"SAFETY_FILTER_TRIGGERED\" , \"error_message\" : \"Response blocked due to safety settings.\" , \"actions\" : {} } These details provide a more complete picture for advanced use cases involving tool authentication, state persistence scope, and error handling within the event stream. ", "code_blocks": [{"language": "text", "code": "// Example Error Event (conceptual)\n{\n  \"author\": \"LLMAgent\",\n  \"invocation_id\": \"e-err...\",\n  \"content\": null,\n  \"error_code\": \"SAFETY_FILTER_TRIGGERED\",\n  \"error_message\": \"Response blocked due to safety settings.\",\n  \"actions\": {}\n}"}]}, {"heading_path": ["Best Practices for Working with Events\u00b6"], "text": "Best Practices for Working with Events \u00b6 To use events effectively in your ADK applications: Clear Authorship: When building custom agents, ensure correct attribution for agent actions in the history. The framework generally handles authorship correctly for LLM/tool events. Python Go Java Use yield Event(author=self.name, ...) in BaseAgent subclasses. In custom agent Run methods, the framework typically handles authorship. If creating an event manually, set the author: yield(&session.Event{Author: a.name, ...}, nil) When constructing an Event in your custom agent logic, set the author, for example: Event.builder().author(this.getAgentName()) // ... .build(); Semantic Content & Actions: Use event.content for the core message/data (text, function call/response). Use event.actions specifically for signaling side effects (state/artifact deltas) or control flow ( transfer , escalate , skip_summarization ). Idempotency Awareness: Understand that the SessionService is responsible for applying the state/artifact changes signaled in event.actions . While ADK services aim for consistency, consider potential downstream effects if your application logic re-processes events. Use is_final_response() : Rely on this helper method in your application/UI layer to identify complete, user-facing text responses. Avoid manually replicating its logic. Leverage History: The session's event list is your primary debugging tool. Examine the sequence of authors, content, and actions to trace execution and diagnose issues. Use Metadata: Use invocation_id to correlate all events within a single user interaction. Use event.id to reference specific, unique occurrences. Treating events as structured messages with clear purposes for their content and actions is key to building, debugging, and managing complex agent behaviors in ADK. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:39.467286", "source_type": "adk-docs"}
{"doc_id": "3072a2901c230c899d4ccc67ebcd640dbe0f6e78cb9a633450a2001c2ce7d373", "url": "https://google.github.io/adk-docs/apps", "title": "Apps: workflow management class - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Apps: workflow management class\u00b6"], "text": "Apps: workflow management class \u00b6 Supported in ADK Python v1.14.0 The App class is a top-level container for an entire Agent Development Kit\n(ADK) agent workflow. It is designed to manage the lifecycle, configuration, and\nstate for a collection of agents grouped by a root agent . The App class\nseparates the concerns of an agent workflow's overall operational infrastructure\nfrom individual agents' task-oriented reasoning. Defining an App object in your ADK workflow is optional and changes how you\norganize your agent code and run your agents. From a practical perspective, you\nuse the App class to configure the following features for your agent workflow: Context caching Context compression Agent resume Plugins This guide explains how to use the App class for configuring and managing your\nADK agent workflows. ", "code_blocks": []}, {"heading_path": ["Purpose of App Class\u00b6"], "text": "Purpose of App Class \u00b6 The App class addresses several architectural issues that arise when\nbuilding complex agentic systems: Centralized configuration: Provides a single, centralized location for\n    managing shared resources like API keys and database clients, avoiding the\n    need to pass configuration down through every agent. Lifecycle management: The App class includes on startup and on shutdown hooks, which allow for reliable management of persistent\n    resources such as database connection pools or in-memory caches that need to\n    exist across multiple invocations. State scope: It defines an explicit boundary for application-level\n     state with an app:* prefix making the scope and lifetime of this state\n    clear to developers. Unit of deployment: The App concept establishes a formal deployable\n    unit , simplifying versioning, testing, and serving of agentic applications. ", "code_blocks": []}, {"heading_path": ["Define an App object\u00b6"], "text": "Define an App object \u00b6 The App class is used as the primary container of your agent workflow and\ncontains the root agent of the project. The root agent is the container\nfor the primary controller agent and any additonal sub-agents. ", "code_blocks": []}, {"heading_path": ["Define app with root agent\u00b6"], "text": "Define app with root agent \u00b6 Create a root agent for your workflow by creating a subclass from the Agent base class. Then define an App object and configure it with\nthe root agent object and optional features, as shown in the following\nsample code: agent.py from google.adk.agents.llm_agent import Agent from google.adk.apps import App root_agent = Agent ( model = 'gemini-2.5-flash' , name = 'greeter_agent' , description = 'An agent that provides a friendly greeting.' , instruction = 'Reply with Hello, World!' , ) app = App ( name = \"agents\" , root_agent = root_agent , # Optionally include App-level features: # plugins, context_cache_config, resumability_config ) Recommended: Use app variable name In your agent project code, set your App object to the variable name app so it is compatible with the ADK command line interface runner tools. ", "code_blocks": [{"language": "text", "code": "from google.adk.agents.llm_agent import Agent\nfrom google.adk.apps import App\n\nroot_agent = Agent(\n    model='gemini-2.5-flash',\n    name='greeter_agent',\n    description='An agent that provides a friendly greeting.',\n    instruction='Reply with Hello, World!',\n)\n\napp = App(\n    name=\"agents\",\n    root_agent=root_agent,\n    # Optionally include App-level features:\n    # plugins, context_cache_config, resumability_config\n)"}]}, {"heading_path": ["Run your App agent\u00b6"], "text": "Run your App agent \u00b6 You can use the Runner class to run your agent workflow using the app parameter, as shown in the following code sample: main.py import asyncio from dotenv import load_dotenv from google.adk.runners import InMemoryRunner from agent import app # import code from agent.py load_dotenv () # load API keys and settings # Set a Runner using the imported application object runner = InMemoryRunner ( app = app ) async def main (): try : # run_debug() requires ADK Python 1.18 or higher: response = await runner . run_debug ( \"Hello there!\" ) except Exception as e : print ( f \"An error occurred during agent execution: { e } \" ) if __name__ == \"__main__\" : asyncio . run ( main ()) Version requirement for Runner.run_debug() The Runner.run_debug() command requires ADK Python v1.18.0 or higher.\nYou can also use Runner.run() , which requires more setup code. For\nmore details, see the Run your App agent with the main.py code using the following command: python main.py ", "code_blocks": [{"language": "text", "code": "import asyncio\nfrom dotenv import load_dotenv\nfrom google.adk.runners import InMemoryRunner\nfrom agent import app # import code from agent.py\n\nload_dotenv() # load API keys and settings\n# Set a Runner using the imported application object\nrunner = InMemoryRunner(app=app)\n\nasync def main():\n    try:  # run_debug() requires ADK Python 1.18 or higher:\n        response = await runner.run_debug(\"Hello there!\")\n\n    except Exception as e:\n        print(f\"An error occurred during agent execution: {e}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"}, {"language": "text", "code": "python main.py"}]}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 For a more complete sample code implementation, see the Hello World App code example. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:39.871406", "source_type": "adk-docs"}
{"doc_id": "7422edff47569981f2c6720e46e0bb103e4e87b54426c1b78fe5d5354850b5b1", "url": "https://google.github.io/adk-docs/plugins", "title": "Plugins - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Plugins\u00b6"], "text": "Plugins \u00b6 Supported in ADK Python v1.7.0 A Plugin in Agent Development Kit (ADK) is a custom code module that can be\nexecuted at various stages of an agent workflow lifecycle using callback hooks.\nYou use Plugins for functionality that is applicable across your agent workflow.\nSome typical applications of Plugins are as follows: Logging and tracing : Create detailed logs of agent, tool, and\n    generative AI model activity for debugging and performance analysis. Policy enforcement : Implement security guardrails, such as a\n    function that checks if users are authorized to use a specific tool and\n    prevent its execution if they do not have permission. Monitoring and metrics : Collect and export metrics on token usage,\n    execution times, and invocation counts to monitoring systems such as\n    Prometheus or Google Cloud Observability (formerly Stackdriver). Response caching : Check if a request has been made before, so you\n    can return a cached response, skipping expensive or time consuming AI model\n    or tool calls. Request or response modification : Dynamically add information to AI\n    model prompts or standardize tool output responses. Tip When implementing security guardrails and policies, use ADK Plugins for\nbetter modularity and flexibility than Callbacks. For more details, see Callbacks and Plugins for Security Guardrails . Caution Plugins are not supported by the ADK web interface .\nIf your ADK workflow uses Plugins, you must run your workflow without the\nweb interface. ", "code_blocks": []}, {"heading_path": ["How do Plugins work?\u00b6"], "text": "How do Plugins work? \u00b6 An ADK Plugin extends the BasePlugin class and contains one or more callback methods, indicating where in the agent lifecycle the Plugin should be\nexecuted. You integrate Plugins into an agent by registering them in your\nagent's Runner class. For more information on how and where you can trigger\nPlugins in your agent application, see Plugin callback hooks . Plugin functionality builds on Callbacks , which is a key design\nelement of the ADK's extensible architecture. While a typical Agent Callback is\nconfigured on a single agent, a single tool for a specific task , a Plugin is\nregistered once on the Runner and its callbacks apply globally to every\nagent, tool, and LLM call managed by that runner. Plugins let you package\nrelated callback functions together to be used across a workflow. This makes\nPlugins an ideal solution for implementing features that cut across your entire\nagent application. ", "code_blocks": []}, {"heading_path": ["Prebuilt Plugins\u00b6"], "text": "Prebuilt Plugins \u00b6 ADK includes several plugins that you can add to your agent workflows\nimmediately: Reflect and Retry Tools :\n    Tracks tool failures and intelligently retries tool requests. BigQuery Analytics :\n    Enables agent logging and analysis with BigQuery. Context Filter :\n    Filters the generative AI context to reduce its size. Global Instruction :\n    Plugin that provides global instructions functionality at the App level. Save Files as Artifacts :\n    Saves files included in user messages as Artifacts. Logging :\n    Log important information at each agent workflow callback point. ", "code_blocks": []}, {"heading_path": ["Define and register Plugins\u00b6"], "text": "Define and register Plugins \u00b6 This section explains how to define Plugin classes and register them as part of\nyour agent workflow. For a complete code example, see Plugin Basic in the repository. ", "code_blocks": []}, {"heading_path": ["Create Plugin class\u00b6"], "text": "Create Plugin class \u00b6 Start by extending the BasePlugin class and add one or more callback methods, as shown in the following code example: count_plugin.py from google.adk.agents.base_agent import BaseAgent from google.adk.agents.callback_context import CallbackContext from google.adk.models.llm_request import LlmRequest from google.adk.plugins.base_plugin import BasePlugin class CountInvocationPlugin ( BasePlugin ): \"\"\"A custom plugin that counts agent and tool invocations.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the plugin with counters.\"\"\" super () . __init__ ( name = \"count_invocation\" ) self . agent_count : int = 0 self . tool_count : int = 0 self . llm_request_count : int = 0 async def before_agent_callback ( self , * , agent : BaseAgent , callback_context : CallbackContext ) -> None : \"\"\"Count agent runs.\"\"\" self . agent_count += 1 print ( f \"[Plugin] Agent run count: { self . agent_count } \" ) async def before_model_callback ( self , * , callback_context : CallbackContext , llm_request : LlmRequest ) -> None : \"\"\"Count LLM requests.\"\"\" self . llm_request_count += 1 print ( f \"[Plugin] LLM request count: { self . llm_request_count } \" ) This example code implements callbacks for before_agent_callback and before_model_callback to count execution of these tasks during the lifecycle\nof the agent. ", "code_blocks": [{"language": "text", "code": "from google.adk.agents.base_agent import BaseAgent\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.models.llm_request import LlmRequest\nfrom google.adk.plugins.base_plugin import BasePlugin\n\nclass CountInvocationPlugin(BasePlugin):\n  \"\"\"A custom plugin that counts agent and tool invocations.\"\"\"\n\n  def __init__(self) -> None:\n    \"\"\"Initialize the plugin with counters.\"\"\"\n    super().__init__(name=\"count_invocation\")\n    self.agent_count: int = 0\n    self.tool_count: int = 0\n    self.llm_request_count: int = 0\n\n  async def before_agent_callback(\n      self, *, agent: BaseAgent, callback_context: CallbackContext\n  ) -> None:\n    \"\"\"Count agent runs.\"\"\"\n    self.agent_count += 1\n    print(f\"[Plugin] Agent run count: {self.agent_count}\")\n\n  async def before_model_callback(\n      self, *, callback_context: CallbackContext, llm_request: LlmRequest\n  ) -> None:\n    \"\"\"Count LLM requests.\"\"\"\n    self.llm_request_count += 1\n    print(f\"[Plugin] LLM request count: {self.llm_request_count}\")"}]}, {"heading_path": ["Register Plugin class\u00b6"], "text": "Register Plugin class \u00b6 Integrate your Plugin class by registering it during your agent initialization\nas part of your Runner class, using the plugins parameter. You can specify\nmultiple Plugins with this parameter. The following code example shows how to\nregister the CountInvocationPlugin plugin defined in the previous section with\na simple ADK agent. from google.adk.runners import InMemoryRunner from google.adk import Agent from google.adk.tools.tool_context import ToolContext from google.genai import types import asyncio # Import the plugin. from .count_plugin import CountInvocationPlugin async def hello_world ( tool_context : ToolContext , query : str ): print ( f 'Hello world: query is [ { query } ]' ) root_agent = Agent ( model = 'gemini-2.0-flash' , name = 'hello_world' , description = 'Prints hello world with user query.' , instruction = \"\"\"Use hello_world tool to print hello world and user query. \"\"\" , tools = [ hello_world ], ) async def main (): \"\"\"Main entry point for the agent.\"\"\" prompt = 'hello world' runner = InMemoryRunner ( agent = root_agent , app_name = 'test_app_with_plugin' , # Add your plugin here. You can add multiple plugins. plugins = [ CountInvocationPlugin ()], ) # The rest is the same as starting a regular ADK runner. session = await runner . session_service . create_session ( user_id = 'user' , app_name = 'test_app_with_plugin' , ) async for event in runner . run_async ( user_id = 'user' , session_id = session . id , new_message = types . Content ( role = 'user' , parts = [ types . Part . from_text ( text = prompt )] ) ): print ( f '** Got event from { event . author } ' ) if __name__ == \"__main__\" : asyncio . run ( main ()) ", "code_blocks": [{"language": "text", "code": "from google.adk.runners import InMemoryRunner\nfrom google.adk import Agent\nfrom google.adk.tools.tool_context import ToolContext\nfrom google.genai import types\nimport asyncio\n\n# Import the plugin.\nfrom .count_plugin import CountInvocationPlugin\n\nasync def hello_world(tool_context: ToolContext, query: str):\n  print(f'Hello world: query is [{query}]')\n\nroot_agent = Agent(\n    model='gemini-2.0-flash',\n    name='hello_world',\n    description='Prints hello world with user query.',\n    instruction=\"\"\"Use hello_world tool to print hello world and user query.\n    \"\"\",\n    tools=[hello_world],\n)\n\nasync def main():\n  \"\"\"Main entry point for the agent.\"\"\"\n  prompt = 'hello world'\n  runner = InMemoryRunner(\n      agent=root_agent,\n      app_name='test_app_with_plugin',\n\n      # Add your plugin here. You can add multiple plugins.\n      plugins=[CountInvocationPlugin()],\n  )\n\n  # The rest is the same as starting a regular ADK runner.\n  session = await runner.session_service.create_session(\n      user_id='user',\n      app_name='test_app_with_plugin',\n  )\n\n  async for event in runner.run_async(\n      user_id='user',\n      session_id=session.id,\n      new_message=types.Content(\n        role='user', parts=[types.Part.from_text(text=prompt)]\n      )\n  ):\n    print(f'** Got event from {event.author}')\n\nif __name__ == \"__main__\":\n  asyncio.run(main())"}]}, {"heading_path": ["Run the agent with the Plugin\u00b6"], "text": "Run the agent with the Plugin \u00b6 Run the plugin as you typically would. The following shows how to run the\ncommand line: python3 -m path.to.main Plugins are not supported by the ADK web interface .\nIf your ADK workflow uses Plugins, you must run your workflow without the web\ninterface. The output of this previously described agent should look similar to the\nfollowing: [Plugin] Agent run count: 1 [Plugin] LLM request count: 1 ** Got event from hello_world Hello world: query is [hello world] ** Got event from hello_world [Plugin] LLM request count: 2 ** Got event from hello_world For more information on running ADK agents, see the Quickstart guide. ", "code_blocks": [{"language": "text", "code": "python3 -m path.to.main"}, {"language": "text", "code": "[Plugin] Agent run count: 1\n[Plugin] LLM request count: 1\n** Got event from hello_world\nHello world: query is [hello world]\n** Got event from hello_world\n[Plugin] LLM request count: 2\n** Got event from hello_world"}]}, {"heading_path": ["Build workflows with Plugins\u00b6"], "text": "Build workflows with Plugins \u00b6 Plugin callback hooks are a mechanism for implementing logic that intercepts,\nmodifies, and even controls the agent's execution lifecycle. Each hook is a\nspecific method in your Plugin class that you can implement to run code at a key\nmoment. You have a choice between two modes of operation based on your hook's\nreturn value: To Observe: Implement a hook with no return value ( None ). This\n    approach is for tasks such as logging or collecting metrics, as it allows\n    the agent's workflow to proceed to the next step without interruption. For\n    example, you could use after_tool_callback in a Plugin to log every\n    tool's result for debugging. To Intervene: Implement a hook and return a value. This approach\n    short-circuits the workflow. The Runner halts processing, skips any\n    subsequent plugins and the original intended action, like a Model call, and\n    use a Plugin callback's return value as the result. A common use case is\n    implementing before_model_callback to return a cached LlmResponse ,\n    preventing a redundant and costly API call. To Amend: Implement a hook and modify the Context object. This\n    approach allows you to modify the context data for the module to be\n    executed without otherwise interrupting the execution of that module. For\n    example, adding additional, standardized prompt text for Model object execution. Caution: Plugin callback functions have precedence over callbacks\nimplemented at the object level. This behavior means that Any Plugin callbacks\ncode is executed before any Agent, Model, or Tool objects callbacks are\nexecuted. Furthermore, if a Plugin-level agent callback returns any value, and\nnot an empty ( None ) response, the Agent, Model, or Tool-level callback is not\nexecuted (skipped). The Plugin design establishes a hierarchy of code execution and separates\nglobal concerns from local agent logic. A Plugin is the stateful module you\nbuild, such as PerformanceMonitoringPlugin , while the callback hooks are the\nspecific functions within that module that get executed. This architecture\ndiffers fundamentally from standard Agent Callbacks in these critical ways: Scope: Plugin hooks are global . You register a Plugin once on the Runner , and its hooks apply universally to every Agent, Model, and Tool\n    it manages. In contrast, Agent Callbacks are local , configured\n    individually on a specific agent instance. Execution Order: Plugins have precedence . For any given event, the\n    Plugin hooks always run before any corresponding Agent Callback. This\n    system behavior makes Plugins the correct architectural choice for\n    implementing cross-cutting features like security policies, universal\n    caching, and consistent logging across your entire application. ", "code_blocks": []}, {"heading_path": ["Agent Callbacks and Plugins\u00b6"], "text": "Agent Callbacks and Plugins \u00b6 As mentioned in the previous section, there are some functional similarities\nbetween Plugins and Agent Callbacks. The following table compares the\ndifferences between Plugins and Agent Callbacks in more detail. Plugins Agent Callbacks Scope Global : Apply to all agents/tools/LLMs in the Runner . Local : Apply only to the specific agent instance\nthey are configured on. Primary Use Case Horizontal Features : Logging, policy, monitoring,\nglobal caching. Specific Agent Logic : Modifying the behavior or\nstate of a single agent. Configuration Configure once on the Runner . Configure individually on each BaseAgent instance. Execution Order Plugin callbacks run before Agent Callbacks. Agent callbacks run after Plugin callbacks. ", "code_blocks": []}, {"heading_path": ["Plugin callback hooks\u00b6"], "text": "Plugin callback hooks \u00b6 You define when a Plugin is called with the callback functions to define in\nyour Plugin class. Callbacks are available when a user message is received,\nbefore and after an Runner , Agent , Model , or Tool is called, for Events , and when a Model , or Tool error occurs. These callbacks include,\nand take precedence over, the any callbacks defined within your Agent, Model,\nand Tool classes. The following diagram illustrates callback points where you can attach and run\nPlugin functionality during your agents workflow: Figure 1. Diagram of ADK agent workflow with Plugin callback hook\nlocations. The following sections describe the available callback hooks for Plugins in\nmore detail. User Message callbacks Runner start callbacks Agent execution callbacks Model callbacks Tool callbacks Runner end callbacks ", "code_blocks": []}, {"heading_path": ["User Message callbacks\u00b6"], "text": "User Message callbacks \u00b6 A User Message c allback ( on_user_message_callback ) happens when a user\nsends a message. The on_user_message_callback is the very first hook to run,\ngiving you a chance to inspect or modify the initial input.\\ When It Runs: This callback happens immediately after runner.run() , before any other processing. Purpose: The first opportunity to inspect or modify the user's raw\n    input. Flow Control: Returns a types.Content object to replace the\n    user's original message. The following code example shows the basic syntax of this callback: async def on_user_message_callback ( self , * , invocation_context : InvocationContext , user_message : types . Content , ) -> Optional [ types . Content ]: ", "code_blocks": [{"language": "text", "code": "async def on_user_message_callback(\n    self,\n    *,\n    invocation_context: InvocationContext,\n    user_message: types.Content,\n) -> Optional[types.Content]:"}]}, {"heading_path": ["Runner start callbacks\u00b6"], "text": "Runner start callbacks \u00b6 A Runner start callback ( before_run_callback ) happens when the Runner object takes the potentially modified user message and prepares for execution.\nThe before_run_callback fires here, allowing for global setup before any agent\nlogic begins. When It Runs: Immediately after runner.run() is called, before\n    any other processing. Purpose: The first opportunity to inspect or modify the user's raw\n    input. Flow Control: Return a types.Content object to replace the\n    user's original message. The following code example shows the basic syntax of this callback: async def before_run_callback ( self , * , invocation_context : InvocationContext ) -> Optional [ types . Content ]: ", "code_blocks": [{"language": "text", "code": "async def before_run_callback(\n    self, *, invocation_context: InvocationContext\n) -> Optional[types.Content]:"}]}, {"heading_path": ["Agent execution callbacks\u00b6"], "text": "Agent execution callbacks \u00b6 Agent execution callbacks ( before_agent , after_agent ) happen when a Runner object invokes an agent. The before_agent_callback runs immediately\nbefore the agent's main work begins. The main work encompasses the agent's\nentire process for handling the request, which could involve calling models or\ntools. After the agent has finished all its steps and prepared a result, the after_agent_callback runs. Caution: Plugins that implement these callbacks are executed before the\nAgent-level callbacks are executed. Furthermore, if a Plugin-level agent\ncallback returns anything other than a None or null response, the Agent-level\ncallback is not executed (skipped). For more information about Agent callbacks defined as part of an Agent object,\nsee Types of Callbacks . ", "code_blocks": []}, {"heading_path": ["Model callbacks\u00b6"], "text": "Model callbacks \u00b6 Model callbacks ( before_model , after_model , on_model_error ) happen\nbefore and after a Model object executes. The Plugins feature also supports a\ncallback in the event of an error, as detailed below: If an agent needs to call an AI model, before_model_callback runs first. If the model call is successful, after_model_callback runs next. If the model call fails with an exception, the on_model_error_callback is triggered instead, allowing for graceful recovery. Caution: Plugins that implement the before_model and **after_model callback methods are executed before the Model-level callbacks are executed.\nFurthermore, if a Plugin-level model callback returns anything other than a None or null response, the Model-level callback is not executed (skipped). ", "code_blocks": []}, {"heading_path": ["Model on error callback details\u00b6"], "text": "Model on error callback details \u00b6 The on error callback for Model objects is only supported by the Plugins\nfeature works as follows: When It Runs: When an exception is raised during the model call. Common Use Cases: Graceful error handling, logging the specific\n    error, or returning a fallback response, such as \"The AI service is\n    currently unavailable.\" Flow Control: Returns an LlmResponse object to suppress the exception and provide a fallback result. Returns None to allow the original exception to be raised. Note : If the execution of the Model object returns a LlmResponse , the\nsystem resumes the execution flow, and after_model_callback will be triggered\nnormally.**** The following code example shows the basic syntax of this callback: async def on_model_error_callback ( self , * , callback_context : CallbackContext , llm_request : LlmRequest , error : Exception , ) -> Optional [ LlmResponse ]: ", "code_blocks": [{"language": "text", "code": "async def on_model_error_callback(\n    self,\n    *,\n    callback_context: CallbackContext,\n    llm_request: LlmRequest,\n    error: Exception,\n) -> Optional[LlmResponse]:"}]}, {"heading_path": ["Tool callbacks\u00b6"], "text": "Tool callbacks \u00b6 Tool callbacks ( before_tool , after_tool , on_tool_error ) for Plugins\nhappen before or after the execution of a tool, or when an error occurs. The\nPlugins feature also supports a callback in the event of an error, as detailed\nbelow:\\ When an agent executes a Tool, before_tool_callback runs first. If the tool executes successfully, after_tool_callback runs next. If the tool raises an exception, the on_tool_error_callback is\n    triggered instead, giving you a chance to handle the failure. If on_tool_error_callback returns a dict, after_tool_callback will be\n    triggered normally. Caution: Plugins that implement these callbacks are executed before the\nTool-level callbacks are executed. Furthermore, if a Plugin-level tool callback\nreturns anything other than a None or null response, the Tool-level callback\nis not executed (skipped). ", "code_blocks": []}, {"heading_path": ["Tool on error callback details\u00b6"], "text": "Tool on error callback details \u00b6 The on error callback for Tool objects is only supported by the Plugins feature\nworks as follows: When It Runs: When an exception is raised during the execution of a\n    tool's run method. Purpose: Catching specific tool exceptions (like APIError ),\n    logging the failure, and providing a user-friendly error message back to\n    the LLM. Flow Control: Return a dict to suppress the exception , provide\n    a fallback result. Return None to allow the original exception to be raised. Note : By returning a dict , this resumes the execution flow, and after_tool_callback will be triggered normally. The following code example shows the basic syntax of this callback: async def on_tool_error_callback ( self , * , tool : BaseTool , tool_args : dict [ str , Any ], tool_context : ToolContext , error : Exception , ) -> Optional [ dict ]: ", "code_blocks": [{"language": "text", "code": "async def on_tool_error_callback(\n    self,\n    *,\n    tool: BaseTool,\n    tool_args: dict[str, Any],\n    tool_context: ToolContext,\n    error: Exception,\n) -> Optional[dict]:"}]}, {"heading_path": ["Event callbacks\u00b6"], "text": "Event callbacks \u00b6 An Event callback ( on_event_callback ) happens when an agent produces\noutputs such as a text response or a tool call result, it yields them as Event objects. The on_event_callback fires for each event, allowing you to modify it\nbefore it's streamed to the client. When It Runs: After an agent yields an Event but before it's sent\n    to the user. An agent's run may produce multiple events. Purpose: Useful for modifying or enriching events (e.g., adding\n    metadata) or for triggering side effects based on specific events. Flow Control: Return an Event object to replace the original\n    event. The following code example shows the basic syntax of this callback: async def on_event_callback ( self , * , invocation_context : InvocationContext , event : Event ) -> Optional [ Event ]: ", "code_blocks": [{"language": "text", "code": "async def on_event_callback(\n    self, *, invocation_context: InvocationContext, event: Event\n) -> Optional[Event]:"}]}, {"heading_path": ["Runner end callbacks\u00b6"], "text": "Runner end callbacks \u00b6 The Runner end callback ( after_run_callback ) happens when the agent has\nfinished its entire process and all events have been handled, the Runner completes its run. The after_run_callback is the final hook, perfect for\ncleanup and final reporting. When It Runs: After the Runner fully completes the execution of a\n    request. Purpose: Ideal for global cleanup tasks, such as closing connections\n    or finalizing logs and metrics data. Flow Control: This callback is for teardown only and cannot alter\n    the final result. The following code example shows the basic syntax of this callback: async def after_run_callback ( self , * , invocation_context : InvocationContext ) -> Optional [ None ]: ", "code_blocks": [{"language": "text", "code": "async def after_run_callback(\n    self, *, invocation_context: InvocationContext\n) -> Optional[None]:"}]}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 Check out these resources for developing and applying Plugins to your ADK\nprojects: For more ADK Plugin code examples, see the ADK Python repository . For information on applying Plugins for security purposes, see Callbacks and Plugins for Security Guardrails . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:40.510796", "source_type": "adk-docs"}
{"doc_id": "85a94257aaddbc1004e27282ba39bd87ca042f05ac040fe24fadd9f23931ddd3", "url": "https://google.github.io/adk-docs/plugins/reflect-and-retry", "title": "Reflect and retry - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Reflect and Retry Tool Plugin\u00b6"], "text": "Reflect and Retry Tool Plugin \u00b6 Supported in ADK Python v1.16.0 The Reflect and Retry Tool plugin can help your agent recover from error\nresponses from ADK Tools and automatically retry the\ntool request. This plugin intercepts tool failures, provides structured guidance\nto the AI model for reflection and correction, and retries the operation up to a\nconfigurable limit. This plugin can help you build more resilience into your\nagent workflows, including the following capabilities: Concurrency safe : Uses locking to safely handle parallel tool executions. Configurable scope : Tracks failures per-invocation (default) or globally. Granular tracking : Failure counts are tracked per-tool. Custom error extraction : Supports detecting errors in normal tool responses. ", "code_blocks": []}, {"heading_path": ["Add Reflect and Retry Plugin\u00b6"], "text": "Add Reflect and Retry Plugin \u00b6 Add this plugin to your ADK workflow by adding it to the plugins setting of your\nADK project's App object, as shown below: from google.adk.apps.app import App from google.adk.plugins import ReflectAndRetryToolPlugin app = App ( name = \"my_app\" , root_agent = root_agent , plugins = [ ReflectAndRetryToolPlugin ( max_retries = 3 ), ], ) With this configuration, if any tool called by an agent returns an error, the\nrequest is updated and tried again, up to a maximum of 3 attempts, per tool. ", "code_blocks": [{"language": "text", "code": "from google.adk.apps.app import App\nfrom google.adk.plugins import ReflectAndRetryToolPlugin\n\napp = App(\n    name=\"my_app\",\n    root_agent=root_agent,\n    plugins=[\n        ReflectAndRetryToolPlugin(max_retries=3),\n    ],\n)"}]}, {"heading_path": ["Configuration settings\u00b6"], "text": "Configuration settings \u00b6 The Reflect and Retry Plugin has the following configuration options: max_retries : (optional) Total number of additional attempts the system\n    makes to receive a non-error response. Default value is 3. throw_exception_if_retry_exceeded : (optional) If set to False , the\n    system does not raise an error if the final retry attempt fails. Default\n    value is True . tracking_scope : (optional) TrackingScope.INVOCATION : Track tool failures across a single\n    invocation and user. This value is the default. TrackingScope.GLOBAL : Track tool failures across all invocations\n    and all users. ", "code_blocks": []}, {"heading_path": ["Advanced configuration\u00b6"], "text": "Advanced configuration \u00b6 You can further modify the behavior of this plugin by extending the ReflectAndRetryToolPlugin class. The following code sample\ndemonstrates a simple extension of the behavior by selecting\nresponses with an error status: class CustomRetryPlugin ( ReflectAndRetryToolPlugin ): async def extract_error_from_result ( self , * , tool , tool_args , tool_context , result ): # Detect error based on response content if result . get ( 'status' ) == 'error' : return result return None # No error detected # add this modified plugin to your App object: error_handling_plugin = CustomRetryPlugin ( max_retries = 5 ) ", "code_blocks": [{"language": "text", "code": "class CustomRetryPlugin(ReflectAndRetryToolPlugin):\n  async def extract_error_from_result(self, *, tool, tool_args,tool_context,\n  result):\n    # Detect error based on response content\n    if result.get('status') == 'error':\n        return result\n    return None  # No error detected\n\n# add this modified plugin to your App object:\nerror_handling_plugin = CustomRetryPlugin(max_retries=5)"}]}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 For complete code samples using the Reflect and Retry plugin, see the following: Basic code sample Hallucinating function name code sample Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:40.976527", "source_type": "adk-docs"}
{"doc_id": "ee1e33219a6c62e012b6ea55a8de31d693ef976e9b1fb0ad89c6f4a8a0647d87", "url": "https://google.github.io/adk-docs/mcp", "title": "Model Context Protocol (MCP) - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Model Context Protocol (MCP)\u00b6"], "text": "Model Context Protocol (MCP) \u00b6 Supported in ADK Python Go Java The Model Context Protocol (MCP) is\nan open standard designed to standardize how Large Language Models (LLMs) like\nGemini and Claude communicate with external applications, data sources, and\ntools. Think of it as a universal connection mechanism that simplifies how LLMs\nobtain context, execute actions, and interact with various systems. ", "code_blocks": []}, {"heading_path": ["How does MCP work?\u00b6"], "text": "How does MCP work? \u00b6 MCP follows a client-server architecture, defining how data (resources),\ninteractive templates (prompts), and actionable functions (tools) are\nexposed by an MCP server and consumed by an MCP client (which could be\nan LLM host application or an AI agent). ", "code_blocks": []}, {"heading_path": ["MCP Tools in ADK\u00b6"], "text": "MCP Tools in ADK \u00b6 ADK helps you both use and consume MCP tools in your agents, whether you're\ntrying to build a tool to call an MCP service, or exposing an MCP server for\nother developers or agents to interact with your tools. Refer to the MCP Tools documentation for code samples\nand design patterns that help you use ADK together with MCP servers, including: Using Existing MCP Servers within ADK : An ADK agent can act as an MCP\n  client and use tools provided by external MCP servers. Exposing ADK Tools via an MCP Server : How to build an MCP server that\n  wraps ADK tools, making them accessible to any MCP client. ", "code_blocks": []}, {"heading_path": ["MCP Toolbox for Databases\u00b6"], "text": "MCP Toolbox for Databases \u00b6 MCP Toolbox for Databases is an\nopen-source MCP server that securely exposes your backend data sources as a\nset of pre-built, production-ready tools for Gen AI agents. It functions as a\nuniversal abstraction layer, allowing your ADK agent to securely query, analyze,\nand retrieve information from a wide array of databases with built-in support. The MCP Toolbox server includes a comprehensive library of connectors, ensuring that\nagents can safely interact with your complex data estate. ", "code_blocks": []}, {"heading_path": ["Supported Data Sources\u00b6"], "text": "Supported Data Sources \u00b6 MCP Toolbox provides out-of-the-box toolsets for the following databases and data platforms: ", "code_blocks": []}, {"heading_path": ["Google Cloud\u00b6"], "text": "Google Cloud \u00b6 BigQuery (including tools for SQL execution, schema discovery, and AI-powered time series forecasting) AlloyDB (PostgreSQL-compatible, with tools for both standard queries and natural language queries) AlloyDB Admin Spanner (supporting both GoogleSQL and PostgreSQL dialects) Cloud SQL (with dedicated support for Cloud SQL for PostgreSQL , Cloud SQL for MySQL , and Cloud SQL for SQL Server ) Cloud SQL Admin Firestore Bigtable Dataplex (for data discovery and metadata search) Cloud Monitoring ", "code_blocks": []}, {"heading_path": ["Relational & SQL Databases\u00b6"], "text": "Relational & SQL Databases \u00b6 PostgreSQL (generic) MySQL (generic) Microsoft SQL Server (generic) ClickHouse TiDB OceanBase Firebird SQLite YugabyteDB ", "code_blocks": []}, {"heading_path": ["NoSQL & Key-Value Stores\u00b6"], "text": "NoSQL & Key-Value Stores \u00b6 MongoDB Couchbase Redis Valkey Cassandra ", "code_blocks": []}, {"heading_path": ["Graph Databases\u00b6"], "text": "Graph Databases \u00b6 Neo4j (with tools for Cypher queries and schema inspection) Dgraph ", "code_blocks": []}, {"heading_path": ["Data Platforms & Federation\u00b6"], "text": "Data Platforms & Federation \u00b6 Looker (for running Looks, queries, and building dashboards via the Looker API) Trino (for running federated queries across multiple sources) ", "code_blocks": []}, {"heading_path": ["Other\u00b6"], "text": "Other \u00b6 HTTP ", "code_blocks": []}, {"heading_path": ["Documentation\u00b6"], "text": "Documentation \u00b6 Refer to the MCP Toolbox for Databases documentation on how you can use ADK together with the MCP Toolbox for\nDatabases. For getting started with the MCP Toolbox for Databases, a blog post Tutorial : MCP Toolbox for Databases - Exposing Big Query Datasets and Codelab MCP Toolbox for Databases:Making BigQuery datasets available to MCP clients are also available. ", "code_blocks": []}, {"heading_path": ["ADK Agent and FastMCP server\u00b6"], "text": "ADK Agent and FastMCP server \u00b6 FastMCP handles all the complex MCP protocol details and server management, so you can focus on building great tools. It's designed to be high-level and Pythonic; in most cases, decorating a function is all you need. Refer to the MCP Tools documentation documentation on\nhow you can use ADK together with the FastMCP server running on Cloud Run. ", "code_blocks": []}, {"heading_path": ["MCP Servers for Google Cloud Genmedia\u00b6"], "text": "MCP Servers for Google Cloud Genmedia \u00b6 MCP Tools for Genmedia Services is a set of open-source MCP servers that enable you to integrate Google Cloud\ngenerative media services\u2014such as Imagen, Veo, Chirp 3 HD voices, and Lyria\u2014into\nyour AI applications. Agent Development Kit (ADK) and Genkit provide built-in\nsupport for these MCP tools, allowing your AI agents to effectively orchestrate\ngenerative media workflows. For implementation guidance, refer to the ADK\nexample\nagent and the Genkit example . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:41.349609", "source_type": "adk-docs"}
{"doc_id": "2bedc5e34bb03dc28823d685f5860c00ee9e18243a4dc32bdf2e34c8613cecb2", "url": "https://google.github.io/adk-docs/a2a", "title": "ADK with Agent2Agent (A2A) Protocol - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["ADK with Agent2Agent (A2A) Protocol\u00b6"], "text": "ADK with Agent2Agent (A2A) Protocol \u00b6 Supported in ADK Python Go Experimental With Agent Development Kit (ADK), you can build complex multi-agent systems where different agents need to collaborate and interact using Agent2Agent (A2A) Protocol ! This section provides a comprehensive guide to building powerful multi-agent systems where agents can communicate and collaborate securely and efficiently. Navigate through the guides below to learn about ADK's A2A capabilities: Introduction to A2A Start here to learn the fundamentals of A2A by building a multi-agent system with a root agent, a local sub-agent, and a remote A2A agent. The following guides cover how do I expose your agent so that other agents can use it via the A2A protocol: A2A Quickstart (Exposing) for Python A2A Quickstart (Exposing) for Go These guides show you how to allow your agent to use another, remote agent using A2A protocol: A2A Quickstart (Consuming) for Python A2A Quickstart (Consuming) for Go Official Website for Agent2Agent (A2A) Protocol The official website for A2A Protocol. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:41.843176", "source_type": "adk-docs"}
{"doc_id": "ea00201d47ddf3e1e7b3d1b776cc4a0d16c1f7629d11bd344bf63a3a73806274", "url": "https://google.github.io/adk-docs/a2a/intro", "title": "Introduction to A2A - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Introduction to A2A\u00b6"], "text": "Introduction to A2A \u00b6 As you build more complex agentic systems, you will find that a single agent\nis often not enough. You will want to create specialized agents that can\ncollaborate to solve a problem. The Agent2Agent (A2A) Protocol is the\nstandard that allows these agents to communicate with each other. ", "code_blocks": []}, {"heading_path": ["When to Use A2A vs. Local Sub-Agents\u00b6"], "text": "When to Use A2A vs. Local Sub-Agents \u00b6 Local Sub-Agents: These are agents that run within the same application\n  process as your main agent. They are like internal modules or libraries, used\n  to organize your code into logical, reusable components. Communication between\n  a main agent and its local sub-agents is very fast because it happens\n  directly in memory, without network overhead. Remote Agents (A2A): These are independent agents that run as separate\n  services, communicating over a network. A2A defines the standard protocol\n  for this communication. Consider using A2A when: The agent you need to talk to is a separate, standalone service (e.g., a\n  specialized financial modeling agent). The agent is maintained by a different team or organization . You need to connect agents written in different programming languages or\n  agent frameworks . You want to enforce a strong, formal contract (the A2A protocol) between\n  your system's components. ", "code_blocks": []}, {"heading_path": ["When to Use A2A: Concrete Examples\u00b6"], "text": "When to Use A2A: Concrete Examples \u00b6 Integrating with a Third-Party Service: Your main agent needs to get\n  real-time stock prices from an external financial data provider. This\n  provider exposes its data through an A2A-compatible agent. Microservices Architecture: You have a large system broken down into\n  smaller, independent services (e.g., an Order Processing Agent, an Inventory\n  Management Agent, a Shipping Agent). A2A is ideal for these services to\n  communicate with each other across network boundaries. Cross-Language Communication: Your core business logic is in a Python\n  agent, but you have a legacy system or a specialized component written in Java\n  that you want to integrate as an agent. A2A provides the standardized\n  communication layer. Formal API Enforcement: You are building a platform where different teams\n  contribute agents, and you need a strict contract for how these agents\n  interact to ensure compatibility and stability. ", "code_blocks": []}, {"heading_path": ["When NOT to Use A2A: Concrete Examples (Prefer Local Sub-Agents)\u00b6"], "text": "When NOT to Use A2A: Concrete Examples (Prefer Local Sub-Agents) \u00b6 Internal Code Organization: You are breaking down a complex task within a\n  single agent into smaller, manageable functions or modules (e.g., a DataValidator sub-agent that cleans input data before processing). These are\n  best handled as local sub-agents for performance and simplicity. Performance-Critical Internal Operations: A sub-agent is responsible for a\n  high-frequency, low-latency operation that is tightly coupled with the main\n  agent's execution (e.g., a RealTimeAnalytics sub-agent that processes data\n  streams within the same application). Shared Memory/Context: When sub-agents need direct access to the main\n  agent's internal state or shared memory for efficiency, A2A's network\n  overhead and serialization/deserialization would be counterproductive. Simple Helper Functions: For small, reusable pieces of logic that don't\n  require independent deployment or complex state management, a simple function\n  or class within the same agent is more appropriate than a separate A2A agent. ", "code_blocks": []}, {"heading_path": ["The A2A Workflow in ADK: A Simplified View\u00b6"], "text": "The A2A Workflow in ADK: A Simplified View \u00b6 Agent Development Kit (ADK) simplifies the process of building and connecting\nagents using the A2A protocol. Here's a straightforward breakdown of how it\nworks: Making an Agent Accessible (Exposing): You start with an existing ADK\n    agent that you want other agents to be able to interact with. The ADK\n    provides a simple way to \"expose\" this agent, turning it into an A2AServer . This server acts as a public interface, allowing other agents\n    to send requests to your agent over a network. Think of it like setting up a\n    web server for your agent. Connecting to an Accessible Agent (Consuming): In a separate agent\n    (which could be running on the same machine or a different one), you'll use\n    a special ADK component called RemoteA2aAgent . This RemoteA2aAgent acts\n    as a client that knows how to communicate with the A2AServer you\n    exposed earlier. It handles all the complexities of network communication,\n    authentication, and data formatting behind the scenes. From your perspective as a developer, once you've set up this connection,\ninteracting with the remote agent feels just like interacting with a local tool\nor function. The ADK abstracts away the network layer, making distributed agent\nsystems as easy to work with as local ones. ", "code_blocks": []}, {"heading_path": ["Visualizing the A2A Workflow\u00b6"], "text": "Visualizing the A2A Workflow \u00b6 To further clarify the A2A workflow, let's look at the \"before and after\" for\nboth exposing and consuming agents, and then the combined system. ", "code_blocks": []}, {"heading_path": ["Exposing an Agent\u00b6"], "text": "Exposing an Agent \u00b6 Before Exposing: Your agent code runs as a standalone component, but in this scenario, you want\nto expose it so that other remote agents can interact with your agent. +-------------------+ | Your Agent Code   | |   (Standalone)    | +-------------------+ After Exposing: Your agent code is integrated with an A2AServer (an ADK component), making it\naccessible over a network to other remote agents. +-----------------+ |   A2A Server    | | (ADK Component) |<--------+ +-----------------+         | |                   | v                   | +-------------------+       | | Your Agent Code   |       | | (Now Accessible)  |       | +-------------------+       | | | (Network Communication) v +-----------------------------+ |       Remote Agent(s)       | |    (Can now communicate)    | +-----------------------------+ ", "code_blocks": [{"language": "text", "code": "+-------------------+\n| Your Agent Code   |\n|   (Standalone)    |\n+-------------------+"}, {"language": "text", "code": "+-----------------+\n|   A2A Server    |\n| (ADK Component) |<--------+\n+-----------------+         |\n        |                   |\n        v                   |\n+-------------------+       |\n| Your Agent Code   |       |\n| (Now Accessible)  |       |\n+-------------------+       |\n                            |\n                            | (Network Communication)\n                            v\n+-----------------------------+\n|       Remote Agent(s)       |\n|    (Can now communicate)    |\n+-----------------------------+"}]}, {"heading_path": ["Consuming an Agent\u00b6"], "text": "Consuming an Agent \u00b6 Before Consuming: Your agent (referred to as the \"Root Agent\" in this context) is the application\nyou are developing that needs to interact with a remote agent. Before\nconsuming, it lacks the direct mechanism to do so. +----------------------+         +-------------------------------------------------------------+ |      Root Agent      |         |                        Remote Agent                         | | (Your existing code) |         | (External Service that you want your Root Agent to talk to) | +----------------------+         +-------------------------------------------------------------+ After Consuming: Your Root Agent uses a RemoteA2aAgent (an ADK component that acts as a\nclient-side proxy for the remote agent) to establish communication with the\nremote agent. +----------------------+         +-----------------------------------+ |      Root Agent      |         |         RemoteA2aAgent            | | (Your existing code) |<------->|         (ADK Client Proxy)        | +----------------------+         |                                   | |  +-----------------------------+  | |  |         Remote Agent        |  | |  |      (External Service)     |  | |  +-----------------------------+  | +-----------------------------------+ (Now talks to remote agent via RemoteA2aAgent) ", "code_blocks": [{"language": "text", "code": "+----------------------+         +-------------------------------------------------------------+\n|      Root Agent      |         |                        Remote Agent                         |\n| (Your existing code) |         | (External Service that you want your Root Agent to talk to) |\n+----------------------+         +-------------------------------------------------------------+"}, {"language": "text", "code": "+----------------------+         +-----------------------------------+\n|      Root Agent      |         |         RemoteA2aAgent            |\n| (Your existing code) |<------->|         (ADK Client Proxy)        |\n+----------------------+         |                                   |\n                                 |  +-----------------------------+  |\n                                 |  |         Remote Agent        |  |\n                                 |  |      (External Service)     |  |\n                                 |  +-----------------------------+  |\n                                 +-----------------------------------+\n      (Now talks to remote agent via RemoteA2aAgent)"}]}, {"heading_path": ["Final System (Combined View)\u00b6"], "text": "Final System (Combined View) \u00b6 This diagram shows how the consuming and exposing parts connect to form a\ncomplete A2A system. Consuming Side: +----------------------+         +-----------------------------------+ |      Root Agent      |         |         RemoteA2aAgent            | | (Your existing code) |<------->|         (ADK Client Proxy)        | +----------------------+         |                                   | |  +-----------------------------+  | |  |         Remote Agent        |  | |  |      (External Service)     |  | |  +-----------------------------+  | +-----------------------------------+ | | (Network Communication) v Exposing Side: +-----------------+ |   A2A Server    | | (ADK Component) | +-----------------+ | v +-------------------+ | Your Agent Code   | | (Exposed Service) | +-------------------+ ", "code_blocks": [{"language": "text", "code": "Consuming Side:\n+----------------------+         +-----------------------------------+\n|      Root Agent      |         |         RemoteA2aAgent            |\n| (Your existing code) |<------->|         (ADK Client Proxy)        |\n+----------------------+         |                                   |\n                                 |  +-----------------------------+  |\n                                 |  |         Remote Agent        |  |\n                                 |  |      (External Service)     |  |\n                                 |  +-----------------------------+  |\n                                 +-----------------------------------+\n                                                 |\n                                                 | (Network Communication)\n                                                 v\nExposing Side:\n                                               +-----------------+\n                                               |   A2A Server    |\n                                               | (ADK Component) |\n                                               +-----------------+\n                                                       |\n                                                       v\n                                               +-------------------+\n                                               | Your Agent Code   |\n                                               | (Exposed Service) |\n                                               +-------------------+"}]}, {"heading_path": ["Concrete Use Case: Customer Service and Product Catalog Agents\u00b6"], "text": "Concrete Use Case: Customer Service and Product Catalog Agents \u00b6 Let's consider a practical example: a Customer Service Agent that needs to\nretrieve product information from a separate Product Catalog Agent . ", "code_blocks": []}, {"heading_path": ["Before A2A\u00b6"], "text": "Before A2A \u00b6 Initially, your Customer Service Agent might not have a direct, standardized\nway to query the Product Catalog Agent, especially if it's a separate service\nor managed by a different team. +-------------------------+         +--------------------------+ | Customer Service Agent  |         |  Product Catalog Agent   | | (Needs Product Info)    |         | (Contains Product Data)  | +-------------------------+         +--------------------------+ (No direct, standardized communication) ", "code_blocks": [{"language": "text", "code": "+-------------------------+         +--------------------------+\n| Customer Service Agent  |         |  Product Catalog Agent   |\n| (Needs Product Info)    |         | (Contains Product Data)  |\n+-------------------------+         +--------------------------+\n      (No direct, standardized communication)"}]}, {"heading_path": ["After A2A\u00b6"], "text": "After A2A \u00b6 By using the A2A Protocol, the Product Catalog Agent can expose its\nfunctionality as an A2A service. Your Customer Service Agent can then easily\nconsume this service using ADK's RemoteA2aAgent . +-------------------------+         +-----------------------------------+ | Customer Service Agent  |         |         RemoteA2aAgent            | | (Your Root Agent)       |<------->|         (ADK Client Proxy)        | +-------------------------+         |                                   | |  +-----------------------------+  | |  |     Product Catalog Agent   |  | |  |      (External Service)     |  | |  +-----------------------------+  | +-----------------------------------+ | | (Network Communication) v +-----------------+ |   A2A Server    | | (ADK Component) | +-----------------+ | v +------------------------+ | Product Catalog Agent  | | (Exposed Service)      | +------------------------+ In this setup, first, the Product Catalog Agent needs to be exposed via an A2A\nServer. Then, the Customer Service Agent can simply call methods on the RemoteA2aAgent as if it were a tool, and the ADK handles all the underlying\ncommunication to the Product Catalog Agent. This allows for clear separation of\nconcerns and easy integration of specialized agents. ", "code_blocks": [{"language": "text", "code": "+-------------------------+         +-----------------------------------+\n| Customer Service Agent  |         |         RemoteA2aAgent            |\n| (Your Root Agent)       |<------->|         (ADK Client Proxy)        |\n+-------------------------+         |                                   |\n                                    |  +-----------------------------+  |\n                                    |  |     Product Catalog Agent   |  |\n                                    |  |      (External Service)     |  |\n                                    |  +-----------------------------+  |\n                                    +-----------------------------------+\n                                                 |\n                                                 | (Network Communication)\n                                                 v\n                                               +-----------------+\n                                               |   A2A Server    |\n                                               | (ADK Component) |\n                                               +-----------------+\n                                                       |\n                                                       v\n                                               +------------------------+\n                                               | Product Catalog Agent  |\n                                               | (Exposed Service)      |\n                                               +------------------------+"}]}, {"heading_path": ["Next Steps\u00b6"], "text": "Next Steps \u00b6 Now that you understand the \"why\" of A2A, let's dive into the \"how.\" Continue to the next guide: Quickstart: Exposing Your Agent Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:42.357721", "source_type": "adk-docs"}
{"doc_id": "e6bd5c24e476cac0d63f10960105f9b15e73d8aa9c0eedde7e224edde98df4c7", "url": "https://google.github.io/adk-docs/a2a/quickstart-exposing", "title": "Python - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Quickstart: Exposing a remote agent via A2A\u00b6"], "text": "Quickstart: Exposing a remote agent via A2A \u00b6 Supported in ADK Python Experimental This quickstart covers the most common starting point for any developer: \"I have an agent. How do I expose it so that other agents can use my agent via A2A?\" . This is crucial for building complex multi-agent systems where different agents need to collaborate and interact. ", "code_blocks": []}, {"heading_path": ["Overview\u00b6"], "text": "Overview \u00b6 This sample demonstrates how you can easily expose an ADK agent so that it can be then consumed by another agent using the A2A Protocol. There are two main ways to expose an ADK agent via A2A. by using the to_a2a(root_agent) function : use this function if you just want to convert an existing agent to work with A2A, and be able to expose it via a server through uvicorn , instead of adk deploy api_server . This means that you have tighter control over what you want to expose via uvicorn when you want to productionize your agent. Furthermore, the to_a2a() function auto-generates an agent card based on your agent code. by creating your own agent card ( agent.json ) and hosting it using adk api_server --a2a : There are two main benefits of using this approach. First, adk api_server --a2a works with adk web , making it easy to use, debug, and test your agent. Second, with adk api_server , you can specify a parent folder with multiple, separate agents. Those agents that have an agent card ( agent.json ), will automatically be usable via A2A by other agents through the same server. However, you will need to create your own agent cards. To create an agent card, you can follow the A2A Python tutorial . This quickstart will focus on to_a2a() , as it is the easiest way to expose your agent and will also autogenerate the agent card behind-the-scenes. If you'd like to use the adk api_server approach, you can see it being used in the A2A Quickstart (Consuming) documentation . Before: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Hello World Agent  \u2502 \u2502  (Python Object)   \u2502 | without agent card \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 to_a2a() \u25bc After: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   Root Agent   \u2502       A2A Protocol          \u2502 A2A-Exposed Hello World Agent \u2502 \u2502(RemoteA2aAgent)\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502      (localhost: 8001)         \u2502 \u2502(localhost:8000)\u2502                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The sample consists of : Remote Hello World Agent ( remote_a2a/hello_world/agent.py ): This is the agent that you want to expose so that other agents can use it via A2A. It is an agent that handles dice rolling and prime number checking. It becomes exposed using the to_a2a() function and is served using uvicorn . Root Agent ( agent.py ): A simple agent that is just calling the remote Hello World agent. ", "code_blocks": [{"language": "text", "code": "Before:\n                                                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                \u2502 Hello World Agent  \u2502\n                                                \u2502  (Python Object)   \u2502\n                                                | without agent card \u2502\n                                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n                                                          \u2502\n                                                          \u2502 to_a2a()\n                                                          \u25bc\n\nAfter:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Root Agent   \u2502       A2A Protocol          \u2502 A2A-Exposed Hello World Agent \u2502\n\u2502(RemoteA2aAgent)\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502      (localhost: 8001)         \u2502\n\u2502(localhost:8000)\u2502                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518"}]}, {"heading_path": ["Exposing the Remote Agent with the to_a2a(root_agent) function\u00b6"], "text": "Exposing the Remote Agent with the to_a2a(root_agent) function \u00b6 You can take an existing agent built using ADK and make it A2A-compatible by simply wrapping it using the to_a2a() function. For example, if you have an agent like the following defined in root_agent : # Your agent code here root_agent = Agent ( model = 'gemini-2.0-flash' , name = 'hello_world_agent' , <... your agent code ...> ) Then you can make it A2A-compatible simply by using to_a2a(root_agent) : from google.adk.a2a.utils.agent_to_a2a import to_a2a # Make your agent A2A-compatible a2a_app = to_a2a ( root_agent , port = 8001 ) The to_a2a() function will even auto-generate an agent card in-memory behind-the-scenes by extracting skills, capabilities, and metadata from the ADK agent , so that the well-known agent card is made available when the agent endpoint is served using uvicorn . You can also provide your own agent card by using the agent_card parameter. The value can be an AgentCard object or a path to an agent card JSON file. Example with an AgentCard object: from google.adk.a2a.utils.agent_to_a2a import to_a2a from a2a.types import AgentCard # Define A2A agent card my_agent_card = AgentCard ( \"name\" : \"file_agent\" , \"url\" : \"http://example.com\" , \"description\" : \"Test agent from file\" , \"version\" : \"1.0.0\" , \"capabilities\" : {}, \"skills\" : [], \"defaultInputModes\" : [ \"text/plain\" ], \"defaultOutputModes\" : [ \"text/plain\" ], \"supportsAuthenticatedExtendedCard\" : False , ) a2a_app = to_a2a ( root_agent , port = 8001 , agent_card = my_agent_card ) Example with a path to a JSON file: from google.adk.a2a.utils.agent_to_a2a import to_a2a # Load A2A agent card from a file a2a_app = to_a2a ( root_agent , port = 8001 , agent_card = \"/path/to/your/agent-card.json\" ) Now let's dive into the sample code. ", "code_blocks": [{"language": "text", "code": "# Your agent code here\nroot_agent = Agent(\n    model='gemini-2.0-flash',\n    name='hello_world_agent',\n\n    <...your agent code...>\n)"}, {"language": "text", "code": "from google.adk.a2a.utils.agent_to_a2a import to_a2a\n\n# Make your agent A2A-compatible\na2a_app = to_a2a(root_agent, port=8001)"}, {"language": "text", "code": "from google.adk.a2a.utils.agent_to_a2a import to_a2a\nfrom a2a.types import AgentCard\n\n# Define A2A agent card\nmy_agent_card = AgentCard(\n    \"name\": \"file_agent\",\n    \"url\": \"http://example.com\",\n    \"description\": \"Test agent from file\",\n    \"version\": \"1.0.0\",\n    \"capabilities\": {},\n    \"skills\": [],\n    \"defaultInputModes\": [\"text/plain\"],\n    \"defaultOutputModes\": [\"text/plain\"],\n    \"supportsAuthenticatedExtendedCard\": False,\n)\na2a_app = to_a2a(root_agent, port=8001, agent_card=my_agent_card)"}, {"language": "text", "code": "from google.adk.a2a.utils.agent_to_a2a import to_a2a\n\n# Load A2A agent card from a file\na2a_app = to_a2a(root_agent, port=8001, agent_card=\"/path/to/your/agent-card.json\")"}]}, {"heading_path": ["1. Getting the Sample Code\u00b6"], "text": "1. Getting the Sample Code \u00b6 First, make sure you have the necessary dependencies installed: pip install google-adk [ a2a ] You can clone and navigate to the a2a_root sample here: git clone https://github.com/google/adk-python.git As you'll see, the folder structure is as follows: a2a_root/ \u251c\u2500\u2500 remote_a2a/ \u2502   \u2514\u2500\u2500 hello_world/ \u2502       \u251c\u2500\u2500 __init__.py \u2502       \u2514\u2500\u2500 agent.py    # Remote Hello World Agent \u251c\u2500\u2500 README.md \u2514\u2500\u2500 agent.py            # Root agent ", "code_blocks": [{"language": "text", "code": "pip install google-adk[a2a]"}, {"language": "text", "code": "git clone https://github.com/google/adk-python.git"}, {"language": "text", "code": "a2a_root/\n\u251c\u2500\u2500 remote_a2a/\n\u2502   \u2514\u2500\u2500 hello_world/    \n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 agent.py    # Remote Hello World Agent\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 agent.py            # Root agent"}]}, {"heading_path": ["Root Agent (a2a_root/agent.py)\u00b6"], "text": "Root Agent ( a2a_root/agent.py ) \u00b6 root_agent : A RemoteA2aAgent that connects to the remote A2A service Agent Card URL : Points to the well-known agent card endpoint on the remote server ", "code_blocks": []}, {"heading_path": ["Remote Hello World Agent (a2a_root/remote_a2a/hello_world/agent.py)\u00b6"], "text": "Remote Hello World Agent ( a2a_root/remote_a2a/hello_world/agent.py ) \u00b6 roll_die(sides: int) : Function tool for rolling dice with state management check_prime(nums: list[int]) : Async function for prime number checking root_agent : The main agent with comprehensive instructions a2a_app : The A2A application created using to_a2a() utility ", "code_blocks": []}, {"heading_path": ["2. Start the Remote A2A Agent server\u00b6"], "text": "2. Start the Remote A2A Agent server \u00b6 You can now start the remote agent server, which will host the a2a_app within the hello_world agent: # Ensure current working directory is adk-python/ # Start the remote agent using uvicorn uvicorn contributing.samples.a2a_root.remote_a2a.hello_world.agent:a2a_app --host localhost --port 8001 Why use port 8001? In this quickstart, when testing locally, your agents will be using localhost, so the port for the A2A server for the exposed agent (the remote, prime agent) must be different from the consuming agent's port. The default port for adk web where you will interact with the consuming agent is 8000 , which is why the A2A server is created using a separate port, 8001 . Once executed, you should see something like: INFO: Started server process [ 10615 ] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://localhost:8001 ( Press CTRL+C to quit ) ", "code_blocks": [{"language": "text", "code": "# Ensure current working directory is adk-python/\n# Start the remote agent using uvicorn\nuvicorn contributing.samples.a2a_root.remote_a2a.hello_world.agent:a2a_app --host localhost --port 8001"}, {"language": "text", "code": "INFO:     Started server process [10615]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:8001 (Press CTRL+C to quit)"}]}, {"heading_path": ["3. Check that your remote agent is running\u00b6"], "text": "3. Check that your remote agent is running \u00b6 You can check that your agent is up and running by visiting the agent card that was auto-generated earlier as part of your to_a2a() function in a2a_root/remote_a2a/hello_world/agent.py : http://localhost:8001/.well-known/agent-card.json You should see the contents of the agent card, which should look like: { \"capabilities\" :{}, \"defaultInputModes\" :[ \"text/plain\" ], \"defaultOutputModes\" :[ \"text/plain\" ], \"description\" : \"hello world agent that can roll a dice of 8 sides and check prime numbers.\" , \"name\" : \"hello_world_agent\" , \"protocolVersion\" : \"0.2.6\" , \"skills\" :[{ \"description\" : \"hello world agent that can roll a dice of 8 sides and check prime numbers. \\n      I roll dice and answer questions about the outcome of the dice rolls.\\n      I can roll dice of different sizes.\\n      I can use multiple tools in parallel by calling functions in parallel(in one request and in one round).\\n      It is ok to discuss previous dice roles, and comment on the dice rolls.\\n      When I are asked to roll a die, I must call the roll_die tool with the number of sides. Be sure to pass in an integer. Do not pass in a string.\\n      I should never roll a die on my own.\\n      When checking prime numbers, call the check_prime tool with a list of integers. Be sure to pass in a list of integers. I should never pass in a string.\\n      I should not check prime numbers before calling the tool.\\n      When I are asked to roll a die and check prime numbers, I should always make the following two function calls:\\n      1. I should first call the roll_die tool to get a roll. Wait for the function response before calling the check_prime tool.\\n      2. After I get the function response from roll_die tool, I should call the check_prime tool with the roll_die result.\\n        2.1 If user asks I to check primes based on previous rolls, make sure I include the previous rolls in the list.\\n      3. When I respond, I must include the roll_die result from step 1.\\n      I should always perform the previous 3 steps when asking for a roll and checking prime numbers.\\n      I should not rely on the previous history on prime results.\\n    \" , \"id\" : \"hello_world_agent\" , \"name\" : \"model\" , \"tags\" :[ \"llm\" ]},{ \"description\" : \"Roll a die and return the rolled result.\\n\\nArgs:\\n  sides: The integer number of sides the die has.\\n  tool_context: the tool context\\nReturns:\\n  An integer of the result of rolling the die.\" , \"id\" : \"hello_world_agent-roll_die\" , \"name\" : \"roll_die\" , \"tags\" :[ \"llm\" , \"tools\" ]},{ \"description\" : \"Check if a given list of numbers are prime.\\n\\nArgs:\\n  nums: The list of numbers to check.\\n\\nReturns:\\n  A str indicating which number is prime.\" , \"id\" : \"hello_world_agent-check_prime\" , \"name\" : \"check_prime\" , \"tags\" :[ \"llm\" , \"tools\" ]}], \"supportsAuthenticatedExtendedCard\" : false , \"url\" : \"http://localhost:8001\" , \"version\" : \"0.0.1\" } ", "code_blocks": [{"language": "text", "code": "{\"capabilities\":{},\"defaultInputModes\":[\"text/plain\"],\"defaultOutputModes\":[\"text/plain\"],\"description\":\"hello world agent that can roll a dice of 8 sides and check prime numbers.\",\"name\":\"hello_world_agent\",\"protocolVersion\":\"0.2.6\",\"skills\":[{\"description\":\"hello world agent that can roll a dice of 8 sides and check prime numbers. \\n      I roll dice and answer questions about the outcome of the dice rolls.\\n      I can roll dice of different sizes.\\n      I can use multiple tools in parallel by calling functions in parallel(in one request and in one round).\\n      It is ok to discuss previous dice roles, and comment on the dice rolls.\\n      When I are asked to roll a die, I must call the roll_die tool with the number of sides. Be sure to pass in an integer. Do not pass in a string.\\n      I should never roll a die on my own.\\n      When checking prime numbers, call the check_prime tool with a list of integers. Be sure to pass in a list of integers. I should never pass in a string.\\n      I should not check prime numbers before calling the tool.\\n      When I are asked to roll a die and check prime numbers, I should always make the following two function calls:\\n      1. I should first call the roll_die tool to get a roll. Wait for the function response before calling the check_prime tool.\\n      2. After I get the function response from roll_die tool, I should call the check_prime tool with the roll_die result.\\n        2.1 If user asks I to check primes based on previous rolls, make sure I include the previous rolls in the list.\\n      3. When I respond, I must include the roll_die result from step 1.\\n      I should always perform the previous 3 steps when asking for a roll and checking prime numbers.\\n      I should not rely on the previous history on prime results.\\n    \",\"id\":\"hello_world_agent\",\"name\":\"model\",\"tags\":[\"llm\"]},{\"description\":\"Roll a die and return the rolled result.\\n\\nArgs:\\n  sides: The integer number of sides the die has.\\n  tool_context: the tool context\\nReturns:\\n  An integer of the result of rolling the die.\",\"id\":\"hello_world_agent-roll_die\",\"name\":\"roll_die\",\"tags\":[\"llm\",\"tools\"]},{\"description\":\"Check if a given list of numbers are prime.\\n\\nArgs:\\n  nums: The list of numbers to check.\\n\\nReturns:\\n  A str indicating which number is prime.\",\"id\":\"hello_world_agent-check_prime\",\"name\":\"check_prime\",\"tags\":[\"llm\",\"tools\"]}],\"supportsAuthenticatedExtendedCard\":false,\"url\":\"http://localhost:8001\",\"version\":\"0.0.1\"}"}]}, {"heading_path": ["4. Run the Main (Consuming) Agent\u00b6"], "text": "4. Run the Main (Consuming) Agent \u00b6 Now that your remote agent is running, you can launch the dev UI and select \"a2a_root\" as your agent. # In a separate terminal, run the adk web server adk web contributing/samples/ To open the adk web server, go to: http://localhost:8000 . ", "code_blocks": [{"language": "text", "code": "# In a separate terminal, run the adk web server\nadk web contributing/samples/"}]}, {"heading_path": ["Example Interactions\u00b6"], "text": "Example Interactions \u00b6 Once both services are running, you can interact with the root agent to see how it calls the remote agent via A2A: Simple Dice Rolling: This interaction uses a local agent, the Roll Agent: User: Roll a 6-sided die Bot: I rolled a 4 for you. Prime Number Checking: This interaction uses a remote agent via A2A, the Prime Agent: User: Is 7 a prime number? Bot: Yes, 7 is a prime number. Combined Operations: This interaction uses both the local Roll Agent and the remote Prime Agent: User: Roll a 10-sided die and check if it's prime Bot: I rolled an 8 for you. Bot: 8 is not a prime number. ", "code_blocks": [{"language": "text", "code": "User: Roll a 6-sided die\nBot: I rolled a 4 for you."}, {"language": "text", "code": "User: Is 7 a prime number?\nBot: Yes, 7 is a prime number."}, {"language": "text", "code": "User: Roll a 10-sided die and check if it's prime\nBot: I rolled an 8 for you.\nBot: 8 is not a prime number."}]}, {"heading_path": ["Next Steps\u00b6"], "text": "Next Steps \u00b6 Now that you have created an agent that's exposing a remote agent via an A2A server, the next step is to learn how to consume it from another agent. A2A Quickstart (Consuming) : Learn how your agent can use other agents using the A2A Protocol. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:42.884692", "source_type": "adk-docs"}
{"doc_id": "84aae25f08ad90cb1d6415a4da6b7315c87e8dbd5eb7769fc5c5ba3776c550c0", "url": "https://google.github.io/adk-docs/a2a/quickstart-exposing-go", "title": "Go - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Quickstart: Exposing a remote agent via A2A\u00b6"], "text": "Quickstart: Exposing a remote agent via A2A \u00b6 Supported in ADK Go Experimental This quickstart covers the most common starting point for any developer: \"I have an agent. How do I expose it so that other agents can use my agent via A2A?\" . This is crucial for building complex multi-agent systems where different agents need to collaborate and interact. ", "code_blocks": []}, {"heading_path": ["Overview\u00b6"], "text": "Overview \u00b6 This sample demonstrates how you can easily expose an ADK agent so that it can be then consumed by another agent using the A2A Protocol. In Go, you expose an agent by using the A2A launcher, which dynamically generates an agent card for you. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   Root Agent    \u2502       A2A Protocol          \u2502 A2A-Exposed Check Prime Agent \u2502 \u2502                 \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502      (localhost: 8001)        \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The sample consists of : Remote Prime Agent ( remote_a2a/check_prime_agent/main.go ): This is the agent that you want to expose so that other agents can use it via A2A. It is an agent that handles prime number checking. It becomes exposed using the A2A launcher. Root Agent ( main.go ): A simple agent that is just calling the remote prime agent. ", "code_blocks": [{"language": "text", "code": "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Root Agent    \u2502       A2A Protocol          \u2502 A2A-Exposed Check Prime Agent \u2502\n\u2502                 \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502      (localhost: 8001)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518"}]}, {"heading_path": ["Exposing the Remote Agent with the A2A Launcher\u00b6"], "text": "Exposing the Remote Agent with the A2A Launcher \u00b6 You can take an existing agent built using the Go ADK and make it A2A-compatible by using the A2A launcher. ", "code_blocks": []}, {"heading_path": ["1. Getting the Sample Code\u00b6"], "text": "1. Getting the Sample Code \u00b6 First, make sure you have Go installed and your environment is set up. You can clone and navigate to the a2a_basic sample here: cd examples/go/a2a_basic As you'll see, the folder structure is as follows: a2a_basic/ \u251c\u2500\u2500 remote_a2a/ \u2502   \u2514\u2500\u2500 check_prime_agent/ \u2502       \u2514\u2500\u2500 main.go    # Remote Prime Agent \u251c\u2500\u2500 go.mod \u251c\u2500\u2500 go.sum \u2514\u2500\u2500 main.go            # Root agent ", "code_blocks": [{"language": "text", "code": "cd examples/go/a2a_basic"}, {"language": "text", "code": "a2a_basic/\n\u251c\u2500\u2500 remote_a2a/\n\u2502   \u2514\u2500\u2500 check_prime_agent/\n\u2502       \u2514\u2500\u2500 main.go    # Remote Prime Agent\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 go.sum\n\u2514\u2500\u2500 main.go            # Root agent"}]}, {"heading_path": ["Root Agent (a2a_basic/main.go)\u00b6"], "text": "Root Agent ( a2a_basic/main.go ) \u00b6 newRootAgent : A local agent that connects to the remote A2A service. ", "code_blocks": []}, {"heading_path": ["Remote Prime Agent (a2a_basic/remote_a2a/check_prime_agent/main.go)\u00b6"], "text": "Remote Prime Agent ( a2a_basic/remote_a2a/check_prime_agent/main.go ) \u00b6 checkPrimeTool : Function for prime number checking. main : The main function that creates the agent and starts the A2A server. ", "code_blocks": []}, {"heading_path": ["2. Start the Remote A2A Agent server\u00b6"], "text": "2. Start the Remote A2A Agent server \u00b6 You can now start the remote agent server, which will host the check_prime_agent : # Start the remote agent go run remote_a2a/check_prime_agent/main.go Once executed, you should see something like: 2025 /11/06 11 :00:19 Starting A2A prime checker server on port 8001 2025 /11/06 11 :00:19 Starting the web server: & { port:8001 } 2025 /11/06 11 :00:19 2025 /11/06 11 :00:19 Web servers starts on http://localhost:8001 2025 /11/06 11 :00:19 a2a: you can access A2A using jsonrpc protocol: http://localhost:8001 ", "code_blocks": [{"language": "text", "code": "# Start the remote agent\ngo run remote_a2a/check_prime_agent/main.go"}, {"language": "text", "code": "2025/11/06 11:00:19 Starting A2A prime checker server on port 8001\n2025/11/06 11:00:19 Starting the web server: &{port:8001}\n2025/11/06 11:00:19 \n2025/11/06 11:00:19 Web servers starts on http://localhost:8001\n2025/11/06 11:00:19        a2a:  you can access A2A using jsonrpc protocol: http://localhost:8001"}]}, {"heading_path": ["3. Check that your remote agent is running\u00b6"], "text": "3. Check that your remote agent is running \u00b6 You can check that your agent is up and running by visiting the agent card that was auto-generated by the A2A launcher: http://localhost:8001/.well-known/agent-card.json You should see the contents of the agent card. ", "code_blocks": []}, {"heading_path": ["4. Run the Main (Consuming) Agent\u00b6"], "text": "4. Run the Main (Consuming) Agent \u00b6 Now that your remote agent is running, you can run the main agent. # In a separate terminal, run the main agent go run main.go ", "code_blocks": [{"language": "text", "code": "# In a separate terminal, run the main agent\ngo run main.go"}]}, {"heading_path": ["How it works\u00b6"], "text": "How it works \u00b6 The remote agent is exposed using the A2A launcher in the main function. The launcher takes care of starting the server and generating the agent card. remote_a2a/check_prime_agent/main.go func main () { ctx := context . Background () primeTool , err := functiontool . New ( functiontool . Config { Name : \"prime_checking\" , Description : \"Check if numbers in a list are prime using efficient mathematical algorithms\" , }, checkPrimeTool ) if err != nil { log . Fatalf ( \"Failed to create prime_checking tool: %v\" , err ) } model , err := gemini . NewModel ( ctx , \"gemini-2.0-flash\" , & genai . ClientConfig {}) if err != nil { log . Fatalf ( \"Failed to create model: %v\" , err ) } primeAgent , err := llmagent . New ( llmagent . Config { Name : \"check_prime_agent\" , Description : \"check prime agent that can check whether numbers are prime.\" , Instruction : ` You check whether numbers are prime. When checking prime numbers, call the check_prime tool with a list of integers. Be sure to pass in a list of integers. You should never pass in a string. You should not rely on the previous history on prime results. ` , Model : model , Tools : [] tool . Tool { primeTool }, }) if err != nil { log . Fatalf ( \"Failed to create agent: %v\" , err ) } // Create launcher. The a2a.NewLauncher() will dynamically generate the agent card. port := 8001 launcher := web . NewLauncher ( a2a . NewLauncher ()) _ , err = launcher . Parse ([] string { \"--port\" , strconv . Itoa ( port ), \"a2a\" , \"--a2a_agent_url\" , \"http://localhost:\" + strconv . Itoa ( port ), }) if err != nil { log . Fatalf ( \"launcher.Parse() error = %v\" , err ) } // Create ADK config config := & adk . Config { AgentLoader : services . NewSingleAgentLoader ( primeAgent ), SessionService : session . InMemoryService (), } log . Printf ( \"Starting A2A prime checker server on port %d\\n\" , port ) // Run launcher if err := launcher . Run ( context . Background (), config ); err != nil { log . Fatalf ( \"launcher.Run() error = %v\" , err ) } } ", "code_blocks": [{"language": "text", "code": "func main() {\n    ctx := context.Background()\n    primeTool, err := functiontool.New(functiontool.Config{\n        Name:        \"prime_checking\",\n        Description: \"Check if numbers in a list are prime using efficient mathematical algorithms\",\n    }, checkPrimeTool)\n    if err != nil {\n        log.Fatalf(\"Failed to create prime_checking tool: %v\", err)\n    }\n\n    model, err := gemini.NewModel(ctx, \"gemini-2.0-flash\", &genai.ClientConfig{})\n    if err != nil {\n        log.Fatalf(\"Failed to create model: %v\", err)\n    }\n\n    primeAgent, err := llmagent.New(llmagent.Config{\n        Name:        \"check_prime_agent\",\n        Description: \"check prime agent that can check whether numbers are prime.\",\n        Instruction: `\n            You check whether numbers are prime.\n            When checking prime numbers, call the check_prime tool with a list of integers. Be sure to pass in a list of integers. You should never pass in a string.\n            You should not rely on the previous history on prime results.\n    `,\n        Model: model,\n        Tools: []tool.Tool{primeTool},\n    })\n    if err != nil {\n        log.Fatalf(\"Failed to create agent: %v\", err)\n    }\n\n    // Create launcher. The a2a.NewLauncher() will dynamically generate the agent card.\n    port := 8001\n    launcher := web.NewLauncher(a2a.NewLauncher())\n    _, err = launcher.Parse([]string{\n        \"--port\", strconv.Itoa(port),\n        \"a2a\", \"--a2a_agent_url\", \"http://localhost:\" + strconv.Itoa(port),\n    })\n    if err != nil {\n        log.Fatalf(\"launcher.Parse() error = %v\", err)\n    }\n\n    // Create ADK config\n    config := &adk.Config{\n        AgentLoader:    services.NewSingleAgentLoader(primeAgent),\n        SessionService: session.InMemoryService(),\n    }\n\n    log.Printf(\"Starting A2A prime checker server on port %d\\n\", port)\n    // Run launcher\n    if err := launcher.Run(context.Background(), config); err != nil {\n        log.Fatalf(\"launcher.Run() error = %v\", err)\n    }\n}"}]}, {"heading_path": ["Example Interactions\u00b6"], "text": "Example Interactions \u00b6 Once both services are running, you can interact with the root agent to see how it calls the remote agent via A2A: Prime Number Checking: This interaction uses a remote agent via A2A, the Prime Agent: User: roll a die and check if it's a prime Bot: Okay, I will first roll a die and then check if the result is a prime number. Bot calls tool: transfer_to_agent with args: map[agent_name:roll_agent] Bot calls tool: roll_die with args: map[sides:6] Bot calls tool: transfer_to_agent with args: map[agent_name:prime_agent] Bot calls tool: prime_checking with args: map[nums:[3]] Bot: 3 is a prime number. ... ", "code_blocks": [{"language": "text", "code": "User: roll a die and check if it's a prime\nBot: Okay, I will first roll a die and then check if the result is a prime number.\n\nBot calls tool: transfer_to_agent with args: map[agent_name:roll_agent]\nBot calls tool: roll_die with args: map[sides:6]\nBot calls tool: transfer_to_agent with args: map[agent_name:prime_agent]\nBot calls tool: prime_checking with args: map[nums:[3]]\nBot: 3 is a prime number.\n..."}]}, {"heading_path": ["Next Steps\u00b6"], "text": "Next Steps \u00b6 Now that you have created an agent that's exposing a remote agent via an A2A server, the next step is to learn how to consume it from another agent. A2A Quickstart (Consuming) : Learn how your agent can use other agents using the A2A Protocol. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:43.378696", "source_type": "adk-docs"}
{"doc_id": "1439f1f555baab1b5c7b8793f8ad3912f1a42b0bd27f9e4b96cf89a2abf0aea8", "url": "https://google.github.io/adk-docs/a2a/quickstart-consuming", "title": "Python - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Quickstart: Consuming a remote agent via A2A\u00b6"], "text": "Quickstart: Consuming a remote agent via A2A \u00b6 Supported in ADK Python Experimental This quickstart covers the most common starting point for any developer: \"There is a remote agent, how do I let my ADK agent use it via A2A?\" . This is crucial for building complex multi-agent systems where different agents need to collaborate and interact. ", "code_blocks": []}, {"heading_path": ["Overview\u00b6"], "text": "Overview \u00b6 This sample demonstrates the Agent2Agent (A2A) architecture in the Agent Development Kit (ADK), showcasing how multiple agents can work together to handle complex tasks. The sample implements an agent that can roll dice and check if numbers are prime. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   Root Agent    \u2502\u2500\u2500\u2500\u25b6\u2502   Roll Agent     \u2502    \u2502   Remote Prime     \u2502 \u2502  (Local)        \u2502    \u2502   (Local)        \u2502    \u2502   Agent            \u2502 \u2502                 \u2502    \u2502                  \u2502    \u2502  (localhost:8001)  \u2502 \u2502                 \u2502\u2500\u2500\u2500\u25b6\u2502                  \u2502\u25c0\u2500\u2500\u2500\u2502                    \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The A2A Basic sample consists of: Root Agent ( root_agent ): The main orchestrator that delegates tasks to specialized sub-agents Roll Agent ( roll_agent ): A local sub-agent that handles dice rolling operations Prime Agent ( prime_agent ): A remote A2A agent that checks if numbers are prime, this agent is running on a separate A2A server ", "code_blocks": [{"language": "text", "code": "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Root Agent    \u2502\u2500\u2500\u2500\u25b6\u2502   Roll Agent     \u2502    \u2502   Remote Prime     \u2502\n\u2502  (Local)        \u2502    \u2502   (Local)        \u2502    \u2502   Agent            \u2502\n\u2502                 \u2502    \u2502                  \u2502    \u2502  (localhost:8001)  \u2502\n\u2502                 \u2502\u2500\u2500\u2500\u25b6\u2502                  \u2502\u25c0\u2500\u2500\u2500\u2502                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518"}]}, {"heading_path": ["Exposing Your Agent with the ADK Server\u00b6"], "text": "Exposing Your Agent with the ADK Server \u00b6 The ADK comes with a built-in CLI command, adk api_server --a2a to expose your agent using the A2A protocol. In the a2a_basic example, you will first need to expose the check_prime_agent via an A2A server, so that the local root agent can use it. ", "code_blocks": []}, {"heading_path": ["1. Getting the Sample Code\u00b6"], "text": "1. Getting the Sample Code \u00b6 First, make sure you have the necessary dependencies installed: pip install google-adk [ a2a ] You can clone and navigate to the a2a_basic sample here: git clone https://github.com/google/adk-python.git As you'll see, the folder structure is as follows: a2a_basic/ \u251c\u2500\u2500 remote_a2a/ \u2502   \u2514\u2500\u2500 check_prime_agent/ \u2502       \u251c\u2500\u2500 __init__.py \u2502       \u251c\u2500\u2500 agent.json \u2502       \u2514\u2500\u2500 agent.py \u251c\u2500\u2500 README.md \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 agent.py # local root agent ", "code_blocks": [{"language": "text", "code": "pip install google-adk[a2a]"}, {"language": "text", "code": "git clone https://github.com/google/adk-python.git"}, {"language": "text", "code": "a2a_basic/\n\u251c\u2500\u2500 remote_a2a/\n\u2502   \u2514\u2500\u2500 check_prime_agent/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 agent.json\n\u2502       \u2514\u2500\u2500 agent.py\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 __init__.py\n\u2514\u2500\u2500 agent.py # local root agent"}]}, {"heading_path": ["Main Agent (a2a_basic/agent.py)\u00b6"], "text": "Main Agent ( a2a_basic/agent.py ) \u00b6 roll_die(sides: int) : Function tool for rolling dice roll_agent : Local agent specialized in dice rolling prime_agent : Remote A2A agent configuration root_agent : Main orchestrator with delegation logic ", "code_blocks": []}, {"heading_path": ["Remote Prime Agent (a2a_basic/remote_a2a/check_prime_agent/)\u00b6"], "text": "Remote Prime Agent ( a2a_basic/remote_a2a/check_prime_agent/ ) \u00b6 agent.py : Implementation of the prime checking service agent.json : Agent card of the A2A agent check_prime(nums: list[int]) : Prime number checking algorithm ", "code_blocks": []}, {"heading_path": ["2. Start the Remote Prime Agent server\u00b6"], "text": "2. Start the Remote Prime Agent server \u00b6 To show how your ADK agent can consume a remote agent via A2A, you'll first need to start a remote agent server, which will host the prime agent (under check_prime_agent ). # Start the remote a2a server that serves the check_prime_agent on port 8001 adk api_server --a2a --port 8001 contributing/samples/a2a_basic/remote_a2a Adding logging for debugging with --log_level debug To enable debug-level logging, you can add --log_level debug to your adk api_server , as in: adk api_server --a2a --port 8001 contributing/samples/a2a_basic/remote_a2a --log_level debug This will give richer logs for you to inspect when testing your agents. Why use port 8001? In this quickstart, when testing locally, your agents will be using localhost, so the port for the A2A server for the exposed agent (the remote, prime agent) must be different from the consuming agent's port. The default port for adk web where you will interact with the consuming agent is 8000 , which is why the A2A server is created using a separate port, 8001 . Once executed, you should see something like: INFO: Started server process [ 56558 ] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://127.0.0.1:8001 ( Press CTRL+C to quit ) ", "code_blocks": [{"language": "text", "code": "# Start the remote a2a server that serves the check_prime_agent on port 8001\nadk api_server --a2a --port 8001 contributing/samples/a2a_basic/remote_a2a"}, {"language": "text", "code": "adk api_server --a2a --port 8001 contributing/samples/a2a_basic/remote_a2a --log_level debug"}, {"language": "text", "code": "INFO:     Started server process [56558]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8001 (Press CTRL+C to quit)"}]}, {"heading_path": ["3. Look out for the required agent card (agent-card.json) of the remote agent\u00b6"], "text": "3. Look out for the required agent card ( agent-card.json ) of the remote agent \u00b6 A2A Protocol requires that each agent must have an agent card that describes what it does. If someone else has already built the remote A2A agent that you are looking to consume in your agent, then you should confirm that they have an agent card ( agent-card.json ). In the sample, the check_prime_agent already has an agent card provided: a2a_basic/remote_a2a/check_prime_agent/agent-card.json { \"capabilities\" : {}, \"defaultInputModes\" : [ \"text/plain\" ], \"defaultOutputModes\" : [ \"application/json\" ], \"description\" : \"An agent specialized in checking whether numbers are prime. It can efficiently determine the primality of individual numbers or lists of numbers.\" , \"name\" : \"check_prime_agent\" , \"skills\" : [ { \"id\" : \"prime_checking\" , \"name\" : \"Prime Number Checking\" , \"description\" : \"Check if numbers in a list are prime using efficient mathematical algorithms\" , \"tags\" : [ \"mathematical\" , \"computation\" , \"prime\" , \"numbers\" ] } ], \"url\" : \"http://localhost:8001/a2a/check_prime_agent\" , \"version\" : \"1.0.0\" } More info on agent cards in ADK In ADK, you can use a to_a2a(root_agent) wrapper which automatically generates an agent card for you. If you're interested in learning more about how to expose your existing agent so others can use it, then please look at the A2A Quickstart (Exposing) tutorial. ", "code_blocks": [{"language": "text", "code": "{\n  \"capabilities\": {},\n  \"defaultInputModes\": [\"text/plain\"],\n  \"defaultOutputModes\": [\"application/json\"],\n  \"description\": \"An agent specialized in checking whether numbers are prime. It can efficiently determine the primality of individual numbers or lists of numbers.\",\n  \"name\": \"check_prime_agent\",\n  \"skills\": [\n    {\n      \"id\": \"prime_checking\",\n      \"name\": \"Prime Number Checking\",\n      \"description\": \"Check if numbers in a list are prime using efficient mathematical algorithms\",\n      \"tags\": [\"mathematical\", \"computation\", \"prime\", \"numbers\"]\n    }\n  ],\n  \"url\": \"http://localhost:8001/a2a/check_prime_agent\",\n  \"version\": \"1.0.0\"\n}"}]}, {"heading_path": ["4. Run the Main (Consuming) Agent\u00b6"], "text": "4. Run the Main (Consuming) Agent \u00b6 # In a separate terminal, run the adk web server adk web contributing/samples/ ", "code_blocks": [{"language": "text", "code": "# In a separate terminal, run the adk web server\nadk web contributing/samples/"}]}, {"heading_path": ["How it works\u00b6"], "text": "How it works \u00b6 The main agent uses the RemoteA2aAgent() function to consume the remote agent ( prime_agent in our example). As you can see below, RemoteA2aAgent() requires the name , description , and the URL of the agent_card . a2a_basic/agent.py <... code truncated ...> from google.adk.agents.remote_a2a_agent import AGENT_CARD_WELL_KNOWN_PATH from google.adk.agents.remote_a2a_agent import RemoteA2aAgent prime_agent = RemoteA2aAgent ( name = \"prime_agent\" , description = \"Agent that handles checking if numbers are prime.\" , agent_card = ( f \"http://localhost:8001/a2a/check_prime_agent { AGENT_CARD_WELL_KNOWN_PATH } \" ), ) <... code truncated > Then, you can simply use the RemoteA2aAgent in your agent. In this case, prime_agent is used as one of the sub-agents in the root_agent below: a2a_basic/agent.py from google.adk.agents.llm_agent import Agent from google.genai import types root_agent = Agent ( model = \"gemini-2.0-flash\" , name = \"root_agent\" , instruction = \"\"\" <You are a helpful assistant that can roll dice and check if numbers are prime. You delegate rolling dice tasks to the roll_agent and prime checking tasks to the prime_agent. Follow these steps: 1. If the user asks to roll a die, delegate to the roll_agent. 2. If the user asks to check primes, delegate to the prime_agent. 3. If the user asks to roll a die and then check if the result is prime, call roll_agent first, then pass the result to prime_agent. Always clarify the results before proceeding.> \"\"\" , global_instruction = ( \"You are DicePrimeBot, ready to roll dice and check prime numbers.\" ), sub_agents = [ roll_agent , prime_agent ], tools = [ example_tool ], generate_content_config = types . GenerateContentConfig ( safety_settings = [ types . SafetySetting ( # avoid false alarm about rolling dice. category = types . HarmCategory . HARM_CATEGORY_DANGEROUS_CONTENT , threshold = types . HarmBlockThreshold . OFF , ), ] ), ) ", "code_blocks": [{"language": "text", "code": "<...code truncated...>\n\nfrom google.adk.agents.remote_a2a_agent import AGENT_CARD_WELL_KNOWN_PATH\nfrom google.adk.agents.remote_a2a_agent import RemoteA2aAgent\n\nprime_agent = RemoteA2aAgent(\n    name=\"prime_agent\",\n    description=\"Agent that handles checking if numbers are prime.\",\n    agent_card=(\n        f\"http://localhost:8001/a2a/check_prime_agent{AGENT_CARD_WELL_KNOWN_PATH}\"\n    ),\n)\n\n<...code truncated>"}, {"language": "text", "code": "from google.adk.agents.llm_agent import Agent\nfrom google.genai import types\n\nroot_agent = Agent(\n    model=\"gemini-2.0-flash\",\n    name=\"root_agent\",\n    instruction=\"\"\"\n      <You are a helpful assistant that can roll dice and check if numbers are prime.\n      You delegate rolling dice tasks to the roll_agent and prime checking tasks to the prime_agent.\n      Follow these steps:\n      1. If the user asks to roll a die, delegate to the roll_agent.\n      2. If the user asks to check primes, delegate to the prime_agent.\n      3. If the user asks to roll a die and then check if the result is prime, call roll_agent first, then pass the result to prime_agent.\n      Always clarify the results before proceeding.>\n    \"\"\",\n    global_instruction=(\n        \"You are DicePrimeBot, ready to roll dice and check prime numbers.\"\n    ),\n    sub_agents=[roll_agent, prime_agent],\n    tools=[example_tool],\n    generate_content_config=types.GenerateContentConfig(\n        safety_settings=[\n            types.SafetySetting(  # avoid false alarm about rolling dice.\n                category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n                threshold=types.HarmBlockThreshold.OFF,\n            ),\n        ]\n    ),\n)"}]}, {"heading_path": ["Example Interactions\u00b6"], "text": "Example Interactions \u00b6 Once both your main and remote agents are running, you can interact with the root agent to see how it calls the remote agent via A2A: Simple Dice Rolling: This interaction uses a local agent, the Roll Agent: User: Roll a 6-sided die Bot: I rolled a 4 for you. Prime Number Checking: This interaction uses a remote agent via A2A, the Prime Agent: User: Is 7 a prime number? Bot: Yes, 7 is a prime number. Combined Operations: This interaction uses both the local Roll Agent and the remote Prime Agent: User: Roll a 10-sided die and check if it's prime Bot: I rolled an 8 for you. Bot: 8 is not a prime number. ", "code_blocks": [{"language": "text", "code": "User: Roll a 6-sided die\nBot: I rolled a 4 for you."}, {"language": "text", "code": "User: Is 7 a prime number?\nBot: Yes, 7 is a prime number."}, {"language": "text", "code": "User: Roll a 10-sided die and check if it's prime\nBot: I rolled an 8 for you.\nBot: 8 is not a prime number."}]}, {"heading_path": ["Next Steps\u00b6"], "text": "Next Steps \u00b6 Now that you have created an agent that's using a remote agent via an A2A server, the next step is to learn how to connect to it from another agent. A2A Quickstart (Exposing) : Learn how to expose your existing agent so that other agents can use it via the A2A Protocol. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:43.871356", "source_type": "adk-docs"}
{"doc_id": "8707af329c31c8d03c7ba6d91abee5ce9e8ec8e96d8d2f47b47ab02ba18ede48", "url": "https://google.github.io/adk-docs/a2a/quickstart-consuming-go", "title": "Go - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Quickstart: Consuming a remote agent via A2A\u00b6"], "text": "Quickstart: Consuming a remote agent via A2A \u00b6 Supported in ADK Go Experimental This quickstart covers the most common starting point for any developer: \"There is a remote agent, how do I let my ADK agent use it via A2A?\" . This is crucial for building complex multi-agent systems where different agents need to collaborate and interact. ", "code_blocks": []}, {"heading_path": ["Overview\u00b6"], "text": "Overview \u00b6 This sample demonstrates the Agent-to-Agent (A2A) architecture in the Agent Development Kit (ADK), showcasing how multiple agents can work together to handle complex tasks. The sample implements an agent that can roll dice and check if numbers are prime. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   Root Agent    \u2502\u2500\u2500\u2500\u25b6\u2502   Roll Agent     \u2502    \u2502   Remote Prime     \u2502 \u2502  (Local)        \u2502    \u2502   (Local)        \u2502    \u2502   Agent            \u2502 \u2502                 \u2502    \u2502                  \u2502    \u2502  (localhost:8001)  \u2502 \u2502                 \u2502\u2500\u2500\u2500\u25b6\u2502                  \u2502\u25c0\u2500\u2500\u2500\u2502                    \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The A2A Basic sample consists of: Root Agent ( root_agent ): The main orchestrator that delegates tasks to specialized sub-agents Roll Agent ( roll_agent ): A local sub-agent that handles dice rolling operations Prime Agent ( prime_agent ): A remote A2A agent that checks if numbers are prime, this agent is running on a separate A2A server ", "code_blocks": [{"language": "text", "code": "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Root Agent    \u2502\u2500\u2500\u2500\u25b6\u2502   Roll Agent     \u2502    \u2502   Remote Prime     \u2502\n\u2502  (Local)        \u2502    \u2502   (Local)        \u2502    \u2502   Agent            \u2502\n\u2502                 \u2502    \u2502                  \u2502    \u2502  (localhost:8001)  \u2502\n\u2502                 \u2502\u2500\u2500\u2500\u25b6\u2502                  \u2502\u25c0\u2500\u2500\u2500\u2502                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518"}]}, {"heading_path": ["Exposing Your Agent with the ADK Server\u00b6"], "text": "Exposing Your Agent with the ADK Server \u00b6 In the a2a_basic example, you will first need to expose the check_prime_agent via an A2A server, so that the local root agent can use it. ", "code_blocks": []}, {"heading_path": ["1. Getting the Sample Code\u00b6"], "text": "1. Getting the Sample Code \u00b6 First, make sure you have Go installed and your environment is set up. You can clone and navigate to the a2a_basic sample here: cd examples/go/a2a_basic As you'll see, the folder structure is as follows: a2a_basic/ \u251c\u2500\u2500 remote_a2a/ \u2502   \u2514\u2500\u2500 check_prime_agent/ \u2502       \u2514\u2500\u2500 main.go \u251c\u2500\u2500 go.mod \u251c\u2500\u2500 go.sum \u2514\u2500\u2500 main.go # local root agent ", "code_blocks": [{"language": "text", "code": "cd examples/go/a2a_basic"}, {"language": "text", "code": "a2a_basic/\n\u251c\u2500\u2500 remote_a2a/\n\u2502   \u2514\u2500\u2500 check_prime_agent/\n\u2502       \u2514\u2500\u2500 main.go\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 go.sum\n\u2514\u2500\u2500 main.go # local root agent"}]}, {"heading_path": ["Main Agent (a2a_basic/main.go)\u00b6"], "text": "Main Agent ( a2a_basic/main.go ) \u00b6 rollDieTool : Function tool for rolling dice newRollAgent : Local agent specialized in dice rolling newPrimeAgent : Remote A2A agent configuration newRootAgent : Main orchestrator with delegation logic ", "code_blocks": []}, {"heading_path": ["Remote Prime Agent (a2a_basic/remote_a2a/check_prime_agent/main.go)\u00b6"], "text": "Remote Prime Agent ( a2a_basic/remote_a2a/check_prime_agent/main.go ) \u00b6 checkPrimeTool : Prime number checking algorithm main : Implementation of the prime checking service and A2A server. ", "code_blocks": []}, {"heading_path": ["2. Start the Remote Prime Agent server\u00b6"], "text": "2. Start the Remote Prime Agent server \u00b6 To show how your ADK agent can consume a remote agent via A2A, you'll first need to start a remote agent server, which will host the prime agent (under check_prime_agent ). # Start the remote a2a server that serves the check_prime_agent on port 8001 go run remote_a2a/check_prime_agent/main.go Once executed, you should see something like: 2025 /11/06 11 :00:19 Starting A2A prime checker server on port 8001 2025 /11/06 11 :00:19 Starting the web server: & { port:8001 } 2025 /11/06 11 :00:19 2025 /11/06 11 :00:19 Web servers starts on http://localhost:8001 2025 /11/06 11 :00:19 a2a: you can access A2A using jsonrpc protocol: http://localhost:8001 ", "code_blocks": [{"language": "text", "code": "# Start the remote a2a server that serves the check_prime_agent on port 8001\ngo run remote_a2a/check_prime_agent/main.go"}, {"language": "text", "code": "2025/11/06 11:00:19 Starting A2A prime checker server on port 8001\n2025/11/06 11:00:19 Starting the web server: &{port:8001}\n2025/11/06 11:00:19 \n2025/11/06 11:00:19 Web servers starts on http://localhost:8001\n2025/11/06 11:00:19        a2a:  you can access A2A using jsonrpc protocol: http://localhost:8001"}]}, {"heading_path": ["3. Look out for the required agent card of the remote agent\u00b6"], "text": "3. Look out for the required agent card of the remote agent \u00b6 A2A Protocol requires that each agent must have an agent card that describes what it does. In the Go ADK, the agent card is generated dynamically when you expose an agent using the A2A launcher. You can visit http://localhost:8001/.well-known/agent-card.json to see the generated card. ", "code_blocks": []}, {"heading_path": ["4. Run the Main (Consuming) Agent\u00b6"], "text": "4. Run the Main (Consuming) Agent \u00b6 # In a separate terminal, run the main agent go run main.go ", "code_blocks": [{"language": "text", "code": "# In a separate terminal, run the main agent\ngo run main.go"}]}, {"heading_path": ["How it works\u00b6"], "text": "How it works \u00b6 The main agent uses remoteagent.New to consume the remote agent ( prime_agent in our example). As you can see below, it requires the Name , Description , and the AgentCardSource URL. a2a_basic/main.go func newPrimeAgent () ( agent . Agent , error ) { remoteAgent , err := remoteagent . New ( remoteagent . A2AConfig { Name : \"prime_agent\" , Description : \"Agent that handles checking if numbers are prime.\" , AgentCardSource : \"http://localhost:8001\" , }) if err != nil { return nil , fmt . Errorf ( \"failed to create remote prime agent: %w\" , err ) } return remoteAgent , nil } Then, you can simply use the remote agent in your root agent. In this case, primeAgent is used as one of the sub-agents in the root_agent below: a2a_basic/main.go func newRootAgent ( ctx context . Context , rollAgent , primeAgent agent . Agent ) ( agent . Agent , error ) { model , err := gemini . NewModel ( ctx , \"gemini-2.0-flash\" , & genai . ClientConfig {}) if err != nil { return nil , err } return llmagent . New ( llmagent . Config { Name : \"root_agent\" , Model : model , Instruction : ` You are a helpful assistant that can roll dice and check if numbers are prime. You delegate rolling dice tasks to the roll_agent and prime checking tasks to the prime_agent. Follow these steps: 1. If the user asks to roll a die, delegate to the roll_agent. 2. If the user asks to check primes, delegate to the prime_agent. 3. If the user asks to roll a die and then check if the result is prime, call roll_agent first, then pass the result to prime_agent. Always clarify the results before proceeding. ` , SubAgents : [] agent . Agent { rollAgent , primeAgent }, Tools : [] tool . Tool {}, }) } ", "code_blocks": [{"language": "text", "code": "func newPrimeAgent() (agent.Agent, error) {\n    remoteAgent, err := remoteagent.New(remoteagent.A2AConfig{\n        Name:            \"prime_agent\",\n        Description:     \"Agent that handles checking if numbers are prime.\",\n        AgentCardSource: \"http://localhost:8001\",\n    })\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create remote prime agent: %w\", err)\n    }\n    return remoteAgent, nil\n}"}, {"language": "text", "code": "func newRootAgent(ctx context.Context, rollAgent, primeAgent agent.Agent) (agent.Agent, error) {\n    model, err := gemini.NewModel(ctx, \"gemini-2.0-flash\", &genai.ClientConfig{})\n    if err != nil {\n        return nil, err\n    }\n    return llmagent.New(llmagent.Config{\n        Name:  \"root_agent\",\n        Model: model,\n        Instruction: `\n      You are a helpful assistant that can roll dice and check if numbers are prime.\n      You delegate rolling dice tasks to the roll_agent and prime checking tasks to the prime_agent.\n      Follow these steps:\n      1. If the user asks to roll a die, delegate to the roll_agent.\n      2. If the user asks to check primes, delegate to the prime_agent.\n      3. If the user asks to roll a die and then check if the result is prime, call roll_agent first, then pass the result to prime_agent.\n      Always clarify the results before proceeding.\n    `,\n        SubAgents: []agent.Agent{rollAgent, primeAgent},\n        Tools:     []tool.Tool{},\n    })\n}"}]}, {"heading_path": ["Example Interactions\u00b6"], "text": "Example Interactions \u00b6 Once both your main and remote agents are running, you can interact with the root agent to see how it calls the remote agent via A2A: Simple Dice Rolling: This interaction uses a local agent, the Roll Agent: User: Roll a 6-sided die Bot calls tool: transfer_to_agent with args: map[agent_name:roll_agent] Bot calls tool: roll_die with args: map[sides:6] Bot: I rolled a 6-sided die and the result is 6. Prime Number Checking: This interaction uses a remote agent via A2A, the Prime Agent: User: Is 7 a prime number? Bot calls tool: transfer_to_agent with args: map[agent_name:prime_agent] Bot calls tool: prime_checking with args: map[nums:[7]] Bot: Yes, 7 is a prime number. Combined Operations: This interaction uses both the local Roll Agent and the remote Prime Agent: User: roll a die and check if it's a prime Bot: Okay, I will first roll a die and then check if the result is a prime number. Bot calls tool: transfer_to_agent with args: map[agent_name:roll_agent] Bot calls tool: roll_die with args: map[sides:6] Bot calls tool: transfer_to_agent with args: map[agent_name:prime_agent] Bot calls tool: prime_checking with args: map[nums:[3]] Bot: 3 is a prime number. ", "code_blocks": [{"language": "text", "code": "User: Roll a 6-sided die\nBot calls tool: transfer_to_agent with args: map[agent_name:roll_agent]\nBot calls tool: roll_die with args: map[sides:6]\nBot: I rolled a 6-sided die and the result is 6."}, {"language": "text", "code": "User: Is 7 a prime number?\nBot calls tool: transfer_to_agent with args: map[agent_name:prime_agent]\nBot calls tool: prime_checking with args: map[nums:[7]]\nBot: Yes, 7 is a prime number."}, {"language": "text", "code": "User: roll a die and check if it's a prime\nBot: Okay, I will first roll a die and then check if the result is a prime number.\n\nBot calls tool: transfer_to_agent with args: map[agent_name:roll_agent]\nBot calls tool: roll_die with args: map[sides:6]\nBot calls tool: transfer_to_agent with args: map[agent_name:prime_agent]\nBot calls tool: prime_checking with args: map[nums:[3]]\nBot: 3 is a prime number."}]}, {"heading_path": ["Next Steps\u00b6"], "text": "Next Steps \u00b6 Now that you have created an agent that's using a remote agent via an A2A server, the next step is to learn how to expose your own agent. A2A Quickstart (Exposing) : Learn how to expose your existing agent so that other agents can use it via the A2A Protocol. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:44.475472", "source_type": "adk-docs"}
{"doc_id": "f4a1ede105b2c8d1faf4b9d4f69a9acfa2fee6d99ee0d988c1ceef3fba85ce69", "url": "https://google.github.io/adk-docs/streaming", "title": "Bidi-streaming (live) in ADK - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Bidi-streaming (live) in ADK\u00b6"], "text": "Bidi-streaming (live) in ADK \u00b6 Supported in ADK Python v0.5.0 Experimental Bidirectional (Bidi) streaming (live) in ADK adds the low-latency bidirectional voice and video interaction\ncapability of Gemini Live API to\nAI agents. Experimental preview release The Bidirectional (Bidi) streaming feature is experimental. With bidi-streaming, or live, mode, you can provide end users with the experience of natural,\nhuman-like voice conversations, including the ability for the user to interrupt\nthe agent's responses with voice commands. Agents with streaming can process\ntext, audio, and video inputs, and they can provide text and audio output. Info This is different from server-side streaming or token-level streaming. \nToken-level streaming is a one-way process where a language model generates a response and sends it back to the user one token at a time. This creates a \"typing\" effect, giving the impression of an immediate response and reducing the time it takes to see the start of the answer. The user sends their full prompt, the model processes it, and then the model begins to generate and send back the response piece by piece. This section is for bidi-streaming (live). Quickstart (Bidi-streaming) In this quickstart, you'll build a simple agent and use streaming in ADK to\nimplement low-latency and bidirectional voice and video communication. Quickstart (Bidi-streaming) Custom Audio Streaming app sample This article overviews the server and client code for a custom asynchronous web app built with ADK Streaming and FastAPI, enabling real-time, bidirectional audio and text communication with WebSockets. Custom Audio Streaming app sample (WebSockets) Bidi-streaming development guide series A series of articles for diving deeper into the Bidi-streaming development with ADK. You can learn basic concepts and use cases, the core API, and end-to-end application design. Bidi-streaming development guide series: Part 1 - Introduction Streaming Tools Streaming tools allows tools (functions) to stream intermediate results back to agents and agents can respond to those intermediate results. For example, we can use streaming tools to monitor the changes of the stock price and have the agent react to it. Another example is we can have the agent monitor the video stream, and when there is changes in video stream, the agent can report the changes. Streaming Tools Custom Audio Streaming app sample This article overviews the server and client code for a custom asynchronous web app built with ADK Streaming and FastAPI, enabling real-time, bidirectional audio and text communication with both Server Sent Events (SSE) and WebSockets. Streaming Configurations Blog post: Google ADK + Vertex AI Live API This article shows how to use Bidi-streaming (live) in ADK for real-time audio/video streaming. It offers a Python server example using LiveRequestQueue to build custom, interactive AI agents. Blog post: Google ADK + Vertex AI Live API Blog post: Supercharge ADK Development with Claude Code Skills This article demonstrates how to use Claude Code Skills to accelerate ADK development, with an example of building a Bidi-streaming chat app. Learn how to leverage AI-powered coding assistance to build better agents faster. Blog post: Supercharge ADK Development with Claude Code Skills Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:44.853644", "source_type": "adk-docs"}
{"doc_id": "72258b52c0cb92a8f5964a38683553c82478f694e79ddb5d995050a1b8adf6b5", "url": "https://google.github.io/adk-docs/streaming/custom-streaming-ws", "title": "Custom Audio Bidi-streaming app sample (WebSockets) - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Custom Audio Streaming Application (WebSocket)\u00b6"], "text": "Custom Audio Streaming Application (WebSocket) \u00b6 Supported in ADK Python v0.5.0 Experimental This article overviews the server and client code for a custom Bidi-streaming web application built with ADK Bidi-streaming and FastAPI , enabling real-time, bidirectional audio and text communication with WebSockets. Note: This guide assumes you have experience of JavaScript and Python asyncio programming. ", "code_blocks": []}, {"heading_path": ["Supported models for voice/video streaming\u00b6"], "text": "Supported models for voice/video streaming \u00b6 In order to use voice/video streaming in ADK, you will need to use Gemini models that support the Live API. You can find the model ID(s) that supports the Gemini Live API in the documentation: Google AI Studio: Gemini Live API Vertex AI: Gemini Live API ", "code_blocks": []}, {"heading_path": ["1. Install ADK\u00b6"], "text": "1. Install ADK \u00b6 Download the sample code: curl -L https://github.com/google/adk-docs/archive/refs/heads/main.tar.gz | \\ tar xz --strip = 5 adk-docs-main/examples/python/snippets/streaming/adk-streaming-ws cd adk-streaming-ws Create & Activate Virtual Environment (Recommended): # Create python -m venv .venv # Activate (each new terminal) # macOS/Linux: source .venv/bin/activate # Windows CMD: .venv\\Scripts\\activate.bat # Windows PowerShell: .venv\\Scripts\\Activate.ps1 Install ADK: pip install --upgrade google-adk == 1 .17.0 Set SSL_CERT_FILE variable with the following command. export SSL_CERT_FILE = $( python -m certifi ) Navigate to the app folder: cd app This sample code has the following files and folders: adk-streaming-ws/ \u2514\u2500\u2500 app/ # the web app folder \u251c\u2500\u2500 .env # Gemini API key / Google Cloud Project ID \u251c\u2500\u2500 main.py # FastAPI web app \u251c\u2500\u2500 static/ # Static content folder |   \u251c\u2500\u2500 js # JavaScript files folder (includes app.js) |   \u2514\u2500\u2500 index.html # The web client page \u2514\u2500\u2500 google_search_agent/ # Agent folder \u251c\u2500\u2500 __init__.py # Python package \u2514\u2500\u2500 agent.py # Agent definition ", "code_blocks": [{"language": "text", "code": "curl -L https://github.com/google/adk-docs/archive/refs/heads/main.tar.gz | \\\n  tar xz --strip=5 adk-docs-main/examples/python/snippets/streaming/adk-streaming-ws\n\ncd adk-streaming-ws"}, {"language": "text", "code": "# Create\npython -m venv .venv\n# Activate (each new terminal)\n# macOS/Linux: source .venv/bin/activate\n# Windows CMD: .venv\\Scripts\\activate.bat\n# Windows PowerShell: .venv\\Scripts\\Activate.ps1"}, {"language": "text", "code": "pip install --upgrade google-adk==1.17.0"}, {"language": "text", "code": "export SSL_CERT_FILE=$(python -m certifi)"}, {"language": "text", "code": "cd app"}, {"language": "text", "code": "adk-streaming-ws/\n\u2514\u2500\u2500 app/ # the web app folder\n    \u251c\u2500\u2500 .env # Gemini API key / Google Cloud Project ID\n    \u251c\u2500\u2500 main.py # FastAPI web app\n    \u251c\u2500\u2500 static/ # Static content folder\n    |   \u251c\u2500\u2500 js # JavaScript files folder (includes app.js)\n    |   \u2514\u2500\u2500 index.html # The web client page\n    \u2514\u2500\u2500 google_search_agent/ # Agent folder\n        \u251c\u2500\u2500 __init__.py # Python package\n        \u2514\u2500\u2500 agent.py # Agent definition"}]}, {"heading_path": ["2. Set up the platform\u00b6"], "text": "2. Set up the platform \u00b6 To run the sample app, choose a platform from either Google AI Studio or Google Cloud Vertex AI: Gemini - Google AI Studio Gemini - Google Cloud Vertex AI Get an API key from Google AI Studio . Open the .env file located inside ( app/ ) and copy-paste the following code. .env GOOGLE_GENAI_USE_VERTEXAI=FALSE GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE DEMO_AGENT_MODEL=gemini-2.5-flash-native-audio-preview-09-2025 #DEMO_AGENT_MODEL=gemini-2.0-flash-exp # if the model above doesn't work Replace PASTE_YOUR_ACTUAL_API_KEY_HERE with your actual API KEY . You need an existing Google Cloud account and a\n   project. Set up a Google Cloud project Set up the gcloud CLI Authenticate to Google Cloud, from the terminal by running gcloud auth login . Enable the Vertex AI API . Open the .env file located inside ( app/ ). Copy-paste\n   the following code and update the project ID and location. .env GOOGLE_GENAI_USE_VERTEXAI=TRUE GOOGLE_CLOUD_PROJECT=PASTE_YOUR_ACTUAL_PROJECT_ID GOOGLE_CLOUD_LOCATION=us-central1 DEMO_AGENT_MODEL=gemini-live-2.5-flash-preview-native-audio-09-2025 #DEMO_AGENT_MODEL=gemini-2.0-flash-exp # if the model above doesn't work ", "code_blocks": [{"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=FALSE\nGOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE\nDEMO_AGENT_MODEL=gemini-2.5-flash-native-audio-preview-09-2025\n#DEMO_AGENT_MODEL=gemini-2.0-flash-exp # if the model above doesn't work"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=TRUE\nGOOGLE_CLOUD_PROJECT=PASTE_YOUR_ACTUAL_PROJECT_ID\nGOOGLE_CLOUD_LOCATION=us-central1\nDEMO_AGENT_MODEL=gemini-live-2.5-flash-preview-native-audio-09-2025\n#DEMO_AGENT_MODEL=gemini-2.0-flash-exp # if the model above doesn't work"}]}, {"heading_path": ["agent.py\u00b6"], "text": "agent.py \u00b6 The agent definition code agent.py in the google_search_agent folder is where the agent's logic is written: import os from google.adk.agents import Agent from google.adk.tools import google_search # Import the tool root_agent = Agent ( name = \"google_search_agent\" , model = os . getenv ( \"DEMO_AGENT_MODEL\" ), description = \"Agent to answer questions using Google Search.\" , instruction = \"Answer the question using the Google Search tool.\" , tools = [ google_search ], ) Note: This application uses the Gemini Live API (also known as bidiGenerateContent ), which enables real-time bidirectional streaming for both text and audio/video input. The model must support the Live API for Bidi-streaming to work. Verify model capabilities by referring to: Gemini Live API - Supported Models Vertex AI Live API - Model Support The agent uses the model specified in the DEMO_AGENT_MODEL environment variable (from the .env file). Notice how easily you integrated grounding with Google Search capabilities.  The Agent class and the google_search tool handle the complex interactions with the LLM and grounding with the search API, allowing you to focus on the agent's purpose and behavior . ", "code_blocks": [{"language": "text", "code": "import os\nfrom google.adk.agents import Agent\nfrom google.adk.tools import google_search  # Import the tool\n\nroot_agent = Agent(\n   name=\"google_search_agent\",\n   model=os.getenv(\"DEMO_AGENT_MODEL\"),\n   description=\"Agent to answer questions using Google Search.\",\n   instruction=\"Answer the question using the Google Search tool.\",\n   tools=[google_search],\n)"}]}, {"heading_path": ["3. Interact with Your Streaming Application\u00b6"], "text": "3. Interact with Your Streaming Application \u00b6 Navigate to the Correct Directory: To run your agent effectively, make sure you are in the app folder ( adk-streaming-ws/app ) Start the Fast API : Run the following command to start CLI interface with uvicorn main:app --reload Access the app with the text mode: Once the app starts, the terminal will display a local URL (e.g., http://localhost:8000 ). Click this link to open the UI in your browser. Now you should see the UI like this: Try asking a question What time is it now? . The agent will use Google Search to respond to your queries. You would notice that the UI shows the agent's response as streaming text. You can also send messages to the agent at any time, even while the agent is still responding. This demonstrates the bidirectional communication capability of ADK Streaming. Access the app with the audio mode: Now click the Start Audio button. The app reconnects with the server in an audio mode, and the UI will show the following dialog for the first time: Click Allow while visiting the site , then you will see the microphone icon will be shown at the top of the browser: Now you can talk to the agent with voice. Ask questions like What time is it now? with voice and you will hear the agent responding in voice too. As Streaming for ADK supports multiple languages , it can also respond to question in the supported languages. Check console logs If you are using the Chrome browser, use the right click and select Inspect to open the DevTools. On the Console , you can see the incoming and outgoing audio data such as [CLIENT TO AGENT] and [AGENT TO CLIENT] , representing the audio data streaming in and out between the browser and the server. At the same time, in the app server console, you should see something like this: INFO:     ('127.0.0.1', 50068) - \"WebSocket /ws/70070018?is_audio=true\" [accepted] Client #70070018 connected, audio mode: true INFO:     connection open INFO:     127.0.0.1:50061 - \"GET /static/js/pcm-player-processor.js HTTP/1.1\" 200 OK INFO:     127.0.0.1:50060 - \"GET /static/js/pcm-recorder-processor.js HTTP/1.1\" 200 OK [AGENT TO CLIENT]: audio/pcm: 9600 bytes. INFO:     127.0.0.1:50082 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found [AGENT TO CLIENT]: audio/pcm: 11520 bytes. [AGENT TO CLIENT]: audio/pcm: 11520 bytes. These console logs are important in case you develop your own streaming application. In many cases, the communication failure between the browser and server becomes a major cause for the streaming application bugs. Troubleshooting tips When ws:// doesn't work: If you see any errors on the Chrome DevTools with regard to ws:// connection, try replacing ws:// with wss:// on app/static/js/app.js at line 28. This may happen when you are running the sample on a cloud environment and using a proxy connection to connect from your browser. When the model doesn't work: If you see any errors on the app server console with regard to model availability, try using the alternative model by uncommenting the #DEMO_AGENT_MODEL=gemini-2.0-flash-exp line in your .env file and commenting out the current DEMO_AGENT_MODEL line. ", "code_blocks": [{"language": "text", "code": "uvicorn main:app --reload"}, {"language": "text", "code": "INFO:     ('127.0.0.1', 50068) - \"WebSocket /ws/70070018?is_audio=true\" [accepted]\nClient #70070018 connected, audio mode: true\nINFO:     connection open\nINFO:     127.0.0.1:50061 - \"GET /static/js/pcm-player-processor.js HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:50060 - \"GET /static/js/pcm-recorder-processor.js HTTP/1.1\" 200 OK\n[AGENT TO CLIENT]: audio/pcm: 9600 bytes.\nINFO:     127.0.0.1:50082 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n[AGENT TO CLIENT]: audio/pcm: 11520 bytes.\n[AGENT TO CLIENT]: audio/pcm: 11520 bytes."}]}, {"heading_path": ["4. Server code overview\u00b6"], "text": "4. Server code overview \u00b6 This server application enables real-time, streaming interaction with an ADK agent via WebSockets. Clients send text/audio to the ADK agent and receive streamed text/audio responses. Core functions:\n1.  Initialize/manage ADK agent sessions.\n2.  Handle client WebSocket connections.\n3.  Relay client messages to the ADK agent.\n4.  Stream ADK agent responses (text/audio) to clients. ", "code_blocks": []}, {"heading_path": ["Architecture Overview\u00b6"], "text": "Architecture Overview \u00b6 The following diagram illustrates how components interact in this streaming application: sequenceDiagram\n    participant Browser\n    participant FastAPI\n    participant ADK Runner\n    participant Gemini Live API\n\n    Note over Browser,Gemini Live API: Connection Establishment\n    Browser->>FastAPI: WebSocket Connect\n    FastAPI->>ADK Runner: start_agent_session()\n    ADK Runner->>Gemini Live API: Establish Live Session\n    Gemini Live API-->>ADK Runner: Session Ready\n\n    Note over Browser,Gemini Live API: Bidirectional Communication\n    Browser->>FastAPI: Send Text/Audio Message\n    FastAPI->>ADK Runner: send_content() / send_realtime()\n    ADK Runner->>Gemini Live API: Forward to Model\n    Gemini Live API-->>ADK Runner: Stream Response (live_events)\n    ADK Runner-->>FastAPI: Process Events\n    FastAPI-->>Browser: Send Response (Text/Audio)\n\n    Note over Browser,Gemini Live API: Continuous Streaming\n    loop Until Disconnection\n        Browser->>FastAPI: Additional Messages\n        FastAPI->>ADK Runner: Process Input\n        ADK Runner->>Gemini Live API: Forward\n        Gemini Live API-->>Browser: Streamed Responses\n    end Key Components: - Browser: WebSocket client that sends/receives text and audio data\n- FastAPI: Server handling WebSocket connections and routing messages\n- ADK Runner: Manages agent sessions and coordinates with Gemini Live API\n- Gemini Live API: Processes requests and streams responses (text/audio) ", "code_blocks": [{"language": "text", "code": "sequenceDiagram\n    participant Browser\n    participant FastAPI\n    participant ADK Runner\n    participant Gemini Live API\n\n    Note over Browser,Gemini Live API: Connection Establishment\n    Browser->>FastAPI: WebSocket Connect\n    FastAPI->>ADK Runner: start_agent_session()\n    ADK Runner->>Gemini Live API: Establish Live Session\n    Gemini Live API-->>ADK Runner: Session Ready\n\n    Note over Browser,Gemini Live API: Bidirectional Communication\n    Browser->>FastAPI: Send Text/Audio Message\n    FastAPI->>ADK Runner: send_content() / send_realtime()\n    ADK Runner->>Gemini Live API: Forward to Model\n    Gemini Live API-->>ADK Runner: Stream Response (live_events)\n    ADK Runner-->>FastAPI: Process Events\n    FastAPI-->>Browser: Send Response (Text/Audio)\n\n    Note over Browser,Gemini Live API: Continuous Streaming\n    loop Until Disconnection\n        Browser->>FastAPI: Additional Messages\n        FastAPI->>ADK Runner: Process Input\n        ADK Runner->>Gemini Live API: Forward\n        Gemini Live API-->>Browser: Streamed Responses\n    end"}]}, {"heading_path": ["ADK Streaming Setup\u00b6"], "text": "ADK Streaming Setup \u00b6 import os import json import asyncio import base64 import warnings from pathlib import Path from dotenv import load_dotenv # Load environment variables BEFORE importing the agent load_dotenv () from google.genai import types from google.genai.types import ( Part , Content , Blob , ) from google.adk.runners import Runner from google.adk.agents import LiveRequestQueue from google.adk.agents.run_config import RunConfig , StreamingMode from google.adk.sessions.in_memory_session_service import InMemorySessionService from fastapi import FastAPI , WebSocket from fastapi.staticfiles import StaticFiles from fastapi.responses import FileResponse from fastapi.websockets import WebSocketDisconnect from google_search_agent.agent import root_agent warnings . filterwarnings ( \"ignore\" , category = UserWarning , module = \"pydantic\" ) Imports: Includes standard Python libraries ( os , json , asyncio , base64 , warnings ), dotenv for environment variables, Google ADK ( types , Part , Content , Blob , Runner , LiveRequestQueue , RunConfig , StreamingMode , InMemorySessionService ), and FastAPI ( FastAPI , WebSocket , StaticFiles , FileResponse , WebSocketDisconnect ). load_dotenv() : Called immediately after importing dotenv and before importing the agent. This ensures environment variables (like DEMO_AGENT_MODEL ) are available when the agent module initializes. warnings.filterwarnings() : Suppresses Pydantic UserWarnings to reduce console noise during development. Initialization: # # ADK Streaming # # Application configuration APP_NAME = \"adk-streaming-ws\" # Initialize session service session_service = InMemorySessionService () # APP_NAME and session_service are defined in the Initialization section above runner = Runner ( app_name = APP_NAME , agent = root_agent , session_service = session_service , ) APP_NAME : Application identifier for ADK. session_service = InMemorySessionService() : Initializes an in-memory ADK session service, suitable for single-instance or development use. Production might use a persistent store. runner = Runner(...) : Creates the Runner instance once at module level (production-ready pattern). This reuses the same runner for all connections, improving performance and resource utilization. ", "code_blocks": [{"language": "text", "code": "import os\nimport json\nimport asyncio\nimport base64\nimport warnings\n\nfrom pathlib import Path\nfrom dotenv import load_dotenv\n\n# Load environment variables BEFORE importing the agent\nload_dotenv()\n\nfrom google.genai import types\nfrom google.genai.types import (\n    Part,\n    Content,\n    Blob,\n)\n\nfrom google.adk.runners import Runner\nfrom google.adk.agents import LiveRequestQueue\nfrom google.adk.agents.run_config import RunConfig, StreamingMode\nfrom google.adk.sessions.in_memory_session_service import InMemorySessionService\n\nfrom fastapi import FastAPI, WebSocket\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import FileResponse\nfrom fastapi.websockets import WebSocketDisconnect\n\nfrom google_search_agent.agent import root_agent\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydantic\")"}, {"language": "text", "code": "#\n# ADK Streaming\n#\n\n# Application configuration\nAPP_NAME = \"adk-streaming-ws\"\n\n# Initialize session service\nsession_service = InMemorySessionService()\n\n# APP_NAME and session_service are defined in the Initialization section above\nrunner = Runner(\n    app_name=APP_NAME,\n    agent=root_agent,\n    session_service=session_service,\n)"}]}, {"heading_path": ["start_agent_session(user_id, is_audio=False)\u00b6"], "text": "start_agent_session(user_id, is_audio=False) \u00b6 async def start_agent_session ( user_id , is_audio = False ): \"\"\"Starts an agent session\"\"\" # Get or create session (recommended pattern for production) session_id = f \" { APP_NAME } _ { user_id } \" session = await runner . session_service . get_session ( app_name = APP_NAME , user_id = user_id , session_id = session_id , ) if not session : session = await runner . session_service . create_session ( app_name = APP_NAME , user_id = user_id , session_id = session_id , ) # Configure response format based on client preference # IMPORTANT: You must choose exactly ONE modality per session # Either [\"TEXT\"] for text responses OR [\"AUDIO\"] for voice responses # You cannot use both modalities simultaneously in the same session # Force AUDIO modality for native audio models regardless of client preference model_name = root_agent . model if isinstance ( root_agent . model , str ) else root_agent . model . model is_native_audio = \"native-audio\" in model_name . lower () modality = \"AUDIO\" if ( is_audio or is_native_audio ) else \"TEXT\" # Enable session resumption for improved reliability # For audio mode, enable output transcription to get text for UI display run_config = RunConfig ( streaming_mode = StreamingMode . BIDI , response_modalities = [ modality ], session_resumption = types . SessionResumptionConfig (), output_audio_transcription = types . AudioTranscriptionConfig () if ( is_audio or is_native_audio ) else None , ) # Create LiveRequestQueue in async context (recommended best practice) # This ensures the queue uses the correct event loop live_request_queue = LiveRequestQueue () # Start streaming session - returns async iterator for agent responses live_events = runner . run_live ( user_id = user_id , session_id = session . id , live_request_queue = live_request_queue , run_config = run_config , ) return live_events , live_request_queue This function initializes an ADK agent live session. It uses APP_NAME and session_service which are defined in the Initialization section above. Parameter Type Description user_id str Unique client identifier. is_audio bool True for audio responses, False for text (default). Key Steps: 1. Get or Create Session: Attempts to retrieve an existing session, or creates a new one if it doesn't exist. This pattern supports session persistence and resumption.\n2. Detect Native Audio Models: Checks if the agent's model name contains \"native-audio\" to automatically force AUDIO modality for native audio models.\n3. Configure Response Modality: Sets modality to \"AUDIO\" if either is_audio=True or the model is a native audio model, otherwise \"TEXT\". Note: You must choose exactly ONE modality per session.\n4. Enable Session Resumption: Configures session_resumption=types.SessionResumptionConfig() for improved reliability during network interruptions.\n5. Enable Output Transcription (Audio Mode): When using audio mode or native audio models, enables output_audio_transcription to get text representation of audio responses for UI display.\n6. Create LiveRequestQueue: Creates a queue in async context (best practice) for sending client inputs to the agent.\n7. Start Agent Session: Calls runner.run_live(...) to start the streaming session, returning live_events (async iterator for agent responses) and the live_request_queue . Returns: (live_events, live_request_queue) . ", "code_blocks": [{"language": "text", "code": "async def start_agent_session(user_id, is_audio=False):\n    \"\"\"Starts an agent session\"\"\"\n\n    # Get or create session (recommended pattern for production)\n    session_id = f\"{APP_NAME}_{user_id}\"\n    session = await runner.session_service.get_session(\n        app_name=APP_NAME,\n        user_id=user_id,\n        session_id=session_id,\n    )\n    if not session:\n        session = await runner.session_service.create_session(\n            app_name=APP_NAME,\n            user_id=user_id,\n            session_id=session_id,\n        )\n\n    # Configure response format based on client preference\n    # IMPORTANT: You must choose exactly ONE modality per session\n    # Either [\"TEXT\"] for text responses OR [\"AUDIO\"] for voice responses\n    # You cannot use both modalities simultaneously in the same session\n\n    # Force AUDIO modality for native audio models regardless of client preference\n    model_name = root_agent.model if isinstance(root_agent.model, str) else root_agent.model.model\n    is_native_audio = \"native-audio\" in model_name.lower()\n\n    modality = \"AUDIO\" if (is_audio or is_native_audio) else \"TEXT\"\n\n    # Enable session resumption for improved reliability\n    # For audio mode, enable output transcription to get text for UI display\n    run_config = RunConfig(\n        streaming_mode=StreamingMode.BIDI,\n        response_modalities=[modality],\n        session_resumption=types.SessionResumptionConfig(),\n        output_audio_transcription=types.AudioTranscriptionConfig() if (is_audio or is_native_audio) else None,\n    )\n\n    # Create LiveRequestQueue in async context (recommended best practice)\n    # This ensures the queue uses the correct event loop\n    live_request_queue = LiveRequestQueue()\n\n    # Start streaming session - returns async iterator for agent responses\n    live_events = runner.run_live(\n        user_id=user_id,\n        session_id=session.id,\n        live_request_queue=live_request_queue,\n        run_config=run_config,\n    )\n    return live_events, live_request_queue"}]}, {"heading_path": ["Output Audio Transcription\u00b6"], "text": "Output Audio Transcription \u00b6 When using audio mode ( is_audio=True ) or native audio models ( is_native_audio=True ), the application enables output audio transcription through RunConfig : output_audio_transcription = types . AudioTranscriptionConfig () if ( is_audio or is_native_audio ) else None , Audio Transcription Features: Native Audio Model Support - Works with models that have native audio output capability Text Representation - Provides text transcription of audio responses for UI display Dual Output - Enables both audio playback and text visualization simultaneously Enhanced Accessibility - Allows users to see what the agent is saying while hearing it Use Cases: Display audio responses as text in the UI for better user experience Enable accessibility features for users who prefer text Support debugging by logging what the agent says Create conversation transcripts alongside audio Note: This feature requires models that support output audio transcription. Not all Live API models may support this capability. ", "code_blocks": [{"language": "text", "code": "output_audio_transcription=types.AudioTranscriptionConfig() if (is_audio or is_native_audio) else None,"}]}, {"heading_path": ["Session Resumption Configuration\u00b6"], "text": "Session Resumption Configuration \u00b6 ADK supports live session resumption to improve reliability during streaming conversations. This feature enables automatic reconnection when live connections are interrupted due to network issues. This sample application enables session resumption by default in the RunConfig : run_config = RunConfig ( streaming_mode = StreamingMode . BIDI , response_modalities = [ modality ], session_resumption = types . SessionResumptionConfig () ) ", "code_blocks": [{"language": "text", "code": "run_config = RunConfig(\n    streaming_mode=StreamingMode.BIDI,\n    response_modalities=[modality],\n    session_resumption=types.SessionResumptionConfig()\n)"}]}, {"heading_path": ["Session Resumption Features\u00b6"], "text": "Session Resumption Features \u00b6 Automatic Handle Caching - The system automatically caches session resumption handles during live conversations Transparent Reconnection - When connections are interrupted, the system attempts to resume using cached handles Context Preservation - Conversation context and state are maintained across reconnections Network Resilience - Provides better user experience during unstable network conditions ", "code_blocks": []}, {"heading_path": ["Implementation Notes\u00b6"], "text": "Implementation Notes \u00b6 Session resumption handles are managed internally by the ADK framework No additional client-side code changes are required The feature is particularly beneficial for long-running streaming conversations Connection interruptions become less disruptive to the user experience ", "code_blocks": []}, {"heading_path": ["Disabling Session Resumption (Optional)\u00b6"], "text": "Disabling Session Resumption (Optional) \u00b6 If you encounter errors with session resumption or want to disable it: Check model compatibility - Ensure you're using a model that supports session resumption API limitations - Some session resumption features may not be available in all API versions Disable session resumption - You can disable session resumption by removing the session_resumption parameter from RunConfig : # Disable session resumption run_config = RunConfig ( streaming_mode = StreamingMode . BIDI , response_modalities = [ modality ] ) Now that we've covered session initialization and optional enhancements, let's explore the core messaging functions that handle bidirectional communication between the client and the ADK agent. ", "code_blocks": [{"language": "text", "code": "# Disable session resumption\nrun_config = RunConfig(\n    streaming_mode=StreamingMode.BIDI,\n    response_modalities=[modality]\n)"}]}, {"heading_path": ["agent_to_client_messaging(websocket, live_events)\u00b6"], "text": "agent_to_client_messaging(websocket, live_events) \u00b6 async def agent_to_client_messaging ( websocket , live_events ): \"\"\"Agent to client communication\"\"\" try : async for event in live_events : # Handle output audio transcription for native audio models # This provides text representation of audio output for UI display if event . output_transcription and event . output_transcription . text : transcript_text = event . output_transcription . text message = { \"mime_type\" : \"text/plain\" , \"data\" : transcript_text , \"is_transcript\" : True } await websocket . send_text ( json . dumps ( message )) print ( f \"[AGENT TO CLIENT]: audio transcript: { transcript_text } \" ) # Continue to process audio data if present # Don't return here as we may want to send both transcript and audio # Read the Content and its first Part part : Part = ( event . content and event . content . parts and event . content . parts [ 0 ] ) if part : # Audio data must be Base64-encoded for JSON transport is_audio = part . inline_data and part . inline_data . mime_type . startswith ( \"audio/pcm\" ) if is_audio : audio_data = part . inline_data and part . inline_data . data if audio_data : message = { \"mime_type\" : \"audio/pcm\" , \"data\" : base64 . b64encode ( audio_data ) . decode ( \"ascii\" ) } await websocket . send_text ( json . dumps ( message )) print ( f \"[AGENT TO CLIENT]: audio/pcm: { len ( audio_data ) } bytes.\" ) # If it's text and a partial text, send it (for cascade audio models or text mode) if part . text and event . partial : message = { \"mime_type\" : \"text/plain\" , \"data\" : part . text } await websocket . send_text ( json . dumps ( message )) print ( f \"[AGENT TO CLIENT]: text/plain: { message } \" ) # If the turn complete or interrupted, send it if event . turn_complete or event . interrupted : message = { \"turn_complete\" : event . turn_complete , \"interrupted\" : event . interrupted , } await websocket . send_text ( json . dumps ( message )) print ( f \"[AGENT TO CLIENT]: { message } \" ) except WebSocketDisconnect : print ( \"Client disconnected from agent_to_client_messaging\" ) except Exception as e : print ( f \"Error in agent_to_client_messaging: { e } \" ) This asynchronous function streams ADK agent events to the WebSocket client. Logic: 1.  Iterates through live_events from the agent.\n2. Audio Transcription (Native Audio Models): If the event contains output audio transcription text, sends it to the client with an is_transcript flag: { \"mime_type\": \"text/plain\", \"data\": \"<transcript_text>\", \"is_transcript\": True } . This enables displaying the audio content as text in the UI.\n3. Content Processing: *   Extracts the first Part from event content (if it exists).\n    * Audio Data: If audio (PCM), Base64 encodes and sends it as JSON: { \"mime_type\": \"audio/pcm\", \"data\": \"<base64_audio>\" } .\n    * Text Data (Cascade Audio Models or Text Mode): If partial text, sends it as JSON: { \"mime_type\": \"text/plain\", \"data\": \"<partial_text>\" } .\n4. Turn Completion/Interruption: Sends status flags to the client at the end of each event (see explanation below).\n5.  Logs messages. Understanding Turn Completion and Interruption Events: These events are critical for managing bidirectional streaming conversations: turn_complete : Signals that the agent has finished generating a complete response. This event: Marks the end of the agent's response turn Allows the UI to prepare for the next conversation turn Helps manage conversation state and flow In the UI: Resets currentMessageId to null so the next agent response creates a new message element interrupted : Signals that the agent's response was interrupted (e.g., when the user starts speaking during the agent's audio response). This event: Indicates the current agent turn was cut short Enables natural conversation flow where users can interrupt the agent In the UI: Stops audio playback immediately by sending { command: \"endOfAudio\" } to the audio player worklet Prevents the agent from continuing to speak while the user is talking Both events are handled silently in the UI without visual indicators, prioritizing a seamless conversational experience. ", "code_blocks": [{"language": "text", "code": "async def agent_to_client_messaging(websocket, live_events):\n    \"\"\"Agent to client communication\"\"\"\n    try:\n        async for event in live_events:\n\n            # Handle output audio transcription for native audio models\n            # This provides text representation of audio output for UI display\n            if event.output_transcription and event.output_transcription.text:\n                transcript_text = event.output_transcription.text\n                message = {\n                    \"mime_type\": \"text/plain\",\n                    \"data\": transcript_text,\n                    \"is_transcript\": True\n                }\n                await websocket.send_text(json.dumps(message))\n                print(f\"[AGENT TO CLIENT]: audio transcript: {transcript_text}\")\n                # Continue to process audio data if present\n                # Don't return here as we may want to send both transcript and audio\n\n            # Read the Content and its first Part\n            part: Part = (\n                event.content and event.content.parts and event.content.parts[0]\n            )\n            if part:\n                # Audio data must be Base64-encoded for JSON transport\n                is_audio = part.inline_data and part.inline_data.mime_type.startswith(\"audio/pcm\")\n                if is_audio:\n                    audio_data = part.inline_data and part.inline_data.data\n                    if audio_data:\n                        message = {\n                            \"mime_type\": \"audio/pcm\",\n                            \"data\": base64.b64encode(audio_data).decode(\"ascii\")\n                        }\n                        await websocket.send_text(json.dumps(message))\n                        print(f\"[AGENT TO CLIENT]: audio/pcm: {len(audio_data)} bytes.\")\n\n                # If it's text and a partial text, send it (for cascade audio models or text mode)\n                if part.text and event.partial:\n                    message = {\n                        \"mime_type\": \"text/plain\",\n                        \"data\": part.text\n                    }\n                    await websocket.send_text(json.dumps(message))\n                    print(f\"[AGENT TO CLIENT]: text/plain: {message}\")\n\n            # If the turn complete or interrupted, send it\n            if event.turn_complete or event.interrupted:\n                message = {\n                    \"turn_complete\": event.turn_complete,\n                    \"interrupted\": event.interrupted,\n                }\n                await websocket.send_text(json.dumps(message))\n                print(f\"[AGENT TO CLIENT]: {message}\")\n    except WebSocketDisconnect:\n        print(\"Client disconnected from agent_to_client_messaging\")\n    except Exception as e:\n        print(f\"Error in agent_to_client_messaging: {e}\")"}]}, {"heading_path": ["client_to_agent_messaging(websocket, live_request_queue)\u00b6"], "text": "client_to_agent_messaging(websocket, live_request_queue) \u00b6 async def client_to_agent_messaging ( websocket , live_request_queue ): \"\"\"Client to agent communication\"\"\" try : while True : message_json = await websocket . receive_text () message = json . loads ( message_json ) mime_type = message [ \"mime_type\" ] data = message [ \"data\" ] if mime_type == \"text/plain\" : # send_content() sends text in \"turn-by-turn mode\" # This signals a complete turn to the model, triggering immediate response content = Content ( role = \"user\" , parts = [ Part . from_text ( text = data )]) live_request_queue . send_content ( content = content ) print ( f \"[CLIENT TO AGENT]: { data } \" ) elif mime_type == \"audio/pcm\" : # send_realtime() sends audio in \"realtime mode\" # Data flows continuously without turn boundaries, enabling natural conversation # Audio is Base64-encoded for JSON transport, decode before sending decoded_data = base64 . b64decode ( data ) live_request_queue . send_realtime ( Blob ( data = decoded_data , mime_type = mime_type )) else : raise ValueError ( f \"Mime type not supported: { mime_type } \" ) except WebSocketDisconnect : print ( \"Client disconnected from client_to_agent_messaging\" ) except Exception as e : print ( f \"Error in client_to_agent_messaging: { e } \" ) This asynchronous function relays messages from the WebSocket client to the ADK agent. Logic: 1.  Receives and parses JSON messages from the WebSocket, expecting: { \"mime_type\": \"text/plain\" | \"audio/pcm\", \"data\": \"<data>\" } .\n2. Text Input: For \"text/plain\", sends Content to agent via live_request_queue.send_content() .\n3. Audio Input: For \"audio/pcm\", decodes Base64 data, wraps in Blob , and sends via live_request_queue.send_realtime() .\n4.  Raises ValueError for unsupported MIME types.\n5.  Logs messages. Error Handling: Both agent_to_client_messaging and client_to_agent_messaging functions include try-except blocks to handle WebSocket disconnections gracefully: WebSocketDisconnect : Catches when the client disconnects unexpectedly and logs the disconnection without raising an error Generic Exception : Catches any other errors (JSON parsing, Base64 decoding, etc.) and logs them for debugging This error handling ensures:\n- Clean shutdown when clients disconnect\n- Proper logging for debugging connection issues\n- The WebSocket connection closes gracefully without propagating unhandled exceptions\n- The FIRST_EXCEPTION condition in asyncio.wait() can still trigger for cleanup For production environments, consider additional error handling:\n- Send error messages back to the client to inform them of invalid input (before the connection closes)\n- Implement retry logic for transient failures\n- Add monitoring and alerting for error patterns\n- Validate message structure before processing to provide better error messages ", "code_blocks": [{"language": "text", "code": "async def client_to_agent_messaging(websocket, live_request_queue):\n    \"\"\"Client to agent communication\"\"\"\n    try:\n        while True:\n            message_json = await websocket.receive_text()\n            message = json.loads(message_json)\n            mime_type = message[\"mime_type\"]\n            data = message[\"data\"]\n\n            if mime_type == \"text/plain\":\n                # send_content() sends text in \"turn-by-turn mode\"\n                # This signals a complete turn to the model, triggering immediate response\n                content = Content(role=\"user\", parts=[Part.from_text(text=data)])\n                live_request_queue.send_content(content=content)\n                print(f\"[CLIENT TO AGENT]: {data}\")\n            elif mime_type == \"audio/pcm\":\n                # send_realtime() sends audio in \"realtime mode\"\n                # Data flows continuously without turn boundaries, enabling natural conversation\n                # Audio is Base64-encoded for JSON transport, decode before sending\n                decoded_data = base64.b64decode(data)\n                live_request_queue.send_realtime(Blob(data=decoded_data, mime_type=mime_type))\n            else:\n                raise ValueError(f\"Mime type not supported: {mime_type}\")\n    except WebSocketDisconnect:\n        print(\"Client disconnected from client_to_agent_messaging\")\n    except Exception as e:\n        print(f\"Error in client_to_agent_messaging: {e}\")"}]}, {"heading_path": ["FastAPI Web Application\u00b6"], "text": "FastAPI Web Application \u00b6 # # FastAPI web app # app = FastAPI () STATIC_DIR = Path ( \"static\" ) app . mount ( \"/static\" , StaticFiles ( directory = STATIC_DIR ), name = \"static\" ) @app . get ( \"/\" ) async def root (): \"\"\"Serves the index.html\"\"\" return FileResponse ( os . path . join ( STATIC_DIR , \"index.html\" )) @app . websocket ( \"/ws/ {user_id} \" ) async def websocket_endpoint ( websocket : WebSocket , user_id : int , is_audio : str ): \"\"\"Client websocket endpoint This async function creates the LiveRequestQueue in an async context, which is the recommended best practice from the ADK documentation. This ensures the queue uses the correct event loop. \"\"\" await websocket . accept () print ( f \"Client # { user_id } connected, audio mode: { is_audio } \" ) user_id_str = str ( user_id ) live_events , live_request_queue = await start_agent_session ( user_id_str , is_audio == \"true\" ) # Run bidirectional messaging concurrently agent_to_client_task = asyncio . create_task ( agent_to_client_messaging ( websocket , live_events ) ) client_to_agent_task = asyncio . create_task ( client_to_agent_messaging ( websocket , live_request_queue ) ) try : # Wait for either task to complete (connection close or error) tasks = [ agent_to_client_task , client_to_agent_task ] done , pending = await asyncio . wait ( tasks , return_when = asyncio . FIRST_EXCEPTION ) # Check for errors in completed tasks for task in done : if task . exception () is not None : print ( f \"Task error for client # { user_id } : { task . exception () } \" ) import traceback traceback . print_exception ( type ( task . exception ()), task . exception (), task . exception () . __traceback__ ) finally : # Clean up resources (always runs, even if asyncio.wait fails) live_request_queue . close () print ( f \"Client # { user_id } disconnected\" ) app = FastAPI() : Initializes the application. Static Files: Serves files from the static directory under /static . @app.get(\"/\") (Root Endpoint): Serves index.html . @app.websocket(\"/ws/{user_id}\") (WebSocket Endpoint): Path Parameters: user_id (int) and is_audio (str: \"true\"/\"false\"). Connection Handling: Accepts WebSocket connection. Calls start_agent_session() using user_id and is_audio . Concurrent Messaging Tasks: Creates and runs agent_to_client_messaging and client_to_agent_messaging concurrently using asyncio.wait . These tasks handle bidirectional message flow. Error Handling: Uses a try-finally block to: Check completed tasks for exceptions and log detailed error information with traceback Ensure live_request_queue.close() is always called in the finally block for proper cleanup Logs client connection and disconnection. ", "code_blocks": [{"language": "text", "code": "#\n# FastAPI web app\n#\n\napp = FastAPI()\n\nSTATIC_DIR = Path(\"static\")\napp.mount(\"/static\", StaticFiles(directory=STATIC_DIR), name=\"static\")\n\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Serves the index.html\"\"\"\n    return FileResponse(os.path.join(STATIC_DIR, \"index.html\"))\n\n\n@app.websocket(\"/ws/{user_id}\")\nasync def websocket_endpoint(websocket: WebSocket, user_id: int, is_audio: str):\n    \"\"\"Client websocket endpoint\n\n    This async function creates the LiveRequestQueue in an async context,\n    which is the recommended best practice from the ADK documentation.\n    This ensures the queue uses the correct event loop.\n    \"\"\"\n\n    await websocket.accept()\n    print(f\"Client #{user_id} connected, audio mode: {is_audio}\")\n\n    user_id_str = str(user_id)\n    live_events, live_request_queue = await start_agent_session(user_id_str, is_audio == \"true\")\n\n    # Run bidirectional messaging concurrently\n    agent_to_client_task = asyncio.create_task(\n        agent_to_client_messaging(websocket, live_events)\n    )\n    client_to_agent_task = asyncio.create_task(\n        client_to_agent_messaging(websocket, live_request_queue)\n    )\n\n    try:\n        # Wait for either task to complete (connection close or error)\n        tasks = [agent_to_client_task, client_to_agent_task]\n        done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_EXCEPTION)\n\n        # Check for errors in completed tasks\n        for task in done:\n            if task.exception() is not None:\n                print(f\"Task error for client #{user_id}: {task.exception()}\")\n                import traceback\n                traceback.print_exception(type(task.exception()), task.exception(), task.exception().__traceback__)\n    finally:\n        # Clean up resources (always runs, even if asyncio.wait fails)\n        live_request_queue.close()\n        print(f\"Client #{user_id} disconnected\")"}]}, {"heading_path": ["How It Works (Overall Flow)\u00b6"], "text": "How It Works (Overall Flow) \u00b6 Client connects to ws://<server>/ws/<user_id>?is_audio=<true_or_false> . Server's websocket_endpoint accepts, starts ADK session ( start_agent_session ). Two asyncio tasks manage communication: client_to_agent_messaging : Client WebSocket messages -> ADK live_request_queue . agent_to_client_messaging : ADK live_events -> Client WebSocket. Bidirectional streaming continues until disconnection or error. ", "code_blocks": []}, {"heading_path": ["5. Client code overview\u00b6"], "text": "5. Client code overview \u00b6 The JavaScript app.js (in app/static/js ) manages client-side interaction with the ADK Streaming WebSocket server. It handles sending text/audio and receiving/displaying streamed responses. Key functionalities:\n1.  Manage WebSocket connection.\n2.  Handle text input.\n3.  Capture microphone audio (Web Audio API, AudioWorklets).\n4.  Send text/audio to server.\n5.  Receive and render text/audio responses from the ADK agent.\n6.  Manage UI. ", "code_blocks": []}, {"heading_path": ["Prerequisites\u00b6"], "text": "Prerequisites \u00b6 HTML Structure: Requires specific element IDs (e.g., messageForm , message , messages , sendButton , startAudioButton ). Backend Server: The Python FastAPI server must be running. Audio Worklet Files: audio-player.js and audio-recorder.js for audio processing. ", "code_blocks": []}, {"heading_path": ["WebSocket Handling\u00b6"], "text": "WebSocket Handling \u00b6 // Connect the server with a WebSocket connection const sessionId = Math . random (). toString (). substring ( 10 ); const ws_url = \"ws://\" + window . location . host + \"/ws/\" + sessionId ; let websocket = null ; let is_audio = false ; // Get DOM elements const messageForm = document . getElementById ( \"messageForm\" ); const messageInput = document . getElementById ( \"message\" ); const messagesDiv = document . getElementById ( \"messages\" ); let currentMessageId = null ; // WebSocket handlers function connectWebsocket () { // Connect websocket websocket = new WebSocket ( ws_url + \"?is_audio=\" + is_audio ); // Handle connection open websocket . onopen = function () { // Connection opened messages console . log ( \"WebSocket connection opened.\" ); document . getElementById ( \"messages\" ). textContent = \"Connection opened\" ; // Enable the Send button document . getElementById ( \"sendButton\" ). disabled = false ; addSubmitHandler (); }; // Handle incoming messages websocket . onmessage = function ( event ) { // Parse the incoming message const message_from_server = JSON . parse ( event . data ); console . log ( \"[AGENT TO CLIENT] \" , message_from_server ); // Check if the turn is complete // if turn complete, add new message if ( message_from_server . turn_complete && message_from_server . turn_complete == true ) { currentMessageId = null ; return ; } // Check for interrupt message if ( message_from_server . interrupted && message_from_server . interrupted === true ) { // Stop audio playback if it's playing if ( audioPlayerNode ) { audioPlayerNode . port . postMessage ({ command : \"endOfAudio\" }); } return ; } // If it's audio, play it if ( message_from_server . mime_type == \"audio/pcm\" && audioPlayerNode ) { audioPlayerNode . port . postMessage ( base64ToArray ( message_from_server . data )); } // If it's a text, print it if ( message_from_server . mime_type == \"text/plain\" ) { // add a new message for a new turn if ( currentMessageId == null ) { currentMessageId = Math . random (). toString ( 36 ). substring ( 7 ); const message = document . createElement ( \"p\" ); message . id = currentMessageId ; // Append the message element to the messagesDiv messagesDiv . appendChild ( message ); } // Add message text to the existing message element const message = document . getElementById ( currentMessageId ); message . textContent += message_from_server . data ; // Scroll down to the bottom of the messagesDiv messagesDiv . scrollTop = messagesDiv . scrollHeight ; } }; // Handle connection close websocket . onclose = function () { console . log ( \"WebSocket connection closed.\" ); document . getElementById ( \"sendButton\" ). disabled = true ; document . getElementById ( \"messages\" ). textContent = \"Connection closed\" ; setTimeout ( function () { console . log ( \"Reconnecting...\" ); connectWebsocket (); }, 5000 ); }; websocket . onerror = function ( e ) { console . log ( \"WebSocket error: \" , e ); }; } connectWebsocket (); // Add submit handler to the form function addSubmitHandler () { messageForm . onsubmit = function ( e ) { e . preventDefault (); const message = messageInput . value ; if ( message ) { const p = document . createElement ( \"p\" ); p . textContent = \"> \" + message ; messagesDiv . appendChild ( p ); messageInput . value = \"\" ; sendMessage ({ mime_type : \"text/plain\" , data : message , }); console . log ( \"[CLIENT TO AGENT] \" + message ); } return false ; }; } // Send a message to the server as a JSON string function sendMessage ( message ) { if ( websocket && websocket . readyState == WebSocket . OPEN ) { const messageJson = JSON . stringify ( message ); websocket . send ( messageJson ); } } // Decode Base64 data to Array function base64ToArray ( base64 ) { const binaryString = window . atob ( base64 ); const len = binaryString . length ; const bytes = new Uint8Array ( len ); for ( let i = 0 ; i < len ; i ++ ) { bytes [ i ] = binaryString . charCodeAt ( i ); } return bytes . buffer ; } Connection Setup: Generates sessionId , constructs ws_url . is_audio flag (initially false ) appends ?is_audio=true to URL when active. connectWebsocket() initializes the connection. websocket.onopen : Enables send button, updates UI, calls addSubmitHandler() . websocket.onmessage : Parses incoming JSON from server. Turn Completion: Resets currentMessageId to null when agent turn is complete, preparing for the next response. Interruption: Stops audio playback by sending { command: \"endOfAudio\" } to audioPlayerNode when the agent is interrupted (e.g., user starts speaking). Audio Data ( audio/pcm ): Decodes Base64 audio ( base64ToArray() ) and sends to audioPlayerNode for playback. Text Data ( text/plain ): If new turn ( currentMessageId is null), creates new <p> . Appends received text to the current message paragraph for streaming effect. Scrolls messagesDiv . websocket.onclose : Disables send button, updates UI, attempts auto-reconnection after 5s. websocket.onerror : Logs errors. Initial Connection: connectWebsocket() is called on script load. ", "code_blocks": [{"language": "text", "code": "// Connect the server with a WebSocket connection\nconst sessionId = Math.random().toString().substring(10);\nconst ws_url =\n  \"ws://\" + window.location.host + \"/ws/\" + sessionId;\nlet websocket = null;\nlet is_audio = false;\n\n// Get DOM elements\nconst messageForm = document.getElementById(\"messageForm\");\nconst messageInput = document.getElementById(\"message\");\nconst messagesDiv = document.getElementById(\"messages\");\nlet currentMessageId = null;\n\n// WebSocket handlers\nfunction connectWebsocket() {\n  // Connect websocket\n  websocket = new WebSocket(ws_url + \"?is_audio=\" + is_audio);\n\n  // Handle connection open\n  websocket.onopen = function () {\n    // Connection opened messages\n    console.log(\"WebSocket connection opened.\");\n    document.getElementById(\"messages\").textContent = \"Connection opened\";\n\n    // Enable the Send button\n    document.getElementById(\"sendButton\").disabled = false;\n    addSubmitHandler();\n  };\n\n  // Handle incoming messages\n  websocket.onmessage = function (event) {\n    // Parse the incoming message\n    const message_from_server = JSON.parse(event.data);\n    console.log(\"[AGENT TO CLIENT] \", message_from_server);\n\n    // Check if the turn is complete\n    // if turn complete, add new message\n    if (\n      message_from_server.turn_complete &&\n      message_from_server.turn_complete == true\n    ) {\n      currentMessageId = null;\n      return;\n    }\n\n    // Check for interrupt message\n    if (\n      message_from_server.interrupted &&\n      message_from_server.interrupted === true\n    ) {\n      // Stop audio playback if it's playing\n      if (audioPlayerNode) {\n        audioPlayerNode.port.postMessage({ command: \"endOfAudio\" });\n      }\n      return;\n    }\n\n    // If it's audio, play it\n    if (message_from_server.mime_type == \"audio/pcm\" && audioPlayerNode) {\n      audioPlayerNode.port.postMessage(base64ToArray(message_from_server.data));\n    }\n\n    // If it's a text, print it\n    if (message_from_server.mime_type == \"text/plain\") {\n      // add a new message for a new turn\n      if (currentMessageId == null) {\n        currentMessageId = Math.random().toString(36).substring(7);\n        const message = document.createElement(\"p\");\n        message.id = currentMessageId;\n        // Append the message element to the messagesDiv\n        messagesDiv.appendChild(message);\n      }\n\n      // Add message text to the existing message element\n      const message = document.getElementById(currentMessageId);\n      message.textContent += message_from_server.data;\n\n      // Scroll down to the bottom of the messagesDiv\n      messagesDiv.scrollTop = messagesDiv.scrollHeight;\n    }\n  };\n\n  // Handle connection close\n  websocket.onclose = function () {\n    console.log(\"WebSocket connection closed.\");\n    document.getElementById(\"sendButton\").disabled = true;\n    document.getElementById(\"messages\").textContent = \"Connection closed\";\n    setTimeout(function () {\n      console.log(\"Reconnecting...\");\n      connectWebsocket();\n    }, 5000);\n  };\n\n  websocket.onerror = function (e) {\n    console.log(\"WebSocket error: \", e);\n  };\n}\nconnectWebsocket();\n\n// Add submit handler to the form\nfunction addSubmitHandler() {\n  messageForm.onsubmit = function (e) {\n    e.preventDefault();\n    const message = messageInput.value;\n    if (message) {\n      const p = document.createElement(\"p\");\n      p.textContent = \"> \" + message;\n      messagesDiv.appendChild(p);\n      messageInput.value = \"\";\n      sendMessage({\n        mime_type: \"text/plain\",\n        data: message,\n      });\n      console.log(\"[CLIENT TO AGENT] \" + message);\n    }\n    return false;\n  };\n}\n\n// Send a message to the server as a JSON string\nfunction sendMessage(message) {\n  if (websocket && websocket.readyState == WebSocket.OPEN) {\n    const messageJson = JSON.stringify(message);\n    websocket.send(messageJson);\n  }\n}\n\n// Decode Base64 data to Array\nfunction base64ToArray(base64) {\n  const binaryString = window.atob(base64);\n  const len = binaryString.length;\n  const bytes = new Uint8Array(len);\n  for (let i = 0; i < len; i++) {\n    bytes[i] = binaryString.charCodeAt(i);\n  }\n  return bytes.buffer;\n}"}]}, {"heading_path": ["DOM Interaction & Message Submission\u00b6"], "text": "DOM Interaction & Message Submission \u00b6 Element Retrieval: Fetches required DOM elements. addSubmitHandler() : Attached to messageForm 's submit. Prevents default submission, gets text from messageInput , displays user message, clears input, and calls sendMessage() with { mime_type: \"text/plain\", data: messageText } . sendMessage(messagePayload) : Sends JSON stringified messagePayload if WebSocket is open. ", "code_blocks": []}, {"heading_path": ["Audio Handling\u00b6"], "text": "Audio Handling \u00b6 let audioPlayerNode ; let audioPlayerContext ; let audioRecorderNode ; let audioRecorderContext ; let micStream ; // Import the audio worklets import { startAudioPlayerWorklet } from \"./audio-player.js\" ; import { startAudioRecorderWorklet } from \"./audio-recorder.js\" ; // Start audio function startAudio () { // Start audio output startAudioPlayerWorklet (). then (([ node , ctx ]) => { audioPlayerNode = node ; audioPlayerContext = ctx ; }); // Start audio input startAudioRecorderWorklet ( audioRecorderHandler ). then ( ([ node , ctx , stream ]) => { audioRecorderNode = node ; audioRecorderContext = ctx ; micStream = stream ; } ); } // Start the audio only when the user clicked the button // (due to the gesture requirement for the Web Audio API) const startAudioButton = document . getElementById ( \"startAudioButton\" ); startAudioButton . addEventListener ( \"click\" , () => { startAudioButton . disabled = true ; startAudio (); is_audio = true ; connectWebsocket (); // reconnect with the audio mode }); // Audio recorder handler function audioRecorderHandler ( pcmData ) { // Send the pcm data as base64 sendMessage ({ mime_type : \"audio/pcm\" , data : arrayBufferToBase64 ( pcmData ), }); console . log ( \"[CLIENT TO AGENT] sent %s bytes\" , pcmData . byteLength ); } // Encode an array buffer with Base64 function arrayBufferToBase64 ( buffer ) { let binary = \"\" ; const bytes = new Uint8Array ( buffer ); const len = bytes . byteLength ; for ( let i = 0 ; i < len ; i ++ ) { binary += String . fromCharCode ( bytes [ i ]); } return window . btoa ( binary ); } Audio Worklets: Uses AudioWorkletNode via audio-player.js (for playback) and audio-recorder.js (for capture). State Variables: Store AudioContexts and WorkletNodes (e.g., audioPlayerNode ). startAudio() : Initializes player and recorder worklets. Passes audioRecorderHandler as callback to recorder. \"Start Audio\" Button ( startAudioButton ): Requires user gesture for Web Audio API. On click: disables button, calls startAudio() , sets is_audio = true , then calls connectWebsocket() to reconnect in audio mode (URL includes ?is_audio=true ). audioRecorderHandler(pcmData) : Callback from recorder worklet with PCM audio chunks. Encodes pcmData to Base64 ( arrayBufferToBase64() ) and sends to server via sendMessage() with mime_type: \"audio/pcm\" . Helper Functions: base64ToArray() (server audio -> client player) and arrayBufferToBase64() (client mic audio -> server). ", "code_blocks": [{"language": "text", "code": "let audioPlayerNode;\nlet audioPlayerContext;\nlet audioRecorderNode;\nlet audioRecorderContext;\nlet micStream;\n\n// Import the audio worklets\nimport { startAudioPlayerWorklet } from \"./audio-player.js\";\nimport { startAudioRecorderWorklet } from \"./audio-recorder.js\";\n\n// Start audio\nfunction startAudio() {\n  // Start audio output\n  startAudioPlayerWorklet().then(([node, ctx]) => {\n    audioPlayerNode = node;\n    audioPlayerContext = ctx;\n  });\n  // Start audio input\n  startAudioRecorderWorklet(audioRecorderHandler).then(\n    ([node, ctx, stream]) => {\n      audioRecorderNode = node;\n      audioRecorderContext = ctx;\n      micStream = stream;\n    }\n  );\n}\n\n// Start the audio only when the user clicked the button\n// (due to the gesture requirement for the Web Audio API)\nconst startAudioButton = document.getElementById(\"startAudioButton\");\nstartAudioButton.addEventListener(\"click\", () => {\n  startAudioButton.disabled = true;\n  startAudio();\n  is_audio = true;\n  connectWebsocket(); // reconnect with the audio mode\n});\n\n// Audio recorder handler\nfunction audioRecorderHandler(pcmData) {\n  // Send the pcm data as base64\n  sendMessage({\n    mime_type: \"audio/pcm\",\n    data: arrayBufferToBase64(pcmData),\n  });\n  console.log(\"[CLIENT TO AGENT] sent %s bytes\", pcmData.byteLength);\n}\n\n// Encode an array buffer with Base64\nfunction arrayBufferToBase64(buffer) {\n  let binary = \"\";\n  const bytes = new Uint8Array(buffer);\n  const len = bytes.byteLength;\n  for (let i = 0; i < len; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return window.btoa(binary);\n}"}]}, {"heading_path": ["How It Works (Client-Side Flow)\u00b6"], "text": "How It Works (Client-Side Flow) \u00b6 Page Load: Establishes WebSocket in text mode. Text Interaction: User types/submits text; sent to server. Server text responses displayed, streamed. Switching to Audio Mode: \"Start Audio\" button click initializes audio worklets, sets is_audio=true , and reconnects WebSocket in audio mode. Audio Interaction: Recorder sends mic audio (Base64 PCM) to server. Server audio/text responses handled by websocket.onmessage for playback/display. Connection Management: Auto-reconnect on WebSocket close. ", "code_blocks": []}, {"heading_path": ["Summary\u00b6"], "text": "Summary \u00b6 This article overviews the server and client code for a custom asynchronous web application built with ADK Streaming and FastAPI, enabling real-time, bidirectional voice and text communication. The Python FastAPI server code initializes ADK agent sessions, configured for text or audio responses. It uses a WebSocket endpoint to handle client connections. Asynchronous tasks manage bidirectional messaging: forwarding client text or Base64-encoded PCM audio to the ADK agent, and streaming text or Base64-encoded PCM audio responses from the ADK agent back to the client. The client-side JavaScript code manages a WebSocket connection, which can be re-established to switch between text and audio modes. It sends user input (text or microphone audio captured via Web Audio API and AudioWorklets) to the server. Incoming messages from the server are processed: text is displayed (streamed), and Base64-encoded PCM audio is decoded and played using an AudioWorklet. ", "code_blocks": []}, {"heading_path": ["Additional Resources\u00b6"], "text": "Additional Resources \u00b6 For comprehensive guidance on ADK Bidi-streaming best practices, architecture patterns, and advanced features, refer to: ADK Documentation : Complete ADK documentation including agents, tools, and session management Gemini Live API Documentation : Live API reference for Google AI Studio Vertex AI Live API Documentation : Live API reference for Google Cloud Vertex AI These resources provide detailed explanations of: Phase-based lifecycle patterns for streaming applications (initialization, session management, active streaming, termination) Event handling patterns including partial/complete text, interruptions, and turn completion signals Advanced features like session resumption, voice activity detection, audio transcription, and context window compression Production deployment strategies including load balancing, stateless session management, and health checks Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:45.506077", "source_type": "adk-docs"}
{"doc_id": "49f32c08d9ebabb3a5d31b495f5c0d09e66678343c9dd266a705c416b8bc8013", "url": "https://google.github.io/adk-docs/streaming/dev-guide/part1", "title": "Bidi-streaming development guide series - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["ADK Bidi-streaming development guide: Part 1 - Introduction\u00b6"], "text": "ADK Bidi-streaming development guide: Part 1 - Introduction \u00b6 Supported in ADK Python v0.5.0 Experimental Welcome to the world of bidirectional streaming with Agent Development Kit (ADK) . This article will transform your understanding of AI agent communication from traditional request-response patterns to dynamic, real-time conversations that feel as natural as talking to another person. Imagine building an AI assistant that doesn't just wait for you to finish speaking before responding, but actively listens and can be interrupted mid-sentence when you have a sudden thought. Picture creating customer support bots that handle audio, video, and text simultaneously while maintaining context throughout the conversation. This is the power of bidirectional streaming, and ADK makes it accessible to every developer. ", "code_blocks": []}, {"heading_path": ["1.1 What is Bidi-streaming?\u00b6"], "text": "1.1 What is Bidi-streaming? \u00b6 Bidi-streaming (Bidirectional streaming) represents a fundamental shift from traditional AI interactions. Instead of the rigid \"ask-and-wait\" pattern, it enables real-time, two-way communication where both human and AI can speak, listen, and respond simultaneously. This creates natural, human-like conversations with immediate responses and the revolutionary ability to interrupt ongoing interactions. Think of the difference between sending emails and having a phone conversation. Traditional AI interactions are like emails\u2014you send a complete message, wait for a complete response, then send another complete message. Bidirectional streaming is like a phone conversation\u2014fluid, natural, with the ability to interrupt, clarify, and respond in real-time. ", "code_blocks": []}, {"heading_path": ["Key Characteristics\u00b6"], "text": "Key Characteristics \u00b6 These characteristics distinguish bidirectional streaming from traditional AI interactions and make it uniquely powerful for creating engaging user experiences: Two-way Communication : Continuous data exchange without waiting for complete responses. Either the user and AI can start responding to the first few words of your question while you're still speaking, creating an experience that feels genuinely conversational rather than transactional. Responsive Interruption : Perhaps the most important feature for the natural user experience\u2014users can interrupt the agent mid-response with new input, just like in human conversation. If an AI is explaining quantum physics and you suddenly ask \"wait, what's an electron?\", the AI stops immediately and addresses your question. Best for Multimodal : Simultaneous support for text, audio, and video inputs creates rich, natural interactions. Users can speak while showing documents, type follow-up questions during voice calls, or seamlessly switch between communication modes without losing context. sequenceDiagram\n    participant Client as User\n    participant Agent\n\n    Client->>Agent: \"Hi!\"\n    Client->>Agent: \"Explain the history of Japan\"\n    Agent->>Client: \"Hello!\"\n    Agent->>Client: \"Sure! Japan's history is a...\" (partial content)\n    Client->>Agent: \"Ah, wait.\"\n\n    Agent->>Client: \"OK, how can I help?\" (interrupted = True) ", "code_blocks": [{"language": "text", "code": "sequenceDiagram\n    participant Client as User\n    participant Agent\n\n    Client->>Agent: \"Hi!\"\n    Client->>Agent: \"Explain the history of Japan\"\n    Agent->>Client: \"Hello!\"\n    Agent->>Client: \"Sure! Japan's history is a...\" (partial content)\n    Client->>Agent: \"Ah, wait.\"\n\n    Agent->>Client: \"OK, how can I help?\" (interrupted = True)"}]}, {"heading_path": ["Difference from Other Streaming Types\u00b6"], "text": "Difference from Other Streaming Types \u00b6 Understanding how bidirectional streaming differs from other approaches is crucial for appreciating its unique value. The streaming landscape includes several distinct patterns, each serving different use cases: Streaming Types Comparison Bidi-streaming differs fundamentally from other streaming approaches: Server-Side Streaming : One-way data flow from server to client. Like watching a live video stream\u2014you receive continuous data but can't interact with it in real-time. Useful for dashboards or live feeds, but not for conversations. Token-Level Streaming : Sequential text token delivery without interruption. The AI generates response word-by-word, but you must wait for completion before sending new input. Like watching someone type a message in real-time\u2014you see it forming, but can't interrupt. Bidirectional Streaming : Full two-way communication with interruption support. True conversational AI where both parties can speak, listen, and respond simultaneously. This is what enables natural dialogue where you can interrupt, clarify, or change topics mid-conversation. ", "code_blocks": []}, {"heading_path": ["Real-World Applications\u00b6"], "text": "Real-World Applications \u00b6 Bidirectional streaming revolutionizes agentic AI applications by enabling agents to operate with human-like responsiveness and intelligence. These applications showcase how streaming transforms static AI interactions into dynamic, agent-driven experiences that feel genuinely intelligent and proactive. In a video of the Shopper's Concierge demo , the multimodal, bi-directional streaming feature significantly improve the user experience of e-commerce by enabling a faster and more intuitive shopping experience. The combination of conversational understanding and rapid, parallelized searching culminates in advanced capabilities like virtual try-on, boosting buyer confidence and reducing the friction of online shopping. Also, you can think of many possible real-world applications for bidirectional streaming: Customer Service & Contact Centers : This is the most direct application. The technology can create sophisticated virtual agents that go far beyond traditional chatbots. Use case : A customer calls a retail company's support line about a defective product. Multimodality (video) : The customer can say, \"My coffee machine is leaking from the bottom, let me show you.\" They can then use their phone's camera to stream live video of the issue. The AI agent can use its vision capabilities to identify the model and the specific point of failure. Live Interaction & Interruption : If the agent says, \"Okay, I'm processing a return for your Model X coffee maker,\" the customer can interrupt with, \"No, wait, it's the Model Y Pro,\" and the agent can immediately correct its course without restarting the conversation. Field Service & Technical Assistance : Technicians working on-site can use a hands-free, voice-activated assistant to get real-time help. Use Case : An HVAC technician is on-site trying to diagnose a complex commercial air conditioning unit. Multimodality (Video & Voice) : The technician, wearing smart glasses or using a phone, can stream their point-of-view to the AI agent. They can ask, \"I'm hearing a strange noise from this compressor. Can you identify it and pull up the diagnostic flowchart for this model?\" Live Interaction : The agent can guide the technician step-by-step, and the technician can ask clarifying questions or interrupt at any point without taking their hands off their tools. Healthcare & Telemedicine : The agent can serve as a first point of contact for patient intake, triage, and basic consultations. Use Case : A patient uses a provider's app for a preliminary consultation about a skin condition. Multimodality (Video/Image) : The patient can securely share a live video or high-resolution image of a rash. The AI can perform a preliminary analysis and ask clarifying questions. Financial Services & Wealth Management : An agent can provide clients with a secure, interactive, and data-rich way to manage their finances. Use Case : A client wants to review their investment portfolio and discuss market trends. Multimodality (Screen Sharing) : The agent can share its screen to display charts, graphs, and portfolio performance data. The client could also share their screen to point to a specific news article and ask, \"What is the potential impact of this event on my tech stocks?\" Live Interaction : Analyze the client's current portfolio allocation by accessing their account data.Simulate the impact of a potential trade on the portfolio's risk profile. ", "code_blocks": []}, {"heading_path": ["1.2 ADK Bidi-streaming Architecture Overview\u00b6"], "text": "1.2 ADK Bidi-streaming Architecture Overview \u00b6 ADK Bidi-streaming architecture enables bidirectional AI conversations feel as natural as human dialogue. The architecture seamlessly integrates with Google's Gemini Live API through a sophisticated pipeline that has been designed for low latency and high-throughput communication. The system handles the complex orchestration required for real-time streaming\u2014managing multiple concurrent data flows, handling interruptions gracefully, processing multimodal inputs simultaneously, and maintaining conversation state across dynamic interactions. ADK Bidi-streaming abstracts this complexity into simple, intuitive APIs that developers can use without needing to understand the intricate details of streaming protocols or AI model communication patterns. ", "code_blocks": []}, {"heading_path": ["High-Level Architecture\u00b6"], "text": "High-Level Architecture \u00b6 graph TB\n    subgraph \"Application\"\n        subgraph \"Client\"\n            C1[\"Web / Mobile\"]\n        end\n\n        subgraph \"Transport Layer\"\n            T1[\"WebSocket / SSE (e.g. FastAPI)\"]\n        end\n    end\n\n    subgraph \"ADK\"\n        subgraph \"ADK Bidi-streaming\"\n            L1[LiveRequestQueue]\n            L2[Runner]\n            L3[Agent]\n            L4[LLM Flow]\n        end\n\n        subgraph \"LLM Integration\"\n            G1[GeminiLlmConnection]\n            G2[Gemini Live API]\n        end\n    end\n\n    C1 <--> T1\n    T1 -->|\"live_request_queue.send()\"| L1\n    L1 -->|\"runner.run_live(queue)\"| L2\n    L2 -->|\"agent.run_live()\"| L3\n    L3 -->|\"_llm_flow.run_live()\"| L4\n    L4 -->|\"llm.connect()\"| G1\n    G1 <--> G2\n    G1 -->|\"yield LlmResponse\"| L4\n    L4 -->|\"yield Event\"| L3\n    L3 -->|\"yield Event\"| L2\n    L2 -->|\"yield Event\"| T1\n\n    classDef external fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n    classDef adk fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n\n    class C1,T1,L3 external\n    class L1,L2,L4,G1,G2 adk Developer provides: ADK provides: Gemini provides: Web / Mobile : Frontend applications that users interact with, handling UI/UX, user input capture, and response display WebSocket / SSE Server : Real-time communication server (such as FastAPI ) that manages client connections, handles streaming protocols, and routes messages between clients and ADK Agent : Custom AI agent definition with specific instructions, tools, and behavior tailored to your application's needs LiveRequestQueue : Message queue that buffers and sequences incoming user messages (text content, audio blobs, control signals) for orderly processing by the agent Runner : Execution engine that orchestrates agent sessions, manages conversation state, and provides the run_live() streaming interface LLM Flow : Processing pipeline that handles streaming conversation logic, manages context, and coordinates with language models GeminiLlmConnection : Abstraction layer that bridges ADK's streaming architecture with Gemini Live API, handling protocol translation and connection management Gemini Live API : Google's real-time language model service that processes streaming input, generates responses, handles interruptions, supports multimodal content (text, audio, video), and provides advanced AI capabilities like function calling and contextual understanding ", "code_blocks": [{"language": "text", "code": "graph TB\n    subgraph \"Application\"\n        subgraph \"Client\"\n            C1[\"Web / Mobile\"]\n        end\n\n        subgraph \"Transport Layer\"\n            T1[\"WebSocket / SSE (e.g. FastAPI)\"]\n        end\n    end\n\n    subgraph \"ADK\"\n        subgraph \"ADK Bidi-streaming\"\n            L1[LiveRequestQueue]\n            L2[Runner]\n            L3[Agent]\n            L4[LLM Flow]\n        end\n\n        subgraph \"LLM Integration\"\n            G1[GeminiLlmConnection]\n            G2[Gemini Live API]\n        end\n    end\n\n    C1 <--> T1\n    T1 -->|\"live_request_queue.send()\"| L1\n    L1 -->|\"runner.run_live(queue)\"| L2\n    L2 -->|\"agent.run_live()\"| L3\n    L3 -->|\"_llm_flow.run_live()\"| L4\n    L4 -->|\"llm.connect()\"| G1\n    G1 <--> G2\n    G1 -->|\"yield LlmResponse\"| L4\n    L4 -->|\"yield Event\"| L3\n    L3 -->|\"yield Event\"| L2\n    L2 -->|\"yield Event\"| T1\n\n    classDef external fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n    classDef adk fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n\n    class C1,T1,L3 external\n    class L1,L2,L4,G1,G2 adk"}]}, {"heading_path": ["1.3 Setting Up Your Development Environment\u00b6"], "text": "1.3 Setting Up Your Development Environment \u00b6 Now that you understand the gist of ADK Bidi-streaming architecture and the value it provides, it's time to get hands-on experience. This section will prepare your development environment so you can start building the streaming agents and applications described in the previous sections. By the end of this setup, you'll have everything needed to create the intelligent voice assistants, proactive customer support agents, and multi-agent collaboration platforms we've discussed. The setup process is straightforward\u2014ADK handles the complex streaming infrastructure, so you can focus on building your agent's unique capabilities rather than wrestling with low-level streaming protocols. ", "code_blocks": []}, {"heading_path": ["Installation Steps\u00b6"], "text": "Installation Steps \u00b6 ", "code_blocks": []}, {"heading_path": ["1. Create Virtual Environment (Recommended)\u00b6"], "text": "1. Create Virtual Environment (Recommended) \u00b6 # Create virtual environment python -m venv .venv # Activate virtual environment # macOS/Linux: source .venv/bin/activate # Windows CMD: # .venv\\Scripts\\activate.bat # Windows PowerShell: # .venv\\Scripts\\Activate.ps1 ", "code_blocks": [{"language": "text", "code": "# Create virtual environment\npython -m venv .venv\n\n# Activate virtual environment\n# macOS/Linux:\nsource .venv/bin/activate\n# Windows CMD:\n# .venv\\Scripts\\activate.bat\n# Windows PowerShell:\n# .venv\\Scripts\\Activate.ps1"}]}, {"heading_path": ["2. Install ADK\u00b6"], "text": "2. Install ADK \u00b6 Create a requirements.txt file in your project root. Note that google-adk library includes FastAPI and uvicorn that you can use as the web server for bidi-streaming applications. google-adk==1.3.0 python-dotenv>=1.0.0 Install all dependencies: pip install -r requirements.txt ", "code_blocks": [{"language": "text", "code": "google-adk==1.3.0\npython-dotenv>=1.0.0"}, {"language": "text", "code": "pip install -r requirements.txt"}]}, {"heading_path": ["3. Set SSL Certificate Path (macOS only)\u00b6"], "text": "3. Set SSL Certificate Path (macOS only) \u00b6 # Required for proper SSL handling on macOS export SSL_CERT_FILE = $( python -m certifi ) ", "code_blocks": [{"language": "text", "code": "# Required for proper SSL handling on macOS\nexport SSL_CERT_FILE=$(python -m certifi)"}]}, {"heading_path": ["4. Set Up API Keys\u00b6"], "text": "4. Set Up API Keys \u00b6 Choose your preferred platform for running agents: Google AI Studio Google Cloud Vertex AI Get an API key from Google AI Studio Create a .env file in your project root: GOOGLE_GENAI_USE_VERTEXAI=FALSE GOOGLE_API_KEY=your_actual_api_key_here Set up Google Cloud project Install and configure gcloud CLI Authenticate: gcloud auth login Enable Vertex AI API Create a .env file in your project root: GOOGLE_GENAI_USE_VERTEXAI=TRUE GOOGLE_CLOUD_PROJECT=your_actual_project_id GOOGLE_CLOUD_LOCATION=us-central1 ", "code_blocks": [{"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=FALSE\nGOOGLE_API_KEY=your_actual_api_key_here"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=TRUE\nGOOGLE_CLOUD_PROJECT=your_actual_project_id\nGOOGLE_CLOUD_LOCATION=us-central1"}]}, {"heading_path": ["5. Create Environment Setup Script\u00b6"], "text": "5. Create Environment Setup Script \u00b6 We will create the validation script that will verify your installation: # Create the directory structure mkdir -p src/part1 Create src/part1/1-3-1_environment_setup.py : #!/usr/bin/env python3 \"\"\" Part 1.3.1: Environment Setup Validation Comprehensive script to validate ADK streaming environment configuration. \"\"\" import os import sys from pathlib import Path from dotenv import load_dotenv def validate_environment (): \"\"\"Validate ADK streaming environment setup.\"\"\" print ( \"\ud83d\udd27 ADK Streaming Environment Validation\" ) print ( \"=\" * 45 ) # Load environment variables env_path = Path ( __file__ ) . parent . parent . parent / '.env' if env_path . exists (): load_dotenv ( env_path ) print ( f \"\u2713 Environment file loaded: { env_path } \" ) else : print ( f \"\u274c Environment file not found: { env_path } \" ) return False # Check Python version python_version = sys . version_info if python_version >= ( 3 , 8 ): print ( f \"\u2713 Python version: { python_version . major } . { python_version . minor } . { python_version . micro } \" ) else : print ( f \"\u274c Python version { python_version . major } . { python_version . minor } - requires 3.8+\" ) return False # Test ADK installation try : import google.adk print ( f \"\u2713 ADK import successful\" ) # Try to get version if available try : from google.adk.version import __version__ print ( f \"\u2713 ADK version: { __version__ } \" ) except : print ( \"\u2139\ufe0f ADK version info not available\" ) except ImportError as e : print ( f \"\u274c ADK import failed: { e } \" ) return False # Check essential imports essential_imports = [ ( 'google.adk.agents' , 'Agent, LiveRequestQueue' ), ( 'google.adk.runners' , 'InMemoryRunner' ), ( 'google.genai.types' , 'Content, Part, Blob' ), ] for module , components in essential_imports : try : __import__ ( module ) print ( f \"\u2713 Import: { module } \" ) except ImportError as e : print ( f \"\u274c Import failed: { module } - { e } \" ) return False # Validate environment variables env_checks = [ ( 'GOOGLE_GENAI_USE_VERTEXAI' , 'Platform configuration' ), ( 'GOOGLE_API_KEY' , 'API authentication' ), ] for env_var , description in env_checks : value = os . getenv ( env_var ) if value : # Mask API key for security display_value = value if env_var != 'GOOGLE_API_KEY' else f \" { value [: 10 ] } ...\" print ( f \"\u2713 { description } : { display_value } \" ) else : print ( f \"\u274c Missing: { env_var } ( { description } )\" ) return False # Test basic ADK functionality try : from google.adk.agents import LiveRequestQueue from google.genai.types import Content , Part # Create test queue queue = LiveRequestQueue () test_content = Content ( parts = [ Part ( text = \"Test message\" )]) queue . send_content ( test_content ) queue . close () print ( \"\u2713 Basic ADK functionality test passed\" ) except Exception as e : print ( f \"\u274c ADK functionality test failed: { e } \" ) return False print ( \" \\n \ud83c\udf89 Environment validation successful!\" ) print ( \" \\n Next steps:\" ) print ( \"\u2022 Start building your streaming agents in src/agents/\" ) print ( \"\u2022 Create custom tools in src/tools/\" ) print ( \"\u2022 Add utility functions in src/utils/\" ) print ( \"\u2022 Test with Part 3 examples\" ) return True def main (): \"\"\"Run environment validation.\"\"\" try : success = validate_environment () sys . exit ( 0 if success else 1 ) except KeyboardInterrupt : print ( \" \\n\\n \u26a0\ufe0f Validation interrupted by user\" ) sys . exit ( 1 ) except Exception as e : print ( f \" \\n \u274c Unexpected error: { e } \" ) sys . exit ( 1 ) if __name__ == \"__main__\" : main () ", "code_blocks": [{"language": "text", "code": "# Create the directory structure\nmkdir -p src/part1"}, {"language": "text", "code": "#!/usr/bin/env python3\n\"\"\"\nPart 1.3.1: Environment Setup Validation\nComprehensive script to validate ADK streaming environment configuration.\n\"\"\"\n\nimport os\nimport sys\nfrom pathlib import Path\nfrom dotenv import load_dotenv\n\ndef validate_environment():\n    \"\"\"Validate ADK streaming environment setup.\"\"\"\n\n    print(\"\ud83d\udd27 ADK Streaming Environment Validation\")\n    print(\"=\" * 45)\n\n    # Load environment variables\n    env_path = Path(__file__).parent.parent.parent / '.env'\n    if env_path.exists():\n        load_dotenv(env_path)\n        print(f\"\u2713 Environment file loaded: {env_path}\")\n    else:\n        print(f\"\u274c Environment file not found: {env_path}\")\n        return False\n\n    # Check Python version\n    python_version = sys.version_info\n    if python_version >= (3, 8):\n        print(f\"\u2713 Python version: {python_version.major}.{python_version.minor}.{python_version.micro}\")\n    else:\n        print(f\"\u274c Python version {python_version.major}.{python_version.minor} - requires 3.8+\")\n        return False\n\n    # Test ADK installation\n    try:\n        import google.adk\n        print(f\"\u2713 ADK import successful\")\n\n        # Try to get version if available\n        try:\n            from google.adk.version import __version__\n            print(f\"\u2713 ADK version: {__version__}\")\n        except:\n            print(\"\u2139\ufe0f ADK version info not available\")\n\n    except ImportError as e:\n        print(f\"\u274c ADK import failed: {e}\")\n        return False\n\n    # Check essential imports\n    essential_imports = [\n        ('google.adk.agents', 'Agent, LiveRequestQueue'),\n        ('google.adk.runners', 'InMemoryRunner'),\n        ('google.genai.types', 'Content, Part, Blob'),\n    ]\n\n    for module, components in essential_imports:\n        try:\n            __import__(module)\n            print(f\"\u2713 Import: {module}\")\n        except ImportError as e:\n            print(f\"\u274c Import failed: {module} - {e}\")\n            return False\n\n    # Validate environment variables\n    env_checks = [\n        ('GOOGLE_GENAI_USE_VERTEXAI', 'Platform configuration'),\n        ('GOOGLE_API_KEY', 'API authentication'),\n    ]\n\n    for env_var, description in env_checks:\n        value = os.getenv(env_var)\n        if value:\n            # Mask API key for security\n            display_value = value if env_var != 'GOOGLE_API_KEY' else f\"{value[:10]}...\"\n            print(f\"\u2713 {description}: {display_value}\")\n        else:\n            print(f\"\u274c Missing: {env_var} ({description})\")\n            return False\n\n    # Test basic ADK functionality\n    try:\n        from google.adk.agents import LiveRequestQueue\n        from google.genai.types import Content, Part\n\n        # Create test queue\n        queue = LiveRequestQueue()\n        test_content = Content(parts=[Part(text=\"Test message\")])\n        queue.send_content(test_content)\n        queue.close()\n\n        print(\"\u2713 Basic ADK functionality test passed\")\n\n    except Exception as e:\n        print(f\"\u274c ADK functionality test failed: {e}\")\n        return False\n\n    print(\"\\n\ud83c\udf89 Environment validation successful!\")\n    print(\"\\nNext steps:\")\n    print(\"\u2022 Start building your streaming agents in src/agents/\")\n    print(\"\u2022 Create custom tools in src/tools/\")\n    print(\"\u2022 Add utility functions in src/utils/\")\n    print(\"\u2022 Test with Part 3 examples\")\n\n    return True\n\ndef main():\n    \"\"\"Run environment validation.\"\"\"\n\n    try:\n        success = validate_environment()\n        sys.exit(0 if success else 1)\n\n    except KeyboardInterrupt:\n        print(\"\\n\\n\u26a0\ufe0f Validation interrupted by user\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"\\n\u274c Unexpected error: {e}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()"}]}, {"heading_path": ["Project Structure\u00b6"], "text": "Project Structure \u00b6 Now your streaming project should now have this structure: your-streaming-project/ \u251c\u2500\u2500 .env                              # Environment variables (API keys) \u251c\u2500\u2500 requirements.txt                 # Python dependencies \u2514\u2500\u2500 src/ \u2514\u2500\u2500 part1/ \u2514\u2500\u2500 1-3-1_environment_setup.py  # Environment validation script ", "code_blocks": [{"language": "text", "code": "your-streaming-project/\n\u251c\u2500\u2500 .env                              # Environment variables (API keys)\n\u251c\u2500\u2500 requirements.txt                 # Python dependencies\n\u2514\u2500\u2500 src/\n    \u2514\u2500\u2500 part1/\n        \u2514\u2500\u2500 1-3-1_environment_setup.py  # Environment validation script"}]}, {"heading_path": ["Run It\u00b6"], "text": "Run It \u00b6 Use our complete environment setup script to ensure everything is configured correctly: python src/part1/1-3-1_environment_setup.py Expected Output When you run the validation script, you should see output similar to this: \ud83d\udd27 ADK Streaming Environment Validation ============================================= \u2713 Environment file loaded: /path/to/your-streaming-project/.env \u2713 Python version: 3.12.8 \u2713 ADK import successful \u2713 ADK version: 1.3.0 \u2713 Import: google.adk.agents \u2713 Import: google.adk.runners \u2713 Import: google.genai.types \u2713 Platform configuration: FALSE \u2713 API authentication: AIzaSyAolZ... \u2713 Basic ADK functionality test passed \ud83c\udf89 Environment validation successful! This comprehensive validation script checks: ADK installation and version Required environment variables API key validation Basic import verification ", "code_blocks": [{"language": "text", "code": "python src/part1/1-3-1_environment_setup.py"}, {"language": "text", "code": "\ud83d\udd27 ADK Streaming Environment Validation\n=============================================\n\u2713 Environment file loaded: /path/to/your-streaming-project/.env\n\u2713 Python version: 3.12.8\n\u2713 ADK import successful\n\u2713 ADK version: 1.3.0\n\u2713 Import: google.adk.agents\n\u2713 Import: google.adk.runners\n\u2713 Import: google.genai.types\n\u2713 Platform configuration: FALSE\n\u2713 API authentication: AIzaSyAolZ...\n\u2713 Basic ADK functionality test passed\n\n\ud83c\udf89 Environment validation successful!"}]}, {"heading_path": ["Next Steps\u00b6"], "text": "Next Steps \u00b6 With your environment set up, you're ready to dive into the core streaming APIs. In the next part (coming soon), You'll learn about: LiveRequestQueue : The heart of bidirectional communication run_live() method : Starting streaming sessions Event processing : Handling real-time responses Gemini Live API : Direct integration patterns Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:45.909461", "source_type": "adk-docs"}
{"doc_id": "a51c5b6f8e864249340b3a4837958dbc67ced380dec59f9af03b3e36a174b502", "url": "https://google.github.io/adk-docs/streaming/streaming-tools", "title": "Streaming Tools - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Streaming Tools\u00b6"], "text": "Streaming Tools \u00b6 Supported in ADK Python v0.5.0 Experimental Streaming tools allows tools(functions) to stream intermediate results back to agents and agents can respond to those intermediate results. \nFor example, we can use streaming tools to monitor the changes of the stock price and have the agent react to it. Another example is we can have the agent monitor the video stream, and when there is changes in video stream, the agent can report the changes. Info This is only supported in streaming(live) agents/api. To define a streaming tool, you must adhere to the following: Asynchronous Function: The tool must be an async Python function. AsyncGenerator Return Type: The function must be typed to return an AsyncGenerator . The first type parameter to AsyncGenerator is the type of the data you yield (e.g., str for text messages, or a custom object for structured data). The second type parameter is typically None if the generator doesn't receive values via send() . We support two types of streaming tools:\n- Simple type. This is a one type of streaming tools that only take non video/audio streams(the streams that you feed to adk web or adk runner) as input.\n- Video streaming tools. This only works in video streaming and the video stream(the streams that you feed to adk web or adk runner) will be passed into this function. Now let's define an agent that can monitor stock price changes and monitor the video stream changes. import asyncio from typing import AsyncGenerator from google.adk.agents import LiveRequestQueue from google.adk.agents.llm_agent import Agent from google.adk.tools.function_tool import FunctionTool from google.genai import Client from google.genai import types as genai_types async def monitor_stock_price ( stock_symbol : str ) -> AsyncGenerator [ str , None ]: \"\"\"This function will monitor the price for the given stock_symbol in a continuous, streaming and asynchronously way.\"\"\" print ( f \"Start monitor stock price for { stock_symbol } !\" ) # Let's mock stock price change. await asyncio . sleep ( 4 ) price_alert1 = f \"the price for { stock_symbol } is 300\" yield price_alert1 print ( price_alert1 ) await asyncio . sleep ( 4 ) price_alert1 = f \"the price for { stock_symbol } is 400\" yield price_alert1 print ( price_alert1 ) await asyncio . sleep ( 20 ) price_alert1 = f \"the price for { stock_symbol } is 900\" yield price_alert1 print ( price_alert1 ) await asyncio . sleep ( 20 ) price_alert1 = f \"the price for { stock_symbol } is 500\" yield price_alert1 print ( price_alert1 ) # for video streaming, `input_stream: LiveRequestQueue` is required and reserved key parameter for ADK to pass the video streams in. async def monitor_video_stream ( input_stream : LiveRequestQueue , ) -> AsyncGenerator [ str , None ]: \"\"\"Monitor how many people are in the video streams.\"\"\" print ( \"start monitor_video_stream!\" ) client = Client ( vertexai = False ) prompt_text = ( \"Count the number of people in this image. Just respond with a numeric\" \" number.\" ) last_count = None while True : last_valid_req = None print ( \"Start monitoring loop\" ) # use this loop to pull the latest images and discard the old ones while input_stream . _queue . qsize () != 0 : live_req = await input_stream . get () if live_req . blob is not None and live_req . blob . mime_type == \"image/jpeg\" : last_valid_req = live_req # If we found a valid image, process it if last_valid_req is not None : print ( \"Processing the most recent frame from the queue\" ) # Create an image part using the blob's data and mime type image_part = genai_types . Part . from_bytes ( data = last_valid_req . blob . data , mime_type = last_valid_req . blob . mime_type ) contents = genai_types . Content ( role = \"user\" , parts = [ image_part , genai_types . Part . from_text ( prompt_text )], ) # Call the model to generate content based on the provided image and prompt response = client . models . generate_content ( model = \"gemini-2.0-flash-exp\" , contents = contents , config = genai_types . GenerateContentConfig ( system_instruction = ( \"You are a helpful video analysis assistant. You can count\" \" the number of people in this image or video. Just respond\" \" with a numeric number.\" ) ), ) if not last_count : last_count = response . candidates [ 0 ] . content . parts [ 0 ] . text elif last_count != response . candidates [ 0 ] . content . parts [ 0 ] . text : last_count = response . candidates [ 0 ] . content . parts [ 0 ] . text yield response print ( \"response:\" , response ) # Wait before checking for new images await asyncio . sleep ( 0.5 ) # Use this exact function to help ADK stop your streaming tools when requested. # for example, if we want to stop `monitor_stock_price`, then the agent will # invoke this function with stop_streaming(function_name=monitor_stock_price). def stop_streaming ( function_name : str ): \"\"\"Stop the streaming Args: function_name: The name of the streaming function to stop. \"\"\" pass root_agent = Agent ( model = \"gemini-2.0-flash-exp\" , name = \"video_streaming_agent\" , instruction = \"\"\" You are a monitoring agent. You can do video monitoring and stock price monitoring using the provided tools/functions. When users want to monitor a video stream, You can use monitor_video_stream function to do that. When monitor_video_stream returns the alert, you should tell the users. When users want to monitor a stock price, you can use monitor_stock_price. Don't ask too many questions. Don't be too talkative. \"\"\" , tools = [ monitor_video_stream , monitor_stock_price , FunctionTool ( stop_streaming ), ] ) Here are some sample queries to test:\n- Help me monitor the stock price for $XYZ stock.\n- Help me monitor how many people are there in the video stream. Back to top ", "code_blocks": [{"language": "text", "code": "import asyncio\nfrom typing import AsyncGenerator\n\nfrom google.adk.agents import LiveRequestQueue\nfrom google.adk.agents.llm_agent import Agent\nfrom google.adk.tools.function_tool import FunctionTool\nfrom google.genai import Client\nfrom google.genai import types as genai_types\n\n\nasync def monitor_stock_price(stock_symbol: str) -> AsyncGenerator[str, None]:\n  \"\"\"This function will monitor the price for the given stock_symbol in a continuous, streaming and asynchronously way.\"\"\"\n  print(f\"Start monitor stock price for {stock_symbol}!\")\n\n  # Let's mock stock price change.\n  await asyncio.sleep(4)\n  price_alert1 = f\"the price for {stock_symbol} is 300\"\n  yield price_alert1\n  print(price_alert1)\n\n  await asyncio.sleep(4)\n  price_alert1 = f\"the price for {stock_symbol} is 400\"\n  yield price_alert1\n  print(price_alert1)\n\n  await asyncio.sleep(20)\n  price_alert1 = f\"the price for {stock_symbol} is 900\"\n  yield price_alert1\n  print(price_alert1)\n\n  await asyncio.sleep(20)\n  price_alert1 = f\"the price for {stock_symbol} is 500\"\n  yield price_alert1\n  print(price_alert1)\n\n\n# for video streaming, `input_stream: LiveRequestQueue` is required and reserved key parameter for ADK to pass the video streams in.\nasync def monitor_video_stream(\n    input_stream: LiveRequestQueue,\n) -> AsyncGenerator[str, None]:\n  \"\"\"Monitor how many people are in the video streams.\"\"\"\n  print(\"start monitor_video_stream!\")\n  client = Client(vertexai=False)\n  prompt_text = (\n      \"Count the number of people in this image. Just respond with a numeric\"\n      \" number.\"\n  )\n  last_count = None\n  while True:\n    last_valid_req = None\n    print(\"Start monitoring loop\")\n\n    # use this loop to pull the latest images and discard the old ones\n    while input_stream._queue.qsize() != 0:\n      live_req = await input_stream.get()\n\n      if live_req.blob is not None and live_req.blob.mime_type == \"image/jpeg\":\n        last_valid_req = live_req\n\n    # If we found a valid image, process it\n    if last_valid_req is not None:\n      print(\"Processing the most recent frame from the queue\")\n\n      # Create an image part using the blob's data and mime type\n      image_part = genai_types.Part.from_bytes(\n          data=last_valid_req.blob.data, mime_type=last_valid_req.blob.mime_type\n      )\n\n      contents = genai_types.Content(\n          role=\"user\",\n          parts=[image_part, genai_types.Part.from_text(prompt_text)],\n      )\n\n      # Call the model to generate content based on the provided image and prompt\n      response = client.models.generate_content(\n          model=\"gemini-2.0-flash-exp\",\n          contents=contents,\n          config=genai_types.GenerateContentConfig(\n              system_instruction=(\n                  \"You are a helpful video analysis assistant. You can count\"\n                  \" the number of people in this image or video. Just respond\"\n                  \" with a numeric number.\"\n              )\n          ),\n      )\n      if not last_count:\n        last_count = response.candidates[0].content.parts[0].text\n      elif last_count != response.candidates[0].content.parts[0].text:\n        last_count = response.candidates[0].content.parts[0].text\n        yield response\n        print(\"response:\", response)\n\n    # Wait before checking for new images\n    await asyncio.sleep(0.5)\n\n\n# Use this exact function to help ADK stop your streaming tools when requested.\n# for example, if we want to stop `monitor_stock_price`, then the agent will\n# invoke this function with stop_streaming(function_name=monitor_stock_price).\ndef stop_streaming(function_name: str):\n  \"\"\"Stop the streaming\n\n  Args:\n    function_name: The name of the streaming function to stop.\n  \"\"\"\n  pass\n\n\nroot_agent = Agent(\n    model=\"gemini-2.0-flash-exp\",\n    name=\"video_streaming_agent\",\n    instruction=\"\"\"\n      You are a monitoring agent. You can do video monitoring and stock price monitoring\n      using the provided tools/functions.\n      When users want to monitor a video stream,\n      You can use monitor_video_stream function to do that. When monitor_video_stream\n      returns the alert, you should tell the users.\n      When users want to monitor a stock price, you can use monitor_stock_price.\n      Don't ask too many questions. Don't be too talkative.\n    \"\"\",\n    tools=[\n        monitor_video_stream,\n        monitor_stock_price,\n        FunctionTool(stop_streaming),\n    ]\n)"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:46.428763", "source_type": "adk-docs"}
{"doc_id": "f743167a3d17dc6121aa0652d97d3ac95fb953ac4fb68e34a827d193bedd23b4", "url": "https://google.github.io/adk-docs/streaming/configuration", "title": "Configurating Bidi-streaming behaviour - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Configurating streaming behaviour\u00b6"], "text": "Configurating streaming behaviour \u00b6 Supported in ADK Python v0.5.0 Experimental There are some configurations you can set for live(streaming) agents. It's set by RunConfig . You should use RunConfig with your Runner.run_live(...) . For example, if you want to set voice config, you can leverage speech_config. voice_config = genai_types . VoiceConfig ( prebuilt_voice_config = genai_types . PrebuiltVoiceConfigDict ( voice_name = 'Aoede' ) ) speech_config = genai_types . SpeechConfig ( voice_config = voice_config ) run_config = RunConfig ( speech_config = speech_config ) runner . run_live ( ... , run_config = run_config , ) Back to top ", "code_blocks": [{"language": "text", "code": "voice_config = genai_types.VoiceConfig(\n    prebuilt_voice_config=genai_types.PrebuiltVoiceConfigDict(\n        voice_name='Aoede'\n    )\n)\nspeech_config = genai_types.SpeechConfig(voice_config=voice_config)\nrun_config = RunConfig(speech_config=speech_config)\n\nrunner.run_live(\n    ...,\n    run_config=run_config,\n)"}]}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:46.848702", "source_type": "adk-docs"}
{"doc_id": "c2d365c8e8e94ebbfac1b031e4360535f96b1e8ec4e2dd61c760c68ebb4815b2", "url": "https://google.github.io/adk-docs/grounding/google_search_grounding", "title": "Understanding Google Search Grounding - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Understanding Google Search Grounding\u00b6"], "text": "Understanding Google Search Grounding \u00b6 Google Search Grounding tool is a powerful feature in the Agent Development Kit (ADK) that enables AI agents to access real-time, authoritative information from the web. By connecting your agents to Google Search, you can provide users with up-to-date answers backed by reliable sources. This feature is particularly valuable for queries requiring current information like weather updates, news events, stock prices, or any facts that may have changed since the model's training data cutoff. When your agent determines that external information is needed, it automatically performs web searches and incorporates the results into its response with proper attribution. ", "code_blocks": []}, {"heading_path": ["What You'll Learn\u00b6"], "text": "What You'll Learn \u00b6 In this guide, you'll discover: Quick Setup : How to create and run a Google Search-enabled agent from scratch Grounding Architecture : The data flow and technical process behind web grounding Response Structure : How to interpret grounded responses and their metadata Best Practices : Guidelines for displaying search results and citations to users ", "code_blocks": []}, {"heading_path": ["Additional resource\u00b6"], "text": "Additional resource \u00b6 As an additional resource, Gemini Fullstack Agent Development Kit (ADK) Quickstart has a great practical use of the Google Search grounding as a full stack application example. ", "code_blocks": []}, {"heading_path": ["Google Search Grounding Quickstart\u00b6"], "text": "Google Search Grounding Quickstart \u00b6 This quickstart guides you through creating an ADK agent with Google Search grounding feature. This quickstart assumes a local IDE (VS Code or PyCharm, etc.) with Python 3.9+ and terminal access. ", "code_blocks": []}, {"heading_path": ["1. Set up Environment & Install ADK\u00b6"], "text": "1. Set up Environment & Install ADK \u00b6 Create & Activate Virtual Environment: # Create python -m venv .venv # Activate (each new terminal) # macOS/Linux: source .venv/bin/activate # Windows CMD: .venv\\Scripts\\activate.bat # Windows PowerShell: .venv\\Scripts\\Activate.ps1 Install ADK: pip install google-adk == 1 .4.2 ", "code_blocks": [{"language": "text", "code": "# Create\npython -m venv .venv\n\n# Activate (each new terminal)\n# macOS/Linux: source .venv/bin/activate\n# Windows CMD: .venv\\Scripts\\activate.bat\n# Windows PowerShell: .venv\\Scripts\\Activate.ps1"}, {"language": "text", "code": "pip install google-adk==1.4.2"}]}, {"heading_path": ["2. Create Agent Project\u00b6"], "text": "2. Create Agent Project \u00b6 Under a project directory, run the following commands: OS X & Linux Windows # Step 1: Create a new directory for your agent mkdir google_search_agent # Step 2: Create __init__.py for the agent echo \"from . import agent\" > google_search_agent/__init__.py # Step 3: Create an agent.py (the agent definition) and .env (Gemini authentication config) touch google_search_agent/agent.py .env # Step 1: Create a new directory for your agent mkdir google_search_agent # Step 2: Create __init__.py for the agent echo \"from . import agent\" > google_search_agent/__init__.py # Step 3: Create an agent.py (the agent definition) and .env (Gemini authentication config) type nul > google_search_agent \\a gent.py type nul > google_search_agent \\. env ", "code_blocks": [{"language": "text", "code": "# Step 1: Create a new directory for your agent\nmkdir google_search_agent\n\n# Step 2: Create __init__.py for the agent\necho \"from . import agent\" > google_search_agent/__init__.py\n\n# Step 3: Create an agent.py (the agent definition) and .env (Gemini authentication config)\ntouch google_search_agent/agent.py .env"}, {"language": "text", "code": "# Step 1: Create a new directory for your agent\nmkdir google_search_agent\n\n# Step 2: Create __init__.py for the agent\necho \"from . import agent\" > google_search_agent/__init__.py\n\n# Step 3: Create an agent.py (the agent definition) and .env (Gemini authentication config)\ntype nul > google_search_agent\\agent.py \ntype nul > google_search_agent\\.env"}]}, {"heading_path": ["Edit agent.py\u00b6"], "text": "Edit agent.py \u00b6 Copy and paste the following code into agent.py : google_search_agent/agent.py from google.adk.agents import Agent from google.adk.tools import google_search root_agent = Agent ( name = \"google_search_agent\" , model = \"gemini-2.5-flash\" , instruction = \"Answer questions using Google Search when needed. Always cite sources.\" , description = \"Professional search assistant with Google Search capabilities\" , tools = [ google_search ] ) Now you would have the following directory structure: my_project/ google_search_agent/ __init__.py agent.py .env ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools import google_search\n\nroot_agent = Agent(\n    name=\"google_search_agent\",\n    model=\"gemini-2.5-flash\",\n    instruction=\"Answer questions using Google Search when needed. Always cite sources.\",\n    description=\"Professional search assistant with Google Search capabilities\",\n    tools=[google_search]\n)"}, {"language": "text", "code": "my_project/\n    google_search_agent/\n        __init__.py\n        agent.py\n    .env"}]}, {"heading_path": ["3. Choose a platform\u00b6"], "text": "3. Choose a platform \u00b6 To run the agent, you need to select a platform that the agent will use for calling the Gemini model. Choose one from Google AI Studio or Vertex AI: Gemini - Google AI Studio Gemini - Google Cloud Vertex AI Get an API key from Google AI Studio . When using Python, open the .env file and copy-paste the following code. .env GOOGLE_GENAI_USE_VERTEXAI=FALSE GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE Replace PASTE_YOUR_ACTUAL_API_KEY_HERE with your actual API KEY . You need an existing Google Cloud account and a\nproject. Set up a Google Cloud project Set up the gcloud CLI Authenticate to Google Cloud, from the terminal by running gcloud auth login . Enable the Vertex AI API . When using Python, open the .env file and copy-paste the following code and update the project ID and location. .env GOOGLE_GENAI_USE_VERTEXAI=TRUE GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID GOOGLE_CLOUD_LOCATION=LOCATION ", "code_blocks": [{"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=FALSE\nGOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=TRUE\nGOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID\nGOOGLE_CLOUD_LOCATION=LOCATION"}]}, {"heading_path": ["4. Run Your Agent\u00b6"], "text": "4. Run Your Agent \u00b6 There are multiple ways to interact with your agent: Dev UI (adk web) Terminal (adk run) Run the following command to launch the dev UI . adk web Note for Windows users When hitting the _make_subprocess_transport NotImplementedError , consider using adk web --no-reload instead. Step 1: Open the URL provided (usually http://localhost:8000 or http://127.0.0.1:8000 ) directly in your browser. Step 2. In the top-left corner of the UI, you can select your agent in\nthe dropdown. Select \"google_search_agent\". Troubleshooting If you do not see \"google_search_agent\" in the dropdown menu, make sure you\nare running adk web in the parent folder of your agent folder\n(i.e. the parent folder of google_search_agent). Step 3. Now you can chat with your agent using the textbox. Run the following command, to chat with your Weather agent. adk run google_search_agent To exit, use Cmd/Ctrl+C. ", "code_blocks": [{"language": "text", "code": "adk web"}, {"language": "text", "code": "adk run google_search_agent"}]}, {"heading_path": ["\ud83d\udcdd Example prompts to try\u00b6"], "text": "\ud83d\udcdd Example prompts to try \u00b6 With those questions, you can confirm that the agent is actually calling Google Search\nto get the latest weather and time. What is the weather in New York? What is the time in New York? What is the weather in Paris? What is the time in Paris? You've successfully created and interacted with your Google Search agent using ADK! ", "code_blocks": []}, {"heading_path": ["How grounding with Google Search works\u00b6"], "text": "How grounding with Google Search works \u00b6 Grounding is the process that connects your agent to real-time information from the web, allowing it to generate more accurate and current responses. When a user's prompt requires information that the model was not trained on, or that is time-sensitive, the agent's underlying Large Language Model intelligently decides to invoke the google_search tool to find the relevant facts ", "code_blocks": []}, {"heading_path": ["Data Flow Diagram\u00b6"], "text": "Data Flow Diagram \u00b6 This diagram illustrates the step-by-step process of how a user query results in a grounded response. ", "code_blocks": []}, {"heading_path": ["Detailed Description\u00b6"], "text": "Detailed Description \u00b6 The grounding agent uses the data flow described in the diagram to retrieve, process, and incorporate external information into the final answer presented to the user. User Query : An end-user interacts with your agent by asking a question or giving a command. ADK Orchestration : The Agent Development Kit orchestrates the agent's behavior and passes the user's message to the core of your agent. LLM Analysis and Tool-Calling : The agent's LLM (e.g., a Gemini model) analyzes the prompt. If it determines that external, up-to-date information is required, it triggers the grounding mechanism by calling the google_search tool. This is ideal for answering queries about recent news, weather, or facts not present in the model's training data. Grounding Service Interaction : The google_search tool interacts with an internal grounding service that formulates and sends one or more queries to the Google Search Index. Context Injection : The grounding service retrieves the relevant web pages and snippets. It then integrates these search results into the model's context before the final response is generated. This crucial step allows the model to \"reason\" over factual, real-time data. Grounded Response Generation : The LLM, now informed by the fresh search results, generates a response that incorporates the retrieved information. Response Presentation with Sources : The ADK receives the final grounded response, which includes the necessary source URLs and groundingMetadata, and presents it to the user with attribution. This allows end-users to verify the information and builds trust in the agent's answers. ", "code_blocks": []}, {"heading_path": ["Understanding grounding with Google Search response\u00b6"], "text": "Understanding grounding with Google Search response \u00b6 When the agent uses Google Search to ground a response, it returns a detailed set of information that includes not only the final text answer but also the sources it used to generate that answer. This metadata is crucial for verifying the response and for providing attribution to the original sources. ", "code_blocks": []}, {"heading_path": ["Example of a Grounded Response\u00b6"], "text": "Example of a Grounded Response \u00b6 The following is an example of the content object returned by the model after a grounded query. Final Answer Text: \"Yes, Inter Miami won their last game in the FIFA Club World Cup. They defeated FC Porto 2-1 in their second group stage match. Their first game in the tournament was a 0-0 draw against Al Ahly FC. Inter Miami is scheduled to play their third group stage match against Palmeiras on Monday, June 23, 2025.\" Grounding Metadata Snippet: \"groundingMetadata\" : { \"groundingChunks\" : [ { \"web\" : { \"title\" : \"mlssoccer.com\" , \"uri\" : \"...\" } }, { \"web\" : { \"title\" : \"intermiamicf.com\" , \"uri\" : \"...\" } }, { \"web\" : { \"title\" : \"mlssoccer.com\" , \"uri\" : \"...\" } } ], \"groundingSupports\" : [ { \"groundingChunkIndices\" : [ 0 , 1 ], \"segment\" : { \"startIndex\" : 65 , \"endIndex\" : 126 , \"text\" : \"They defeated FC Porto 2-1 in their second group stage match.\" } }, { \"groundingChunkIndices\" : [ 1 ], \"segment\" : { \"startIndex\" : 127 , \"endIndex\" : 196 , \"text\" : \"Their first game in the tournament was a 0-0 draw against Al Ahly FC.\" } }, { \"groundingChunkIndices\" : [ 0 , 2 ], \"segment\" : { \"startIndex\" : 197 , \"endIndex\" : 303 , \"text\" : \"Inter Miami is scheduled to play their third group stage match against Palmeiras on Monday, June 23, 2025.\" } } ], \"searchEntryPoint\" : { ... } } ", "code_blocks": [{"language": "text", "code": "\"Yes, Inter Miami won their last game in the FIFA Club World Cup. They defeated FC Porto 2-1 in their second group stage match. Their first game in the tournament was a 0-0 draw against Al Ahly FC. Inter Miami is scheduled to play their third group stage match against Palmeiras on Monday, June 23, 2025.\""}, {"language": "text", "code": "\"groundingMetadata\": {\n  \"groundingChunks\": [\n    { \"web\": { \"title\": \"mlssoccer.com\", \"uri\": \"...\" } },\n    { \"web\": { \"title\": \"intermiamicf.com\", \"uri\": \"...\" } },\n    { \"web\": { \"title\": \"mlssoccer.com\", \"uri\": \"...\" } }\n  ],\n  \"groundingSupports\": [\n    {\n      \"groundingChunkIndices\": [0, 1],\n      \"segment\": {\n        \"startIndex\": 65,\n        \"endIndex\": 126,\n        \"text\": \"They defeated FC Porto 2-1 in their second group stage match.\"\n      }\n    },\n    {\n      \"groundingChunkIndices\": [1],\n      \"segment\": {\n        \"startIndex\": 127,\n        \"endIndex\": 196,\n        \"text\": \"Their first game in the tournament was a 0-0 draw against Al Ahly FC.\"\n      }\n    },\n    {\n      \"groundingChunkIndices\": [0, 2],\n      \"segment\": {\n        \"startIndex\": 197,\n        \"endIndex\": 303,\n        \"text\": \"Inter Miami is scheduled to play their third group stage match against Palmeiras on Monday, June 23, 2025.\"\n      }\n    }\n  ],\n  \"searchEntryPoint\": { ... }\n}"}]}, {"heading_path": ["How to Interpret the Response\u00b6"], "text": "How to Interpret the Response \u00b6 The metadata provides a link between the text generated by the model and the sources that support it. Here is a step-by-step breakdown: groundingChunks : This is a list of the web pages the model consulted. Each chunk contains the title of the webpage and a uri that links to the source. groundingSupports : This list connects specific sentences in the final answer back to the groundingChunks. segment : This object identifies a specific portion of the final text answer, defined by its startIndex, endIndex, and the text itself. groundingChunkIndices : This array contains the index numbers that correspond to the sources listed in the groundingChunks. For example, the sentence \"They defeated FC Porto 2-1...\" is supported by information from groundingChunks at index 0 and 1 (both from mlssoccer.com and intermiamicf.com). ", "code_blocks": []}, {"heading_path": ["How to display grounding responses with Google Search\u00b6"], "text": "How to display grounding responses with Google Search \u00b6 A critical part of using grounding is to correctly display the information, including citations and search suggestions, to the end-user. This builds trust and allows users to verify the information. ", "code_blocks": []}, {"heading_path": ["Displaying Search Suggestions\u00b6"], "text": "Displaying Search Suggestions \u00b6 The searchEntryPoint object in the groundingMetadata contains pre-formatted HTML for displaying search query suggestions. As seen in the example image, these are typically rendered as clickable chips that allow the user to explore related topics. Rendered HTML from searchEntryPoint: The metadata provides the necessary HTML and CSS to render the search suggestions bar, which includes the Google logo and chips for related queries like \"When is the next FIFA Club World Cup\" and \"Inter Miami FIFA Club World Cup history\". Integrating this HTML directly into your application's front end will display the suggestions as intended. For more information, consult using Google Search Suggestions in Vertex AI documentation. ", "code_blocks": []}, {"heading_path": ["Summary\u00b6"], "text": "Summary \u00b6 Google Search Grounding transforms AI agents from static knowledge repositories into dynamic, web-connected assistants capable of providing real-time, accurate information. By integrating this feature into your ADK agents, you enable them to: Access current information beyond their training data Provide source attribution for transparency and trust Deliver comprehensive answers with verifiable facts Enhance user experience with relevant search suggestions The grounding process seamlessly connects user queries to Google's vast search index, enriching responses with up-to-date context while maintaining the conversational flow. With proper implementation and display of grounded responses, your agents become powerful tools for information discovery and decision-making. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:47.383081", "source_type": "adk-docs"}
{"doc_id": "413083088c51b98d6922c2d214b99e89a0e9158f58982c17db345023dc246154", "url": "https://google.github.io/adk-docs/grounding/vertex_ai_search_grounding", "title": "Understanding Vertex AI Search Grounding - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Understanding Vertex AI Search Grounding\u00b6"], "text": "Understanding Vertex AI Search Grounding \u00b6 Vertex AI Search Grounding tool is a powerful feature in the Agent Development Kit (ADK) that enables AI agents to access information from your private enterprise documents and data repositories. By connecting your agents to indexed enterprise content, you can provide users with answers grounded in your organization's knowledge base. This feature is particularly valuable for enterprise-specific queries requiring information from internal documentation, policies, research papers, or any proprietary content that has been indexed in your Vertex AI Search datastore. When your agent determines that information from your knowledge base is needed, it automatically searches your indexed documents and incorporates the results into its response with proper attribution. ", "code_blocks": []}, {"heading_path": ["What You'll Learn\u00b6"], "text": "What You'll Learn \u00b6 In this guide, you'll discover: Quick Setup : How to create and run a Vertex AI Search-enabled agent from scratch Grounding Architecture : The data flow and technical process behind enterprise document grounding Response Structure : How to interpret grounded responses and their metadata Best Practices : Guidelines for displaying citations and document references to users ", "code_blocks": []}, {"heading_path": ["Vertex AI Search Grounding Quickstart\u00b6"], "text": "Vertex AI Search Grounding Quickstart \u00b6 This quickstart guides you through creating an ADK agent with Vertex AI Search grounding feature. This quickstart assumes a local IDE (VS Code or PyCharm, etc.) with Python 3.9+ and terminal access. ", "code_blocks": []}, {"heading_path": ["1. Prepare Vertex AI Search\u00b6"], "text": "1. Prepare Vertex AI Search \u00b6 If you already have a Vertex AI Search Data Store and its Data Store ID, you can skip this section. If not, follow the instruction in the Get started with custom search until the end of Create a data store , with selecting the Unstructured data tab. With this instruction, you will build a sample Data Store with earning report PDFs from the Alphabet investor site . After finishing the Create a data store section, open the Data Stores and select the data store you created, and find the Data store ID : Note this Data store ID as we will use this later. ", "code_blocks": []}, {"heading_path": ["2. Set up Environment & Install ADK\u00b6"], "text": "2. Set up Environment & Install ADK \u00b6 Create & Activate Virtual Environment: # Create python -m venv .venv # Activate (each new terminal) # macOS/Linux: source .venv/bin/activate # Windows CMD: .venv\\Scripts\\activate.bat # Windows PowerShell: .venv\\Scripts\\Activate.ps1 Install ADK: pip install google-adk == 1 .5.0 ", "code_blocks": [{"language": "text", "code": "# Create\npython -m venv .venv\n\n# Activate (each new terminal)\n# macOS/Linux: source .venv/bin/activate\n# Windows CMD: .venv\\Scripts\\activate.bat\n# Windows PowerShell: .venv\\Scripts\\Activate.ps1"}, {"language": "text", "code": "pip install google-adk==1.5.0"}]}, {"heading_path": ["3. Create Agent Project\u00b6"], "text": "3. Create Agent Project \u00b6 Under a project directory, run the following commands: OS X & Linux Windows # Step 1: Create a new directory for your agent mkdir vertex_search_agent # Step 2: Create __init__.py for the agent echo \"from . import agent\" > vertex_search_agent/__init__.py # Step 3: Create an agent.py (the agent definition) and .env (authentication config) touch vertex_search_agent/agent.py .env # Step 1: Create a new directory for your agent mkdir vertex_search_agent # Step 2: Create __init__.py for the agent echo \"from . import agent\" > vertex_search_agent/__init__.py # Step 3: Create an agent.py (the agent definition) and .env (authentication config) type nul > vertex_search_agent \\a gent.py type nul > google_search_agent \\. env ", "code_blocks": [{"language": "text", "code": "# Step 1: Create a new directory for your agent\nmkdir vertex_search_agent\n\n# Step 2: Create __init__.py for the agent\necho \"from . import agent\" > vertex_search_agent/__init__.py\n\n# Step 3: Create an agent.py (the agent definition) and .env (authentication config)\ntouch vertex_search_agent/agent.py .env"}, {"language": "text", "code": "# Step 1: Create a new directory for your agent\nmkdir vertex_search_agent\n\n# Step 2: Create __init__.py for the agent\necho \"from . import agent\" > vertex_search_agent/__init__.py\n\n# Step 3: Create an agent.py (the agent definition) and .env (authentication config)\ntype nul > vertex_search_agent\\agent.py \ntype nul > google_search_agent\\.env"}]}, {"heading_path": ["Edit agent.py\u00b6"], "text": "Edit agent.py \u00b6 Copy and paste the following code into agent.py , and replace YOUR_PROJECT_ID and YOUR_DATASTORE_ID at the Configuration part with your project ID and Data Store ID accordingly: vertex_search_agent/agent.py from google.adk.agents import Agent from google.adk.tools import VertexAiSearchTool # Configuration DATASTORE_ID = \"projects/YOUR_PROJECT_ID/locations/global/collections/default_collection/dataStores/YOUR_DATASTORE_ID\" root_agent = Agent ( name = \"vertex_search_agent\" , model = \"gemini-2.5-flash\" , instruction = \"Answer questions using Vertex AI Search to find information from internal documents. Always cite sources when available.\" , description = \"Enterprise document search assistant with Vertex AI Search capabilities\" , tools = [ VertexAiSearchTool ( data_store_id = DATASTORE_ID )] ) Now you would have the following directory structure: my_project/ vertex_search_agent/ __init__.py agent.py .env ", "code_blocks": [{"language": "text", "code": "from google.adk.agents import Agent\nfrom google.adk.tools import VertexAiSearchTool\n\n# Configuration\nDATASTORE_ID = \"projects/YOUR_PROJECT_ID/locations/global/collections/default_collection/dataStores/YOUR_DATASTORE_ID\"\n\nroot_agent = Agent(\n    name=\"vertex_search_agent\",\n    model=\"gemini-2.5-flash\",\n    instruction=\"Answer questions using Vertex AI Search to find information from internal documents. Always cite sources when available.\",\n    description=\"Enterprise document search assistant with Vertex AI Search capabilities\",\n    tools=[VertexAiSearchTool(data_store_id=DATASTORE_ID)]\n)"}, {"language": "text", "code": "my_project/\n    vertex_search_agent/\n        __init__.py\n        agent.py\n    .env"}]}, {"heading_path": ["4. Authentication Setup\u00b6"], "text": "4. Authentication Setup \u00b6 Note: Vertex AI Search requires Google Cloud Platform (Vertex AI) authentication. Google AI Studio is not supported for this tool. Set up the gcloud CLI Authenticate to Google Cloud, from the terminal by running gcloud auth login . Open the .env file and copy-paste the following code and update the project ID and location. .env GOOGLE_GENAI_USE_VERTEXAI=TRUE GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID GOOGLE_CLOUD_LOCATION=LOCATION ", "code_blocks": [{"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=TRUE\nGOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID\nGOOGLE_CLOUD_LOCATION=LOCATION"}]}, {"heading_path": ["5. Run Your Agent\u00b6"], "text": "5. Run Your Agent \u00b6 There are multiple ways to interact with your agent: Dev UI (adk web) Terminal (adk run) Run the following command to launch the dev UI . adk web Note for Windows users When hitting the _make_subprocess_transport NotImplementedError , consider using adk web --no-reload instead. Step 1: Open the URL provided (usually http://localhost:8000 or http://127.0.0.1:8000 ) directly in your browser. Step 2. In the top-left corner of the UI, you can select your agent in\nthe dropdown. Select \"vertex_search_agent\". Troubleshooting If you do not see \"vertex_search_agent\" in the dropdown menu, make sure you\nare running adk web in the parent folder of your agent folder\n(i.e. the parent folder of vertex_search_agent). Step 3. Now you can chat with your agent using the textbox. Run the following command, to chat with your Vertex AI Search agent. adk run vertex_search_agent To exit, use Cmd/Ctrl+C. ", "code_blocks": [{"language": "text", "code": "adk web"}, {"language": "text", "code": "adk run vertex_search_agent"}]}, {"heading_path": ["\ud83d\udcdd Example prompts to try\u00b6"], "text": "\ud83d\udcdd Example prompts to try \u00b6 With those questions, you can confirm that the agent is actually calling Vertex AI Search\nto get information from the Alphabet reports: What is the revenue of Google Cloud in 2022 Q1? What about YouTube? You've successfully created and interacted with your Vertex AI Search agent using ADK! ", "code_blocks": []}, {"heading_path": ["How grounding with Vertex AI Search works\u00b6"], "text": "How grounding with Vertex AI Search works \u00b6 Grounding with Vertex AI Search is the process that connects your agent to your organization's indexed documents and data, allowing it to generate accurate responses based on private enterprise content. When a user's prompt requires information from your internal knowledge base, the agent's underlying LLM intelligently decides to invoke the VertexAiSearchTool to find relevant facts from your indexed documents. ", "code_blocks": []}, {"heading_path": ["Data Flow Diagram\u00b6"], "text": "Data Flow Diagram \u00b6 This diagram illustrates the step-by-step process of how a user query results in a grounded response. ", "code_blocks": []}, {"heading_path": ["Detailed Description\u00b6"], "text": "Detailed Description \u00b6 The grounding agent uses the data flow described in the diagram to retrieve, process, and incorporate enterprise information into the final answer presented to the user. User Query : An end-user interacts with your agent by asking a question about internal documents or enterprise data. ADK Orchestration : The Agent Development Kit orchestrates the agent's behavior and passes the user's message to the core of your agent. LLM Analysis and Tool-Calling : The agent's LLM (e.g., a Gemini model) analyzes the prompt. If it determines that information from your indexed documents is required, it triggers the grounding mechanism by calling the VertexAiSearchTool. This is ideal for answering queries about company policies, technical documentation, or proprietary research. Vertex AI Search Service Interaction : The VertexAiSearchTool interacts with your configured Vertex AI Search datastore, which contains your indexed enterprise documents. The service formulates and executes search queries against your private content. Document Retrieval & Ranking : Vertex AI Search retrieves and ranks the most relevant document chunks from your datastore based on semantic similarity and relevance scoring. Context Injection : The search service integrates the retrieved document snippets into the model's context before the final response is generated. This crucial step allows the model to \"reason\" over your organization's factual data. Grounded Response Generation : The LLM, now informed by relevant enterprise content, generates a response that incorporates the retrieved information from your documents. Response Presentation with Sources : The ADK receives the final grounded response, which includes the necessary source document references and groundingMetadata, and presents it to the user with attribution. This allows end-users to verify the information against your enterprise sources. ", "code_blocks": []}, {"heading_path": ["Understanding grounding with Vertex AI Search response\u00b6"], "text": "Understanding grounding with Vertex AI Search response \u00b6 When the agent uses Vertex AI Search to ground a response, it returns detailed information that includes the final text answer and metadata about the documents used to generate that answer. This metadata is crucial for verifying the response and providing attribution to your enterprise sources. ", "code_blocks": []}, {"heading_path": ["Example of a Grounded Response\u00b6"], "text": "Example of a Grounded Response \u00b6 The following is an example of the content object returned by the model after a grounded query against enterprise documents. Final Answer Text: \"Developing models for a medical scribe presents several significant challenges, primarily due to the complex nature of medical documentation, the sensitive data involved, and the demanding requirements of clinical workflows. Key challenges include: **Accuracy and Reliability:** Medical documentation requires extremely high levels of accuracy, as errors can lead to misdiagnoses, incorrect treatments, and legal repercussions. Ensuring that AI models can reliably capture nuanced medical language, distinguish between subjective and objective information, and accurately transcribe physician-patient interactions is a major hurdle. **Natural Language Understanding (NLU) and Speech Recognition:** Medical conversations are often rapid, involve highly specialized jargon, acronyms, and abbreviations, and can be spoken by individuals with diverse accents or speech patterns... [response continues with detailed analysis of privacy, integration, and technical challenges]\" Grounding Metadata Snippet: This is the grounding metadata you will receive. On adk web , you can find this on the Response tab: { \"groundingMetadata\" : { \"groundingChunks\" : [ { \"document\" : { \"title\" : \"AI in Medical Scribing: Technical Challenges\" , \"uri\" : \"projects/your-project/locations/global/dataStores/your-datastore-id/documents/doc-medical-scribe-ai-tech-challenges\" , \"id\" : \"doc-medical-scribe-ai-tech-challenges\" } }, { \"document\" : { \"title\" : \"Regulatory and Ethical Hurdles for AI in Healthcare\" , \"uri\" : \"projects/your-project/locations/global/dataStores/your-datastore-id/documents/doc-ai-healthcare-ethics\" , \"id\" : \"doc-ai-healthcare-ethics\" } } // ... additional documents ], \"groundingSupports\" : [ { \"groundingChunkIndices\" : [ 0 , 1 ], \"segment\" : { \"endIndex\" : 637 , \"startIndex\" : 433 , \"text\" : \"Ensuring that AI models can reliably capture nuanced medical language...\" } } // ... additional supports linking text segments to source documents ], \"retrievalQueries\" : [ \"challenges in natural language processing medical domain\" , \"AI medical scribe challenges\" , \"difficulties in developing AI for medical scribes\" // ... additional search queries executed ] } } ", "code_blocks": [{"language": "text", "code": "\"Developing models for a medical scribe presents several significant challenges, primarily due to the complex nature of medical documentation, the sensitive data involved, and the demanding requirements of clinical workflows. Key challenges include: **Accuracy and Reliability:** Medical documentation requires extremely high levels of accuracy, as errors can lead to misdiagnoses, incorrect treatments, and legal repercussions. Ensuring that AI models can reliably capture nuanced medical language, distinguish between subjective and objective information, and accurately transcribe physician-patient interactions is a major hurdle. **Natural Language Understanding (NLU) and Speech Recognition:** Medical conversations are often rapid, involve highly specialized jargon, acronyms, and abbreviations, and can be spoken by individuals with diverse accents or speech patterns... [response continues with detailed analysis of privacy, integration, and technical challenges]\""}, {"language": "text", "code": "{\n  \"groundingMetadata\": {\n    \"groundingChunks\": [\n      {\n        \"document\": {\n          \"title\": \"AI in Medical Scribing: Technical Challenges\",\n          \"uri\": \"projects/your-project/locations/global/dataStores/your-datastore-id/documents/doc-medical-scribe-ai-tech-challenges\",\n          \"id\": \"doc-medical-scribe-ai-tech-challenges\"\n        }\n      },\n      {\n        \"document\": {\n          \"title\": \"Regulatory and Ethical Hurdles for AI in Healthcare\",\n          \"uri\": \"projects/your-project/locations/global/dataStores/your-datastore-id/documents/doc-ai-healthcare-ethics\",\n          \"id\": \"doc-ai-healthcare-ethics\"\n        }\n      }\n      // ... additional documents\n    ],\n    \"groundingSupports\": [\n      {\n        \"groundingChunkIndices\": [0, 1],\n        \"segment\": {\n          \"endIndex\": 637,\n          \"startIndex\": 433,\n          \"text\": \"Ensuring that AI models can reliably capture nuanced medical language...\"\n        }\n      }\n      // ... additional supports linking text segments to source documents\n    ],\n    \"retrievalQueries\": [\n      \"challenges in natural language processing medical domain\",\n      \"AI medical scribe challenges\",\n      \"difficulties in developing AI for medical scribes\"\n      // ... additional search queries executed\n    ]\n  }\n}"}]}, {"heading_path": ["How to Interpret the Response\u00b6"], "text": "How to Interpret the Response \u00b6 The metadata provides a link between the text generated by the model and the enterprise documents that support it. Here is a step-by-step breakdown: groundingChunks : This is a list of the enterprise documents the model consulted. Each chunk contains the document title, uri (document path), and id. groundingSupports : This list connects specific sentences in the final answer back to the groundingChunks . segment : This object identifies a specific portion of the final text answer, defined by its startIndex , endIndex , and the text itself. groundingChunkIndices : This array contains the index numbers that correspond to the sources listed in the groundingChunks . For example, the text about \"HIPAA compliance\" is supported by information from groundingChunks at index 1 (the \"Regulatory and Ethical Hurdles\" document). retrievalQueries : This array shows the specific search queries that were executed against your datastore to find relevant information. ", "code_blocks": []}, {"heading_path": ["How to display grounding responses with Vertex AI Search\u00b6"], "text": "How to display grounding responses with Vertex AI Search \u00b6 Unlike Google Search grounding, Vertex AI Search grounding does not require specific display components. However, displaying citations and document references builds trust and allows users to verify information against your organization's authoritative sources. ", "code_blocks": []}, {"heading_path": ["Optional Citation Display\u00b6"], "text": "Optional Citation Display \u00b6 Since grounding metadata is provided, you can choose to implement citation displays based on your application needs: Simple Text Display (Minimal Implementation): for event in events : if event . is_final_response (): print ( event . content . parts [ 0 ] . text ) # Optional: Show source count if event . grounding_metadata : print ( f \" \\n Based on { len ( event . grounding_metadata . grounding_chunks ) } documents\" ) Enhanced Citation Display (Optional): You can implement interactive citations that show which documents support each statement. The grounding metadata provides all necessary information to map text segments to source documents. ", "code_blocks": [{"language": "text", "code": "for event in events:\n    if event.is_final_response():\n        print(event.content.parts[0].text)\n\n        # Optional: Show source count\n        if event.grounding_metadata:\n            print(f\"\\nBased on {len(event.grounding_metadata.grounding_chunks)} documents\")"}]}, {"heading_path": ["Implementation Considerations\u00b6"], "text": "Implementation Considerations \u00b6 When implementing Vertex AI Search grounding displays: Document Access : Verify user permissions for referenced documents Simple Integration : Basic text output requires no additional display logic Optional Enhancements : Add citations only if your use case benefits from source attribution Document Links : Convert document URIs to accessible internal links when needed Search Queries : The retrievalQueries array shows what searches were performed against your datastore ", "code_blocks": []}, {"heading_path": ["Summary\u00b6"], "text": "Summary \u00b6 Vertex AI Search Grounding transforms AI agents from general-purpose assistants into enterprise-specific knowledge systems capable of providing accurate, source-attributed information from your organization's private documents. By integrating this feature into your ADK agents, you enable them to: Access proprietary information from your indexed document repositories Provide source attribution for transparency and trust Deliver comprehensive answers with verifiable enterprise facts Maintain data privacy within your Google Cloud environment The grounding process seamlessly connects user queries to your organization's knowledge base, enriching responses with relevant context from your private documents while maintaining the conversational flow. With proper implementation, your agents become powerful tools for enterprise information discovery and decision-making. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:48.036320", "source_type": "adk-docs"}
{"doc_id": "da589c8bce127b31807de9e2b461999e0f0b099b38f63f7660d9d8f327c9b054", "url": "https://google.github.io/adk-docs/api-reference", "title": "API Reference - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["API Reference\u00b6"], "text": "API Reference \u00b6 The Agent Development Kit (ADK) provides comprehensive API references for both Python and Java, allowing you to dive deep into all available classes, methods, and functionalities. ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. Python API Reference Explore the complete API documentation for the Python Agent Development Kit. Discover detailed information on all modules, classes, functions, and examples to build sophisticated AI agents with Python. View Python API Docs Assuming your Python API docs are in a 'python' subdirectory Or link to an external ReadTheDocs, etc. <a href=\"python/index.html\">\u0002klzzwxh:0004\u0003 View Python API Docs</a> This comment forces a block separation ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. Go API Reference Explore the complete API documentation for the Go Agent Development Kit. Discover detailed information on all modules, classes, and functions to build sophisticated AI agents with Go. View Go API Docs This comment forces a block separation ! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. Java API Reference Access the comprehensive Javadoc for the Java Agent Development Kit. This reference provides detailed specifications for all packages, classes, interfaces, and methods, enabling you to develop robust AI agents using Java. View Java API Docs Assuming your Java API docs (Javadocs) are in a 'java' subdirectory Or link to an external Javadoc hosting site <a href=\"java/index.html\">\u0002klzzwxh:0019\u0003 View Java API Docs</a> This comment forces a block separation CLI Reference Explore the complete API documentation for the CLI including all of the \nvalid options and subcommands. View CLI Docs This comment forces a block separation Agent Config YAML reference View the full Agent Config syntax for configuring ADK with \nYAML text files. View Agent Config reference This comment forces a block separation REST API Reference Explore the REST API for the ADK web server. This reference provides details on the available endpoints, request and response formats, and more. View REST API Docs Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:48.350367", "source_type": "adk-docs"}
{"doc_id": "fd7af23ad271b40276c609d76a6726952f0fd8bdc1c15e7f7b192b220446be87", "url": "https://google.github.io/adk-docs/api-reference/python", "title": "Agent Development Kit documentation", "sections": [{"heading_path": [], "text": "Contents Menu Expand Light mode Dark mode Auto light/dark, in light mode Auto light/dark, in dark mode Hide navigation sidebar Hide table of contents sidebar Skip to content Agent Development Kit  documentation Submodules google.adk.a2a module google.adk.agents module google.adk.artifacts module google.adk.apps package google.adk.auth module google.adk.cli module google.adk.code_executors module google.adk.errors module google.adk.evaluation module google.adk.events module google.adk.examples module google.adk.flows module google.adk.memory module google.adk.models module google.adk.planners module google.adk.platform module google.adk.plugins module google.adk.runners module google.adk.sessions module google.adk.telemetry module google.adk.tools package google.adk.tools.agent_tool module google.adk.tools.apihub_tool module google.adk.tools.application_integration_tool module google.adk.tools.authenticated_function_tool module google.adk.tools.base_authenticated_tool module google.adk.tools.base_tool module google.adk.tools.base_toolset module google.adk.tools.bigquery module google.adk.tools.crewai_tool module google.adk.tools.enterprise_search_tool module google.adk.tools.example_tool module google.adk.tools.exit_loop_tool module google.adk.tools.function_tool module google.adk.tools.get_user_choice_tool module google.adk.tools.google_api_tool module google.adk.tools.google_maps_grounding_tool module google.adk.tools.google_search_tool module google.adk.tools.langchain_tool module google.adk.tools.load_artifacts_tool module google.adk.tools.load_memory_tool module google.adk.tools.load_web_page module google.adk.tools.long_running_tool module google.adk.tools.mcp_tool module google.adk.tools.openapi_tool module google.adk.tools.preload_memory_tool module google.adk.tools.retrieval module google.adk.tools.tool_context module google.adk.tools.toolbox_toolset module google.adk.tools.transfer_to_agent_tool module google.adk.tools.url_context_tool module google.adk.tools.vertex_ai_search_tool module google.adk.utils module google.adk.version module Back to top View this page Toggle Light / Dark / Auto color theme Toggle table of contents sidebar ", "code_blocks": []}, {"heading_path": ["google\u00b6"], "text": "google \u00b6 Submodules google.adk.a2a module google.adk.agents module Agent BaseAgent BaseAgent.after_agent_callback BaseAgent.before_agent_callback BaseAgent.description BaseAgent.name BaseAgent.parent_agent BaseAgent.sub_agents BaseAgent.config_type BaseAgent.from_config() BaseAgent.validate_name BaseAgent.clone() BaseAgent.find_agent() BaseAgent.find_sub_agent() BaseAgent.model_post_init() BaseAgent.run_async() BaseAgent.run_live() BaseAgent.canonical_after_agent_callbacks BaseAgent.canonical_before_agent_callbacks BaseAgent.root_agent InvocationContext InvocationContext.active_streaming_tools InvocationContext.agent InvocationContext.agent_states InvocationContext.artifact_service InvocationContext.branch InvocationContext.context_cache_config InvocationContext.credential_service InvocationContext.end_invocation InvocationContext.end_of_agents InvocationContext.input_realtime_cache InvocationContext.invocation_id InvocationContext.live_request_queue InvocationContext.live_session_resumption_handle InvocationContext.memory_service InvocationContext.output_realtime_cache InvocationContext.plugin_manager InvocationContext.resumability_config InvocationContext.run_config InvocationContext.session InvocationContext.session_service InvocationContext.transcription_cache InvocationContext.user_content InvocationContext.increment_llm_call_count() InvocationContext.model_post_init() InvocationContext.populate_invocation_agent_states() InvocationContext.reset_sub_agent_states() InvocationContext.set_agent_state() InvocationContext.should_pause_invocation() InvocationContext.app_name InvocationContext.is_resumable InvocationContext.user_id LiveRequest LiveRequest.activity_end LiveRequest.activity_start LiveRequest.blob LiveRequest.close LiveRequest.content LiveRequestQueue LiveRequestQueue.close() LiveRequestQueue.get() LiveRequestQueue.send() LiveRequestQueue.send_activity_end() LiveRequestQueue.send_activity_start() LiveRequestQueue.send_content() LiveRequestQueue.send_realtime() LlmAgent LlmAgent.after_model_callback LlmAgent.after_tool_callback LlmAgent.before_model_callback LlmAgent.before_tool_callback LlmAgent.code_executor LlmAgent.disallow_transfer_to_parent LlmAgent.disallow_transfer_to_peers LlmAgent.generate_content_config LlmAgent.global_instruction LlmAgent.include_contents LlmAgent.input_schema LlmAgent.instruction LlmAgent.model LlmAgent.output_key LlmAgent.output_schema LlmAgent.planner LlmAgent.static_instruction LlmAgent.tools LlmAgent.config_type LlmAgent.validate_generate_content_config LlmAgent.canonical_global_instruction() LlmAgent.canonical_instruction() LlmAgent.canonical_tools() LlmAgent.canonical_after_model_callbacks LlmAgent.canonical_after_tool_callbacks LlmAgent.canonical_before_model_callbacks LlmAgent.canonical_before_tool_callbacks LlmAgent.canonical_model LoopAgent LoopAgent.max_iterations LoopAgent.config_type ParallelAgent ParallelAgent.config_type RunConfig RunConfig.context_window_compression RunConfig.enable_affective_dialog RunConfig.input_audio_transcription RunConfig.max_llm_calls RunConfig.output_audio_transcription RunConfig.proactivity RunConfig.realtime_input_config RunConfig.response_modalities RunConfig.save_live_audio RunConfig.session_resumption RunConfig.speech_config RunConfig.streaming_mode RunConfig.support_cfc RunConfig.validate_max_llm_calls RunConfig.save_input_blobs_as_artifacts RunConfig.msg RunConfig.wrapped_property RunConfig.field_name SequentialAgent SequentialAgent.config_type google.adk.artifacts module BaseArtifactService BaseArtifactService.delete_artifact() BaseArtifactService.get_artifact_version() BaseArtifactService.list_artifact_keys() BaseArtifactService.list_artifact_versions() BaseArtifactService.list_versions() BaseArtifactService.load_artifact() BaseArtifactService.save_artifact() GcsArtifactService GcsArtifactService.delete_artifact() GcsArtifactService.get_artifact_version() GcsArtifactService.list_artifact_keys() GcsArtifactService.list_artifact_versions() GcsArtifactService.list_versions() GcsArtifactService.load_artifact() GcsArtifactService.save_artifact() InMemoryArtifactService InMemoryArtifactService.artifacts InMemoryArtifactService.delete_artifact() InMemoryArtifactService.get_artifact_version() InMemoryArtifactService.list_artifact_keys() InMemoryArtifactService.list_artifact_versions() InMemoryArtifactService.list_versions() InMemoryArtifactService.load_artifact() InMemoryArtifactService.save_artifact() google.adk.apps package App App.context_cache_config App.events_compaction_config App.name App.plugins App.resumability_config App.root_agent ResumabilityConfig ResumabilityConfig.is_resumable google.adk.auth module google.adk.cli module google.adk.code_executors module BaseCodeExecutor BaseCodeExecutor.optimize_data_file BaseCodeExecutor.stateful BaseCodeExecutor.error_retry_attempts BaseCodeExecutor.code_block_delimiters BaseCodeExecutor.execution_result_delimiters BaseCodeExecutor.code_block_delimiters BaseCodeExecutor.error_retry_attempts BaseCodeExecutor.execution_result_delimiters BaseCodeExecutor.optimize_data_file BaseCodeExecutor.stateful BaseCodeExecutor.execute_code() BuiltInCodeExecutor BuiltInCodeExecutor.execute_code() BuiltInCodeExecutor.process_llm_request() CodeExecutorContext CodeExecutorContext.add_input_files() CodeExecutorContext.add_processed_file_names() CodeExecutorContext.clear_input_files() CodeExecutorContext.get_error_count() CodeExecutorContext.get_execution_id() CodeExecutorContext.get_input_files() CodeExecutorContext.get_processed_file_names() CodeExecutorContext.get_state_delta() CodeExecutorContext.increment_error_count() CodeExecutorContext.reset_error_count() CodeExecutorContext.set_execution_id() CodeExecutorContext.update_code_execution_result() UnsafeLocalCodeExecutor UnsafeLocalCodeExecutor.optimize_data_file UnsafeLocalCodeExecutor.stateful UnsafeLocalCodeExecutor.execute_code() google.adk.errors module google.adk.evaluation module AgentEvaluator AgentEvaluator.evaluate() AgentEvaluator.evaluate_eval_set() AgentEvaluator.find_config_for_test_file() AgentEvaluator.migrate_eval_data_to_new_schema() google.adk.events module Event Event.actions Event.author Event.branch Event.id Event.invocation_id Event.long_running_tool_ids Event.timestamp Event.new_id() Event.get_function_calls() Event.get_function_responses() Event.has_trailing_code_execution_result() Event.is_final_response() Event.model_post_init() EventActions EventActions.agent_state EventActions.artifact_delta EventActions.compaction EventActions.end_of_agent EventActions.escalate EventActions.requested_auth_configs EventActions.requested_tool_confirmations EventActions.rewind_before_invocation_id EventActions.skip_summarization EventActions.state_delta EventActions.transfer_to_agent google.adk.examples module BaseExampleProvider BaseExampleProvider.get_examples() Example Example.input Example.output Example.input Example.output VertexAiExampleStore VertexAiExampleStore.get_examples() google.adk.flows module google.adk.memory module BaseMemoryService BaseMemoryService.add_session_to_memory() BaseMemoryService.search_memory() InMemoryMemoryService InMemoryMemoryService.add_session_to_memory() InMemoryMemoryService.search_memory() VertexAiMemoryBankService VertexAiMemoryBankService.add_session_to_memory() VertexAiMemoryBankService.search_memory() VertexAiRagMemoryService VertexAiRagMemoryService.add_session_to_memory() VertexAiRagMemoryService.search_memory() google.adk.models module BaseLlm BaseLlm.model BaseLlm.supported_models() BaseLlm.connect() BaseLlm.generate_content_async() Gemini Gemini.model Gemini.model Gemini.retry_options Gemini.supported_models() Gemini.connect() Gemini.generate_content_async() Gemini.api_client Gemma Gemma.model Gemma.supported_models() Gemma.generate_content_async() LLMRegistry LLMRegistry.new_llm() LLMRegistry.register() LLMRegistry.resolve() google.adk.planners module BasePlanner BasePlanner.build_planning_instruction() BasePlanner.process_planning_response() BuiltInPlanner BuiltInPlanner.thinking_config BuiltInPlanner.apply_thinking_config() BuiltInPlanner.build_planning_instruction() BuiltInPlanner.process_planning_response() BuiltInPlanner.thinking_config PlanReActPlanner PlanReActPlanner.build_planning_instruction() PlanReActPlanner.process_planning_response() google.adk.platform module google.adk.plugins module BasePlugin BasePlugin.after_agent_callback() BasePlugin.after_model_callback() BasePlugin.after_run_callback() BasePlugin.after_tool_callback() BasePlugin.before_agent_callback() BasePlugin.before_model_callback() BasePlugin.before_run_callback() BasePlugin.before_tool_callback() BasePlugin.on_event_callback() BasePlugin.on_model_error_callback() BasePlugin.on_tool_error_callback() BasePlugin.on_user_message_callback() LoggingPlugin LoggingPlugin.after_agent_callback() LoggingPlugin.after_model_callback() LoggingPlugin.after_run_callback() LoggingPlugin.after_tool_callback() LoggingPlugin.before_agent_callback() LoggingPlugin.before_model_callback() LoggingPlugin.before_run_callback() LoggingPlugin.before_tool_callback() LoggingPlugin.on_event_callback() LoggingPlugin.on_model_error_callback() LoggingPlugin.on_tool_error_callback() LoggingPlugin.on_user_message_callback() PluginManager PluginManager.get_plugin() PluginManager.register_plugin() PluginManager.run_after_agent_callback() PluginManager.run_after_model_callback() PluginManager.run_after_run_callback() PluginManager.run_after_tool_callback() PluginManager.run_before_agent_callback() PluginManager.run_before_model_callback() PluginManager.run_before_run_callback() PluginManager.run_before_tool_callback() PluginManager.run_on_event_callback() PluginManager.run_on_model_error_callback() PluginManager.run_on_tool_error_callback() PluginManager.run_on_user_message_callback() ReflectAndRetryToolPlugin ReflectAndRetryToolPlugin.after_tool_callback() ReflectAndRetryToolPlugin.extract_error_from_result() ReflectAndRetryToolPlugin.on_tool_error_callback() google.adk.runners module InMemoryRunner InMemoryRunner.agent InMemoryRunner.app_name Runner Runner.app_name Runner.agent Runner.artifact_service Runner.plugin_manager Runner.session_service Runner.memory_service Runner.credential_service Runner.context_cache_config Runner.resumability_config Runner.agent Runner.app_name Runner.artifact_service Runner.close() Runner.context_cache_config Runner.credential_service Runner.memory_service Runner.plugin_manager Runner.resumability_config Runner.rewind_async() Runner.run() Runner.run_async() Runner.run_live() Runner.session_service google.adk.sessions module BaseSessionService BaseSessionService.append_event() BaseSessionService.create_session() BaseSessionService.delete_session() BaseSessionService.get_session() BaseSessionService.list_sessions() DatabaseSessionService DatabaseSessionService.append_event() DatabaseSessionService.create_session() DatabaseSessionService.delete_session() DatabaseSessionService.get_session() DatabaseSessionService.list_sessions() InMemorySessionService InMemorySessionService.append_event() InMemorySessionService.create_session() InMemorySessionService.create_session_sync() InMemorySessionService.delete_session() InMemorySessionService.delete_session_sync() InMemorySessionService.get_session() InMemorySessionService.get_session_sync() InMemorySessionService.list_sessions() InMemorySessionService.list_sessions_sync() Session Session.app_name Session.events Session.id Session.last_update_time Session.state Session.user_id State State.APP_PREFIX State.TEMP_PREFIX State.USER_PREFIX State.get() State.has_delta() State.setdefault() State.to_dict() State.update() VertexAiSessionService VertexAiSessionService.append_event() VertexAiSessionService.create_session() VertexAiSessionService.delete_session() VertexAiSessionService.get_session() VertexAiSessionService.list_sessions() google.adk.telemetry module trace_call_llm() trace_merged_tool_calls() trace_send_data() trace_tool_call() google.adk.tools package APIHubToolset APIHubToolset.close() APIHubToolset.get_tools() AgentTool AgentTool.agent AgentTool.skip_summarization AgentTool.from_config() AgentTool.populate_name() AgentTool.run_async() AuthToolArguments AuthToolArguments.auth_config AuthToolArguments.function_call_id BaseTool BaseTool.custom_metadata BaseTool.description BaseTool.from_config() BaseTool.is_long_running BaseTool.name BaseTool.process_llm_request() BaseTool.run_async() DiscoveryEngineSearchTool DiscoveryEngineSearchTool.discovery_engine_search() ExampleTool ExampleTool.examples ExampleTool.from_config() ExampleTool.process_llm_request() FunctionTool FunctionTool.func FunctionTool.run_async() LongRunningFunctionTool LongRunningFunctionTool.is_long_running MCPToolset ToolContext ToolContext.invocation_context ToolContext.function_call_id ToolContext.event_actions ToolContext.tool_confirmation ToolContext.actions ToolContext.get_auth_response() ToolContext.request_confirmation() ToolContext.request_credential() ToolContext.search_memory() VertexAiSearchTool VertexAiSearchTool.data_store_id VertexAiSearchTool.search_engine_id VertexAiSearchTool.process_llm_request() exit_loop() transfer_to_agent() google.adk.tools.agent_tool module AgentTool AgentTool.agent AgentTool.skip_summarization AgentTool.from_config() AgentTool.populate_name() AgentTool.run_async() AgentToolConfig AgentToolConfig.agent AgentToolConfig.skip_summarization google.adk.tools.apihub_tool module APIHubToolset APIHubToolset.close() APIHubToolset.get_tools() google.adk.tools.application_integration_tool module ApplicationIntegrationToolset ApplicationIntegrationToolset.close() ApplicationIntegrationToolset.get_tools() IntegrationConnectorTool IntegrationConnectorTool.EXCLUDE_FIELDS IntegrationConnectorTool.OPTIONAL_FIELDS IntegrationConnectorTool.run_async() google.adk.tools.authenticated_function_tool module AuthenticatedFunctionTool AuthenticatedFunctionTool.run_async() google.adk.tools.base_authenticated_tool module BaseAuthenticatedTool BaseAuthenticatedTool.run_async() google.adk.tools.base_tool module BaseTool BaseTool.custom_metadata BaseTool.description BaseTool.from_config() BaseTool.is_long_running BaseTool.name BaseTool.process_llm_request() BaseTool.run_async() google.adk.tools.base_toolset module BaseToolset BaseToolset.close() BaseToolset.from_config() BaseToolset.get_tools() BaseToolset.get_tools_with_prefix() BaseToolset.process_llm_request() ToolPredicate google.adk.tools.bigquery module BigQueryCredentialsConfig BigQueryCredentialsConfig.model_post_init() BigQueryToolset BigQueryToolset.close() BigQueryToolset.get_tools() google.adk.tools.crewai_tool module CrewaiTool CrewaiTool.from_config() CrewaiTool.tool CrewaiToolConfig CrewaiToolConfig.description CrewaiToolConfig.name CrewaiToolConfig.tool google.adk.tools.enterprise_search_tool module EnterpriseWebSearchTool EnterpriseWebSearchTool.description EnterpriseWebSearchTool.name EnterpriseWebSearchTool.process_llm_request() google.adk.tools.example_tool module ExampleTool ExampleTool.examples ExampleTool.from_config() ExampleTool.process_llm_request() ExampleToolConfig ExampleToolConfig.examples google.adk.tools.exit_loop_tool module exit_loop() google.adk.tools.function_tool module FunctionTool FunctionTool.func FunctionTool.run_async() google.adk.tools.get_user_choice_tool module get_user_choice() google.adk.tools.google_api_tool module BigQueryToolset CalendarToolset DocsToolset GmailToolset GoogleApiTool GoogleApiTool.configure_auth() GoogleApiTool.configure_sa_auth() GoogleApiTool.description GoogleApiTool.name GoogleApiTool.run_async() GoogleApiToolset GoogleApiToolset.close() GoogleApiToolset.configure_auth() GoogleApiToolset.configure_sa_auth() GoogleApiToolset.get_tools() GoogleApiToolset.set_tool_filter() SheetsToolset SlidesToolset YoutubeToolset google.adk.tools.google_maps_grounding_tool module GoogleMapsGroundingTool GoogleMapsGroundingTool.description GoogleMapsGroundingTool.name GoogleMapsGroundingTool.process_llm_request() google.adk.tools.google_search_tool module GoogleSearchTool GoogleSearchTool.description GoogleSearchTool.name GoogleSearchTool.process_llm_request() google.adk.tools.langchain_tool module LangchainTool LangchainTool.from_config() LangchainToolConfig LangchainToolConfig.description LangchainToolConfig.name LangchainToolConfig.tool google.adk.tools.load_artifacts_tool module LoadArtifactsTool LoadArtifactsTool.description LoadArtifactsTool.name LoadArtifactsTool.process_llm_request() LoadArtifactsTool.run_async() google.adk.tools.load_memory_tool module LoadMemoryResponse LoadMemoryResponse.memories LoadMemoryTool LoadMemoryTool.process_llm_request() load_memory() google.adk.tools.load_web_page module load_web_page() google.adk.tools.long_running_tool module LongRunningFunctionTool LongRunningFunctionTool.is_long_running google.adk.tools.mcp_tool module MCPTool MCPToolset McpTool McpTool.raw_mcp_tool McpTool.run_async() McpToolset McpToolset.close() McpToolset.from_config() McpToolset.get_tools() SseConnectionParams SseConnectionParams.url SseConnectionParams.headers SseConnectionParams.timeout SseConnectionParams.sse_read_timeout SseConnectionParams.headers SseConnectionParams.sse_read_timeout SseConnectionParams.timeout SseConnectionParams.url StdioConnectionParams StdioConnectionParams.server_params StdioConnectionParams.timeout StdioConnectionParams.server_params StdioConnectionParams.timeout StreamableHTTPConnectionParams StreamableHTTPConnectionParams.url StreamableHTTPConnectionParams.headers StreamableHTTPConnectionParams.timeout StreamableHTTPConnectionParams.sse_read_timeout StreamableHTTPConnectionParams.terminate_on_close StreamableHTTPConnectionParams.headers StreamableHTTPConnectionParams.sse_read_timeout StreamableHTTPConnectionParams.terminate_on_close StreamableHTTPConnectionParams.timeout StreamableHTTPConnectionParams.url adk_to_mcp_tool_type() gemini_to_json_schema() google.adk.tools.openapi_tool module OpenAPIToolset OpenAPIToolset.close() OpenAPIToolset.get_tool() OpenAPIToolset.get_tools() RestApiTool RestApiTool.call() RestApiTool.configure_auth_credential() RestApiTool.configure_auth_scheme() RestApiTool.description RestApiTool.from_parsed_operation() RestApiTool.from_parsed_operation_str() RestApiTool.name RestApiTool.run_async() google.adk.tools.preload_memory_tool module PreloadMemoryTool PreloadMemoryTool.description PreloadMemoryTool.name PreloadMemoryTool.process_llm_request() google.adk.tools.retrieval module BaseRetrievalTool BaseRetrievalTool.description BaseRetrievalTool.name google.adk.tools.tool_context module ToolContext ToolContext.invocation_context ToolContext.function_call_id ToolContext.event_actions ToolContext.tool_confirmation ToolContext.actions ToolContext.get_auth_response() ToolContext.request_confirmation() ToolContext.request_credential() ToolContext.search_memory() google.adk.tools.toolbox_toolset module ToolboxToolset ToolboxToolset.close() ToolboxToolset.get_tools() google.adk.tools.transfer_to_agent_tool module transfer_to_agent() google.adk.tools.url_context_tool module UrlContextTool UrlContextTool.description UrlContextTool.name UrlContextTool.process_llm_request() google.adk.tools.vertex_ai_search_tool module VertexAiSearchTool VertexAiSearchTool.data_store_id VertexAiSearchTool.search_engine_id VertexAiSearchTool.process_llm_request() google.adk.utils module google.adk.version module ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:48.946873", "source_type": "adk-docs"}
{"doc_id": "18668f9633447d66b37cc1658c87be49dc5c0f4fece69e241501f30909044e5a", "url": "https://google.github.io/adk-docs/api-reference/java", "title": "Overview (Google Agent Development Kit Maven Parent POM 0.2.1-SNAPSHOT API)", "sections": [{"heading_path": [], "text": "JavaScript is disabled on your browser. ", "code_blocks": []}, {"heading_path": ["Agent Development Kit"], "text": "Agent Development Kit Packages Package Description com.google.adk com.google.adk.agents com.google.adk.artifacts com.google.adk.events com.google.adk.examples com.google.adk.exceptions com.google.adk.flows com.google.adk.flows.llmflows com.google.adk.flows.llmflows.audio com.google.adk.memory com.google.adk.models com.google.adk.models.langchain4j com.google.adk.network com.google.adk.runner com.google.adk.sessions com.google.adk.tools com.google.adk.tools.applicationintegrationtoolset com.google.adk.tools.mcp com.google.adk.tools.retrieval com.google.adk.utils com.google.adk.web com.google.adk.web.config ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:49.473331", "source_type": "adk-docs"}
{"doc_id": "951bd641a24fc47939c02f492075f0b91cc771fbf298f6f2ff79d5a97bad517d", "url": "https://google.github.io/adk-docs/api-reference/cli", "title": "adk cli documentation \u2014 adk cli  documentation", "sections": [{"heading_path": ["adk cli documentation\u00b6"], "text": "adk cli documentation \u00b6 Add your content using reStructuredText syntax. See the reStructuredText documentation for details. Contents: CLI Reference adk ", "code_blocks": []}, {"heading_path": ["adk cli"], "text": "adk cli ", "code_blocks": []}, {"heading_path": ["Navigation"], "text": "Navigation Contents: CLI Reference ", "code_blocks": []}, {"heading_path": ["Related Topics"], "text": "Related Topics Documentation overview Next: CLI Reference \u00a92025, Google.\n      \n      |\n      Powered by Sphinx 8.2.3 & Alabaster 1.0.0 | Page source ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:49.844627", "source_type": "adk-docs"}
{"doc_id": "bb88ce7abef123278407cc123d3619db56c1111ed8d070c4f5baf91da8a60f50", "url": "https://google.github.io/adk-docs/api-reference/agentconfig", "title": "AgentConfig", "sections": [{"heading_path": ["AgentConfig"], "text": "AgentConfig The config for the YAML schema to create an agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of LlmAgentConfig LoopAgentConfig ParallelAgentConfig SequentialAgentConfig BaseAgentConfig root anyOf LlmAgentConfig ", "code_blocks": []}, {"heading_path": ["LlmAgentConfig"], "text": "LlmAgentConfig Type: object The config for the YAML schema of a LlmAgent. No Additional Properties ", "code_blocks": []}, {"heading_path": ["agent_class"], "text": "agent_class root anyOf LlmAgentConfig agent_class ", "code_blocks": []}, {"heading_path": ["Agent Class"], "text": "Agent Class Type: enum (of string) Default: \"LlmAgent\" The value is used to uniquely identify the LlmAgent class. If it is empty, it is by default an LlmAgent. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"LlmAgent\" \"\" ", "code_blocks": []}, {"heading_path": ["name Required"], "text": "name Required root anyOf LlmAgentConfig name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Type: string Required. The name of the agent. ", "code_blocks": []}, {"heading_path": ["description"], "text": "description root anyOf LlmAgentConfig description ", "code_blocks": []}, {"heading_path": ["Description"], "text": "Description Type: string Default: \"\" Optional. The description of the agent. ", "code_blocks": []}, {"heading_path": ["sub_agents"], "text": "sub_agents root anyOf LlmAgentConfig sub_agents ", "code_blocks": []}, {"heading_path": ["Sub Agents"], "text": "Sub Agents Default: null Optional. The sub-agents of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig sub_agents anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig sub_agents anyOf item 0 AgentRefConfig ", "code_blocks": []}, {"heading_path": ["AgentRefConfig"], "text": "AgentRefConfig Type: object The config for the reference to another agent. No Additional Properties ", "code_blocks": []}, {"heading_path": ["config_path"], "text": "config_path root anyOf LlmAgentConfig sub_agents anyOf item 0 AgentRefConfig config_path ", "code_blocks": []}, {"heading_path": ["Config Path"], "text": "Config Path Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig sub_agents anyOf item 0 AgentRefConfig config_path anyOf item 0 Type: string root anyOf LlmAgentConfig sub_agents anyOf item 0 AgentRefConfig config_path anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["code"], "text": "code root anyOf LlmAgentConfig sub_agents anyOf item 0 AgentRefConfig code ", "code_blocks": []}, {"heading_path": ["Code"], "text": "Code Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig sub_agents anyOf item 0 AgentRefConfig code anyOf item 0 Type: string root anyOf LlmAgentConfig sub_agents anyOf item 0 AgentRefConfig code anyOf item 1 Type: null root anyOf LlmAgentConfig sub_agents anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["before_agent_callbacks"], "text": "before_agent_callbacks root anyOf LlmAgentConfig before_agent_callbacks ", "code_blocks": []}, {"heading_path": ["Before Agent Callbacks"], "text": "Before Agent Callbacks Default: null Optional. The before agent callbacks of the agent. Example: before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback ", "code_blocks": [{"language": "text", "code": "before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback"}]}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. No Additional Properties ", "code_blocks": []}, {"heading_path": ["name Required"], "text": "name Required root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Type: string ", "code_blocks": []}, {"heading_path": ["args"], "text": "args root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig args ", "code_blocks": []}, {"heading_path": ["Args"], "text": "Args Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig args anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig args anyOf item 0 ArgumentConfig ", "code_blocks": []}, {"heading_path": ["ArgumentConfig"], "text": "ArgumentConfig Type: object An argument passed to a function or a class's constructor. No Additional Properties ", "code_blocks": []}, {"heading_path": ["name"], "text": "name root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig args anyOf item 0 ArgumentConfig name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig args anyOf item 0 ArgumentConfig name anyOf item 0 Type: string root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig args anyOf item 0 ArgumentConfig name anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["value Required"], "text": "value Required root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig args anyOf item 0 ArgumentConfig value ", "code_blocks": []}, {"heading_path": ["Value"], "text": "Value Type: object root anyOf LlmAgentConfig before_agent_callbacks anyOf item 0 CodeConfig args anyOf item 1 Type: null root anyOf LlmAgentConfig before_agent_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["after_agent_callbacks"], "text": "after_agent_callbacks root anyOf LlmAgentConfig after_agent_callbacks ", "code_blocks": []}, {"heading_path": ["After Agent Callbacks"], "text": "After Agent Callbacks Default: null Optional. The after agent callbacks of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig after_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig after_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf LlmAgentConfig after_agent_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["model"], "text": "model root anyOf LlmAgentConfig model ", "code_blocks": []}, {"heading_path": ["Model"], "text": "Model Default: null Optional. LlmAgent.model. If not set, the model will be inherited from the ancestor. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig model anyOf item 0 Type: string root anyOf LlmAgentConfig model anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["instruction Required"], "text": "instruction Required root anyOf LlmAgentConfig instruction ", "code_blocks": []}, {"heading_path": ["Instruction"], "text": "Instruction Type: string Required. LlmAgent.instruction. ", "code_blocks": []}, {"heading_path": ["disallow_transfer_to_parent"], "text": "disallow_transfer_to_parent root anyOf LlmAgentConfig disallow_transfer_to_parent ", "code_blocks": []}, {"heading_path": ["Disallow Transfer To Parent"], "text": "Disallow Transfer To Parent Default: null Optional. LlmAgent.disallow transfer to_parent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig disallow_transfer_to_parent anyOf item 0 Type: boolean root anyOf LlmAgentConfig disallow_transfer_to_parent anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["disallow_transfer_to_peers"], "text": "disallow_transfer_to_peers root anyOf LlmAgentConfig disallow_transfer_to_peers ", "code_blocks": []}, {"heading_path": ["Disallow Transfer To Peers"], "text": "Disallow Transfer To Peers Default: null Optional. LlmAgent.disallow transfer to_peers. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig disallow_transfer_to_peers anyOf item 0 Type: boolean root anyOf LlmAgentConfig disallow_transfer_to_peers anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["input_schema"], "text": "input_schema root anyOf LlmAgentConfig input_schema Default: null Optional. LlmAgent.input_schema. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of CodeConfig Option 2 root anyOf LlmAgentConfig input_schema anyOf CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf LlmAgentConfig input_schema anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["output_schema"], "text": "output_schema root anyOf LlmAgentConfig output_schema Default: null Optional. LlmAgent.output_schema. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of CodeConfig Option 2 root anyOf LlmAgentConfig output_schema anyOf CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf LlmAgentConfig output_schema anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["output_key"], "text": "output_key root anyOf LlmAgentConfig output_key ", "code_blocks": []}, {"heading_path": ["Output Key"], "text": "Output Key Default: null Optional. LlmAgent.output_key. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig output_key anyOf item 0 Type: string root anyOf LlmAgentConfig output_key anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["include_contents"], "text": "include_contents root anyOf LlmAgentConfig include_contents ", "code_blocks": []}, {"heading_path": ["Include Contents"], "text": "Include Contents Type: enum (of string) Default: \"default\" Optional. LlmAgent.include_contents. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"default\" \"none\" ", "code_blocks": []}, {"heading_path": ["tools"], "text": "tools root anyOf LlmAgentConfig tools ", "code_blocks": []}, {"heading_path": ["Tools"], "text": "Tools Default: null Optional. LlmAgent.tools. Examples: For ADK built-in tools in google.adk.tools package, they can be referenced directly with the name: tools:\n  - name: google_search\n  - name: load_memory For user-defined tools, they can be referenced with fully qualified name: tools:\n  - name: my_library.my_tools.my_tool For tools that needs to be created via functions: tools:\n  - name: my_library.my_tools.create_tool\n    args:\n      - name: param1\n        value: value1\n      - name: param2\n        value: value2 For more advanced tools, instead of specifying arguments in config, it's recommended to define them in Python files and reference them. E.g., # tools.py\nmy_mcp_toolset = MCPToolset(\n    connection_params=StdioServerParameters(\n        command=\"npx\",\n        args=[\"-y\", \"@notionhq/notion-mcp-server\"],\n        env={\"OPENAPI_MCP_HEADERS\": NOTION_HEADERS},\n    )\n) Then, reference the toolset in config: tools:\n  - name: tools.my_mcp_toolset ", "code_blocks": [{"language": "text", "code": "tools:\n  - name: google_search\n  - name: load_memory"}, {"language": "text", "code": "tools:\n  - name: my_library.my_tools.my_tool"}, {"language": "text", "code": "tools:\n  - name: my_library.my_tools.create_tool\n    args:\n      - name: param1\n        value: value1\n      - name: param2\n        value: value2"}, {"language": "text", "code": "# tools.py\nmy_mcp_toolset = MCPToolset(\n    connection_params=StdioServerParameters(\n        command=\"npx\",\n        args=[\"-y\", \"@notionhq/notion-mcp-server\"],\n        env={\"OPENAPI_MCP_HEADERS\": NOTION_HEADERS},\n    )\n)"}, {"language": "text", "code": "tools:\n  - name: tools.my_mcp_toolset"}]}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig tools anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig tools anyOf item 0 ToolConfig ", "code_blocks": []}, {"heading_path": ["ToolConfig"], "text": "ToolConfig Type: object The configuration for a tool. The config supports these types of tools: 1. ADK built-in tools 2. User-defined tool instances 3. User-defined tool classes 4. User-defined functions that generate tool instances 5. User-defined function tools For examples: For ADK built-in tool instances or classes in google.adk.tools package, they can be referenced directly with the name and optionally with args . tools:\n  - name: google_search\n  - name: AgentTool\n    args:\n      agent: ./another_agent.yaml\n      skip_summarization: true For user-defined tool instances, the name is the fully qualified path to the tool instance. tools:\n  - name: my_package.my_module.my_tool For user-defined tool classes (custom tools), the name is the fully qualified path to the tool class and args is the arguments for the tool. tools:\n  - name: my_package.my_module.my_tool_class\n    args:\n      my_tool_arg1: value1\n      my_tool_arg2: value2 For user-defined functions that generate tool instances, the name is the fully qualified path to the function and args is passed to the function as arguments. tools:\n  - name: my_package.my_module.my_tool_function\n    args:\n      my_function_arg1: value1\n      my_function_arg2: value2 The function must have the following signature: def my_function(args: ToolArgsConfig) -> BaseTool:\n  ... For user-defined function tools, the name is the fully qualified path to the function. tools:\n  - name: my_package.my_module.my_function_tool If the above use cases don't suffice, users can define a custom tool config by extending BaseToolConfig and override from_config() in the custom tool. No Additional Properties ", "code_blocks": [{"language": "text", "code": "tools:\n  - name: google_search\n  - name: AgentTool\n    args:\n      agent: ./another_agent.yaml\n      skip_summarization: true"}, {"language": "text", "code": "tools:\n  - name: my_package.my_module.my_tool"}, {"language": "text", "code": "tools:\n  - name: my_package.my_module.my_tool_class\n    args:\n      my_tool_arg1: value1\n      my_tool_arg2: value2"}, {"language": "text", "code": "tools:\n  - name: my_package.my_module.my_tool_function\n    args:\n      my_function_arg1: value1\n      my_function_arg2: value2"}, {"language": "text", "code": "def my_function(args: ToolArgsConfig) -> BaseTool:\n  ..."}, {"language": "text", "code": "tools:\n  - name: my_package.my_module.my_function_tool"}]}, {"heading_path": ["name Required"], "text": "name Required root anyOf LlmAgentConfig tools anyOf item 0 ToolConfig name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Type: string The name of the tool. For ADK built-in tools, name is the name of the tool, e.g. google_search or AgentTool . For user-defined tools, the name is the fully qualified path to the tool, e.g. my_package.my_module.my_tool . ", "code_blocks": []}, {"heading_path": ["args"], "text": "args root anyOf LlmAgentConfig tools anyOf item 0 ToolConfig args Default: null The args for the tool. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ToolArgsConfig Option 2 root anyOf LlmAgentConfig tools anyOf item 0 ToolConfig args anyOf ToolArgsConfig ", "code_blocks": []}, {"heading_path": ["ToolArgsConfig"], "text": "ToolArgsConfig Type: object Config to host free key-value pairs for the args in ToolConfig. ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig tools anyOf item 0 ToolConfig args anyOf ToolArgsConfig additionalProperties Type: object root anyOf LlmAgentConfig tools anyOf item 0 ToolConfig args anyOf item 1 Type: null root anyOf LlmAgentConfig tools anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["before_model_callbacks"], "text": "before_model_callbacks root anyOf LlmAgentConfig before_model_callbacks ", "code_blocks": []}, {"heading_path": ["Before Model Callbacks"], "text": "Before Model Callbacks Default: null Optional. LlmAgent.before model callbacks. Example: before_model_callbacks:\n  - name: my_library.callbacks.before_model_callback ", "code_blocks": [{"language": "text", "code": "before_model_callbacks:\n  - name: my_library.callbacks.before_model_callback"}]}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig before_model_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig before_model_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf LlmAgentConfig before_model_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["after_model_callbacks"], "text": "after_model_callbacks root anyOf LlmAgentConfig after_model_callbacks ", "code_blocks": []}, {"heading_path": ["After Model Callbacks"], "text": "After Model Callbacks Default: null Optional. LlmAgent.after model callbacks. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig after_model_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig after_model_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf LlmAgentConfig after_model_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["before_tool_callbacks"], "text": "before_tool_callbacks root anyOf LlmAgentConfig before_tool_callbacks ", "code_blocks": []}, {"heading_path": ["Before Tool Callbacks"], "text": "Before Tool Callbacks Default: null Optional. LlmAgent.before tool callbacks. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig before_tool_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig before_tool_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf LlmAgentConfig before_tool_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["after_tool_callbacks"], "text": "after_tool_callbacks root anyOf LlmAgentConfig after_tool_callbacks ", "code_blocks": []}, {"heading_path": ["After Tool Callbacks"], "text": "After Tool Callbacks Default: null Optional. LlmAgent.after tool callbacks. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig after_tool_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig after_tool_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf LlmAgentConfig after_tool_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["generate_content_config"], "text": "generate_content_config root anyOf LlmAgentConfig generate_content_config Default: null Optional. LlmAgent.generate content config. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of GenerateContentConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig ", "code_blocks": []}, {"heading_path": ["GenerateContentConfig"], "text": "GenerateContentConfig Type: object Optional model configuration parameters. For more information, see Content generation parameters\n<https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters> _. No Additional Properties ", "code_blocks": []}, {"heading_path": ["httpOptions"], "text": "httpOptions root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions Default: null Used to override HTTP request options. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of HttpOptions Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions ", "code_blocks": []}, {"heading_path": ["HttpOptions"], "text": "HttpOptions Type: object HTTP options to be used in each of the requests. No Additional Properties ", "code_blocks": []}, {"heading_path": ["baseUrl"], "text": "baseUrl root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions baseUrl ", "code_blocks": []}, {"heading_path": ["Baseurl"], "text": "Baseurl Default: null The base URL for the AI platform service endpoint. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions baseUrl anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions baseUrl anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["apiVersion"], "text": "apiVersion root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions apiVersion ", "code_blocks": []}, {"heading_path": ["Apiversion"], "text": "Apiversion Default: null Specifies the version of the API to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions apiVersion anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions apiVersion anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["headers"], "text": "headers root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions headers ", "code_blocks": []}, {"heading_path": ["Headers"], "text": "Headers Default: null Additional HTTP headers to be sent with the request. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions headers anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Each additional property must conform to the following schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions headers anyOf item 0 additionalProperties Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions headers anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["timeout"], "text": "timeout root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions timeout ", "code_blocks": []}, {"heading_path": ["Timeout"], "text": "Timeout Default: null Timeout for the request in milliseconds. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions timeout anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions timeout anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["clientArgs"], "text": "clientArgs root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions clientArgs ", "code_blocks": []}, {"heading_path": ["Clientargs"], "text": "Clientargs Default: null Args passed to the HTTP client. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions clientArgs anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions clientArgs anyOf item 0 additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions clientArgs anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["asyncClientArgs"], "text": "asyncClientArgs root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions asyncClientArgs ", "code_blocks": []}, {"heading_path": ["Asyncclientargs"], "text": "Asyncclientargs Default: null Args passed to the async HTTP client. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions asyncClientArgs anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions asyncClientArgs anyOf item 0 additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions asyncClientArgs anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["extraBody"], "text": "extraBody root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions extraBody ", "code_blocks": []}, {"heading_path": ["Extrabody"], "text": "Extrabody Default: null Extra parameters to add to the request body. The structure must match the backend API's request structure. - VertexAI backend API docs: https://cloud.google.com/vertex-ai/docs/reference/rest - GeminiAPI backend API docs: https://ai.google.dev/api/rest ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions extraBody anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions extraBody anyOf item 0 additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions extraBody anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["retryOptions"], "text": "retryOptions root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions Default: null HTTP retry options for the request. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of HttpRetryOptions Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions ", "code_blocks": []}, {"heading_path": ["HttpRetryOptions"], "text": "HttpRetryOptions Type: object HTTP retry options to be used in each of the requests. No Additional Properties ", "code_blocks": []}, {"heading_path": ["attempts"], "text": "attempts root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions attempts ", "code_blocks": []}, {"heading_path": ["Attempts"], "text": "Attempts Default: null Maximum number of attempts, including the original request. If 0 or 1, it means no retries. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions attempts anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions attempts anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["initialDelay"], "text": "initialDelay root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions initialDelay ", "code_blocks": []}, {"heading_path": ["Initialdelay"], "text": "Initialdelay Default: null Initial delay before the first retry, in fractions of a second. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions initialDelay anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions initialDelay anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["maxDelay"], "text": "maxDelay root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions maxDelay ", "code_blocks": []}, {"heading_path": ["Maxdelay"], "text": "Maxdelay Default: null Maximum delay between retries, in fractions of a second. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions maxDelay anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions maxDelay anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["expBase"], "text": "expBase root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions expBase ", "code_blocks": []}, {"heading_path": ["Expbase"], "text": "Expbase Default: null Multiplier by which the delay increases after each attempt. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions expBase anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions expBase anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["jitter"], "text": "jitter root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions jitter ", "code_blocks": []}, {"heading_path": ["Jitter"], "text": "Jitter Default: null Randomness factor for the delay. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions jitter anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions jitter anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["httpStatusCodes"], "text": "httpStatusCodes root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions httpStatusCodes ", "code_blocks": []}, {"heading_path": ["Httpstatuscodes"], "text": "Httpstatuscodes Default: null List of HTTP status codes that should trigger a retry. If not specified, a default set of retryable codes may be used. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions httpStatusCodes anyOf item 0 Type: array of integer No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions httpStatusCodes anyOf item 0 item 0 items Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf HttpRetryOptions httpStatusCodes anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf HttpOptions retryOptions anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig httpOptions anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["systemInstruction"], "text": "systemInstruction root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction ", "code_blocks": []}, {"heading_path": ["Systeminstruction"], "text": "Systeminstruction Default: null Instructions for the model to steer it toward better performance. For example, \"Answer as concisely as possible\" or \"Don't use technical terms in your response\". ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Content Option 2 File Part Option 5 Option 6 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content ", "code_blocks": []}, {"heading_path": ["Content"], "text": "Content Type: object Contains the multi-part content of a message. No Additional Properties ", "code_blocks": []}, {"heading_path": ["parts"], "text": "parts root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts ", "code_blocks": []}, {"heading_path": ["Parts"], "text": "Parts Default: null List of parts that constitute a single message. Each part may have a different IANA MIME type. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part ", "code_blocks": []}, {"heading_path": ["Part"], "text": "Part Type: object A datatype containing media content. Exactly one field within a Part should be set, representing the specific type of content being conveyed. Using multiple fields within the same Part instance is considered invalid. No Additional Properties ", "code_blocks": []}, {"heading_path": ["videoMetadata"], "text": "videoMetadata root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata Default: null Metadata for a given video. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of VideoMetadata Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata ", "code_blocks": []}, {"heading_path": ["VideoMetadata"], "text": "VideoMetadata Type: object Describes how the video in the Part should be used by the model. No Additional Properties ", "code_blocks": []}, {"heading_path": ["fps"], "text": "fps root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata fps ", "code_blocks": []}, {"heading_path": ["Fps"], "text": "Fps Default: null The frame rate of the video sent to the model. If not specified, the default value will be 1.0. The fps range is (0.0, 24.0]. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata fps anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata fps anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["endOffset"], "text": "endOffset root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata endOffset ", "code_blocks": []}, {"heading_path": ["Endoffset"], "text": "Endoffset Default: null Optional. The end offset of the video. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata endOffset anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata endOffset anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["startOffset"], "text": "startOffset root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata startOffset ", "code_blocks": []}, {"heading_path": ["Startoffset"], "text": "Startoffset Default: null Optional. The start offset of the video. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata startOffset anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf VideoMetadata startOffset anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part videoMetadata anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["thought"], "text": "thought root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part thought ", "code_blocks": []}, {"heading_path": ["Thought"], "text": "Thought Default: null Indicates if the part is thought from the model. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part thought anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part thought anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["inlineData"], "text": "inlineData root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData Default: null Optional. Inlined bytes data. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Blob Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob ", "code_blocks": []}, {"heading_path": ["Blob"], "text": "Blob Type: object Content blob. No Additional Properties ", "code_blocks": []}, {"heading_path": ["displayName"], "text": "displayName root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob displayName ", "code_blocks": []}, {"heading_path": ["Displayname"], "text": "Displayname Default: null Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob displayName anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob displayName anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["data"], "text": "data root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob data ", "code_blocks": []}, {"heading_path": ["Data"], "text": "Data Default: null Required. Raw bytes. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob data anyOf item 0 Type: string Format: base64url root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob data anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["mimeType"], "text": "mimeType root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob mimeType ", "code_blocks": []}, {"heading_path": ["Mimetype"], "text": "Mimetype Default: null Required. The IANA standard MIME type of the source data. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob mimeType anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf Blob mimeType anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part inlineData anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["fileData"], "text": "fileData root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData Default: null Optional. URI based data. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FileData Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData ", "code_blocks": []}, {"heading_path": ["FileData"], "text": "FileData Type: object URI based data. No Additional Properties ", "code_blocks": []}, {"heading_path": ["displayName"], "text": "displayName root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData displayName ", "code_blocks": []}, {"heading_path": ["Displayname"], "text": "Displayname Default: null Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData displayName anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData displayName anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["fileUri"], "text": "fileUri root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData fileUri ", "code_blocks": []}, {"heading_path": ["Fileuri"], "text": "Fileuri Default: null Required. URI. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData fileUri anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData fileUri anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["mimeType"], "text": "mimeType root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData mimeType ", "code_blocks": []}, {"heading_path": ["Mimetype"], "text": "Mimetype Default: null Required. The IANA standard MIME type of the source data. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData mimeType anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf FileData mimeType anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part fileData anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["thoughtSignature"], "text": "thoughtSignature root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part thoughtSignature ", "code_blocks": []}, {"heading_path": ["Thoughtsignature"], "text": "Thoughtsignature Default: null An opaque signature for the thought so it can be reused in subsequent requests. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part thoughtSignature anyOf item 0 Type: string Format: base64url root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part thoughtSignature anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["codeExecutionResult"], "text": "codeExecutionResult root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part codeExecutionResult Default: null Optional. Result of executing the [ExecutableCode]. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of CodeExecutionResult Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part codeExecutionResult anyOf CodeExecutionResult ", "code_blocks": []}, {"heading_path": ["CodeExecutionResult"], "text": "CodeExecutionResult Type: object Result of executing the [ExecutableCode]. Only generated when using the [CodeExecution] tool, and always follows a part containing the [ExecutableCode]. No Additional Properties ", "code_blocks": []}, {"heading_path": ["outcome"], "text": "outcome root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part codeExecutionResult anyOf CodeExecutionResult outcome Default: null Required. Outcome of the code execution. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Outcome Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part codeExecutionResult anyOf CodeExecutionResult outcome anyOf Outcome ", "code_blocks": []}, {"heading_path": ["Outcome"], "text": "Outcome Type: enum (of string) Required. Outcome of the code execution. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"OUTCOME_UNSPECIFIED\" \"OUTCOME_OK\" \"OUTCOME_FAILED\" \"OUTCOME_DEADLINE_EXCEEDED\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part codeExecutionResult anyOf CodeExecutionResult outcome anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["output"], "text": "output root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part codeExecutionResult anyOf CodeExecutionResult output ", "code_blocks": []}, {"heading_path": ["Output"], "text": "Output Default: null Optional. Contains stdout when code execution is successful, stderr or other description otherwise. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part codeExecutionResult anyOf CodeExecutionResult output anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part codeExecutionResult anyOf CodeExecutionResult output anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part codeExecutionResult anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["executableCode"], "text": "executableCode root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part executableCode Default: null Optional. Code generated by the model that is meant to be executed. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ExecutableCode Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part executableCode anyOf ExecutableCode ", "code_blocks": []}, {"heading_path": ["ExecutableCode"], "text": "ExecutableCode Type: object Code generated by the model that is meant to be executed, and the result returned to the model. Generated when using the [CodeExecution] tool, in which the code will be automatically executed, and a corresponding [CodeExecutionResult] will also be generated. No Additional Properties ", "code_blocks": []}, {"heading_path": ["code"], "text": "code root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part executableCode anyOf ExecutableCode code ", "code_blocks": []}, {"heading_path": ["Code"], "text": "Code Default: null Required. The code to be executed. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part executableCode anyOf ExecutableCode code anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part executableCode anyOf ExecutableCode code anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["language"], "text": "language root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part executableCode anyOf ExecutableCode language Default: null Required. Programming language of the code . ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Language Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part executableCode anyOf ExecutableCode language anyOf Language ", "code_blocks": []}, {"heading_path": ["Language"], "text": "Language Type: enum (of string) Required. Programming language of the code . ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"LANGUAGE_UNSPECIFIED\" \"PYTHON\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part executableCode anyOf ExecutableCode language anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part executableCode anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["functionCall"], "text": "functionCall root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall Default: null Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FunctionCall Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall ", "code_blocks": []}, {"heading_path": ["FunctionCall"], "text": "FunctionCall Type: object A function call. No Additional Properties ", "code_blocks": []}, {"heading_path": ["id"], "text": "id root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall id ", "code_blocks": []}, {"heading_path": ["Id"], "text": "Id Default: null The unique id of the function call. If populated, the client to execute the function_call and return the response with the matching id . ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall id anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall id anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["args"], "text": "args root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall args ", "code_blocks": []}, {"heading_path": ["Args"], "text": "Args Default: null Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall args anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall args anyOf item 0 additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall args anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["name"], "text": "name root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Default: null Required. The name of the function to call. Matches [FunctionDeclaration.name]. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall name anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf FunctionCall name anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionCall anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["functionResponse"], "text": "functionResponse root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse Default: null Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FunctionResponse Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse ", "code_blocks": []}, {"heading_path": ["FunctionResponse"], "text": "FunctionResponse Type: object A function response. No Additional Properties ", "code_blocks": []}, {"heading_path": ["willContinue"], "text": "willContinue root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse willContinue ", "code_blocks": []}, {"heading_path": ["Willcontinue"], "text": "Willcontinue Default: null Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty response with will_continue=False to signal that the function call is finished. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse willContinue anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse willContinue anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["scheduling"], "text": "scheduling root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse scheduling Default: null Specifies how the response should be scheduled in the conversation. Only applicable to NON BLOCKING function calls, is ignored otherwise. Defaults to WHEN IDLE. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FunctionResponseScheduling Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse scheduling anyOf FunctionResponseScheduling ", "code_blocks": []}, {"heading_path": ["FunctionResponseScheduling"], "text": "FunctionResponseScheduling Type: enum (of string) Specifies how the response should be scheduled in the conversation. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"SCHEDULING_UNSPECIFIED\" \"SILENT\" \"WHEN_IDLE\" \"INTERRUPT\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse scheduling anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["id"], "text": "id root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse id ", "code_blocks": []}, {"heading_path": ["Id"], "text": "Id Default: null Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call id . ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse id anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse id anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["name"], "text": "name root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Default: null Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name]. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse name anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse name anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["response"], "text": "response root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse response ", "code_blocks": []}, {"heading_path": ["Response"], "text": "Response Default: null Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse response anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse response anyOf item 0 additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf FunctionResponse response anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part functionResponse anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["text"], "text": "text root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part text ", "code_blocks": []}, {"heading_path": ["Text"], "text": "Text Default: null Optional. Text part (can be code). ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part text anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 0 Part text anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content parts anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["role"], "text": "role root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content role ", "code_blocks": []}, {"heading_path": ["Role"], "text": "Role Default: null Optional. The producer of the content. Must be either 'user' or 'model'. Useful to set for multi-turn conversations, otherwise can be empty. If role is not specified, SDK will determine the role. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content role anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Content role anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of File Part Option 3 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File ", "code_blocks": []}, {"heading_path": ["File"], "text": "File Type: object A file uploaded to the API. No Additional Properties ", "code_blocks": []}, {"heading_path": ["name"], "text": "name root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Default: null The File resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: files/123-456 ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File name anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File name anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["displayName"], "text": "displayName root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File displayName ", "code_blocks": []}, {"heading_path": ["Displayname"], "text": "Displayname Default: null Optional. The human-readable display name for the File . The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image' ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File displayName anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File displayName anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["mimeType"], "text": "mimeType root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File mimeType ", "code_blocks": []}, {"heading_path": ["Mimetype"], "text": "Mimetype Default: null Output only. MIME type of the file. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File mimeType anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File mimeType anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["sizeBytes"], "text": "sizeBytes root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File sizeBytes ", "code_blocks": []}, {"heading_path": ["Sizebytes"], "text": "Sizebytes Default: null Output only. Size of the file in bytes. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File sizeBytes anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File sizeBytes anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["createTime"], "text": "createTime root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File createTime ", "code_blocks": []}, {"heading_path": ["Createtime"], "text": "Createtime Default: null Output only. The timestamp of when the File was created. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File createTime anyOf item 0 Type: string Format: date-time root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File createTime anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["expirationTime"], "text": "expirationTime root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File expirationTime ", "code_blocks": []}, {"heading_path": ["Expirationtime"], "text": "Expirationtime Default: null Output only. The timestamp of when the File will be deleted. Only set if the File is scheduled to expire. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File expirationTime anyOf item 0 Type: string Format: date-time root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File expirationTime anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["updateTime"], "text": "updateTime root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File updateTime ", "code_blocks": []}, {"heading_path": ["Updatetime"], "text": "Updatetime Default: null Output only. The timestamp of when the File was last updated. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File updateTime anyOf item 0 Type: string Format: date-time root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File updateTime anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["sha256Hash"], "text": "sha256Hash root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File sha256Hash ", "code_blocks": []}, {"heading_path": ["Sha256Hash"], "text": "Sha256Hash Default: null Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File sha256Hash anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File sha256Hash anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["uri"], "text": "uri root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File uri ", "code_blocks": []}, {"heading_path": ["Uri"], "text": "Uri Default: null Output only. The URI of the File . ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File uri anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File uri anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["downloadUri"], "text": "downloadUri root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File downloadUri ", "code_blocks": []}, {"heading_path": ["Downloaduri"], "text": "Downloaduri Default: null Output only. The URI of the File , only set for downloadable (generated) files. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File downloadUri anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File downloadUri anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["state"], "text": "state root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File state Default: null Output only. Processing state of the File. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FileState Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File state anyOf FileState ", "code_blocks": []}, {"heading_path": ["FileState"], "text": "FileState Type: enum (of string) State for the lifecycle of a File. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"STATE_UNSPECIFIED\" \"PROCESSING\" \"ACTIVE\" \"FAILED\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File state anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["source"], "text": "source root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File source Default: null Output only. The source of the File . ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FileSource Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File source anyOf FileSource ", "code_blocks": []}, {"heading_path": ["FileSource"], "text": "FileSource Type: enum (of string) Source of the File. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"SOURCE_UNSPECIFIED\" \"UPLOADED\" \"GENERATED\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File source anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["videoMetadata"], "text": "videoMetadata root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File videoMetadata ", "code_blocks": []}, {"heading_path": ["Videometadata"], "text": "Videometadata Default: null Output only. Metadata for a video. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File videoMetadata anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File videoMetadata anyOf item 0 additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File videoMetadata anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["error"], "text": "error root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error Default: null Output only. Error status if File processing failed. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FileStatus Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus ", "code_blocks": []}, {"heading_path": ["FileStatus"], "text": "FileStatus Type: object Status of a File that uses a common error model. No Additional Properties ", "code_blocks": []}, {"heading_path": ["details"], "text": "details root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus details ", "code_blocks": []}, {"heading_path": ["Details"], "text": "Details Default: null A list of messages that carry the error details. There is a common set of message types for APIs to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus details anyOf item 0 Type: array of object No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus details anyOf item 0 item 0 items Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus details anyOf item 0 item 0 items additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus details anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["message"], "text": "message root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus message ", "code_blocks": []}, {"heading_path": ["Message"], "text": "Message Default: null A list of messages that carry the error details. There is a common set of message types for APIs to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus message anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus message anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["code"], "text": "code root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus code ", "code_blocks": []}, {"heading_path": ["Code"], "text": "Code Default: null The status code. 0 for OK, 1 for CANCELLED ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus code anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf FileStatus code anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf File error anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf Part ", "code_blocks": []}, {"heading_path": ["Part"], "text": "Part Type: object A datatype containing media content. Exactly one field within a Part should be set, representing the specific type of content being conveyed. Using multiple fields within the same Part instance is considered invalid. Same definition as Part root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 1 item 1 items anyOf item 2 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf File ", "code_blocks": []}, {"heading_path": ["File"], "text": "File Type: object A file uploaded to the API. Same definition as File root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf Part ", "code_blocks": []}, {"heading_path": ["Part"], "text": "Part Type: object A datatype containing media content. Exactly one field within a Part should be set, representing the specific type of content being conveyed. Using multiple fields within the same Part instance is considered invalid. Same definition as Part root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 4 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig systemInstruction anyOf item 5 Type: null ", "code_blocks": []}, {"heading_path": ["temperature"], "text": "temperature root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig temperature ", "code_blocks": []}, {"heading_path": ["Temperature"], "text": "Temperature Default: null Value that controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig temperature anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig temperature anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["topP"], "text": "topP root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig topP ", "code_blocks": []}, {"heading_path": ["Topp"], "text": "Topp Default: null Tokens are selected from the most to least probable until the sum of their probabilities equals this value. Use a lower value for less random responses and a higher value for more random responses. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig topP anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig topP anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["topK"], "text": "topK root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig topK ", "code_blocks": []}, {"heading_path": ["Topk"], "text": "Topk Default: null For each token selection step, the top_k tokens with the highest probabilities are sampled. Then tokens are further filtered based on top_p with the final token selected using temperature sampling. Use a lower number for less random responses and a higher number for more random responses. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig topK anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig topK anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["candidateCount"], "text": "candidateCount root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig candidateCount ", "code_blocks": []}, {"heading_path": ["Candidatecount"], "text": "Candidatecount Default: null Number of response variations to return. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig candidateCount anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig candidateCount anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["maxOutputTokens"], "text": "maxOutputTokens root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig maxOutputTokens ", "code_blocks": []}, {"heading_path": ["Maxoutputtokens"], "text": "Maxoutputtokens Default: null Maximum number of tokens that can be generated in the response. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig maxOutputTokens anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig maxOutputTokens anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["stopSequences"], "text": "stopSequences root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig stopSequences ", "code_blocks": []}, {"heading_path": ["Stopsequences"], "text": "Stopsequences Default: null List of strings that tells the model to stop generating text if one of the strings is encountered in the response. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig stopSequences anyOf item 0 Type: array of string No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig stopSequences anyOf item 0 item 0 items Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig stopSequences anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["responseLogprobs"], "text": "responseLogprobs root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseLogprobs ", "code_blocks": []}, {"heading_path": ["Responselogprobs"], "text": "Responselogprobs Default: null Whether to return the log probabilities of the tokens that were chosen by the model at each step. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseLogprobs anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseLogprobs anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["logprobs"], "text": "logprobs root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig logprobs ", "code_blocks": []}, {"heading_path": ["Logprobs"], "text": "Logprobs Default: null Number of top candidate tokens to return the log probabilities for at each generation step. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig logprobs anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig logprobs anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["presencePenalty"], "text": "presencePenalty root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig presencePenalty ", "code_blocks": []}, {"heading_path": ["Presencepenalty"], "text": "Presencepenalty Default: null Positive values penalize tokens that already appear in the generated text, increasing the probability of generating more diverse content. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig presencePenalty anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig presencePenalty anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["frequencyPenalty"], "text": "frequencyPenalty root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig frequencyPenalty ", "code_blocks": []}, {"heading_path": ["Frequencypenalty"], "text": "Frequencypenalty Default: null Positive values penalize tokens that repeatedly appear in the generated text, increasing the probability of generating more diverse content. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig frequencyPenalty anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig frequencyPenalty anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["seed"], "text": "seed root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig seed ", "code_blocks": []}, {"heading_path": ["Seed"], "text": "Seed Default: null When seed is fixed to a specific number, the model makes a best effort to provide the same response for repeated requests. By default, a random number is used. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig seed anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig seed anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["responseMimeType"], "text": "responseMimeType root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseMimeType ", "code_blocks": []}, {"heading_path": ["Responsemimetype"], "text": "Responsemimetype Default: null Output response mimetype of the generated candidate text. Supported mimetype: - text/plain : (default) Text output. - application/json : JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseMimeType anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseMimeType anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["responseSchema"], "text": "responseSchema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema ", "code_blocks": []}, {"heading_path": ["Responseschema"], "text": "Responseschema Default: null The Schema object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an OpenAPI 3.0 schema object . If set, a compatible response mime type must also be set. Compatible mimetypes: application/json : Schema for JSON response. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Schema Option 3 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf item 0 additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema ", "code_blocks": []}, {"heading_path": ["Schema"], "text": "Schema Type: object Schema is used to define the format of input/output data. Represents a select subset of an OpenAPI 3.0 schema object . More fields may be added in the future as needed. No Additional Properties ", "code_blocks": []}, {"heading_path": ["additionalProperties"], "text": "additionalProperties root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema additionalProperties ", "code_blocks": []}, {"heading_path": ["Additionalproperties"], "text": "Additionalproperties Default: null Optional. Can either be a boolean or an object; controls the presence of additional properties. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema additionalProperties anyOf item 0 Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema additionalProperties anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["defs"], "text": "defs root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema defs ", "code_blocks": []}, {"heading_path": ["Defs"], "text": "Defs Default: null Optional. A map of definitions for use by ref Only allowed at the root of the schema. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema defs anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Each additional property must conform to the following schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema defs anyOf item 0 Schema ", "code_blocks": []}, {"heading_path": ["Schema"], "text": "Schema Type: object Schema is used to define the format of input/output data. Represents a select subset of an OpenAPI 3.0 schema object . More fields may be added in the future as needed. Same definition as Schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema defs anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["ref"], "text": "ref root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema ref ", "code_blocks": []}, {"heading_path": ["Ref"], "text": "Ref Default: null Optional. Allows indirect references between schema nodes. The value should be a valid reference to a child of the root defs . For example, the following schema defines a reference to a schema node named \"Pet\": type: object properties: pet: ref: #/defs/Pet defs: Pet: type: object properties: name: type: string The value of the \"pet\" property is a reference to the schema node named \"Pet\". See details in https://json-schema.org/understanding-json-schema/structuring ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema ref anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema ref anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["anyOf"], "text": "anyOf root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema anyOf ", "code_blocks": []}, {"heading_path": ["Anyof"], "text": "Anyof Default: null Optional. The value should be validated against any (one or more) of the subschemas in the list. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema anyOf anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema anyOf anyOf item 0 Schema ", "code_blocks": []}, {"heading_path": ["Schema"], "text": "Schema Type: object Schema is used to define the format of input/output data. Represents a select subset of an OpenAPI 3.0 schema object . More fields may be added in the future as needed. Same definition as Schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema anyOf anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["default"], "text": "default root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema default ", "code_blocks": []}, {"heading_path": ["Default"], "text": "Default Default: null Optional. Default value of the data. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema default anyOf item 0 Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema default anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["description"], "text": "description root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema description ", "code_blocks": []}, {"heading_path": ["Description"], "text": "Description Default: null Optional. The description of the data. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema description anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema description anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["enum"], "text": "enum root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema enum ", "code_blocks": []}, {"heading_path": ["Enum"], "text": "Enum Default: null Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]} ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema enum anyOf item 0 Type: array of string No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema enum anyOf item 0 item 0 items Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema enum anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["example"], "text": "example root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema example ", "code_blocks": []}, {"heading_path": ["Example"], "text": "Example Default: null Optional. Example of the object. Will only populated when the object is the root. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema example anyOf item 0 Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema example anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["format"], "text": "format root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema format ", "code_blocks": []}, {"heading_path": ["Format"], "text": "Format Default: null Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema format anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema format anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["items"], "text": "items root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema items Default: null Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Schema Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema items anyOf Schema ", "code_blocks": []}, {"heading_path": ["Schema"], "text": "Schema Type: object Schema is used to define the format of input/output data. Represents a select subset of an OpenAPI 3.0 schema object . More fields may be added in the future as needed. Same definition as Schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema items anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["maxItems"], "text": "maxItems root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maxItems ", "code_blocks": []}, {"heading_path": ["Maxitems"], "text": "Maxitems Default: null Optional. Maximum number of the elements for Type.ARRAY. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maxItems anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maxItems anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["maxLength"], "text": "maxLength root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maxLength ", "code_blocks": []}, {"heading_path": ["Maxlength"], "text": "Maxlength Default: null Optional. Maximum length of the Type.STRING ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maxLength anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maxLength anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["maxProperties"], "text": "maxProperties root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maxProperties ", "code_blocks": []}, {"heading_path": ["Maxproperties"], "text": "Maxproperties Default: null Optional. Maximum number of the properties for Type.OBJECT. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maxProperties anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maxProperties anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["maximum"], "text": "maximum root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maximum ", "code_blocks": []}, {"heading_path": ["Maximum"], "text": "Maximum Default: null Optional. Maximum value of the Type.INTEGER and Type.NUMBER ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maximum anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema maximum anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["minItems"], "text": "minItems root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minItems ", "code_blocks": []}, {"heading_path": ["Minitems"], "text": "Minitems Default: null Optional. Minimum number of the elements for Type.ARRAY. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minItems anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minItems anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["minLength"], "text": "minLength root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minLength ", "code_blocks": []}, {"heading_path": ["Minlength"], "text": "Minlength Default: null Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minLength anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minLength anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["minProperties"], "text": "minProperties root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minProperties ", "code_blocks": []}, {"heading_path": ["Minproperties"], "text": "Minproperties Default: null Optional. Minimum number of the properties for Type.OBJECT. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minProperties anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minProperties anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["minimum"], "text": "minimum root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minimum ", "code_blocks": []}, {"heading_path": ["Minimum"], "text": "Minimum Default: null Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minimum anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema minimum anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["nullable"], "text": "nullable root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema nullable ", "code_blocks": []}, {"heading_path": ["Nullable"], "text": "Nullable Default: null Optional. Indicates if the value may be null. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema nullable anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema nullable anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["pattern"], "text": "pattern root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema pattern ", "code_blocks": []}, {"heading_path": ["Pattern"], "text": "Pattern Default: null Optional. Pattern of the Type.STRING to restrict a string to a regular expression. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema pattern anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema pattern anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["properties"], "text": "properties root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema properties ", "code_blocks": []}, {"heading_path": ["Properties"], "text": "Properties Default: null Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema properties anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Each additional property must conform to the following schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema properties anyOf item 0 Schema ", "code_blocks": []}, {"heading_path": ["Schema"], "text": "Schema Type: object Schema is used to define the format of input/output data. Represents a select subset of an OpenAPI 3.0 schema object . More fields may be added in the future as needed. Same definition as Schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema properties anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["propertyOrdering"], "text": "propertyOrdering root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema propertyOrdering ", "code_blocks": []}, {"heading_path": ["Propertyordering"], "text": "Propertyordering Default: null Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema propertyOrdering anyOf item 0 Type: array of string No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema propertyOrdering anyOf item 0 item 0 items Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema propertyOrdering anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["required"], "text": "required root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema required ", "code_blocks": []}, {"heading_path": ["Required"], "text": "Required Default: null Optional. Required properties of Type.OBJECT. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema required anyOf item 0 Type: array of string No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema required anyOf item 0 item 0 items Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema required anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["title"], "text": "title root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema title ", "code_blocks": []}, {"heading_path": ["Title"], "text": "Title Default: null Optional. The title of the Schema. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema title anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema title anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["type"], "text": "type root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema type Default: null Optional. The type of the data. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Type Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema type anyOf Type ", "code_blocks": []}, {"heading_path": ["Type"], "text": "Type Type: enum (of string) Optional. The type of the data. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"TYPE_UNSPECIFIED\" \"STRING\" \"NUMBER\" \"INTEGER\" \"BOOLEAN\" \"ARRAY\" \"OBJECT\" \"NULL\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf Schema type anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseSchema anyOf item 2 Type: null ", "code_blocks": []}, {"heading_path": ["responseJsonSchema"], "text": "responseJsonSchema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseJsonSchema ", "code_blocks": []}, {"heading_path": ["Responsejsonschema"], "text": "Responsejsonschema Default: null Optional. Output schema of the generated response. This is an alternative to response_schema that accepts JSON Schema . If set, response_schema must be omitted, but response_mime_type is required. While the full JSON Schema may be sent, not all features are supported. Specifically, only the following properties are supported: - $id - $defs - $ref - $anchor - type - format - title - description - enum (for strings and numbers) - items - prefixItems - minItems - maxItems - minimum - maximum - anyOf - oneOf (interpreted the same as anyOf ) - properties - additionalProperties - required The non-standard propertyOrdering property may also be set. Cyclic references are unrolled to a limited degree and, as such, may only be used within non-required properties. (Nullable properties are not sufficient.) If $ref is set on a sub-schema, no other properties, except for than those starting as a $ , may be set. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseJsonSchema anyOf item 0 Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseJsonSchema anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["routingConfig"], "text": "routingConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig Default: null Configuration for model router requests. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of GenerationConfigRoutingConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig ", "code_blocks": []}, {"heading_path": ["GenerationConfigRoutingConfig"], "text": "GenerationConfigRoutingConfig Type: object The configuration for routing the request to a specific model. No Additional Properties ", "code_blocks": []}, {"heading_path": ["autoMode"], "text": "autoMode root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig autoMode Default: null Automated routing. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of GenerationConfigRoutingConfigAutoRoutingMode Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig autoMode anyOf GenerationConfigRoutingConfigAutoRoutingMode ", "code_blocks": []}, {"heading_path": ["GenerationConfigRoutingConfigAutoRoutingMode"], "text": "GenerationConfigRoutingConfigAutoRoutingMode Type: object When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference. No Additional Properties ", "code_blocks": []}, {"heading_path": ["modelRoutingPreference"], "text": "modelRoutingPreference root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig autoMode anyOf GenerationConfigRoutingConfigAutoRoutingMode modelRoutingPreference ", "code_blocks": []}, {"heading_path": ["Modelroutingpreference"], "text": "Modelroutingpreference Default: null The model routing preference. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig autoMode anyOf GenerationConfigRoutingConfigAutoRoutingMode modelRoutingPreference anyOf item 0 Type: enum (of string) ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"UNKNOWN\" \"PRIORITIZE_QUALITY\" \"BALANCED\" \"PRIORITIZE_COST\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig autoMode anyOf GenerationConfigRoutingConfigAutoRoutingMode modelRoutingPreference anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig autoMode anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["manualMode"], "text": "manualMode root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig manualMode Default: null Manual routing. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of GenerationConfigRoutingConfigManualRoutingMode Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig manualMode anyOf GenerationConfigRoutingConfigManualRoutingMode ", "code_blocks": []}, {"heading_path": ["GenerationConfigRoutingConfigManualRoutingMode"], "text": "GenerationConfigRoutingConfigManualRoutingMode Type: object When manual routing is set, the specified model will be used directly. No Additional Properties ", "code_blocks": []}, {"heading_path": ["modelName"], "text": "modelName root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig manualMode anyOf GenerationConfigRoutingConfigManualRoutingMode modelName ", "code_blocks": []}, {"heading_path": ["Modelname"], "text": "Modelname Default: null The model name to use. Only the public LLM models are accepted. See Supported models . ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig manualMode anyOf GenerationConfigRoutingConfigManualRoutingMode modelName anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig manualMode anyOf GenerationConfigRoutingConfigManualRoutingMode modelName anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf GenerationConfigRoutingConfig manualMode anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig routingConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["modelSelectionConfig"], "text": "modelSelectionConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig modelSelectionConfig Default: null Configuration for model selection. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ModelSelectionConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig modelSelectionConfig anyOf ModelSelectionConfig ", "code_blocks": []}, {"heading_path": ["ModelSelectionConfig"], "text": "ModelSelectionConfig Type: object Config for model selection. No Additional Properties ", "code_blocks": []}, {"heading_path": ["featureSelectionPreference"], "text": "featureSelectionPreference root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig modelSelectionConfig anyOf ModelSelectionConfig featureSelectionPreference Default: null Options for feature selection preference. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FeatureSelectionPreference Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig modelSelectionConfig anyOf ModelSelectionConfig featureSelectionPreference anyOf FeatureSelectionPreference ", "code_blocks": []}, {"heading_path": ["FeatureSelectionPreference"], "text": "FeatureSelectionPreference Type: enum (of string) Options for feature selection preference. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"FEATURE_SELECTION_PREFERENCE_UNSPECIFIED\" \"PRIORITIZE_QUALITY\" \"BALANCED\" \"PRIORITIZE_COST\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig modelSelectionConfig anyOf ModelSelectionConfig featureSelectionPreference anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig modelSelectionConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["safetySettings"], "text": "safetySettings root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings ", "code_blocks": []}, {"heading_path": ["Safetysettings"], "text": "Safetysettings Default: null Safety settings in the request to block unsafe content in the response. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting ", "code_blocks": []}, {"heading_path": ["SafetySetting"], "text": "SafetySetting Type: object Safety settings. No Additional Properties ", "code_blocks": []}, {"heading_path": ["method"], "text": "method root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting method Default: null Determines if the harm block method uses probability or probability and severity scores. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of HarmBlockMethod Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting method anyOf HarmBlockMethod ", "code_blocks": []}, {"heading_path": ["HarmBlockMethod"], "text": "HarmBlockMethod Type: enum (of string) Optional. Specify if the threshold is used for probability or severity score. If not specified, the threshold is used for probability score. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"HARM_BLOCK_METHOD_UNSPECIFIED\" \"SEVERITY\" \"PROBABILITY\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting method anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["category"], "text": "category root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting category Default: null Required. Harm category. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of HarmCategory Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting category anyOf HarmCategory ", "code_blocks": []}, {"heading_path": ["HarmCategory"], "text": "HarmCategory Type: enum (of string) Required. Harm category. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"HARM_CATEGORY_UNSPECIFIED\" \"HARM_CATEGORY_HATE_SPEECH\" \"HARM_CATEGORY_DANGEROUS_CONTENT\" \"HARM_CATEGORY_HARASSMENT\" \"HARM_CATEGORY_SEXUALLY_EXPLICIT\" \"HARM_CATEGORY_CIVIC_INTEGRITY\" \"HARM_CATEGORY_IMAGE_HATE\" \"HARM_CATEGORY_IMAGE_DANGEROUS_CONTENT\" \"HARM_CATEGORY_IMAGE_HARASSMENT\" \"HARM_CATEGORY_IMAGE_SEXUALLY_EXPLICIT\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting category anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["threshold"], "text": "threshold root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting threshold Default: null Required. The harm block threshold. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of HarmBlockThreshold Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting threshold anyOf HarmBlockThreshold ", "code_blocks": []}, {"heading_path": ["HarmBlockThreshold"], "text": "HarmBlockThreshold Type: enum (of string) Required. The harm block threshold. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"HARM_BLOCK_THRESHOLD_UNSPECIFIED\" \"BLOCK_LOW_AND_ABOVE\" \"BLOCK_MEDIUM_AND_ABOVE\" \"BLOCK_ONLY_HIGH\" \"BLOCK_NONE\" \"OFF\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 0 SafetySetting threshold anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig safetySettings anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["tools"], "text": "tools root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools ", "code_blocks": []}, {"heading_path": ["Tools"], "text": "Tools Default: null Code that enables the system to interact with external systems to perform an action outside of the knowledge and scope of the model. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Tool Tool root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool ", "code_blocks": []}, {"heading_path": ["Tool"], "text": "Tool Type: object Tool details of a tool that the model may use to generate a response. No Additional Properties ", "code_blocks": []}, {"heading_path": ["functionDeclarations"], "text": "functionDeclarations root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations ", "code_blocks": []}, {"heading_path": ["Functiondeclarations"], "text": "Functiondeclarations Default: null List of function declarations that the tool supports. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration ", "code_blocks": []}, {"heading_path": ["FunctionDeclaration"], "text": "FunctionDeclaration Type: object Defines a function that the model can generate JSON inputs for. The inputs are based on OpenAPI 3.0 specifications\n<https://spec.openapis.org/oas/v3.0.3> _. No Additional Properties ", "code_blocks": []}, {"heading_path": ["behavior"], "text": "behavior root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration behavior Default: null Defines the function behavior. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Behavior Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration behavior anyOf Behavior ", "code_blocks": []}, {"heading_path": ["Behavior"], "text": "Behavior Type: enum (of string) Defines the function behavior. Defaults to BLOCKING . ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"UNSPECIFIED\" \"BLOCKING\" \"NON_BLOCKING\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration behavior anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["description"], "text": "description root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration description ", "code_blocks": []}, {"heading_path": ["Description"], "text": "Description Default: null Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration description anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration description anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["name"], "text": "name root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Default: null Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration name anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration name anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["parameters"], "text": "parameters root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration parameters Default: null Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1 ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Schema Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration parameters anyOf Schema ", "code_blocks": []}, {"heading_path": ["Schema"], "text": "Schema Type: object Schema is used to define the format of input/output data. Represents a select subset of an OpenAPI 3.0 schema object . More fields may be added in the future as needed. Same definition as Schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration parameters anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["parametersJsonSchema"], "text": "parametersJsonSchema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration parametersJsonSchema ", "code_blocks": []}, {"heading_path": ["Parametersjsonschema"], "text": "Parametersjsonschema Default: null Optional. Describes the parameters to the function in JSON Schema format. The schema must describe an object where the properties are the parameters to the function. For example: { \"type\": \"object\", \"properties\": { \"name\": { \"type\": \"string\" }, \"age\": { \"type\": \"integer\" } }, \"additionalProperties\": false, \"required\": [\"name\", \"age\"], \"propertyOrdering\": [\"name\", \"age\"] } This field is mutually exclusive with parameters . ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration parametersJsonSchema anyOf item 0 Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration parametersJsonSchema anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["response"], "text": "response root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration response Default: null Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Schema Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration response anyOf Schema ", "code_blocks": []}, {"heading_path": ["Schema"], "text": "Schema Type: object Schema is used to define the format of input/output data. Represents a select subset of an OpenAPI 3.0 schema object . More fields may be added in the future as needed. Same definition as Schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration response anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["responseJsonSchema"], "text": "responseJsonSchema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration responseJsonSchema ", "code_blocks": []}, {"heading_path": ["Responsejsonschema"], "text": "Responsejsonschema Default: null Optional. Describes the output from this function in JSON Schema format. The value specified by the schema is the response value of the function. This field is mutually exclusive with response . ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration responseJsonSchema anyOf item 0 Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 0 FunctionDeclaration responseJsonSchema anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool functionDeclarations anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["retrieval"], "text": "retrieval root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval Default: null Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Retrieval Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval ", "code_blocks": []}, {"heading_path": ["Retrieval"], "text": "Retrieval Type: object Defines a retrieval tool that model can call to access external knowledge. No Additional Properties ", "code_blocks": []}, {"heading_path": ["disableAttribution"], "text": "disableAttribution root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval disableAttribution ", "code_blocks": []}, {"heading_path": ["Disableattribution"], "text": "Disableattribution Default: null Optional. Deprecated. This option is no longer supported. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval disableAttribution anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval disableAttribution anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["externalApi"], "text": "externalApi root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi Default: null Use data source powered by external API for grounding. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ExternalApi Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi ", "code_blocks": []}, {"heading_path": ["ExternalApi"], "text": "ExternalApi Type: object Retrieve from data source powered by external API for grounding. The external API is not owned by Google, but need to follow the pre-defined API spec. No Additional Properties ", "code_blocks": []}, {"heading_path": ["apiAuth"], "text": "apiAuth root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth Default: null The authentication config to access the API. Deprecated. Please use auth_config instead. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ApiAuth Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth ", "code_blocks": []}, {"heading_path": ["ApiAuth"], "text": "ApiAuth Type: object The generic reusable api auth config. Deprecated. Please use AuthConfig (google/cloud/aiplatform/master/auth.proto) instead. No Additional Properties ", "code_blocks": []}, {"heading_path": ["apiKeyConfig"], "text": "apiKeyConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth apiKeyConfig Default: null The API secret. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ApiAuthApiKeyConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth apiKeyConfig anyOf ApiAuthApiKeyConfig ", "code_blocks": []}, {"heading_path": ["ApiAuthApiKeyConfig"], "text": "ApiAuthApiKeyConfig Type: object The API secret. No Additional Properties ", "code_blocks": []}, {"heading_path": ["apiKeySecretVersion"], "text": "apiKeySecretVersion root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth apiKeyConfig anyOf ApiAuthApiKeyConfig apiKeySecretVersion ", "code_blocks": []}, {"heading_path": ["Apikeysecretversion"], "text": "Apikeysecretversion Default: null Required. The SecretManager secret version resource name storing API key. e.g. projects/{project}/secrets/{secret}/versions/{version} ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth apiKeyConfig anyOf ApiAuthApiKeyConfig apiKeySecretVersion anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth apiKeyConfig anyOf ApiAuthApiKeyConfig apiKeySecretVersion anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["apiKeyString"], "text": "apiKeyString root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth apiKeyConfig anyOf ApiAuthApiKeyConfig apiKeyString ", "code_blocks": []}, {"heading_path": ["Apikeystring"], "text": "Apikeystring Default: null The API key string. Either this or api_key_secret_version must be set. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth apiKeyConfig anyOf ApiAuthApiKeyConfig apiKeyString anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth apiKeyConfig anyOf ApiAuthApiKeyConfig apiKeyString anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf ApiAuth apiKeyConfig anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiAuth anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["apiSpec"], "text": "apiSpec root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiSpec Default: null The API spec that the external API implements. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ApiSpec Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiSpec anyOf ApiSpec ", "code_blocks": []}, {"heading_path": ["ApiSpec"], "text": "ApiSpec Type: enum (of string) The API spec that the external API implements. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"API_SPEC_UNSPECIFIED\" \"SIMPLE_SEARCH\" \"ELASTIC_SEARCH\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi apiSpec anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["authConfig"], "text": "authConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig Default: null The authentication config to access the API. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of AuthConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig ", "code_blocks": []}, {"heading_path": ["AuthConfig"], "text": "AuthConfig Type: object Auth configuration to run the extension. No Additional Properties ", "code_blocks": []}, {"heading_path": ["apiKeyConfig"], "text": "apiKeyConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig apiKeyConfig Default: null Config for API key auth. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ApiKeyConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig apiKeyConfig anyOf ApiKeyConfig ", "code_blocks": []}, {"heading_path": ["ApiKeyConfig"], "text": "ApiKeyConfig Type: object Config for authentication with API key. No Additional Properties ", "code_blocks": []}, {"heading_path": ["apiKeyString"], "text": "apiKeyString root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig apiKeyConfig anyOf ApiKeyConfig apiKeyString ", "code_blocks": []}, {"heading_path": ["Apikeystring"], "text": "Apikeystring Default: null The API key to be used in the request directly. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig apiKeyConfig anyOf ApiKeyConfig apiKeyString anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig apiKeyConfig anyOf ApiKeyConfig apiKeyString anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig apiKeyConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["authType"], "text": "authType root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig authType Default: null Type of auth scheme. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of AuthType Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig authType anyOf AuthType ", "code_blocks": []}, {"heading_path": ["AuthType"], "text": "AuthType Type: enum (of string) Type of auth scheme. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"AUTH_TYPE_UNSPECIFIED\" \"NO_AUTH\" \"API_KEY_AUTH\" \"HTTP_BASIC_AUTH\" \"GOOGLE_SERVICE_ACCOUNT_AUTH\" \"OAUTH\" \"OIDC_AUTH\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig authType anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["googleServiceAccountConfig"], "text": "googleServiceAccountConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig googleServiceAccountConfig Default: null Config for Google Service Account auth. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of AuthConfigGoogleServiceAccountConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig googleServiceAccountConfig anyOf AuthConfigGoogleServiceAccountConfig ", "code_blocks": []}, {"heading_path": ["AuthConfigGoogleServiceAccountConfig"], "text": "AuthConfigGoogleServiceAccountConfig Type: object Config for Google Service Account Authentication. No Additional Properties ", "code_blocks": []}, {"heading_path": ["serviceAccount"], "text": "serviceAccount root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig googleServiceAccountConfig anyOf AuthConfigGoogleServiceAccountConfig serviceAccount ", "code_blocks": []}, {"heading_path": ["Serviceaccount"], "text": "Serviceaccount Default: null Optional. The service account that the extension execution service runs as. - If the service account is specified, the iam.serviceAccounts.getAccessToken permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig googleServiceAccountConfig anyOf AuthConfigGoogleServiceAccountConfig serviceAccount anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig googleServiceAccountConfig anyOf AuthConfigGoogleServiceAccountConfig serviceAccount anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig googleServiceAccountConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["httpBasicAuthConfig"], "text": "httpBasicAuthConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig httpBasicAuthConfig Default: null Config for HTTP Basic auth. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of AuthConfigHttpBasicAuthConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig httpBasicAuthConfig anyOf AuthConfigHttpBasicAuthConfig ", "code_blocks": []}, {"heading_path": ["AuthConfigHttpBasicAuthConfig"], "text": "AuthConfigHttpBasicAuthConfig Type: object Config for HTTP Basic Authentication. No Additional Properties ", "code_blocks": []}, {"heading_path": ["credentialSecret"], "text": "credentialSecret root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig httpBasicAuthConfig anyOf AuthConfigHttpBasicAuthConfig credentialSecret ", "code_blocks": []}, {"heading_path": ["Credentialsecret"], "text": "Credentialsecret Default: null Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: projects/{project}/secrets/{secrete}/versions/{version} - If specified, the secretmanager.versions.access permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig httpBasicAuthConfig anyOf AuthConfigHttpBasicAuthConfig credentialSecret anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig httpBasicAuthConfig anyOf AuthConfigHttpBasicAuthConfig credentialSecret anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig httpBasicAuthConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["oauthConfig"], "text": "oauthConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oauthConfig Default: null Config for user oauth. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of AuthConfigOauthConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oauthConfig anyOf AuthConfigOauthConfig ", "code_blocks": []}, {"heading_path": ["AuthConfigOauthConfig"], "text": "AuthConfigOauthConfig Type: object Config for user oauth. No Additional Properties ", "code_blocks": []}, {"heading_path": ["accessToken"], "text": "accessToken root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oauthConfig anyOf AuthConfigOauthConfig accessToken ", "code_blocks": []}, {"heading_path": ["Accesstoken"], "text": "Accesstoken Default: null Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime auth config]] at request time. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oauthConfig anyOf AuthConfigOauthConfig accessToken anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oauthConfig anyOf AuthConfigOauthConfig accessToken anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["serviceAccount"], "text": "serviceAccount root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oauthConfig anyOf AuthConfigOauthConfig serviceAccount ", "code_blocks": []}, {"heading_path": ["Serviceaccount"], "text": "Serviceaccount Default: null The service account used to generate access tokens for executing the Extension. - If the service account is specified, the iam.serviceAccounts.getAccessToken permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oauthConfig anyOf AuthConfigOauthConfig serviceAccount anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oauthConfig anyOf AuthConfigOauthConfig serviceAccount anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oauthConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["oidcConfig"], "text": "oidcConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oidcConfig Default: null Config for user OIDC auth. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of AuthConfigOidcConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oidcConfig anyOf AuthConfigOidcConfig ", "code_blocks": []}, {"heading_path": ["AuthConfigOidcConfig"], "text": "AuthConfigOidcConfig Type: object Config for user OIDC auth. No Additional Properties ", "code_blocks": []}, {"heading_path": ["idToken"], "text": "idToken root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oidcConfig anyOf AuthConfigOidcConfig idToken ", "code_blocks": []}, {"heading_path": ["Idtoken"], "text": "Idtoken Default: null OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime auth config]] at request time. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oidcConfig anyOf AuthConfigOidcConfig idToken anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oidcConfig anyOf AuthConfigOidcConfig idToken anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["serviceAccount"], "text": "serviceAccount root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oidcConfig anyOf AuthConfigOidcConfig serviceAccount ", "code_blocks": []}, {"heading_path": ["Serviceaccount"], "text": "Serviceaccount Default: null The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant iam.serviceAccounts.getOpenIdToken permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents). ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oidcConfig anyOf AuthConfigOidcConfig serviceAccount anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oidcConfig anyOf AuthConfigOidcConfig serviceAccount anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf AuthConfig oidcConfig anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi authConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["elasticSearchParams"], "text": "elasticSearchParams root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams Default: null Parameters for the elastic search API. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ExternalApiElasticSearchParams Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams ", "code_blocks": []}, {"heading_path": ["ExternalApiElasticSearchParams"], "text": "ExternalApiElasticSearchParams Type: object The search parameters to use for the ELASTIC_SEARCH spec. No Additional Properties ", "code_blocks": []}, {"heading_path": ["index"], "text": "index root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams index ", "code_blocks": []}, {"heading_path": ["Index"], "text": "Index Default: null The ElasticSearch index to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams index anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams index anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["numHits"], "text": "numHits root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams numHits ", "code_blocks": []}, {"heading_path": ["Numhits"], "text": "Numhits Default: null Optional. Number of hits (chunks) to request. When specified, it is passed to Elasticsearch as the num_hits param. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams numHits anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams numHits anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["searchTemplate"], "text": "searchTemplate root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams searchTemplate ", "code_blocks": []}, {"heading_path": ["Searchtemplate"], "text": "Searchtemplate Default: null The ElasticSearch search template to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams searchTemplate anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf ExternalApiElasticSearchParams searchTemplate anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi elasticSearchParams anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["endpoint"], "text": "endpoint root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi endpoint ", "code_blocks": []}, {"heading_path": ["Endpoint"], "text": "Endpoint Default: null The endpoint of the external API. The system will call the API at this endpoint to retrieve the data for grounding. Example: https://acme.com:443/search ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi endpoint anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi endpoint anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["simpleSearchParams"], "text": "simpleSearchParams root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi simpleSearchParams Default: null Parameters for the simple search API. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ExternalApiSimpleSearchParams Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi simpleSearchParams anyOf ExternalApiSimpleSearchParams ", "code_blocks": []}, {"heading_path": ["ExternalApiSimpleSearchParams"], "text": "ExternalApiSimpleSearchParams Type: object The search parameters to use for SIMPLE_SEARCH spec. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf ExternalApi simpleSearchParams anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval externalApi anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["vertexAiSearch"], "text": "vertexAiSearch root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch Default: null Set to use data source powered by Vertex AI Search. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of VertexAISearch Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch ", "code_blocks": []}, {"heading_path": ["VertexAISearch"], "text": "VertexAISearch Type: object Retrieve from Vertex AI Search datastore or engine for grounding. datastore and engine are mutually exclusive. See https://cloud.google.com/products/agent-builder No Additional Properties ", "code_blocks": []}, {"heading_path": ["dataStoreSpecs"], "text": "dataStoreSpecs root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs ", "code_blocks": []}, {"heading_path": ["Datastorespecs"], "text": "Datastorespecs Default: null Specifications that define the specific DataStores to be searched, along with configurations for those data stores. This is only considered for Engines with multiple data stores. It should only be set if engine is used. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs anyOf item 0 VertexAISearchDataStoreSpec ", "code_blocks": []}, {"heading_path": ["VertexAISearchDataStoreSpec"], "text": "VertexAISearchDataStoreSpec Type: object Define data stores within engine to filter on in a search call and configurations for those data stores. For more information, see https://cloud.google.com/generative-ai-app-builder/docs/reference/rpc/google.cloud.discoveryengine.v1#datastorespec No Additional Properties ", "code_blocks": []}, {"heading_path": ["dataStore"], "text": "dataStore root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs anyOf item 0 VertexAISearchDataStoreSpec dataStore ", "code_blocks": []}, {"heading_path": ["Datastore"], "text": "Datastore Default: null Full resource name of DataStore, such as Format: projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore} ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs anyOf item 0 VertexAISearchDataStoreSpec dataStore anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs anyOf item 0 VertexAISearchDataStoreSpec dataStore anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["filter"], "text": "filter root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs anyOf item 0 VertexAISearchDataStoreSpec filter ", "code_blocks": []}, {"heading_path": ["Filter"], "text": "Filter Default: null Optional. Filter specification to filter documents in the data store specified by data_store field. For more information on filtering, see Filtering ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs anyOf item 0 VertexAISearchDataStoreSpec filter anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs anyOf item 0 VertexAISearchDataStoreSpec filter anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch dataStoreSpecs anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["datastore"], "text": "datastore root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch datastore ", "code_blocks": []}, {"heading_path": ["Datastore"], "text": "Datastore Default: null Optional. Fully-qualified Vertex AI Search data store resource ID. Format: projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore} ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch datastore anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch datastore anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["engine"], "text": "engine root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch engine ", "code_blocks": []}, {"heading_path": ["Engine"], "text": "Engine Default: null Optional. Fully-qualified Vertex AI Search engine resource ID. Format: projects/{project}/locations/{location}/collections/{collection}/engines/{engine} ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch engine anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch engine anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["filter"], "text": "filter root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch filter ", "code_blocks": []}, {"heading_path": ["Filter"], "text": "Filter Default: null Optional. Filter strings to be passed to the search API. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch filter anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch filter anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["maxResults"], "text": "maxResults root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch maxResults ", "code_blocks": []}, {"heading_path": ["Maxresults"], "text": "Maxresults Default: null Optional. Number of search results to return per query. The default value is 10. The maximumm allowed value is 10. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch maxResults anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf VertexAISearch maxResults anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexAiSearch anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["vertexRagStore"], "text": "vertexRagStore root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore Default: null Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of VertexRagStore Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ", "code_blocks": []}, {"heading_path": ["VertexRagStore"], "text": "VertexRagStore Type: object Retrieve from Vertex RAG Store for grounding. No Additional Properties ", "code_blocks": []}, {"heading_path": ["ragCorpora"], "text": "ragCorpora root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragCorpora ", "code_blocks": []}, {"heading_path": ["Ragcorpora"], "text": "Ragcorpora Default: null Optional. Deprecated. Please use rag_resources instead. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragCorpora anyOf item 0 Type: array of string No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragCorpora anyOf item 0 item 0 items Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragCorpora anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["ragResources"], "text": "ragResources root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources ", "code_blocks": []}, {"heading_path": ["Ragresources"], "text": "Ragresources Default: null Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 0 VertexRagStoreRagResource ", "code_blocks": []}, {"heading_path": ["VertexRagStoreRagResource"], "text": "VertexRagStoreRagResource Type: object The definition of the Rag resource. No Additional Properties ", "code_blocks": []}, {"heading_path": ["ragCorpus"], "text": "ragCorpus root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 0 VertexRagStoreRagResource ragCorpus ", "code_blocks": []}, {"heading_path": ["Ragcorpus"], "text": "Ragcorpus Default: null Optional. RagCorpora resource name. Format: projects/{project}/locations/{location}/ragCorpora/{rag_corpus} ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 0 VertexRagStoreRagResource ragCorpus anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 0 VertexRagStoreRagResource ragCorpus anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["ragFileIds"], "text": "ragFileIds root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 0 VertexRagStoreRagResource ragFileIds ", "code_blocks": []}, {"heading_path": ["Ragfileids"], "text": "Ragfileids Default: null Optional. rag file id. The files should be in the same rag corpus set in rag corpus field. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 0 VertexRagStoreRagResource ragFileIds anyOf item 0 Type: array of string No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 0 VertexRagStoreRagResource ragFileIds anyOf item 0 item 0 items Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 0 VertexRagStoreRagResource ragFileIds anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragResources anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["ragRetrievalConfig"], "text": "ragRetrievalConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig Default: null Optional. The retrieval config for the Rag query. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of RagRetrievalConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ", "code_blocks": []}, {"heading_path": ["RagRetrievalConfig"], "text": "RagRetrievalConfig Type: object Specifies the context retrieval config. No Additional Properties ", "code_blocks": []}, {"heading_path": ["filter"], "text": "filter root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter Default: null Optional. Config for filters. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of RagRetrievalConfigFilter Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter ", "code_blocks": []}, {"heading_path": ["RagRetrievalConfigFilter"], "text": "RagRetrievalConfigFilter Type: object Config for filters. No Additional Properties ", "code_blocks": []}, {"heading_path": ["metadataFilter"], "text": "metadataFilter root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter metadataFilter ", "code_blocks": []}, {"heading_path": ["Metadatafilter"], "text": "Metadatafilter Default: null Optional. String for metadata filtering. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter metadataFilter anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter metadataFilter anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["vectorDistanceThreshold"], "text": "vectorDistanceThreshold root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter vectorDistanceThreshold ", "code_blocks": []}, {"heading_path": ["Vectordistancethreshold"], "text": "Vectordistancethreshold Default: null Optional. Only returns contexts with vector distance smaller than the threshold. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter vectorDistanceThreshold anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter vectorDistanceThreshold anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["vectorSimilarityThreshold"], "text": "vectorSimilarityThreshold root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter vectorSimilarityThreshold ", "code_blocks": []}, {"heading_path": ["Vectorsimilaritythreshold"], "text": "Vectorsimilaritythreshold Default: null Optional. Only returns contexts with vector similarity larger than the threshold. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter vectorSimilarityThreshold anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf RagRetrievalConfigFilter vectorSimilarityThreshold anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig filter anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["hybridSearch"], "text": "hybridSearch root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig hybridSearch Default: null Optional. Config for Hybrid Search. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of RagRetrievalConfigHybridSearch Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig hybridSearch anyOf RagRetrievalConfigHybridSearch ", "code_blocks": []}, {"heading_path": ["RagRetrievalConfigHybridSearch"], "text": "RagRetrievalConfigHybridSearch Type: object Config for Hybrid Search. No Additional Properties ", "code_blocks": []}, {"heading_path": ["alpha"], "text": "alpha root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig hybridSearch anyOf RagRetrievalConfigHybridSearch alpha ", "code_blocks": []}, {"heading_path": ["Alpha"], "text": "Alpha Default: null Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig hybridSearch anyOf RagRetrievalConfigHybridSearch alpha anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig hybridSearch anyOf RagRetrievalConfigHybridSearch alpha anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig hybridSearch anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["ranking"], "text": "ranking root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking Default: null Optional. Config for ranking and reranking. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of RagRetrievalConfigRanking Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking ", "code_blocks": []}, {"heading_path": ["RagRetrievalConfigRanking"], "text": "RagRetrievalConfigRanking Type: object Config for ranking and reranking. No Additional Properties ", "code_blocks": []}, {"heading_path": ["llmRanker"], "text": "llmRanker root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking llmRanker Default: null Optional. Config for LlmRanker. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of RagRetrievalConfigRankingLlmRanker Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking llmRanker anyOf RagRetrievalConfigRankingLlmRanker ", "code_blocks": []}, {"heading_path": ["RagRetrievalConfigRankingLlmRanker"], "text": "RagRetrievalConfigRankingLlmRanker Type: object Config for LlmRanker. No Additional Properties ", "code_blocks": []}, {"heading_path": ["modelName"], "text": "modelName root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking llmRanker anyOf RagRetrievalConfigRankingLlmRanker modelName ", "code_blocks": []}, {"heading_path": ["Modelname"], "text": "Modelname Default: null Optional. The model name used for ranking. See Supported models . ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking llmRanker anyOf RagRetrievalConfigRankingLlmRanker modelName anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking llmRanker anyOf RagRetrievalConfigRankingLlmRanker modelName anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking llmRanker anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["rankService"], "text": "rankService root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking rankService Default: null Optional. Config for Rank Service. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of RagRetrievalConfigRankingRankService Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking rankService anyOf RagRetrievalConfigRankingRankService ", "code_blocks": []}, {"heading_path": ["RagRetrievalConfigRankingRankService"], "text": "RagRetrievalConfigRankingRankService Type: object Config for Rank Service. No Additional Properties ", "code_blocks": []}, {"heading_path": ["modelName"], "text": "modelName root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking rankService anyOf RagRetrievalConfigRankingRankService modelName ", "code_blocks": []}, {"heading_path": ["Modelname"], "text": "Modelname Default: null Optional. The model name of the rank service. Format: semantic-ranker-512@latest ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking rankService anyOf RagRetrievalConfigRankingRankService modelName anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking rankService anyOf RagRetrievalConfigRankingRankService modelName anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf RagRetrievalConfigRanking rankService anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig ranking anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["topK"], "text": "topK root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig topK ", "code_blocks": []}, {"heading_path": ["Topk"], "text": "Topk Default: null Optional. The number of contexts to retrieve. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig topK anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf RagRetrievalConfig topK anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore ragRetrievalConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["similarityTopK"], "text": "similarityTopK root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore similarityTopK ", "code_blocks": []}, {"heading_path": ["Similaritytopk"], "text": "Similaritytopk Default: null Optional. Number of top k results to return from the selected corpora. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore similarityTopK anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore similarityTopK anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["storeContext"], "text": "storeContext root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore storeContext ", "code_blocks": []}, {"heading_path": ["Storecontext"], "text": "Storecontext Default: null Optional. Currently only supported for Gemini Multimodal Live API. In Gemini Multimodal Live API, if store_context bool is specified, Gemini will leverage it to automatically memorize the interactions between the client and Gemini, and retrieve context when needed to augment the response generation for users' ongoing and future interactions. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore storeContext anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore storeContext anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["vectorDistanceThreshold"], "text": "vectorDistanceThreshold root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore vectorDistanceThreshold ", "code_blocks": []}, {"heading_path": ["Vectordistancethreshold"], "text": "Vectordistancethreshold Default: null Optional. Only return results with vector distance smaller than the threshold. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore vectorDistanceThreshold anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf VertexRagStore vectorDistanceThreshold anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf Retrieval vertexRagStore anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool retrieval anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["googleSearch"], "text": "googleSearch root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch Default: null Optional. Google Search tool type. Specialized retrieval tool that is powered by Google Search. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of GoogleSearch Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch ", "code_blocks": []}, {"heading_path": ["GoogleSearch"], "text": "GoogleSearch Type: object Tool to support Google Search in Model. Powered by Google. No Additional Properties ", "code_blocks": []}, {"heading_path": ["timeRangeFilter"], "text": "timeRangeFilter root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch timeRangeFilter Default: null Optional. Filter search results to a specific time range. If customers set a start time, they must set an end time (and vice versa). ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Interval Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch timeRangeFilter anyOf Interval ", "code_blocks": []}, {"heading_path": ["Interval"], "text": "Interval Type: object Represents a time interval, encoded as a start time (inclusive) and an end time (exclusive). The start time must be less than or equal to the end time. When the start equals the end time, the interval is an empty interval. (matches no time) When both start and end are unspecified, the interval matches any time. No Additional Properties ", "code_blocks": []}, {"heading_path": ["startTime"], "text": "startTime root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch timeRangeFilter anyOf Interval startTime ", "code_blocks": []}, {"heading_path": ["Starttime"], "text": "Starttime Default: null The start time of the interval. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch timeRangeFilter anyOf Interval startTime anyOf item 0 Type: string Format: date-time root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch timeRangeFilter anyOf Interval startTime anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["endTime"], "text": "endTime root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch timeRangeFilter anyOf Interval endTime ", "code_blocks": []}, {"heading_path": ["Endtime"], "text": "Endtime Default: null The end time of the interval. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch timeRangeFilter anyOf Interval endTime anyOf item 0 Type: string Format: date-time root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch timeRangeFilter anyOf Interval endTime anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf GoogleSearch timeRangeFilter anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearch anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["googleSearchRetrieval"], "text": "googleSearchRetrieval root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval Default: null Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of GoogleSearchRetrieval Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval ", "code_blocks": []}, {"heading_path": ["GoogleSearchRetrieval"], "text": "GoogleSearchRetrieval Type: object Tool to retrieve public web data for grounding, powered by Google. No Additional Properties ", "code_blocks": []}, {"heading_path": ["dynamicRetrievalConfig"], "text": "dynamicRetrievalConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval dynamicRetrievalConfig Default: null Specifies the dynamic retrieval configuration for the given source. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of DynamicRetrievalConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval dynamicRetrievalConfig anyOf DynamicRetrievalConfig ", "code_blocks": []}, {"heading_path": ["DynamicRetrievalConfig"], "text": "DynamicRetrievalConfig Type: object Describes the options to customize dynamic retrieval. No Additional Properties ", "code_blocks": []}, {"heading_path": ["mode"], "text": "mode root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval dynamicRetrievalConfig anyOf DynamicRetrievalConfig mode Default: null The mode of the predictor to be used in dynamic retrieval. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of DynamicRetrievalConfigMode Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval dynamicRetrievalConfig anyOf DynamicRetrievalConfig mode anyOf DynamicRetrievalConfigMode ", "code_blocks": []}, {"heading_path": ["DynamicRetrievalConfigMode"], "text": "DynamicRetrievalConfigMode Type: enum (of string) Config for the dynamic retrieval config mode. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"MODE_UNSPECIFIED\" \"MODE_DYNAMIC\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval dynamicRetrievalConfig anyOf DynamicRetrievalConfig mode anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["dynamicThreshold"], "text": "dynamicThreshold root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval dynamicRetrievalConfig anyOf DynamicRetrievalConfig dynamicThreshold ", "code_blocks": []}, {"heading_path": ["Dynamicthreshold"], "text": "Dynamicthreshold Default: null Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval dynamicRetrievalConfig anyOf DynamicRetrievalConfig dynamicThreshold anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval dynamicRetrievalConfig anyOf DynamicRetrievalConfig dynamicThreshold anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf GoogleSearchRetrieval dynamicRetrievalConfig anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleSearchRetrieval anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["enterpriseWebSearch"], "text": "enterpriseWebSearch root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool enterpriseWebSearch Default: null Optional. Enterprise web search tool type. Specialized retrieval tool that is powered by Vertex AI Search and Sec4 compliance. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of EnterpriseWebSearch Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool enterpriseWebSearch anyOf EnterpriseWebSearch ", "code_blocks": []}, {"heading_path": ["EnterpriseWebSearch"], "text": "EnterpriseWebSearch Type: object Tool to search public web data, powered by Vertex AI Search and Sec4 compliance. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool enterpriseWebSearch anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["googleMaps"], "text": "googleMaps root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleMaps Default: null Optional. Google Maps tool type. Specialized retrieval tool that is powered by Google Maps. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of GoogleMaps Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleMaps anyOf GoogleMaps ", "code_blocks": []}, {"heading_path": ["GoogleMaps"], "text": "GoogleMaps Type: object Tool to support Google Maps in Model. No Additional Properties ", "code_blocks": []}, {"heading_path": ["authConfig"], "text": "authConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleMaps anyOf GoogleMaps authConfig Default: null Optional. Auth config for the Google Maps tool. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of AuthConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleMaps anyOf GoogleMaps authConfig anyOf AuthConfig ", "code_blocks": []}, {"heading_path": ["AuthConfig"], "text": "AuthConfig Type: object Auth configuration to run the extension. Same definition as AuthConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleMaps anyOf GoogleMaps authConfig anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool googleMaps anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["urlContext"], "text": "urlContext root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool urlContext Default: null Optional. Tool to support URL context retrieval. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of UrlContext Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool urlContext anyOf UrlContext ", "code_blocks": []}, {"heading_path": ["UrlContext"], "text": "UrlContext Type: object Tool to support URL context retrieval. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool urlContext anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["codeExecution"], "text": "codeExecution root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool codeExecution Default: null Optional. CodeExecution tool type. Enables the model to execute code as part of generation. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ToolCodeExecution Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool codeExecution anyOf ToolCodeExecution ", "code_blocks": []}, {"heading_path": ["ToolCodeExecution"], "text": "ToolCodeExecution Type: object Tool that executes code generated by the model, and automatically returns the result to the model. See also [ExecutableCode]and [CodeExecutionResult] which are input and output to this tool. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool codeExecution anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["computerUse"], "text": "computerUse root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool computerUse Default: null Optional. Tool to support the model interacting directly with the computer. If enabled, it automatically populates computer-use specific Function Declarations. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ToolComputerUse Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool computerUse anyOf ToolComputerUse ", "code_blocks": []}, {"heading_path": ["ToolComputerUse"], "text": "ToolComputerUse Type: object Tool to support computer use. No Additional Properties ", "code_blocks": []}, {"heading_path": ["environment"], "text": "environment root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool computerUse anyOf ToolComputerUse environment Default: null Required. The environment being operated. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Environment Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool computerUse anyOf ToolComputerUse environment anyOf Environment ", "code_blocks": []}, {"heading_path": ["Environment"], "text": "Environment Type: enum (of string) Required. The environment being operated. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"ENVIRONMENT_UNSPECIFIED\" \"ENVIRONMENT_BROWSER\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool computerUse anyOf ToolComputerUse environment anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool computerUse anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool ", "code_blocks": []}, {"heading_path": ["Tool"], "text": "Tool Type: object Definition for a tool the client can call. ", "code_blocks": []}, {"heading_path": ["name Required"], "text": "name Required root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Type: string ", "code_blocks": []}, {"heading_path": ["title"], "text": "title root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool title ", "code_blocks": []}, {"heading_path": ["Title"], "text": "Title Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool title anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool title anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["description"], "text": "description root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool description ", "code_blocks": []}, {"heading_path": ["Description"], "text": "Description Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool description anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool description anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["inputSchema Required"], "text": "inputSchema Required root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool inputSchema ", "code_blocks": []}, {"heading_path": ["Inputschema"], "text": "Inputschema Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool inputSchema additionalProperties Type: object ", "code_blocks": []}, {"heading_path": ["outputSchema"], "text": "outputSchema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool outputSchema ", "code_blocks": []}, {"heading_path": ["Outputschema"], "text": "Outputschema Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool outputSchema anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool outputSchema anyOf item 0 additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool outputSchema anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["annotations"], "text": "annotations root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ToolAnnotations Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations ", "code_blocks": []}, {"heading_path": ["ToolAnnotations"], "text": "ToolAnnotations Type: object Additional properties describing a Tool to clients. NOTE: all properties in ToolAnnotations are hints . They are not guaranteed to provide a faithful description of tool behavior (including descriptive properties like title ). Clients should never make tool use decisions based on ToolAnnotations received from untrusted servers. ", "code_blocks": []}, {"heading_path": ["title"], "text": "title root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations title ", "code_blocks": []}, {"heading_path": ["Title"], "text": "Title Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations title anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations title anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["readOnlyHint"], "text": "readOnlyHint root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations readOnlyHint ", "code_blocks": []}, {"heading_path": ["Readonlyhint"], "text": "Readonlyhint Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations readOnlyHint anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations readOnlyHint anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["destructiveHint"], "text": "destructiveHint root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations destructiveHint ", "code_blocks": []}, {"heading_path": ["Destructivehint"], "text": "Destructivehint Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations destructiveHint anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations destructiveHint anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["idempotentHint"], "text": "idempotentHint root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations idempotentHint ", "code_blocks": []}, {"heading_path": ["Idempotenthint"], "text": "Idempotenthint Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations idempotentHint anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations idempotentHint anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["openWorldHint"], "text": "openWorldHint root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations openWorldHint ", "code_blocks": []}, {"heading_path": ["Openworldhint"], "text": "Openworldhint Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations openWorldHint anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations openWorldHint anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf ToolAnnotations additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool annotations anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["_meta"], "text": "_meta root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool _meta ", "code_blocks": []}, {"heading_path": ["Meta"], "text": "Meta Default: null ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool _meta anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool _meta anyOf item 0 additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool _meta anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 0 item 0 items anyOf Tool additionalProperties Type: object root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig tools anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["toolConfig"], "text": "toolConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig Default: null Associates model output to a specific function call. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ToolConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig ", "code_blocks": []}, {"heading_path": ["ToolConfig"], "text": "ToolConfig Type: object Tool config. This config is shared for all tools provided in the request. No Additional Properties ", "code_blocks": []}, {"heading_path": ["functionCallingConfig"], "text": "functionCallingConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig Default: null Optional. Function calling config. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FunctionCallingConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig anyOf FunctionCallingConfig ", "code_blocks": []}, {"heading_path": ["FunctionCallingConfig"], "text": "FunctionCallingConfig Type: object Function calling config. No Additional Properties ", "code_blocks": []}, {"heading_path": ["mode"], "text": "mode root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig anyOf FunctionCallingConfig mode Default: null Optional. Function calling mode. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of FunctionCallingConfigMode Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig anyOf FunctionCallingConfig mode anyOf FunctionCallingConfigMode ", "code_blocks": []}, {"heading_path": ["FunctionCallingConfigMode"], "text": "FunctionCallingConfigMode Type: enum (of string) Config for the function calling config mode. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"MODE_UNSPECIFIED\" \"AUTO\" \"ANY\" \"NONE\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig anyOf FunctionCallingConfig mode anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["allowedFunctionNames"], "text": "allowedFunctionNames root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig anyOf FunctionCallingConfig allowedFunctionNames ", "code_blocks": []}, {"heading_path": ["Allowedfunctionnames"], "text": "Allowedfunctionnames Default: null Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig anyOf FunctionCallingConfig allowedFunctionNames anyOf item 0 Type: array of string No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig anyOf FunctionCallingConfig allowedFunctionNames anyOf item 0 item 0 items Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig anyOf FunctionCallingConfig allowedFunctionNames anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig functionCallingConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["retrievalConfig"], "text": "retrievalConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig Default: null Optional. Retrieval config. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of RetrievalConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig ", "code_blocks": []}, {"heading_path": ["RetrievalConfig"], "text": "RetrievalConfig Type: object Retrieval config. No Additional Properties ", "code_blocks": []}, {"heading_path": ["latLng"], "text": "latLng root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig latLng Default: null Optional. The location of the user. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of LatLng Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig latLng anyOf LatLng ", "code_blocks": []}, {"heading_path": ["LatLng"], "text": "LatLng Type: object An object that represents a latitude/longitude pair. This is expressed as a pair of doubles to represent degrees latitude and degrees longitude. Unless specified otherwise, this object must conform to the <a href=\"https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version\"> WGS84 standard</a>. Values must be within normalized ranges. No Additional Properties ", "code_blocks": []}, {"heading_path": ["latitude"], "text": "latitude root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig latLng anyOf LatLng latitude ", "code_blocks": []}, {"heading_path": ["Latitude"], "text": "Latitude Default: null The latitude in degrees. It must be in the range [-90.0, +90.0]. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig latLng anyOf LatLng latitude anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig latLng anyOf LatLng latitude anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["longitude"], "text": "longitude root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig latLng anyOf LatLng longitude ", "code_blocks": []}, {"heading_path": ["Longitude"], "text": "Longitude Default: null The longitude in degrees. It must be in the range [-180.0, +180.0] ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig latLng anyOf LatLng longitude anyOf item 0 Type: number root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig latLng anyOf LatLng longitude anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig latLng anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["languageCode"], "text": "languageCode root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig languageCode ", "code_blocks": []}, {"heading_path": ["Languagecode"], "text": "Languagecode Default: null The language code of the user. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig languageCode anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf RetrievalConfig languageCode anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf ToolConfig retrievalConfig anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig toolConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["labels"], "text": "labels root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig labels ", "code_blocks": []}, {"heading_path": ["Labels"], "text": "Labels Default: null Labels with user-defined metadata to break down billed charges. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig labels anyOf item 0 Type: object ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Each additional property must conform to the following schema root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig labels anyOf item 0 additionalProperties Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig labels anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["cachedContent"], "text": "cachedContent root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig cachedContent ", "code_blocks": []}, {"heading_path": ["Cachedcontent"], "text": "Cachedcontent Default: null Resource name of a context cache that can be used in subsequent requests. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig cachedContent anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig cachedContent anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["responseModalities"], "text": "responseModalities root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseModalities ", "code_blocks": []}, {"heading_path": ["Responsemodalities"], "text": "Responsemodalities Default: null The requested modalities of the response. Represents the set of modalities that the model can return. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseModalities anyOf item 0 Type: array of string No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseModalities anyOf item 0 item 0 items Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig responseModalities anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["mediaResolution"], "text": "mediaResolution root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig mediaResolution Default: null If specified, the media resolution specified will be used. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of MediaResolution Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig mediaResolution anyOf MediaResolution ", "code_blocks": []}, {"heading_path": ["MediaResolution"], "text": "MediaResolution Type: enum (of string) The media resolution to use. ", "code_blocks": []}, {"heading_path": ["Must be one of:"], "text": "Must be one of: \"MEDIA_RESOLUTION_UNSPECIFIED\" \"MEDIA_RESOLUTION_LOW\" \"MEDIA_RESOLUTION_MEDIUM\" \"MEDIA_RESOLUTION_HIGH\" root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig mediaResolution anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["speechConfig"], "text": "speechConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig ", "code_blocks": []}, {"heading_path": ["Speechconfig"], "text": "Speechconfig Default: null The speech generation configuration. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of SpeechConfig Option 2 Option 3 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig ", "code_blocks": []}, {"heading_path": ["SpeechConfig"], "text": "SpeechConfig Type: object The speech generation configuration. No Additional Properties ", "code_blocks": []}, {"heading_path": ["voiceConfig"], "text": "voiceConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig voiceConfig Default: null The configuration for the speaker to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of VoiceConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig voiceConfig anyOf VoiceConfig ", "code_blocks": []}, {"heading_path": ["VoiceConfig"], "text": "VoiceConfig Type: object The configuration for the voice to use. No Additional Properties ", "code_blocks": []}, {"heading_path": ["prebuiltVoiceConfig"], "text": "prebuiltVoiceConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig voiceConfig anyOf VoiceConfig prebuiltVoiceConfig Default: null The configuration for the speaker to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of PrebuiltVoiceConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig voiceConfig anyOf VoiceConfig prebuiltVoiceConfig anyOf PrebuiltVoiceConfig ", "code_blocks": []}, {"heading_path": ["PrebuiltVoiceConfig"], "text": "PrebuiltVoiceConfig Type: object The configuration for the prebuilt speaker to use. No Additional Properties ", "code_blocks": []}, {"heading_path": ["voiceName"], "text": "voiceName root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig voiceConfig anyOf VoiceConfig prebuiltVoiceConfig anyOf PrebuiltVoiceConfig voiceName ", "code_blocks": []}, {"heading_path": ["Voicename"], "text": "Voicename Default: null The name of the prebuilt voice to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig voiceConfig anyOf VoiceConfig prebuiltVoiceConfig anyOf PrebuiltVoiceConfig voiceName anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig voiceConfig anyOf VoiceConfig prebuiltVoiceConfig anyOf PrebuiltVoiceConfig voiceName anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig voiceConfig anyOf VoiceConfig prebuiltVoiceConfig anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig voiceConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["multiSpeakerVoiceConfig"], "text": "multiSpeakerVoiceConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig Default: null The configuration for the multi-speaker setup. It is mutually exclusive with the voice_config field. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of MultiSpeakerVoiceConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig ", "code_blocks": []}, {"heading_path": ["MultiSpeakerVoiceConfig"], "text": "MultiSpeakerVoiceConfig Type: object The configuration for the multi-speaker setup. No Additional Properties ", "code_blocks": []}, {"heading_path": ["speakerVoiceConfigs"], "text": "speakerVoiceConfigs root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs ", "code_blocks": []}, {"heading_path": ["Speakervoiceconfigs"], "text": "Speakervoiceconfigs Default: null The configuration for the speaker to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs anyOf item 0 SpeakerVoiceConfig ", "code_blocks": []}, {"heading_path": ["SpeakerVoiceConfig"], "text": "SpeakerVoiceConfig Type: object The configuration for the speaker to use. No Additional Properties ", "code_blocks": []}, {"heading_path": ["speaker"], "text": "speaker root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs anyOf item 0 SpeakerVoiceConfig speaker ", "code_blocks": []}, {"heading_path": ["Speaker"], "text": "Speaker Default: null The name of the speaker to use. Should be the same as in the prompt. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs anyOf item 0 SpeakerVoiceConfig speaker anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs anyOf item 0 SpeakerVoiceConfig speaker anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["voiceConfig"], "text": "voiceConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs anyOf item 0 SpeakerVoiceConfig voiceConfig Default: null The configuration for the voice to use. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of VoiceConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs anyOf item 0 SpeakerVoiceConfig voiceConfig anyOf VoiceConfig ", "code_blocks": []}, {"heading_path": ["VoiceConfig"], "text": "VoiceConfig Type: object The configuration for the voice to use. Same definition as VoiceConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs anyOf item 0 SpeakerVoiceConfig voiceConfig anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf MultiSpeakerVoiceConfig speakerVoiceConfigs anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig multiSpeakerVoiceConfig anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["languageCode"], "text": "languageCode root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig languageCode ", "code_blocks": []}, {"heading_path": ["Languagecode"], "text": "Languagecode Default: null Language code (ISO 639. e.g. en-US) for the speech synthesization. Only available for Live API. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig languageCode anyOf item 0 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf SpeechConfig languageCode anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf item 1 Type: string root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig speechConfig anyOf item 2 Type: null ", "code_blocks": []}, {"heading_path": ["audioTimestamp"], "text": "audioTimestamp root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig audioTimestamp ", "code_blocks": []}, {"heading_path": ["Audiotimestamp"], "text": "Audiotimestamp Default: null If enabled, audio timestamp will be included in the request to the model. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig audioTimestamp anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig audioTimestamp anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["automaticFunctionCalling"], "text": "automaticFunctionCalling root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling Default: null The configuration for automatic function calling. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of AutomaticFunctionCallingConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig ", "code_blocks": []}, {"heading_path": ["AutomaticFunctionCallingConfig"], "text": "AutomaticFunctionCallingConfig Type: object The configuration for automatic function calling. No Additional Properties ", "code_blocks": []}, {"heading_path": ["disable"], "text": "disable root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig disable ", "code_blocks": []}, {"heading_path": ["Disable"], "text": "Disable Default: null Whether to disable automatic function calling. If not set or set to False, will enable automatic function calling. If set to True, will disable automatic function calling. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig disable anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig disable anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["maximumRemoteCalls"], "text": "maximumRemoteCalls root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig maximumRemoteCalls ", "code_blocks": []}, {"heading_path": ["Maximumremotecalls"], "text": "Maximumremotecalls Default: 10 If automatic function calling is enabled, maximum number of remote calls for automatic function calling. This number should be a positive integer. If not set, SDK will set maximum number of remote calls to 10. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig maximumRemoteCalls anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig maximumRemoteCalls anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["ignoreCallHistory"], "text": "ignoreCallHistory root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig ignoreCallHistory ", "code_blocks": []}, {"heading_path": ["Ignorecallhistory"], "text": "Ignorecallhistory Default: null If automatic function calling is enabled, whether to ignore call history to the response. If not set, SDK will set ignore call history to false, and will append the call history to GenerateContentResponse.automatic function calling_history. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig ignoreCallHistory anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf AutomaticFunctionCallingConfig ignoreCallHistory anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig automaticFunctionCalling anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["thinkingConfig"], "text": "thinkingConfig root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig thinkingConfig Default: null The thinking features configuration. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of ThinkingConfig Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig thinkingConfig anyOf ThinkingConfig ", "code_blocks": []}, {"heading_path": ["ThinkingConfig"], "text": "ThinkingConfig Type: object The thinking features configuration. No Additional Properties ", "code_blocks": []}, {"heading_path": ["includeThoughts"], "text": "includeThoughts root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig thinkingConfig anyOf ThinkingConfig includeThoughts ", "code_blocks": []}, {"heading_path": ["Includethoughts"], "text": "Includethoughts Default: null Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig thinkingConfig anyOf ThinkingConfig includeThoughts anyOf item 0 Type: boolean root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig thinkingConfig anyOf ThinkingConfig includeThoughts anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["thinkingBudget"], "text": "thinkingBudget root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig thinkingConfig anyOf ThinkingConfig thinkingBudget ", "code_blocks": []}, {"heading_path": ["Thinkingbudget"], "text": "Thinkingbudget Default: null Indicates the thinking budget in tokens. 0 is DISABLED. -1 is AUTOMATIC. The default values and allowed ranges are model dependent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig thinkingConfig anyOf ThinkingConfig thinkingBudget anyOf item 0 Type: integer root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig thinkingConfig anyOf ThinkingConfig thinkingBudget anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf GenerateContentConfig thinkingConfig anyOf item 1 Type: null root anyOf LlmAgentConfig generate_content_config anyOf item 1 Type: null root anyOf LoopAgentConfig ", "code_blocks": []}, {"heading_path": ["LoopAgentConfig"], "text": "LoopAgentConfig Type: object The config for the YAML schema of a LoopAgent. No Additional Properties ", "code_blocks": []}, {"heading_path": ["agent_class"], "text": "agent_class root anyOf LoopAgentConfig agent_class ", "code_blocks": []}, {"heading_path": ["Agent Class"], "text": "Agent Class Type: const Default: \"LoopAgent\" The value is used to uniquely identify the LoopAgent class. Specific value: \"LoopAgent\" ", "code_blocks": []}, {"heading_path": ["name Required"], "text": "name Required root anyOf LoopAgentConfig name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Type: string Required. The name of the agent. ", "code_blocks": []}, {"heading_path": ["description"], "text": "description root anyOf LoopAgentConfig description ", "code_blocks": []}, {"heading_path": ["Description"], "text": "Description Type: string Default: \"\" Optional. The description of the agent. ", "code_blocks": []}, {"heading_path": ["sub_agents"], "text": "sub_agents root anyOf LoopAgentConfig sub_agents ", "code_blocks": []}, {"heading_path": ["Sub Agents"], "text": "Sub Agents Default: null Optional. The sub-agents of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LoopAgentConfig sub_agents anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LoopAgentConfig sub_agents anyOf item 0 AgentRefConfig ", "code_blocks": []}, {"heading_path": ["AgentRefConfig"], "text": "AgentRefConfig Type: object The config for the reference to another agent. Same definition as AgentRefConfig root anyOf LoopAgentConfig sub_agents anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["before_agent_callbacks"], "text": "before_agent_callbacks root anyOf LoopAgentConfig before_agent_callbacks ", "code_blocks": []}, {"heading_path": ["Before Agent Callbacks"], "text": "Before Agent Callbacks Default: null Optional. The before agent callbacks of the agent. Example: before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback ", "code_blocks": [{"language": "text", "code": "before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback"}]}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LoopAgentConfig before_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LoopAgentConfig before_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf LoopAgentConfig before_agent_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["after_agent_callbacks"], "text": "after_agent_callbacks root anyOf LoopAgentConfig after_agent_callbacks ", "code_blocks": []}, {"heading_path": ["After Agent Callbacks"], "text": "After Agent Callbacks Default: null Optional. The after agent callbacks of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LoopAgentConfig after_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf LoopAgentConfig after_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf LoopAgentConfig after_agent_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["max_iterations"], "text": "max_iterations root anyOf LoopAgentConfig max_iterations ", "code_blocks": []}, {"heading_path": ["Max Iterations"], "text": "Max Iterations Default: null Optional. LoopAgent.max_iterations. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf LoopAgentConfig max_iterations anyOf item 0 Type: integer root anyOf LoopAgentConfig max_iterations anyOf item 1 Type: null root anyOf ParallelAgentConfig ", "code_blocks": []}, {"heading_path": ["ParallelAgentConfig"], "text": "ParallelAgentConfig Type: object The config for the YAML schema of a ParallelAgent. No Additional Properties ", "code_blocks": []}, {"heading_path": ["agent_class"], "text": "agent_class root anyOf ParallelAgentConfig agent_class ", "code_blocks": []}, {"heading_path": ["Agent Class"], "text": "Agent Class Type: const Default: \"ParallelAgent\" The value is used to uniquely identify the ParallelAgent class. Specific value: \"ParallelAgent\" ", "code_blocks": []}, {"heading_path": ["name Required"], "text": "name Required root anyOf ParallelAgentConfig name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Type: string Required. The name of the agent. ", "code_blocks": []}, {"heading_path": ["description"], "text": "description root anyOf ParallelAgentConfig description ", "code_blocks": []}, {"heading_path": ["Description"], "text": "Description Type: string Default: \"\" Optional. The description of the agent. ", "code_blocks": []}, {"heading_path": ["sub_agents"], "text": "sub_agents root anyOf ParallelAgentConfig sub_agents ", "code_blocks": []}, {"heading_path": ["Sub Agents"], "text": "Sub Agents Default: null Optional. The sub-agents of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf ParallelAgentConfig sub_agents anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf ParallelAgentConfig sub_agents anyOf item 0 AgentRefConfig ", "code_blocks": []}, {"heading_path": ["AgentRefConfig"], "text": "AgentRefConfig Type: object The config for the reference to another agent. Same definition as AgentRefConfig root anyOf ParallelAgentConfig sub_agents anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["before_agent_callbacks"], "text": "before_agent_callbacks root anyOf ParallelAgentConfig before_agent_callbacks ", "code_blocks": []}, {"heading_path": ["Before Agent Callbacks"], "text": "Before Agent Callbacks Default: null Optional. The before agent callbacks of the agent. Example: before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback ", "code_blocks": [{"language": "text", "code": "before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback"}]}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf ParallelAgentConfig before_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf ParallelAgentConfig before_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf ParallelAgentConfig before_agent_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["after_agent_callbacks"], "text": "after_agent_callbacks root anyOf ParallelAgentConfig after_agent_callbacks ", "code_blocks": []}, {"heading_path": ["After Agent Callbacks"], "text": "After Agent Callbacks Default: null Optional. The after agent callbacks of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf ParallelAgentConfig after_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf ParallelAgentConfig after_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf ParallelAgentConfig after_agent_callbacks anyOf item 1 Type: null root anyOf SequentialAgentConfig ", "code_blocks": []}, {"heading_path": ["SequentialAgentConfig"], "text": "SequentialAgentConfig Type: object The config for the YAML schema of a SequentialAgent. No Additional Properties ", "code_blocks": []}, {"heading_path": ["agent_class"], "text": "agent_class root anyOf SequentialAgentConfig agent_class ", "code_blocks": []}, {"heading_path": ["Agent Class"], "text": "Agent Class Type: const Default: \"SequentialAgent\" The value is used to uniquely identify the SequentialAgent class. Specific value: \"SequentialAgent\" ", "code_blocks": []}, {"heading_path": ["name Required"], "text": "name Required root anyOf SequentialAgentConfig name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Type: string Required. The name of the agent. ", "code_blocks": []}, {"heading_path": ["description"], "text": "description root anyOf SequentialAgentConfig description ", "code_blocks": []}, {"heading_path": ["Description"], "text": "Description Type: string Default: \"\" Optional. The description of the agent. ", "code_blocks": []}, {"heading_path": ["sub_agents"], "text": "sub_agents root anyOf SequentialAgentConfig sub_agents ", "code_blocks": []}, {"heading_path": ["Sub Agents"], "text": "Sub Agents Default: null Optional. The sub-agents of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf SequentialAgentConfig sub_agents anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf SequentialAgentConfig sub_agents anyOf item 0 AgentRefConfig ", "code_blocks": []}, {"heading_path": ["AgentRefConfig"], "text": "AgentRefConfig Type: object The config for the reference to another agent. Same definition as AgentRefConfig root anyOf SequentialAgentConfig sub_agents anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["before_agent_callbacks"], "text": "before_agent_callbacks root anyOf SequentialAgentConfig before_agent_callbacks ", "code_blocks": []}, {"heading_path": ["Before Agent Callbacks"], "text": "Before Agent Callbacks Default: null Optional. The before agent callbacks of the agent. Example: before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback ", "code_blocks": [{"language": "text", "code": "before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback"}]}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf SequentialAgentConfig before_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf SequentialAgentConfig before_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf SequentialAgentConfig before_agent_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["after_agent_callbacks"], "text": "after_agent_callbacks root anyOf SequentialAgentConfig after_agent_callbacks ", "code_blocks": []}, {"heading_path": ["After Agent Callbacks"], "text": "After Agent Callbacks Default: null Optional. The after agent callbacks of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf SequentialAgentConfig after_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf SequentialAgentConfig after_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf SequentialAgentConfig after_agent_callbacks anyOf item 1 Type: null root anyOf BaseAgentConfig ", "code_blocks": []}, {"heading_path": ["BaseAgentConfig"], "text": "BaseAgentConfig Type: object The config for the YAML schema of a BaseAgent. Do not use this class directly. It's the base class for all agent configs. ", "code_blocks": []}, {"heading_path": ["agent_class"], "text": "agent_class root anyOf BaseAgentConfig agent_class ", "code_blocks": []}, {"heading_path": ["Agent Class"], "text": "Agent Class Default: \"BaseAgent\" Required. The class of the agent. The value is used to differentiate among different agent classes. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf BaseAgentConfig agent_class anyOf item 0 Type: const Specific value: \"BaseAgent\" root anyOf BaseAgentConfig agent_class anyOf item 1 Type: string ", "code_blocks": []}, {"heading_path": ["name Required"], "text": "name Required root anyOf BaseAgentConfig name ", "code_blocks": []}, {"heading_path": ["Name"], "text": "Name Type: string Required. The name of the agent. ", "code_blocks": []}, {"heading_path": ["description"], "text": "description root anyOf BaseAgentConfig description ", "code_blocks": []}, {"heading_path": ["Description"], "text": "Description Type: string Default: \"\" Optional. The description of the agent. ", "code_blocks": []}, {"heading_path": ["sub_agents"], "text": "sub_agents root anyOf BaseAgentConfig sub_agents ", "code_blocks": []}, {"heading_path": ["Sub Agents"], "text": "Sub Agents Default: null Optional. The sub-agents of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf BaseAgentConfig sub_agents anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf BaseAgentConfig sub_agents anyOf item 0 AgentRefConfig ", "code_blocks": []}, {"heading_path": ["AgentRefConfig"], "text": "AgentRefConfig Type: object The config for the reference to another agent. Same definition as AgentRefConfig root anyOf BaseAgentConfig sub_agents anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["before_agent_callbacks"], "text": "before_agent_callbacks root anyOf BaseAgentConfig before_agent_callbacks ", "code_blocks": []}, {"heading_path": ["Before Agent Callbacks"], "text": "Before Agent Callbacks Default: null Optional. The before agent callbacks of the agent. Example: before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback ", "code_blocks": [{"language": "text", "code": "before_agent_callbacks:\n  - name: my_library.security_callbacks.before_agent_callback"}]}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf BaseAgentConfig before_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf BaseAgentConfig before_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf BaseAgentConfig before_agent_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["after_agent_callbacks"], "text": "after_agent_callbacks root anyOf BaseAgentConfig after_agent_callbacks ", "code_blocks": []}, {"heading_path": ["After Agent Callbacks"], "text": "After Agent Callbacks Default: null Optional. The after agent callbacks of the agent. ", "code_blocks": []}, {"heading_path": ["Any of"], "text": "Any of Option 1 Option 2 root anyOf BaseAgentConfig after_agent_callbacks anyOf item 0 Type: array No Additional Items ", "code_blocks": []}, {"heading_path": ["Each item of this array must be:"], "text": "Each item of this array must be: root anyOf BaseAgentConfig after_agent_callbacks anyOf item 0 CodeConfig ", "code_blocks": []}, {"heading_path": ["CodeConfig"], "text": "CodeConfig Type: object Code reference config for a variable, a function, or a class. This config is used for configuring callbacks and tools. Same definition as CodeConfig root anyOf BaseAgentConfig after_agent_callbacks anyOf item 1 Type: null ", "code_blocks": []}, {"heading_path": ["Additional Properties"], "text": "Additional Properties Additional Properties of any type are allowed. root anyOf BaseAgentConfig additionalProperties Type: object ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:52.619857", "source_type": "adk-docs"}
{"doc_id": "e42cc013b5808e0a4a97b48ea5f35c965dddb7c480ad31471b6a8b9262479fcb", "url": "https://google.github.io/adk-docs/api-reference/rest", "title": "REST API - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["REST API Reference\u00b6"], "text": "REST API Reference \u00b6 This page provides a reference for the REST API provided by the ADK web server.\nFor details on using the ADK REST API in practice, see Use the API Server . Tip You can view an updated API reference on a running ADK web server by browsing\nthe /docs location, for example at: http://localhost:8000/docs ", "code_blocks": []}, {"heading_path": ["Endpoints\u00b6"], "text": "Endpoints \u00b6 ", "code_blocks": []}, {"heading_path": ["/run\u00b6"], "text": "/run \u00b6 This endpoint executes an agent run. It takes a JSON payload with the details of the run and returns a list of events generated during the run. Request Body The request body should be a JSON object with the following fields: app_name (string, required): The name of the agent to run. user_id (string, required): The ID of the user. session_id (string, required): The ID of the session. new_message (Content, required): The new message to send to the agent. See the Content section for more details. streaming (boolean, optional): Whether to use streaming. Defaults to false . state_delta (object, optional): A delta of the state to apply before the run. Response Body The response body is a JSON array of Event objects. ", "code_blocks": []}, {"heading_path": ["/run_sse\u00b6"], "text": "/run_sse \u00b6 This endpoint executes an agent run using Server-Sent Events (SSE) for streaming responses. It takes the same JSON payload as the /run endpoint. Request Body The request body is the same as for the /run endpoint. Response Body The response is a stream of Server-Sent Events. Each event is a JSON object representing an Event . ", "code_blocks": []}, {"heading_path": ["Objects\u00b6"], "text": "Objects \u00b6 ", "code_blocks": []}, {"heading_path": ["Content object\u00b6"], "text": "Content object \u00b6 The Content object represents the content of a message. It has the following structure: { \"parts\" : [ { \"text\" : \"...\" } ], \"role\" : \"...\" } parts : A list of parts. Each part can be either text or a function call. role : The role of the author of the message (e.g., \"user\", \"model\"). ", "code_blocks": [{"language": "text", "code": "{\n  \"parts\": [\n    {\n      \"text\": \"...\"\n    }\n  ],\n  \"role\": \"...\"\n}"}]}, {"heading_path": ["Event object\u00b6"], "text": "Event object \u00b6 The Event object represents an event that occurred during an agent run. It has a complex structure with many optional fields. The most important fields are: id : The ID of the event. timestamp : The timestamp of the event. author : The author of the event. content : The content of the event. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:52.742361", "source_type": "adk-docs"}
{"doc_id": "06da4a9b596729205a74c66bee1ddb86383cef84e46c1537be89f3ce92087815", "url": "https://google.github.io/adk-docs/community", "title": "Community Resources - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Community Resources\u00b6"], "text": "Community Resources \u00b6 Welcome! This page highlights resources built and maintained by the Agent\nDevelopment Kit community. Info Google and the ADK team do not provide support for the content linked in\nthese external community resources. ", "code_blocks": []}, {"heading_path": ["Getting Started\u00b6"], "text": "Getting Started \u00b6 Video Demo ", "code_blocks": []}, {"heading_path": ["\ud83d\udcfa Introducing Agent Development Kit"], "text": "\ud83d\udcfa Introducing Agent Development Kit A demo of building a multi-agent travel planner, showcasing core design principles. Video ", "code_blocks": []}, {"heading_path": ["\ud83d\udcfa Getting started with Agent Development Kit"], "text": "\ud83d\udcfa Getting started with Agent Development Kit Learn the fundamentals of agent definition and how to run and debug your first agent. Video ", "code_blocks": []}, {"heading_path": ["\ud83d\udcfa Getting Started with ADK Tools"], "text": "\ud83d\udcfa Getting Started with ADK Tools A guide to building a software bug assistant using tools like MCP and Google Search. ", "code_blocks": []}, {"heading_path": ["Courses & Deep Dives\u00b6"], "text": "Courses & Deep Dives \u00b6 Video Course ", "code_blocks": []}, {"heading_path": ["\ud83c\udf93 ADK Masterclass: Build AI Agents & Automate Workflows"], "text": "\ud83c\udf93 ADK Masterclass: Build AI Agents & Automate Workflows A complete crash course that takes you from beginner to expert with 12 hands-on examples. Website ", "code_blocks": []}, {"heading_path": ["\ud83c\udf93 ADK Training Hub"], "text": "\ud83c\udf93 ADK Training Hub Master ADK from first principles to production with comprehensive tutorials and examples. YouTube Playlist ", "code_blocks": []}, {"heading_path": ["\ud83c\udf93 Master Agentic AI with ADK"], "text": "\ud83c\udf93 Master Agentic AI with ADK A step-by-step playlist covering everything from setup to deploying and scaling agents. YouTube Playlist ", "code_blocks": []}, {"heading_path": ["\ud83c\udf93 Google ADK End-to-end Course"], "text": "\ud83c\udf93 Google ADK End-to-end Course Build, deploy, and scale production-ready agents with this in-depth course series. Blog Series ", "code_blocks": []}, {"heading_path": ["\ud83c\udf93 Building Intelligent Agents with Google ADK"], "text": "\ud83c\udf93 Building Intelligent Agents with Google ADK A developer's guide to building intelligent agents with Google\u2019s code-first Python toolkit. YouTube Playlist ", "code_blocks": []}, {"heading_path": ["\ud83d\udcfb\ufe0f ADK News - ADK Podcast in Japanese"], "text": "\ud83d\udcfb\ufe0f ADK News - ADK Podcast in Japanese An auto-generated Japanese podcast about ADK, created by an ADK agent that covers commit logs, release notes, and blog posts. ", "code_blocks": []}, {"heading_path": ["Agent Tutorials and Demos\u00b6"], "text": "Agent Tutorials and Demos \u00b6 Video Tutorial ", "code_blocks": []}, {"heading_path": ["\ud83d\udcd6 How to Build a Data Science Agent with ADK"], "text": "\ud83d\udcd6 How to Build a Data Science Agent with ADK A deep dive into building a multi-agent system for database queries, Python analysis, and BigQuery ML. Video Tutorial ", "code_blocks": []}, {"heading_path": ["\ud83d\udcd6 Build a Browser Use Agent with ADK and Selenium"], "text": "\ud83d\udcd6 Build a Browser Use Agent with ADK and Selenium Learn to build an agent that enhances a retail website's product data by filling in missing information. Jupyter Notebook ", "code_blocks": []}, {"heading_path": ["\ud83d\udcd6 Build an E-commerce Recommendation Agent"], "text": "\ud83d\udcd6 Build an E-commerce Recommendation Agent A tutorial on creating a simple multi-agent system for generative e-commerce recommendations. Blog Post ", "code_blocks": []}, {"heading_path": ["\ud83d\udcd6 Google ADK + Vertex AI Live API"], "text": "\ud83d\udcd6 Google ADK + Vertex AI Live API Go beyond the ADK CLI by building real-time, streaming experiences with the Live API. Video Demo ", "code_blocks": []}, {"heading_path": ["\ud83d\udcfa Shopper's Concierge Demo"], "text": "\ud83d\udcfa Shopper's Concierge Demo See how AI agents can revolutionize shopping with personalized, real-time recommendations. ", "code_blocks": []}, {"heading_path": ["ADK for Java\u00b6"], "text": "ADK for Java \u00b6 Video Talk ", "code_blocks": []}, {"heading_path": ["\u2615 Discover ADK Java for Building AI Agents"], "text": "\u2615 Discover ADK Java for Building AI Agents A presentation to help you build your first AI agents in Java. YouTube Playlist ", "code_blocks": []}, {"heading_path": ["\u2615 Google ADK for Java Tutorials"], "text": "\u2615 Google ADK for Java Tutorials Step-by-step tutorials covering A2A, MCP, multi-agent systems, and callbacks in Java. Codelab ", "code_blocks": []}, {"heading_path": ["\u2615 Build AI Agents with ADK for Java"], "text": "\u2615 Build AI Agents with ADK for Java Move beyond simple LLM calls to create autonomous Java agents that reason, plan, and use tools. ", "code_blocks": []}, {"heading_path": ["Translations\u00b6"], "text": "Translations \u00b6 Community-provided translations of the ADK documentation. \ud83c\udde8\ud83c\uddf3 Chinese (\u4e2d\u6587) Documentation \ud83c\uddf0\ud83c\uddf7 Korean (\ud55c\uad6d\uc5b4) Documentation \ud83c\uddef\ud83c\uddf5 Japanese (\u65e5\u672c\u8a9e) Documentation ", "code_blocks": []}, {"heading_path": ["Contributing Your Resource\u00b6"], "text": "Contributing Your Resource \u00b6 Have an ADK resource to share (tutorial, translation, tool, video, or example)? Refer to the steps in the Contributing Guide for more information on how to get involved! Thank you for your contributions to Agent Development Kit! \u2764\ufe0f Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:53.251694", "source_type": "adk-docs"}
{"doc_id": "2c7b8c59e91d7263158874710c35b575958f704110d92d81acebb3db9244e9a4", "url": "https://google.github.io/adk-docs/contributing-guide", "title": "Contributing Guide - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Contributing Guide"], "text": "Contributing Guide Thank you for your interest in contributing to Agent Development Kit (ADK)! We\nwelcome contributions to the core frameworks, documentation, and related\ncomponents, which are listed below. This guide provides information on how to get involved. ", "code_blocks": []}, {"heading_path": ["Preparing to contribute\u00b6"], "text": "Preparing to contribute \u00b6 ", "code_blocks": []}, {"heading_path": ["Choose the right repository\u00b6"], "text": "Choose the right repository \u00b6 The ADK project is split across several repositories. Find the right one for\nyour contribution: Repository Description Detailed Guide google/adk-python Contains the core Python library source code CONTRIBUTING.md google/adk-python-community Contains community-contributed tools, integrations, and scripts CONTRIBUTING.md google/adk-go Contains the core Go library source code google/adk-java Contains the core Java library source code CONTRIBUTING.md google/adk-docs Contains the source for the documentation site you are currently reading CONTRIBUTING.md google/adk-web Contains the source for the adk web dev UI These repositories typically include a CONTRIBUTING.md file in the root of\ntheir repository with more detailed information on requirements, testing, code\nreview processes, etc. for that particular component. ", "code_blocks": []}, {"heading_path": ["Sign a CLA\u00b6"], "text": "Sign a CLA \u00b6 Contributions to this project must be accompanied by a Contributor License Agreement (CLA).\nYou (or your employer) retain the copyright to your contribution; this simply\ngives us permission to use and redistribute your contributions as part of the\nproject. If you or your current employer have already signed the Google CLA (even if it\nwas for a different project), you probably don't need to do it again. Visit https://cla.developers.google.com/ to see your current agreements or to\nsign a new one. ", "code_blocks": []}, {"heading_path": ["Review community guidelines\u00b6"], "text": "Review community guidelines \u00b6 This project follows Google's Open Source Community Guidelines . ", "code_blocks": []}, {"heading_path": ["Join the discussion\u00b6"], "text": "Join the discussion \u00b6 Have questions, want to share ideas, or discuss how you're using ADK? Head over\nto our Python or Java Discussions! This is the primary place for: Asking questions and getting help from the community and maintainers. Sharing your projects or use cases ( Show and Tell ). Discussing potential features or improvements before creating a formal issue. General conversation about ADK. ", "code_blocks": []}, {"heading_path": ["How to contribute\u00b6"], "text": "How to contribute \u00b6 There are several ways you can contribute to ADK: ", "code_blocks": []}, {"heading_path": ["Reporting issues\u00b6"], "text": "Reporting issues \u00b6 If you find a bug in the framework or an error in the documentation: Framework Bugs: Open an issue in google/adk-python or in google/adk-java Documentation Errors: Open an issue in google/adk-docs (use bug template) ", "code_blocks": []}, {"heading_path": ["Suggesting enhancements\u00b6"], "text": "Suggesting enhancements \u00b6 Have an idea for a new feature or an improvement to an existing one? Framework Enhancements: Open an issue in google/adk-python or in google/adk-java Documentation Enhancements: Open an issue in google/adk-docs ", "code_blocks": []}, {"heading_path": ["Improving documentation\u00b6"], "text": "Improving documentation \u00b6 Found a typo, unclear explanation, or missing information? Submit your changes directly: How: Submit a Pull Request (PR) with your suggested improvements. Where: Create a Pull Request in google/adk-docs ", "code_blocks": []}, {"heading_path": ["Writing code\u00b6"], "text": "Writing code \u00b6 Help fix bugs, implement new features or contribute code samples for the documentation: How: Submit a Pull Request (PR) with your code changes. Python Framework: Create a Pull Request in google/adk-python Java Framework: Create a Pull Request in google/adk-java Documentation: Create a Pull Request in google/adk-docs ", "code_blocks": []}, {"heading_path": ["Code reviews\u00b6"], "text": "Code reviews \u00b6 All contributions, including those from project members, undergo a review\n  process. We use GitHub Pull Requests (PRs) for code submission and review. Please\n  ensure your PR clearly describes the changes you are making. ", "code_blocks": []}, {"heading_path": ["License\u00b6"], "text": "License \u00b6 By contributing, you agree that your contributions will be licensed under the\nproject's Apache 2.0 License . ", "code_blocks": []}, {"heading_path": ["Questions?\u00b6"], "text": "Questions? \u00b6 If you get stuck or have questions, feel free to open an issue on the relevant\nrepository's issue tracker. Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:38:53.774302", "source_type": "adk-docs"}
{"doc_id": "0ecc7e09415d525e431cd438bd68475fe567a627c2dcc69ac75efad28ee05668", "url": "https://google.github.io/adk-docs/agents/config?tab=t.0", "title": "Agent Config - Agent Development Kit", "sections": [{"heading_path": [], "text": "Skip to content Copyright 2025 Google LLC\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License. Determine classes Header Copyright (c) 2016-2025 Martin Donath <martin.donath@squidfunk.com>\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to\n  deal in the Software without restriction, including without limitation the\n  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n  sell copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n  IN THE SOFTWARE. Determine classes Navigation ", "code_blocks": []}, {"heading_path": ["Build agents with Agent Config\u00b6"], "text": "Build agents with Agent Config \u00b6 Supported in ADK Python v1.11.0 Experimental The ADK Agent Config feature lets you build an ADK workflow without writing\ncode. An Agent Config uses a YAML format text file with a brief description of\nthe agent, allowing just about anyone to assemble and run an ADK agent. The\nfollowing is a simple example of an basic Agent Config definition: name: assistant_agent model: gemini-2.5-flash description: A helper agent that can answer users' questions. instruction: You are an agent to help answer users' various questions. You can use Agent Config files to build more complex agents which can\nincorporate Functions, Tools, Sub-Agents, and more. This page describes how to\nbuild and run ADK workflows with the Agent Config feature. For detailed\ninformation on the syntax and settings supported by the Agent Config format,\nsee the Agent Config syntax reference . Experimental The Agent Config feature is experimental and has some known limitations . We welcome your feedback ! ", "code_blocks": [{"language": "text", "code": "name: assistant_agent\nmodel: gemini-2.5-flash\ndescription: A helper agent that can answer users' questions.\ninstruction: You are an agent to help answer users' various questions."}]}, {"heading_path": ["Get started\u00b6"], "text": "Get started \u00b6 This section describes how to set up and start building agents with the ADK and\nthe Agent Config feature, including installation setup, building an agent, and\nrunning your agent. ", "code_blocks": []}, {"heading_path": ["Setup\u00b6"], "text": "Setup \u00b6 You need to install the Google Agent Development Kit libraries, and provide an\naccess key for a generative AI model such as Gemini API. This section provides\ndetails on what you must install and configure before you can run agents with\nthe Agent Config files. Note The Agent Config feature currently only supports Gemini models. For more\ninformation about additional; functional restrictions, see Known limitations . To setup ADK for use with Agent Config: Install the ADK Python libraries by following the Installation instructions. Python is currently required. For more information, see the Known limitations . Verify that ADK is installed by running the following command in your\n    terminal: adk --version This command should show the ADK version you have installed. Tip If the adk command fails to run and the version is not listed in step 2, make\nsure your Python environment is active. Execute source .venv/bin/activate in\nyour terminal on Mac and Linux. For other platform commands, see the Installation page. ", "code_blocks": [{"language": "text", "code": "adk --version"}]}, {"heading_path": ["Build an agent\u00b6"], "text": "Build an agent \u00b6 You build an agent with Agent Config using the adk create command to create\nthe project files for an agent, and then editing the root_agent.yaml file it\ngenerates for you. To create an ADK project for use with Agent Config: In your terminal window, run the following command to create a\n    config-based agent: adk create --type=config my_agent This command generates a my_agent/ folder, containing a root_agent.yaml file and an .env file. In the my_agent/.env file, set environment variables for your agent to\n    access generative AI models and other services: For Gemini model access through Google API, add a line to the\n    file with your API key: GOOGLE_GENAI_USE_VERTEXAI=0\nGOOGLE_API_KEY=<your-Google-Gemini-API-key> You can get an API key from the Google AI Studio API Keys page. For Gemini model access through Google Cloud, add these lines to the file: GOOGLE_GENAI_USE_VERTEXAI=1\nGOOGLE_CLOUD_PROJECT=<your_gcp_project>\nGOOGLE_CLOUD_LOCATION=us-central1 For information on creating a Cloud Project, see the Google Cloud docs\nfor Creating and managing projects . Using text editor, edit the Agent Config file my_agent/root_agent.yaml , as shown below: # yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json name: assistant_agent model: gemini-2.5-flash description: A helper agent that can answer users' questions. instruction: You are an agent to help answer users' various questions. You can discover more configuration options for your root_agent.yaml agent\nconfiguration file by referring to the ADK samples repository or the Agent Config syntax reference. ", "code_blocks": [{"language": "text", "code": "adk create --type=config my_agent"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=0\nGOOGLE_API_KEY=<your-Google-Gemini-API-key>"}, {"language": "text", "code": "GOOGLE_GENAI_USE_VERTEXAI=1\nGOOGLE_CLOUD_PROJECT=<your_gcp_project>\nGOOGLE_CLOUD_LOCATION=us-central1"}, {"language": "text", "code": "# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json\nname: assistant_agent\nmodel: gemini-2.5-flash\ndescription: A helper agent that can answer users' questions.\ninstruction: You are an agent to help answer users' various questions."}]}, {"heading_path": ["Run the agent\u00b6"], "text": "Run the agent \u00b6 Once you have completed editing your Agent Config, you can run your agent using\nthe web interface, command line terminal execution, or API server mode. To run your Agent Config-defined agent: In your terminal, navigate to the my_agent/ directory containing the root_agent.yaml file. Type one of the following commands to run your agent: adk web - Run web UI interface for your agent. adk run - Run your agent in the terminal without a user\n    interface. adk api_server - Run your agent as a service that can be\n    used by other applications. For more information on the ways to run your agent, see the Run Your Agent topic in the Quickstart .\nFor more information about the ADK command line options, see the ADK CLI reference . ", "code_blocks": []}, {"heading_path": ["Example configs\u00b6"], "text": "Example configs \u00b6 This section shows examples of Agent Config files to get you started building\nagents. For additional and more complete examples, see the ADK samples repository . ", "code_blocks": []}, {"heading_path": ["Built-in tool example\u00b6"], "text": "Built-in tool example \u00b6 The following example uses a built-in ADK tool function for using google search\nto provide functionality to the agent. This agent automatically uses the search\ntool to reply to user requests. # yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json name: search_agent model: gemini-2.0-flash description: 'an agent whose job it is to perform Google search queries and answer questions about the results.' instruction: You are an agent whose job is to perform Google search queries and answer questions about the results. tools: - name: google_search For more details, see the full code for this sample in the ADK sample repository . ", "code_blocks": [{"language": "text", "code": "# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json\nname: search_agent\nmodel: gemini-2.0-flash\ndescription: 'an agent whose job it is to perform Google search queries and answer questions about the results.'\ninstruction: You are an agent whose job is to perform Google search queries and answer questions about the results.\ntools:\n  - name: google_search"}]}, {"heading_path": ["Custom tool example\u00b6"], "text": "Custom tool example \u00b6 The following example uses a custom tool built with Python code and listed in\nthe tools: section of the config file. The agent uses this tool to check if a\nlist of numbers provided by the user are prime numbers. # yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json agent_class: LlmAgent model: gemini-2.5-flash name: prime_agent description: Handles checking if numbers are prime. instruction: | You are responsible for checking whether numbers are prime. When asked to check primes, you must call the check_prime tool with a list of integers. Never attempt to determine prime numbers manually. Return the prime number results to the root agent. tools: - name: ma_llm.check_prime For more details, see the full code for this sample in the ADK sample repository . ", "code_blocks": [{"language": "text", "code": "# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json\nagent_class: LlmAgent\nmodel: gemini-2.5-flash\nname: prime_agent\ndescription: Handles checking if numbers are prime.\ninstruction: |\n  You are responsible for checking whether numbers are prime.\n  When asked to check primes, you must call the check_prime tool with a list of integers.\n  Never attempt to determine prime numbers manually.\n  Return the prime number results to the root agent.\ntools:\n  - name: ma_llm.check_prime"}]}, {"heading_path": ["Sub-agents example\u00b6"], "text": "Sub-agents example \u00b6 The following example shows an agent defined with two sub-agents in the sub_agents: section, and an example tool in the tools: section of the config\nfile. This agent determines what the user wants, and delegates to one of the\nsub-agents to resolve the request. The sub-agents are defined using Agent Config\nYAML files. # yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json agent_class: LlmAgent model: gemini-2.5-flash name: root_agent description: Learning assistant that provides tutoring in code and math. instruction: | You are a learning assistant that helps students with coding and math questions. You delegate coding questions to the code_tutor_agent and math questions to the math_tutor_agent. Follow these steps: 1. If the user asks about programming or coding, delegate to the code_tutor_agent. 2. If the user asks about math concepts or problems, delegate to the math_tutor_agent. 3. Always provide clear explanations and encourage learning. sub_agents: - config_path: code_tutor_agent.yaml - config_path: math_tutor_agent.yaml For more details, see the full code for this sample in the ADK sample repository . ", "code_blocks": [{"language": "text", "code": "# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json\nagent_class: LlmAgent\nmodel: gemini-2.5-flash\nname: root_agent\ndescription: Learning assistant that provides tutoring in code and math.\ninstruction: |\n  You are a learning assistant that helps students with coding and math questions.\n\n  You delegate coding questions to the code_tutor_agent and math questions to the math_tutor_agent.\n\n  Follow these steps:\n  1. If the user asks about programming or coding, delegate to the code_tutor_agent.\n  2. If the user asks about math concepts or problems, delegate to the math_tutor_agent.\n  3. Always provide clear explanations and encourage learning.\nsub_agents:\n  - config_path: code_tutor_agent.yaml\n  - config_path: math_tutor_agent.yaml"}]}, {"heading_path": ["Deploy agent configs\u00b6"], "text": "Deploy agent configs \u00b6 You can deploy Agent Config agents with Cloud Run and Agent Engine ,\nusing the same procedure as code-based agents. For more information on how\nto prepare and deploy Agent Config-based agents, see the Cloud Run and Agent Engine deployment guides. ", "code_blocks": []}, {"heading_path": ["Known limitations\u00b6"], "text": "Known limitations \u00b6 The Agent Config feature is experimental and includes the following\nlimitations: Model support: Only Gemini models are currently supported.\n    Integration with third-party models is in progress. Programming language: The Agent Config feature currently supports\n    only Python code for tools and other functionality requiring programming code. ADK Tool support: The following ADK tools are supported by the Agent\n    Config feature, but not all tools are fully supported : google_search load_artifacts url_context exit_loop preload_memory get_user_choice enterprise_web_search load_web_page : Requires a fully-qualified path to access web\n    pages. Agent Type Support: The LangGraphAgent and A2aAgent types are\n    not yet supported. AgentTool LongRunningFunctionTool VertexAiSearchTool MCPToolset ExampleTool ", "code_blocks": []}, {"heading_path": ["Next steps\u00b6"], "text": "Next steps \u00b6 For ideas on how and what to build with ADK Agent Configs, see the yaml-based\nagent definitions in the ADK adk-samples repository. For detailed information on the syntax and settings supported by\nthe Agent Config format, see the Agent Config syntax reference . Back to top ", "code_blocks": []}, {"heading_path": ["Cookie consent"], "text": "Cookie consent We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better. Google Analytics GitHub Accept Manage settings ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:39:05.841112", "source_type": "adk-docs"}
{"doc_id": "96f55da311ff824376b0b8d6b707a8e330b2c78acdcb732117b7cdf6f39604fd", "url": "https://google.github.io/adk-docs/tools/mcp-tools", "title": "Redirecting...", "sections": [{"heading_path": [], "text": "You're being redirected to a new destination . ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:39:14.870916", "source_type": "adk-docs"}
{"doc_id": "371105beb048205be99ffbafd62bbc5e8f46b5d55a6c479fac28a4b994384678", "url": "https://google.github.io/adk-docs/api-reference/python/google-adk.html", "title": "Submodules - Agent Development Kit documentation", "sections": [{"heading_path": [], "text": "Contents Menu Expand Light mode Dark mode Auto light/dark, in light mode Auto light/dark, in dark mode Hide navigation sidebar Hide table of contents sidebar Skip to content Agent Development Kit  documentation Submodules google.adk.a2a module google.adk.agents module google.adk.artifacts module google.adk.apps package google.adk.auth module google.adk.cli module google.adk.code_executors module google.adk.errors module google.adk.evaluation module google.adk.events module google.adk.examples module google.adk.flows module google.adk.memory module google.adk.models module google.adk.planners module google.adk.platform module google.adk.plugins module google.adk.runners module google.adk.sessions module google.adk.telemetry module google.adk.tools package google.adk.tools.agent_tool module google.adk.tools.apihub_tool module google.adk.tools.application_integration_tool module google.adk.tools.authenticated_function_tool module google.adk.tools.base_authenticated_tool module google.adk.tools.base_tool module google.adk.tools.base_toolset module google.adk.tools.bigquery module google.adk.tools.crewai_tool module google.adk.tools.enterprise_search_tool module google.adk.tools.example_tool module google.adk.tools.exit_loop_tool module google.adk.tools.function_tool module google.adk.tools.get_user_choice_tool module google.adk.tools.google_api_tool module google.adk.tools.google_maps_grounding_tool module google.adk.tools.google_search_tool module google.adk.tools.langchain_tool module google.adk.tools.load_artifacts_tool module google.adk.tools.load_memory_tool module google.adk.tools.load_web_page module google.adk.tools.long_running_tool module google.adk.tools.mcp_tool module google.adk.tools.openapi_tool module google.adk.tools.preload_memory_tool module google.adk.tools.retrieval module google.adk.tools.tool_context module google.adk.tools.toolbox_toolset module google.adk.tools.transfer_to_agent_tool module google.adk.tools.url_context_tool module google.adk.tools.vertex_ai_search_tool module google.adk.utils module google.adk.version module Back to top View this page Toggle Light / Dark / Auto color theme Toggle table of contents sidebar ", "code_blocks": []}, {"heading_path": ["Submodules\u00b6"], "text": "Submodules \u00b6 ", "code_blocks": []}, {"heading_path": ["google.adk.a2a module\u00b6"], "text": "google.adk.a2a module \u00b6 ", "code_blocks": []}, {"heading_path": ["google.adk.agents module\u00b6"], "text": "google.adk.agents module \u00b6 google.adk.agents. Agent \u00b6 alias of LlmAgent pydantic model google.adk.agents. BaseAgent \u00b6 Bases: BaseModel Base class for all agents in Agent Development Kit. Show JSON schema { \"$defs\" : { \"BaseAgent\" : { \"additionalProperties\" : false , \"description\" : \"Base class for all agents in Agent Development Kit.\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" } }, \"required\" : [ \"name\" ], \"title\" : \"BaseAgent\" , \"type\" : \"object\" } }, \"$ref\" : \"#/$defs/BaseAgent\" } Fields : after_agent_callback (Callable[[google.adk.agents.callback_context.CallbackContext], Awaitable[google.genai.types.Content | None] | google.genai.types.Content | None] | list[Callable[[google.adk.agents.callback_context.CallbackContext], Awaitable[google.genai.types.Content | None] | google.genai.types.Content | None]] | None) before_agent_callback (Callable[[google.adk.agents.callback_context.CallbackContext], Awaitable[google.genai.types.Content | None] | google.genai.types.Content | None] | list[Callable[[google.adk.agents.callback_context.CallbackContext], Awaitable[google.genai.types.Content | None] | google.genai.types.Content | None]] | None) description (str) name (str) parent_agent (google.adk.agents.base_agent.BaseAgent | None) sub_agents (list[google.adk.agents.base_agent.BaseAgent]) Validators : validate_name \u00bb name field after_agent_callback : Optional[AfterAgentCallback] = None \u00b6 Callback or list of callbacks to be invoked after the agent run. When a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None. Parameters : callback_context \u2013 MUST be named \u2018callback_context\u2019 (enforced). Returns : The content to return to the user. When the content is present, the provided content will be used as agent\nresponse and appended to event history as agent response. Return type : Optional[types.Content] field before_agent_callback : Optional[BeforeAgentCallback] = None \u00b6 Callback or list of callbacks to be invoked before the agent run. When a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None. Parameters : callback_context \u2013 MUST be named \u2018callback_context\u2019 (enforced). Returns : The content to return to the user. When the content is present, the agent run will be skipped and the\nprovided content will be returned to user. Return type : Optional[types.Content] field description : str = '' \u00b6 Description about the agent\u2019s capability. The model uses this to determine whether to delegate control to the agent.\nOne-line description is enough and preferred. field name : str [Required] \u00b6 The agent\u2019s name. Agent name must be a Python identifier and unique within the agent tree.\nAgent name cannot be \u201cuser\u201d, since it\u2019s reserved for end-user\u2019s input. Validated by : validate_name field parent_agent : Optional[BaseAgent] = None \u00b6 The parent agent of this agent. Note that an agent can ONLY be added as sub-agent once. If you want to add one agent twice as sub-agent, consider to create two agent\ninstances with identical config, but with different name and add them to the\nagent tree. field sub_agents : list[BaseAgent] [Optional] \u00b6 The sub-agents of this agent. config_type \u00b6 alias of BaseAgentConfig classmethod from_config ( cls , config , config_abs_path ) \u00b6 Creates an agent from a config. If sub-classes uses a custom agent config, override _from_config_kwargs method to return an updated kwargs for agent construstor. Return type : TypeVar ( SelfAgent , bound= BaseAgent) Parameters : config \u2013 The config to create the agent from. config_abs_path \u2013 The absolute path to the config file that contains the\nagent config. Returns : The created agent. validator validate_name \u00bb name \u00b6 clone ( update = None ) \u00b6 Creates a copy of this agent instance. Return type : TypeVar ( SelfAgent , bound= BaseAgent) Parameters : update \u2013 Optional mapping of new values for the fields of the cloned agent.\nThe keys of the mapping are the names of the fields to be updated, and\nthe values are the new values for those fields.\nFor example: {\u201cname\u201d: \u201ccloned_agent\u201d} Returns : A new agent instance with identical configuration as the original\nagent except for the fields specified in the update. find_agent ( name ) \u00b6 Finds the agent with the given name in this agent and its descendants. Return type : Optional [ BaseAgent ] Parameters : name \u2013 The name of the agent to find. Returns : The agent with the matching name, or None if no such agent is found. find_sub_agent ( name ) \u00b6 Finds the agent with the given name in this agent\u2019s descendants. Return type : Optional [ BaseAgent ] Parameters : name \u2013 The name of the agent to find. Returns : The agent with the matching name, or None if no such agent is found. model_post_init ( _BaseAgent__context ) \u00b6 Override this method to perform additional initialization after __init__ and model_construct .\nThis is useful if you want to do some validation that requires the entire model to be initialized. Return type : None async run_async ( parent_context ) \u00b6 Entry method to run an agent via text-based conversation. Return type : AsyncGenerator [ Event , None ] Parameters : parent_context \u2013 InvocationContext, the invocation context of the parent\nagent. Yields : Event \u2013 the events generated by the agent. async run_live ( parent_context ) \u00b6 Entry method to run an agent via video/audio-based conversation. Return type : AsyncGenerator [ Event , None ] Parameters : parent_context \u2013 InvocationContext, the invocation context of the parent\nagent. Yields : Event \u2013 the events generated by the agent. property canonical_after_agent_callbacks : list [ Callable [ [ CallbackContext ] , Awaitable [ Content | None ] | Content | None ] ] \u00b6 The resolved self.after_agent_callback field as a list of _SingleAgentCallback. This method is only for use by Agent Development Kit. property canonical_before_agent_callbacks : list [ Callable [ [ CallbackContext ] , Awaitable [ Content | None ] | Content | None ] ] \u00b6 The resolved self.before_agent_callback field as a list of _SingleAgentCallback. This method is only for use by Agent Development Kit. property root_agent : BaseAgent \u00b6 Gets the root agent of this agent. pydantic model google.adk.agents. InvocationContext \u00b6 Bases: BaseModel An invocation context represents the data of a single invocation of an agent. An invocation: Starts with a user message and ends with a final response. Can contain one or multiple agent calls. Is handled by runner.run_async(). An invocation runs an agent until it does not request to transfer to another\nagent. An agent call: Is handled by agent.run(). Ends when agent.run() ends. An LLM agent call is an agent with a BaseLLMFlow.\nAn LLM agent call can contain one or multiple steps. An LLM agent runs steps in a loop until: A final response is generated. The agent transfers to another agent. The end_invocation is set to true by any callbacks or tools. A step: Calls the LLM only once and yields its response. Calls the tools and yields their responses if requested. The summarization of the function response is considered another step, since\nit is another llm call.\nA step ends when it\u2019s done calling llm and tools, or if the end_invocation\nis set to true at any time. `` ` \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 invocation \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 llm_agent_call_1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500 agent_call_2 \u2500\u2510\n\u250c\u2500\u2500\u2500\u2500 step_1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500 step_2 \u2500\u2500\u2500\u2500\u2500\u2500\u2510\n[call_llm] [call_tool] [call_llm] [transfer] `` ` Show JSON schema { \"title\" : \"InvocationContext\" , \"type\" : \"object\" , \"properties\" : { \"artifact_service\" : { \"default\" : null , \"title\" : \"Artifact Service\" }, \"session_service\" : { \"default\" : null , \"title\" : \"Session Service\" }, \"memory_service\" : { \"default\" : null , \"title\" : \"Memory Service\" }, \"credential_service\" : { \"default\" : null , \"title\" : \"Credential Service\" }, \"context_cache_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ContextCacheConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"invocation_id\" : { \"title\" : \"Invocation Id\" , \"type\" : \"string\" }, \"branch\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Branch\" }, \"agent\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"user_content\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Content\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"session\" : { \"$ref\" : \"#/$defs/Session\" }, \"agent_states\" : { \"additionalProperties\" : { \"additionalProperties\" : true , \"type\" : \"object\" }, \"title\" : \"Agent States\" , \"type\" : \"object\" }, \"end_of_agents\" : { \"additionalProperties\" : { \"type\" : \"boolean\" }, \"title\" : \"End Of Agents\" , \"type\" : \"object\" }, \"end_invocation\" : { \"default\" : false , \"title\" : \"End Invocation\" , \"type\" : \"boolean\" }, \"live_request_queue\" : { \"default\" : null , \"title\" : \"Live Request Queue\" }, \"active_streaming_tools\" : { \"default\" : null , \"title\" : \"Active Streaming Tools\" }, \"transcription_cache\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/TranscriptionEntry\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Transcription Cache\" }, \"live_session_resumption_handle\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Live Session Resumption Handle\" }, \"input_realtime_cache\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/RealtimeCacheEntry\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Input Realtime Cache\" }, \"output_realtime_cache\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/RealtimeCacheEntry\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Output Realtime Cache\" }, \"run_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RunConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"resumability_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ResumabilityConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"plugin_manager\" : { \"default\" : null , \"title\" : \"Plugin Manager\" } }, \"$defs\" : { \"APIKey\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"apiKey\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"in\" : { \"$ref\" : \"#/$defs/APIKeyIn\" }, \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" } }, \"required\" : [ \"in\" , \"name\" ], \"title\" : \"APIKey\" , \"type\" : \"object\" }, \"APIKeyIn\" : { \"enum\" : [ \"query\" , \"header\" , \"cookie\" ], \"title\" : \"APIKeyIn\" , \"type\" : \"string\" }, \"ActivityHandling\" : { \"description\" : \"The different ways of handling user activity.\" , \"enum\" : [ \"ACTIVITY_HANDLING_UNSPECIFIED\" , \"START_OF_ACTIVITY_INTERRUPTS\" , \"NO_INTERRUPTION\" ], \"title\" : \"ActivityHandling\" , \"type\" : \"string\" }, \"AudioTranscriptionConfig\" : { \"additionalProperties\" : false , \"description\" : \"The audio transcription configuration in Setup.\" , \"properties\" : {}, \"title\" : \"AudioTranscriptionConfig\" , \"type\" : \"object\" }, \"AuthConfig\" : { \"additionalProperties\" : true , \"description\" : \"The auth config sent by tool asking client to collect auth credentials and\\n\\nadk and client will help to fill in the response\" , \"properties\" : { \"authScheme\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/APIKey\" }, { \"$ref\" : \"#/$defs/HTTPBase\" }, { \"$ref\" : \"#/$defs/OAuth2\" }, { \"$ref\" : \"#/$defs/OpenIdConnect\" }, { \"$ref\" : \"#/$defs/HTTPBearer\" }, { \"$ref\" : \"#/$defs/OpenIdConnectWithConfig\" } ], \"title\" : \"Authscheme\" }, \"rawAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"exchangedAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"credentialKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Credentialkey\" } }, \"required\" : [ \"authScheme\" ], \"title\" : \"AuthConfig\" , \"type\" : \"object\" }, \"AuthCredential\" : { \"additionalProperties\" : true , \"description\" : \"Data class representing an authentication credential.\\n\\nTo exchange for the actual credential, please use\\nCredentialExchanger.exchange_credential().\\n\\nExamples: API Key Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    api_key=\\\"1234\\\",\\n)\\n\\nExample: HTTP Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"basic\\\",\\n        credentials=HttpCredentials(username=\\\"user\\\", password=\\\"password\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Bearer Token in HTTP Header\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"bearer\\\",\\n        credentials=HttpCredentials(token=\\\"eyAkaknabna....\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Auth with Authorization Code Flow\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OAUTH2,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n    ),\\n)\\n\\nExample: OpenID Connect Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OPEN_ID_CONNECT,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n        redirect_uri=\\\"https://example.com\\\",\\n        scopes=[\\\"scope1\\\", \\\"scope2\\\"],\\n    ),\\n)\\n\\nExample: Auth with resource reference\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    resource_ref=\\\"projects/1234/locations/us-central1/resources/resource1\\\",\\n)\" , \"properties\" : { \"authType\" : { \"$ref\" : \"#/$defs/AuthCredentialTypes\" }, \"resourceRef\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Resourceref\" }, \"apiKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Apikey\" }, \"http\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HttpAuth\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"serviceAccount\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccount\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"oauth2\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuth2Auth\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"required\" : [ \"authType\" ], \"title\" : \"AuthCredential\" , \"type\" : \"object\" }, \"AuthCredentialTypes\" : { \"description\" : \"Represents the type of authentication credential.\" , \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" , \"serviceAccount\" ], \"title\" : \"AuthCredentialTypes\" , \"type\" : \"string\" }, \"AutomaticActivityDetection\" : { \"additionalProperties\" : false , \"description\" : \"Configures automatic detection of activity.\" , \"properties\" : { \"disabled\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals.\" , \"title\" : \"Disabled\" }, \"startOfSpeechSensitivity\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/StartSensitivity\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Determines how likely speech is to be detected.\" }, \"endOfSpeechSensitivity\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/EndSensitivity\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Determines how likely detected speech is ended.\" }, \"prefixPaddingMs\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives.\" , \"title\" : \"Prefixpaddingms\" }, \"silenceDurationMs\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user's activity but this will increase the model's latency.\" , \"title\" : \"Silencedurationms\" } }, \"title\" : \"AutomaticActivityDetection\" , \"type\" : \"object\" }, \"BaseAgent\" : { \"additionalProperties\" : false , \"description\" : \"Base class for all agents in Agent Development Kit.\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" } }, \"required\" : [ \"name\" ], \"title\" : \"BaseAgent\" , \"type\" : \"object\" }, \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CacheMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Metadata for context cache associated with LLM responses.\\n\\nThis class stores cache identification, usage tracking, and lifecycle\\ninformation for a particular cache instance. It can be in two states:\\n\\n1. Active cache state: cache_name is set, all fields populated\\n2. Fingerprint-only state: cache_name is None, only fingerprint and\\n   contents_count are set for prefix matching\\n\\nToken counts (cached and total) are available in the LlmResponse.usage_metadata\\nand should be accessed from there to avoid duplication.\\n\\nAttributes:\\n    cache_name: The full resource name of the cached content (e.g.,\\n        'projects/123/locations/us-central1/cachedContents/456').\\n        None when no active cache exists (fingerprint-only state).\\n    expire_time: Unix timestamp when the cache expires. None when no\\n        active cache exists.\\n    fingerprint: Hash of cacheable contents (instruction + tools + contents).\\n        Always present for prefix matching.\\n    invocations_used: Number of invocations this cache has been used for.\\n        None when no active cache exists.\\n    contents_count: Number of contents. When active cache exists, this is\\n        the count of cached contents. When no active cache exists, this is\\n        the total count of contents in the request.\\n    created_at: Unix timestamp when the cache was created. None when\\n        no active cache exists.\" , \"properties\" : { \"cache_name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Full resource name of the cached content (None if no active cache)\" , \"title\" : \"Cache Name\" }, \"expire_time\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Unix timestamp when cache expires (None if no active cache)\" , \"title\" : \"Expire Time\" }, \"fingerprint\" : { \"description\" : \"Hash of cacheable contents used to detect changes\" , \"title\" : \"Fingerprint\" , \"type\" : \"string\" }, \"invocations_used\" : { \"anyOf\" : [ { \"minimum\" : 0 , \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of invocations this cache has been used for (None if no active cache)\" , \"title\" : \"Invocations Used\" }, \"contents_count\" : { \"description\" : \"Number of contents (cached contents when active cache exists, total contents in request when no active cache)\" , \"minimum\" : 0 , \"title\" : \"Contents Count\" , \"type\" : \"integer\" }, \"created_at\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Unix timestamp when cache was created (None if no active cache)\" , \"title\" : \"Created At\" } }, \"required\" : [ \"fingerprint\" , \"contents_count\" ], \"title\" : \"CacheMetadata\" , \"type\" : \"object\" }, \"Citation\" : { \"additionalProperties\" : false , \"description\" : \"Source attributions for content.\" , \"properties\" : { \"endIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. End index into the content.\" , \"title\" : \"Endindex\" }, \"license\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. License of the attribution.\" , \"title\" : \"License\" }, \"publicationDate\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GoogleTypeDate\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Publication date of the attribution.\" }, \"startIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Start index into the content.\" , \"title\" : \"Startindex\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Title of the attribution.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Url reference of the attribution.\" , \"title\" : \"Uri\" } }, \"title\" : \"Citation\" , \"type\" : \"object\" }, \"CitationMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Citation information when the model quotes another source.\" , \"properties\" : { \"citations\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Citation\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Contains citation information when the model directly quotes, at\\n      length, from another source. Can include traditional websites and code\\n      repositories.\\n      \" , \"title\" : \"Citations\" } }, \"title\" : \"CitationMetadata\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"Content\" : { \"additionalProperties\" : false , \"description\" : \"Contains the multi-part content of a message.\" , \"properties\" : { \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Part\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a single message. Each part may have\\n      a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The producer of the content. Must be either 'user' or\\n      'model'. Useful to set for multi-turn conversations, otherwise can be\\n      empty. If role is not specified, SDK will determine the role.\" , \"title\" : \"Role\" } }, \"title\" : \"Content\" , \"type\" : \"object\" }, \"ContextCacheConfig\" : { \"additionalProperties\" : false , \"description\" : \"Configuration for context caching across all agents in an app.\\n\\nThis configuration enables and controls context caching behavior for\\nall LLM agents in an app. When this config is present on an app, context\\ncaching is enabled for all agents. When absent (None), context caching\\nis disabled.\\n\\nContext caching can significantly reduce costs and improve response times\\nby reusing previously processed context across multiple requests.\\n\\nAttributes:\\n    cache_intervals: Maximum number of invocations to reuse the same cache before refreshing it\\n    ttl_seconds: Time-to-live for cache in seconds\\n    min_tokens: Minimum tokens required to enable caching\" , \"properties\" : { \"cache_intervals\" : { \"default\" : 10 , \"description\" : \"Maximum number of invocations to reuse the same cache before refreshing it\" , \"maximum\" : 100 , \"minimum\" : 1 , \"title\" : \"Cache Intervals\" , \"type\" : \"integer\" }, \"ttl_seconds\" : { \"default\" : 1800 , \"description\" : \"Time-to-live for cache in seconds\" , \"exclusiveMinimum\" : 0 , \"title\" : \"Ttl Seconds\" , \"type\" : \"integer\" }, \"min_tokens\" : { \"default\" : 0 , \"description\" : \"Minimum estimated request tokens required to enable caching. This compares against the estimated total tokens of the request (system instruction + tools + contents). Context cache storage may have cost. Set higher to avoid caching small requests where overhead may exceed benefits.\" , \"minimum\" : 0 , \"title\" : \"Min Tokens\" , \"type\" : \"integer\" } }, \"title\" : \"ContextCacheConfig\" , \"type\" : \"object\" }, \"ContextWindowCompressionConfig\" : { \"additionalProperties\" : false , \"description\" : \"Enables context window compression -- mechanism managing model context window so it does not exceed given length.\" , \"properties\" : { \"triggerTokens\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens (before running turn) that triggers context window compression mechanism.\" , \"title\" : \"Triggertokens\" }, \"slidingWindow\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/SlidingWindow\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Sliding window compression mechanism.\" } }, \"title\" : \"ContextWindowCompressionConfig\" , \"type\" : \"object\" }, \"EndSensitivity\" : { \"description\" : \"End of speech sensitivity.\" , \"enum\" : [ \"END_SENSITIVITY_UNSPECIFIED\" , \"END_SENSITIVITY_HIGH\" , \"END_SENSITIVITY_LOW\" ], \"title\" : \"EndSensitivity\" , \"type\" : \"string\" }, \"Event\" : { \"additionalProperties\" : false , \"description\" : \"Represents an event in a conversation between agents and users.\\n\\nIt is used to store the content of the conversation, as well as the actions\\ntaken by the agents like function calls, etc.\" , \"properties\" : { \"content\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Content\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"groundingMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"partial\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Partial\" }, \"turnComplete\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Turncomplete\" }, \"finishReason\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FinishReason\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"errorCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Errorcode\" }, \"errorMessage\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Errormessage\" }, \"interrupted\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Interrupted\" }, \"customMetadata\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Custommetadata\" }, \"usageMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GenerateContentResponseUsageMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"liveSessionResumptionUpdate\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/LiveServerSessionResumptionUpdate\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"inputTranscription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Transcription\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"outputTranscription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Transcription\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"avgLogprobs\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Avglogprobs\" }, \"logprobsResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/LogprobsResult\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"cacheMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CacheMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"citationMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CitationMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"invocationId\" : { \"default\" : \"\" , \"title\" : \"Invocationid\" , \"type\" : \"string\" }, \"author\" : { \"title\" : \"Author\" , \"type\" : \"string\" }, \"actions\" : { \"$ref\" : \"#/$defs/EventActions\" }, \"longRunningToolIds\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" , \"uniqueItems\" : true }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Longrunningtoolids\" }, \"branch\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Branch\" }, \"id\" : { \"default\" : \"\" , \"title\" : \"Id\" , \"type\" : \"string\" }, \"timestamp\" : { \"title\" : \"Timestamp\" , \"type\" : \"number\" } }, \"required\" : [ \"author\" ], \"title\" : \"Event\" , \"type\" : \"object\" }, \"EventActions\" : { \"additionalProperties\" : false , \"description\" : \"Represents the actions attached to an event.\" , \"properties\" : { \"skipSummarization\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Skipsummarization\" }, \"stateDelta\" : { \"additionalProperties\" : true , \"title\" : \"Statedelta\" , \"type\" : \"object\" }, \"artifactDelta\" : { \"additionalProperties\" : { \"type\" : \"integer\" }, \"title\" : \"Artifactdelta\" , \"type\" : \"object\" }, \"transferToAgent\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Transfertoagent\" }, \"escalate\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Escalate\" }, \"requestedAuthConfigs\" : { \"additionalProperties\" : { \"$ref\" : \"#/$defs/AuthConfig\" }, \"title\" : \"Requestedauthconfigs\" , \"type\" : \"object\" }, \"requestedToolConfirmations\" : { \"additionalProperties\" : { \"$ref\" : \"#/$defs/ToolConfirmation\" }, \"title\" : \"Requestedtoolconfirmations\" , \"type\" : \"object\" }, \"compaction\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/EventCompaction\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"endOfAgent\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Endofagent\" }, \"agentState\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Agentstate\" }, \"rewindBeforeInvocationId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Rewindbeforeinvocationid\" } }, \"title\" : \"EventActions\" , \"type\" : \"object\" }, \"EventCompaction\" : { \"additionalProperties\" : false , \"description\" : \"The compaction of the events.\" , \"properties\" : { \"startTimestamp\" : { \"title\" : \"Starttimestamp\" , \"type\" : \"number\" }, \"endTimestamp\" : { \"title\" : \"Endtimestamp\" , \"type\" : \"number\" }, \"compactedContent\" : { \"$ref\" : \"#/$defs/Content\" } }, \"required\" : [ \"startTimestamp\" , \"endTimestamp\" , \"compactedContent\" ], \"title\" : \"EventCompaction\" , \"type\" : \"object\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FinishReason\" : { \"description\" : \"Output only. The reason why the model stopped generating tokens.\\n\\nIf empty, the model has not stopped generating the tokens.\" , \"enum\" : [ \"FINISH_REASON_UNSPECIFIED\" , \"STOP\" , \"MAX_TOKENS\" , \"SAFETY\" , \"RECITATION\" , \"LANGUAGE\" , \"OTHER\" , \"BLOCKLIST\" , \"PROHIBITED_CONTENT\" , \"SPII\" , \"MALFORMED_FUNCTION_CALL\" , \"IMAGE_SAFETY\" , \"UNEXPECTED_TOOL_CALL\" , \"IMAGE_PROHIBITED_CONTENT\" , \"NO_IMAGE\" ], \"title\" : \"FinishReason\" , \"type\" : \"string\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"GenerateContentResponseUsageMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Usage metadata about response(s).\" , \"properties\" : { \"cacheTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities of the cached content in the request input.\" , \"title\" : \"Cachetokensdetails\" }, \"cachedContentTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Number of tokens in the cached part in the input (the cached content).\" , \"title\" : \"Cachedcontenttokencount\" }, \"candidatesTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens in the response(s).\" , \"title\" : \"Candidatestokencount\" }, \"candidatesTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities that were returned in the response.\" , \"title\" : \"Candidatestokensdetails\" }, \"promptTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens in the request. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content.\" , \"title\" : \"Prompttokencount\" }, \"promptTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities that were processed in the request input.\" , \"title\" : \"Prompttokensdetails\" }, \"thoughtsTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Number of tokens present in thoughts output.\" , \"title\" : \"Thoughtstokencount\" }, \"toolUsePromptTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Number of tokens present in tool-use prompt(s).\" , \"title\" : \"Tooluseprompttokencount\" }, \"toolUsePromptTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities that were processed for tool-use request inputs.\" , \"title\" : \"Tooluseprompttokensdetails\" }, \"totalTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Total token count for prompt, response candidates, and tool-use prompts (if present).\" , \"title\" : \"Totaltokencount\" }, \"trafficType\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/TrafficType\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota.\" } }, \"title\" : \"GenerateContentResponseUsageMetadata\" , \"type\" : \"object\" }, \"GoogleTypeDate\" : { \"additionalProperties\" : false , \"description\" : \"Represents a whole or partial calendar date, such as a birthday.\\n\\nThe time of day and time zone are either specified elsewhere or are\\ninsignificant. The date is relative to the Gregorian Calendar. This can\\nrepresent one of the following: * A full date, with non-zero year, month, and\\nday values. * A month and day, with a zero year (for example, an anniversary).\\n* A year on its own, with a zero month and a zero day. * A year and month,\\nwith a zero day (for example, a credit card expiration date). Related types: *\\ngoogle.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp\" , \"properties\" : { \"day\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.\" , \"title\" : \"Day\" }, \"month\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.\" , \"title\" : \"Month\" }, \"year\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year.\" , \"title\" : \"Year\" } }, \"title\" : \"GoogleTypeDate\" , \"type\" : \"object\" }, \"GroundingChunk\" : { \"additionalProperties\" : false , \"description\" : \"Grounding chunk.\" , \"properties\" : { \"maps\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkMaps\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Grounding chunk from Google Maps.\" }, \"retrievedContext\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkRetrievedContext\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Grounding chunk from context retrieved by the retrieval tools.\" }, \"web\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkWeb\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Grounding chunk from the web.\" } }, \"title\" : \"GroundingChunk\" , \"type\" : \"object\" }, \"GroundingChunkMaps\" : { \"additionalProperties\" : false , \"description\" : \"Chunk from Google Maps.\" , \"properties\" : { \"placeAnswerSources\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkMapsPlaceAnswerSources\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Sources used to generate the place answer. This includes review snippets and photos that were used to generate the answer, as well as uris to flag content.\" }, \"placeId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"This Place's resource name, in `places/{place_id}` format. Can be used to look up the Place.\" , \"title\" : \"Placeid\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Text of the chunk.\" , \"title\" : \"Text\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Title of the chunk.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI reference of the chunk.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkMaps\" , \"type\" : \"object\" }, \"GroundingChunkMapsPlaceAnswerSources\" : { \"additionalProperties\" : false , \"description\" : \"Sources used to generate the place answer.\" , \"properties\" : { \"flagContentUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A link where users can flag a problem with the generated answer.\" , \"title\" : \"Flagcontenturi\" }, \"reviewSnippets\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/GroundingChunkMapsPlaceAnswerSourcesReviewSnippet\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Snippets of reviews that are used to generate the answer.\" , \"title\" : \"Reviewsnippets\" } }, \"title\" : \"GroundingChunkMapsPlaceAnswerSources\" , \"type\" : \"object\" }, \"GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution\" : { \"additionalProperties\" : false , \"description\" : \"Author attribution for a photo or review.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Name of the author of the Photo or Review.\" , \"title\" : \"Displayname\" }, \"photoUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Profile photo URI of the author of the Photo or Review.\" , \"title\" : \"Photouri\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI of the author of the Photo or Review.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution\" , \"type\" : \"object\" }, \"GroundingChunkMapsPlaceAnswerSourcesReviewSnippet\" : { \"additionalProperties\" : false , \"description\" : \"Encapsulates a review snippet.\" , \"properties\" : { \"authorAttribution\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"This review's author.\" }, \"flagContentUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A link where users can flag a problem with the review.\" , \"title\" : \"Flagcontenturi\" }, \"googleMapsUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A link to show the review on Google Maps.\" , \"title\" : \"Googlemapsuri\" }, \"relativePublishTimeDescription\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A string of formatted recent time, expressing the review time relative to the current time in a form appropriate for the language and country.\" , \"title\" : \"Relativepublishtimedescription\" }, \"review\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A reference representing this place review which may be used to look up this place review again.\" , \"title\" : \"Review\" } }, \"title\" : \"GroundingChunkMapsPlaceAnswerSourcesReviewSnippet\" , \"type\" : \"object\" }, \"GroundingChunkRetrievedContext\" : { \"additionalProperties\" : false , \"description\" : \"Chunk from context retrieved by the retrieval tools.\" , \"properties\" : { \"documentName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The full document name for the referenced Vertex AI Search document.\" , \"title\" : \"Documentname\" }, \"ragChunk\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagChunk\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Additional context for the RAG retrieval result. This is only populated when using the RAG retrieval tool.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Text of the attribution.\" , \"title\" : \"Text\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Title of the attribution.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI reference of the attribution.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkRetrievedContext\" , \"type\" : \"object\" }, \"GroundingChunkWeb\" : { \"additionalProperties\" : false , \"description\" : \"Chunk from the web.\" , \"properties\" : { \"domain\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Domain of the (original) URI.\" , \"title\" : \"Domain\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Title of the chunk.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI reference of the chunk.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkWeb\" , \"type\" : \"object\" }, \"GroundingMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Metadata returned to client when grounding is enabled.\" , \"properties\" : { \"googleMapsWidgetContextToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Output only. Resource name of the Google Maps widget context token to be used with the PlacesContextElement widget to render contextual data. This is populated only for Google Maps grounding.\" , \"title\" : \"Googlemapswidgetcontexttoken\" }, \"groundingChunks\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/GroundingChunk\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of supporting references retrieved from specified grounding source.\" , \"title\" : \"Groundingchunks\" }, \"groundingSupports\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/GroundingSupport\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. List of grounding support.\" , \"title\" : \"Groundingsupports\" }, \"retrievalMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RetrievalMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Output only. Retrieval metadata.\" }, \"retrievalQueries\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Queries executed by the retrieval tools.\" , \"title\" : \"Retrievalqueries\" }, \"searchEntryPoint\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/SearchEntryPoint\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Google search entry for the following-up web searches.\" }, \"webSearchQueries\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Web search queries for the following-up web search.\" , \"title\" : \"Websearchqueries\" } }, \"title\" : \"GroundingMetadata\" , \"type\" : \"object\" }, \"GroundingSupport\" : { \"additionalProperties\" : false , \"description\" : \"Grounding support.\" , \"properties\" : { \"confidenceScores\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"number\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. For Gemini 2.0 and before, this list must have the same size as the grounding_chunk_indices. For Gemini 2.5 and after, this list will be empty and should be ignored.\" , \"title\" : \"Confidencescores\" }, \"groundingChunkIndices\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"integer\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.\" , \"title\" : \"Groundingchunkindices\" }, \"segment\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Segment\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Segment of the content this support belongs to.\" } }, \"title\" : \"GroundingSupport\" , \"type\" : \"object\" }, \"HTTPBase\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" } }, \"required\" : [ \"scheme\" ], \"title\" : \"HTTPBase\" , \"type\" : \"object\" }, \"HTTPBearer\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"const\" : \"bearer\" , \"default\" : \"bearer\" , \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"bearerFormat\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Bearerformat\" } }, \"title\" : \"HTTPBearer\" , \"type\" : \"object\" }, \"HttpAuth\" : { \"additionalProperties\" : true , \"description\" : \"The credentials and metadata for HTTP authentication.\" , \"properties\" : { \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"credentials\" : { \"$ref\" : \"#/$defs/HttpCredentials\" } }, \"required\" : [ \"scheme\" , \"credentials\" ], \"title\" : \"HttpAuth\" , \"type\" : \"object\" }, \"HttpCredentials\" : { \"additionalProperties\" : true , \"description\" : \"Represents the secret token value for HTTP authentication, like user name, password, oauth token, etc.\" , \"properties\" : { \"username\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Username\" }, \"password\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Password\" }, \"token\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token\" } }, \"title\" : \"HttpCredentials\" , \"type\" : \"object\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"LiveServerSessionResumptionUpdate\" : { \"additionalProperties\" : false , \"description\" : \"Update of the session resumption state.\\n\\nOnly sent if `session_resumption` was set in the connection config.\" , \"properties\" : { \"newHandle\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"New handle that represents state that can be resumed. Empty if `resumable`=false.\" , \"title\" : \"Newhandle\" }, \"resumable\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss.\" , \"title\" : \"Resumable\" }, \"lastConsumedClientMessageIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when `SessionResumptionConfig.transparent` is set.\\n\\nPresence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last `SessionResmumptionTokenUpdate`. This field will enable them to limit buffering (avoid keeping all requests in RAM).\\n\\nNote: This should not be used for when resuming a session at some time later -- in those cases partial audio and video frames arelikely not needed.\" , \"title\" : \"Lastconsumedclientmessageindex\" } }, \"title\" : \"LiveServerSessionResumptionUpdate\" , \"type\" : \"object\" }, \"LogprobsResult\" : { \"additionalProperties\" : false , \"description\" : \"Logprobs Result\" , \"properties\" : { \"chosenCandidates\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/LogprobsResultCandidate\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates.\" , \"title\" : \"Chosencandidates\" }, \"topCandidates\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/LogprobsResultTopCandidates\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Length = total number of decoding steps.\" , \"title\" : \"Topcandidates\" } }, \"title\" : \"LogprobsResult\" , \"type\" : \"object\" }, \"LogprobsResultCandidate\" : { \"additionalProperties\" : false , \"description\" : \"Candidate for the logprobs token and score.\" , \"properties\" : { \"logProbability\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The candidate's log probability.\" , \"title\" : \"Logprobability\" }, \"token\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The candidate's token string value.\" , \"title\" : \"Token\" }, \"tokenId\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The candidate's token id value.\" , \"title\" : \"Tokenid\" } }, \"title\" : \"LogprobsResultCandidate\" , \"type\" : \"object\" }, \"LogprobsResultTopCandidates\" : { \"additionalProperties\" : false , \"description\" : \"Candidates with top log probabilities at each decoding step.\" , \"properties\" : { \"candidates\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/LogprobsResultCandidate\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Sorted by log probability in descending order.\" , \"title\" : \"Candidates\" } }, \"title\" : \"LogprobsResultTopCandidates\" , \"type\" : \"object\" }, \"MediaModality\" : { \"description\" : \"Server content modalities.\" , \"enum\" : [ \"MODALITY_UNSPECIFIED\" , \"TEXT\" , \"IMAGE\" , \"VIDEO\" , \"AUDIO\" , \"DOCUMENT\" ], \"title\" : \"MediaModality\" , \"type\" : \"string\" }, \"ModalityTokenCount\" : { \"additionalProperties\" : false , \"description\" : \"Represents token counting info for a single modality.\" , \"properties\" : { \"modality\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/MediaModality\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The modality associated with this token count.\" }, \"tokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens.\" , \"title\" : \"Tokencount\" } }, \"title\" : \"ModalityTokenCount\" , \"type\" : \"object\" }, \"MultiSpeakerVoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the multi-speaker setup.\" , \"properties\" : { \"speakerVoiceConfigs\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/SpeakerVoiceConfig\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the speaker to use.\" , \"title\" : \"Speakervoiceconfigs\" } }, \"title\" : \"MultiSpeakerVoiceConfig\" , \"type\" : \"object\" }, \"OAuth2\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"oauth2\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"flows\" : { \"$ref\" : \"#/$defs/OAuthFlows\" } }, \"required\" : [ \"flows\" ], \"title\" : \"OAuth2\" , \"type\" : \"object\" }, \"OAuth2Auth\" : { \"additionalProperties\" : true , \"description\" : \"Represents credential value and its metadata for a OAuth2 credential.\" , \"properties\" : { \"clientId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientid\" }, \"clientSecret\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientsecret\" }, \"authUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authuri\" }, \"state\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"State\" }, \"redirectUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Redirecturi\" }, \"authResponseUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authresponseuri\" }, \"authCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authcode\" }, \"accessToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Accesstoken\" }, \"refreshToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshtoken\" }, \"expiresAt\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresat\" }, \"expiresIn\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresin\" }, \"audience\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Audience\" } }, \"title\" : \"OAuth2Auth\" , \"type\" : \"object\" }, \"OAuthFlowAuthorizationCode\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" , \"tokenUrl\" ], \"title\" : \"OAuthFlowAuthorizationCode\" , \"type\" : \"object\" }, \"OAuthFlowClientCredentials\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowClientCredentials\" , \"type\" : \"object\" }, \"OAuthFlowImplicit\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" ], \"title\" : \"OAuthFlowImplicit\" , \"type\" : \"object\" }, \"OAuthFlowPassword\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowPassword\" , \"type\" : \"object\" }, \"OAuthFlows\" : { \"additionalProperties\" : true , \"properties\" : { \"implicit\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowImplicit\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"password\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowPassword\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"clientCredentials\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowClientCredentials\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"authorizationCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowAuthorizationCode\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"title\" : \"OAuthFlows\" , \"type\" : \"object\" }, \"OpenIdConnect\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"openIdConnectUrl\" : { \"title\" : \"Openidconnecturl\" , \"type\" : \"string\" } }, \"required\" : [ \"openIdConnectUrl\" ], \"title\" : \"OpenIdConnect\" , \"type\" : \"object\" }, \"OpenIdConnectWithConfig\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"authorization_endpoint\" : { \"title\" : \"Authorization Endpoint\" , \"type\" : \"string\" }, \"token_endpoint\" : { \"title\" : \"Token Endpoint\" , \"type\" : \"string\" }, \"userinfo_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Userinfo Endpoint\" }, \"revocation_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Revocation Endpoint\" }, \"token_endpoint_auth_methods_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token Endpoint Auth Methods Supported\" }, \"grant_types_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Grant Types Supported\" }, \"scopes\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Scopes\" } }, \"required\" : [ \"authorization_endpoint\" , \"token_endpoint\" ], \"title\" : \"OpenIdConnectWithConfig\" , \"type\" : \"object\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"PrebuiltVoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the prebuilt speaker to use.\" , \"properties\" : { \"voiceName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The name of the prebuilt voice to use.\" , \"title\" : \"Voicename\" } }, \"title\" : \"PrebuiltVoiceConfig\" , \"type\" : \"object\" }, \"ProactivityConfig\" : { \"additionalProperties\" : false , \"description\" : \"Config for proactivity features.\" , \"properties\" : { \"proactiveAudio\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If enabled, the model can reject responding to the last prompt. For\\n        example, this allows the model to ignore out of context speech or to stay\\n        silent if the user did not make a request, yet.\" , \"title\" : \"Proactiveaudio\" } }, \"title\" : \"ProactivityConfig\" , \"type\" : \"object\" }, \"RagChunk\" : { \"additionalProperties\" : false , \"description\" : \"A RagChunk includes the content of a chunk of a RagFile, and associated metadata.\" , \"properties\" : { \"pageSpan\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagChunkPageSpan\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If populated, represents where the chunk starts and ends in the document.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The content of the chunk.\" , \"title\" : \"Text\" } }, \"title\" : \"RagChunk\" , \"type\" : \"object\" }, \"RagChunkPageSpan\" : { \"additionalProperties\" : false , \"description\" : \"Represents where the chunk starts and ends in the document.\" , \"properties\" : { \"firstPage\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Page where chunk starts in the document. Inclusive. 1-indexed.\" , \"title\" : \"Firstpage\" }, \"lastPage\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Page where chunk ends in the document. Inclusive. 1-indexed.\" , \"title\" : \"Lastpage\" } }, \"title\" : \"RagChunkPageSpan\" , \"type\" : \"object\" }, \"RealtimeCacheEntry\" : { \"additionalProperties\" : false , \"description\" : \"Store audio data chunks for caching before flushing.\" , \"properties\" : { \"role\" : { \"title\" : \"Role\" , \"type\" : \"string\" }, \"data\" : { \"$ref\" : \"#/$defs/Blob\" }, \"timestamp\" : { \"title\" : \"Timestamp\" , \"type\" : \"number\" } }, \"required\" : [ \"role\" , \"data\" , \"timestamp\" ], \"title\" : \"RealtimeCacheEntry\" , \"type\" : \"object\" }, \"RealtimeInputConfig\" : { \"additionalProperties\" : false , \"description\" : \"Marks the end of user activity.\\n\\nThis can only be sent if automatic (i.e. server-side) activity detection is\\ndisabled.\" , \"properties\" : { \"automaticActivityDetection\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AutomaticActivityDetection\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals.\" }, \"activityHandling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ActivityHandling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Defines what effect activity has.\" }, \"turnCoverage\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/TurnCoverage\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Defines which input is included in the user's turn.\" } }, \"title\" : \"RealtimeInputConfig\" , \"type\" : \"object\" }, \"ResumabilityConfig\" : { \"description\" : \"The config of the resumability for an application.\\n\\nThe \\\"resumability\\\" in ADK refers to the ability to:\\n1. pause an invocation upon a long running function call.\\n2. resume an invocation from the last event, if it's paused or failed midway\\nthrough.\\n\\nNote: ADK resumes the invocation in a best-effort manner:\\n1. Tool call to resume needs to be idempotent because we only guarantee\\nan at-least-once behavior once resumed.\\n2. Any temporary / in-memory state will be lost upon resumption.\" , \"properties\" : { \"is_resumable\" : { \"default\" : false , \"title\" : \"Is Resumable\" , \"type\" : \"boolean\" } }, \"title\" : \"ResumabilityConfig\" , \"type\" : \"object\" }, \"RetrievalMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Metadata related to retrieval in the grounding flow.\" , \"properties\" : { \"googleSearchDynamicRetrievalScore\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.\" , \"title\" : \"Googlesearchdynamicretrievalscore\" } }, \"title\" : \"RetrievalMetadata\" , \"type\" : \"object\" }, \"RunConfig\" : { \"additionalProperties\" : false , \"description\" : \"Configs for runtime behavior of agents.\" , \"properties\" : { \"speech_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/SpeechConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"response_modalities\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Response Modalities\" }, \"save_input_blobs_as_artifacts\" : { \"default\" : false , \"deprecated\" : true , \"description\" : \"Whether or not to save the input blobs as artifacts. DEPRECATED: Use SaveFilesAsArtifactsPlugin instead for better control and flexibility. See google.adk.plugins.SaveFilesAsArtifactsPlugin.\" , \"title\" : \"Save Input Blobs As Artifacts\" , \"type\" : \"boolean\" }, \"support_cfc\" : { \"default\" : false , \"title\" : \"Support Cfc\" , \"type\" : \"boolean\" }, \"streaming_mode\" : { \"$ref\" : \"#/$defs/StreamingMode\" , \"default\" : null }, \"output_audio_transcription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AudioTranscriptionConfig\" }, { \"type\" : \"null\" } ] }, \"input_audio_transcription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AudioTranscriptionConfig\" }, { \"type\" : \"null\" } ] }, \"realtime_input_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RealtimeInputConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"enable_affective_dialog\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Enable Affective Dialog\" }, \"proactivity\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ProactivityConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"session_resumption\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/SessionResumptionConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"context_window_compression\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ContextWindowCompressionConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"save_live_audio\" : { \"default\" : false , \"title\" : \"Save Live Audio\" , \"type\" : \"boolean\" }, \"max_llm_calls\" : { \"default\" : 500 , \"title\" : \"Max Llm Calls\" , \"type\" : \"integer\" } }, \"title\" : \"RunConfig\" , \"type\" : \"object\" }, \"SearchEntryPoint\" : { \"additionalProperties\" : false , \"description\" : \"Google search entry point.\" , \"properties\" : { \"renderedContent\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Web content snippet that can be embedded in a web page or an app webview.\" , \"title\" : \"Renderedcontent\" }, \"sdkBlob\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Base64 encoded JSON representing array of tuple.\" , \"title\" : \"Sdkblob\" } }, \"title\" : \"SearchEntryPoint\" , \"type\" : \"object\" }, \"SecuritySchemeType\" : { \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" ], \"title\" : \"SecuritySchemeType\" , \"type\" : \"string\" }, \"Segment\" : { \"additionalProperties\" : false , \"description\" : \"Segment of the content.\" , \"properties\" : { \"endIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.\" , \"title\" : \"Endindex\" }, \"partIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The index of a Part object within its parent Content object.\" , \"title\" : \"Partindex\" }, \"startIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.\" , \"title\" : \"Startindex\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The text corresponding to the segment from the response.\" , \"title\" : \"Text\" } }, \"title\" : \"Segment\" , \"type\" : \"object\" }, \"ServiceAccount\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\" , \"properties\" : { \"serviceAccountCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccountCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"scopes\" : { \"items\" : { \"type\" : \"string\" }, \"title\" : \"Scopes\" , \"type\" : \"array\" }, \"useDefaultCredential\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : false , \"title\" : \"Usedefaultcredential\" } }, \"required\" : [ \"scopes\" ], \"title\" : \"ServiceAccount\" , \"type\" : \"object\" }, \"ServiceAccountCredential\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\\n\\nAttributes:\\n  type: The type should be \\\"service_account\\\".\\n  project_id: The project ID.\\n  private_key_id: The ID of the private key.\\n  private_key: The private key.\\n  client_email: The client email.\\n  client_id: The client ID.\\n  auth_uri: The authorization URI.\\n  token_uri: The token URI.\\n  auth_provider_x509_cert_url: URL for auth provider's X.509 cert.\\n  client_x509_cert_url: URL for the client's X.509 cert.\\n  universe_domain: The universe domain.\\n\\nExample:\\n\\n    config = ServiceAccountCredential(\\n        type_=\\\"service_account\\\",\\n        project_id=\\\"your_project_id\\\",\\n        private_key_id=\\\"your_private_key_id\\\",\\n        private_key=\\\"-----BEGIN PRIVATE KEY-----...\\\",\\n        client_email=\\\"...@....iam.gserviceaccount.com\\\",\\n        client_id=\\\"your_client_id\\\",\\n        auth_uri=\\\"https://accounts.google.com/o/oauth2/auth\\\",\\n        token_uri=\\\"https://oauth2.googleapis.com/token\\\",\\n        auth_provider_x509_cert_url=\\\"https://www.googleapis.com/oauth2/v1/certs\\\",\\n        client_x509_cert_url=\\\"https://www.googleapis.com/robot/v1/metadata/x509/...\\\",\\n        universe_domain=\\\"googleapis.com\\\"\\n    )\\n\\n\\n    config = ServiceAccountConfig.model_construct(**{\\n        ...service account config dict\\n    })\" , \"properties\" : { \"type\" : { \"default\" : \"\" , \"title\" : \"Type\" , \"type\" : \"string\" }, \"projectId\" : { \"title\" : \"Projectid\" , \"type\" : \"string\" }, \"privateKeyId\" : { \"title\" : \"Privatekeyid\" , \"type\" : \"string\" }, \"privateKey\" : { \"title\" : \"Privatekey\" , \"type\" : \"string\" }, \"clientEmail\" : { \"title\" : \"Clientemail\" , \"type\" : \"string\" }, \"clientId\" : { \"title\" : \"Clientid\" , \"type\" : \"string\" }, \"authUri\" : { \"title\" : \"Authuri\" , \"type\" : \"string\" }, \"tokenUri\" : { \"title\" : \"Tokenuri\" , \"type\" : \"string\" }, \"authProviderX509CertUrl\" : { \"title\" : \"Authproviderx509Certurl\" , \"type\" : \"string\" }, \"clientX509CertUrl\" : { \"title\" : \"Clientx509Certurl\" , \"type\" : \"string\" }, \"universeDomain\" : { \"title\" : \"Universedomain\" , \"type\" : \"string\" } }, \"required\" : [ \"projectId\" , \"privateKeyId\" , \"privateKey\" , \"clientEmail\" , \"clientId\" , \"authUri\" , \"tokenUri\" , \"authProviderX509CertUrl\" , \"clientX509CertUrl\" , \"universeDomain\" ], \"title\" : \"ServiceAccountCredential\" , \"type\" : \"object\" }, \"Session\" : { \"additionalProperties\" : false , \"description\" : \"Represents a series of interactions between a user and agents.\" , \"properties\" : { \"id\" : { \"title\" : \"Id\" , \"type\" : \"string\" }, \"appName\" : { \"title\" : \"Appname\" , \"type\" : \"string\" }, \"userId\" : { \"title\" : \"Userid\" , \"type\" : \"string\" }, \"state\" : { \"additionalProperties\" : true , \"title\" : \"State\" , \"type\" : \"object\" }, \"events\" : { \"items\" : { \"$ref\" : \"#/$defs/Event\" }, \"title\" : \"Events\" , \"type\" : \"array\" }, \"lastUpdateTime\" : { \"default\" : 0.0 , \"title\" : \"Lastupdatetime\" , \"type\" : \"number\" } }, \"required\" : [ \"id\" , \"appName\" , \"userId\" ], \"title\" : \"Session\" , \"type\" : \"object\" }, \"SessionResumptionConfig\" : { \"additionalProperties\" : false , \"description\" : \"Configuration of session resumption mechanism.\\n\\nIncluded in `LiveConnectConfig.session_resumption`. If included server\\nwill send `LiveServerSessionResumptionUpdate` messages.\" , \"properties\" : { \"handle\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Session resumption handle of previous session (session to restore).\\n\\nIf not present new session will be started.\" , \"title\" : \"Handle\" }, \"transparent\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If set the server will send `last_consumed_client_message_index` in the `session_resumption_update` messages to allow for transparent reconnections.\" , \"title\" : \"Transparent\" } }, \"title\" : \"SessionResumptionConfig\" , \"type\" : \"object\" }, \"SlidingWindow\" : { \"additionalProperties\" : false , \"description\" : \"Context window will be truncated by keeping only suffix of it.\\n\\nContext window will always be cut at start of USER role turn. System\\ninstructions and `BidiGenerateContentSetup.prefix_turns` will not be\\nsubject to the sliding window mechanism, they will always stay at the\\nbeginning of context window.\" , \"properties\" : { \"targetTokens\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed.\" , \"title\" : \"Targettokens\" } }, \"title\" : \"SlidingWindow\" , \"type\" : \"object\" }, \"SpeakerVoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the speaker to use.\" , \"properties\" : { \"speaker\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The name of the speaker to use. Should be the same as in the\\n          prompt.\" , \"title\" : \"Speaker\" }, \"voiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the voice to use.\" } }, \"title\" : \"SpeakerVoiceConfig\" , \"type\" : \"object\" }, \"SpeechConfig\" : { \"additionalProperties\" : false , \"description\" : \"The speech generation configuration.\" , \"properties\" : { \"voiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the speaker to use.\\n      \" }, \"multiSpeakerVoiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/MultiSpeakerVoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the multi-speaker setup.\\n          It is mutually exclusive with the voice_config field.\\n          \" }, \"languageCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Language code (ISO 639. e.g. en-US) for the speech synthesization.\\n      Only available for Live API.\\n      \" , \"title\" : \"Languagecode\" } }, \"title\" : \"SpeechConfig\" , \"type\" : \"object\" }, \"StartSensitivity\" : { \"description\" : \"Start of speech sensitivity.\" , \"enum\" : [ \"START_SENSITIVITY_UNSPECIFIED\" , \"START_SENSITIVITY_HIGH\" , \"START_SENSITIVITY_LOW\" ], \"title\" : \"StartSensitivity\" , \"type\" : \"string\" }, \"StreamingMode\" : { \"enum\" : [ null , \"sse\" , \"bidi\" ], \"title\" : \"StreamingMode\" }, \"ToolConfirmation\" : { \"additionalProperties\" : false , \"description\" : \"Represents a tool confirmation configuration.\" , \"properties\" : { \"hint\" : { \"default\" : \"\" , \"title\" : \"Hint\" , \"type\" : \"string\" }, \"confirmed\" : { \"default\" : false , \"title\" : \"Confirmed\" , \"type\" : \"boolean\" }, \"payload\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Payload\" } }, \"title\" : \"ToolConfirmation\" , \"type\" : \"object\" }, \"TrafficType\" : { \"description\" : \"Output only.\\n\\nTraffic type. This shows whether a request consumes Pay-As-You-Go or\\nProvisioned Throughput quota.\" , \"enum\" : [ \"TRAFFIC_TYPE_UNSPECIFIED\" , \"ON_DEMAND\" , \"PROVISIONED_THROUGHPUT\" ], \"title\" : \"TrafficType\" , \"type\" : \"string\" }, \"Transcription\" : { \"additionalProperties\" : false , \"description\" : \"Audio transcription in Server Conent.\" , \"properties\" : { \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Transcription text.\\n      \" , \"title\" : \"Text\" }, \"finished\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The bool indicates the end of the transcription.\\n      \" , \"title\" : \"Finished\" } }, \"title\" : \"Transcription\" , \"type\" : \"object\" }, \"TranscriptionEntry\" : { \"additionalProperties\" : false , \"description\" : \"Store the data that can be used for transcription.\" , \"properties\" : { \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Role\" }, \"data\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"$ref\" : \"#/$defs/Content\" } ], \"title\" : \"Data\" } }, \"required\" : [ \"data\" ], \"title\" : \"TranscriptionEntry\" , \"type\" : \"object\" }, \"TurnCoverage\" : { \"description\" : \"Options about which input is included in the user's turn.\" , \"enum\" : [ \"TURN_COVERAGE_UNSPECIFIED\" , \"TURN_INCLUDES_ONLY_ACTIVITY\" , \"TURN_INCLUDES_ALL_INPUT\" ], \"title\" : \"TurnCoverage\" , \"type\" : \"string\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" }, \"VoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the voice to use.\" , \"properties\" : { \"prebuiltVoiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/PrebuiltVoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the speaker to use.\\n      \" } }, \"title\" : \"VoiceConfig\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"invocation_id\" , \"agent\" , \"session\" ] } Fields : active_streaming_tools (dict[str, google.adk.agents.active_streaming_tool.ActiveStreamingTool] | None) agent (google.adk.agents.base_agent.BaseAgent) agent_states (dict[str, dict[str, Any]]) artifact_service (google.adk.artifacts.base_artifact_service.BaseArtifactService | None) branch (str | None) context_cache_config (google.adk.agents.context_cache_config.ContextCacheConfig | None) credential_service (google.adk.auth.credential_service.base_credential_service.BaseCredentialService | None) end_invocation (bool) end_of_agents (dict[str, bool]) input_realtime_cache (list[google.adk.agents.invocation_context.RealtimeCacheEntry] | None) invocation_id (str) live_request_queue (google.adk.agents.live_request_queue.LiveRequestQueue | None) live_session_resumption_handle (str | None) memory_service (google.adk.memory.base_memory_service.BaseMemoryService | None) output_realtime_cache (list[google.adk.agents.invocation_context.RealtimeCacheEntry] | None) plugin_manager (google.adk.plugins.plugin_manager.PluginManager) resumability_config (google.adk.apps.app.ResumabilityConfig | None) run_config (google.adk.agents.run_config.RunConfig | None) session (google.adk.sessions.session.Session) session_service (google.adk.sessions.base_session_service.BaseSessionService) transcription_cache (list[google.adk.agents.transcription_entry.TranscriptionEntry] | None) user_content (google.genai.types.Content | None) field active_streaming_tools : Optional[dict[str, ActiveStreamingTool]] = None \u00b6 The running streaming tools of this invocation. field agent : BaseAgent [Required] \u00b6 The current agent of this invocation context. Readonly. field agent_states : dict[str, dict[str, Any]] [Optional] \u00b6 The state of the agent for this invocation. field artifact_service : Optional[BaseArtifactService] = None \u00b6 field branch : Optional[str] = None \u00b6 The branch of the invocation context. The format is like agent_1.agent_2.agent_3, where agent_1 is the parent of\nagent_2, and agent_2 is the parent of agent_3. Branch is used when multiple sub-agents shouldn\u2019t see their peer agents\u2019\nconversation history. field context_cache_config : Optional[ContextCacheConfig] = None \u00b6 field credential_service : Optional[BaseCredentialService] = None \u00b6 field end_invocation : bool = False \u00b6 Whether to end this invocation. Set to True in callbacks or tools to terminate this invocation. field end_of_agents : dict[str, bool] [Optional] \u00b6 The end of agent status for each agent in this invocation. field input_realtime_cache : Optional[list[RealtimeCacheEntry]] = None \u00b6 Caches input audio chunks before flushing to session and artifact services. field invocation_id : str [Required] \u00b6 The id of this invocation context. Readonly. field live_request_queue : Optional[LiveRequestQueue] = None \u00b6 The queue to receive live requests. field live_session_resumption_handle : Optional[str] = None \u00b6 The handle for live session resumption. field memory_service : Optional[BaseMemoryService] = None \u00b6 field output_realtime_cache : Optional[list[RealtimeCacheEntry]] = None \u00b6 Caches output audio chunks before flushing to session and artifact services. field plugin_manager : PluginManager [Optional] \u00b6 The manager for keeping track of plugins in this invocation. field resumability_config : Optional[ResumabilityConfig] = None \u00b6 The resumability config that applies to all agents under this invocation. field run_config : Optional[RunConfig] = None \u00b6 Configurations for live agents under this invocation. field session : Session [Required] \u00b6 The current session of this invocation context. Readonly. field session_service : BaseSessionService [Required] \u00b6 field transcription_cache : Optional[list[TranscriptionEntry]] = None \u00b6 Caches necessary data, audio or contents, that are needed by transcription. field user_content : Optional[types.Content] = None \u00b6 The user content that started this invocation. Readonly. increment_llm_call_count ( ) \u00b6 Tracks number of llm calls made. Raises : LlmCallsLimitExceededError \u2013 If number of llm calls made exceed the set\n    threshold. model_post_init ( context , / ) \u00b6 This function is meant to behave like a BaseModel method to initialise private attributes. It takes context as an argument since that\u2019s what pydantic-core passes when calling it. Return type : None Parameters : self \u2013 The BaseModel instance. context \u2013 The context. populate_invocation_agent_states ( ) \u00b6 Populates agent states for the current invocation if it is resumable. For history events that contain agent state information, set the\nagent_state and end_of_agent of the agent that generated the event. For non-workflow agents, also set an initial agent_state if it has\nalready generated some contents. Return type : None reset_sub_agent_states ( agent_name ) \u00b6 Resets the state of all sub-agents of the given agent in this invocation. Return type : None Parameters : agent_name \u2013 The name of the agent whose sub-agent states need to be reset. set_agent_state ( agent_name , * , agent_state = None , end_of_agent = False ) \u00b6 Sets the state of an agent in this invocation.\n:rtype: None If end_of_agent is True, will set the end_of_agent flag to True and\nclear the agent_state. Otherwise, if agent_state is not None, will set the agent_state and\nreset the end_of_agent flag to False. Otherwise, will clear the agent_state and end_of_agent flag, to allow the\nagent to re-run. Parameters : agent_name \u2013 The name of the agent. agent_state \u2013 The state of the agent. Will be ignored if end_of_agent is\nTrue. end_of_agent \u2013 Whether the agent has finished running. should_pause_invocation ( event ) \u00b6 Returns whether to pause the invocation right after this event. \u201cPausing\u201d an invocation is different from \u201cending\u201d an invocation. A paused\ninvocation can be resumed later, while an ended invocation cannot. Pausing the current agent\u2019s run will also pause all the agents that\ndepend on its execution, i.e. the subsequent agents in a workflow, and the\ncurrent agent\u2019s ancestors, etc. Note that parallel sibling agents won\u2019t be affected, but their common\nancestors will be paused after all the non-blocking sub-agents finished\nrunning. Return type : bool Should meet all following conditions to pause an invocation: The app is resumable. The current event has a long running function call. Parameters : event \u2013 The current event. Returns : Whether to pause the invocation right after this event. property app_name : str \u00b6 property is_resumable : bool \u00b6 Returns whether the current invocation is resumable. property user_id : str \u00b6 pydantic model google.adk.agents. LiveRequest \u00b6 Bases: BaseModel Request send to live agents. Show JSON schema { \"title\" : \"LiveRequest\" , \"description\" : \"Request send to live agents.\" , \"type\" : \"object\" , \"properties\" : { \"content\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Content\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"blob\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"activity_start\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ActivityStart\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"activity_end\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ActivityEnd\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"close\" : { \"default\" : false , \"title\" : \"Close\" , \"type\" : \"boolean\" } }, \"$defs\" : { \"ActivityEnd\" : { \"additionalProperties\" : false , \"description\" : \"Marks the end of user activity.\\n\\nThis can only be sent if automatic (i.e. server-side) activity detection is\\ndisabled.\" , \"properties\" : {}, \"title\" : \"ActivityEnd\" , \"type\" : \"object\" }, \"ActivityStart\" : { \"additionalProperties\" : false , \"description\" : \"Marks the start of user activity.\\n\\nThis can only be sent if automatic (i.e. server-side) activity detection is\\ndisabled.\" , \"properties\" : {}, \"title\" : \"ActivityStart\" , \"type\" : \"object\" }, \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"Content\" : { \"additionalProperties\" : false , \"description\" : \"Contains the multi-part content of a message.\" , \"properties\" : { \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Part\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a single message. Each part may have\\n      a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The producer of the content. Must be either 'user' or\\n      'model'. Useful to set for multi-turn conversations, otherwise can be\\n      empty. If role is not specified, SDK will determine the role.\" , \"title\" : \"Role\" } }, \"title\" : \"Content\" , \"type\" : \"object\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" } } } Fields : activity_end (google.genai.types.ActivityEnd | None) activity_start (google.genai.types.ActivityStart | None) blob (google.genai.types.Blob | None) close (bool) content (google.genai.types.Content | None) field activity_end : Optional[types.ActivityEnd] = None \u00b6 If set, signal the end of user activity to the model. field activity_start : Optional[types.ActivityStart] = None \u00b6 If set, signal the start of user activity to the model. field blob : Optional[types.Blob] = None \u00b6 If set, send the blob to the model in realtime mode. field close : bool = False \u00b6 If set, close the queue. queue.shutdown() is only supported in Python 3.13+. field content : Optional[types.Content] = None \u00b6 If set, send the content to the model in turn-by-turn mode. class google.adk.agents. LiveRequestQueue \u00b6 Bases: object Queue used to send LiveRequest in a live(bidirectional streaming) way. close ( ) \u00b6 async get ( ) \u00b6 Return type : LiveRequest send ( req ) \u00b6 send_activity_end ( ) \u00b6 Sends an activity end signal to mark the end of user input. send_activity_start ( ) \u00b6 Sends an activity start signal to mark the beginning of user input. send_content ( content ) \u00b6 send_realtime ( blob ) \u00b6 pydantic model google.adk.agents. LlmAgent \u00b6 Bases: BaseAgent LLM-based Agent. Show JSON schema { \"title\" : \"LlmAgent\" , \"type\" : \"object\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" }, \"model\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"$ref\" : \"#/$defs/BaseLlm\" } ], \"default\" : \"\" , \"title\" : \"Model\" }, \"instruction\" : { \"default\" : \"\" , \"title\" : \"Instruction\" , \"type\" : \"string\" }, \"global_instruction\" : { \"default\" : \"\" , \"title\" : \"Global Instruction\" , \"type\" : \"string\" }, \"static_instruction\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Content\" }, { \"type\" : \"string\" }, { \"$ref\" : \"#/$defs/File\" }, { \"$ref\" : \"#/$defs/Part\" }, { \"items\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"$ref\" : \"#/$defs/File\" }, { \"$ref\" : \"#/$defs/Part\" } ] }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Static Instruction\" }, \"tools\" : { \"items\" : { \"anyOf\" : [] }, \"title\" : \"Tools\" , \"type\" : \"array\" }, \"generate_content_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GenerateContentConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"disallow_transfer_to_parent\" : { \"default\" : false , \"title\" : \"Disallow Transfer To Parent\" , \"type\" : \"boolean\" }, \"disallow_transfer_to_peers\" : { \"default\" : false , \"title\" : \"Disallow Transfer To Peers\" , \"type\" : \"boolean\" }, \"include_contents\" : { \"default\" : \"default\" , \"enum\" : [ \"default\" , \"none\" ], \"title\" : \"Include Contents\" , \"type\" : \"string\" }, \"input_schema\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Input Schema\" }, \"output_schema\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Output Schema\" }, \"output_key\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Output Key\" }, \"planner\" : { \"default\" : null , \"title\" : \"Planner\" }, \"code_executor\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseCodeExecutor\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"before_model_callback\" : { \"default\" : null , \"title\" : \"Before Model Callback\" , \"type\" : \"null\" }, \"after_model_callback\" : { \"default\" : null , \"title\" : \"After Model Callback\" , \"type\" : \"null\" }, \"before_tool_callback\" : { \"default\" : null , \"title\" : \"Before Tool Callback\" , \"type\" : \"null\" }, \"after_tool_callback\" : { \"default\" : null , \"title\" : \"After Tool Callback\" , \"type\" : \"null\" } }, \"$defs\" : { \"ApiAuth\" : { \"additionalProperties\" : false , \"description\" : \"The generic reusable api auth config.\\n\\nDeprecated. Please use AuthConfig (google/cloud/aiplatform/master/auth.proto)\\ninstead.\" , \"properties\" : { \"apiKeyConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ApiAuthApiKeyConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The API secret.\" } }, \"title\" : \"ApiAuth\" , \"type\" : \"object\" }, \"ApiAuthApiKeyConfig\" : { \"additionalProperties\" : false , \"description\" : \"The API secret.\" , \"properties\" : { \"apiKeySecretVersion\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The SecretManager secret version resource name storing API key. e.g. projects/{project}/secrets/{secret}/versions/{version}\" , \"title\" : \"Apikeysecretversion\" }, \"apiKeyString\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The API key string. Either this or `api_key_secret_version` must be set.\" , \"title\" : \"Apikeystring\" } }, \"title\" : \"ApiAuthApiKeyConfig\" , \"type\" : \"object\" }, \"ApiKeyConfig\" : { \"additionalProperties\" : false , \"description\" : \"Config for authentication with API key.\" , \"properties\" : { \"apiKeyString\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The API key to be used in the request directly.\" , \"title\" : \"Apikeystring\" } }, \"title\" : \"ApiKeyConfig\" , \"type\" : \"object\" }, \"ApiSpec\" : { \"description\" : \"The API spec that the external API implements.\" , \"enum\" : [ \"API_SPEC_UNSPECIFIED\" , \"SIMPLE_SEARCH\" , \"ELASTIC_SEARCH\" ], \"title\" : \"ApiSpec\" , \"type\" : \"string\" }, \"AuthConfig\" : { \"additionalProperties\" : false , \"description\" : \"Auth configuration to run the extension.\" , \"properties\" : { \"apiKeyConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ApiKeyConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Config for API key auth.\" }, \"authType\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthType\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Type of auth scheme.\" }, \"googleServiceAccountConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthConfigGoogleServiceAccountConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Config for Google Service Account auth.\" }, \"httpBasicAuthConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthConfigHttpBasicAuthConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Config for HTTP Basic auth.\" }, \"oauthConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthConfigOauthConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Config for user oauth.\" }, \"oidcConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthConfigOidcConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Config for user OIDC auth.\" } }, \"title\" : \"AuthConfig\" , \"type\" : \"object\" }, \"AuthConfigGoogleServiceAccountConfig\" : { \"additionalProperties\" : false , \"description\" : \"Config for Google Service Account Authentication.\" , \"properties\" : { \"serviceAccount\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.\" , \"title\" : \"Serviceaccount\" } }, \"title\" : \"AuthConfigGoogleServiceAccountConfig\" , \"type\" : \"object\" }, \"AuthConfigHttpBasicAuthConfig\" : { \"additionalProperties\" : false , \"description\" : \"Config for HTTP Basic Authentication.\" , \"properties\" : { \"credentialSecret\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.\" , \"title\" : \"Credentialsecret\" } }, \"title\" : \"AuthConfigHttpBasicAuthConfig\" , \"type\" : \"object\" }, \"AuthConfigOauthConfig\" : { \"additionalProperties\" : false , \"description\" : \"Config for user oauth.\" , \"properties\" : { \"accessToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.\" , \"title\" : \"Accesstoken\" }, \"serviceAccount\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.\" , \"title\" : \"Serviceaccount\" } }, \"title\" : \"AuthConfigOauthConfig\" , \"type\" : \"object\" }, \"AuthConfigOidcConfig\" : { \"additionalProperties\" : false , \"description\" : \"Config for user OIDC auth.\" , \"properties\" : { \"idToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.\" , \"title\" : \"Idtoken\" }, \"serviceAccount\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).\" , \"title\" : \"Serviceaccount\" } }, \"title\" : \"AuthConfigOidcConfig\" , \"type\" : \"object\" }, \"AuthType\" : { \"description\" : \"Type of auth scheme.\" , \"enum\" : [ \"AUTH_TYPE_UNSPECIFIED\" , \"NO_AUTH\" , \"API_KEY_AUTH\" , \"HTTP_BASIC_AUTH\" , \"GOOGLE_SERVICE_ACCOUNT_AUTH\" , \"OAUTH\" , \"OIDC_AUTH\" ], \"title\" : \"AuthType\" , \"type\" : \"string\" }, \"AutomaticFunctionCallingConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for automatic function calling.\" , \"properties\" : { \"disable\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Whether to disable automatic function calling.\\n      If not set or set to False, will enable automatic function calling.\\n      If set to True, will disable automatic function calling.\\n      \" , \"title\" : \"Disable\" }, \"maximumRemoteCalls\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : 10 , \"description\" : \"If automatic function calling is enabled,\\n      maximum number of remote calls for automatic function calling.\\n      This number should be a positive integer.\\n      If not set, SDK will set maximum number of remote calls to 10.\\n      \" , \"title\" : \"Maximumremotecalls\" }, \"ignoreCallHistory\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If automatic function calling is enabled,\\n      whether to ignore call history to the response.\\n      If not set, SDK will set ignore_call_history to false,\\n      and will append the call history to\\n      GenerateContentResponse.automatic_function_calling_history.\\n      \" , \"title\" : \"Ignorecallhistory\" } }, \"title\" : \"AutomaticFunctionCallingConfig\" , \"type\" : \"object\" }, \"BaseAgent\" : { \"additionalProperties\" : false , \"description\" : \"Base class for all agents in Agent Development Kit.\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" } }, \"required\" : [ \"name\" ], \"title\" : \"BaseAgent\" , \"type\" : \"object\" }, \"BaseCodeExecutor\" : { \"description\" : \"Abstract base class for all code executors.\\n\\nThe code executor allows the agent to execute code blocks from model responses\\nand incorporate the execution results into the final response.\\n\\nAttributes:\\n  optimize_data_file: If true, extract and process data files from the model\\n    request and attach them to the code executor. Supported data file\\n    MimeTypes are [text/csv]. Default to False.\\n  stateful: Whether the code executor is stateful. Default to False.\\n  error_retry_attempts: The number of attempts to retry on consecutive code\\n    execution errors. Default to 2.\\n  code_block_delimiters: The list of the enclosing delimiters to identify the\\n    code blocks.\\n  execution_result_delimiters: The delimiters to format the code execution\\n    result.\" , \"properties\" : { \"optimize_data_file\" : { \"default\" : false , \"title\" : \"Optimize Data File\" , \"type\" : \"boolean\" }, \"stateful\" : { \"default\" : false , \"title\" : \"Stateful\" , \"type\" : \"boolean\" }, \"error_retry_attempts\" : { \"default\" : 2 , \"title\" : \"Error Retry Attempts\" , \"type\" : \"integer\" }, \"code_block_delimiters\" : { \"default\" : [ [ \"```tool_code\\n\" , \"\\n```\" ], [ \"```python\\n\" , \"\\n```\" ] ], \"items\" : { \"maxItems\" : 2 , \"minItems\" : 2 , \"prefixItems\" : [ { \"type\" : \"string\" }, { \"type\" : \"string\" } ], \"type\" : \"array\" }, \"title\" : \"Code Block Delimiters\" , \"type\" : \"array\" }, \"execution_result_delimiters\" : { \"default\" : [ \"```tool_output\\n\" , \"\\n```\" ], \"maxItems\" : 2 , \"minItems\" : 2 , \"prefixItems\" : [ { \"type\" : \"string\" }, { \"type\" : \"string\" } ], \"title\" : \"Execution Result Delimiters\" , \"type\" : \"array\" } }, \"title\" : \"BaseCodeExecutor\" , \"type\" : \"object\" }, \"BaseLlm\" : { \"description\" : \"The BaseLLM class.\" , \"properties\" : { \"model\" : { \"title\" : \"Model\" , \"type\" : \"string\" } }, \"required\" : [ \"model\" ], \"title\" : \"BaseLlm\" , \"type\" : \"object\" }, \"Behavior\" : { \"description\" : \"Defines the function behavior. Defaults to `BLOCKING`.\" , \"enum\" : [ \"UNSPECIFIED\" , \"BLOCKING\" , \"NON_BLOCKING\" ], \"title\" : \"Behavior\" , \"type\" : \"string\" }, \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"ComputerUse\" : { \"additionalProperties\" : false , \"description\" : \"Tool to support computer use.\" , \"properties\" : { \"environment\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Environment\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The environment being operated.\" }, \"excludedPredefinedFunctions\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"By default, predefined functions are included in the final model call.\\n    Some of them can be explicitly excluded from being automatically included.\\n    This can serve two purposes:\\n      1. Using a more restricted / different action space.\\n      2. Improving the definitions / instructions of predefined functions.\" , \"title\" : \"Excludedpredefinedfunctions\" } }, \"title\" : \"ComputerUse\" , \"type\" : \"object\" }, \"Content\" : { \"additionalProperties\" : false , \"description\" : \"Contains the multi-part content of a message.\" , \"properties\" : { \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Part\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a single message. Each part may have\\n      a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The producer of the content. Must be either 'user' or\\n      'model'. Useful to set for multi-turn conversations, otherwise can be\\n      empty. If role is not specified, SDK will determine the role.\" , \"title\" : \"Role\" } }, \"title\" : \"Content\" , \"type\" : \"object\" }, \"DynamicRetrievalConfig\" : { \"additionalProperties\" : false , \"description\" : \"Describes the options to customize dynamic retrieval.\" , \"properties\" : { \"mode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/DynamicRetrievalConfigMode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The mode of the predictor to be used in dynamic retrieval.\" }, \"dynamicThreshold\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.\" , \"title\" : \"Dynamicthreshold\" } }, \"title\" : \"DynamicRetrievalConfig\" , \"type\" : \"object\" }, \"DynamicRetrievalConfigMode\" : { \"description\" : \"Config for the dynamic retrieval config mode.\" , \"enum\" : [ \"MODE_UNSPECIFIED\" , \"MODE_DYNAMIC\" ], \"title\" : \"DynamicRetrievalConfigMode\" , \"type\" : \"string\" }, \"EnterpriseWebSearch\" : { \"additionalProperties\" : false , \"description\" : \"Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.\" , \"properties\" : { \"excludeDomains\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. List of domains to be excluded from the search results. The default limit is 2000 domains.\" , \"title\" : \"Excludedomains\" } }, \"title\" : \"EnterpriseWebSearch\" , \"type\" : \"object\" }, \"Environment\" : { \"description\" : \"The environment being operated.\" , \"enum\" : [ \"ENVIRONMENT_UNSPECIFIED\" , \"ENVIRONMENT_BROWSER\" ], \"title\" : \"Environment\" , \"type\" : \"string\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"ExternalApi\" : { \"additionalProperties\" : false , \"description\" : \"Retrieve from data source powered by external API for grounding.\\n\\nThe external API is not owned by Google, but need to follow the pre-defined\\nAPI spec.\" , \"properties\" : { \"apiAuth\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ApiAuth\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The authentication config to access the API. Deprecated. Please use auth_config instead.\" }, \"apiSpec\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ApiSpec\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The API spec that the external API implements.\" }, \"authConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The authentication config to access the API.\" }, \"elasticSearchParams\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExternalApiElasticSearchParams\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Parameters for the elastic search API.\" }, \"endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The endpoint of the external API. The system will call the API at this endpoint to retrieve the data for grounding. Example: https://acme.com:443/search\" , \"title\" : \"Endpoint\" }, \"simpleSearchParams\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExternalApiSimpleSearchParams\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Parameters for the simple search API.\" } }, \"title\" : \"ExternalApi\" , \"type\" : \"object\" }, \"ExternalApiElasticSearchParams\" : { \"additionalProperties\" : false , \"description\" : \"The search parameters to use for the ELASTIC_SEARCH spec.\" , \"properties\" : { \"index\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The ElasticSearch index to use.\" , \"title\" : \"Index\" }, \"numHits\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Number of hits (chunks) to request. When specified, it is passed to Elasticsearch as the `num_hits` param.\" , \"title\" : \"Numhits\" }, \"searchTemplate\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The ElasticSearch search template to use.\" , \"title\" : \"Searchtemplate\" } }, \"title\" : \"ExternalApiElasticSearchParams\" , \"type\" : \"object\" }, \"ExternalApiSimpleSearchParams\" : { \"additionalProperties\" : false , \"description\" : \"The search parameters to use for SIMPLE_SEARCH spec.\" , \"properties\" : {}, \"title\" : \"ExternalApiSimpleSearchParams\" , \"type\" : \"object\" }, \"FeatureSelectionPreference\" : { \"description\" : \"Options for feature selection preference.\" , \"enum\" : [ \"FEATURE_SELECTION_PREFERENCE_UNSPECIFIED\" , \"PRIORITIZE_QUALITY\" , \"BALANCED\" , \"PRIORITIZE_COST\" ], \"title\" : \"FeatureSelectionPreference\" , \"type\" : \"string\" }, \"File\" : { \"additionalProperties\" : false , \"description\" : \"A file uploaded to the API.\" , \"properties\" : { \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The `File` resource name. The ID (name excluding the \\\"files/\\\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`\" , \"title\" : \"Name\" }, \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image'\" , \"title\" : \"Displayname\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. MIME type of the file.\" , \"title\" : \"Mimetype\" }, \"sizeBytes\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Size of the file in bytes.\" , \"title\" : \"Sizebytes\" }, \"createTime\" : { \"anyOf\" : [ { \"format\" : \"date-time\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The timestamp of when the `File` was created.\" , \"title\" : \"Createtime\" }, \"expirationTime\" : { \"anyOf\" : [ { \"format\" : \"date-time\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.\" , \"title\" : \"Expirationtime\" }, \"updateTime\" : { \"anyOf\" : [ { \"format\" : \"date-time\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The timestamp of when the `File` was last updated.\" , \"title\" : \"Updatetime\" }, \"sha256Hash\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.\" , \"title\" : \"Sha256Hash\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The URI of the `File`.\" , \"title\" : \"Uri\" }, \"downloadUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The URI of the `File`, only set for downloadable (generated) files.\" , \"title\" : \"Downloaduri\" }, \"state\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileState\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Processing state of the File.\" }, \"source\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileSource\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The source of the `File`.\" }, \"videoMetadata\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Metadata for a video.\" , \"title\" : \"Videometadata\" }, \"error\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileStatus\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Error status if File processing failed.\" } }, \"title\" : \"File\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FileSource\" : { \"description\" : \"Source of the File.\" , \"enum\" : [ \"SOURCE_UNSPECIFIED\" , \"UPLOADED\" , \"GENERATED\" ], \"title\" : \"FileSource\" , \"type\" : \"string\" }, \"FileState\" : { \"description\" : \"State for the lifecycle of a File.\" , \"enum\" : [ \"STATE_UNSPECIFIED\" , \"PROCESSING\" , \"ACTIVE\" , \"FAILED\" ], \"title\" : \"FileState\" , \"type\" : \"string\" }, \"FileStatus\" : { \"additionalProperties\" : false , \"description\" : \"Status of a File that uses a common error model.\" , \"properties\" : { \"details\" : { \"anyOf\" : [ { \"items\" : { \"additionalProperties\" : true , \"type\" : \"object\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A list of messages that carry the error details. There is a common set of message types for APIs to use.\" , \"title\" : \"Details\" }, \"message\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A list of messages that carry the error details. There is a common set of message types for APIs to use.\" , \"title\" : \"Message\" }, \"code\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The status code. 0 for OK, 1 for CANCELLED\" , \"title\" : \"Code\" } }, \"title\" : \"FileStatus\" , \"type\" : \"object\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionCallingConfig\" : { \"additionalProperties\" : false , \"description\" : \"Function calling config.\" , \"properties\" : { \"mode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCallingConfigMode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Function calling mode.\" }, \"allowedFunctionNames\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided.\" , \"title\" : \"Allowedfunctionnames\" } }, \"title\" : \"FunctionCallingConfig\" , \"type\" : \"object\" }, \"FunctionCallingConfigMode\" : { \"description\" : \"Config for the function calling config mode.\" , \"enum\" : [ \"MODE_UNSPECIFIED\" , \"AUTO\" , \"ANY\" , \"NONE\" , \"VALIDATED\" ], \"title\" : \"FunctionCallingConfigMode\" , \"type\" : \"string\" }, \"FunctionDeclaration\" : { \"additionalProperties\" : false , \"description\" : \"Defines a function that the model can generate JSON inputs for.\\n\\nThe inputs are based on `OpenAPI 3.0 specifications\\n<https://spec.openapis.org/oas/v3.0.3>`_.\" , \"properties\" : { \"behavior\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Behavior\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Defines the function behavior.\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.\" , \"title\" : \"Description\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.\" , \"title\" : \"Name\" }, \"parameters\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Schema\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1\" }, \"parametersJsonSchema\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Describes the parameters to the function in JSON Schema format. The schema must describe an object where the properties are the parameters to the function. For example: ``` { \\\"type\\\": \\\"object\\\", \\\"properties\\\": { \\\"name\\\": { \\\"type\\\": \\\"string\\\" }, \\\"age\\\": { \\\"type\\\": \\\"integer\\\" } }, \\\"additionalProperties\\\": false, \\\"required\\\": [\\\"name\\\", \\\"age\\\"], \\\"propertyOrdering\\\": [\\\"name\\\", \\\"age\\\"] } ``` This field is mutually exclusive with `parameters`.\" , \"title\" : \"Parametersjsonschema\" }, \"response\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Schema\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function.\" }, \"responseJsonSchema\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Describes the output from this function in JSON Schema format. The value specified by the schema is the response value of the function. This field is mutually exclusive with `response`.\" , \"title\" : \"Responsejsonschema\" } }, \"title\" : \"FunctionDeclaration\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"GenerateContentConfig\" : { \"additionalProperties\" : false , \"description\" : \"Optional model configuration parameters.\\n\\nFor more information, see `Content generation parameters\\n<https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters>`_.\" , \"properties\" : { \"httpOptions\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HttpOptions\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Used to override HTTP request options.\" }, \"shouldReturnHttpResponse\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \" If true, the raw HTTP response will be returned in the 'sdk_http_response' field.\" , \"title\" : \"Shouldreturnhttpresponse\" }, \"systemInstruction\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Content\" }, { \"type\" : \"string\" }, { \"$ref\" : \"#/$defs/File\" }, { \"$ref\" : \"#/$defs/Part\" }, { \"items\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"$ref\" : \"#/$defs/File\" }, { \"$ref\" : \"#/$defs/Part\" } ] }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Instructions for the model to steer it toward better performance.\\n      For example, \\\"Answer as concisely as possible\\\" or \\\"Don't use technical\\n      terms in your response\\\".\\n      \" , \"title\" : \"Systeminstruction\" }, \"temperature\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Value that controls the degree of randomness in token selection.\\n      Lower temperatures are good for prompts that require a less open-ended or\\n      creative response, while higher temperatures can lead to more diverse or\\n      creative results.\\n      \" , \"title\" : \"Temperature\" }, \"topP\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Tokens are selected from the most to least probable until the sum\\n      of their probabilities equals this value. Use a lower value for less\\n      random responses and a higher value for more random responses.\\n      \" , \"title\" : \"Topp\" }, \"topK\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"For each token selection step, the ``top_k`` tokens with the\\n      highest probabilities are sampled. Then tokens are further filtered based\\n      on ``top_p`` with the final token selected using temperature sampling. Use\\n      a lower number for less random responses and a higher number for more\\n      random responses.\\n      \" , \"title\" : \"Topk\" }, \"candidateCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of response variations to return.\\n      \" , \"title\" : \"Candidatecount\" }, \"maxOutputTokens\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Maximum number of tokens that can be generated in the response.\\n      \" , \"title\" : \"Maxoutputtokens\" }, \"stopSequences\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of strings that tells the model to stop generating text if one\\n      of the strings is encountered in the response.\\n      \" , \"title\" : \"Stopsequences\" }, \"responseLogprobs\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Whether to return the log probabilities of the tokens that were\\n      chosen by the model at each step.\\n      \" , \"title\" : \"Responselogprobs\" }, \"logprobs\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of top candidate tokens to return the log probabilities for\\n      at each generation step.\\n      \" , \"title\" : \"Logprobs\" }, \"presencePenalty\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Positive values penalize tokens that already appear in the\\n      generated text, increasing the probability of generating more diverse\\n      content.\\n      \" , \"title\" : \"Presencepenalty\" }, \"frequencyPenalty\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Positive values penalize tokens that repeatedly appear in the\\n      generated text, increasing the probability of generating more diverse\\n      content.\\n      \" , \"title\" : \"Frequencypenalty\" }, \"seed\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"When ``seed`` is fixed to a specific number, the model makes a best\\n      effort to provide the same response for repeated requests. By default, a\\n      random number is used.\\n      \" , \"title\" : \"Seed\" }, \"responseMimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output response mimetype of the generated candidate text.\\n      Supported mimetype:\\n        - `text/plain`: (default) Text output.\\n        - `application/json`: JSON response in the candidates.\\n      The model needs to be prompted to output the appropriate response type,\\n      otherwise the behavior is undefined.\\n      This is a preview feature.\\n      \" , \"title\" : \"Responsemimetype\" }, \"responseSchema\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"$ref\" : \"#/$defs/Schema\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The `Schema` object allows the definition of input and output data types.\\n      These types can be objects, but also primitives and arrays.\\n      Represents a select subset of an [OpenAPI 3.0 schema\\n      object](https://spec.openapis.org/oas/v3.0.3#schema).\\n      If set, a compatible response_mime_type must also be set.\\n      Compatible mimetypes: `application/json`: Schema for JSON response.\\n      \" , \"title\" : \"Responseschema\" }, \"responseJsonSchema\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Output schema of the generated response.\\n      This is an alternative to `response_schema` that accepts [JSON\\n      Schema](https://json-schema.org/). If set, `response_schema` must be\\n      omitted, but `response_mime_type` is required. While the full JSON Schema\\n      may be sent, not all features are supported. Specifically, only the\\n      following properties are supported: - `$id` - `$defs` - `$ref` - `$anchor`\\n      - `type` - `format` - `title` - `description` - `enum` (for strings and\\n      numbers) - `items` - `prefixItems` - `minItems` - `maxItems` - `minimum` -\\n      `maximum` - `anyOf` - `oneOf` (interpreted the same as `anyOf`) -\\n      `properties` - `additionalProperties` - `required` The non-standard\\n      `propertyOrdering` property may also be set. Cyclic references are\\n      unrolled to a limited degree and, as such, may only be used within\\n      non-required properties. (Nullable properties are not sufficient.) If\\n      `$ref` is set on a sub-schema, no other properties, except for than those\\n      starting as a `$`, may be set.\" , \"title\" : \"Responsejsonschema\" }, \"routingConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GenerationConfigRoutingConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Configuration for model router requests.\\n      \" }, \"modelSelectionConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ModelSelectionConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Configuration for model selection.\\n      \" }, \"safetySettings\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/SafetySetting\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Safety settings in the request to block unsafe content in the\\n      response.\\n      \" , \"title\" : \"Safetysettings\" }, \"tools\" : { \"anyOf\" : [ { \"items\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/google__genai__types__Tool\" }, { \"$ref\" : \"#/$defs/mcp__types__Tool\" } ] }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Code that enables the system to interact with external systems to\\n      perform an action outside of the knowledge and scope of the model.\\n      \" , \"title\" : \"Tools\" }, \"toolConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ToolConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Associates model output to a specific function call.\\n      \" }, \"labels\" : { \"anyOf\" : [ { \"additionalProperties\" : { \"type\" : \"string\" }, \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Labels with user-defined metadata to break down billed charges.\" , \"title\" : \"Labels\" }, \"cachedContent\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Resource name of a context cache that can be used in subsequent\\n      requests.\\n      \" , \"title\" : \"Cachedcontent\" }, \"responseModalities\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The requested modalities of the response. Represents the set of\\n      modalities that the model can return.\\n      \" , \"title\" : \"Responsemodalities\" }, \"mediaResolution\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/MediaResolution\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If specified, the media resolution specified will be used.\\n    \" }, \"speechConfig\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"$ref\" : \"#/$defs/SpeechConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The speech generation configuration.\\n      \" , \"title\" : \"Speechconfig\" }, \"audioTimestamp\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If enabled, audio timestamp will be included in the request to the\\n       model.\\n      \" , \"title\" : \"Audiotimestamp\" }, \"automaticFunctionCalling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AutomaticFunctionCallingConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for automatic function calling.\\n      \" }, \"thinkingConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ThinkingConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The thinking features configuration.\\n      \" }, \"imageConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ImageConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The image generation configuration.\\n      \" } }, \"title\" : \"GenerateContentConfig\" , \"type\" : \"object\" }, \"GenerationConfigRoutingConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for routing the request to a specific model.\" , \"properties\" : { \"autoMode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GenerationConfigRoutingConfigAutoRoutingMode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Automated routing.\" }, \"manualMode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GenerationConfigRoutingConfigManualRoutingMode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Manual routing.\" } }, \"title\" : \"GenerationConfigRoutingConfig\" , \"type\" : \"object\" }, \"GenerationConfigRoutingConfigAutoRoutingMode\" : { \"additionalProperties\" : false , \"description\" : \"When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.\" , \"properties\" : { \"modelRoutingPreference\" : { \"anyOf\" : [ { \"enum\" : [ \"UNKNOWN\" , \"PRIORITIZE_QUALITY\" , \"BALANCED\" , \"PRIORITIZE_COST\" ], \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The model routing preference.\" , \"title\" : \"Modelroutingpreference\" } }, \"title\" : \"GenerationConfigRoutingConfigAutoRoutingMode\" , \"type\" : \"object\" }, \"GenerationConfigRoutingConfigManualRoutingMode\" : { \"additionalProperties\" : false , \"description\" : \"When manual routing is set, the specified model will be used directly.\" , \"properties\" : { \"modelName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The model name to use. Only the public LLM models are accepted. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models).\" , \"title\" : \"Modelname\" } }, \"title\" : \"GenerationConfigRoutingConfigManualRoutingMode\" , \"type\" : \"object\" }, \"GoogleMaps\" : { \"additionalProperties\" : false , \"description\" : \"Tool to support Google Maps in Model.\" , \"properties\" : { \"authConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Auth config for the Google Maps tool.\" } }, \"title\" : \"GoogleMaps\" , \"type\" : \"object\" }, \"GoogleSearch\" : { \"additionalProperties\" : false , \"description\" : \"Tool to support Google Search in Model. Powered by Google.\" , \"properties\" : { \"timeRangeFilter\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Interval\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Filter search results to a specific time range.\\n      If customers set a start time, they must set an end time (and vice versa).\\n      \" }, \"excludeDomains\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. List of domains to be excluded from the search results.\\n      The default limit is 2000 domains.\" , \"title\" : \"Excludedomains\" } }, \"title\" : \"GoogleSearch\" , \"type\" : \"object\" }, \"GoogleSearchRetrieval\" : { \"additionalProperties\" : false , \"description\" : \"Tool to retrieve public web data for grounding, powered by Google.\" , \"properties\" : { \"dynamicRetrievalConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/DynamicRetrievalConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies the dynamic retrieval configuration for the given source.\" } }, \"title\" : \"GoogleSearchRetrieval\" , \"type\" : \"object\" }, \"HarmBlockMethod\" : { \"description\" : \"Optional.\\n\\nSpecify if the threshold is used for probability or severity score. If not\\nspecified, the threshold is used for probability score.\" , \"enum\" : [ \"HARM_BLOCK_METHOD_UNSPECIFIED\" , \"SEVERITY\" , \"PROBABILITY\" ], \"title\" : \"HarmBlockMethod\" , \"type\" : \"string\" }, \"HarmBlockThreshold\" : { \"description\" : \"Required. The harm block threshold.\" , \"enum\" : [ \"HARM_BLOCK_THRESHOLD_UNSPECIFIED\" , \"BLOCK_LOW_AND_ABOVE\" , \"BLOCK_MEDIUM_AND_ABOVE\" , \"BLOCK_ONLY_HIGH\" , \"BLOCK_NONE\" , \"OFF\" ], \"title\" : \"HarmBlockThreshold\" , \"type\" : \"string\" }, \"HarmCategory\" : { \"description\" : \"Required. Harm category.\" , \"enum\" : [ \"HARM_CATEGORY_UNSPECIFIED\" , \"HARM_CATEGORY_HATE_SPEECH\" , \"HARM_CATEGORY_DANGEROUS_CONTENT\" , \"HARM_CATEGORY_HARASSMENT\" , \"HARM_CATEGORY_SEXUALLY_EXPLICIT\" , \"HARM_CATEGORY_CIVIC_INTEGRITY\" , \"HARM_CATEGORY_IMAGE_HATE\" , \"HARM_CATEGORY_IMAGE_DANGEROUS_CONTENT\" , \"HARM_CATEGORY_IMAGE_HARASSMENT\" , \"HARM_CATEGORY_IMAGE_SEXUALLY_EXPLICIT\" ], \"title\" : \"HarmCategory\" , \"type\" : \"string\" }, \"HttpOptions\" : { \"additionalProperties\" : false , \"description\" : \"HTTP options to be used in each of the requests.\" , \"properties\" : { \"baseUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The base URL for the AI platform service endpoint.\" , \"title\" : \"Baseurl\" }, \"apiVersion\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies the version of the API to use.\" , \"title\" : \"Apiversion\" }, \"headers\" : { \"anyOf\" : [ { \"additionalProperties\" : { \"type\" : \"string\" }, \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Additional HTTP headers to be sent with the request.\" , \"title\" : \"Headers\" }, \"timeout\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Timeout for the request in milliseconds.\" , \"title\" : \"Timeout\" }, \"clientArgs\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Args passed to the HTTP client.\" , \"title\" : \"Clientargs\" }, \"asyncClientArgs\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Args passed to the async HTTP client.\" , \"title\" : \"Asyncclientargs\" }, \"extraBody\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Extra parameters to add to the request body.\\n      The structure must match the backend API's request structure.\\n      - VertexAI backend API docs: https://cloud.google.com/vertex-ai/docs/reference/rest\\n      - GeminiAPI backend API docs: https://ai.google.dev/api/rest\" , \"title\" : \"Extrabody\" }, \"retryOptions\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HttpRetryOptions\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"HTTP retry options for the request.\" } }, \"title\" : \"HttpOptions\" , \"type\" : \"object\" }, \"HttpRetryOptions\" : { \"additionalProperties\" : false , \"description\" : \"HTTP retry options to be used in each of the requests.\" , \"properties\" : { \"attempts\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Maximum number of attempts, including the original request.\\n      If 0 or 1, it means no retries.\" , \"title\" : \"Attempts\" }, \"initialDelay\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Initial delay before the first retry, in fractions of a second.\" , \"title\" : \"Initialdelay\" }, \"maxDelay\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Maximum delay between retries, in fractions of a second.\" , \"title\" : \"Maxdelay\" }, \"expBase\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Multiplier by which the delay increases after each attempt.\" , \"title\" : \"Expbase\" }, \"jitter\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Randomness factor for the delay.\" , \"title\" : \"Jitter\" }, \"httpStatusCodes\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"integer\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of HTTP status codes that should trigger a retry.\\n      If not specified, a default set of retryable codes may be used.\" , \"title\" : \"Httpstatuscodes\" } }, \"title\" : \"HttpRetryOptions\" , \"type\" : \"object\" }, \"ImageConfig\" : { \"additionalProperties\" : false , \"description\" : \"The image generation configuration to be used in GenerateContentConfig.\" , \"properties\" : { \"aspectRatio\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Aspect ratio of the generated images. Supported values are\\n      \\\"1:1\\\", \\\"2:3\\\", \\\"3:2\\\", \\\"3:4\\\", \\\"4:3\\\", \\\"9:16\\\", \\\"16:9\\\", and \\\"21:9\\\".\" , \"title\" : \"Aspectratio\" } }, \"title\" : \"ImageConfig\" , \"type\" : \"object\" }, \"Interval\" : { \"additionalProperties\" : false , \"description\" : \"Represents a time interval, encoded as a start time (inclusive) and an end time (exclusive).\\n\\nThe start time must be less than or equal to the end time.\\nWhen the start equals the end time, the interval is an empty interval.\\n(matches no time)\\nWhen both start and end are unspecified, the interval matches any time.\" , \"properties\" : { \"startTime\" : { \"anyOf\" : [ { \"format\" : \"date-time\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The start time of the interval.\" , \"title\" : \"Starttime\" }, \"endTime\" : { \"anyOf\" : [ { \"format\" : \"date-time\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The end time of the interval.\" , \"title\" : \"Endtime\" } }, \"title\" : \"Interval\" , \"type\" : \"object\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"LatLng\" : { \"additionalProperties\" : false , \"description\" : \"An object that represents a latitude/longitude pair.\\n\\nThis is expressed as a pair of doubles to represent degrees latitude and\\ndegrees longitude. Unless specified otherwise, this object must conform to the\\n<a href=\\\"https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version\\\">\\nWGS84 standard</a>. Values must be within normalized ranges.\" , \"properties\" : { \"latitude\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The latitude in degrees. It must be in the range [-90.0, +90.0].\" , \"title\" : \"Latitude\" }, \"longitude\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The longitude in degrees. It must be in the range [-180.0, +180.0]\" , \"title\" : \"Longitude\" } }, \"title\" : \"LatLng\" , \"type\" : \"object\" }, \"MediaResolution\" : { \"description\" : \"The media resolution to use.\" , \"enum\" : [ \"MEDIA_RESOLUTION_UNSPECIFIED\" , \"MEDIA_RESOLUTION_LOW\" , \"MEDIA_RESOLUTION_MEDIUM\" , \"MEDIA_RESOLUTION_HIGH\" ], \"title\" : \"MediaResolution\" , \"type\" : \"string\" }, \"ModelSelectionConfig\" : { \"additionalProperties\" : false , \"description\" : \"Config for model selection.\" , \"properties\" : { \"featureSelectionPreference\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FeatureSelectionPreference\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Options for feature selection preference.\" } }, \"title\" : \"ModelSelectionConfig\" , \"type\" : \"object\" }, \"MultiSpeakerVoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the multi-speaker setup.\" , \"properties\" : { \"speakerVoiceConfigs\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/SpeakerVoiceConfig\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the speaker to use.\" , \"title\" : \"Speakervoiceconfigs\" } }, \"title\" : \"MultiSpeakerVoiceConfig\" , \"type\" : \"object\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"PrebuiltVoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the prebuilt speaker to use.\" , \"properties\" : { \"voiceName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The name of the prebuilt voice to use.\" , \"title\" : \"Voicename\" } }, \"title\" : \"PrebuiltVoiceConfig\" , \"type\" : \"object\" }, \"RagRetrievalConfig\" : { \"additionalProperties\" : false , \"description\" : \"Specifies the context retrieval config.\" , \"properties\" : { \"filter\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagRetrievalConfigFilter\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Config for filters.\" }, \"hybridSearch\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagRetrievalConfigHybridSearch\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Config for Hybrid Search.\" }, \"ranking\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagRetrievalConfigRanking\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Config for ranking and reranking.\" }, \"topK\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The number of contexts to retrieve.\" , \"title\" : \"Topk\" } }, \"title\" : \"RagRetrievalConfig\" , \"type\" : \"object\" }, \"RagRetrievalConfigFilter\" : { \"additionalProperties\" : false , \"description\" : \"Config for filters.\" , \"properties\" : { \"metadataFilter\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. String for metadata filtering.\" , \"title\" : \"Metadatafilter\" }, \"vectorDistanceThreshold\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Only returns contexts with vector distance smaller than the threshold.\" , \"title\" : \"Vectordistancethreshold\" }, \"vectorSimilarityThreshold\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Only returns contexts with vector similarity larger than the threshold.\" , \"title\" : \"Vectorsimilaritythreshold\" } }, \"title\" : \"RagRetrievalConfigFilter\" , \"type\" : \"object\" }, \"RagRetrievalConfigHybridSearch\" : { \"additionalProperties\" : false , \"description\" : \"Config for Hybrid Search.\" , \"properties\" : { \"alpha\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.\" , \"title\" : \"Alpha\" } }, \"title\" : \"RagRetrievalConfigHybridSearch\" , \"type\" : \"object\" }, \"RagRetrievalConfigRanking\" : { \"additionalProperties\" : false , \"description\" : \"Config for ranking and reranking.\" , \"properties\" : { \"llmRanker\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagRetrievalConfigRankingLlmRanker\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Config for LlmRanker.\" }, \"rankService\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagRetrievalConfigRankingRankService\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Config for Rank Service.\" } }, \"title\" : \"RagRetrievalConfigRanking\" , \"type\" : \"object\" }, \"RagRetrievalConfigRankingLlmRanker\" : { \"additionalProperties\" : false , \"description\" : \"Config for LlmRanker.\" , \"properties\" : { \"modelName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The model name used for ranking. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models).\" , \"title\" : \"Modelname\" } }, \"title\" : \"RagRetrievalConfigRankingLlmRanker\" , \"type\" : \"object\" }, \"RagRetrievalConfigRankingRankService\" : { \"additionalProperties\" : false , \"description\" : \"Config for Rank Service.\" , \"properties\" : { \"modelName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`\" , \"title\" : \"Modelname\" } }, \"title\" : \"RagRetrievalConfigRankingRankService\" , \"type\" : \"object\" }, \"Retrieval\" : { \"additionalProperties\" : false , \"description\" : \"Defines a retrieval tool that model can call to access external knowledge.\" , \"properties\" : { \"disableAttribution\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Deprecated. This option is no longer supported.\" , \"title\" : \"Disableattribution\" }, \"externalApi\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExternalApi\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Use data source powered by external API for grounding.\" }, \"vertexAiSearch\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VertexAISearch\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Set to use data source powered by Vertex AI Search.\" }, \"vertexRagStore\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VertexRagStore\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService.\" } }, \"title\" : \"Retrieval\" , \"type\" : \"object\" }, \"RetrievalConfig\" : { \"additionalProperties\" : false , \"description\" : \"Retrieval config.\" , \"properties\" : { \"latLng\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/LatLng\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The location of the user.\" }, \"languageCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The language code of the user.\" , \"title\" : \"Languagecode\" } }, \"title\" : \"RetrievalConfig\" , \"type\" : \"object\" }, \"SafetySetting\" : { \"additionalProperties\" : false , \"description\" : \"Safety settings.\" , \"properties\" : { \"method\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HarmBlockMethod\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Determines if the harm block method uses probability or probability\\n      and severity scores.\" }, \"category\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HarmCategory\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Harm category.\" }, \"threshold\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HarmBlockThreshold\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The harm block threshold.\" } }, \"title\" : \"SafetySetting\" , \"type\" : \"object\" }, \"Schema\" : { \"additionalProperties\" : false , \"description\" : \"Schema is used to define the format of input/output data.\\n\\nRepresents a select subset of an [OpenAPI 3.0 schema\\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\\nbe added in the future as needed.\" , \"properties\" : { \"additionalProperties\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Can either be a boolean or an object; controls the presence of additional properties.\" , \"title\" : \"Additionalproperties\" }, \"defs\" : { \"anyOf\" : [ { \"additionalProperties\" : { \"$ref\" : \"#/$defs/Schema\" }, \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. A map of definitions for use by `ref` Only allowed at the root of the schema.\" , \"title\" : \"Defs\" }, \"ref\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Allows indirect references between schema nodes. The value should be a valid reference to a child of the root `defs`. For example, the following schema defines a reference to a schema node named \\\"Pet\\\": type: object properties: pet: ref: #/defs/Pet defs: Pet: type: object properties: name: type: string The value of the \\\"pet\\\" property is a reference to the schema node named \\\"Pet\\\". See details in https://json-schema.org/understanding-json-schema/structuring\" , \"title\" : \"Ref\" }, \"anyOf\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Schema\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The value should be validated against any (one or more) of the subschemas in the list.\" , \"title\" : \"Anyof\" }, \"default\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Default value of the data.\" , \"title\" : \"Default\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The description of the data.\" , \"title\" : \"Description\" }, \"enum\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\\\"EAST\\\", NORTH\\\", \\\"SOUTH\\\", \\\"WEST\\\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\\\"101\\\", \\\"201\\\", \\\"301\\\"]}\" , \"title\" : \"Enum\" }, \"example\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Example of the object. Will only populated when the object is the root.\" , \"title\" : \"Example\" }, \"format\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The format of the data. Supported formats: for NUMBER type: \\\"float\\\", \\\"double\\\" for INTEGER type: \\\"int32\\\", \\\"int64\\\" for STRING type: \\\"email\\\", \\\"byte\\\", etc\" , \"title\" : \"Format\" }, \"items\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Schema\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY.\" }, \"maxItems\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Maximum number of the elements for Type.ARRAY.\" , \"title\" : \"Maxitems\" }, \"maxLength\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Maximum length of the Type.STRING\" , \"title\" : \"Maxlength\" }, \"maxProperties\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Maximum number of the properties for Type.OBJECT.\" , \"title\" : \"Maxproperties\" }, \"maximum\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Maximum value of the Type.INTEGER and Type.NUMBER\" , \"title\" : \"Maximum\" }, \"minItems\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Minimum number of the elements for Type.ARRAY.\" , \"title\" : \"Minitems\" }, \"minLength\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING\" , \"title\" : \"Minlength\" }, \"minProperties\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Minimum number of the properties for Type.OBJECT.\" , \"title\" : \"Minproperties\" }, \"minimum\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER\" , \"title\" : \"Minimum\" }, \"nullable\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Indicates if the value may be null.\" , \"title\" : \"Nullable\" }, \"pattern\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Pattern of the Type.STRING to restrict a string to a regular expression.\" , \"title\" : \"Pattern\" }, \"properties\" : { \"anyOf\" : [ { \"additionalProperties\" : { \"$ref\" : \"#/$defs/Schema\" }, \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.\" , \"title\" : \"Properties\" }, \"propertyOrdering\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.\" , \"title\" : \"Propertyordering\" }, \"required\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Required properties of Type.OBJECT.\" , \"title\" : \"Required\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The title of the Schema.\" , \"title\" : \"Title\" }, \"type\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Type\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The type of the data.\" } }, \"title\" : \"Schema\" , \"type\" : \"object\" }, \"SpeakerVoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the speaker to use.\" , \"properties\" : { \"speaker\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The name of the speaker to use. Should be the same as in the\\n          prompt.\" , \"title\" : \"Speaker\" }, \"voiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the voice to use.\" } }, \"title\" : \"SpeakerVoiceConfig\" , \"type\" : \"object\" }, \"SpeechConfig\" : { \"additionalProperties\" : false , \"description\" : \"The speech generation configuration.\" , \"properties\" : { \"voiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the speaker to use.\\n      \" }, \"multiSpeakerVoiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/MultiSpeakerVoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the multi-speaker setup.\\n          It is mutually exclusive with the voice_config field.\\n          \" }, \"languageCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Language code (ISO 639. e.g. en-US) for the speech synthesization.\\n      Only available for Live API.\\n      \" , \"title\" : \"Languagecode\" } }, \"title\" : \"SpeechConfig\" , \"type\" : \"object\" }, \"ThinkingConfig\" : { \"additionalProperties\" : false , \"description\" : \"The thinking features configuration.\" , \"properties\" : { \"includeThoughts\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available.\\n      \" , \"title\" : \"Includethoughts\" }, \"thinkingBudget\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates the thinking budget in tokens. 0 is DISABLED. -1 is AUTOMATIC. The default values and allowed ranges are model dependent.\\n      \" , \"title\" : \"Thinkingbudget\" } }, \"title\" : \"ThinkingConfig\" , \"type\" : \"object\" }, \"ToolAnnotations\" : { \"additionalProperties\" : true , \"description\" : \"Additional properties describing a Tool to clients.\\n\\nNOTE: all properties in ToolAnnotations are **hints**.\\nThey are not guaranteed to provide a faithful description of\\ntool behavior (including descriptive properties like `title`).\\n\\nClients should never make tool use decisions based on ToolAnnotations\\nreceived from untrusted servers.\" , \"properties\" : { \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Title\" }, \"readOnlyHint\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Readonlyhint\" }, \"destructiveHint\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Destructivehint\" }, \"idempotentHint\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Idempotenthint\" }, \"openWorldHint\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Openworldhint\" } }, \"title\" : \"ToolAnnotations\" , \"type\" : \"object\" }, \"ToolCodeExecution\" : { \"additionalProperties\" : false , \"description\" : \"Tool that executes code generated by the model, and automatically returns the result to the model.\\n\\nSee also [ExecutableCode]and [CodeExecutionResult] which are input and output\\nto this tool.\" , \"properties\" : {}, \"title\" : \"ToolCodeExecution\" , \"type\" : \"object\" }, \"ToolConfig\" : { \"additionalProperties\" : false , \"description\" : \"Tool config.\\n\\nThis config is shared for all tools provided in the request.\" , \"properties\" : { \"functionCallingConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCallingConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Function calling config.\" }, \"retrievalConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RetrievalConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Retrieval config.\" } }, \"title\" : \"ToolConfig\" , \"type\" : \"object\" }, \"Type\" : { \"description\" : \"Optional. The type of the data.\" , \"enum\" : [ \"TYPE_UNSPECIFIED\" , \"STRING\" , \"NUMBER\" , \"INTEGER\" , \"BOOLEAN\" , \"ARRAY\" , \"OBJECT\" , \"NULL\" ], \"title\" : \"Type\" , \"type\" : \"string\" }, \"UrlContext\" : { \"additionalProperties\" : false , \"description\" : \"Tool to support URL context retrieval.\" , \"properties\" : {}, \"title\" : \"UrlContext\" , \"type\" : \"object\" }, \"VertexAISearch\" : { \"additionalProperties\" : false , \"description\" : \"Retrieve from Vertex AI Search datastore or engine for grounding.\\n\\ndatastore and engine are mutually exclusive. See\\nhttps://cloud.google.com/products/agent-builder\" , \"properties\" : { \"dataStoreSpecs\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/VertexAISearchDataStoreSpec\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifications that define the specific DataStores to be searched, along with configurations for those data stores. This is only considered for Engines with multiple data stores. It should only be set if engine is used.\" , \"title\" : \"Datastorespecs\" }, \"datastore\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`\" , \"title\" : \"Datastore\" }, \"engine\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`\" , \"title\" : \"Engine\" }, \"filter\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Filter strings to be passed to the search API.\" , \"title\" : \"Filter\" }, \"maxResults\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Number of search results to return per query. The default value is 10. The maximumm allowed value is 10.\" , \"title\" : \"Maxresults\" } }, \"title\" : \"VertexAISearch\" , \"type\" : \"object\" }, \"VertexAISearchDataStoreSpec\" : { \"additionalProperties\" : false , \"description\" : \"Define data stores within engine to filter on in a search call and configurations for those data stores.\\n\\nFor more information, see\\nhttps://cloud.google.com/generative-ai-app-builder/docs/reference/rpc/google.cloud.discoveryengine.v1#datastorespec\" , \"properties\" : { \"dataStore\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Full resource name of DataStore, such as Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`\" , \"title\" : \"Datastore\" }, \"filter\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Filter specification to filter documents in the data store specified by data_store field. For more information on filtering, see [Filtering](https://cloud.google.com/generative-ai-app-builder/docs/filter-search-metadata)\" , \"title\" : \"Filter\" } }, \"title\" : \"VertexAISearchDataStoreSpec\" , \"type\" : \"object\" }, \"VertexRagStore\" : { \"additionalProperties\" : false , \"description\" : \"Retrieve from Vertex RAG Store for grounding.\" , \"properties\" : { \"ragCorpora\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Deprecated. Please use rag_resources instead.\" , \"title\" : \"Ragcorpora\" }, \"ragResources\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/VertexRagStoreRagResource\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.\" , \"title\" : \"Ragresources\" }, \"ragRetrievalConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagRetrievalConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The retrieval config for the Rag query.\" }, \"similarityTopK\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Number of top k results to return from the selected corpora.\" , \"title\" : \"Similaritytopk\" }, \"storeContext\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Currently only supported for Gemini Multimodal Live API. In Gemini Multimodal Live API, if `store_context` bool is specified, Gemini will leverage it to automatically memorize the interactions between the client and Gemini, and retrieve context when needed to augment the response generation for users' ongoing and future interactions.\" , \"title\" : \"Storecontext\" }, \"vectorDistanceThreshold\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Only return results with vector distance smaller than the threshold.\" , \"title\" : \"Vectordistancethreshold\" } }, \"title\" : \"VertexRagStore\" , \"type\" : \"object\" }, \"VertexRagStoreRagResource\" : { \"additionalProperties\" : false , \"description\" : \"The definition of the Rag resource.\" , \"properties\" : { \"ragCorpus\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`\" , \"title\" : \"Ragcorpus\" }, \"ragFileIds\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.\" , \"title\" : \"Ragfileids\" } }, \"title\" : \"VertexRagStoreRagResource\" , \"type\" : \"object\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" }, \"VoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the voice to use.\" , \"properties\" : { \"prebuiltVoiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/PrebuiltVoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the speaker to use.\\n      \" } }, \"title\" : \"VoiceConfig\" , \"type\" : \"object\" }, \"google__genai__types__Tool\" : { \"additionalProperties\" : false , \"description\" : \"Tool details of a tool that the model may use to generate a response.\" , \"properties\" : { \"functionDeclarations\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionDeclaration\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of function declarations that the tool supports.\" , \"title\" : \"Functiondeclarations\" }, \"retrieval\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Retrieval\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation.\" }, \"googleSearch\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GoogleSearch\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Google Search tool type. Specialized retrieval tool\\n      that is powered by Google Search.\" }, \"googleSearchRetrieval\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GoogleSearchRetrieval\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search.\" }, \"enterpriseWebSearch\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/EnterpriseWebSearch\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Enterprise web search tool type. Specialized retrieval\\n      tool that is powered by Vertex AI Search and Sec4 compliance.\" }, \"googleMaps\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GoogleMaps\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Google Maps tool type. Specialized retrieval tool\\n      that is powered by Google Maps.\" }, \"urlContext\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/UrlContext\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Tool to support URL context retrieval.\" }, \"computerUse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ComputerUse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Tool to support the model interacting directly with the\\n      computer. If enabled, it automatically populates computer-use specific\\n      Function Declarations.\" }, \"codeExecution\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ToolCodeExecution\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. CodeExecution tool type. Enables the model to execute code as part of generation.\" } }, \"title\" : \"Tool\" , \"type\" : \"object\" }, \"mcp__types__Tool\" : { \"additionalProperties\" : true , \"description\" : \"Definition for a tool the client can call.\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"inputSchema\" : { \"additionalProperties\" : true , \"title\" : \"Inputschema\" , \"type\" : \"object\" }, \"annotations\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ToolAnnotations\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"required\" : [ \"name\" , \"inputSchema\" ], \"title\" : \"Tool\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"name\" ] } Fields : after_model_callback (Optional[AfterModelCallback]) after_tool_callback (Optional[AfterToolCallback]) before_model_callback (Optional[BeforeModelCallback]) before_tool_callback (Optional[BeforeToolCallback]) code_executor (Optional[BaseCodeExecutor]) disallow_transfer_to_parent (bool) disallow_transfer_to_peers (bool) generate_content_config (Optional[types.GenerateContentConfig]) global_instruction (Union[str, InstructionProvider]) include_contents (Literal['default', 'none']) input_schema (Optional[type[BaseModel]]) instruction (Union[str, InstructionProvider]) model (Union[str, BaseLlm]) output_key (Optional[str]) output_schema (Optional[type[BaseModel]]) planner (Optional[BasePlanner]) static_instruction (Optional[types.ContentUnion]) tools (list[ToolUnion]) Validators : __model_validator_after \u00bb all fields validate_generate_content_config \u00bb generate_content_config field after_model_callback : Optional[AfterModelCallback] = None \u00b6 Callback or list of callbacks to be called after calling the LLM. When a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None. Parameters : callback_context \u2013 CallbackContext, llm_response \u2013 LlmResponse, the actual model response. Returns : The content to return to the user. When present, the actual model response\nwill be ignored and the provided content will be returned to user. Validated by : __model_validator_after field after_tool_callback : Optional[AfterToolCallback] = None \u00b6 Callback or list of callbacks to be called after calling the tool. When a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None. Parameters : tool \u2013 The tool to be called. args \u2013 The arguments to the tool. tool_context \u2013 ToolContext, tool_response \u2013 The response from the tool. Returns : When present, the returned dict will be used as tool result. Validated by : __model_validator_after field before_model_callback : Optional[BeforeModelCallback] = None \u00b6 Callback or list of callbacks to be called before calling the LLM. When a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None. Parameters : callback_context \u2013 CallbackContext, llm_request \u2013 LlmRequest, The raw model request. Callback can mutate the request. Returns : The content to return to the user. When present, the model call will be\nskipped and the provided content will be returned to user. Validated by : __model_validator_after field before_tool_callback : Optional[BeforeToolCallback] = None \u00b6 Callback or list of callbacks to be called before calling the tool. When a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None. Parameters : tool \u2013 The tool to be called. args \u2013 The arguments to the tool. tool_context \u2013 ToolContext, Returns : The tool response. When present, the returned tool response will be used and\nthe framework will skip calling the actual tool. Validated by : __model_validator_after field code_executor : Optional[BaseCodeExecutor] = None \u00b6 Allow agent to execute code blocks from model responses using the provided\nCodeExecutor. Check out available code executions in google.adk.code_executor package. Note To use model\u2019s built-in code executor, use the BuiltInCodeExecutor . Validated by : __model_validator_after field disallow_transfer_to_parent : bool = False \u00b6 Disallows LLM-controlled transferring to the parent agent. NOTE: Setting this as True also prevents this agent to continue reply to the\nend-user. This behavior prevents one-way transfer, in which end-user may be\nstuck with one agent that cannot transfer to other agents in the agent tree. Validated by : __model_validator_after field disallow_transfer_to_peers : bool = False \u00b6 Disallows LLM-controlled transferring to the peer agents. Validated by : __model_validator_after field generate_content_config : Optional[types.GenerateContentConfig] = None \u00b6 The additional content generation configurations. NOTE: not all fields are usable, e.g. tools must be configured via tools ,\nthinking_config must be configured via planner in LlmAgent. For example: use this config to adjust model temperature, configure safety\nsettings, etc. Validated by : __model_validator_after validate_generate_content_config field global_instruction : Union[str, InstructionProvider] = '' \u00b6 Instructions for all the agents in the entire agent tree. DEPRECATED: This field is deprecated and will be removed in a future version.\nUse GlobalInstructionPlugin instead, which provides the same functionality\nat the App level. See migration guide for details. ONLY the global_instruction in root agent will take effect. For example: use global_instruction to make all agents have a stable identity\nor personality. Validated by : __model_validator_after field include_contents : Literal['default', 'none'] = 'default' \u00b6 Controls content inclusion in model requests. Options: default: Model receives relevant conversation history\nnone: Model receives no prior history, operates solely on current\ninstruction and input Validated by : __model_validator_after field input_schema : Optional[type[BaseModel]] = None \u00b6 The input schema when agent is used as a tool. Validated by : __model_validator_after field instruction : Union[str, InstructionProvider] = '' \u00b6 Dynamic instructions for the LLM model, guiding the agent\u2019s behavior. These instructions can contain placeholders like {variable_name} that will be\nresolved at runtime using session state and context. Behavior depends on static_instruction: - If static_instruction is None: instruction goes to system_instruction\n- If static_instruction is set: instruction goes to user content in the request This allows for context caching optimization where static content (static_instruction)\ncomes first in the prompt, followed by dynamic content (instruction). Validated by : __model_validator_after field model : Union[str, BaseLlm] = '' \u00b6 The model to use for the agent. When not set, the agent will inherit the model from its ancestor. Validated by : __model_validator_after field output_key : Optional[str] = None \u00b6 The key in session state to store the output of the agent. Typically use cases:\n- Extracts agent reply for later use, such as in tools, callbacks, etc.\n- Connects agents to coordinate with each other. Validated by : __model_validator_after field output_schema : Optional[type[BaseModel]] = None \u00b6 The output schema when agent replies. Note When this is set, agent can ONLY reply and CANNOT use any tools, such as\nfunction tools, RAGs, agent transfer, etc. Validated by : __model_validator_after field planner : Optional[BasePlanner] = None \u00b6 Instructs the agent to make a plan and execute it step by step. Note To use model\u2019s built-in thinking features, set the thinking_config field in google.adk.planners.built_in_planner . Validated by : __model_validator_after field static_instruction : Optional[types.ContentUnion] = None \u00b6 Static instruction content sent literally as system instruction at the beginning. This field is for content that never changes and doesn\u2019t contain placeholders.\nIt\u2019s sent directly to the model without any processing or variable substitution. This field is primarily for context caching optimization. Static instructions\nare sent as system instruction at the beginning of the request, allowing\nfor improved performance when the static portion remains unchanged. Live API\nhas its own cache mechanism, thus this field doesn\u2019t work with Live API. Impact on instruction field: - When static_instruction is None: instruction \u2192 system_instruction\n- When static_instruction is set: instruction \u2192 user content (after static content) Context Caching: - Implicit Cache : Automatic caching by model providers (no config needed)\n- Explicit Cache : Cache explicitly created by user for instructions, tools and contents See below for more information of Implicit Cache and Explicit Cache\nGemini API: https://ai.google.dev/gemini-api/docs/caching?lang=python Vertex API: https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview Setting static_instruction alone does NOT enable caching automatically.\nFor explicit caching control, configure context_cache_config at App level. Content Support: Accepts types.ContentUnion which includes:\n- str: Simple text instruction\n- types.Content: Rich content object\n- types.Part: Single part (text, inline_data, file_data, etc.)\n- PIL.Image.Image: Image object\n- types.File: File reference\n- list[PartUnion]: List of parts Examples: `` ` python\n# Simple string instruction\nstatic_instruction = \u201cYou are a helpful assistant.\u201d # Rich content with files\nstatic_instruction = types.Content( role=\u2019user\u2019,\nparts=[ types.Part(text=\u2019You are a helpful assistant.\u2019),\ntypes.Part(file_data=types.FileData(\u2026)) ] ", "code_blocks": []}, {"heading_path": [")\u00b6"], "text": ") \u00b6 Validated by : __model_validator_after field tools : list[ToolUnion] [Optional] \u00b6 Tools available to this agent. Validated by : __model_validator_after config_type \u00b6 alias of LlmAgentConfig validator validate_generate_content_config \u00bb generate_content_config \u00b6 Return type : GenerateContentConfig async canonical_global_instruction ( ctx ) \u00b6 The resolved self.instruction field to construct global instruction. This method is only for use by Agent Development Kit. Return type : tuple [ str , bool ] Parameters : ctx \u2013 The context to retrieve the session state. Returns : A tuple of (instruction, bypass_state_injection).\ninstruction: The resolved self.global_instruction field.\nbypass_state_injection: Whether the instruction is based on\nInstructionProvider. async canonical_instruction ( ctx ) \u00b6 The resolved self.instruction field to construct instruction for this agent. This method is only for use by Agent Development Kit. Return type : tuple [ str , bool ] Parameters : ctx \u2013 The context to retrieve the session state. Returns : A tuple of (instruction, bypass_state_injection).\ninstruction: The resolved self.instruction field.\nbypass_state_injection: Whether the instruction is based on\nInstructionProvider. async canonical_tools ( ctx = None ) \u00b6 The resolved self.tools field as a list of BaseTool based on the context. This method is only for use by Agent Development Kit. Return type : list [ BaseTool ] property canonical_after_model_callbacks : list [ Callable [ [ CallbackContext , LlmResponse ] , Awaitable [ LlmResponse | None ] | LlmResponse | None ] ] \u00b6 The resolved self.after_model_callback field as a list of _SingleAfterModelCallback. This method is only for use by Agent Development Kit. property canonical_after_tool_callbacks : list [ Callable [ [ BaseTool , dict [ str , Any ] , ToolContext , dict ] , Awaitable [ dict | None ] | dict | None ] | list [ Callable [ [ BaseTool , dict [ str , Any ] , ToolContext , dict ] , Awaitable [ dict | None ] | dict | None ] ] ] \u00b6 The resolved self.after_tool_callback field as a list of AfterToolCallback. This method is only for use by Agent Development Kit. property canonical_before_model_callbacks : list [ Callable [ [ CallbackContext , LlmRequest ] , Awaitable [ LlmResponse | None ] | LlmResponse | None ] ] \u00b6 The resolved self.before_model_callback field as a list of _SingleBeforeModelCallback. This method is only for use by Agent Development Kit. property canonical_before_tool_callbacks : list [ Callable [ [ BaseTool , dict [ str , Any ] , ToolContext ] , Awaitable [ dict | None ] | dict | None ] | list [ Callable [ [ BaseTool , dict [ str , Any ] , ToolContext ] , Awaitable [ dict | None ] | dict | None ] ] ] \u00b6 The resolved self.before_tool_callback field as a list of BeforeToolCallback. This method is only for use by Agent Development Kit. property canonical_model : BaseLlm \u00b6 The resolved self.model field as BaseLlm. This method is only for use by Agent Development Kit. pydantic model google.adk.agents. LoopAgent \u00b6 Bases: BaseAgent A shell agent that run its sub-agents in a loop. When sub-agent generates an event with escalate or max_iterations are\nreached, the loop agent will stop. Show JSON schema { \"title\" : \"LoopAgent\" , \"description\" : \"A shell agent that run its sub-agents in a loop.\\n\\nWhen sub-agent generates an event with escalate or max_iterations are\\nreached, the loop agent will stop.\" , \"type\" : \"object\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" }, \"max_iterations\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Max Iterations\" } }, \"$defs\" : { \"BaseAgent\" : { \"additionalProperties\" : false , \"description\" : \"Base class for all agents in Agent Development Kit.\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" } }, \"required\" : [ \"name\" ], \"title\" : \"BaseAgent\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"name\" ] } Fields : max_iterations (Optional[int]) Validators : field max_iterations : Optional[int] = None \u00b6 The maximum number of iterations to run the loop agent. If not set, the loop agent will run indefinitely until a sub-agent\nescalates. config_type \u00b6 alias of LoopAgentConfig pydantic model google.adk.agents. ParallelAgent \u00b6 Bases: BaseAgent A shell agent that run its sub-agents in parallel in isolated manner. This approach is beneficial for scenarios requiring multiple perspectives or\nattempts on a single task, such as: Running different algorithms simultaneously. Generating multiple responses for review by a subsequent evaluation agent. Show JSON schema { \"title\" : \"ParallelAgent\" , \"description\" : \"A shell agent that run its sub-agents in parallel in isolated manner.\\n\\nThis approach is beneficial for scenarios requiring multiple perspectives or\\nattempts on a single task, such as:\\n\\n- Running different algorithms simultaneously.\\n- Generating multiple responses for review by a subsequent evaluation agent.\" , \"type\" : \"object\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" } }, \"$defs\" : { \"BaseAgent\" : { \"additionalProperties\" : false , \"description\" : \"Base class for all agents in Agent Development Kit.\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" } }, \"required\" : [ \"name\" ], \"title\" : \"BaseAgent\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"name\" ] } Fields : Validators : config_type \u00b6 alias of ParallelAgentConfig pydantic model google.adk.agents. RunConfig \u00b6 Bases: BaseModel Configs for runtime behavior of agents. Show JSON schema { \"title\" : \"RunConfig\" , \"description\" : \"Configs for runtime behavior of agents.\" , \"type\" : \"object\" , \"properties\" : { \"speech_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/SpeechConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"response_modalities\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Response Modalities\" }, \"save_input_blobs_as_artifacts\" : { \"default\" : false , \"deprecated\" : true , \"description\" : \"Whether or not to save the input blobs as artifacts. DEPRECATED: Use SaveFilesAsArtifactsPlugin instead for better control and flexibility. See google.adk.plugins.SaveFilesAsArtifactsPlugin.\" , \"title\" : \"Save Input Blobs As Artifacts\" , \"type\" : \"boolean\" }, \"support_cfc\" : { \"default\" : false , \"title\" : \"Support Cfc\" , \"type\" : \"boolean\" }, \"streaming_mode\" : { \"$ref\" : \"#/$defs/StreamingMode\" , \"default\" : null }, \"output_audio_transcription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AudioTranscriptionConfig\" }, { \"type\" : \"null\" } ] }, \"input_audio_transcription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AudioTranscriptionConfig\" }, { \"type\" : \"null\" } ] }, \"realtime_input_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RealtimeInputConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"enable_affective_dialog\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Enable Affective Dialog\" }, \"proactivity\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ProactivityConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"session_resumption\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/SessionResumptionConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"context_window_compression\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ContextWindowCompressionConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"save_live_audio\" : { \"default\" : false , \"title\" : \"Save Live Audio\" , \"type\" : \"boolean\" }, \"max_llm_calls\" : { \"default\" : 500 , \"title\" : \"Max Llm Calls\" , \"type\" : \"integer\" } }, \"$defs\" : { \"ActivityHandling\" : { \"description\" : \"The different ways of handling user activity.\" , \"enum\" : [ \"ACTIVITY_HANDLING_UNSPECIFIED\" , \"START_OF_ACTIVITY_INTERRUPTS\" , \"NO_INTERRUPTION\" ], \"title\" : \"ActivityHandling\" , \"type\" : \"string\" }, \"AudioTranscriptionConfig\" : { \"additionalProperties\" : false , \"description\" : \"The audio transcription configuration in Setup.\" , \"properties\" : {}, \"title\" : \"AudioTranscriptionConfig\" , \"type\" : \"object\" }, \"AutomaticActivityDetection\" : { \"additionalProperties\" : false , \"description\" : \"Configures automatic detection of activity.\" , \"properties\" : { \"disabled\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals.\" , \"title\" : \"Disabled\" }, \"startOfSpeechSensitivity\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/StartSensitivity\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Determines how likely speech is to be detected.\" }, \"endOfSpeechSensitivity\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/EndSensitivity\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Determines how likely detected speech is ended.\" }, \"prefixPaddingMs\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives.\" , \"title\" : \"Prefixpaddingms\" }, \"silenceDurationMs\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user's activity but this will increase the model's latency.\" , \"title\" : \"Silencedurationms\" } }, \"title\" : \"AutomaticActivityDetection\" , \"type\" : \"object\" }, \"ContextWindowCompressionConfig\" : { \"additionalProperties\" : false , \"description\" : \"Enables context window compression -- mechanism managing model context window so it does not exceed given length.\" , \"properties\" : { \"triggerTokens\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens (before running turn) that triggers context window compression mechanism.\" , \"title\" : \"Triggertokens\" }, \"slidingWindow\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/SlidingWindow\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Sliding window compression mechanism.\" } }, \"title\" : \"ContextWindowCompressionConfig\" , \"type\" : \"object\" }, \"EndSensitivity\" : { \"description\" : \"End of speech sensitivity.\" , \"enum\" : [ \"END_SENSITIVITY_UNSPECIFIED\" , \"END_SENSITIVITY_HIGH\" , \"END_SENSITIVITY_LOW\" ], \"title\" : \"EndSensitivity\" , \"type\" : \"string\" }, \"MultiSpeakerVoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the multi-speaker setup.\" , \"properties\" : { \"speakerVoiceConfigs\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/SpeakerVoiceConfig\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the speaker to use.\" , \"title\" : \"Speakervoiceconfigs\" } }, \"title\" : \"MultiSpeakerVoiceConfig\" , \"type\" : \"object\" }, \"PrebuiltVoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the prebuilt speaker to use.\" , \"properties\" : { \"voiceName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The name of the prebuilt voice to use.\" , \"title\" : \"Voicename\" } }, \"title\" : \"PrebuiltVoiceConfig\" , \"type\" : \"object\" }, \"ProactivityConfig\" : { \"additionalProperties\" : false , \"description\" : \"Config for proactivity features.\" , \"properties\" : { \"proactiveAudio\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If enabled, the model can reject responding to the last prompt. For\\n        example, this allows the model to ignore out of context speech or to stay\\n        silent if the user did not make a request, yet.\" , \"title\" : \"Proactiveaudio\" } }, \"title\" : \"ProactivityConfig\" , \"type\" : \"object\" }, \"RealtimeInputConfig\" : { \"additionalProperties\" : false , \"description\" : \"Marks the end of user activity.\\n\\nThis can only be sent if automatic (i.e. server-side) activity detection is\\ndisabled.\" , \"properties\" : { \"automaticActivityDetection\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AutomaticActivityDetection\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals.\" }, \"activityHandling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ActivityHandling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Defines what effect activity has.\" }, \"turnCoverage\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/TurnCoverage\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Defines which input is included in the user's turn.\" } }, \"title\" : \"RealtimeInputConfig\" , \"type\" : \"object\" }, \"SessionResumptionConfig\" : { \"additionalProperties\" : false , \"description\" : \"Configuration of session resumption mechanism.\\n\\nIncluded in `LiveConnectConfig.session_resumption`. If included server\\nwill send `LiveServerSessionResumptionUpdate` messages.\" , \"properties\" : { \"handle\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Session resumption handle of previous session (session to restore).\\n\\nIf not present new session will be started.\" , \"title\" : \"Handle\" }, \"transparent\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If set the server will send `last_consumed_client_message_index` in the `session_resumption_update` messages to allow for transparent reconnections.\" , \"title\" : \"Transparent\" } }, \"title\" : \"SessionResumptionConfig\" , \"type\" : \"object\" }, \"SlidingWindow\" : { \"additionalProperties\" : false , \"description\" : \"Context window will be truncated by keeping only suffix of it.\\n\\nContext window will always be cut at start of USER role turn. System\\ninstructions and `BidiGenerateContentSetup.prefix_turns` will not be\\nsubject to the sliding window mechanism, they will always stay at the\\nbeginning of context window.\" , \"properties\" : { \"targetTokens\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed.\" , \"title\" : \"Targettokens\" } }, \"title\" : \"SlidingWindow\" , \"type\" : \"object\" }, \"SpeakerVoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the speaker to use.\" , \"properties\" : { \"speaker\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The name of the speaker to use. Should be the same as in the\\n          prompt.\" , \"title\" : \"Speaker\" }, \"voiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the voice to use.\" } }, \"title\" : \"SpeakerVoiceConfig\" , \"type\" : \"object\" }, \"SpeechConfig\" : { \"additionalProperties\" : false , \"description\" : \"The speech generation configuration.\" , \"properties\" : { \"voiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the speaker to use.\\n      \" }, \"multiSpeakerVoiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/MultiSpeakerVoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the multi-speaker setup.\\n          It is mutually exclusive with the voice_config field.\\n          \" }, \"languageCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Language code (ISO 639. e.g. en-US) for the speech synthesization.\\n      Only available for Live API.\\n      \" , \"title\" : \"Languagecode\" } }, \"title\" : \"SpeechConfig\" , \"type\" : \"object\" }, \"StartSensitivity\" : { \"description\" : \"Start of speech sensitivity.\" , \"enum\" : [ \"START_SENSITIVITY_UNSPECIFIED\" , \"START_SENSITIVITY_HIGH\" , \"START_SENSITIVITY_LOW\" ], \"title\" : \"StartSensitivity\" , \"type\" : \"string\" }, \"StreamingMode\" : { \"enum\" : [ null , \"sse\" , \"bidi\" ], \"title\" : \"StreamingMode\" }, \"TurnCoverage\" : { \"description\" : \"Options about which input is included in the user's turn.\" , \"enum\" : [ \"TURN_COVERAGE_UNSPECIFIED\" , \"TURN_INCLUDES_ONLY_ACTIVITY\" , \"TURN_INCLUDES_ALL_INPUT\" ], \"title\" : \"TurnCoverage\" , \"type\" : \"string\" }, \"VoiceConfig\" : { \"additionalProperties\" : false , \"description\" : \"The configuration for the voice to use.\" , \"properties\" : { \"prebuiltVoiceConfig\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/PrebuiltVoiceConfig\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The configuration for the speaker to use.\\n      \" } }, \"title\" : \"VoiceConfig\" , \"type\" : \"object\" } }, \"additionalProperties\" : false } Fields : context_window_compression (google.genai.types.ContextWindowCompressionConfig | None) enable_affective_dialog (bool | None) input_audio_transcription (google.genai.types.AudioTranscriptionConfig | None) max_llm_calls (int) output_audio_transcription (google.genai.types.AudioTranscriptionConfig | None) proactivity (google.genai.types.ProactivityConfig | None) realtime_input_config (google.genai.types.RealtimeInputConfig | None) response_modalities (list[str] | None) save_input_blobs_as_artifacts (bool) save_live_audio (bool) session_resumption (google.genai.types.SessionResumptionConfig | None) speech_config (google.genai.types.SpeechConfig | None) streaming_mode (google.adk.agents.run_config.StreamingMode) support_cfc (bool) Validators : validate_max_llm_calls \u00bb max_llm_calls field context_window_compression : Optional[types.ContextWindowCompressionConfig] = None \u00b6 Configuration for context window compression. If set, this will enable context window compression for LLM input. field enable_affective_dialog : Optional[bool] = None \u00b6 If enabled, the model will detect emotions and adapt its responses accordingly. field input_audio_transcription : Optional[types.AudioTranscriptionConfig] [Optional] \u00b6 Input transcription for live agents with audio input from user. field max_llm_calls : int = 500 \u00b6 A limit on the total number of llm calls for a given run. Valid Values: More than 0 and less than sys.maxsize: The bound on the number of llm\ncalls is enforced, if the value is set in this range. Less than or equal to 0: This allows for unbounded number of llm calls. Validated by : validate_max_llm_calls field output_audio_transcription : Optional[types.AudioTranscriptionConfig] [Optional] \u00b6 Output transcription for live agents with audio response. field proactivity : Optional[types.ProactivityConfig] = None \u00b6 Configures the proactivity of the model. This allows the model to respond proactively to the input and to ignore irrelevant input. field realtime_input_config : Optional[types.RealtimeInputConfig] = None \u00b6 Realtime input config for live agents with audio input from user. field response_modalities : Optional[list[str]] = None \u00b6 The output modalities. If not set, it\u2019s default to AUDIO. field save_live_audio : bool = False \u00b6 Saves live video and audio data to session and artifact service. Right now, only audio is supported. field session_resumption : Optional[types.SessionResumptionConfig] = None \u00b6 Configures session resumption mechanism. Only support transparent session resumption mode now. field speech_config : Optional[types.SpeechConfig] = None \u00b6 Speech configuration for the live agent. field streaming_mode : StreamingMode = StreamingMode.NONE \u00b6 Streaming mode, None or StreamingMode.SSE or StreamingMode.BIDI. field support_cfc : bool = False \u00b6 Whether to support CFC (Compositional Function Calling). Only applicable for\nStreamingMode.SSE. If it\u2019s true. the LIVE API will be invoked. Since only LIVE\nAPI supports CFC Warning This feature is experimental and its API or behavior may change\nin future releases. validator validate_max_llm_calls \u00bb max_llm_calls \u00b6 Return type : int save_input_blobs_as_artifacts : bool \u00b6 Read-only data descriptor used to emit a runtime deprecation warning before accessing a deprecated field. msg \u00b6 The deprecation message to be emitted. wrapped_property \u00b6 The property instance if the deprecated field is a computed field, or None . field_name \u00b6 The name of the field being deprecated. pydantic model google.adk.agents. SequentialAgent \u00b6 Bases: BaseAgent A shell agent that runs its sub-agents in sequence. Show JSON schema { \"title\" : \"SequentialAgent\" , \"description\" : \"A shell agent that runs its sub-agents in sequence.\" , \"type\" : \"object\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" } }, \"$defs\" : { \"BaseAgent\" : { \"additionalProperties\" : false , \"description\" : \"Base class for all agents in Agent Development Kit.\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" } }, \"required\" : [ \"name\" ], \"title\" : \"BaseAgent\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"name\" ] } Fields : Validators : config_type \u00b6 alias of SequentialAgentConfig ", "code_blocks": []}, {"heading_path": ["google.adk.artifacts module\u00b6"], "text": "google.adk.artifacts module \u00b6 class google.adk.artifacts. BaseArtifactService \u00b6 Bases: ABC Abstract base class for artifact services. abstractmethod async delete_artifact ( * , app_name , user_id , filename , session_id = None ) \u00b6 Deletes an artifact. Return type : None Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , delete the user-scoped\nartifact. abstractmethod async get_artifact_version ( * , app_name , user_id , filename , session_id = None , version = None ) \u00b6 Gets the metadata for a specific version of an artifact. Return type : Optional [ ArtifactVersion ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , the artifact will be fetched\nfrom the user-scoped artifacts. Otherwise, it will be fetched from the\nspecified session. version \u2013 The version number of the artifact to retrieve. If None , the\nlatest version will be returned. Returns : An ArtifactVersion object containing the metadata of the specified\nartifact version, or None if the artifact version is not found. abstractmethod async list_artifact_keys ( * , app_name , user_id , session_id = None ) \u00b6 Lists all the artifact filenames within a session. Return type : list [ str ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. session_id \u2013 The ID of the session. Returns : A list of artifact filenames. If session_id is provided, returns\nboth session-scoped and user-scoped artifact filenames. If session_id is None , returns\nuser-scoped artifact filenames. abstractmethod async list_artifact_versions ( * , app_name , user_id , filename , session_id = None ) \u00b6 Lists all versions and their metadata for a specific artifact. Return type : list [ ArtifactVersion ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , lists versions of the\nuser-scoped artifact. Otherwise, lists versions of the artifact within\nthe specified session. Returns : A list of ArtifactVersion objects, each representing a version of the\nartifact and its associated metadata. abstractmethod async list_versions ( * , app_name , user_id , filename , session_id = None ) \u00b6 Lists all versions of an artifact. Return type : list [ int ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , only list the user-scoped\nartifacts versions. Returns : A list of all available versions of the artifact. abstractmethod async load_artifact ( * , app_name , user_id , filename , session_id = None , version = None ) \u00b6 Gets an artifact from the artifact service storage. The artifact is a file identified by the app name, user ID, session ID, and\nfilename. Return type : Optional [ Part ] Parameters : app_name \u2013 The app name. user_id \u2013 The user ID. filename \u2013 The filename of the artifact. session_id \u2013 The session ID. If None , load the user-scoped artifact. version \u2013 The version of the artifact. If None, the latest version will be\nreturned. Returns : The artifact or None if not found. abstractmethod async save_artifact ( * , app_name , user_id , filename , artifact , session_id = None , custom_metadata = None ) \u00b6 Saves an artifact to the artifact service storage. The artifact is a file identified by the app name, user ID, session ID, and\nfilename. After saving the artifact, a revision ID is returned to identify\nthe artifact version. Return type : int Parameters : app_name \u2013 The app name. user_id \u2013 The user ID. filename \u2013 The filename of the artifact. artifact \u2013 The artifact to save. If the artifact consists of file_data ,\nthe artifact service assumes its content has been uploaded separately,\nand this method will associate the file_data with the artifact if\nnecessary. session_id \u2013 The session ID. If None , the artifact is user-scoped. custom_metadata \u2013 custom metadata to associate with the artifact. Returns : The revision ID. The first version of the artifact has a revision ID of 0.\nThis is incremented by 1 after each successful save. class google.adk.artifacts. GcsArtifactService ( bucket_name , ** kwargs ) \u00b6 Bases: BaseArtifactService An artifact service implementation using Google Cloud Storage (GCS). Initializes the GcsArtifactService. Parameters : bucket_name \u2013 The name of the bucket to use. **kwargs \u2013 Keyword arguments to pass to the Google Cloud Storage client. async delete_artifact ( * , app_name , user_id , filename , session_id = None ) \u00b6 Deletes an artifact. Return type : None Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , delete the user-scoped\nartifact. async get_artifact_version ( * , app_name , user_id , filename , session_id = None , version = None ) \u00b6 Gets the metadata for a specific version of an artifact. Return type : Optional [ ArtifactVersion ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , the artifact will be fetched\nfrom the user-scoped artifacts. Otherwise, it will be fetched from the\nspecified session. version \u2013 The version number of the artifact to retrieve. If None , the\nlatest version will be returned. Returns : An ArtifactVersion object containing the metadata of the specified\nartifact version, or None if the artifact version is not found. async list_artifact_keys ( * , app_name , user_id , session_id = None ) \u00b6 Lists all the artifact filenames within a session. Return type : list [ str ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. session_id \u2013 The ID of the session. Returns : A list of artifact filenames. If session_id is provided, returns\nboth session-scoped and user-scoped artifact filenames. If session_id is None , returns\nuser-scoped artifact filenames. async list_artifact_versions ( * , app_name , user_id , filename , session_id = None ) \u00b6 Lists all versions and their metadata for a specific artifact. Return type : list [ ArtifactVersion ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , lists versions of the\nuser-scoped artifact. Otherwise, lists versions of the artifact within\nthe specified session. Returns : A list of ArtifactVersion objects, each representing a version of the\nartifact and its associated metadata. async list_versions ( * , app_name , user_id , filename , session_id = None ) \u00b6 Lists all versions of an artifact. Return type : list [ int ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , only list the user-scoped\nartifacts versions. Returns : A list of all available versions of the artifact. async load_artifact ( * , app_name , user_id , filename , session_id = None , version = None ) \u00b6 Gets an artifact from the artifact service storage. The artifact is a file identified by the app name, user ID, session ID, and\nfilename. Return type : Optional [ Part ] Parameters : app_name \u2013 The app name. user_id \u2013 The user ID. filename \u2013 The filename of the artifact. session_id \u2013 The session ID. If None , load the user-scoped artifact. version \u2013 The version of the artifact. If None, the latest version will be\nreturned. Returns : The artifact or None if not found. async save_artifact ( * , app_name , user_id , filename , artifact , session_id = None , custom_metadata = None ) \u00b6 Saves an artifact to the artifact service storage. The artifact is a file identified by the app name, user ID, session ID, and\nfilename. After saving the artifact, a revision ID is returned to identify\nthe artifact version. Return type : int Parameters : app_name \u2013 The app name. user_id \u2013 The user ID. filename \u2013 The filename of the artifact. artifact \u2013 The artifact to save. If the artifact consists of file_data ,\nthe artifact service assumes its content has been uploaded separately,\nand this method will associate the file_data with the artifact if\nnecessary. session_id \u2013 The session ID. If None , the artifact is user-scoped. custom_metadata \u2013 custom metadata to associate with the artifact. Returns : The revision ID. The first version of the artifact has a revision ID of 0.\nThis is incremented by 1 after each successful save. pydantic model google.adk.artifacts. InMemoryArtifactService \u00b6 Bases: BaseArtifactService , BaseModel An in-memory implementation of the artifact service. It is not suitable for multi-threaded production environments. Use it for\ntesting and development only. Show JSON schema { \"title\" : \"InMemoryArtifactService\" , \"description\" : \"An in-memory implementation of the artifact service.\\n\\nIt is not suitable for multi-threaded production environments. Use it for\\ntesting and development only.\" , \"type\" : \"object\" , \"properties\" : { \"artifacts\" : { \"additionalProperties\" : { \"items\" : { \"$ref\" : \"#/$defs/_ArtifactEntry\" }, \"type\" : \"array\" }, \"title\" : \"Artifacts\" , \"type\" : \"object\" } }, \"$defs\" : { \"ArtifactVersion\" : { \"description\" : \"Represents the metadata of a specific version of an artifact.\" , \"properties\" : { \"version\" : { \"title\" : \"Version\" , \"type\" : \"integer\" }, \"canonical_uri\" : { \"title\" : \"Canonical Uri\" , \"type\" : \"string\" }, \"custom_metadata\" : { \"additionalProperties\" : true , \"title\" : \"Custom Metadata\" , \"type\" : \"object\" }, \"create_time\" : { \"title\" : \"Create Time\" , \"type\" : \"number\" }, \"mime_type\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Mime Type\" } }, \"required\" : [ \"version\" , \"canonical_uri\" ], \"title\" : \"ArtifactVersion\" , \"type\" : \"object\" }, \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" }, \"_ArtifactEntry\" : { \"properties\" : { \"data\" : { \"$ref\" : \"#/$defs/Part\" }, \"artifact_version\" : { \"$ref\" : \"#/$defs/ArtifactVersion\" } }, \"required\" : [ \"data\" , \"artifact_version\" ], \"title\" : \"_ArtifactEntry\" , \"type\" : \"object\" } } } Fields : artifacts (dict[str, list[google.adk.artifacts.in_memory_artifact_service._ArtifactEntry]]) field artifacts : dict[str, list[_ArtifactEntry]] [Optional] \u00b6 async delete_artifact ( * , app_name , user_id , filename , session_id = None ) \u00b6 Deletes an artifact. Return type : None Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , delete the user-scoped\nartifact. async get_artifact_version ( * , app_name , user_id , filename , session_id = None , version = None ) \u00b6 Gets the metadata for a specific version of an artifact. Return type : Optional [ ArtifactVersion ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , the artifact will be fetched\nfrom the user-scoped artifacts. Otherwise, it will be fetched from the\nspecified session. version \u2013 The version number of the artifact to retrieve. If None , the\nlatest version will be returned. Returns : An ArtifactVersion object containing the metadata of the specified\nartifact version, or None if the artifact version is not found. async list_artifact_keys ( * , app_name , user_id , session_id = None ) \u00b6 Lists all the artifact filenames within a session. Return type : list [ str ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. session_id \u2013 The ID of the session. Returns : A list of artifact filenames. If session_id is provided, returns\nboth session-scoped and user-scoped artifact filenames. If session_id is None , returns\nuser-scoped artifact filenames. async list_artifact_versions ( * , app_name , user_id , filename , session_id = None ) \u00b6 Lists all versions and their metadata for a specific artifact. Return type : list [ ArtifactVersion ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , lists versions of the\nuser-scoped artifact. Otherwise, lists versions of the artifact within\nthe specified session. Returns : A list of ArtifactVersion objects, each representing a version of the\nartifact and its associated metadata. async list_versions ( * , app_name , user_id , filename , session_id = None ) \u00b6 Lists all versions of an artifact. Return type : list [ int ] Parameters : app_name \u2013 The name of the application. user_id \u2013 The ID of the user. filename \u2013 The name of the artifact file. session_id \u2013 The ID of the session. If None , only list the user-scoped\nartifacts versions. Returns : A list of all available versions of the artifact. async load_artifact ( * , app_name , user_id , filename , session_id = None , version = None ) \u00b6 Gets an artifact from the artifact service storage. The artifact is a file identified by the app name, user ID, session ID, and\nfilename. Return type : Optional [ Part ] Parameters : app_name \u2013 The app name. user_id \u2013 The user ID. filename \u2013 The filename of the artifact. session_id \u2013 The session ID. If None , load the user-scoped artifact. version \u2013 The version of the artifact. If None, the latest version will be\nreturned. Returns : The artifact or None if not found. async save_artifact ( * , app_name , user_id , filename , artifact , session_id = None , custom_metadata = None ) \u00b6 Saves an artifact to the artifact service storage. The artifact is a file identified by the app name, user ID, session ID, and\nfilename. After saving the artifact, a revision ID is returned to identify\nthe artifact version. Return type : int Parameters : app_name \u2013 The app name. user_id \u2013 The user ID. filename \u2013 The filename of the artifact. artifact \u2013 The artifact to save. If the artifact consists of file_data ,\nthe artifact service assumes its content has been uploaded separately,\nand this method will associate the file_data with the artifact if\nnecessary. session_id \u2013 The session ID. If None , the artifact is user-scoped. custom_metadata \u2013 custom metadata to associate with the artifact. Returns : The revision ID. The first version of the artifact has a revision ID of 0.\nThis is incremented by 1 after each successful save. ", "code_blocks": []}, {"heading_path": ["google.adk.apps package\u00b6"], "text": "google.adk.apps package \u00b6 pydantic model google.adk.apps. App \u00b6 Bases: BaseModel Represents an LLM-backed agentic application. An App is the top-level container for an agentic system powered by LLMs.\nIt manages a root agent ( root_agent ), which serves as the root of an agent\ntree, enabling coordination and communication across all agents in the\nhierarchy.\nThe plugins are application-wide components that provide shared capabilities\nand services to the entire system. Show JSON schema { \"title\" : \"App\" , \"type\" : \"object\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"root_agent\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"plugins\" : { \"default\" : null , \"title\" : \"Plugins\" }, \"events_compaction_config\" : { \"default\" : null , \"title\" : \"Events Compaction Config\" }, \"context_cache_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ContextCacheConfig\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"resumability_config\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ResumabilityConfig\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"$defs\" : { \"BaseAgent\" : { \"additionalProperties\" : false , \"description\" : \"Base class for all agents in Agent Development Kit.\" , \"properties\" : { \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" }, \"parent_agent\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/BaseAgent\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"sub_agents\" : { \"items\" : { \"$ref\" : \"#/$defs/BaseAgent\" }, \"title\" : \"Sub Agents\" , \"type\" : \"array\" }, \"before_agent_callback\" : { \"default\" : null , \"title\" : \"Before Agent Callback\" , \"type\" : \"null\" }, \"after_agent_callback\" : { \"default\" : null , \"title\" : \"After Agent Callback\" , \"type\" : \"null\" } }, \"required\" : [ \"name\" ], \"title\" : \"BaseAgent\" , \"type\" : \"object\" }, \"ContextCacheConfig\" : { \"additionalProperties\" : false , \"description\" : \"Configuration for context caching across all agents in an app.\\n\\nThis configuration enables and controls context caching behavior for\\nall LLM agents in an app. When this config is present on an app, context\\ncaching is enabled for all agents. When absent (None), context caching\\nis disabled.\\n\\nContext caching can significantly reduce costs and improve response times\\nby reusing previously processed context across multiple requests.\\n\\nAttributes:\\n    cache_intervals: Maximum number of invocations to reuse the same cache before refreshing it\\n    ttl_seconds: Time-to-live for cache in seconds\\n    min_tokens: Minimum tokens required to enable caching\" , \"properties\" : { \"cache_intervals\" : { \"default\" : 10 , \"description\" : \"Maximum number of invocations to reuse the same cache before refreshing it\" , \"maximum\" : 100 , \"minimum\" : 1 , \"title\" : \"Cache Intervals\" , \"type\" : \"integer\" }, \"ttl_seconds\" : { \"default\" : 1800 , \"description\" : \"Time-to-live for cache in seconds\" , \"exclusiveMinimum\" : 0 , \"title\" : \"Ttl Seconds\" , \"type\" : \"integer\" }, \"min_tokens\" : { \"default\" : 0 , \"description\" : \"Minimum estimated request tokens required to enable caching. This compares against the estimated total tokens of the request (system instruction + tools + contents). Context cache storage may have cost. Set higher to avoid caching small requests where overhead may exceed benefits.\" , \"minimum\" : 0 , \"title\" : \"Min Tokens\" , \"type\" : \"integer\" } }, \"title\" : \"ContextCacheConfig\" , \"type\" : \"object\" }, \"ResumabilityConfig\" : { \"description\" : \"The config of the resumability for an application.\\n\\nThe \\\"resumability\\\" in ADK refers to the ability to:\\n1. pause an invocation upon a long running function call.\\n2. resume an invocation from the last event, if it's paused or failed midway\\nthrough.\\n\\nNote: ADK resumes the invocation in a best-effort manner:\\n1. Tool call to resume needs to be idempotent because we only guarantee\\nan at-least-once behavior once resumed.\\n2. Any temporary / in-memory state will be lost upon resumption.\" , \"properties\" : { \"is_resumable\" : { \"default\" : false , \"title\" : \"Is Resumable\" , \"type\" : \"boolean\" } }, \"title\" : \"ResumabilityConfig\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"name\" , \"root_agent\" ] } Fields : context_cache_config (google.adk.agents.context_cache_config.ContextCacheConfig | None) events_compaction_config (google.adk.apps.app.EventsCompactionConfig | None) name (str) plugins (list[google.adk.plugins.base_plugin.BasePlugin]) resumability_config (google.adk.apps.app.ResumabilityConfig | None) root_agent (google.adk.agents.base_agent.BaseAgent) field context_cache_config : Optional[ContextCacheConfig] = None \u00b6 Context cache configuration that applies to all LLM agents in the app. field events_compaction_config : Optional[EventsCompactionConfig] = None \u00b6 The config of event compaction for the application. field name : str [Required] \u00b6 The name of the application. field plugins : list[BasePlugin] [Optional] \u00b6 The plugins in the application. field resumability_config : Optional[ResumabilityConfig] = None \u00b6 The config of the resumability for the application.\nIf configured, will be applied to all agents in the app. field root_agent : BaseAgent [Required] \u00b6 The root agent in the application. One app can only have one root agent. pydantic model google.adk.apps. ResumabilityConfig \u00b6 Bases: BaseModel The config of the resumability for an application. The \u201cresumability\u201d in ADK refers to the ability to:\n1. pause an invocation upon a long running function call.\n2. resume an invocation from the last event, if it\u2019s paused or failed midway\nthrough. Note: ADK resumes the invocation in a best-effort manner:\n1. Tool call to resume needs to be idempotent because we only guarantee\nan at-least-once behavior once resumed.\n2. Any temporary / in-memory state will be lost upon resumption. Show JSON schema { \"title\" : \"ResumabilityConfig\" , \"description\" : \"The config of the resumability for an application.\\n\\nThe \\\"resumability\\\" in ADK refers to the ability to:\\n1. pause an invocation upon a long running function call.\\n2. resume an invocation from the last event, if it's paused or failed midway\\nthrough.\\n\\nNote: ADK resumes the invocation in a best-effort manner:\\n1. Tool call to resume needs to be idempotent because we only guarantee\\nan at-least-once behavior once resumed.\\n2. Any temporary / in-memory state will be lost upon resumption.\" , \"type\" : \"object\" , \"properties\" : { \"is_resumable\" : { \"default\" : false , \"title\" : \"Is Resumable\" , \"type\" : \"boolean\" } } } Fields : is_resumable (bool) field is_resumable : bool = False \u00b6 Whether the app supports agent resumption.\nIf enabled, the feature will be enabled for all agents in the app. ", "code_blocks": []}, {"heading_path": ["google.adk.auth module\u00b6"], "text": "google.adk.auth module \u00b6 ", "code_blocks": []}, {"heading_path": ["google.adk.cli module\u00b6"], "text": "google.adk.cli module \u00b6 ", "code_blocks": []}, {"heading_path": ["google.adk.code_executors module\u00b6"], "text": "google.adk.code_executors module \u00b6 pydantic model google.adk.code_executors. BaseCodeExecutor \u00b6 Bases: BaseModel Abstract base class for all code executors. The code executor allows the agent to execute code blocks from model responses\nand incorporate the execution results into the final response. optimize_data_file \u00b6 If true, extract and process data files from the model\nrequest and attach them to the code executor. Supported data file\nMimeTypes are [text/csv]. Default to False. stateful \u00b6 Whether the code executor is stateful. Default to False. error_retry_attempts \u00b6 The number of attempts to retry on consecutive code\nexecution errors. Default to 2. code_block_delimiters \u00b6 The list of the enclosing delimiters to identify the\ncode blocks. execution_result_delimiters \u00b6 The delimiters to format the code execution\nresult. Show JSON schema { \"title\" : \"BaseCodeExecutor\" , \"description\" : \"Abstract base class for all code executors.\\n\\nThe code executor allows the agent to execute code blocks from model responses\\nand incorporate the execution results into the final response.\\n\\nAttributes:\\n  optimize_data_file: If true, extract and process data files from the model\\n    request and attach them to the code executor. Supported data file\\n    MimeTypes are [text/csv]. Default to False.\\n  stateful: Whether the code executor is stateful. Default to False.\\n  error_retry_attempts: The number of attempts to retry on consecutive code\\n    execution errors. Default to 2.\\n  code_block_delimiters: The list of the enclosing delimiters to identify the\\n    code blocks.\\n  execution_result_delimiters: The delimiters to format the code execution\\n    result.\" , \"type\" : \"object\" , \"properties\" : { \"optimize_data_file\" : { \"default\" : false , \"title\" : \"Optimize Data File\" , \"type\" : \"boolean\" }, \"stateful\" : { \"default\" : false , \"title\" : \"Stateful\" , \"type\" : \"boolean\" }, \"error_retry_attempts\" : { \"default\" : 2 , \"title\" : \"Error Retry Attempts\" , \"type\" : \"integer\" }, \"code_block_delimiters\" : { \"default\" : [ [ \"```tool_code\\n\" , \"\\n```\" ], [ \"```python\\n\" , \"\\n```\" ] ], \"items\" : { \"maxItems\" : 2 , \"minItems\" : 2 , \"prefixItems\" : [ { \"type\" : \"string\" }, { \"type\" : \"string\" } ], \"type\" : \"array\" }, \"title\" : \"Code Block Delimiters\" , \"type\" : \"array\" }, \"execution_result_delimiters\" : { \"default\" : [ \"```tool_output\\n\" , \"\\n```\" ], \"maxItems\" : 2 , \"minItems\" : 2 , \"prefixItems\" : [ { \"type\" : \"string\" }, { \"type\" : \"string\" } ], \"title\" : \"Execution Result Delimiters\" , \"type\" : \"array\" } } } Fields : code_block_delimiters (List[tuple[str, str]]) error_retry_attempts (int) execution_result_delimiters (tuple[str, str]) optimize_data_file (bool) stateful (bool) field code_block_delimiters : List[tuple[str, str]] = [('```tool_code\\n', '\\n```'), ('```python\\n', '\\n```')] \u00b6 The list of the enclosing delimiters to identify the code blocks. For example, the delimiter (\u2019 `python\\n', '\\n` \u2019) can be\nused to identify code blocks with the following format: ```python\nprint(\"hello\")\n``` field error_retry_attempts : int = 2 \u00b6 The number of attempts to retry on consecutive code execution errors. Default to 2. field execution_result_delimiters : tuple[str, str] = ('```tool_output\\n', '\\n```') \u00b6 The delimiters to format the code execution result. field optimize_data_file : bool = False \u00b6 If true, extract and process data files from the model request\nand attach them to the code executor. Supported data file MimeTypes are [text/csv].\nDefault to False. field stateful : bool = False \u00b6 Whether the code executor is stateful. Default to False. abstractmethod execute_code ( invocation_context , code_execution_input ) \u00b6 Executes code and return the code execution result. Return type : CodeExecutionResult Parameters : invocation_context \u2013 The invocation context of the code execution. code_execution_input \u2013 The code execution input. Returns : The code execution result. pydantic model google.adk.code_executors. BuiltInCodeExecutor \u00b6 Bases: BaseCodeExecutor A code executor that uses the Model\u2019s built-in code executor. Currently only supports Gemini 2.0+ models, but will be expanded to\nother models. Show JSON schema { \"title\" : \"BuiltInCodeExecutor\" , \"description\" : \"A code executor that uses the Model's built-in code executor.\\n\\nCurrently only supports Gemini 2.0+ models, but will be expanded to\\nother models.\" , \"type\" : \"object\" , \"properties\" : { \"optimize_data_file\" : { \"default\" : false , \"title\" : \"Optimize Data File\" , \"type\" : \"boolean\" }, \"stateful\" : { \"default\" : false , \"title\" : \"Stateful\" , \"type\" : \"boolean\" }, \"error_retry_attempts\" : { \"default\" : 2 , \"title\" : \"Error Retry Attempts\" , \"type\" : \"integer\" }, \"code_block_delimiters\" : { \"default\" : [ [ \"```tool_code\\n\" , \"\\n```\" ], [ \"```python\\n\" , \"\\n```\" ] ], \"items\" : { \"maxItems\" : 2 , \"minItems\" : 2 , \"prefixItems\" : [ { \"type\" : \"string\" }, { \"type\" : \"string\" } ], \"type\" : \"array\" }, \"title\" : \"Code Block Delimiters\" , \"type\" : \"array\" }, \"execution_result_delimiters\" : { \"default\" : [ \"```tool_output\\n\" , \"\\n```\" ], \"maxItems\" : 2 , \"minItems\" : 2 , \"prefixItems\" : [ { \"type\" : \"string\" }, { \"type\" : \"string\" } ], \"title\" : \"Execution Result Delimiters\" , \"type\" : \"array\" } } } Fields : execute_code ( invocation_context , code_execution_input ) \u00b6 Executes code and return the code execution result. Return type : CodeExecutionResult Parameters : invocation_context \u2013 The invocation context of the code execution. code_execution_input \u2013 The code execution input. Returns : The code execution result. process_llm_request ( llm_request ) \u00b6 Pre-process the LLM request for Gemini 2.0+ models to use the code execution tool. Return type : None class google.adk.code_executors. CodeExecutorContext ( session_state ) \u00b6 Bases: object The persistent context used to configure the code executor. Initializes the code executor context. Parameters : session_state \u2013 The session state to get the code executor context from. add_input_files ( input_files ) \u00b6 Adds the input files to the code executor context. Parameters : input_files \u2013 The input files to add to the code executor context. add_processed_file_names ( file_names ) \u00b6 Adds the processed file name to the session state. Parameters : file_names \u2013 The processed file names to add to the session state. clear_input_files ( ) \u00b6 Removes the input files and processed file names to the code executor context. get_error_count ( invocation_id ) \u00b6 Gets the error count from the session state. Return type : int Parameters : invocation_id \u2013 The invocation ID to get the error count for. Returns : The error count for the given invocation ID. get_execution_id ( ) \u00b6 Gets the session ID for the code executor. Return type : Optional [ str ] Returns : The session ID for the code executor context. get_input_files ( ) \u00b6 Gets the code executor input file names from the session state. Return type : list [ File ] Returns : A list of input files in the code executor context. get_processed_file_names ( ) \u00b6 Gets the processed file names from the session state. Return type : list [ str ] Returns : A list of processed file names in the code executor context. get_state_delta ( ) \u00b6 Gets the state delta to update in the persistent session state. Return type : dict [ str , Any ] Returns : The state delta to update in the persistent session state. increment_error_count ( invocation_id ) \u00b6 Increments the error count from the session state. Parameters : invocation_id \u2013 The invocation ID to increment the error count for. reset_error_count ( invocation_id ) \u00b6 Resets the error count from the session state. Parameters : invocation_id \u2013 The invocation ID to reset the error count for. set_execution_id ( session_id ) \u00b6 Sets the session ID for the code executor. Parameters : session_id \u2013 The session ID for the code executor. update_code_execution_result ( invocation_id , code , result_stdout , result_stderr ) \u00b6 Updates the code execution result. Parameters : invocation_id \u2013 The invocation ID to update the code execution result for. code \u2013 The code to execute. result_stdout \u2013 The standard output of the code execution. result_stderr \u2013 The standard error of the code execution. pydantic model google.adk.code_executors. UnsafeLocalCodeExecutor \u00b6 Bases: BaseCodeExecutor A code executor that unsafely execute code in the current local context. Initializes the UnsafeLocalCodeExecutor. Show JSON schema { \"title\" : \"UnsafeLocalCodeExecutor\" , \"description\" : \"A code executor that unsafely execute code in the current local context.\" , \"type\" : \"object\" , \"properties\" : { \"optimize_data_file\" : { \"default\" : false , \"title\" : \"Optimize Data File\" , \"type\" : \"boolean\" }, \"stateful\" : { \"default\" : false , \"title\" : \"Stateful\" , \"type\" : \"boolean\" }, \"error_retry_attempts\" : { \"default\" : 2 , \"title\" : \"Error Retry Attempts\" , \"type\" : \"integer\" }, \"code_block_delimiters\" : { \"default\" : [ [ \"```tool_code\\n\" , \"\\n```\" ], [ \"```python\\n\" , \"\\n```\" ] ], \"items\" : { \"maxItems\" : 2 , \"minItems\" : 2 , \"prefixItems\" : [ { \"type\" : \"string\" }, { \"type\" : \"string\" } ], \"type\" : \"array\" }, \"title\" : \"Code Block Delimiters\" , \"type\" : \"array\" }, \"execution_result_delimiters\" : { \"default\" : [ \"```tool_output\\n\" , \"\\n```\" ], \"maxItems\" : 2 , \"minItems\" : 2 , \"prefixItems\" : [ { \"type\" : \"string\" }, { \"type\" : \"string\" } ], \"title\" : \"Execution Result Delimiters\" , \"type\" : \"array\" } } } Fields : optimize_data_file (bool) stateful (bool) field optimize_data_file : bool = False \u00b6 If true, extract and process data files from the model request\nand attach them to the code executor. Supported data file MimeTypes are [text/csv].\nDefault to False. field stateful : bool = False \u00b6 Whether the code executor is stateful. Default to False. execute_code ( invocation_context , code_execution_input ) \u00b6 Executes code and return the code execution result. Return type : CodeExecutionResult Parameters : invocation_context \u2013 The invocation context of the code execution. code_execution_input \u2013 The code execution input. Returns : The code execution result. ", "code_blocks": []}, {"heading_path": ["google.adk.errors module\u00b6"], "text": "google.adk.errors module \u00b6 ", "code_blocks": []}, {"heading_path": ["google.adk.evaluation module\u00b6"], "text": "google.adk.evaluation module \u00b6 class google.adk.evaluation. AgentEvaluator \u00b6 Bases: object An evaluator for Agents, mainly intended for helping with test cases. async static evaluate ( agent_module , eval_dataset_file_path_or_dir , num_runs = 2 , agent_name = None , initial_session_file = None , print_detailed_results = True ) \u00b6 Evaluates an Agent given eval data. Parameters : agent_module \u2013 The path to python module that contains the definition of\nthe agent. There is convention in place here, where the code is going to\nlook for \u2018root_agent\u2019 or \u2018get_agent_async\u2019 in the loaded module. eval_dataset_file_path_or_dir \u2013 The eval data set. This can be either a\nstring representing full path to the file containing eval dataset, or a\ndirectory that is recursively explored for all files that have a .test.json suffix. num_runs \u2013 Number of times all entries in the eval dataset should be\nassessed. agent_name \u2013 The name of the agent. initial_session_file \u2013 File that contains initial session state that is\nneeded by all the evals in the eval dataset. print_detailed_results \u2013 Whether to print detailed results for each metric\nevaluation. async static evaluate_eval_set ( agent_module , eval_set , criteria = None , eval_config = None , num_runs = 2 , agent_name = None , print_detailed_results = True ) \u00b6 Evaluates an agent using the given EvalSet. Parameters : agent_module \u2013 The path to python module that contains the definition of\nthe agent. There is convention in place here, where the code is going to\nlook for \u2018root_agent\u2019 or get_agent_async in the loaded module. eval_set \u2013 The eval set. criteria \u2013 Evauation criterias, a dictionary of metric names to their\nrespective thresholds. This field is deprecated. eval_config \u2013 The evauation config. num_runs \u2013 Number of times all entries in the eval dataset should be\nassessed. agent_name \u2013 The name of the agent, if trying to evaluate something other\nthan root agent. If left empty or none, then root agent is evaluated. print_detailed_results \u2013 Whether to print detailed results for each metric\nevaluation. static find_config_for_test_file ( test_file ) \u00b6 Find the test_config.json file in the same folder as the test file. Return type : EvalConfig static migrate_eval_data_to_new_schema ( old_eval_data_file , new_eval_data_file , initial_session_file = None ) \u00b6 A utility for migrating eval data to new schema backed by EvalSet. ", "code_blocks": []}, {"heading_path": ["google.adk.events module\u00b6"], "text": "google.adk.events module \u00b6 pydantic model google.adk.events. Event \u00b6 Bases: LlmResponse Represents an event in a conversation between agents and users. It is used to store the content of the conversation, as well as the actions\ntaken by the agents like function calls, etc. Show JSON schema { \"title\" : \"Event\" , \"description\" : \"Represents an event in a conversation between agents and users.\\n\\nIt is used to store the content of the conversation, as well as the actions\\ntaken by the agents like function calls, etc.\" , \"type\" : \"object\" , \"properties\" : { \"content\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Content\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"groundingMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"partial\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Partial\" }, \"turnComplete\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Turncomplete\" }, \"finishReason\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FinishReason\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"errorCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Errorcode\" }, \"errorMessage\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Errormessage\" }, \"interrupted\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Interrupted\" }, \"customMetadata\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Custommetadata\" }, \"usageMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GenerateContentResponseUsageMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"liveSessionResumptionUpdate\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/LiveServerSessionResumptionUpdate\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"inputTranscription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Transcription\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"outputTranscription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Transcription\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"avgLogprobs\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Avglogprobs\" }, \"logprobsResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/LogprobsResult\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"cacheMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CacheMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"citationMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CitationMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"invocationId\" : { \"default\" : \"\" , \"title\" : \"Invocationid\" , \"type\" : \"string\" }, \"author\" : { \"title\" : \"Author\" , \"type\" : \"string\" }, \"actions\" : { \"$ref\" : \"#/$defs/EventActions\" }, \"longRunningToolIds\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" , \"uniqueItems\" : true }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Longrunningtoolids\" }, \"branch\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Branch\" }, \"id\" : { \"default\" : \"\" , \"title\" : \"Id\" , \"type\" : \"string\" }, \"timestamp\" : { \"title\" : \"Timestamp\" , \"type\" : \"number\" } }, \"$defs\" : { \"APIKey\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"apiKey\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"in\" : { \"$ref\" : \"#/$defs/APIKeyIn\" }, \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" } }, \"required\" : [ \"in\" , \"name\" ], \"title\" : \"APIKey\" , \"type\" : \"object\" }, \"APIKeyIn\" : { \"enum\" : [ \"query\" , \"header\" , \"cookie\" ], \"title\" : \"APIKeyIn\" , \"type\" : \"string\" }, \"AuthConfig\" : { \"additionalProperties\" : true , \"description\" : \"The auth config sent by tool asking client to collect auth credentials and\\n\\nadk and client will help to fill in the response\" , \"properties\" : { \"authScheme\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/APIKey\" }, { \"$ref\" : \"#/$defs/HTTPBase\" }, { \"$ref\" : \"#/$defs/OAuth2\" }, { \"$ref\" : \"#/$defs/OpenIdConnect\" }, { \"$ref\" : \"#/$defs/HTTPBearer\" }, { \"$ref\" : \"#/$defs/OpenIdConnectWithConfig\" } ], \"title\" : \"Authscheme\" }, \"rawAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"exchangedAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"credentialKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Credentialkey\" } }, \"required\" : [ \"authScheme\" ], \"title\" : \"AuthConfig\" , \"type\" : \"object\" }, \"AuthCredential\" : { \"additionalProperties\" : true , \"description\" : \"Data class representing an authentication credential.\\n\\nTo exchange for the actual credential, please use\\nCredentialExchanger.exchange_credential().\\n\\nExamples: API Key Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    api_key=\\\"1234\\\",\\n)\\n\\nExample: HTTP Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"basic\\\",\\n        credentials=HttpCredentials(username=\\\"user\\\", password=\\\"password\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Bearer Token in HTTP Header\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"bearer\\\",\\n        credentials=HttpCredentials(token=\\\"eyAkaknabna....\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Auth with Authorization Code Flow\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OAUTH2,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n    ),\\n)\\n\\nExample: OpenID Connect Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OPEN_ID_CONNECT,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n        redirect_uri=\\\"https://example.com\\\",\\n        scopes=[\\\"scope1\\\", \\\"scope2\\\"],\\n    ),\\n)\\n\\nExample: Auth with resource reference\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    resource_ref=\\\"projects/1234/locations/us-central1/resources/resource1\\\",\\n)\" , \"properties\" : { \"authType\" : { \"$ref\" : \"#/$defs/AuthCredentialTypes\" }, \"resourceRef\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Resourceref\" }, \"apiKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Apikey\" }, \"http\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HttpAuth\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"serviceAccount\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccount\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"oauth2\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuth2Auth\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"required\" : [ \"authType\" ], \"title\" : \"AuthCredential\" , \"type\" : \"object\" }, \"AuthCredentialTypes\" : { \"description\" : \"Represents the type of authentication credential.\" , \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" , \"serviceAccount\" ], \"title\" : \"AuthCredentialTypes\" , \"type\" : \"string\" }, \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CacheMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Metadata for context cache associated with LLM responses.\\n\\nThis class stores cache identification, usage tracking, and lifecycle\\ninformation for a particular cache instance. It can be in two states:\\n\\n1. Active cache state: cache_name is set, all fields populated\\n2. Fingerprint-only state: cache_name is None, only fingerprint and\\n   contents_count are set for prefix matching\\n\\nToken counts (cached and total) are available in the LlmResponse.usage_metadata\\nand should be accessed from there to avoid duplication.\\n\\nAttributes:\\n    cache_name: The full resource name of the cached content (e.g.,\\n        'projects/123/locations/us-central1/cachedContents/456').\\n        None when no active cache exists (fingerprint-only state).\\n    expire_time: Unix timestamp when the cache expires. None when no\\n        active cache exists.\\n    fingerprint: Hash of cacheable contents (instruction + tools + contents).\\n        Always present for prefix matching.\\n    invocations_used: Number of invocations this cache has been used for.\\n        None when no active cache exists.\\n    contents_count: Number of contents. When active cache exists, this is\\n        the count of cached contents. When no active cache exists, this is\\n        the total count of contents in the request.\\n    created_at: Unix timestamp when the cache was created. None when\\n        no active cache exists.\" , \"properties\" : { \"cache_name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Full resource name of the cached content (None if no active cache)\" , \"title\" : \"Cache Name\" }, \"expire_time\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Unix timestamp when cache expires (None if no active cache)\" , \"title\" : \"Expire Time\" }, \"fingerprint\" : { \"description\" : \"Hash of cacheable contents used to detect changes\" , \"title\" : \"Fingerprint\" , \"type\" : \"string\" }, \"invocations_used\" : { \"anyOf\" : [ { \"minimum\" : 0 , \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of invocations this cache has been used for (None if no active cache)\" , \"title\" : \"Invocations Used\" }, \"contents_count\" : { \"description\" : \"Number of contents (cached contents when active cache exists, total contents in request when no active cache)\" , \"minimum\" : 0 , \"title\" : \"Contents Count\" , \"type\" : \"integer\" }, \"created_at\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Unix timestamp when cache was created (None if no active cache)\" , \"title\" : \"Created At\" } }, \"required\" : [ \"fingerprint\" , \"contents_count\" ], \"title\" : \"CacheMetadata\" , \"type\" : \"object\" }, \"Citation\" : { \"additionalProperties\" : false , \"description\" : \"Source attributions for content.\" , \"properties\" : { \"endIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. End index into the content.\" , \"title\" : \"Endindex\" }, \"license\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. License of the attribution.\" , \"title\" : \"License\" }, \"publicationDate\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GoogleTypeDate\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Publication date of the attribution.\" }, \"startIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Start index into the content.\" , \"title\" : \"Startindex\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Title of the attribution.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Url reference of the attribution.\" , \"title\" : \"Uri\" } }, \"title\" : \"Citation\" , \"type\" : \"object\" }, \"CitationMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Citation information when the model quotes another source.\" , \"properties\" : { \"citations\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Citation\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Contains citation information when the model directly quotes, at\\n      length, from another source. Can include traditional websites and code\\n      repositories.\\n      \" , \"title\" : \"Citations\" } }, \"title\" : \"CitationMetadata\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"Content\" : { \"additionalProperties\" : false , \"description\" : \"Contains the multi-part content of a message.\" , \"properties\" : { \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Part\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a single message. Each part may have\\n      a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The producer of the content. Must be either 'user' or\\n      'model'. Useful to set for multi-turn conversations, otherwise can be\\n      empty. If role is not specified, SDK will determine the role.\" , \"title\" : \"Role\" } }, \"title\" : \"Content\" , \"type\" : \"object\" }, \"EventActions\" : { \"additionalProperties\" : false , \"description\" : \"Represents the actions attached to an event.\" , \"properties\" : { \"skipSummarization\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Skipsummarization\" }, \"stateDelta\" : { \"additionalProperties\" : true , \"title\" : \"Statedelta\" , \"type\" : \"object\" }, \"artifactDelta\" : { \"additionalProperties\" : { \"type\" : \"integer\" }, \"title\" : \"Artifactdelta\" , \"type\" : \"object\" }, \"transferToAgent\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Transfertoagent\" }, \"escalate\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Escalate\" }, \"requestedAuthConfigs\" : { \"additionalProperties\" : { \"$ref\" : \"#/$defs/AuthConfig\" }, \"title\" : \"Requestedauthconfigs\" , \"type\" : \"object\" }, \"requestedToolConfirmations\" : { \"additionalProperties\" : { \"$ref\" : \"#/$defs/ToolConfirmation\" }, \"title\" : \"Requestedtoolconfirmations\" , \"type\" : \"object\" }, \"compaction\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/EventCompaction\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"endOfAgent\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Endofagent\" }, \"agentState\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Agentstate\" }, \"rewindBeforeInvocationId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Rewindbeforeinvocationid\" } }, \"title\" : \"EventActions\" , \"type\" : \"object\" }, \"EventCompaction\" : { \"additionalProperties\" : false , \"description\" : \"The compaction of the events.\" , \"properties\" : { \"startTimestamp\" : { \"title\" : \"Starttimestamp\" , \"type\" : \"number\" }, \"endTimestamp\" : { \"title\" : \"Endtimestamp\" , \"type\" : \"number\" }, \"compactedContent\" : { \"$ref\" : \"#/$defs/Content\" } }, \"required\" : [ \"startTimestamp\" , \"endTimestamp\" , \"compactedContent\" ], \"title\" : \"EventCompaction\" , \"type\" : \"object\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FinishReason\" : { \"description\" : \"Output only. The reason why the model stopped generating tokens.\\n\\nIf empty, the model has not stopped generating the tokens.\" , \"enum\" : [ \"FINISH_REASON_UNSPECIFIED\" , \"STOP\" , \"MAX_TOKENS\" , \"SAFETY\" , \"RECITATION\" , \"LANGUAGE\" , \"OTHER\" , \"BLOCKLIST\" , \"PROHIBITED_CONTENT\" , \"SPII\" , \"MALFORMED_FUNCTION_CALL\" , \"IMAGE_SAFETY\" , \"UNEXPECTED_TOOL_CALL\" , \"IMAGE_PROHIBITED_CONTENT\" , \"NO_IMAGE\" ], \"title\" : \"FinishReason\" , \"type\" : \"string\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"GenerateContentResponseUsageMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Usage metadata about response(s).\" , \"properties\" : { \"cacheTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities of the cached content in the request input.\" , \"title\" : \"Cachetokensdetails\" }, \"cachedContentTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Number of tokens in the cached part in the input (the cached content).\" , \"title\" : \"Cachedcontenttokencount\" }, \"candidatesTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens in the response(s).\" , \"title\" : \"Candidatestokencount\" }, \"candidatesTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities that were returned in the response.\" , \"title\" : \"Candidatestokensdetails\" }, \"promptTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens in the request. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content.\" , \"title\" : \"Prompttokencount\" }, \"promptTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities that were processed in the request input.\" , \"title\" : \"Prompttokensdetails\" }, \"thoughtsTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Number of tokens present in thoughts output.\" , \"title\" : \"Thoughtstokencount\" }, \"toolUsePromptTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Number of tokens present in tool-use prompt(s).\" , \"title\" : \"Tooluseprompttokencount\" }, \"toolUsePromptTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities that were processed for tool-use request inputs.\" , \"title\" : \"Tooluseprompttokensdetails\" }, \"totalTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Total token count for prompt, response candidates, and tool-use prompts (if present).\" , \"title\" : \"Totaltokencount\" }, \"trafficType\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/TrafficType\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota.\" } }, \"title\" : \"GenerateContentResponseUsageMetadata\" , \"type\" : \"object\" }, \"GoogleTypeDate\" : { \"additionalProperties\" : false , \"description\" : \"Represents a whole or partial calendar date, such as a birthday.\\n\\nThe time of day and time zone are either specified elsewhere or are\\ninsignificant. The date is relative to the Gregorian Calendar. This can\\nrepresent one of the following: * A full date, with non-zero year, month, and\\nday values. * A month and day, with a zero year (for example, an anniversary).\\n* A year on its own, with a zero month and a zero day. * A year and month,\\nwith a zero day (for example, a credit card expiration date). Related types: *\\ngoogle.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp\" , \"properties\" : { \"day\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.\" , \"title\" : \"Day\" }, \"month\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.\" , \"title\" : \"Month\" }, \"year\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year.\" , \"title\" : \"Year\" } }, \"title\" : \"GoogleTypeDate\" , \"type\" : \"object\" }, \"GroundingChunk\" : { \"additionalProperties\" : false , \"description\" : \"Grounding chunk.\" , \"properties\" : { \"maps\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkMaps\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Grounding chunk from Google Maps.\" }, \"retrievedContext\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkRetrievedContext\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Grounding chunk from context retrieved by the retrieval tools.\" }, \"web\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkWeb\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Grounding chunk from the web.\" } }, \"title\" : \"GroundingChunk\" , \"type\" : \"object\" }, \"GroundingChunkMaps\" : { \"additionalProperties\" : false , \"description\" : \"Chunk from Google Maps.\" , \"properties\" : { \"placeAnswerSources\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkMapsPlaceAnswerSources\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Sources used to generate the place answer. This includes review snippets and photos that were used to generate the answer, as well as uris to flag content.\" }, \"placeId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"This Place's resource name, in `places/{place_id}` format. Can be used to look up the Place.\" , \"title\" : \"Placeid\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Text of the chunk.\" , \"title\" : \"Text\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Title of the chunk.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI reference of the chunk.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkMaps\" , \"type\" : \"object\" }, \"GroundingChunkMapsPlaceAnswerSources\" : { \"additionalProperties\" : false , \"description\" : \"Sources used to generate the place answer.\" , \"properties\" : { \"flagContentUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A link where users can flag a problem with the generated answer.\" , \"title\" : \"Flagcontenturi\" }, \"reviewSnippets\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/GroundingChunkMapsPlaceAnswerSourcesReviewSnippet\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Snippets of reviews that are used to generate the answer.\" , \"title\" : \"Reviewsnippets\" } }, \"title\" : \"GroundingChunkMapsPlaceAnswerSources\" , \"type\" : \"object\" }, \"GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution\" : { \"additionalProperties\" : false , \"description\" : \"Author attribution for a photo or review.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Name of the author of the Photo or Review.\" , \"title\" : \"Displayname\" }, \"photoUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Profile photo URI of the author of the Photo or Review.\" , \"title\" : \"Photouri\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI of the author of the Photo or Review.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution\" , \"type\" : \"object\" }, \"GroundingChunkMapsPlaceAnswerSourcesReviewSnippet\" : { \"additionalProperties\" : false , \"description\" : \"Encapsulates a review snippet.\" , \"properties\" : { \"authorAttribution\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"This review's author.\" }, \"flagContentUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A link where users can flag a problem with the review.\" , \"title\" : \"Flagcontenturi\" }, \"googleMapsUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A link to show the review on Google Maps.\" , \"title\" : \"Googlemapsuri\" }, \"relativePublishTimeDescription\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A string of formatted recent time, expressing the review time relative to the current time in a form appropriate for the language and country.\" , \"title\" : \"Relativepublishtimedescription\" }, \"review\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A reference representing this place review which may be used to look up this place review again.\" , \"title\" : \"Review\" } }, \"title\" : \"GroundingChunkMapsPlaceAnswerSourcesReviewSnippet\" , \"type\" : \"object\" }, \"GroundingChunkRetrievedContext\" : { \"additionalProperties\" : false , \"description\" : \"Chunk from context retrieved by the retrieval tools.\" , \"properties\" : { \"documentName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The full document name for the referenced Vertex AI Search document.\" , \"title\" : \"Documentname\" }, \"ragChunk\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagChunk\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Additional context for the RAG retrieval result. This is only populated when using the RAG retrieval tool.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Text of the attribution.\" , \"title\" : \"Text\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Title of the attribution.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI reference of the attribution.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkRetrievedContext\" , \"type\" : \"object\" }, \"GroundingChunkWeb\" : { \"additionalProperties\" : false , \"description\" : \"Chunk from the web.\" , \"properties\" : { \"domain\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Domain of the (original) URI.\" , \"title\" : \"Domain\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Title of the chunk.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI reference of the chunk.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkWeb\" , \"type\" : \"object\" }, \"GroundingMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Metadata returned to client when grounding is enabled.\" , \"properties\" : { \"googleMapsWidgetContextToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Output only. Resource name of the Google Maps widget context token to be used with the PlacesContextElement widget to render contextual data. This is populated only for Google Maps grounding.\" , \"title\" : \"Googlemapswidgetcontexttoken\" }, \"groundingChunks\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/GroundingChunk\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of supporting references retrieved from specified grounding source.\" , \"title\" : \"Groundingchunks\" }, \"groundingSupports\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/GroundingSupport\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. List of grounding support.\" , \"title\" : \"Groundingsupports\" }, \"retrievalMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RetrievalMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Output only. Retrieval metadata.\" }, \"retrievalQueries\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Queries executed by the retrieval tools.\" , \"title\" : \"Retrievalqueries\" }, \"searchEntryPoint\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/SearchEntryPoint\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Google search entry for the following-up web searches.\" }, \"webSearchQueries\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Web search queries for the following-up web search.\" , \"title\" : \"Websearchqueries\" } }, \"title\" : \"GroundingMetadata\" , \"type\" : \"object\" }, \"GroundingSupport\" : { \"additionalProperties\" : false , \"description\" : \"Grounding support.\" , \"properties\" : { \"confidenceScores\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"number\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. For Gemini 2.0 and before, this list must have the same size as the grounding_chunk_indices. For Gemini 2.5 and after, this list will be empty and should be ignored.\" , \"title\" : \"Confidencescores\" }, \"groundingChunkIndices\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"integer\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.\" , \"title\" : \"Groundingchunkindices\" }, \"segment\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Segment\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Segment of the content this support belongs to.\" } }, \"title\" : \"GroundingSupport\" , \"type\" : \"object\" }, \"HTTPBase\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" } }, \"required\" : [ \"scheme\" ], \"title\" : \"HTTPBase\" , \"type\" : \"object\" }, \"HTTPBearer\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"const\" : \"bearer\" , \"default\" : \"bearer\" , \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"bearerFormat\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Bearerformat\" } }, \"title\" : \"HTTPBearer\" , \"type\" : \"object\" }, \"HttpAuth\" : { \"additionalProperties\" : true , \"description\" : \"The credentials and metadata for HTTP authentication.\" , \"properties\" : { \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"credentials\" : { \"$ref\" : \"#/$defs/HttpCredentials\" } }, \"required\" : [ \"scheme\" , \"credentials\" ], \"title\" : \"HttpAuth\" , \"type\" : \"object\" }, \"HttpCredentials\" : { \"additionalProperties\" : true , \"description\" : \"Represents the secret token value for HTTP authentication, like user name, password, oauth token, etc.\" , \"properties\" : { \"username\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Username\" }, \"password\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Password\" }, \"token\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token\" } }, \"title\" : \"HttpCredentials\" , \"type\" : \"object\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"LiveServerSessionResumptionUpdate\" : { \"additionalProperties\" : false , \"description\" : \"Update of the session resumption state.\\n\\nOnly sent if `session_resumption` was set in the connection config.\" , \"properties\" : { \"newHandle\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"New handle that represents state that can be resumed. Empty if `resumable`=false.\" , \"title\" : \"Newhandle\" }, \"resumable\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss.\" , \"title\" : \"Resumable\" }, \"lastConsumedClientMessageIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when `SessionResumptionConfig.transparent` is set.\\n\\nPresence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last `SessionResmumptionTokenUpdate`. This field will enable them to limit buffering (avoid keeping all requests in RAM).\\n\\nNote: This should not be used for when resuming a session at some time later -- in those cases partial audio and video frames arelikely not needed.\" , \"title\" : \"Lastconsumedclientmessageindex\" } }, \"title\" : \"LiveServerSessionResumptionUpdate\" , \"type\" : \"object\" }, \"LogprobsResult\" : { \"additionalProperties\" : false , \"description\" : \"Logprobs Result\" , \"properties\" : { \"chosenCandidates\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/LogprobsResultCandidate\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates.\" , \"title\" : \"Chosencandidates\" }, \"topCandidates\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/LogprobsResultTopCandidates\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Length = total number of decoding steps.\" , \"title\" : \"Topcandidates\" } }, \"title\" : \"LogprobsResult\" , \"type\" : \"object\" }, \"LogprobsResultCandidate\" : { \"additionalProperties\" : false , \"description\" : \"Candidate for the logprobs token and score.\" , \"properties\" : { \"logProbability\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The candidate's log probability.\" , \"title\" : \"Logprobability\" }, \"token\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The candidate's token string value.\" , \"title\" : \"Token\" }, \"tokenId\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The candidate's token id value.\" , \"title\" : \"Tokenid\" } }, \"title\" : \"LogprobsResultCandidate\" , \"type\" : \"object\" }, \"LogprobsResultTopCandidates\" : { \"additionalProperties\" : false , \"description\" : \"Candidates with top log probabilities at each decoding step.\" , \"properties\" : { \"candidates\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/LogprobsResultCandidate\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Sorted by log probability in descending order.\" , \"title\" : \"Candidates\" } }, \"title\" : \"LogprobsResultTopCandidates\" , \"type\" : \"object\" }, \"MediaModality\" : { \"description\" : \"Server content modalities.\" , \"enum\" : [ \"MODALITY_UNSPECIFIED\" , \"TEXT\" , \"IMAGE\" , \"VIDEO\" , \"AUDIO\" , \"DOCUMENT\" ], \"title\" : \"MediaModality\" , \"type\" : \"string\" }, \"ModalityTokenCount\" : { \"additionalProperties\" : false , \"description\" : \"Represents token counting info for a single modality.\" , \"properties\" : { \"modality\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/MediaModality\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The modality associated with this token count.\" }, \"tokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens.\" , \"title\" : \"Tokencount\" } }, \"title\" : \"ModalityTokenCount\" , \"type\" : \"object\" }, \"OAuth2\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"oauth2\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"flows\" : { \"$ref\" : \"#/$defs/OAuthFlows\" } }, \"required\" : [ \"flows\" ], \"title\" : \"OAuth2\" , \"type\" : \"object\" }, \"OAuth2Auth\" : { \"additionalProperties\" : true , \"description\" : \"Represents credential value and its metadata for a OAuth2 credential.\" , \"properties\" : { \"clientId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientid\" }, \"clientSecret\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientsecret\" }, \"authUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authuri\" }, \"state\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"State\" }, \"redirectUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Redirecturi\" }, \"authResponseUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authresponseuri\" }, \"authCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authcode\" }, \"accessToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Accesstoken\" }, \"refreshToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshtoken\" }, \"expiresAt\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresat\" }, \"expiresIn\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresin\" }, \"audience\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Audience\" } }, \"title\" : \"OAuth2Auth\" , \"type\" : \"object\" }, \"OAuthFlowAuthorizationCode\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" , \"tokenUrl\" ], \"title\" : \"OAuthFlowAuthorizationCode\" , \"type\" : \"object\" }, \"OAuthFlowClientCredentials\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowClientCredentials\" , \"type\" : \"object\" }, \"OAuthFlowImplicit\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" ], \"title\" : \"OAuthFlowImplicit\" , \"type\" : \"object\" }, \"OAuthFlowPassword\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowPassword\" , \"type\" : \"object\" }, \"OAuthFlows\" : { \"additionalProperties\" : true , \"properties\" : { \"implicit\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowImplicit\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"password\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowPassword\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"clientCredentials\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowClientCredentials\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"authorizationCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowAuthorizationCode\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"title\" : \"OAuthFlows\" , \"type\" : \"object\" }, \"OpenIdConnect\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"openIdConnectUrl\" : { \"title\" : \"Openidconnecturl\" , \"type\" : \"string\" } }, \"required\" : [ \"openIdConnectUrl\" ], \"title\" : \"OpenIdConnect\" , \"type\" : \"object\" }, \"OpenIdConnectWithConfig\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"authorization_endpoint\" : { \"title\" : \"Authorization Endpoint\" , \"type\" : \"string\" }, \"token_endpoint\" : { \"title\" : \"Token Endpoint\" , \"type\" : \"string\" }, \"userinfo_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Userinfo Endpoint\" }, \"revocation_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Revocation Endpoint\" }, \"token_endpoint_auth_methods_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token Endpoint Auth Methods Supported\" }, \"grant_types_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Grant Types Supported\" }, \"scopes\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Scopes\" } }, \"required\" : [ \"authorization_endpoint\" , \"token_endpoint\" ], \"title\" : \"OpenIdConnectWithConfig\" , \"type\" : \"object\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"RagChunk\" : { \"additionalProperties\" : false , \"description\" : \"A RagChunk includes the content of a chunk of a RagFile, and associated metadata.\" , \"properties\" : { \"pageSpan\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagChunkPageSpan\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If populated, represents where the chunk starts and ends in the document.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The content of the chunk.\" , \"title\" : \"Text\" } }, \"title\" : \"RagChunk\" , \"type\" : \"object\" }, \"RagChunkPageSpan\" : { \"additionalProperties\" : false , \"description\" : \"Represents where the chunk starts and ends in the document.\" , \"properties\" : { \"firstPage\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Page where chunk starts in the document. Inclusive. 1-indexed.\" , \"title\" : \"Firstpage\" }, \"lastPage\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Page where chunk ends in the document. Inclusive. 1-indexed.\" , \"title\" : \"Lastpage\" } }, \"title\" : \"RagChunkPageSpan\" , \"type\" : \"object\" }, \"RetrievalMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Metadata related to retrieval in the grounding flow.\" , \"properties\" : { \"googleSearchDynamicRetrievalScore\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.\" , \"title\" : \"Googlesearchdynamicretrievalscore\" } }, \"title\" : \"RetrievalMetadata\" , \"type\" : \"object\" }, \"SearchEntryPoint\" : { \"additionalProperties\" : false , \"description\" : \"Google search entry point.\" , \"properties\" : { \"renderedContent\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Web content snippet that can be embedded in a web page or an app webview.\" , \"title\" : \"Renderedcontent\" }, \"sdkBlob\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Base64 encoded JSON representing array of tuple.\" , \"title\" : \"Sdkblob\" } }, \"title\" : \"SearchEntryPoint\" , \"type\" : \"object\" }, \"SecuritySchemeType\" : { \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" ], \"title\" : \"SecuritySchemeType\" , \"type\" : \"string\" }, \"Segment\" : { \"additionalProperties\" : false , \"description\" : \"Segment of the content.\" , \"properties\" : { \"endIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.\" , \"title\" : \"Endindex\" }, \"partIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The index of a Part object within its parent Content object.\" , \"title\" : \"Partindex\" }, \"startIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.\" , \"title\" : \"Startindex\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The text corresponding to the segment from the response.\" , \"title\" : \"Text\" } }, \"title\" : \"Segment\" , \"type\" : \"object\" }, \"ServiceAccount\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\" , \"properties\" : { \"serviceAccountCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccountCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"scopes\" : { \"items\" : { \"type\" : \"string\" }, \"title\" : \"Scopes\" , \"type\" : \"array\" }, \"useDefaultCredential\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : false , \"title\" : \"Usedefaultcredential\" } }, \"required\" : [ \"scopes\" ], \"title\" : \"ServiceAccount\" , \"type\" : \"object\" }, \"ServiceAccountCredential\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\\n\\nAttributes:\\n  type: The type should be \\\"service_account\\\".\\n  project_id: The project ID.\\n  private_key_id: The ID of the private key.\\n  private_key: The private key.\\n  client_email: The client email.\\n  client_id: The client ID.\\n  auth_uri: The authorization URI.\\n  token_uri: The token URI.\\n  auth_provider_x509_cert_url: URL for auth provider's X.509 cert.\\n  client_x509_cert_url: URL for the client's X.509 cert.\\n  universe_domain: The universe domain.\\n\\nExample:\\n\\n    config = ServiceAccountCredential(\\n        type_=\\\"service_account\\\",\\n        project_id=\\\"your_project_id\\\",\\n        private_key_id=\\\"your_private_key_id\\\",\\n        private_key=\\\"-----BEGIN PRIVATE KEY-----...\\\",\\n        client_email=\\\"...@....iam.gserviceaccount.com\\\",\\n        client_id=\\\"your_client_id\\\",\\n        auth_uri=\\\"https://accounts.google.com/o/oauth2/auth\\\",\\n        token_uri=\\\"https://oauth2.googleapis.com/token\\\",\\n        auth_provider_x509_cert_url=\\\"https://www.googleapis.com/oauth2/v1/certs\\\",\\n        client_x509_cert_url=\\\"https://www.googleapis.com/robot/v1/metadata/x509/...\\\",\\n        universe_domain=\\\"googleapis.com\\\"\\n    )\\n\\n\\n    config = ServiceAccountConfig.model_construct(**{\\n        ...service account config dict\\n    })\" , \"properties\" : { \"type\" : { \"default\" : \"\" , \"title\" : \"Type\" , \"type\" : \"string\" }, \"projectId\" : { \"title\" : \"Projectid\" , \"type\" : \"string\" }, \"privateKeyId\" : { \"title\" : \"Privatekeyid\" , \"type\" : \"string\" }, \"privateKey\" : { \"title\" : \"Privatekey\" , \"type\" : \"string\" }, \"clientEmail\" : { \"title\" : \"Clientemail\" , \"type\" : \"string\" }, \"clientId\" : { \"title\" : \"Clientid\" , \"type\" : \"string\" }, \"authUri\" : { \"title\" : \"Authuri\" , \"type\" : \"string\" }, \"tokenUri\" : { \"title\" : \"Tokenuri\" , \"type\" : \"string\" }, \"authProviderX509CertUrl\" : { \"title\" : \"Authproviderx509Certurl\" , \"type\" : \"string\" }, \"clientX509CertUrl\" : { \"title\" : \"Clientx509Certurl\" , \"type\" : \"string\" }, \"universeDomain\" : { \"title\" : \"Universedomain\" , \"type\" : \"string\" } }, \"required\" : [ \"projectId\" , \"privateKeyId\" , \"privateKey\" , \"clientEmail\" , \"clientId\" , \"authUri\" , \"tokenUri\" , \"authProviderX509CertUrl\" , \"clientX509CertUrl\" , \"universeDomain\" ], \"title\" : \"ServiceAccountCredential\" , \"type\" : \"object\" }, \"ToolConfirmation\" : { \"additionalProperties\" : false , \"description\" : \"Represents a tool confirmation configuration.\" , \"properties\" : { \"hint\" : { \"default\" : \"\" , \"title\" : \"Hint\" , \"type\" : \"string\" }, \"confirmed\" : { \"default\" : false , \"title\" : \"Confirmed\" , \"type\" : \"boolean\" }, \"payload\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Payload\" } }, \"title\" : \"ToolConfirmation\" , \"type\" : \"object\" }, \"TrafficType\" : { \"description\" : \"Output only.\\n\\nTraffic type. This shows whether a request consumes Pay-As-You-Go or\\nProvisioned Throughput quota.\" , \"enum\" : [ \"TRAFFIC_TYPE_UNSPECIFIED\" , \"ON_DEMAND\" , \"PROVISIONED_THROUGHPUT\" ], \"title\" : \"TrafficType\" , \"type\" : \"string\" }, \"Transcription\" : { \"additionalProperties\" : false , \"description\" : \"Audio transcription in Server Conent.\" , \"properties\" : { \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Transcription text.\\n      \" , \"title\" : \"Text\" }, \"finished\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The bool indicates the end of the transcription.\\n      \" , \"title\" : \"Finished\" } }, \"title\" : \"Transcription\" , \"type\" : \"object\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"author\" ] } Fields : actions (google.adk.events.event_actions.EventActions) author (str) branch (str | None) id (str) invocation_id (str) long_running_tool_ids (set[str] | None) timestamp (float) field actions : EventActions [Optional] \u00b6 The actions taken by the agent. field author : str [Required] \u00b6 \u2018user\u2019 or the name of the agent, indicating who appended the event to the\nsession. field branch : Optional[str] = None \u00b6 The branch of the event. The format is like agent_1.agent_2.agent_3, where agent_1 is the parent of\nagent_2, and agent_2 is the parent of agent_3. Branch is used when multiple sub-agent shouldn\u2019t see their peer agents\u2019\nconversation history. field id : str = '' \u00b6 The unique identifier of the event. field invocation_id : str = '' (alias 'invocationId') \u00b6 The invocation ID of the event. Should be non-empty before appending to a session. field long_running_tool_ids : Optional[set[str]] = None (alias 'longRunningToolIds') \u00b6 Set of ids of the long running function calls.\nAgent client will know from this field about which function call is long running.\nonly valid for function call event field timestamp : float [Optional] \u00b6 The timestamp of the event. static new_id ( ) \u00b6 get_function_calls ( ) \u00b6 Returns the function calls in the event. Return type : list [ FunctionCall ] get_function_responses ( ) \u00b6 Returns the function responses in the event. Return type : list [ FunctionResponse ] has_trailing_code_execution_result ( ) \u00b6 Returns whether the event has a trailing code execution result. Return type : bool is_final_response ( ) \u00b6 Returns whether the event is the final response of an agent. NOTE: This method is ONLY for use by Agent Development Kit. Note that when multiple agents participage in one invocation, there could be\none event has is_final_response() as True for each participating agent. Return type : bool model_post_init ( _Event__context ) \u00b6 Post initialization logic for the event. pydantic model google.adk.events. EventActions \u00b6 Bases: BaseModel Represents the actions attached to an event. Show JSON schema { \"title\" : \"EventActions\" , \"description\" : \"Represents the actions attached to an event.\" , \"type\" : \"object\" , \"properties\" : { \"skipSummarization\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Skipsummarization\" }, \"stateDelta\" : { \"additionalProperties\" : true , \"title\" : \"Statedelta\" , \"type\" : \"object\" }, \"artifactDelta\" : { \"additionalProperties\" : { \"type\" : \"integer\" }, \"title\" : \"Artifactdelta\" , \"type\" : \"object\" }, \"transferToAgent\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Transfertoagent\" }, \"escalate\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Escalate\" }, \"requestedAuthConfigs\" : { \"additionalProperties\" : { \"$ref\" : \"#/$defs/AuthConfig\" }, \"title\" : \"Requestedauthconfigs\" , \"type\" : \"object\" }, \"requestedToolConfirmations\" : { \"additionalProperties\" : { \"$ref\" : \"#/$defs/ToolConfirmation\" }, \"title\" : \"Requestedtoolconfirmations\" , \"type\" : \"object\" }, \"compaction\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/EventCompaction\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"endOfAgent\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Endofagent\" }, \"agentState\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Agentstate\" }, \"rewindBeforeInvocationId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Rewindbeforeinvocationid\" } }, \"$defs\" : { \"APIKey\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"apiKey\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"in\" : { \"$ref\" : \"#/$defs/APIKeyIn\" }, \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" } }, \"required\" : [ \"in\" , \"name\" ], \"title\" : \"APIKey\" , \"type\" : \"object\" }, \"APIKeyIn\" : { \"enum\" : [ \"query\" , \"header\" , \"cookie\" ], \"title\" : \"APIKeyIn\" , \"type\" : \"string\" }, \"AuthConfig\" : { \"additionalProperties\" : true , \"description\" : \"The auth config sent by tool asking client to collect auth credentials and\\n\\nadk and client will help to fill in the response\" , \"properties\" : { \"authScheme\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/APIKey\" }, { \"$ref\" : \"#/$defs/HTTPBase\" }, { \"$ref\" : \"#/$defs/OAuth2\" }, { \"$ref\" : \"#/$defs/OpenIdConnect\" }, { \"$ref\" : \"#/$defs/HTTPBearer\" }, { \"$ref\" : \"#/$defs/OpenIdConnectWithConfig\" } ], \"title\" : \"Authscheme\" }, \"rawAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"exchangedAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"credentialKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Credentialkey\" } }, \"required\" : [ \"authScheme\" ], \"title\" : \"AuthConfig\" , \"type\" : \"object\" }, \"AuthCredential\" : { \"additionalProperties\" : true , \"description\" : \"Data class representing an authentication credential.\\n\\nTo exchange for the actual credential, please use\\nCredentialExchanger.exchange_credential().\\n\\nExamples: API Key Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    api_key=\\\"1234\\\",\\n)\\n\\nExample: HTTP Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"basic\\\",\\n        credentials=HttpCredentials(username=\\\"user\\\", password=\\\"password\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Bearer Token in HTTP Header\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"bearer\\\",\\n        credentials=HttpCredentials(token=\\\"eyAkaknabna....\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Auth with Authorization Code Flow\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OAUTH2,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n    ),\\n)\\n\\nExample: OpenID Connect Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OPEN_ID_CONNECT,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n        redirect_uri=\\\"https://example.com\\\",\\n        scopes=[\\\"scope1\\\", \\\"scope2\\\"],\\n    ),\\n)\\n\\nExample: Auth with resource reference\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    resource_ref=\\\"projects/1234/locations/us-central1/resources/resource1\\\",\\n)\" , \"properties\" : { \"authType\" : { \"$ref\" : \"#/$defs/AuthCredentialTypes\" }, \"resourceRef\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Resourceref\" }, \"apiKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Apikey\" }, \"http\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HttpAuth\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"serviceAccount\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccount\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"oauth2\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuth2Auth\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"required\" : [ \"authType\" ], \"title\" : \"AuthCredential\" , \"type\" : \"object\" }, \"AuthCredentialTypes\" : { \"description\" : \"Represents the type of authentication credential.\" , \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" , \"serviceAccount\" ], \"title\" : \"AuthCredentialTypes\" , \"type\" : \"string\" }, \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"Content\" : { \"additionalProperties\" : false , \"description\" : \"Contains the multi-part content of a message.\" , \"properties\" : { \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Part\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a single message. Each part may have\\n      a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The producer of the content. Must be either 'user' or\\n      'model'. Useful to set for multi-turn conversations, otherwise can be\\n      empty. If role is not specified, SDK will determine the role.\" , \"title\" : \"Role\" } }, \"title\" : \"Content\" , \"type\" : \"object\" }, \"EventCompaction\" : { \"additionalProperties\" : false , \"description\" : \"The compaction of the events.\" , \"properties\" : { \"startTimestamp\" : { \"title\" : \"Starttimestamp\" , \"type\" : \"number\" }, \"endTimestamp\" : { \"title\" : \"Endtimestamp\" , \"type\" : \"number\" }, \"compactedContent\" : { \"$ref\" : \"#/$defs/Content\" } }, \"required\" : [ \"startTimestamp\" , \"endTimestamp\" , \"compactedContent\" ], \"title\" : \"EventCompaction\" , \"type\" : \"object\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"HTTPBase\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" } }, \"required\" : [ \"scheme\" ], \"title\" : \"HTTPBase\" , \"type\" : \"object\" }, \"HTTPBearer\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"const\" : \"bearer\" , \"default\" : \"bearer\" , \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"bearerFormat\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Bearerformat\" } }, \"title\" : \"HTTPBearer\" , \"type\" : \"object\" }, \"HttpAuth\" : { \"additionalProperties\" : true , \"description\" : \"The credentials and metadata for HTTP authentication.\" , \"properties\" : { \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"credentials\" : { \"$ref\" : \"#/$defs/HttpCredentials\" } }, \"required\" : [ \"scheme\" , \"credentials\" ], \"title\" : \"HttpAuth\" , \"type\" : \"object\" }, \"HttpCredentials\" : { \"additionalProperties\" : true , \"description\" : \"Represents the secret token value for HTTP authentication, like user name, password, oauth token, etc.\" , \"properties\" : { \"username\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Username\" }, \"password\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Password\" }, \"token\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token\" } }, \"title\" : \"HttpCredentials\" , \"type\" : \"object\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"OAuth2\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"oauth2\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"flows\" : { \"$ref\" : \"#/$defs/OAuthFlows\" } }, \"required\" : [ \"flows\" ], \"title\" : \"OAuth2\" , \"type\" : \"object\" }, \"OAuth2Auth\" : { \"additionalProperties\" : true , \"description\" : \"Represents credential value and its metadata for a OAuth2 credential.\" , \"properties\" : { \"clientId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientid\" }, \"clientSecret\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientsecret\" }, \"authUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authuri\" }, \"state\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"State\" }, \"redirectUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Redirecturi\" }, \"authResponseUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authresponseuri\" }, \"authCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authcode\" }, \"accessToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Accesstoken\" }, \"refreshToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshtoken\" }, \"expiresAt\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresat\" }, \"expiresIn\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresin\" }, \"audience\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Audience\" } }, \"title\" : \"OAuth2Auth\" , \"type\" : \"object\" }, \"OAuthFlowAuthorizationCode\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" , \"tokenUrl\" ], \"title\" : \"OAuthFlowAuthorizationCode\" , \"type\" : \"object\" }, \"OAuthFlowClientCredentials\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowClientCredentials\" , \"type\" : \"object\" }, \"OAuthFlowImplicit\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" ], \"title\" : \"OAuthFlowImplicit\" , \"type\" : \"object\" }, \"OAuthFlowPassword\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowPassword\" , \"type\" : \"object\" }, \"OAuthFlows\" : { \"additionalProperties\" : true , \"properties\" : { \"implicit\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowImplicit\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"password\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowPassword\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"clientCredentials\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowClientCredentials\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"authorizationCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowAuthorizationCode\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"title\" : \"OAuthFlows\" , \"type\" : \"object\" }, \"OpenIdConnect\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"openIdConnectUrl\" : { \"title\" : \"Openidconnecturl\" , \"type\" : \"string\" } }, \"required\" : [ \"openIdConnectUrl\" ], \"title\" : \"OpenIdConnect\" , \"type\" : \"object\" }, \"OpenIdConnectWithConfig\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"authorization_endpoint\" : { \"title\" : \"Authorization Endpoint\" , \"type\" : \"string\" }, \"token_endpoint\" : { \"title\" : \"Token Endpoint\" , \"type\" : \"string\" }, \"userinfo_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Userinfo Endpoint\" }, \"revocation_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Revocation Endpoint\" }, \"token_endpoint_auth_methods_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token Endpoint Auth Methods Supported\" }, \"grant_types_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Grant Types Supported\" }, \"scopes\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Scopes\" } }, \"required\" : [ \"authorization_endpoint\" , \"token_endpoint\" ], \"title\" : \"OpenIdConnectWithConfig\" , \"type\" : \"object\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"SecuritySchemeType\" : { \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" ], \"title\" : \"SecuritySchemeType\" , \"type\" : \"string\" }, \"ServiceAccount\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\" , \"properties\" : { \"serviceAccountCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccountCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"scopes\" : { \"items\" : { \"type\" : \"string\" }, \"title\" : \"Scopes\" , \"type\" : \"array\" }, \"useDefaultCredential\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : false , \"title\" : \"Usedefaultcredential\" } }, \"required\" : [ \"scopes\" ], \"title\" : \"ServiceAccount\" , \"type\" : \"object\" }, \"ServiceAccountCredential\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\\n\\nAttributes:\\n  type: The type should be \\\"service_account\\\".\\n  project_id: The project ID.\\n  private_key_id: The ID of the private key.\\n  private_key: The private key.\\n  client_email: The client email.\\n  client_id: The client ID.\\n  auth_uri: The authorization URI.\\n  token_uri: The token URI.\\n  auth_provider_x509_cert_url: URL for auth provider's X.509 cert.\\n  client_x509_cert_url: URL for the client's X.509 cert.\\n  universe_domain: The universe domain.\\n\\nExample:\\n\\n    config = ServiceAccountCredential(\\n        type_=\\\"service_account\\\",\\n        project_id=\\\"your_project_id\\\",\\n        private_key_id=\\\"your_private_key_id\\\",\\n        private_key=\\\"-----BEGIN PRIVATE KEY-----...\\\",\\n        client_email=\\\"...@....iam.gserviceaccount.com\\\",\\n        client_id=\\\"your_client_id\\\",\\n        auth_uri=\\\"https://accounts.google.com/o/oauth2/auth\\\",\\n        token_uri=\\\"https://oauth2.googleapis.com/token\\\",\\n        auth_provider_x509_cert_url=\\\"https://www.googleapis.com/oauth2/v1/certs\\\",\\n        client_x509_cert_url=\\\"https://www.googleapis.com/robot/v1/metadata/x509/...\\\",\\n        universe_domain=\\\"googleapis.com\\\"\\n    )\\n\\n\\n    config = ServiceAccountConfig.model_construct(**{\\n        ...service account config dict\\n    })\" , \"properties\" : { \"type\" : { \"default\" : \"\" , \"title\" : \"Type\" , \"type\" : \"string\" }, \"projectId\" : { \"title\" : \"Projectid\" , \"type\" : \"string\" }, \"privateKeyId\" : { \"title\" : \"Privatekeyid\" , \"type\" : \"string\" }, \"privateKey\" : { \"title\" : \"Privatekey\" , \"type\" : \"string\" }, \"clientEmail\" : { \"title\" : \"Clientemail\" , \"type\" : \"string\" }, \"clientId\" : { \"title\" : \"Clientid\" , \"type\" : \"string\" }, \"authUri\" : { \"title\" : \"Authuri\" , \"type\" : \"string\" }, \"tokenUri\" : { \"title\" : \"Tokenuri\" , \"type\" : \"string\" }, \"authProviderX509CertUrl\" : { \"title\" : \"Authproviderx509Certurl\" , \"type\" : \"string\" }, \"clientX509CertUrl\" : { \"title\" : \"Clientx509Certurl\" , \"type\" : \"string\" }, \"universeDomain\" : { \"title\" : \"Universedomain\" , \"type\" : \"string\" } }, \"required\" : [ \"projectId\" , \"privateKeyId\" , \"privateKey\" , \"clientEmail\" , \"clientId\" , \"authUri\" , \"tokenUri\" , \"authProviderX509CertUrl\" , \"clientX509CertUrl\" , \"universeDomain\" ], \"title\" : \"ServiceAccountCredential\" , \"type\" : \"object\" }, \"ToolConfirmation\" : { \"additionalProperties\" : false , \"description\" : \"Represents a tool confirmation configuration.\" , \"properties\" : { \"hint\" : { \"default\" : \"\" , \"title\" : \"Hint\" , \"type\" : \"string\" }, \"confirmed\" : { \"default\" : false , \"title\" : \"Confirmed\" , \"type\" : \"boolean\" }, \"payload\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Payload\" } }, \"title\" : \"ToolConfirmation\" , \"type\" : \"object\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" } }, \"additionalProperties\" : false } Fields : agent_state (dict[str, Any] | None) artifact_delta (dict[str, int]) compaction (google.adk.events.event_actions.EventCompaction | None) end_of_agent (bool | None) escalate (bool | None) requested_auth_configs (dict[str, google.adk.auth.auth_tool.AuthConfig]) requested_tool_confirmations (dict[str, google.adk.tools.tool_confirmation.ToolConfirmation]) rewind_before_invocation_id (str | None) skip_summarization (bool | None) state_delta (dict[str, object]) transfer_to_agent (str | None) field agent_state : Optional[dict[str, Any]] = None (alias 'agentState') \u00b6 The agent state at the current event. field artifact_delta : dict[str, int] [Optional] (alias 'artifactDelta') \u00b6 Indicates that the event is updating an artifact. key is the filename,\nvalue is the version. field compaction : Optional[EventCompaction] = None \u00b6 The compaction of the events. field end_of_agent : Optional[bool] = None (alias 'endOfAgent') \u00b6 If true, the current agent has finished its current run. Note that there\ncan be multiple events with end_of_agent=True for the same agent within one\ninvocation when there is a loop. field escalate : Optional[bool] = None \u00b6 The agent is escalating to a higher level agent. field requested_auth_configs : dict[str, AuthConfig] [Optional] (alias 'requestedAuthConfigs') \u00b6 Authentication configurations requested by tool responses. This field will only be set by a tool response event indicating tool request\nauth credential.\n- Keys: The function call id. Since one function response event could contain\nmultiple function responses that correspond to multiple function calls. Each\nfunction call could request different auth configs. This id is used to\nidentify the function call.\n- Values: The requested auth config. field requested_tool_confirmations : dict[str, ToolConfirmation] [Optional] (alias 'requestedToolConfirmations') \u00b6 A dict of tool confirmation requested by this event, keyed by\nfunction call id. field rewind_before_invocation_id : Optional[str] = None (alias 'rewindBeforeInvocationId') \u00b6 The invocation id to rewind to. This is only set for rewind event. field skip_summarization : Optional[bool] = None (alias 'skipSummarization') \u00b6 If true, it won\u2019t call model to summarize function response. Only used for function_response event. field state_delta : dict[str, object] [Optional] (alias 'stateDelta') \u00b6 Indicates that the event is updating the state with the given delta. field transfer_to_agent : Optional[str] = None (alias 'transferToAgent') \u00b6 If set, the event transfers to the specified agent. ", "code_blocks": []}, {"heading_path": ["google.adk.examples module\u00b6"], "text": "google.adk.examples module \u00b6 class google.adk.examples. BaseExampleProvider \u00b6 Bases: ABC Base class for example providers. This class defines the interface for providing examples for a given query. abstractmethod get_examples ( query ) \u00b6 Returns a list of examples for a given query. Return type : list [ Example ] Parameters : query \u2013 The query to get examples for. Returns : A list of Example objects. pydantic model google.adk.examples. Example \u00b6 Bases: BaseModel A few-shot example. input \u00b6 The input content for the example. output \u00b6 The expected output content for the example. Show JSON schema { \"title\" : \"Example\" , \"description\" : \"A few-shot example.\\n\\nAttributes:\\n  input: The input content for the example.\\n  output: The expected output content for the example.\" , \"type\" : \"object\" , \"properties\" : { \"input\" : { \"$ref\" : \"#/$defs/Content\" }, \"output\" : { \"items\" : { \"$ref\" : \"#/$defs/Content\" }, \"title\" : \"Output\" , \"type\" : \"array\" } }, \"$defs\" : { \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"Content\" : { \"additionalProperties\" : false , \"description\" : \"Contains the multi-part content of a message.\" , \"properties\" : { \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Part\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a single message. Each part may have\\n      a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The producer of the content. Must be either 'user' or\\n      'model'. Useful to set for multi-turn conversations, otherwise can be\\n      empty. If role is not specified, SDK will determine the role.\" , \"title\" : \"Role\" } }, \"title\" : \"Content\" , \"type\" : \"object\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" } }, \"required\" : [ \"input\" , \"output\" ] } Fields : input (google.genai.types.Content) output (list[google.genai.types.Content]) field input : Content [Required] \u00b6 field output : list [ Content ] [Required] \u00b6 class google.adk.examples. VertexAiExampleStore ( examples_store_name ) \u00b6 Bases: BaseExampleProvider Provides examples from Vertex example store. Initializes the VertexAiExampleStore. Parameters : examples_store_name \u2013 The resource name of the vertex example store, in\nthe format of projects/{project}/locations/{location}/exampleStores/{example_store} . get_examples ( query ) \u00b6 Returns a list of examples for a given query. Return type : list [ Example ] Parameters : query \u2013 The query to get examples for. Returns : A list of Example objects. ", "code_blocks": []}, {"heading_path": ["google.adk.flows module\u00b6"], "text": "google.adk.flows module \u00b6 ", "code_blocks": []}, {"heading_path": ["google.adk.memory module\u00b6"], "text": "google.adk.memory module \u00b6 class google.adk.memory. BaseMemoryService \u00b6 Bases: ABC Base class for memory services. The service provides functionalities to ingest sessions into memory so that\nthe memory can be used for user queries. abstractmethod async add_session_to_memory ( session ) \u00b6 Adds a session to the memory service. A session may be added multiple times during its lifetime. Parameters : session \u2013 The session to add. abstractmethod async search_memory ( * , app_name , user_id , query ) \u00b6 Searches for sessions that match the query. Return type : SearchMemoryResponse Parameters : app_name \u2013 The name of the application. user_id \u2013 The id of the user. query \u2013 The query to search for. Returns : A SearchMemoryResponse containing the matching memories. class google.adk.memory. InMemoryMemoryService \u00b6 Bases: BaseMemoryService An in-memory memory service for prototyping purpose only. Uses keyword matching instead of semantic search. This class is thread-safe, however, it should be used for testing and\ndevelopment only. async add_session_to_memory ( session ) \u00b6 Adds a session to the memory service. A session may be added multiple times during its lifetime. Parameters : session \u2013 The session to add. async search_memory ( * , app_name , user_id , query ) \u00b6 Searches for sessions that match the query. Return type : SearchMemoryResponse Parameters : app_name \u2013 The name of the application. user_id \u2013 The id of the user. query \u2013 The query to search for. Returns : A SearchMemoryResponse containing the matching memories. class google.adk.memory. VertexAiMemoryBankService ( project = None , location = None , agent_engine_id = None ) \u00b6 Bases: BaseMemoryService Implementation of the BaseMemoryService using Vertex AI Memory Bank. Initializes a VertexAiMemoryBankService. Parameters : project \u2013 The project ID of the Memory Bank to use. location \u2013 The location of the Memory Bank to use. agent_engine_id \u2013 The ID of the agent engine to use for the Memory Bank.\ne.g. \u2018456\u2019 in\n\u2018projects/my-project/locations/us-central1/reasoningEngines/456\u2019. async add_session_to_memory ( session ) \u00b6 Adds a session to the memory service. A session may be added multiple times during its lifetime. Parameters : session \u2013 The session to add. async search_memory ( * , app_name , user_id , query ) \u00b6 Searches for sessions that match the query. Parameters : app_name \u2013 The name of the application. user_id \u2013 The id of the user. query \u2013 The query to search for. Returns : A SearchMemoryResponse containing the matching memories. class google.adk.memory. VertexAiRagMemoryService ( rag_corpus = None , similarity_top_k = None , vector_distance_threshold = 10 ) \u00b6 Bases: BaseMemoryService A memory service that uses Vertex AI RAG for storage and retrieval. Initializes a VertexAiRagMemoryService. Parameters : rag_corpus \u2013 The name of the Vertex AI RAG corpus to use. Format: projects/{project}/locations/{location}/ragCorpora/{rag_corpus_id} or {rag_corpus_id} similarity_top_k \u2013 The number of contexts to retrieve. vector_distance_threshold \u2013 Only returns contexts with vector distance\nsmaller than the threshold.. async add_session_to_memory ( session ) \u00b6 Adds a session to the memory service. A session may be added multiple times during its lifetime. Parameters : session \u2013 The session to add. async search_memory ( * , app_name , user_id , query ) \u00b6 Searches for sessions that match the query using rag.retrieval_query. Return type : SearchMemoryResponse ", "code_blocks": []}, {"heading_path": ["google.adk.models module\u00b6"], "text": "google.adk.models module \u00b6 Defines the interface to support a model. pydantic model google.adk.models. BaseLlm \u00b6 Bases: BaseModel The BaseLLM class. Show JSON schema { \"title\" : \"BaseLlm\" , \"description\" : \"The BaseLLM class.\" , \"type\" : \"object\" , \"properties\" : { \"model\" : { \"title\" : \"Model\" , \"type\" : \"string\" } }, \"required\" : [ \"model\" ] } Fields : model (str) field model : str [Required] \u00b6 The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro. classmethod supported_models ( ) \u00b6 Returns a list of supported models in regex for LlmRegistry. Return type : list [ str ] connect ( llm_request ) \u00b6 Creates a live connection to the LLM. Return type : BaseLlmConnection Parameters : llm_request \u2013 LlmRequest, the request to send to the LLM. Returns : BaseLlmConnection, the connection to the LLM. abstractmethod async generate_content_async ( llm_request , stream = False ) \u00b6 Generates one content from the given contents and tools. Return type : AsyncGenerator [ LlmResponse , None ] Parameters : llm_request \u2013 LlmRequest, the request to send to the LLM. stream \u2013 bool = False, whether to do streaming call. Yields : a generator of types.Content. For non-streaming call, it will only yield one Content. For streaming call, it may yield more than one content, but all yielded\ncontents should be treated as one content by merging the\nparts list. pydantic model google.adk.models. Gemini \u00b6 Bases: BaseLlm Integration for Gemini models. model \u00b6 The name of the Gemini model. Show JSON schema { \"title\" : \"Gemini\" , \"description\" : \"Integration for Gemini models.\\n\\nAttributes:\\n  model: The name of the Gemini model.\" , \"type\" : \"object\" , \"properties\" : { \"model\" : { \"default\" : \"gemini-2.5-flash\" , \"title\" : \"Model\" , \"type\" : \"string\" }, \"retry_options\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HttpRetryOptions\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"$defs\" : { \"HttpRetryOptions\" : { \"additionalProperties\" : false , \"description\" : \"HTTP retry options to be used in each of the requests.\" , \"properties\" : { \"attempts\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Maximum number of attempts, including the original request.\\n      If 0 or 1, it means no retries.\" , \"title\" : \"Attempts\" }, \"initialDelay\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Initial delay before the first retry, in fractions of a second.\" , \"title\" : \"Initialdelay\" }, \"maxDelay\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Maximum delay between retries, in fractions of a second.\" , \"title\" : \"Maxdelay\" }, \"expBase\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Multiplier by which the delay increases after each attempt.\" , \"title\" : \"Expbase\" }, \"jitter\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Randomness factor for the delay.\" , \"title\" : \"Jitter\" }, \"httpStatusCodes\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"integer\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of HTTP status codes that should trigger a retry.\\n      If not specified, a default set of retryable codes may be used.\" , \"title\" : \"Httpstatuscodes\" } }, \"title\" : \"HttpRetryOptions\" , \"type\" : \"object\" } } } Fields : model (str) retry_options (Optional[types.HttpRetryOptions]) field model : str = 'gemini-2.5-flash' \u00b6 The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro. field retry_options : Optional[types.HttpRetryOptions] = None \u00b6 Allow Gemini to retry failed responses. Sample: `` ` python\nfrom google.genai import types # \u2026 agent = Agent( model=Gemini( retry_options=types.HttpRetryOptions(initial_delay=1, attempts=2), ) ", "code_blocks": []}, {"heading_path": [")\u00b6"], "text": ") \u00b6 classmethod supported_models ( ) \u00b6 Provides the list of supported models. Return type : list [ str ] Returns : A list of supported models. connect ( llm_request ) \u00b6 Connects to the Gemini model and returns an llm connection. Return type : BaseLlmConnection Parameters : llm_request \u2013 LlmRequest, the request to send to the Gemini model. Yields : BaseLlmConnection, the connection to the Gemini model. async generate_content_async ( llm_request , stream = False ) \u00b6 Sends a request to the Gemini model. Return type : AsyncGenerator [ LlmResponse , None ] Parameters : llm_request \u2013 LlmRequest, the request to send to the Gemini model. stream \u2013 bool = False, whether to do streaming call. Yields : LlmResponse \u2013 The model response. property api_client : Client \u00b6 Provides the api client. Returns : The api client. pydantic model google.adk.models. Gemma \u00b6 Bases: Gemini Integration for Gemma models exposed via the Gemini API. Only Gemma 3 models are supported at this time. For agentic use cases,\nuse of gemma-3-27b-it and gemma-3-12b-it are strongly recommended. For full documentation, see: https://ai.google.dev/gemma/docs/core/ NOTE: Gemma does NOT support system instructions. Any system instructions\nwill be replaced with an initial user prompt in the LLM request. If system\ninstructions change over the course of agent execution, the initial content SHOULD be replaced. Special care is warranted here.\nSee: https://ai.google.dev/gemma/docs/core/prompt-structure#system-instructions NOTE: Gemma\u2019s function calling support is limited. It does not have full access to the\nsame built-in tools as Gemini. It also does not have special API support for tools and\nfunctions. Rather, tools must be passed in via a user prompt, and extracted from model\nresponses based on approximate shape. NOTE: Vertex AI API support for Gemma is not currently included. This ONLY supports\nusage via the Gemini API. Show JSON schema { \"title\" : \"Gemma\" , \"description\" : \"Integration for Gemma models exposed via the Gemini API.\\n\\nOnly Gemma 3 models are supported at this time. For agentic use cases,\\nuse of gemma-3-27b-it and gemma-3-12b-it are strongly recommended.\\n\\nFor full documentation, see: https://ai.google.dev/gemma/docs/core/\\n\\nNOTE: Gemma does **NOT** support system instructions. Any system instructions\\nwill be replaced with an initial *user* prompt in the LLM request. If system\\ninstructions change over the course of agent execution, the initial content\\n**SHOULD** be replaced. Special care is warranted here.\\nSee: https://ai.google.dev/gemma/docs/core/prompt-structure#system-instructions\\n\\nNOTE: Gemma's function calling support is limited. It does not have full access to the\\nsame built-in tools as Gemini. It also does not have special API support for tools and\\nfunctions. Rather, tools must be passed in via a `user` prompt, and extracted from model\\nresponses based on approximate shape.\\n\\nNOTE: Vertex AI API support for Gemma is not currently included. This **ONLY** supports\\nusage via the Gemini API.\" , \"type\" : \"object\" , \"properties\" : { \"model\" : { \"default\" : \"gemma-3-27b-it\" , \"title\" : \"Model\" , \"type\" : \"string\" }, \"retry_options\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HttpRetryOptions\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"$defs\" : { \"HttpRetryOptions\" : { \"additionalProperties\" : false , \"description\" : \"HTTP retry options to be used in each of the requests.\" , \"properties\" : { \"attempts\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Maximum number of attempts, including the original request.\\n      If 0 or 1, it means no retries.\" , \"title\" : \"Attempts\" }, \"initialDelay\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Initial delay before the first retry, in fractions of a second.\" , \"title\" : \"Initialdelay\" }, \"maxDelay\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Maximum delay between retries, in fractions of a second.\" , \"title\" : \"Maxdelay\" }, \"expBase\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Multiplier by which the delay increases after each attempt.\" , \"title\" : \"Expbase\" }, \"jitter\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Randomness factor for the delay.\" , \"title\" : \"Jitter\" }, \"httpStatusCodes\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"integer\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of HTTP status codes that should trigger a retry.\\n      If not specified, a default set of retryable codes may be used.\" , \"title\" : \"Httpstatuscodes\" } }, \"title\" : \"HttpRetryOptions\" , \"type\" : \"object\" } } } Fields : model (str) field model : str = 'gemma-3-27b-it' \u00b6 The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro. classmethod supported_models ( ) \u00b6 Provides the list of supported models. Returns:\nA list of supported models. Return type : list [ str ] async generate_content_async ( llm_request , stream = False ) \u00b6 Sends a request to the Gemma model. Return type : AsyncGenerator [ LlmResponse , None ] Parameters : llm_request \u2013 LlmRequest, the request to send to the Gemini model. stream \u2013 bool = False, whether to do streaming call. Yields : LlmResponse \u2013 The model response. class google.adk.models. LLMRegistry \u00b6 Bases: object Registry for LLMs. static new_llm ( model ) \u00b6 Creates a new LLM instance. Return type : BaseLlm Parameters : model \u2013 The model name. Returns : The LLM instance. static register ( llm_cls ) \u00b6 Registers a new LLM class. Parameters : llm_cls \u2013 The class that implements the model. static resolve ( model ) \u00b6 Resolves the model to a BaseLlm subclass. Return type : type [ BaseLlm ] Parameters : model \u2013 The model name. Returns : The BaseLlm subclass. Raises : ValueError \u2013 If the model is not found. ", "code_blocks": []}, {"heading_path": ["google.adk.planners module\u00b6"], "text": "google.adk.planners module \u00b6 class google.adk.planners. BasePlanner \u00b6 Bases: ABC Abstract base class for all planners. The planner allows the agent to generate plans for the queries to guide its\naction. abstractmethod build_planning_instruction ( readonly_context , llm_request ) \u00b6 Builds the system instruction to be appended to the LLM request for planning. Return type : Optional [ str ] Parameters : readonly_context \u2013 The readonly context of the invocation. llm_request \u2013 The LLM request. Readonly. Returns : The planning system instruction, or None if no instruction is needed. abstractmethod process_planning_response ( callback_context , response_parts ) \u00b6 Processes the LLM response for planning. Return type : Optional [ List [ Part ]] Parameters : callback_context \u2013 The callback context of the invocation. response_parts \u2013 The LLM response parts. Readonly. Returns : The processed response parts, or None if no processing is needed. class google.adk.planners. BuiltInPlanner ( * , thinking_config ) \u00b6 Bases: BasePlanner The built-in planner that uses model\u2019s built-in thinking features. thinking_config \u00b6 Config for model built-in thinking features. An error\nwill be returned if this field is set for models that don\u2019t support\nthinking. Initializes the built-in planner. Parameters : thinking_config \u2013 Config for model built-in thinking features. An error\nwill be returned if this field is set for models that don\u2019t support\nthinking. apply_thinking_config ( llm_request ) \u00b6 Applies the thinking config to the LLM request. Return type : None Parameters : llm_request \u2013 The LLM request to apply the thinking config to. build_planning_instruction ( readonly_context , llm_request ) \u00b6 Builds the system instruction to be appended to the LLM request for planning. Return type : Optional [ str ] Parameters : readonly_context \u2013 The readonly context of the invocation. llm_request \u2013 The LLM request. Readonly. Returns : The planning system instruction, or None if no instruction is needed. process_planning_response ( callback_context , response_parts ) \u00b6 Processes the LLM response for planning. Return type : Optional [ List [ Part ]] Parameters : callback_context \u2013 The callback context of the invocation. response_parts \u2013 The LLM response parts. Readonly. Returns : The processed response parts, or None if no processing is needed. thinking_config : ThinkingConfig \u00b6 Config for model built-in thinking features. An error will be returned if this\nfield is set for models that don\u2019t support thinking. class google.adk.planners. PlanReActPlanner \u00b6 Bases: BasePlanner Plan-Re-Act planner that constrains the LLM response to generate a plan before any action/observation. Note: this planner does not require the model to support built-in thinking\nfeatures or setting the thinking config. build_planning_instruction ( readonly_context , llm_request ) \u00b6 Builds the system instruction to be appended to the LLM request for planning. Return type : str Parameters : readonly_context \u2013 The readonly context of the invocation. llm_request \u2013 The LLM request. Readonly. Returns : The planning system instruction, or None if no instruction is needed. process_planning_response ( callback_context , response_parts ) \u00b6 Processes the LLM response for planning. Return type : Optional [ List [ Part ]] Parameters : callback_context \u2013 The callback context of the invocation. response_parts \u2013 The LLM response parts. Readonly. Returns : The processed response parts, or None if no processing is needed. ", "code_blocks": []}, {"heading_path": ["google.adk.platform module\u00b6"], "text": "google.adk.platform module \u00b6 ", "code_blocks": []}, {"heading_path": ["google.adk.plugins module\u00b6"], "text": "google.adk.plugins module \u00b6 class google.adk.plugins. BasePlugin ( name ) \u00b6 Bases: ABC Base class for creating plugins. Plugins provide a structured way to intercept and modify agent, tool, and\nLLM behaviors at critical execution points in a callback manner. While agent\ncallbacks apply to a particular agent, plugins applies globally to all\nagents added in the runner. Plugins are best used for adding custom behaviors\nlike logging, monitoring, caching, or modifying requests and responses at key\nstages. A plugin can implement one or more methods of callbacks, but should not\nimplement the same method of callback for multiple times. Relation with [Agent callbacks]( https://google.github.io/adk-docs/callbacks/ ): Execution Order Similar to Agent callbacks, Plugins are executed in the order they are\nregistered. However, Plugin and Agent Callbacks are executed sequentially,\nwith Plugins takes precedence over agent callbacks. When the callback in a\nplugin returns a value, it will short circuit all remaining plugins and\nagent callbacks, causing all remaining plugins and agent callbacks\nto be skipped. Change Propagation Plugins and agent callbacks can both modify the value of the input parameters,\nincluding agent input, tool input, and LLM request/response, etc. They work in\nthe exactly same way. The modifications will be visible and passed to the next\ncallback in the chain. For example, if a plugin modifies the tool input with\nbefore_tool_callback, the modified tool input will be passed to the\nbefore_tool_callback of the next plugin, and further passed to the agent\ncallbacks if not short circuited. To use a plugin, implement the desired callback methods and pass an instance\nof your custom plugin class to the ADK Runner. Examples A simple plugin that logs every tool call. >>> class ToolLoggerPlugin ( BasePlugin ): ..   def __init__(self): ..     super().__init__(name=\"tool_logger\") .. ..   async def before_tool_callback( ..       self, *, tool: BaseTool, tool_args: dict[str, Any], tool_context: ToolContext ..   ): ..     print(f\"[{self.name}] Calling tool '{tool.name}' with args: {tool_args}\") .. ..   async def after_tool_callback( ..       self, *, tool: BaseTool, tool_args: dict, tool_context: ToolContext, result: dict ..   ): ..     print(f\"[{self.name}] Tool '{tool.name}' finished with result: {result}\") .. >>> # Add the plugin to ADK Runner >>> # runner = Runner( >>> #     ... >>> #     plugins=[ToolLoggerPlugin(), AgentPolicyPlugin()], >>> # ) Initializes the plugin. Parameters : name \u2013 A unique identifier for this plugin instance. async after_agent_callback ( * , agent , callback_context ) \u00b6 Callback executed after an agent\u2019s primary logic has completed. Return type : Optional [ Content ] Parameters : agent \u2013 The agent that has just run. callback_context \u2013 The context for the agent invocation. Returns : An optional types.Content object. The content to return to the user.\nWhen the content is present, the provided content will be used as agent\nresponse and appended to event history as agent response. async after_model_callback ( * , callback_context , llm_response ) \u00b6 Callback executed after a response is received from the model. This is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw LlmResponse . Return type : Optional [ LlmResponse ] Parameters : callback_context \u2013 The context for the current agent call. llm_response \u2013 The response object received from the model. Returns : An optional value. A non- None return may be used by the framework to\nmodify or replace the response. Returning None allows the original\nresponse to be used. async after_run_callback ( * , invocation_context ) \u00b6 Callback executed after an ADK runner run has completed. This is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks. Return type : None Parameters : invocation_context \u2013 The context for the entire invocation. Returns : None async after_tool_callback ( * , tool , tool_args , tool_context , result ) \u00b6 Callback executed after a tool has been called. This callback allows for inspecting, logging, or modifying the result\nreturned by a tool. Return type : Optional [ dict ] Parameters : tool \u2013 The tool instance that has just been executed. tool_args \u2013 The original arguments that were passed to the tool. tool_context \u2013 The context specific to the tool execution. result \u2013 The dictionary returned by the tool invocation. Returns : An optional dictionary. If a dictionary is returned, it will replace the original result from the tool. This allows for post-processing or\naltering tool outputs. Returning None uses the original, unmodified\nresult. async before_agent_callback ( * , agent , callback_context ) \u00b6 Callback executed before an agent\u2019s primary logic is invoked. This callback can be used for logging, setup, or to short-circuit the\nagent\u2019s execution by returning a value. Return type : Optional [ Content ] Parameters : agent \u2013 The agent that is about to run. callback_context \u2013 The context for the agent invocation. Returns : An optional types.Content object. If a value is returned, it will bypass\nthe agent\u2019s callbacks and its execution, and return this value directly.\nReturning None allows the agent to proceed normally. async before_model_callback ( * , callback_context , llm_request ) \u00b6 Callback executed before a request is sent to the model. This provides an opportunity to inspect, log, or modify the LlmRequest object. It can also be used to implement caching by returning a cached LlmResponse , which would skip the actual model call. Return type : Optional [ LlmResponse ] Parameters : callback_context \u2013 The context for the current agent call. llm_request \u2013 The prepared request object to be sent to the model. Returns : An optional value. The interpretation of a non- None trigger an early\nexit and returns the response immediately. Returning None allows the LLM\nrequest to proceed normally. async before_run_callback ( * , invocation_context ) \u00b6 Callback executed before the ADK runner runs. This is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks. Return type : Optional [ Content ] Parameters : invocation_context \u2013 The context for the entire invocation, containing\nsession information, the root agent, etc. Returns : An optional Event to be returned to the ADK. Returning a value to\nhalt execution of the runner and ends the runner with that event. Return None to proceed normally. async before_tool_callback ( * , tool , tool_args , tool_context ) \u00b6 Callback executed before a tool is called. This callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool. Return type : Optional [ dict ] Parameters : tool \u2013 The tool instance that is about to be executed. tool_args \u2013 The dictionary of arguments to be used for invoking the tool. tool_context \u2013 The context specific to the tool execution. Returns : An optional dictionary. If a dictionary is returned, it will stop the tool\nexecution and return this response immediately. Returning None uses the\noriginal, unmodified arguments. async on_event_callback ( * , invocation_context , event ) \u00b6 Callback executed after an event is yielded from runner. This is the ideal place to make modification to the event before the event\nis handled by the underlying agent app. Return type : Optional [ Event ] Parameters : invocation_context \u2013 The context for the entire invocation. event \u2013 The event raised by the runner. Returns : An optional value. A non- None return may be used by the framework to\nmodify or replace the response. Returning None allows the original\nresponse to be used. async on_model_error_callback ( * , callback_context , llm_request , error ) \u00b6 Callback executed when a model call encounters an error. This callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms. Return type : Optional [ LlmResponse ] Parameters : callback_context \u2013 The context for the current agent call. llm_request \u2013 The request that was sent to the model when the error\noccurred. error \u2013 The exception that was raised during model execution. Returns : An optional LlmResponse. If an LlmResponse is returned, it will be used\ninstead of propagating the error. Returning None allows the original\nerror to be raised. async on_tool_error_callback ( * , tool , tool_args , tool_context , error ) \u00b6 Callback executed when a tool call encounters an error. This callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms. Return type : Optional [ dict ] Parameters : tool \u2013 The tool instance that encountered an error. tool_args \u2013 The arguments that were passed to the tool. tool_context \u2013 The context specific to the tool execution. error \u2013 The exception that was raised during tool execution. Returns : An optional dictionary. If a dictionary is returned, it will be used as\nthe tool response instead of propagating the error. Returning None allows the original error to be raised. async on_user_message_callback ( * , invocation_context , user_message ) \u00b6 Callback executed when a user message is received before an invocation starts. This callback helps logging and modifying the user message before the\nrunner starts the invocation. Return type : Optional [ Content ] Parameters : invocation_context \u2013 The context for the entire invocation. user_message \u2013 The message content input by user. Returns : An optional types.Content to be returned to the ADK. Returning a\nvalue to replace the user message. Returning None to proceed\nnormally. class google.adk.plugins. LoggingPlugin ( name = 'logging_plugin' ) \u00b6 Bases: BasePlugin A plugin that logs important information at each callback point. This plugin helps printing all critical events in the console. It is not a\nreplacement of existing logging in ADK. It rather helps terminal based\ndebugging by showing all logs in the console, and serves as a simple demo for\neveryone to leverage when developing new plugins. This plugin helps users track the invocation status by logging:\n- User messages and invocation context\n- Agent execution flow\n- LLM requests and responses\n- Tool calls with arguments and results\n- Events and final responses\n- Errors during model and tool execution Example >>> logging_plugin = LoggingPlugin () >>> runner = Runner ( ... agents = [ my_agent ], ... # ... ... plugins = [ logging_plugin ], ... ) Initialize the logging plugin. Parameters : name \u2013 The name of the plugin instance. async after_agent_callback ( * , agent , callback_context ) \u00b6 Log agent execution completion. Return type : Optional [ Content ] async after_model_callback ( * , callback_context , llm_response ) \u00b6 Log LLM response after receiving from model. Return type : Optional [ LlmResponse ] async after_run_callback ( * , invocation_context ) \u00b6 Log invocation completion. Return type : None async after_tool_callback ( * , tool , tool_args , tool_context , result ) \u00b6 Log tool execution completion. Return type : Optional [ dict ] async before_agent_callback ( * , agent , callback_context ) \u00b6 Log agent execution start. Return type : Optional [ Content ] async before_model_callback ( * , callback_context , llm_request ) \u00b6 Log LLM request before sending to model. Return type : Optional [ LlmResponse ] async before_run_callback ( * , invocation_context ) \u00b6 Log invocation start. Return type : Optional [ Content ] async before_tool_callback ( * , tool , tool_args , tool_context ) \u00b6 Log tool execution start. Return type : Optional [ dict ] async on_event_callback ( * , invocation_context , event ) \u00b6 Log events yielded from the runner. Return type : Optional [ Event ] async on_model_error_callback ( * , callback_context , llm_request , error ) \u00b6 Log LLM error. Return type : Optional [ LlmResponse ] async on_tool_error_callback ( * , tool , tool_args , tool_context , error ) \u00b6 Log tool error. Return type : Optional [ dict ] async on_user_message_callback ( * , invocation_context , user_message ) \u00b6 Log user message and invocation start. Return type : Optional [ Content ] class google.adk.plugins. PluginManager ( plugins = None ) \u00b6 Bases: object Manages the registration and execution of plugins. The PluginManager is an internal class that orchestrates the invocation of\nplugin callbacks at key points in the SDK\u2019s execution lifecycle. It maintains\na list of registered plugins and ensures they are called in the order they\nwere registered. The core execution logic implements an \u201cearly exit\u201d strategy: if any plugin\ncallback returns a non- None value, the execution of subsequent plugins for\nthat specific event is halted, and the returned value is propagated up the\ncall stack. This allows plugins to short-circuit operations like agent runs,\ntool calls, or model requests. Initializes the plugin service. Parameters : plugins \u2013 An optional list of plugins to register upon initialization. get_plugin ( plugin_name ) \u00b6 Retrieves a registered plugin by its name. Return type : Optional [ BasePlugin ] Parameters : plugin_name \u2013 The name of the plugin to retrieve. Returns : The plugin instance if found, otherwise None . register_plugin ( plugin ) \u00b6 Registers a new plugin. Return type : None Parameters : plugin \u2013 The plugin instance to register. Raises : ValueError \u2013 If a plugin with the same name is already registered. async run_after_agent_callback ( * , agent , callback_context ) \u00b6 Runs the after_agent_callback for all plugins. Return type : Optional [ Content ] async run_after_model_callback ( * , callback_context , llm_response ) \u00b6 Runs the after_model_callback for all plugins. Return type : Optional [ LlmResponse ] async run_after_run_callback ( * , invocation_context ) \u00b6 Runs the after_run_callback for all plugins. Return type : None async run_after_tool_callback ( * , tool , tool_args , tool_context , result ) \u00b6 Runs the after_tool_callback for all plugins. Return type : Optional [ dict ] async run_before_agent_callback ( * , agent , callback_context ) \u00b6 Runs the before_agent_callback for all plugins. Return type : Optional [ Content ] async run_before_model_callback ( * , callback_context , llm_request ) \u00b6 Runs the before_model_callback for all plugins. Return type : Optional [ LlmResponse ] async run_before_run_callback ( * , invocation_context ) \u00b6 Runs the before_run_callback for all plugins. Return type : Optional [ Content ] async run_before_tool_callback ( * , tool , tool_args , tool_context ) \u00b6 Runs the before_tool_callback for all plugins. Return type : Optional [ dict ] async run_on_event_callback ( * , invocation_context , event ) \u00b6 Runs the on_event_callback for all plugins. Return type : Optional [ Event ] async run_on_model_error_callback ( * , callback_context , llm_request , error ) \u00b6 Runs the on_model_error_callback for all plugins. Return type : Optional [ LlmResponse ] async run_on_tool_error_callback ( * , tool , tool_args , tool_context , error ) \u00b6 Runs the on_tool_error_callback for all plugins. Return type : Optional [ dict ] async run_on_user_message_callback ( * , user_message , invocation_context ) \u00b6 Runs the on_user_message_callback for all plugins. Return type : Optional [ Content ] class google.adk.plugins. ReflectAndRetryToolPlugin ( name = 'reflect_retry_tool_plugin' , max_retries = 3 , throw_exception_if_retry_exceeded = True , tracking_scope = TrackingScope.INVOCATION ) \u00b6 Bases: BasePlugin Provides self-healing, concurrent-safe error recovery for tool failures. This plugin intercepts tool failures, provides structured guidance to the LLM\nfor reflection and correction, and retries the operation up to a configurable\nlimit. Key Features: Concurrency Safe: Uses locking to safely handle parallel tool executions\n- Configurable Scope: Tracks failures per-invocation (default) or globally using the TrackingScope enum. Extensible Scoping: The _get_scope_key method can be overridden to\nimplement custom tracking logic (e.g., per-user or per-session). Granular Tracking: Failure counts are tracked per-tool within the\ndefined scope. A success with one tool resets its counter without affecting\nothers. Custom Error Extraction: Supports detecting errors in normal tool responses\nthat don\u2019t throw exceptions, by overriding the extract_error_from_result method. Example: `` ` python\nfrom my_project.plugins import ReflectAndRetryToolPlugin, TrackingScope # Example 1: (MOST COMMON USAGE):\n# Track failures only within the current agent invocation (default).\nerror_handling_plugin = ReflectAndRetryToolPlugin(max_retries=3) # Example 2:\n# Track failures globally across all turns and users.\nglobal_error_handling_plugin = ReflectAndRetryToolPlugin(max_retries=5,\nscope=TrackingScope.GLOBAL) # Example 3:\n# Retry on failures but do not throw exceptions.\nerror_handling_plugin = ReflectAndRetryToolPlugin(max_retries=3,\nthrow_exception_if_retry_exceeded=False) # Example 4:\n# Track failures in successful tool responses that contain errors.\nclass CustomRetryPlugin(ReflectAndRetryToolPlugin): async def extract_error_from_result(self, * , tool, tool_args,tool_context,\nresult): # Detect error based on response content\nif result.get(\u2018status\u2019) == \u2018error\u2019: return result return None  # No error detected error_handling_plugin = CustomRetryPlugin(max_retries=5) `` ` Initializes the ReflectAndRetryToolPlugin. Parameters : name \u2013 Plugin instance identifier. max_retries \u2013 Maximum consecutive failures before giving up (0 = no\nretries). throw_exception_if_retry_exceeded \u2013 If True, raises the final exception\nwhen the retry limit is reached. If False, returns guidance instead. tracking_scope \u2013 Determines the lifecycle of the error tracking state.\nDefaults to TrackingScope.INVOCATION tracking per-invocation. async after_tool_callback ( * , tool , tool_args , tool_context , result ) \u00b6 Handles successful tool calls or extracts and processes errors. Return type : Optional [ dict [ str , Any ]] Parameters : tool \u2013 The tool that was called. tool_args \u2013 The arguments passed to the tool. tool_context \u2013 The context of the tool call. result \u2013 The result of the tool call. Returns : An optional dictionary containing reflection guidance if an error is\ndetected, or None if the tool call was successful or the\nresponse is already a reflection message. async extract_error_from_result ( * , tool , tool_args , tool_context , result ) \u00b6 Extracts an error from a successful tool result and triggers retry logic. This is useful when tool call finishes successfully but the result contains\nan error object like {\u201cerror\u201d: \u2026} that should be handled by the plugin. By overriding this method, you can trigger retry logic on these successful\nresults that contain errors. Return type : Optional [ dict [ str , Any ]] Parameters : tool \u2013 The tool that was called. tool_args \u2013 The arguments passed to the tool. tool_context \u2013 The context of the tool call. result \u2013 The result of the tool call. Returns : The extracted error if any, or None if no error was detected. async on_tool_error_callback ( * , tool , tool_args , tool_context , error ) \u00b6 Handles tool exceptions by providing reflection guidance. Return type : Optional [ dict [ str , Any ]] Parameters : tool \u2013 The tool that was called. tool_args \u2013 The arguments passed to the tool. tool_context \u2013 The context of the tool call. error \u2013 The exception raised by the tool. Returns : An optional dictionary containing reflection guidance for the error. ", "code_blocks": []}, {"heading_path": ["google.adk.runners module\u00b6"], "text": "google.adk.runners module \u00b6 class google.adk.runners. InMemoryRunner ( agent = None , * , app_name = None , plugins = None , app = None ) \u00b6 Bases: Runner An in-memory Runner for testing and development. This runner uses in-memory implementations for artifact, session, and memory\nservices, providing a lightweight and self-contained environment for agent\nexecution. agent \u00b6 The root agent to run. app_name \u00b6 The application name of the runner. Defaults to\n\u2018InMemoryRunner\u2019. Initializes the InMemoryRunner. Parameters : agent \u2013 The root agent to run. app_name \u2013 The application name of the runner. Defaults to\n\u2018InMemoryRunner\u2019. class google.adk.runners. Runner ( * , app = None , app_name = None , agent = None , plugins = None , artifact_service = None , session_service , memory_service = None , credential_service = None ) \u00b6 Bases: object The Runner class is used to run agents. It manages the execution of an agent within a session, handling message\nprocessing, event generation, and interaction with various services like\nartifact storage, session management, and memory. app_name \u00b6 The application name of the runner. agent \u00b6 The root agent to run. artifact_service \u00b6 The artifact service for the runner. plugin_manager \u00b6 The plugin manager for the runner. session_service \u00b6 The session service for the runner. memory_service \u00b6 The memory service for the runner. credential_service \u00b6 The credential service for the runner. context_cache_config \u00b6 The context cache config for the runner. resumability_config \u00b6 The resumability config for the application. Initializes the Runner. Developers should provide either an app instance or both app_name and agent . Providing a mix of app and app_name / agent will result in a ValueError . Providing app is the recommended way to create a runner. Parameters : app \u2013 An optional App instance. If provided, app_name and agent should not be specified. app_name \u2013 The application name of the runner. Required if app is not\nprovided. agent \u2013 The root agent to run. Required if app is not provided. plugins \u2013 Deprecated. A list of plugins for the runner. Please use the app argument to provide plugins instead. artifact_service \u2013 The artifact service for the runner. session_service \u2013 The session service for the runner. memory_service \u2013 The memory service for the runner. credential_service \u2013 The credential service for the runner. Raises : ValueError \u2013 If app is provided along with app_name or plugins , or\n    if app is not provided but either app_name or agent is missing. agent : BaseAgent \u00b6 The root agent to run. app_name : str \u00b6 The app name of the runner. artifact_service : Optional [ BaseArtifactService ] = None \u00b6 The artifact service for the runner. async close ( ) \u00b6 Closes the runner. context_cache_config : Optional [ ContextCacheConfig ] = None \u00b6 The context cache config for the runner. credential_service : Optional [ BaseCredentialService ] = None \u00b6 The credential service for the runner. memory_service : Optional [ BaseMemoryService ] = None \u00b6 The memory service for the runner. plugin_manager : PluginManager \u00b6 The plugin manager for the runner. resumability_config : Optional [ ResumabilityConfig ] = None \u00b6 The resumability config for the application. async rewind_async ( * , user_id , session_id , rewind_before_invocation_id ) \u00b6 Rewinds the session to before the specified invocation. Return type : None run ( * , user_id , session_id , new_message , run_config = None ) \u00b6 Runs the agent. Return type : Generator [ Event , None , None ] Note This sync interface is only for local testing and convenience purpose.\nConsider using run_async for production usage. Parameters : user_id \u2013 The user ID of the session. session_id \u2013 The session ID of the session. new_message \u2013 A new message to append to the session. run_config \u2013 The run config for the agent. Yields : The events generated by the agent. async run_async ( * , user_id , session_id , invocation_id = None , new_message = None , state_delta = None , run_config = None ) \u00b6 Main entry method to run the agent in this runner. Return type : AsyncGenerator [ Event , None ] Parameters : user_id \u2013 The user ID of the session. session_id \u2013 The session ID of the session. invocation_id \u2013 The invocation ID of the session, set this to resume an\ninterrupted invocation. new_message \u2013 A new message to append to the session. state_delta \u2013 Optional state changes to apply to the session. run_config \u2013 The run config for the agent. Yields : The events generated by the agent. Raises : ValueError \u2013 If the session is not found; If both invocation_id and\n    new_message are None. async run_live ( * , user_id = None , session_id = None , live_request_queue , run_config = None , session = None ) \u00b6 Runs the agent in live mode (experimental feature). Return type : AsyncGenerator [ Event , None ] Parameters : user_id \u2013 The user ID for the session. Required if session is None. session_id \u2013 The session ID for the session. Required if session is\nNone. live_request_queue \u2013 The queue for live requests. run_config \u2013 The run config for the agent. session \u2013 The session to use. This parameter is deprecated, please use user_id and session_id instead. Yields : AsyncGenerator[Event, None] \u2013 An asynchronous generator that yields Event objects as they are produced by the agent during its live execution. Warning This feature is experimental and its API or behavior may change\nin future releases. Note Either session or both user_id and session_id must be provided. session_service : BaseSessionService \u00b6 The session service for the runner. ", "code_blocks": []}, {"heading_path": ["google.adk.sessions module\u00b6"], "text": "google.adk.sessions module \u00b6 class google.adk.sessions. BaseSessionService \u00b6 Bases: ABC Base class for session services. The service provides a set of methods for managing sessions and events. async append_event ( session , event ) \u00b6 Appends an event to a session object. Return type : Event abstractmethod async create_session ( * , app_name , user_id , state = None , session_id = None ) \u00b6 Creates a new session. Return type : Session Parameters : app_name \u2013 the name of the app. user_id \u2013 the id of the user. state \u2013 the initial state of the session. session_id \u2013 the client-provided id of the session. If not provided, a\ngenerated ID will be used. Returns : The newly created session instance. Return type : session abstractmethod async delete_session ( * , app_name , user_id , session_id ) \u00b6 Deletes a session. Return type : None abstractmethod async get_session ( * , app_name , user_id , session_id , config = None ) \u00b6 Gets a session. Return type : Optional [ Session ] abstractmethod async list_sessions ( * , app_name , user_id = None ) \u00b6 Lists all the sessions for a user. Return type : ListSessionsResponse Parameters : app_name \u2013 The name of the app. user_id \u2013 The ID of the user. If not provided, lists all sessions for all\nusers. Returns : A ListSessionsResponse containing the sessions. class google.adk.sessions. DatabaseSessionService ( db_url , ** kwargs ) \u00b6 Bases: BaseSessionService A session service that uses a database for storage. Initializes the database session service with a database URL. async append_event ( session , event ) \u00b6 Appends an event to a session object. Return type : Event async create_session ( * , app_name , user_id , state = None , session_id = None ) \u00b6 Creates a new session. Return type : Session Parameters : app_name \u2013 the name of the app. user_id \u2013 the id of the user. state \u2013 the initial state of the session. session_id \u2013 the client-provided id of the session. If not provided, a\ngenerated ID will be used. Returns : The newly created session instance. Return type : session async delete_session ( app_name , user_id , session_id ) \u00b6 Deletes a session. Return type : None async get_session ( * , app_name , user_id , session_id , config = None ) \u00b6 Gets a session. Return type : Optional [ Session ] async list_sessions ( * , app_name , user_id = None ) \u00b6 Lists all the sessions for a user. Return type : ListSessionsResponse Parameters : app_name \u2013 The name of the app. user_id \u2013 The ID of the user. If not provided, lists all sessions for all\nusers. Returns : A ListSessionsResponse containing the sessions. class google.adk.sessions. InMemorySessionService \u00b6 Bases: BaseSessionService An in-memory implementation of the session service. It is not suitable for multi-threaded production environments. Use it for\ntesting and development only. async append_event ( session , event ) \u00b6 Appends an event to a session object. Return type : Event async create_session ( * , app_name , user_id , state = None , session_id = None ) \u00b6 Creates a new session. Return type : Session Parameters : app_name \u2013 the name of the app. user_id \u2013 the id of the user. state \u2013 the initial state of the session. session_id \u2013 the client-provided id of the session. If not provided, a\ngenerated ID will be used. Returns : The newly created session instance. Return type : session create_session_sync ( * , app_name , user_id , state = None , session_id = None ) \u00b6 Return type : Session async delete_session ( * , app_name , user_id , session_id ) \u00b6 Deletes a session. Return type : None delete_session_sync ( * , app_name , user_id , session_id ) \u00b6 Return type : None async get_session ( * , app_name , user_id , session_id , config = None ) \u00b6 Gets a session. Return type : Optional [ Session ] get_session_sync ( * , app_name , user_id , session_id , config = None ) \u00b6 Return type : Optional [ Session ] async list_sessions ( * , app_name , user_id = None ) \u00b6 Lists all the sessions for a user. Return type : ListSessionsResponse Parameters : app_name \u2013 The name of the app. user_id \u2013 The ID of the user. If not provided, lists all sessions for all\nusers. Returns : A ListSessionsResponse containing the sessions. list_sessions_sync ( * , app_name , user_id = None ) \u00b6 Return type : ListSessionsResponse pydantic model google.adk.sessions. Session \u00b6 Bases: BaseModel Represents a series of interactions between a user and agents. Show JSON schema { \"title\" : \"Session\" , \"description\" : \"Represents a series of interactions between a user and agents.\" , \"type\" : \"object\" , \"properties\" : { \"id\" : { \"title\" : \"Id\" , \"type\" : \"string\" }, \"appName\" : { \"title\" : \"Appname\" , \"type\" : \"string\" }, \"userId\" : { \"title\" : \"Userid\" , \"type\" : \"string\" }, \"state\" : { \"additionalProperties\" : true , \"title\" : \"State\" , \"type\" : \"object\" }, \"events\" : { \"items\" : { \"$ref\" : \"#/$defs/Event\" }, \"title\" : \"Events\" , \"type\" : \"array\" }, \"lastUpdateTime\" : { \"default\" : 0.0 , \"title\" : \"Lastupdatetime\" , \"type\" : \"number\" } }, \"$defs\" : { \"APIKey\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"apiKey\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"in\" : { \"$ref\" : \"#/$defs/APIKeyIn\" }, \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" } }, \"required\" : [ \"in\" , \"name\" ], \"title\" : \"APIKey\" , \"type\" : \"object\" }, \"APIKeyIn\" : { \"enum\" : [ \"query\" , \"header\" , \"cookie\" ], \"title\" : \"APIKeyIn\" , \"type\" : \"string\" }, \"AuthConfig\" : { \"additionalProperties\" : true , \"description\" : \"The auth config sent by tool asking client to collect auth credentials and\\n\\nadk and client will help to fill in the response\" , \"properties\" : { \"authScheme\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/APIKey\" }, { \"$ref\" : \"#/$defs/HTTPBase\" }, { \"$ref\" : \"#/$defs/OAuth2\" }, { \"$ref\" : \"#/$defs/OpenIdConnect\" }, { \"$ref\" : \"#/$defs/HTTPBearer\" }, { \"$ref\" : \"#/$defs/OpenIdConnectWithConfig\" } ], \"title\" : \"Authscheme\" }, \"rawAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"exchangedAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"credentialKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Credentialkey\" } }, \"required\" : [ \"authScheme\" ], \"title\" : \"AuthConfig\" , \"type\" : \"object\" }, \"AuthCredential\" : { \"additionalProperties\" : true , \"description\" : \"Data class representing an authentication credential.\\n\\nTo exchange for the actual credential, please use\\nCredentialExchanger.exchange_credential().\\n\\nExamples: API Key Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    api_key=\\\"1234\\\",\\n)\\n\\nExample: HTTP Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"basic\\\",\\n        credentials=HttpCredentials(username=\\\"user\\\", password=\\\"password\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Bearer Token in HTTP Header\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"bearer\\\",\\n        credentials=HttpCredentials(token=\\\"eyAkaknabna....\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Auth with Authorization Code Flow\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OAUTH2,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n    ),\\n)\\n\\nExample: OpenID Connect Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OPEN_ID_CONNECT,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n        redirect_uri=\\\"https://example.com\\\",\\n        scopes=[\\\"scope1\\\", \\\"scope2\\\"],\\n    ),\\n)\\n\\nExample: Auth with resource reference\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    resource_ref=\\\"projects/1234/locations/us-central1/resources/resource1\\\",\\n)\" , \"properties\" : { \"authType\" : { \"$ref\" : \"#/$defs/AuthCredentialTypes\" }, \"resourceRef\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Resourceref\" }, \"apiKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Apikey\" }, \"http\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HttpAuth\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"serviceAccount\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccount\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"oauth2\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuth2Auth\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"required\" : [ \"authType\" ], \"title\" : \"AuthCredential\" , \"type\" : \"object\" }, \"AuthCredentialTypes\" : { \"description\" : \"Represents the type of authentication credential.\" , \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" , \"serviceAccount\" ], \"title\" : \"AuthCredentialTypes\" , \"type\" : \"string\" }, \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CacheMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Metadata for context cache associated with LLM responses.\\n\\nThis class stores cache identification, usage tracking, and lifecycle\\ninformation for a particular cache instance. It can be in two states:\\n\\n1. Active cache state: cache_name is set, all fields populated\\n2. Fingerprint-only state: cache_name is None, only fingerprint and\\n   contents_count are set for prefix matching\\n\\nToken counts (cached and total) are available in the LlmResponse.usage_metadata\\nand should be accessed from there to avoid duplication.\\n\\nAttributes:\\n    cache_name: The full resource name of the cached content (e.g.,\\n        'projects/123/locations/us-central1/cachedContents/456').\\n        None when no active cache exists (fingerprint-only state).\\n    expire_time: Unix timestamp when the cache expires. None when no\\n        active cache exists.\\n    fingerprint: Hash of cacheable contents (instruction + tools + contents).\\n        Always present for prefix matching.\\n    invocations_used: Number of invocations this cache has been used for.\\n        None when no active cache exists.\\n    contents_count: Number of contents. When active cache exists, this is\\n        the count of cached contents. When no active cache exists, this is\\n        the total count of contents in the request.\\n    created_at: Unix timestamp when the cache was created. None when\\n        no active cache exists.\" , \"properties\" : { \"cache_name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Full resource name of the cached content (None if no active cache)\" , \"title\" : \"Cache Name\" }, \"expire_time\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Unix timestamp when cache expires (None if no active cache)\" , \"title\" : \"Expire Time\" }, \"fingerprint\" : { \"description\" : \"Hash of cacheable contents used to detect changes\" , \"title\" : \"Fingerprint\" , \"type\" : \"string\" }, \"invocations_used\" : { \"anyOf\" : [ { \"minimum\" : 0 , \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of invocations this cache has been used for (None if no active cache)\" , \"title\" : \"Invocations Used\" }, \"contents_count\" : { \"description\" : \"Number of contents (cached contents when active cache exists, total contents in request when no active cache)\" , \"minimum\" : 0 , \"title\" : \"Contents Count\" , \"type\" : \"integer\" }, \"created_at\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Unix timestamp when cache was created (None if no active cache)\" , \"title\" : \"Created At\" } }, \"required\" : [ \"fingerprint\" , \"contents_count\" ], \"title\" : \"CacheMetadata\" , \"type\" : \"object\" }, \"Citation\" : { \"additionalProperties\" : false , \"description\" : \"Source attributions for content.\" , \"properties\" : { \"endIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. End index into the content.\" , \"title\" : \"Endindex\" }, \"license\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. License of the attribution.\" , \"title\" : \"License\" }, \"publicationDate\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GoogleTypeDate\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Publication date of the attribution.\" }, \"startIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Start index into the content.\" , \"title\" : \"Startindex\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Title of the attribution.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Url reference of the attribution.\" , \"title\" : \"Uri\" } }, \"title\" : \"Citation\" , \"type\" : \"object\" }, \"CitationMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Citation information when the model quotes another source.\" , \"properties\" : { \"citations\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Citation\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Contains citation information when the model directly quotes, at\\n      length, from another source. Can include traditional websites and code\\n      repositories.\\n      \" , \"title\" : \"Citations\" } }, \"title\" : \"CitationMetadata\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"Content\" : { \"additionalProperties\" : false , \"description\" : \"Contains the multi-part content of a message.\" , \"properties\" : { \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Part\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a single message. Each part may have\\n      a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The producer of the content. Must be either 'user' or\\n      'model'. Useful to set for multi-turn conversations, otherwise can be\\n      empty. If role is not specified, SDK will determine the role.\" , \"title\" : \"Role\" } }, \"title\" : \"Content\" , \"type\" : \"object\" }, \"Event\" : { \"additionalProperties\" : false , \"description\" : \"Represents an event in a conversation between agents and users.\\n\\nIt is used to store the content of the conversation, as well as the actions\\ntaken by the agents like function calls, etc.\" , \"properties\" : { \"content\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Content\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"groundingMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"partial\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Partial\" }, \"turnComplete\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Turncomplete\" }, \"finishReason\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FinishReason\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"errorCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Errorcode\" }, \"errorMessage\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Errormessage\" }, \"interrupted\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Interrupted\" }, \"customMetadata\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Custommetadata\" }, \"usageMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GenerateContentResponseUsageMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"liveSessionResumptionUpdate\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/LiveServerSessionResumptionUpdate\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"inputTranscription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Transcription\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"outputTranscription\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Transcription\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"avgLogprobs\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Avglogprobs\" }, \"logprobsResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/LogprobsResult\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"cacheMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CacheMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"citationMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CitationMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"invocationId\" : { \"default\" : \"\" , \"title\" : \"Invocationid\" , \"type\" : \"string\" }, \"author\" : { \"title\" : \"Author\" , \"type\" : \"string\" }, \"actions\" : { \"$ref\" : \"#/$defs/EventActions\" }, \"longRunningToolIds\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" , \"uniqueItems\" : true }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Longrunningtoolids\" }, \"branch\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Branch\" }, \"id\" : { \"default\" : \"\" , \"title\" : \"Id\" , \"type\" : \"string\" }, \"timestamp\" : { \"title\" : \"Timestamp\" , \"type\" : \"number\" } }, \"required\" : [ \"author\" ], \"title\" : \"Event\" , \"type\" : \"object\" }, \"EventActions\" : { \"additionalProperties\" : false , \"description\" : \"Represents the actions attached to an event.\" , \"properties\" : { \"skipSummarization\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Skipsummarization\" }, \"stateDelta\" : { \"additionalProperties\" : true , \"title\" : \"Statedelta\" , \"type\" : \"object\" }, \"artifactDelta\" : { \"additionalProperties\" : { \"type\" : \"integer\" }, \"title\" : \"Artifactdelta\" , \"type\" : \"object\" }, \"transferToAgent\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Transfertoagent\" }, \"escalate\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Escalate\" }, \"requestedAuthConfigs\" : { \"additionalProperties\" : { \"$ref\" : \"#/$defs/AuthConfig\" }, \"title\" : \"Requestedauthconfigs\" , \"type\" : \"object\" }, \"requestedToolConfirmations\" : { \"additionalProperties\" : { \"$ref\" : \"#/$defs/ToolConfirmation\" }, \"title\" : \"Requestedtoolconfirmations\" , \"type\" : \"object\" }, \"compaction\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/EventCompaction\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"endOfAgent\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Endofagent\" }, \"agentState\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Agentstate\" }, \"rewindBeforeInvocationId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Rewindbeforeinvocationid\" } }, \"title\" : \"EventActions\" , \"type\" : \"object\" }, \"EventCompaction\" : { \"additionalProperties\" : false , \"description\" : \"The compaction of the events.\" , \"properties\" : { \"startTimestamp\" : { \"title\" : \"Starttimestamp\" , \"type\" : \"number\" }, \"endTimestamp\" : { \"title\" : \"Endtimestamp\" , \"type\" : \"number\" }, \"compactedContent\" : { \"$ref\" : \"#/$defs/Content\" } }, \"required\" : [ \"startTimestamp\" , \"endTimestamp\" , \"compactedContent\" ], \"title\" : \"EventCompaction\" , \"type\" : \"object\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FinishReason\" : { \"description\" : \"Output only. The reason why the model stopped generating tokens.\\n\\nIf empty, the model has not stopped generating the tokens.\" , \"enum\" : [ \"FINISH_REASON_UNSPECIFIED\" , \"STOP\" , \"MAX_TOKENS\" , \"SAFETY\" , \"RECITATION\" , \"LANGUAGE\" , \"OTHER\" , \"BLOCKLIST\" , \"PROHIBITED_CONTENT\" , \"SPII\" , \"MALFORMED_FUNCTION_CALL\" , \"IMAGE_SAFETY\" , \"UNEXPECTED_TOOL_CALL\" , \"IMAGE_PROHIBITED_CONTENT\" , \"NO_IMAGE\" ], \"title\" : \"FinishReason\" , \"type\" : \"string\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"GenerateContentResponseUsageMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Usage metadata about response(s).\" , \"properties\" : { \"cacheTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities of the cached content in the request input.\" , \"title\" : \"Cachetokensdetails\" }, \"cachedContentTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Number of tokens in the cached part in the input (the cached content).\" , \"title\" : \"Cachedcontenttokencount\" }, \"candidatesTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens in the response(s).\" , \"title\" : \"Candidatestokencount\" }, \"candidatesTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities that were returned in the response.\" , \"title\" : \"Candidatestokensdetails\" }, \"promptTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens in the request. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content.\" , \"title\" : \"Prompttokencount\" }, \"promptTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities that were processed in the request input.\" , \"title\" : \"Prompttokensdetails\" }, \"thoughtsTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Number of tokens present in thoughts output.\" , \"title\" : \"Thoughtstokencount\" }, \"toolUsePromptTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Number of tokens present in tool-use prompt(s).\" , \"title\" : \"Tooluseprompttokencount\" }, \"toolUsePromptTokensDetails\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/ModalityTokenCount\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. List of modalities that were processed for tool-use request inputs.\" , \"title\" : \"Tooluseprompttokensdetails\" }, \"totalTokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Total token count for prompt, response candidates, and tool-use prompts (if present).\" , \"title\" : \"Totaltokencount\" }, \"trafficType\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/TrafficType\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota.\" } }, \"title\" : \"GenerateContentResponseUsageMetadata\" , \"type\" : \"object\" }, \"GoogleTypeDate\" : { \"additionalProperties\" : false , \"description\" : \"Represents a whole or partial calendar date, such as a birthday.\\n\\nThe time of day and time zone are either specified elsewhere or are\\ninsignificant. The date is relative to the Gregorian Calendar. This can\\nrepresent one of the following: * A full date, with non-zero year, month, and\\nday values. * A month and day, with a zero year (for example, an anniversary).\\n* A year on its own, with a zero month and a zero day. * A year and month,\\nwith a zero day (for example, a credit card expiration date). Related types: *\\ngoogle.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp\" , \"properties\" : { \"day\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.\" , \"title\" : \"Day\" }, \"month\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.\" , \"title\" : \"Month\" }, \"year\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year.\" , \"title\" : \"Year\" } }, \"title\" : \"GoogleTypeDate\" , \"type\" : \"object\" }, \"GroundingChunk\" : { \"additionalProperties\" : false , \"description\" : \"Grounding chunk.\" , \"properties\" : { \"maps\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkMaps\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Grounding chunk from Google Maps.\" }, \"retrievedContext\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkRetrievedContext\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Grounding chunk from context retrieved by the retrieval tools.\" }, \"web\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkWeb\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Grounding chunk from the web.\" } }, \"title\" : \"GroundingChunk\" , \"type\" : \"object\" }, \"GroundingChunkMaps\" : { \"additionalProperties\" : false , \"description\" : \"Chunk from Google Maps.\" , \"properties\" : { \"placeAnswerSources\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkMapsPlaceAnswerSources\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Sources used to generate the place answer. This includes review snippets and photos that were used to generate the answer, as well as uris to flag content.\" }, \"placeId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"This Place's resource name, in `places/{place_id}` format. Can be used to look up the Place.\" , \"title\" : \"Placeid\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Text of the chunk.\" , \"title\" : \"Text\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Title of the chunk.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI reference of the chunk.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkMaps\" , \"type\" : \"object\" }, \"GroundingChunkMapsPlaceAnswerSources\" : { \"additionalProperties\" : false , \"description\" : \"Sources used to generate the place answer.\" , \"properties\" : { \"flagContentUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A link where users can flag a problem with the generated answer.\" , \"title\" : \"Flagcontenturi\" }, \"reviewSnippets\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/GroundingChunkMapsPlaceAnswerSourcesReviewSnippet\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Snippets of reviews that are used to generate the answer.\" , \"title\" : \"Reviewsnippets\" } }, \"title\" : \"GroundingChunkMapsPlaceAnswerSources\" , \"type\" : \"object\" }, \"GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution\" : { \"additionalProperties\" : false , \"description\" : \"Author attribution for a photo or review.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Name of the author of the Photo or Review.\" , \"title\" : \"Displayname\" }, \"photoUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Profile photo URI of the author of the Photo or Review.\" , \"title\" : \"Photouri\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI of the author of the Photo or Review.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution\" , \"type\" : \"object\" }, \"GroundingChunkMapsPlaceAnswerSourcesReviewSnippet\" : { \"additionalProperties\" : false , \"description\" : \"Encapsulates a review snippet.\" , \"properties\" : { \"authorAttribution\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"This review's author.\" }, \"flagContentUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A link where users can flag a problem with the review.\" , \"title\" : \"Flagcontenturi\" }, \"googleMapsUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A link to show the review on Google Maps.\" , \"title\" : \"Googlemapsuri\" }, \"relativePublishTimeDescription\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A string of formatted recent time, expressing the review time relative to the current time in a form appropriate for the language and country.\" , \"title\" : \"Relativepublishtimedescription\" }, \"review\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A reference representing this place review which may be used to look up this place review again.\" , \"title\" : \"Review\" } }, \"title\" : \"GroundingChunkMapsPlaceAnswerSourcesReviewSnippet\" , \"type\" : \"object\" }, \"GroundingChunkRetrievedContext\" : { \"additionalProperties\" : false , \"description\" : \"Chunk from context retrieved by the retrieval tools.\" , \"properties\" : { \"documentName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The full document name for the referenced Vertex AI Search document.\" , \"title\" : \"Documentname\" }, \"ragChunk\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagChunk\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Additional context for the RAG retrieval result. This is only populated when using the RAG retrieval tool.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Text of the attribution.\" , \"title\" : \"Text\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Title of the attribution.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI reference of the attribution.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkRetrievedContext\" , \"type\" : \"object\" }, \"GroundingChunkWeb\" : { \"additionalProperties\" : false , \"description\" : \"Chunk from the web.\" , \"properties\" : { \"domain\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Domain of the (original) URI.\" , \"title\" : \"Domain\" }, \"title\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Title of the chunk.\" , \"title\" : \"Title\" }, \"uri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"URI reference of the chunk.\" , \"title\" : \"Uri\" } }, \"title\" : \"GroundingChunkWeb\" , \"type\" : \"object\" }, \"GroundingMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Metadata returned to client when grounding is enabled.\" , \"properties\" : { \"googleMapsWidgetContextToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Output only. Resource name of the Google Maps widget context token to be used with the PlacesContextElement widget to render contextual data. This is populated only for Google Maps grounding.\" , \"title\" : \"Googlemapswidgetcontexttoken\" }, \"groundingChunks\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/GroundingChunk\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of supporting references retrieved from specified grounding source.\" , \"title\" : \"Groundingchunks\" }, \"groundingSupports\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/GroundingSupport\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. List of grounding support.\" , \"title\" : \"Groundingsupports\" }, \"retrievalMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RetrievalMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Output only. Retrieval metadata.\" }, \"retrievalQueries\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Queries executed by the retrieval tools.\" , \"title\" : \"Retrievalqueries\" }, \"searchEntryPoint\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/SearchEntryPoint\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Google search entry for the following-up web searches.\" }, \"webSearchQueries\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Web search queries for the following-up web search.\" , \"title\" : \"Websearchqueries\" } }, \"title\" : \"GroundingMetadata\" , \"type\" : \"object\" }, \"GroundingSupport\" : { \"additionalProperties\" : false , \"description\" : \"Grounding support.\" , \"properties\" : { \"confidenceScores\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"number\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. For Gemini 2.0 and before, this list must have the same size as the grounding_chunk_indices. For Gemini 2.5 and after, this list will be empty and should be ignored.\" , \"title\" : \"Confidencescores\" }, \"groundingChunkIndices\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"integer\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.\" , \"title\" : \"Groundingchunkindices\" }, \"segment\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Segment\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Segment of the content this support belongs to.\" } }, \"title\" : \"GroundingSupport\" , \"type\" : \"object\" }, \"HTTPBase\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" } }, \"required\" : [ \"scheme\" ], \"title\" : \"HTTPBase\" , \"type\" : \"object\" }, \"HTTPBearer\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"const\" : \"bearer\" , \"default\" : \"bearer\" , \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"bearerFormat\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Bearerformat\" } }, \"title\" : \"HTTPBearer\" , \"type\" : \"object\" }, \"HttpAuth\" : { \"additionalProperties\" : true , \"description\" : \"The credentials and metadata for HTTP authentication.\" , \"properties\" : { \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"credentials\" : { \"$ref\" : \"#/$defs/HttpCredentials\" } }, \"required\" : [ \"scheme\" , \"credentials\" ], \"title\" : \"HttpAuth\" , \"type\" : \"object\" }, \"HttpCredentials\" : { \"additionalProperties\" : true , \"description\" : \"Represents the secret token value for HTTP authentication, like user name, password, oauth token, etc.\" , \"properties\" : { \"username\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Username\" }, \"password\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Password\" }, \"token\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token\" } }, \"title\" : \"HttpCredentials\" , \"type\" : \"object\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"LiveServerSessionResumptionUpdate\" : { \"additionalProperties\" : false , \"description\" : \"Update of the session resumption state.\\n\\nOnly sent if `session_resumption` was set in the connection config.\" , \"properties\" : { \"newHandle\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"New handle that represents state that can be resumed. Empty if `resumable`=false.\" , \"title\" : \"Newhandle\" }, \"resumable\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss.\" , \"title\" : \"Resumable\" }, \"lastConsumedClientMessageIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when `SessionResumptionConfig.transparent` is set.\\n\\nPresence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last `SessionResmumptionTokenUpdate`. This field will enable them to limit buffering (avoid keeping all requests in RAM).\\n\\nNote: This should not be used for when resuming a session at some time later -- in those cases partial audio and video frames arelikely not needed.\" , \"title\" : \"Lastconsumedclientmessageindex\" } }, \"title\" : \"LiveServerSessionResumptionUpdate\" , \"type\" : \"object\" }, \"LogprobsResult\" : { \"additionalProperties\" : false , \"description\" : \"Logprobs Result\" , \"properties\" : { \"chosenCandidates\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/LogprobsResultCandidate\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates.\" , \"title\" : \"Chosencandidates\" }, \"topCandidates\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/LogprobsResultTopCandidates\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Length = total number of decoding steps.\" , \"title\" : \"Topcandidates\" } }, \"title\" : \"LogprobsResult\" , \"type\" : \"object\" }, \"LogprobsResultCandidate\" : { \"additionalProperties\" : false , \"description\" : \"Candidate for the logprobs token and score.\" , \"properties\" : { \"logProbability\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The candidate's log probability.\" , \"title\" : \"Logprobability\" }, \"token\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The candidate's token string value.\" , \"title\" : \"Token\" }, \"tokenId\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The candidate's token id value.\" , \"title\" : \"Tokenid\" } }, \"title\" : \"LogprobsResultCandidate\" , \"type\" : \"object\" }, \"LogprobsResultTopCandidates\" : { \"additionalProperties\" : false , \"description\" : \"Candidates with top log probabilities at each decoding step.\" , \"properties\" : { \"candidates\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/LogprobsResultCandidate\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Sorted by log probability in descending order.\" , \"title\" : \"Candidates\" } }, \"title\" : \"LogprobsResultTopCandidates\" , \"type\" : \"object\" }, \"MediaModality\" : { \"description\" : \"Server content modalities.\" , \"enum\" : [ \"MODALITY_UNSPECIFIED\" , \"TEXT\" , \"IMAGE\" , \"VIDEO\" , \"AUDIO\" , \"DOCUMENT\" ], \"title\" : \"MediaModality\" , \"type\" : \"string\" }, \"ModalityTokenCount\" : { \"additionalProperties\" : false , \"description\" : \"Represents token counting info for a single modality.\" , \"properties\" : { \"modality\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/MediaModality\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The modality associated with this token count.\" }, \"tokenCount\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Number of tokens.\" , \"title\" : \"Tokencount\" } }, \"title\" : \"ModalityTokenCount\" , \"type\" : \"object\" }, \"OAuth2\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"oauth2\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"flows\" : { \"$ref\" : \"#/$defs/OAuthFlows\" } }, \"required\" : [ \"flows\" ], \"title\" : \"OAuth2\" , \"type\" : \"object\" }, \"OAuth2Auth\" : { \"additionalProperties\" : true , \"description\" : \"Represents credential value and its metadata for a OAuth2 credential.\" , \"properties\" : { \"clientId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientid\" }, \"clientSecret\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientsecret\" }, \"authUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authuri\" }, \"state\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"State\" }, \"redirectUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Redirecturi\" }, \"authResponseUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authresponseuri\" }, \"authCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authcode\" }, \"accessToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Accesstoken\" }, \"refreshToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshtoken\" }, \"expiresAt\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresat\" }, \"expiresIn\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresin\" }, \"audience\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Audience\" } }, \"title\" : \"OAuth2Auth\" , \"type\" : \"object\" }, \"OAuthFlowAuthorizationCode\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" , \"tokenUrl\" ], \"title\" : \"OAuthFlowAuthorizationCode\" , \"type\" : \"object\" }, \"OAuthFlowClientCredentials\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowClientCredentials\" , \"type\" : \"object\" }, \"OAuthFlowImplicit\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" ], \"title\" : \"OAuthFlowImplicit\" , \"type\" : \"object\" }, \"OAuthFlowPassword\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowPassword\" , \"type\" : \"object\" }, \"OAuthFlows\" : { \"additionalProperties\" : true , \"properties\" : { \"implicit\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowImplicit\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"password\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowPassword\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"clientCredentials\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowClientCredentials\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"authorizationCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowAuthorizationCode\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"title\" : \"OAuthFlows\" , \"type\" : \"object\" }, \"OpenIdConnect\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"openIdConnectUrl\" : { \"title\" : \"Openidconnecturl\" , \"type\" : \"string\" } }, \"required\" : [ \"openIdConnectUrl\" ], \"title\" : \"OpenIdConnect\" , \"type\" : \"object\" }, \"OpenIdConnectWithConfig\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"authorization_endpoint\" : { \"title\" : \"Authorization Endpoint\" , \"type\" : \"string\" }, \"token_endpoint\" : { \"title\" : \"Token Endpoint\" , \"type\" : \"string\" }, \"userinfo_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Userinfo Endpoint\" }, \"revocation_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Revocation Endpoint\" }, \"token_endpoint_auth_methods_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token Endpoint Auth Methods Supported\" }, \"grant_types_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Grant Types Supported\" }, \"scopes\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Scopes\" } }, \"required\" : [ \"authorization_endpoint\" , \"token_endpoint\" ], \"title\" : \"OpenIdConnectWithConfig\" , \"type\" : \"object\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"RagChunk\" : { \"additionalProperties\" : false , \"description\" : \"A RagChunk includes the content of a chunk of a RagFile, and associated metadata.\" , \"properties\" : { \"pageSpan\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/RagChunkPageSpan\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"If populated, represents where the chunk starts and ends in the document.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The content of the chunk.\" , \"title\" : \"Text\" } }, \"title\" : \"RagChunk\" , \"type\" : \"object\" }, \"RagChunkPageSpan\" : { \"additionalProperties\" : false , \"description\" : \"Represents where the chunk starts and ends in the document.\" , \"properties\" : { \"firstPage\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Page where chunk starts in the document. Inclusive. 1-indexed.\" , \"title\" : \"Firstpage\" }, \"lastPage\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Page where chunk ends in the document. Inclusive. 1-indexed.\" , \"title\" : \"Lastpage\" } }, \"title\" : \"RagChunkPageSpan\" , \"type\" : \"object\" }, \"RetrievalMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Metadata related to retrieval in the grounding flow.\" , \"properties\" : { \"googleSearchDynamicRetrievalScore\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.\" , \"title\" : \"Googlesearchdynamicretrievalscore\" } }, \"title\" : \"RetrievalMetadata\" , \"type\" : \"object\" }, \"SearchEntryPoint\" : { \"additionalProperties\" : false , \"description\" : \"Google search entry point.\" , \"properties\" : { \"renderedContent\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Web content snippet that can be embedded in a web page or an app webview.\" , \"title\" : \"Renderedcontent\" }, \"sdkBlob\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Base64 encoded JSON representing array of tuple.\" , \"title\" : \"Sdkblob\" } }, \"title\" : \"SearchEntryPoint\" , \"type\" : \"object\" }, \"SecuritySchemeType\" : { \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" ], \"title\" : \"SecuritySchemeType\" , \"type\" : \"string\" }, \"Segment\" : { \"additionalProperties\" : false , \"description\" : \"Segment of the content.\" , \"properties\" : { \"endIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.\" , \"title\" : \"Endindex\" }, \"partIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The index of a Part object within its parent Content object.\" , \"title\" : \"Partindex\" }, \"startIndex\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.\" , \"title\" : \"Startindex\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Output only. The text corresponding to the segment from the response.\" , \"title\" : \"Text\" } }, \"title\" : \"Segment\" , \"type\" : \"object\" }, \"ServiceAccount\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\" , \"properties\" : { \"serviceAccountCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccountCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"scopes\" : { \"items\" : { \"type\" : \"string\" }, \"title\" : \"Scopes\" , \"type\" : \"array\" }, \"useDefaultCredential\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : false , \"title\" : \"Usedefaultcredential\" } }, \"required\" : [ \"scopes\" ], \"title\" : \"ServiceAccount\" , \"type\" : \"object\" }, \"ServiceAccountCredential\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\\n\\nAttributes:\\n  type: The type should be \\\"service_account\\\".\\n  project_id: The project ID.\\n  private_key_id: The ID of the private key.\\n  private_key: The private key.\\n  client_email: The client email.\\n  client_id: The client ID.\\n  auth_uri: The authorization URI.\\n  token_uri: The token URI.\\n  auth_provider_x509_cert_url: URL for auth provider's X.509 cert.\\n  client_x509_cert_url: URL for the client's X.509 cert.\\n  universe_domain: The universe domain.\\n\\nExample:\\n\\n    config = ServiceAccountCredential(\\n        type_=\\\"service_account\\\",\\n        project_id=\\\"your_project_id\\\",\\n        private_key_id=\\\"your_private_key_id\\\",\\n        private_key=\\\"-----BEGIN PRIVATE KEY-----...\\\",\\n        client_email=\\\"...@....iam.gserviceaccount.com\\\",\\n        client_id=\\\"your_client_id\\\",\\n        auth_uri=\\\"https://accounts.google.com/o/oauth2/auth\\\",\\n        token_uri=\\\"https://oauth2.googleapis.com/token\\\",\\n        auth_provider_x509_cert_url=\\\"https://www.googleapis.com/oauth2/v1/certs\\\",\\n        client_x509_cert_url=\\\"https://www.googleapis.com/robot/v1/metadata/x509/...\\\",\\n        universe_domain=\\\"googleapis.com\\\"\\n    )\\n\\n\\n    config = ServiceAccountConfig.model_construct(**{\\n        ...service account config dict\\n    })\" , \"properties\" : { \"type\" : { \"default\" : \"\" , \"title\" : \"Type\" , \"type\" : \"string\" }, \"projectId\" : { \"title\" : \"Projectid\" , \"type\" : \"string\" }, \"privateKeyId\" : { \"title\" : \"Privatekeyid\" , \"type\" : \"string\" }, \"privateKey\" : { \"title\" : \"Privatekey\" , \"type\" : \"string\" }, \"clientEmail\" : { \"title\" : \"Clientemail\" , \"type\" : \"string\" }, \"clientId\" : { \"title\" : \"Clientid\" , \"type\" : \"string\" }, \"authUri\" : { \"title\" : \"Authuri\" , \"type\" : \"string\" }, \"tokenUri\" : { \"title\" : \"Tokenuri\" , \"type\" : \"string\" }, \"authProviderX509CertUrl\" : { \"title\" : \"Authproviderx509Certurl\" , \"type\" : \"string\" }, \"clientX509CertUrl\" : { \"title\" : \"Clientx509Certurl\" , \"type\" : \"string\" }, \"universeDomain\" : { \"title\" : \"Universedomain\" , \"type\" : \"string\" } }, \"required\" : [ \"projectId\" , \"privateKeyId\" , \"privateKey\" , \"clientEmail\" , \"clientId\" , \"authUri\" , \"tokenUri\" , \"authProviderX509CertUrl\" , \"clientX509CertUrl\" , \"universeDomain\" ], \"title\" : \"ServiceAccountCredential\" , \"type\" : \"object\" }, \"ToolConfirmation\" : { \"additionalProperties\" : false , \"description\" : \"Represents a tool confirmation configuration.\" , \"properties\" : { \"hint\" : { \"default\" : \"\" , \"title\" : \"Hint\" , \"type\" : \"string\" }, \"confirmed\" : { \"default\" : false , \"title\" : \"Confirmed\" , \"type\" : \"boolean\" }, \"payload\" : { \"anyOf\" : [ {}, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Payload\" } }, \"title\" : \"ToolConfirmation\" , \"type\" : \"object\" }, \"TrafficType\" : { \"description\" : \"Output only.\\n\\nTraffic type. This shows whether a request consumes Pay-As-You-Go or\\nProvisioned Throughput quota.\" , \"enum\" : [ \"TRAFFIC_TYPE_UNSPECIFIED\" , \"ON_DEMAND\" , \"PROVISIONED_THROUGHPUT\" ], \"title\" : \"TrafficType\" , \"type\" : \"string\" }, \"Transcription\" : { \"additionalProperties\" : false , \"description\" : \"Audio transcription in Server Conent.\" , \"properties\" : { \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Transcription text.\\n      \" , \"title\" : \"Text\" }, \"finished\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The bool indicates the end of the transcription.\\n      \" , \"title\" : \"Finished\" } }, \"title\" : \"Transcription\" , \"type\" : \"object\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"id\" , \"appName\" , \"userId\" ] } Fields : app_name (str) events (list[google.adk.events.event.Event]) id (str) last_update_time (float) state (dict[str, Any]) user_id (str) field app_name : str [Required] (alias 'appName') \u00b6 The name of the app. field events : list[Event] [Optional] \u00b6 The events of the session, e.g. user input, model response, function\ncall/response, etc. field id : str [Required] \u00b6 The unique identifier of the session. field last_update_time : float = 0.0 (alias 'lastUpdateTime') \u00b6 The last update time of the session. field state : dict[str, Any] [Optional] \u00b6 The state of the session. field user_id : str [Required] (alias 'userId') \u00b6 The id of the user. class google.adk.sessions. State ( value , delta ) \u00b6 Bases: object A state dict that maintain the current value and the pending-commit delta. Parameters : value \u2013 The current value of the state dict. delta \u2013 The delta change to the current value that hasn\u2019t been committed. APP_PREFIX = 'app:' \u00b6 TEMP_PREFIX = 'temp:' \u00b6 USER_PREFIX = 'user:' \u00b6 get ( key , default = None ) \u00b6 Returns the value of the state dict for the given key. Return type : Any has_delta ( ) \u00b6 Whether the state has pending delta. Return type : bool setdefault ( key , default = None ) \u00b6 Gets the value of a key, or sets it to a default if the key doesn\u2019t exist. Return type : Any to_dict ( ) \u00b6 Returns the state dict. Return type : dict [ str , Any ] update ( delta ) \u00b6 Updates the state dict with the given delta. class google.adk.sessions. VertexAiSessionService ( project = None , location = None , agent_engine_id = None ) \u00b6 Bases: BaseSessionService Connects to the Vertex AI Agent Engine Session Service using Agent Engine SDK. https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/sessions/overview Initializes the VertexAiSessionService. Parameters : project \u2013 The project id of the project to use. location \u2013 The location of the project to use. agent_engine_id \u2013 The resource ID of the agent engine to use. async append_event ( session , event ) \u00b6 Appends an event to a session object. Return type : Event async create_session ( * , app_name , user_id , state = None , session_id = None ) \u00b6 Creates a new session. Return type : Session Parameters : app_name \u2013 the name of the app. user_id \u2013 the id of the user. state \u2013 the initial state of the session. session_id \u2013 the client-provided id of the session. If not provided, a\ngenerated ID will be used. Returns : The newly created session instance. Return type : session async delete_session ( * , app_name , user_id , session_id ) \u00b6 Deletes a session. Return type : None async get_session ( * , app_name , user_id , session_id , config = None ) \u00b6 Gets a session. Return type : Optional [ Session ] async list_sessions ( * , app_name , user_id = None ) \u00b6 Lists all the sessions for a user. Return type : ListSessionsResponse Parameters : app_name \u2013 The name of the app. user_id \u2013 The ID of the user. If not provided, lists all sessions for all\nusers. Returns : A ListSessionsResponse containing the sessions. ", "code_blocks": []}, {"heading_path": ["google.adk.telemetry module\u00b6"], "text": "google.adk.telemetry module \u00b6 google.adk.telemetry. trace_call_llm ( invocation_context , event_id , llm_request , llm_response ) \u00b6 Traces a call to the LLM. This function records details about the LLM request and response as\nattributes on the current OpenTelemetry span. Parameters : invocation_context \u2013 The invocation context for the current agent run. event_id \u2013 The ID of the event. llm_request \u2013 The LLM request object. llm_response \u2013 The LLM response object. google.adk.telemetry. trace_merged_tool_calls ( response_event_id , function_response_event ) \u00b6 Traces merged tool call events. Calling this function is not needed for telemetry purposes. This is provided\nfor preventing /debug/trace requests (typically sent by web UI). Parameters : response_event_id \u2013 The ID of the response event. function_response_event \u2013 The merged response event. google.adk.telemetry. trace_send_data ( invocation_context , event_id , data ) \u00b6 Traces the sending of data to the agent. This function records details about the data sent to the agent as\nattributes on the current OpenTelemetry span. Parameters : invocation_context \u2013 The invocation context for the current agent run. event_id \u2013 The ID of the event. data \u2013 A list of content objects. google.adk.telemetry. trace_tool_call ( tool , args , function_response_event ) \u00b6 Traces tool call. Parameters : tool \u2013 The tool that was called. args \u2013 The arguments to the tool call. function_response_event \u2013 The event with the function response details. ", "code_blocks": []}, {"heading_path": ["google.adk.tools package\u00b6"], "text": "google.adk.tools package \u00b6 class google.adk.tools. APIHubToolset ( * , apihub_resource_name , access_token = None , service_account_json = None , name = '' , description = '' , lazy_load_spec = False , auth_scheme = None , auth_credential = None , apihub_client = None , tool_filter = None ) \u00b6 Bases: BaseToolset APIHubTool generates tools from a given API Hub resource. Examples: apihub_toolset = APIHubToolset ( apihub_resource_name = \"projects/test-project/locations/us-central1/apis/test-api\" , service_account_json = \"...\" , tool_filter = lambda tool , ctx = None : tool . name in ( 'my_tool' , 'my_other_tool' ) ) # Get all available tools agent = LlmAgent ( tools = apihub_toolset ) apihub_resource_name is the resource name from API Hub. It must include\nAPI name, and can optionally include API version and spec name. If apihub_resource_name includes a spec resource name, the content of that\nspec will be used for generating the tools. If apihub_resource_name includes only an api or a version name, the\nfirst spec of the first version of that API will be used. Initializes the APIHubTool with the given parameters. Examples: apihub_toolset = APIHubToolset ( apihub_resource_name = \"projects/test-project/locations/us-central1/apis/test-api\" , service_account_json = \"...\" , ) # Get all available tools agent = LlmAgent ( tools = [ apihub_toolset ]) apihub_toolset = APIHubToolset ( apihub_resource_name = \"projects/test-project/locations/us-central1/apis/test-api\" , service_account_json = \"...\" , tool_filter = [ 'my_tool' ] ) # Get a specific tool agent = LlmAgent ( tools = [ ... , apihub_toolset , ]) apihub_resource_name is the resource name from API Hub. It must include\nAPI name, and can optionally include API version and spec name. If apihub_resource_name includes a spec resource name, the content of that\nspec will be used for generating the tools. If apihub_resource_name includes only an api or a version name, the\nfirst spec of the first version of that API will be used. Example: projects/xxx/locations/us-central1/apis/apiname/\u2026 https://console.cloud.google.com/apigee/api-hub/apis/apiname?project=xxx Parameters : apihub_resource_name \u2013 The resource name of the API in API Hub.\nExample: projects/test-project/locations/us-central1/apis/test-api . access_token \u2013 Google Access token. Generate with gcloud cli gcloud auth auth print-access-token . Used for fetching API Specs from API Hub. service_account_json \u2013 The service account config as a json string.\nRequired if not using default service credential. It is used for\ncreating the API Hub client and fetching the API Specs from API Hub. apihub_client \u2013 Optional custom API Hub client. name \u2013 Name of the toolset. Optional. description \u2013 Description of the toolset. Optional. auth_scheme \u2013 Auth scheme that applies to all the tool in the toolset. auth_credential \u2013 Auth credential that applies to all the tool in the\ntoolset. lazy_load_spec \u2013 If True, the spec will be loaded lazily when needed.\nOtherwise, the spec will be loaded immediately and the tools will be\ngenerated during initialization. tool_filter \u2013 The filter used to filter the tools in the toolset. It can\nbe either a tool predicate or a list of tool names of the tools to\nexpose. async close ( ) \u00b6 Performs cleanup and releases resources held by the toolset. Note This method is invoked, for example, at the end of an agent server\u2019s\nlifecycle or when the toolset is no longer needed. Implementations\nshould ensure that any open connections, files, or other managed\nresources are properly released to prevent leaks. async get_tools ( readonly_context = None ) \u00b6 Retrieves all available tools. Return type : List [ RestApiTool ] Returns : A list of all available RestApiTool objects. class google.adk.tools. AgentTool ( agent , skip_summarization = False ) \u00b6 Bases: BaseTool A tool that wraps an agent. This tool allows an agent to be called as a tool within a larger application.\nThe agent\u2019s input schema is used to define the tool\u2019s input parameters, and\nthe agent\u2019s output is returned as the tool\u2019s result. agent \u00b6 The agent to wrap. skip_summarization \u00b6 Whether to skip summarization of the agent output. classmethod from_config ( config , config_abs_path ) \u00b6 Creates a tool instance from a config. This default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic. Return type : AgentTool Parameters : config \u2013 The config for the tool. config_abs_path \u2013 The absolute path to the config file that contains the\ntool config. Returns : The tool instance. populate_name ( ) \u00b6 Return type : Any async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. pydantic model google.adk.tools. AuthToolArguments \u00b6 Bases: BaseModelWithConfig the arguments for the special long running function tool that is used to request end user credentials. Show JSON schema { \"title\" : \"AuthToolArguments\" , \"description\" : \"the arguments for the special long running function tool that is used to\\n\\nrequest end user credentials.\" , \"type\" : \"object\" , \"properties\" : { \"functionCallId\" : { \"title\" : \"Functioncallid\" , \"type\" : \"string\" }, \"authConfig\" : { \"$ref\" : \"#/$defs/AuthConfig\" } }, \"$defs\" : { \"APIKey\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"apiKey\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"in\" : { \"$ref\" : \"#/$defs/APIKeyIn\" }, \"name\" : { \"title\" : \"Name\" , \"type\" : \"string\" } }, \"required\" : [ \"in\" , \"name\" ], \"title\" : \"APIKey\" , \"type\" : \"object\" }, \"APIKeyIn\" : { \"enum\" : [ \"query\" , \"header\" , \"cookie\" ], \"title\" : \"APIKeyIn\" , \"type\" : \"string\" }, \"AuthConfig\" : { \"additionalProperties\" : true , \"description\" : \"The auth config sent by tool asking client to collect auth credentials and\\n\\nadk and client will help to fill in the response\" , \"properties\" : { \"authScheme\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/APIKey\" }, { \"$ref\" : \"#/$defs/HTTPBase\" }, { \"$ref\" : \"#/$defs/OAuth2\" }, { \"$ref\" : \"#/$defs/OpenIdConnect\" }, { \"$ref\" : \"#/$defs/HTTPBearer\" }, { \"$ref\" : \"#/$defs/OpenIdConnectWithConfig\" } ], \"title\" : \"Authscheme\" }, \"rawAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"exchangedAuthCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/AuthCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"credentialKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Credentialkey\" } }, \"required\" : [ \"authScheme\" ], \"title\" : \"AuthConfig\" , \"type\" : \"object\" }, \"AuthCredential\" : { \"additionalProperties\" : true , \"description\" : \"Data class representing an authentication credential.\\n\\nTo exchange for the actual credential, please use\\nCredentialExchanger.exchange_credential().\\n\\nExamples: API Key Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    api_key=\\\"1234\\\",\\n)\\n\\nExample: HTTP Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"basic\\\",\\n        credentials=HttpCredentials(username=\\\"user\\\", password=\\\"password\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Bearer Token in HTTP Header\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.HTTP,\\n    http=HttpAuth(\\n        scheme=\\\"bearer\\\",\\n        credentials=HttpCredentials(token=\\\"eyAkaknabna....\\\"),\\n    ),\\n)\\n\\nExample: OAuth2 Auth with Authorization Code Flow\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OAUTH2,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n    ),\\n)\\n\\nExample: OpenID Connect Auth\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.OPEN_ID_CONNECT,\\n    oauth2=OAuth2Auth(\\n        client_id=\\\"1234\\\",\\n        client_secret=\\\"secret\\\",\\n        redirect_uri=\\\"https://example.com\\\",\\n        scopes=[\\\"scope1\\\", \\\"scope2\\\"],\\n    ),\\n)\\n\\nExample: Auth with resource reference\\nAuthCredential(\\n    auth_type=AuthCredentialTypes.API_KEY,\\n    resource_ref=\\\"projects/1234/locations/us-central1/resources/resource1\\\",\\n)\" , \"properties\" : { \"authType\" : { \"$ref\" : \"#/$defs/AuthCredentialTypes\" }, \"resourceRef\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Resourceref\" }, \"apiKey\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Apikey\" }, \"http\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/HttpAuth\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"serviceAccount\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccount\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"oauth2\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuth2Auth\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"required\" : [ \"authType\" ], \"title\" : \"AuthCredential\" , \"type\" : \"object\" }, \"AuthCredentialTypes\" : { \"description\" : \"Represents the type of authentication credential.\" , \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" , \"serviceAccount\" ], \"title\" : \"AuthCredentialTypes\" , \"type\" : \"string\" }, \"HTTPBase\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" } }, \"required\" : [ \"scheme\" ], \"title\" : \"HTTPBase\" , \"type\" : \"object\" }, \"HTTPBearer\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"http\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"scheme\" : { \"const\" : \"bearer\" , \"default\" : \"bearer\" , \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"bearerFormat\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Bearerformat\" } }, \"title\" : \"HTTPBearer\" , \"type\" : \"object\" }, \"HttpAuth\" : { \"additionalProperties\" : true , \"description\" : \"The credentials and metadata for HTTP authentication.\" , \"properties\" : { \"scheme\" : { \"title\" : \"Scheme\" , \"type\" : \"string\" }, \"credentials\" : { \"$ref\" : \"#/$defs/HttpCredentials\" } }, \"required\" : [ \"scheme\" , \"credentials\" ], \"title\" : \"HttpAuth\" , \"type\" : \"object\" }, \"HttpCredentials\" : { \"additionalProperties\" : true , \"description\" : \"Represents the secret token value for HTTP authentication, like user name, password, oauth token, etc.\" , \"properties\" : { \"username\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Username\" }, \"password\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Password\" }, \"token\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token\" } }, \"title\" : \"HttpCredentials\" , \"type\" : \"object\" }, \"OAuth2\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"oauth2\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"flows\" : { \"$ref\" : \"#/$defs/OAuthFlows\" } }, \"required\" : [ \"flows\" ], \"title\" : \"OAuth2\" , \"type\" : \"object\" }, \"OAuth2Auth\" : { \"additionalProperties\" : true , \"description\" : \"Represents credential value and its metadata for a OAuth2 credential.\" , \"properties\" : { \"clientId\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientid\" }, \"clientSecret\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Clientsecret\" }, \"authUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authuri\" }, \"state\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"State\" }, \"redirectUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Redirecturi\" }, \"authResponseUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authresponseuri\" }, \"authCode\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Authcode\" }, \"accessToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Accesstoken\" }, \"refreshToken\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshtoken\" }, \"expiresAt\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresat\" }, \"expiresIn\" : { \"anyOf\" : [ { \"type\" : \"integer\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Expiresin\" }, \"audience\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Audience\" } }, \"title\" : \"OAuth2Auth\" , \"type\" : \"object\" }, \"OAuthFlowAuthorizationCode\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" , \"tokenUrl\" ], \"title\" : \"OAuthFlowAuthorizationCode\" , \"type\" : \"object\" }, \"OAuthFlowClientCredentials\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowClientCredentials\" , \"type\" : \"object\" }, \"OAuthFlowImplicit\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"authorizationUrl\" : { \"title\" : \"Authorizationurl\" , \"type\" : \"string\" } }, \"required\" : [ \"authorizationUrl\" ], \"title\" : \"OAuthFlowImplicit\" , \"type\" : \"object\" }, \"OAuthFlowPassword\" : { \"additionalProperties\" : true , \"properties\" : { \"refreshUrl\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Refreshurl\" }, \"scopes\" : { \"additionalProperties\" : { \"type\" : \"string\" }, \"default\" : {}, \"title\" : \"Scopes\" , \"type\" : \"object\" }, \"tokenUrl\" : { \"title\" : \"Tokenurl\" , \"type\" : \"string\" } }, \"required\" : [ \"tokenUrl\" ], \"title\" : \"OAuthFlowPassword\" , \"type\" : \"object\" }, \"OAuthFlows\" : { \"additionalProperties\" : true , \"properties\" : { \"implicit\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowImplicit\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"password\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowPassword\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"clientCredentials\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowClientCredentials\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"authorizationCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/OAuthFlowAuthorizationCode\" }, { \"type\" : \"null\" } ], \"default\" : null } }, \"title\" : \"OAuthFlows\" , \"type\" : \"object\" }, \"OpenIdConnect\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"openIdConnectUrl\" : { \"title\" : \"Openidconnecturl\" , \"type\" : \"string\" } }, \"required\" : [ \"openIdConnectUrl\" ], \"title\" : \"OpenIdConnect\" , \"type\" : \"object\" }, \"OpenIdConnectWithConfig\" : { \"additionalProperties\" : true , \"properties\" : { \"type\" : { \"$ref\" : \"#/$defs/SecuritySchemeType\" , \"default\" : \"openIdConnect\" }, \"description\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Description\" }, \"authorization_endpoint\" : { \"title\" : \"Authorization Endpoint\" , \"type\" : \"string\" }, \"token_endpoint\" : { \"title\" : \"Token Endpoint\" , \"type\" : \"string\" }, \"userinfo_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Userinfo Endpoint\" }, \"revocation_endpoint\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Revocation Endpoint\" }, \"token_endpoint_auth_methods_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Token Endpoint Auth Methods Supported\" }, \"grant_types_supported\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Grant Types Supported\" }, \"scopes\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Scopes\" } }, \"required\" : [ \"authorization_endpoint\" , \"token_endpoint\" ], \"title\" : \"OpenIdConnectWithConfig\" , \"type\" : \"object\" }, \"SecuritySchemeType\" : { \"enum\" : [ \"apiKey\" , \"http\" , \"oauth2\" , \"openIdConnect\" ], \"title\" : \"SecuritySchemeType\" , \"type\" : \"string\" }, \"ServiceAccount\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\" , \"properties\" : { \"serviceAccountCredential\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ServiceAccountCredential\" }, { \"type\" : \"null\" } ], \"default\" : null }, \"scopes\" : { \"items\" : { \"type\" : \"string\" }, \"title\" : \"Scopes\" , \"type\" : \"array\" }, \"useDefaultCredential\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : false , \"title\" : \"Usedefaultcredential\" } }, \"required\" : [ \"scopes\" ], \"title\" : \"ServiceAccount\" , \"type\" : \"object\" }, \"ServiceAccountCredential\" : { \"additionalProperties\" : true , \"description\" : \"Represents Google Service Account configuration.\\n\\nAttributes:\\n  type: The type should be \\\"service_account\\\".\\n  project_id: The project ID.\\n  private_key_id: The ID of the private key.\\n  private_key: The private key.\\n  client_email: The client email.\\n  client_id: The client ID.\\n  auth_uri: The authorization URI.\\n  token_uri: The token URI.\\n  auth_provider_x509_cert_url: URL for auth provider's X.509 cert.\\n  client_x509_cert_url: URL for the client's X.509 cert.\\n  universe_domain: The universe domain.\\n\\nExample:\\n\\n    config = ServiceAccountCredential(\\n        type_=\\\"service_account\\\",\\n        project_id=\\\"your_project_id\\\",\\n        private_key_id=\\\"your_private_key_id\\\",\\n        private_key=\\\"-----BEGIN PRIVATE KEY-----...\\\",\\n        client_email=\\\"...@....iam.gserviceaccount.com\\\",\\n        client_id=\\\"your_client_id\\\",\\n        auth_uri=\\\"https://accounts.google.com/o/oauth2/auth\\\",\\n        token_uri=\\\"https://oauth2.googleapis.com/token\\\",\\n        auth_provider_x509_cert_url=\\\"https://www.googleapis.com/oauth2/v1/certs\\\",\\n        client_x509_cert_url=\\\"https://www.googleapis.com/robot/v1/metadata/x509/...\\\",\\n        universe_domain=\\\"googleapis.com\\\"\\n    )\\n\\n\\n    config = ServiceAccountConfig.model_construct(**{\\n        ...service account config dict\\n    })\" , \"properties\" : { \"type\" : { \"default\" : \"\" , \"title\" : \"Type\" , \"type\" : \"string\" }, \"projectId\" : { \"title\" : \"Projectid\" , \"type\" : \"string\" }, \"privateKeyId\" : { \"title\" : \"Privatekeyid\" , \"type\" : \"string\" }, \"privateKey\" : { \"title\" : \"Privatekey\" , \"type\" : \"string\" }, \"clientEmail\" : { \"title\" : \"Clientemail\" , \"type\" : \"string\" }, \"clientId\" : { \"title\" : \"Clientid\" , \"type\" : \"string\" }, \"authUri\" : { \"title\" : \"Authuri\" , \"type\" : \"string\" }, \"tokenUri\" : { \"title\" : \"Tokenuri\" , \"type\" : \"string\" }, \"authProviderX509CertUrl\" : { \"title\" : \"Authproviderx509Certurl\" , \"type\" : \"string\" }, \"clientX509CertUrl\" : { \"title\" : \"Clientx509Certurl\" , \"type\" : \"string\" }, \"universeDomain\" : { \"title\" : \"Universedomain\" , \"type\" : \"string\" } }, \"required\" : [ \"projectId\" , \"privateKeyId\" , \"privateKey\" , \"clientEmail\" , \"clientId\" , \"authUri\" , \"tokenUri\" , \"authProviderX509CertUrl\" , \"clientX509CertUrl\" , \"universeDomain\" ], \"title\" : \"ServiceAccountCredential\" , \"type\" : \"object\" } }, \"additionalProperties\" : true , \"required\" : [ \"functionCallId\" , \"authConfig\" ] } Fields : auth_config (google.adk.auth.auth_tool.AuthConfig) function_call_id (str) field auth_config : AuthConfig [Required] (alias 'authConfig') \u00b6 field function_call_id : str [Required] (alias 'functionCallId') \u00b6 class google.adk.tools. BaseTool ( * , name , description , is_long_running = False , custom_metadata = None ) \u00b6 Bases: ABC The base class for all tools. custom_metadata : Optional [ dict [ str , Any ]] = None \u00b6 The custom metadata of the BaseTool. An optional key-value pair for storing and retrieving tool-specific metadata,\nsuch as tool manifests, etc. NOTE: the entire dict must be JSON serializable. description : str \u00b6 The description of the tool. classmethod from_config ( config , config_abs_path ) \u00b6 Creates a tool instance from a config. This default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic. Return type : TypeVar ( SelfTool , bound= BaseTool) Parameters : config \u2013 The config for the tool. config_abs_path \u2013 The absolute path to the config file that contains the\ntool config. Returns : The tool instance. is_long_running : bool = False \u00b6 Whether the tool is a long running operation, which typically returns a\nresource id first and finishes the operation later. name : str \u00b6 The name of the tool. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. class google.adk.tools. DiscoveryEngineSearchTool ( data_store_id = None , data_store_specs = None , search_engine_id = None , filter = None , max_results = None ) \u00b6 Bases: FunctionTool Tool for searching the discovery engine. Initializes the DiscoveryEngineSearchTool. Parameters : data_store_id \u2013 The Vertex AI search data store resource ID in the format\nof\n\u201cprojects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}\u201d. data_store_specs \u2013 Specifications that define the specific DataStores to be\nsearched. It should only be set if engine is used. search_engine_id \u2013 The Vertex AI search engine resource ID in the format of\n\u201cprojects/{project}/locations/{location}/collections/{collection}/engines/{engine}\u201d. filter \u2013 The filter to be applied to the search request. Default is None. max_results \u2013 The maximum number of results to return. Default is None. discovery_engine_search ( query ) \u00b6 Search through Vertex AI Search\u2019s discovery engine search API. Return type : dict [ str , Any ] Parameters : query \u2013 The search query. Returns : A dictionary containing the status of the request and the list of search\nresults, which contains the title, url and content. class google.adk.tools. ExampleTool ( examples ) \u00b6 Bases: BaseTool A tool that adds (few-shot) examples to the LLM request. examples \u00b6 The examples to add to the LLM request. classmethod from_config ( config , config_abs_path ) \u00b6 Creates a tool instance from a config. This default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic. Return type : ExampleTool Parameters : config \u2013 The config for the tool. config_abs_path \u2013 The absolute path to the config file that contains the\ntool config. Returns : The tool instance. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. class google.adk.tools. FunctionTool ( func , * , require_confirmation = False ) \u00b6 Bases: BaseTool A tool that wraps a user-defined Python function. func \u00b6 The function to wrap. Initializes the FunctionTool. Extracts metadata from a callable object. Parameters : func \u2013 The function to wrap. require_confirmation \u2013 Wether this tool requires confirmation. A boolean or\na callable that takes the function\u2019s arguments and returns a boolean. If\nthe callable returns True, the tool will require confirmation from the\nuser. async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. class google.adk.tools. LongRunningFunctionTool ( func ) \u00b6 Bases: FunctionTool A function tool that returns the result asynchronously. This tool is used for long-running operations that may take a significant\namount of time to complete. The framework will call the function. Once the\nfunction returns, the response will be returned asynchronously to the\nframework which is identified by the function_call_id. Example: `python tool = LongRunningFunctionTool(a_long_running_function) ` is_long_running \u00b6 Whether the tool is a long running operation. Initializes the FunctionTool. Extracts metadata from a callable object. Parameters : func \u2013 The function to wrap. require_confirmation \u2013 Wether this tool requires confirmation. A boolean or\na callable that takes the function\u2019s arguments and returns a boolean. If\nthe callable returns True, the tool will require confirmation from the\nuser. class google.adk.tools. MCPToolset ( * args , ** kwargs ) \u00b6 Bases: McpToolset Deprecated name, use McpToolset instead. Initializes the MCPToolset. Parameters : connection_params \u2013 The connection parameters to the MCP server. Can be: StdioConnectionParams for using local mcp server (e.g. using npx or python3 ); or SseConnectionParams for a local/remote SSE server; or StreamableHTTPConnectionParams for local/remote Streamable http\nserver. Note, StdioServerParameters is also supported for using local\nmcp server (e.g. using npx or python3 ), but it does not support\ntimeout, and we recommend to use StdioConnectionParams instead when\ntimeout is needed. tool_filter \u2013 Optional filter to select specific tools. Can be either: - A\nlist of tool names to include - A ToolPredicate function for custom\nfiltering logic tool_name_prefix \u2013 A prefix to be added to the name of each tool in this\ntoolset. errlog \u2013 TextIO stream for error logging. auth_scheme \u2013 The auth scheme of the tool for tool calling auth_credential \u2013 The auth credential of the tool for tool calling require_confirmation \u2013 Whether tools in this toolset require\nconfirmation. Can be a single boolean or a callable to apply to all\ntools. header_provider \u2013 A callable that takes a ReadonlyContext and returns a\ndictionary of headers to be used for the MCP session. class google.adk.tools. ToolContext ( invocation_context , * , function_call_id = None , event_actions = None , tool_confirmation = None ) \u00b6 Bases: CallbackContext The context of the tool. This class provides the context for a tool invocation, including access to\nthe invocation context, function call ID, event actions, and authentication\nresponse. It also provides methods for requesting credentials, retrieving\nauthentication responses, listing artifacts, and searching memory. invocation_context \u00b6 The invocation context of the tool. function_call_id \u00b6 The function call id of the current tool call. This id was\nreturned in the function call event from LLM to identify a function call.\nIf LLM didn\u2019t return this id, ADK will assign one to it. This id is used\nto map function call response to the original function call. event_actions \u00b6 The event actions of the current tool call. tool_confirmation \u00b6 The tool confirmation of the current tool call. property actions : EventActions \u00b6 get_auth_response ( auth_config ) \u00b6 Return type : AuthCredential request_confirmation ( * , hint = None , payload = None ) \u00b6 Requests confirmation for the given function call. Return type : None Parameters : hint \u2013 A hint to the user on how to confirm the tool call. payload \u2013 The payload used to confirm the tool call. request_credential ( auth_config ) \u00b6 Return type : None async search_memory ( query ) \u00b6 Searches the memory of the current user. Return type : SearchMemoryResponse class google.adk.tools. VertexAiSearchTool ( * , data_store_id = None , data_store_specs = None , search_engine_id = None , filter = None , max_results = None , bypass_multi_tools_limit = False ) \u00b6 Bases: BaseTool A built-in tool using Vertex AI Search. data_store_id \u00b6 The Vertex AI search data store resource ID. search_engine_id \u00b6 The Vertex AI search engine resource ID. Initializes the Vertex AI Search tool. Parameters : data_store_id \u2013 The Vertex AI search data store resource ID in the format\nof\n\u201cprojects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}\u201d. data_store_specs \u2013 Specifications that define the specific DataStores to be\nsearched. It should only be set if engine is used. search_engine_id \u2013 The Vertex AI search engine resource ID in the format of\n\u201cprojects/{project}/locations/{location}/collections/{collection}/engines/{engine}\u201d. filter \u2013 The filter to apply to the search results. max_results \u2013 The maximum number of results to return. bypass_multi_tools_limit \u2013 Whether to bypass the multi tools limitation,\nso that the tool can be used with other tools in the same agent. Raises : ValueError \u2013 If both data_store_id and search_engine_id are not specified or both are specified. \u2013 async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. google.adk.tools. exit_loop ( tool_context ) \u00b6 Exits the loop. Call this function only when you are instructed to do so. google.adk.tools. transfer_to_agent ( agent_name , tool_context ) \u00b6 Transfer the question to another agent. This tool hands off control to another agent when it\u2019s more suitable to\nanswer the user\u2019s question according to the agent\u2019s description. Return type : None Parameters : agent_name \u2013 the agent name to transfer to. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.agent_tool module\u00b6"], "text": "google.adk.tools.agent_tool module \u00b6 class google.adk.tools.agent_tool. AgentTool ( agent , skip_summarization = False ) \u00b6 Bases: BaseTool A tool that wraps an agent. This tool allows an agent to be called as a tool within a larger application.\nThe agent\u2019s input schema is used to define the tool\u2019s input parameters, and\nthe agent\u2019s output is returned as the tool\u2019s result. agent \u00b6 The agent to wrap. skip_summarization \u00b6 Whether to skip summarization of the agent output. classmethod from_config ( config , config_abs_path ) \u00b6 Creates a tool instance from a config. This default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic. Return type : AgentTool Parameters : config \u2013 The config for the tool. config_abs_path \u2013 The absolute path to the config file that contains the\ntool config. Returns : The tool instance. populate_name ( ) \u00b6 Return type : Any async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. pydantic model google.adk.tools.agent_tool. AgentToolConfig \u00b6 Bases: BaseToolConfig The config for the AgentTool. Show JSON schema { \"title\" : \"AgentToolConfig\" , \"description\" : \"The config for the AgentTool.\" , \"type\" : \"object\" , \"properties\" : { \"agent\" : { \"$ref\" : \"#/$defs/AgentRefConfig\" }, \"skip_summarization\" : { \"default\" : false , \"title\" : \"Skip Summarization\" , \"type\" : \"boolean\" } }, \"$defs\" : { \"AgentRefConfig\" : { \"additionalProperties\" : false , \"description\" : \"The config for the reference to another agent.\" , \"properties\" : { \"config_path\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Config Path\" }, \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Code\" } }, \"title\" : \"AgentRefConfig\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"agent\" ] } Fields : agent (google.adk.agents.common_configs.AgentRefConfig) skip_summarization (bool) field agent : AgentRefConfig [Required] \u00b6 The reference to the agent instance. field skip_summarization : bool = False \u00b6 Whether to skip summarization of the agent output. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.apihub_tool module\u00b6"], "text": "google.adk.tools.apihub_tool module \u00b6 class google.adk.tools.apihub_tool. APIHubToolset ( * , apihub_resource_name , access_token = None , service_account_json = None , name = '' , description = '' , lazy_load_spec = False , auth_scheme = None , auth_credential = None , apihub_client = None , tool_filter = None ) \u00b6 Bases: BaseToolset APIHubTool generates tools from a given API Hub resource. Examples: apihub_toolset = APIHubToolset ( apihub_resource_name = \"projects/test-project/locations/us-central1/apis/test-api\" , service_account_json = \"...\" , tool_filter = lambda tool , ctx = None : tool . name in ( 'my_tool' , 'my_other_tool' ) ) # Get all available tools agent = LlmAgent ( tools = apihub_toolset ) apihub_resource_name is the resource name from API Hub. It must include\nAPI name, and can optionally include API version and spec name. If apihub_resource_name includes a spec resource name, the content of that\nspec will be used for generating the tools. If apihub_resource_name includes only an api or a version name, the\nfirst spec of the first version of that API will be used. Initializes the APIHubTool with the given parameters. Examples: apihub_toolset = APIHubToolset ( apihub_resource_name = \"projects/test-project/locations/us-central1/apis/test-api\" , service_account_json = \"...\" , ) # Get all available tools agent = LlmAgent ( tools = [ apihub_toolset ]) apihub_toolset = APIHubToolset ( apihub_resource_name = \"projects/test-project/locations/us-central1/apis/test-api\" , service_account_json = \"...\" , tool_filter = [ 'my_tool' ] ) # Get a specific tool agent = LlmAgent ( tools = [ ... , apihub_toolset , ]) apihub_resource_name is the resource name from API Hub. It must include\nAPI name, and can optionally include API version and spec name. If apihub_resource_name includes a spec resource name, the content of that\nspec will be used for generating the tools. If apihub_resource_name includes only an api or a version name, the\nfirst spec of the first version of that API will be used. Example: projects/xxx/locations/us-central1/apis/apiname/\u2026 https://console.cloud.google.com/apigee/api-hub/apis/apiname?project=xxx Parameters : apihub_resource_name \u2013 The resource name of the API in API Hub.\nExample: projects/test-project/locations/us-central1/apis/test-api . access_token \u2013 Google Access token. Generate with gcloud cli gcloud auth auth print-access-token . Used for fetching API Specs from API Hub. service_account_json \u2013 The service account config as a json string.\nRequired if not using default service credential. It is used for\ncreating the API Hub client and fetching the API Specs from API Hub. apihub_client \u2013 Optional custom API Hub client. name \u2013 Name of the toolset. Optional. description \u2013 Description of the toolset. Optional. auth_scheme \u2013 Auth scheme that applies to all the tool in the toolset. auth_credential \u2013 Auth credential that applies to all the tool in the\ntoolset. lazy_load_spec \u2013 If True, the spec will be loaded lazily when needed.\nOtherwise, the spec will be loaded immediately and the tools will be\ngenerated during initialization. tool_filter \u2013 The filter used to filter the tools in the toolset. It can\nbe either a tool predicate or a list of tool names of the tools to\nexpose. async close ( ) \u00b6 Performs cleanup and releases resources held by the toolset. Note This method is invoked, for example, at the end of an agent server\u2019s\nlifecycle or when the toolset is no longer needed. Implementations\nshould ensure that any open connections, files, or other managed\nresources are properly released to prevent leaks. async get_tools ( readonly_context = None ) \u00b6 Retrieves all available tools. Return type : List [ RestApiTool ] Returns : A list of all available RestApiTool objects. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.application_integration_tool module\u00b6"], "text": "google.adk.tools.application_integration_tool module \u00b6 class google.adk.tools.application_integration_tool. ApplicationIntegrationToolset ( project , location , integration = None , triggers = None , connection = None , entity_operations = None , actions = None , tool_name_prefix = '' , tool_instructions = '' , service_account_json = None , auth_scheme = None , auth_credential = None , tool_filter = None ) \u00b6 Bases: BaseToolset ApplicationIntegrationToolset generates tools from a given Application\nIntegration or Integration Connector resource. Example Usage: # Get all available tools for an integration with api trigger application_integration_toolset = ApplicationIntegrationToolset ( project = \"test-project\" , location = \"us-central1\" integration = \"test-integration\" , triggers = [ \"api_trigger/test_trigger\" ], service_account_credentials = { ... }, ) # Get all available tools for a connection using entity operations and # actions # Note: Find the list of supported entity operations and actions for a # connection using integration connector apis: # https://cloud.google.com/integration-connectors/docs/reference/rest/v1/projects.locations.connections.connectionSchemaMetadata application_integration_toolset = ApplicationIntegrationToolset ( project = \"test-project\" , location = \"us-central1\" connection = \"test-connection\" , entity_operations = [ \"EntityId1\" : [ \"LIST\" , \"CREATE\" ], \"EntityId2\" : []], #empty list for actions means all operations on the entity are supported actions = [ \"action1\" ], service_account_credentials = { ... }, ) # Feed the toolset to agent agent = LlmAgent ( tools = [ ... , application_integration_toolset , ]) Args: Parameters : project \u2013 The GCP project ID. location \u2013 The GCP location. integration \u2013 The integration name. triggers \u2013 The list of trigger names in the integration. connection \u2013 The connection name. entity_operations \u2013 The entity operations supported by the connection. actions \u2013 The actions supported by the connection. tool_name_prefix \u2013 The name prefix of the generated tools. tool_instructions \u2013 The instructions for the tool. service_account_json \u2013 The service account configuration as a dictionary.\nRequired if not using default service credential. Used for fetching\nthe Application Integration or Integration Connector resource. tool_filter \u2013 The filter used to filter the tools in the toolset. It can\nbe either a tool predicate or a list of tool names of the tools to\nexpose. Raises : ValueError \u2013 If none of the following conditions are met:\n    - integration is provided.\n    - connection is provided and at least one of entity_operations or actions is provided. Exception \u2013 If there is an error during the initialization of the\n    integration or connection client. async close ( ) \u00b6 Performs cleanup and releases resources held by the toolset. Return type : None Note This method is invoked, for example, at the end of an agent server\u2019s\nlifecycle or when the toolset is no longer needed. Implementations\nshould ensure that any open connections, files, or other managed\nresources are properly released to prevent leaks. async get_tools ( readonly_context = None ) \u00b6 Return all tools in the toolset based on the provided context. Return type : List [ RestApiTool ] Parameters : readonly_context ( ReadonlyContext , optional ) \u2013 Context used to filter tools\navailable to the agent. If None, all tools in the toolset are returned. Returns : A list of tools available under the specified context. Return type : list[ BaseTool ] class google.adk.tools.application_integration_tool. IntegrationConnectorTool ( name , description , connection_name , connection_host , connection_service_name , entity , operation , action , rest_api_tool , auth_scheme = None , auth_credential = None ) \u00b6 Bases: BaseTool A tool that wraps a RestApiTool to interact with a specific Application Integration endpoint. This tool adds Application Integration specific context like connection\ndetails, entity, operation, and action to the underlying REST API call\nhandled by RestApiTool. It prepares the arguments and then delegates the\nactual API call execution to the contained RestApiTool instance. Generates request params and body Attaches auth credentials to API call. Example: # Each API operation in the spec will be turned into its own tool # Name of the tool is the operationId of that operation, in snake case operations = OperationGenerator () . parse ( openapi_spec_dict ) tool = [ RestApiTool . from_parsed_operation ( o ) for o in operations ] Initializes the ApplicationIntegrationTool. Parameters : name \u2013 The name of the tool, typically derived from the API operation.\nShould be unique and adhere to Gemini function naming conventions\n(e.g., less than 64 characters). description \u2013 A description of what the tool does, usually based on the\nAPI operation\u2019s summary or description. connection_name \u2013 The name of the Integration Connector connection. connection_host \u2013 The hostname or IP address for the connection. connection_service_name \u2013 The specific service name within the host. entity \u2013 The Integration Connector entity being targeted. operation \u2013 The specific operation being performed on the entity. action \u2013 The action associated with the operation (e.g., \u2018execute\u2019). rest_api_tool \u2013 An initialized RestApiTool instance that handles the\nunderlying REST API communication based on an OpenAPI specification\noperation. This tool will be called by ApplicationIntegrationTool with\nadded connection and context arguments. tool =\n[RestApiTool.from_parsed_operation(o) for o in operations] EXCLUDE_FIELDS = ['connection_name', 'service_name', 'host', 'entity', 'operation', 'action', 'dynamic_auth_config'] \u00b6 OPTIONAL_FIELDS = ['page_size', 'page_token', 'filter', 'sortByColumns'] \u00b6 async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Dict [ str , Any ] Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.authenticated_function_tool module\u00b6"], "text": "google.adk.tools.authenticated_function_tool module \u00b6 class google.adk.tools.authenticated_function_tool. AuthenticatedFunctionTool ( * , func , auth_config = None , response_for_auth_required = None ) \u00b6 Bases: FunctionTool A FunctionTool that handles authentication before the actual tool logic\ngets called. Functions can accept a special credential argument which is the\ncredential ready for use.(Experimental) Initializes the AuthenticatedFunctionTool. Parameters : func \u2013 The function to be called. auth_config \u2013 The authentication configuration. response_for_auth_required \u2013 The response to return when the tool is\nrequesting auth credential from the client. There could be two case,\nthe tool doesn\u2019t configure any credentials\n(auth_config.raw_auth_credential is missing) or the credentials\nconfigured is not enough to authenticate the tool (e.g. an OAuth\nclient id and client secrect is configured.) and needs client input\n(e.g. client need to involve the end user in an oauth flow and get\nback the oauth response.) async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.base_authenticated_tool module\u00b6"], "text": "google.adk.tools.base_authenticated_tool module \u00b6 class google.adk.tools.base_authenticated_tool. BaseAuthenticatedTool ( * , name , description , auth_config = None , response_for_auth_required = None ) \u00b6 Bases: BaseTool A base tool class that handles authentication before the actual tool logic\ngets called. Functions can accept a special credential argument which is the\ncredential ready for use.(Experimental) Parameters : name \u2013 The name of the tool. description \u2013 The description of the tool. auth_config \u2013 The auth configuration of the tool. response_for_auth_required \u2013 The response to return when the tool is\nrequesting auth credential from the client. There could be two case,\nthe tool doesn\u2019t configure any credentials\n(auth_config.raw_auth_credential is missing) or the credentials\nconfigured is not enough to authenticate the tool (e.g. an OAuth\nclient id and client secrect is configured.) and needs client input\n(e.g. client need to involve the end user in an oauth flow and get\nback the oauth response.) async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.base_tool module\u00b6"], "text": "google.adk.tools.base_tool module \u00b6 class google.adk.tools.base_tool. BaseTool ( * , name , description , is_long_running = False , custom_metadata = None ) \u00b6 Bases: ABC The base class for all tools. custom_metadata : Optional [ dict [ str , Any ]] = None \u00b6 The custom metadata of the BaseTool. An optional key-value pair for storing and retrieving tool-specific metadata,\nsuch as tool manifests, etc. NOTE: the entire dict must be JSON serializable. description : str \u00b6 The description of the tool. classmethod from_config ( config , config_abs_path ) \u00b6 Creates a tool instance from a config. This default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic. Return type : TypeVar ( SelfTool , bound= BaseTool) Parameters : config \u2013 The config for the tool. config_abs_path \u2013 The absolute path to the config file that contains the\ntool config. Returns : The tool instance. is_long_running : bool = False \u00b6 Whether the tool is a long running operation, which typically returns a\nresource id first and finishes the operation later. name : str \u00b6 The name of the tool. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.base_toolset module\u00b6"], "text": "google.adk.tools.base_toolset module \u00b6 class google.adk.tools.base_toolset. BaseToolset ( * , tool_filter = None , tool_name_prefix = None ) \u00b6 Bases: ABC Base class for toolset. A toolset is a collection of tools that can be used by an agent. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. async close ( ) \u00b6 Performs cleanup and releases resources held by the toolset. Return type : None Note This method is invoked, for example, at the end of an agent server\u2019s\nlifecycle or when the toolset is no longer needed. Implementations\nshould ensure that any open connections, files, or other managed\nresources are properly released to prevent leaks. classmethod from_config ( config , config_abs_path ) \u00b6 Creates a toolset instance from a config. Return type : TypeVar ( SelfToolset , bound= BaseToolset) Parameters : config \u2013 The config for the tool. config_abs_path \u2013 The absolute path to the config file that contains the\ntool config. Returns : The toolset instance. abstractmethod async get_tools ( readonly_context = None ) \u00b6 Return all tools in the toolset based on the provided context. Return type : list [ BaseTool ] Parameters : readonly_context ( ReadonlyContext , optional ) \u2013 Context used to filter tools\navailable to the agent. If None, all tools in the toolset are returned. Returns : A list of tools available under the specified context. Return type : list[ BaseTool ] final async get_tools_with_prefix ( readonly_context = None ) \u00b6 Return all tools with optional prefix applied to tool names. This method calls get_tools() and applies prefixing if tool_name_prefix is provided. Return type : list [ BaseTool ] Parameters : readonly_context ( ReadonlyContext , optional ) \u2013 Context used to filter tools\navailable to the agent. If None, all tools in the toolset are returned. Returns : A list of tools with prefixed names if tool_name_prefix is provided. Return type : list[ BaseTool ] async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request. Return type : None Use cases:\n- Instead of let each tool process the llm request, we can let the toolset process the llm request. e.g. ComputerUseToolset can add computer use\ntool to the llm request. Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. class google.adk.tools.base_toolset. ToolPredicate ( * args , ** kwargs ) \u00b6 Bases: Protocol Base class for a predicate that defines the interface to decide whether a tool should be exposed to LLM. Toolset implementer could consider whether to\naccept such instance in the toolset\u2019s constructor and apply the predicate in\nget_tools method. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.bigquery module\u00b6"], "text": "google.adk.tools.bigquery module \u00b6 BigQuery Tools (Experimental). BigQuery Tools under this module are hand crafted and customized while the tools\nunder google.adk.tools.google_api_tool are auto generated based on API\ndefinition. The rationales to have customized tool are: BigQuery APIs have functions overlaps and LLM can\u2019t tell what tool to use BigQuery APIs have a lot of parameters with some rarely used, which are not\nLLM-friendly We want to provide more high-level tools like forecasting, RAG, segmentation,\netc. We want to provide extra access guardrails in those tools. For example,\nexecute_sql can\u2019t arbitrarily mutate existing data. pydantic model google.adk.tools.bigquery. BigQueryCredentialsConfig \u00b6 Bases: BaseGoogleCredentialsConfig BigQuery Credentials Configuration for Google API tools (Experimental). Please do not use this in production, as it may be deprecated later. Show JSON schema { \"title\" : \"BigQueryCredentialsConfig\" , \"type\" : \"object\" , \"properties\" : { \"credentials\" : { \"default\" : null , \"title\" : \"Credentials\" }, \"client_id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Client Id\" }, \"client_secret\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Client Secret\" }, \"scopes\" : { \"anyOf\" : [ { \"items\" : { \"type\" : \"string\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Scopes\" } }, \"additionalProperties\" : false } Fields : Validators : __post_init__ \u00bb all fields model_post_init ( context , / ) \u00b6 This function is meant to behave like a BaseModel method to initialise private attributes. It takes context as an argument since that\u2019s what pydantic-core passes when calling it. Return type : None Parameters : self \u2013 The BaseModel instance. context \u2013 The context. class google.adk.tools.bigquery. BigQueryToolset ( * , tool_filter = None , credentials_config = None , bigquery_tool_config = None ) \u00b6 Bases: BaseToolset BigQuery Toolset contains tools for interacting with BigQuery data and metadata. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. async close ( ) \u00b6 Performs cleanup and releases resources held by the toolset. Note This method is invoked, for example, at the end of an agent server\u2019s\nlifecycle or when the toolset is no longer needed. Implementations\nshould ensure that any open connections, files, or other managed\nresources are properly released to prevent leaks. async get_tools ( readonly_context = None ) \u00b6 Get tools from the toolset. Return type : List [ BaseTool ] ", "code_blocks": []}, {"heading_path": ["google.adk.tools.crewai_tool module\u00b6"], "text": "google.adk.tools.crewai_tool module \u00b6 class google.adk.tools.crewai_tool. CrewaiTool ( tool , * , name , description ) \u00b6 Bases: FunctionTool Use this class to wrap a CrewAI tool. If the original tool name and description are not suitable, you can override\nthem in the constructor. Initializes the FunctionTool. Extracts metadata from a callable object. Parameters : func \u2013 The function to wrap. require_confirmation \u2013 Wether this tool requires confirmation. A boolean or\na callable that takes the function\u2019s arguments and returns a boolean. If\nthe callable returns True, the tool will require confirmation from the\nuser. classmethod from_config ( config , config_abs_path ) \u00b6 Creates a tool instance from a config. This default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic. Return type : CrewaiTool Parameters : config \u2013 The config for the tool. config_abs_path \u2013 The absolute path to the config file that contains the\ntool config. Returns : The tool instance. tool : CrewaiBaseTool \u00b6 The wrapped CrewAI tool. pydantic model google.adk.tools.crewai_tool. CrewaiToolConfig \u00b6 Bases: BaseToolConfig Show JSON schema { \"title\" : \"CrewaiToolConfig\" , \"type\" : \"object\" , \"properties\" : { \"tool\" : { \"title\" : \"Tool\" , \"type\" : \"string\" }, \"name\" : { \"default\" : \"\" , \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" } }, \"additionalProperties\" : false , \"required\" : [ \"tool\" ] } Fields : description (str) name (str) tool (str) field description : str = '' \u00b6 The description of the tool. field name : str = '' \u00b6 The name of the tool. field tool : str [Required] \u00b6 The fully qualified path of the CrewAI tool instance. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.enterprise_search_tool module\u00b6"], "text": "google.adk.tools.enterprise_search_tool module \u00b6 class google.adk.tools.enterprise_search_tool. EnterpriseWebSearchTool \u00b6 Bases: BaseTool A Gemini 2+ built-in tool using web grounding for Enterprise compliance. See the documentation for more details: https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/web-grounding-enterprise . Initializes the Vertex AI Search tool. description : str \u00b6 The description of the tool. name : str \u00b6 The name of the tool. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.example_tool module\u00b6"], "text": "google.adk.tools.example_tool module \u00b6 class google.adk.tools.example_tool. ExampleTool ( examples ) \u00b6 Bases: BaseTool A tool that adds (few-shot) examples to the LLM request. examples \u00b6 The examples to add to the LLM request. classmethod from_config ( config , config_abs_path ) \u00b6 Creates a tool instance from a config. This default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic. Return type : ExampleTool Parameters : config \u2013 The config for the tool. config_abs_path \u2013 The absolute path to the config file that contains the\ntool config. Returns : The tool instance. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. pydantic model google.adk.tools.example_tool. ExampleToolConfig \u00b6 Bases: BaseToolConfig Show JSON schema { \"title\" : \"ExampleToolConfig\" , \"type\" : \"object\" , \"properties\" : { \"examples\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Example\" }, \"type\" : \"array\" }, { \"type\" : \"string\" } ], \"title\" : \"Examples\" } }, \"$defs\" : { \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"Content\" : { \"additionalProperties\" : false , \"description\" : \"Contains the multi-part content of a message.\" , \"properties\" : { \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Part\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a single message. Each part may have\\n      a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The producer of the content. Must be either 'user' or\\n      'model'. Useful to set for multi-turn conversations, otherwise can be\\n      empty. If role is not specified, SDK will determine the role.\" , \"title\" : \"Role\" } }, \"title\" : \"Content\" , \"type\" : \"object\" }, \"Example\" : { \"description\" : \"A few-shot example.\\n\\nAttributes:\\n  input: The input content for the example.\\n  output: The expected output content for the example.\" , \"properties\" : { \"input\" : { \"$ref\" : \"#/$defs/Content\" }, \"output\" : { \"items\" : { \"$ref\" : \"#/$defs/Content\" }, \"title\" : \"Output\" , \"type\" : \"array\" } }, \"required\" : [ \"input\" , \"output\" ], \"title\" : \"Example\" , \"type\" : \"object\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" } }, \"additionalProperties\" : false , \"required\" : [ \"examples\" ] } Fields : examples (list[google.adk.examples.example.Example] | str) field examples : Union[list[Example], str] [Required] \u00b6 The examples to add to the LLM request. User can either provide a list of\nexamples or a fully-qualified name to a BaseExampleProvider object in code. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.exit_loop_tool module\u00b6"], "text": "google.adk.tools.exit_loop_tool module \u00b6 google.adk.tools.exit_loop_tool. exit_loop ( tool_context ) \u00b6 Exits the loop. Call this function only when you are instructed to do so. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.function_tool module\u00b6"], "text": "google.adk.tools.function_tool module \u00b6 class google.adk.tools.function_tool. FunctionTool ( func , * , require_confirmation = False ) \u00b6 Bases: BaseTool A tool that wraps a user-defined Python function. func \u00b6 The function to wrap. Initializes the FunctionTool. Extracts metadata from a callable object. Parameters : func \u2013 The function to wrap. require_confirmation \u2013 Wether this tool requires confirmation. A boolean or\na callable that takes the function\u2019s arguments and returns a boolean. If\nthe callable returns True, the tool will require confirmation from the\nuser. async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.get_user_choice_tool module\u00b6"], "text": "google.adk.tools.get_user_choice_tool module \u00b6 google.adk.tools.get_user_choice_tool. get_user_choice ( options , tool_context ) \u00b6 Provides the options to the user and asks them to choose one. Return type : Optional [ str ] ", "code_blocks": []}, {"heading_path": ["google.adk.tools.google_api_tool module\u00b6"], "text": "google.adk.tools.google_api_tool module \u00b6 Auto-generated tools and toolsets for Google APIs. These tools and toolsets are auto-generated based on the API specifications\nprovided by the Google API Discovery API. class google.adk.tools.google_api_tool. BigQueryToolset ( client_id = None , client_secret = None , tool_filter = None , service_account = None , tool_name_prefix = None ) \u00b6 Bases: GoogleApiToolset Auto-generated BigQuery toolset based on Google BigQuery API v2 spec exposed by Google API discovery API. Parameters : client_id \u2013 OAuth2 client ID for authentication. client_secret \u2013 OAuth2 client secret for authentication. tool_filter \u2013 Optional filter to include only specific tools or use a predicate function. service_account \u2013 Optional service account for authentication. tool_name_prefix \u2013 Optional prefix to add to all tool names in this toolset. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. class google.adk.tools.google_api_tool. CalendarToolset ( client_id = None , client_secret = None , tool_filter = None , service_account = None , tool_name_prefix = None ) \u00b6 Bases: GoogleApiToolset Auto-generated Calendar toolset based on Google Calendar API v3 spec exposed by Google API discovery API. Parameters : client_id \u2013 OAuth2 client ID for authentication. client_secret \u2013 OAuth2 client secret for authentication. tool_filter \u2013 Optional filter to include only specific tools or use a predicate function. service_account \u2013 Optional service account for authentication. tool_name_prefix \u2013 Optional prefix to add to all tool names in this toolset. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. class google.adk.tools.google_api_tool. DocsToolset ( client_id = None , client_secret = None , tool_filter = None , service_account = None , tool_name_prefix = None ) \u00b6 Bases: GoogleApiToolset Auto-generated Docs toolset based on Google Docs API v1 spec exposed by Google API discovery API. Parameters : client_id \u2013 OAuth2 client ID for authentication. client_secret \u2013 OAuth2 client secret for authentication. tool_filter \u2013 Optional filter to include only specific tools or use a predicate function. service_account \u2013 Optional service account for authentication. tool_name_prefix \u2013 Optional prefix to add to all tool names in this toolset. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. class google.adk.tools.google_api_tool. GmailToolset ( client_id = None , client_secret = None , tool_filter = None , service_account = None , tool_name_prefix = None ) \u00b6 Bases: GoogleApiToolset Auto-generated Gmail toolset based on Google Gmail API v1 spec exposed by Google API discovery API. Parameters : client_id \u2013 OAuth2 client ID for authentication. client_secret \u2013 OAuth2 client secret for authentication. tool_filter \u2013 Optional filter to include only specific tools or use a predicate function. service_account \u2013 Optional service account for authentication. tool_name_prefix \u2013 Optional prefix to add to all tool names in this toolset. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. class google.adk.tools.google_api_tool. GoogleApiTool ( rest_api_tool , client_id = None , client_secret = None , service_account = None ) \u00b6 Bases: BaseTool configure_auth ( client_id , client_secret ) \u00b6 configure_sa_auth ( service_account ) \u00b6 description : str \u00b6 The description of the tool. name : str \u00b6 The name of the tool. async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Dict [ str , Any ] Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. class google.adk.tools.google_api_tool. GoogleApiToolset ( api_name , api_version , client_id = None , client_secret = None , tool_filter = None , service_account = None , tool_name_prefix = None ) \u00b6 Bases: BaseToolset Google API Toolset contains tools for interacting with Google APIs. Usually one toolsets will contains tools only related to one Google API, e.g.\nGoogle Bigquery API toolset will contains tools only related to Google\nBigquery API, like list dataset tool, list table tool etc. Parameters : api_name \u2013 The name of the Google API (e.g., \u201ccalendar\u201d, \u201cgmail\u201d). api_version \u2013 The version of the API (e.g., \u201cv3\u201d, \u201cv1\u201d). client_id \u2013 OAuth2 client ID for authentication. client_secret \u2013 OAuth2 client secret for authentication. tool_filter \u2013 Optional filter to include only specific tools or use a predicate function. service_account \u2013 Optional service account for authentication. tool_name_prefix \u2013 Optional prefix to add to all tool names in this toolset. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. async close ( ) \u00b6 Performs cleanup and releases resources held by the toolset. Note This method is invoked, for example, at the end of an agent server\u2019s\nlifecycle or when the toolset is no longer needed. Implementations\nshould ensure that any open connections, files, or other managed\nresources are properly released to prevent leaks. configure_auth ( client_id , client_secret ) \u00b6 configure_sa_auth ( service_account ) \u00b6 async get_tools ( readonly_context = None ) \u00b6 Get all tools in the toolset. Return type : List [ GoogleApiTool ] set_tool_filter ( tool_filter ) \u00b6 class google.adk.tools.google_api_tool. SheetsToolset ( client_id = None , client_secret = None , tool_filter = None , service_account = None , tool_name_prefix = None ) \u00b6 Bases: GoogleApiToolset Auto-generated Sheets toolset based on Google Sheets API v4 spec exposed by Google API discovery API. Parameters : client_id \u2013 OAuth2 client ID for authentication. client_secret \u2013 OAuth2 client secret for authentication. tool_filter \u2013 Optional filter to include only specific tools or use a predicate function. service_account \u2013 Optional service account for authentication. tool_name_prefix \u2013 Optional prefix to add to all tool names in this toolset. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. class google.adk.tools.google_api_tool. SlidesToolset ( client_id = None , client_secret = None , tool_filter = None , service_account = None , tool_name_prefix = None ) \u00b6 Bases: GoogleApiToolset Auto-generated Slides toolset based on Google Slides API v1 spec exposed by Google API discovery API. Parameters : client_id \u2013 OAuth2 client ID for authentication. client_secret \u2013 OAuth2 client secret for authentication. tool_filter \u2013 Optional filter to include only specific tools or use a predicate function. service_account \u2013 Optional service account for authentication. tool_name_prefix \u2013 Optional prefix to add to all tool names in this toolset. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. class google.adk.tools.google_api_tool. YoutubeToolset ( client_id = None , client_secret = None , tool_filter = None , service_account = None , tool_name_prefix = None ) \u00b6 Bases: GoogleApiToolset Auto-generated YouTube toolset based on YouTube API v3 spec exposed by Google API discovery API. Parameters : client_id \u2013 OAuth2 client ID for authentication. client_secret \u2013 OAuth2 client secret for authentication. tool_filter \u2013 Optional filter to include only specific tools or use a predicate function. service_account \u2013 Optional service account for authentication. tool_name_prefix \u2013 Optional prefix to add to all tool names in this toolset. Initialize the toolset. Parameters : tool_filter \u2013 Filter to apply to tools. tool_name_prefix \u2013 The prefix to prepend to the names of the tools returned by the toolset. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.google_maps_grounding_tool module\u00b6"], "text": "google.adk.tools.google_maps_grounding_tool module \u00b6 class google.adk.tools.google_maps_grounding_tool. GoogleMapsGroundingTool \u00b6 Bases: BaseTool A built-in tool that is automatically invoked by Gemini 2 models to ground query results with Google Maps. This tool operates internally within the model and does not require or perform\nlocal code execution. Only available for use with the VertexAI Gemini API (e.g.\nGOOGLE_GENAI_USE_VERTEXAI=TRUE) description : str \u00b6 The description of the tool. name : str \u00b6 The name of the tool. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.google_search_tool module\u00b6"], "text": "google.adk.tools.google_search_tool module \u00b6 class google.adk.tools.google_search_tool. GoogleSearchTool ( * , bypass_multi_tools_limit = False ) \u00b6 Bases: BaseTool A built-in tool that is automatically invoked by Gemini 2 models to retrieve search results from Google Search. This tool operates internally within the model and does not require or perform\nlocal code execution. Initializes the Google search tool. Parameters : bypass_multi_tools_limit \u2013 Whether to bypass the multi tools limitation,\nso that the tool can be used with other tools in the same agent. description : str \u00b6 The description of the tool. name : str \u00b6 The name of the tool. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.langchain_tool module\u00b6"], "text": "google.adk.tools.langchain_tool module \u00b6 class google.adk.tools.langchain_tool. LangchainTool ( tool , name = None , description = None ) \u00b6 Bases: FunctionTool Adapter class that wraps a Langchain tool for use with ADK. This adapter converts Langchain tools into a format compatible with Google\u2019s\ngenerative AI function calling interface. It preserves the tool\u2019s name,\ndescription, and functionality while adapting its schema. The original tool\u2019s name and description can be overridden if needed. Parameters : tool \u2013 A Langchain tool to wrap (BaseTool or a tool with a .run method) name \u2013 Optional override for the tool\u2019s name description \u2013 Optional override for the tool\u2019s description Examples: from langchain.tools import DuckDuckGoSearchTool from google.genai.tools import LangchainTool search_tool = DuckDuckGoSearchTool () wrapped_tool = LangchainTool ( search_tool ) Initializes the FunctionTool. Extracts metadata from a callable object. Parameters : func \u2013 The function to wrap. require_confirmation \u2013 Wether this tool requires confirmation. A boolean or\na callable that takes the function\u2019s arguments and returns a boolean. If\nthe callable returns True, the tool will require confirmation from the\nuser. classmethod from_config ( config , config_abs_path ) \u00b6 Creates a tool instance from a config. This default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic. Return type : LangchainTool Parameters : config \u2013 The config for the tool. config_abs_path \u2013 The absolute path to the config file that contains the\ntool config. Returns : The tool instance. pydantic model google.adk.tools.langchain_tool. LangchainToolConfig \u00b6 Bases: BaseToolConfig Show JSON schema { \"title\" : \"LangchainToolConfig\" , \"type\" : \"object\" , \"properties\" : { \"tool\" : { \"title\" : \"Tool\" , \"type\" : \"string\" }, \"name\" : { \"default\" : \"\" , \"title\" : \"Name\" , \"type\" : \"string\" }, \"description\" : { \"default\" : \"\" , \"title\" : \"Description\" , \"type\" : \"string\" } }, \"additionalProperties\" : false , \"required\" : [ \"tool\" ] } Fields : description (str) name (str) tool (str) field description : str = '' \u00b6 The description of the tool. field name : str = '' \u00b6 The name of the tool. field tool : str [Required] \u00b6 The fully qualified path of the Langchain tool instance. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.load_artifacts_tool module\u00b6"], "text": "google.adk.tools.load_artifacts_tool module \u00b6 class google.adk.tools.load_artifacts_tool. LoadArtifactsTool \u00b6 Bases: BaseTool A tool that loads the artifacts and adds them to the session. description : str \u00b6 The description of the tool. name : str \u00b6 The name of the tool. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.load_memory_tool module\u00b6"], "text": "google.adk.tools.load_memory_tool module \u00b6 pydantic model google.adk.tools.load_memory_tool. LoadMemoryResponse \u00b6 Bases: BaseModel Show JSON schema { \"title\" : \"LoadMemoryResponse\" , \"type\" : \"object\" , \"properties\" : { \"memories\" : { \"items\" : { \"$ref\" : \"#/$defs/MemoryEntry\" }, \"title\" : \"Memories\" , \"type\" : \"array\" } }, \"$defs\" : { \"Blob\" : { \"additionalProperties\" : false , \"description\" : \"Content blob.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Raw bytes.\" , \"title\" : \"Data\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"Blob\" , \"type\" : \"object\" }, \"CodeExecutionResult\" : { \"additionalProperties\" : false , \"description\" : \"Result of executing the [ExecutableCode].\\n\\nOnly generated when using the [CodeExecution] tool, and always follows a\\n`part` containing the [ExecutableCode].\" , \"properties\" : { \"outcome\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Outcome\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Outcome of the code execution.\" }, \"output\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Contains stdout when code execution is successful, stderr or other description otherwise.\" , \"title\" : \"Output\" } }, \"title\" : \"CodeExecutionResult\" , \"type\" : \"object\" }, \"Content\" : { \"additionalProperties\" : false , \"description\" : \"Contains the multi-part content of a message.\" , \"properties\" : { \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/Part\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a single message. Each part may have\\n      a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"role\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The producer of the content. Must be either 'user' or\\n      'model'. Useful to set for multi-turn conversations, otherwise can be\\n      empty. If role is not specified, SDK will determine the role.\" , \"title\" : \"Role\" } }, \"title\" : \"Content\" , \"type\" : \"object\" }, \"ExecutableCode\" : { \"additionalProperties\" : false , \"description\" : \"Code generated by the model that is meant to be executed, and the result returned to the model.\\n\\nGenerated when using the [CodeExecution] tool, in which the code will be\\nautomatically executed, and a corresponding [CodeExecutionResult] will also be\\ngenerated.\" , \"properties\" : { \"code\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The code to be executed.\" , \"title\" : \"Code\" }, \"language\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Language\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Programming language of the `code`.\" } }, \"title\" : \"ExecutableCode\" , \"type\" : \"object\" }, \"FileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data.\" , \"properties\" : { \"displayName\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls.\" , \"title\" : \"Displayname\" }, \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FileData\" , \"type\" : \"object\" }, \"FunctionCall\" : { \"additionalProperties\" : false , \"description\" : \"A function call.\" , \"properties\" : { \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The unique id of the function call. If populated, the client to execute the\\n   `function_call` and return the response with the matching `id`.\" , \"title\" : \"Id\" }, \"args\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.\" , \"title\" : \"Args\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name].\" , \"title\" : \"Name\" } }, \"title\" : \"FunctionCall\" , \"type\" : \"object\" }, \"FunctionResponse\" : { \"additionalProperties\" : false , \"description\" : \"A function response.\" , \"properties\" : { \"willContinue\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.\" , \"title\" : \"Willcontinue\" }, \"scheduling\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseScheduling\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.\" }, \"parts\" : { \"anyOf\" : [ { \"items\" : { \"$ref\" : \"#/$defs/FunctionResponsePart\" }, \"type\" : \"array\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"List of parts that constitute a function response. Each part may\\n      have a different IANA MIME type.\" , \"title\" : \"Parts\" }, \"id\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.\" , \"title\" : \"Id\" }, \"name\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].\" , \"title\" : \"Name\" }, \"response\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The function response in JSON object format. Use \\\"output\\\" key to specify function output and \\\"error\\\" key to specify error details (if any). If \\\"output\\\" and \\\"error\\\" keys are not specified, then whole \\\"response\\\" is treated as function output.\" , \"title\" : \"Response\" } }, \"title\" : \"FunctionResponse\" , \"type\" : \"object\" }, \"FunctionResponseBlob\" : { \"additionalProperties\" : false , \"description\" : \"Raw media bytes for function response.\\n\\nText should not be sent as raw bytes, use the FunctionResponse.response\\nfield.\" , \"properties\" : { \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" }, \"data\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. Inline media bytes.\" , \"title\" : \"Data\" } }, \"title\" : \"FunctionResponseBlob\" , \"type\" : \"object\" }, \"FunctionResponseFileData\" : { \"additionalProperties\" : false , \"description\" : \"URI based data for function response.\" , \"properties\" : { \"fileUri\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. URI.\" , \"title\" : \"Fileuri\" }, \"mimeType\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Required. The IANA standard MIME type of the source data.\" , \"title\" : \"Mimetype\" } }, \"title\" : \"FunctionResponseFileData\" , \"type\" : \"object\" }, \"FunctionResponsePart\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media that is part of a `FunctionResponse` message.\\n\\nA `FunctionResponsePart` consists of data which has an associated datatype. A\\n`FunctionResponsePart` can only contain one of the accepted types in\\n`FunctionResponsePart.data`.\\n\\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\\ntype and subtype of the media if the `inline_data` field is filled with raw\\nbytes.\" , \"properties\" : { \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseBlob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inline media bytes.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponseFileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" } }, \"title\" : \"FunctionResponsePart\" , \"type\" : \"object\" }, \"FunctionResponseScheduling\" : { \"description\" : \"Specifies how the response should be scheduled in the conversation.\" , \"enum\" : [ \"SCHEDULING_UNSPECIFIED\" , \"SILENT\" , \"WHEN_IDLE\" , \"INTERRUPT\" ], \"title\" : \"FunctionResponseScheduling\" , \"type\" : \"string\" }, \"Language\" : { \"description\" : \"Required. Programming language of the `code`.\" , \"enum\" : [ \"LANGUAGE_UNSPECIFIED\" , \"PYTHON\" ], \"title\" : \"Language\" , \"type\" : \"string\" }, \"MemoryEntry\" : { \"description\" : \"Represent one memory entry.\" , \"properties\" : { \"content\" : { \"$ref\" : \"#/$defs/Content\" }, \"author\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Author\" }, \"timestamp\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Timestamp\" } }, \"required\" : [ \"content\" ], \"title\" : \"MemoryEntry\" , \"type\" : \"object\" }, \"Outcome\" : { \"description\" : \"Required. Outcome of the code execution.\" , \"enum\" : [ \"OUTCOME_UNSPECIFIED\" , \"OUTCOME_OK\" , \"OUTCOME_FAILED\" , \"OUTCOME_DEADLINE_EXCEEDED\" ], \"title\" : \"Outcome\" , \"type\" : \"string\" }, \"Part\" : { \"additionalProperties\" : false , \"description\" : \"A datatype containing media content.\\n\\nExactly one field within a Part should be set, representing the specific type\\nof content being conveyed. Using multiple fields within the same `Part`\\ninstance is considered invalid.\" , \"properties\" : { \"videoMetadata\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/VideoMetadata\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Metadata for a given video.\" }, \"thought\" : { \"anyOf\" : [ { \"type\" : \"boolean\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Indicates if the part is thought from the model.\" , \"title\" : \"Thought\" }, \"inlineData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/Blob\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Inlined bytes data.\" }, \"fileData\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FileData\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. URI based data.\" }, \"thoughtSignature\" : { \"anyOf\" : [ { \"format\" : \"base64url\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"An opaque signature for the thought so it can be reused in subsequent requests.\" , \"title\" : \"Thoughtsignature\" }, \"functionCall\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionCall\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"A predicted [FunctionCall] returned from the model that contains a string\\n      representing the [FunctionDeclaration.name] and a structured JSON object\\n      containing the parameters and their values.\" }, \"codeExecutionResult\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/CodeExecutionResult\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Result of executing the [ExecutableCode].\" }, \"executableCode\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/ExecutableCode\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Code generated by the model that is meant to be executed.\" }, \"functionResponse\" : { \"anyOf\" : [ { \"$ref\" : \"#/$defs/FunctionResponse\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.\" }, \"text\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. Text part (can be code).\" , \"title\" : \"Text\" } }, \"title\" : \"Part\" , \"type\" : \"object\" }, \"VideoMetadata\" : { \"additionalProperties\" : false , \"description\" : \"Describes how the video in the Part should be used by the model.\" , \"properties\" : { \"fps\" : { \"anyOf\" : [ { \"type\" : \"number\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"The frame rate of the video sent to the model. If not specified, the\\n        default value will be 1.0. The fps range is (0.0, 24.0].\" , \"title\" : \"Fps\" }, \"endOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The end offset of the video.\" , \"title\" : \"Endoffset\" }, \"startOffset\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"description\" : \"Optional. The start offset of the video.\" , \"title\" : \"Startoffset\" } }, \"title\" : \"VideoMetadata\" , \"type\" : \"object\" } } } Fields : memories (list[google.adk.memory.memory_entry.MemoryEntry]) field memories : list[MemoryEntry] [Optional] \u00b6 class google.adk.tools.load_memory_tool. LoadMemoryTool \u00b6 Bases: FunctionTool A tool that loads the memory for the current user. NOTE: Currently this tool only uses text part from the memory. Initializes the FunctionTool. Extracts metadata from a callable object. Parameters : func \u2013 The function to wrap. require_confirmation \u2013 Wether this tool requires confirmation. A boolean or\na callable that takes the function\u2019s arguments and returns a boolean. If\nthe callable returns True, the tool will require confirmation from the\nuser. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. async google.adk.tools.load_memory_tool. load_memory ( query , tool_context ) \u00b6 Loads the memory for the current user. Return type : LoadMemoryResponse Parameters : query \u2013 The query to load the memory for. Returns : A list of memory results. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.load_web_page module\u00b6"], "text": "google.adk.tools.load_web_page module \u00b6 Tool for web browse. google.adk.tools.load_web_page. load_web_page ( url ) \u00b6 Fetches the content in the url and returns the text in it. Return type : str Parameters : url ( str ) \u2013 The url to browse. Returns : The text content of the url. Return type : str ", "code_blocks": []}, {"heading_path": ["google.adk.tools.long_running_tool module\u00b6"], "text": "google.adk.tools.long_running_tool module \u00b6 class google.adk.tools.long_running_tool. LongRunningFunctionTool ( func ) \u00b6 Bases: FunctionTool A function tool that returns the result asynchronously. This tool is used for long-running operations that may take a significant\namount of time to complete. The framework will call the function. Once the\nfunction returns, the response will be returned asynchronously to the\nframework which is identified by the function_call_id. Example: `python tool = LongRunningFunctionTool(a_long_running_function) ` is_long_running \u00b6 Whether the tool is a long running operation. Initializes the FunctionTool. Extracts metadata from a callable object. Parameters : func \u2013 The function to wrap. require_confirmation \u2013 Wether this tool requires confirmation. A boolean or\na callable that takes the function\u2019s arguments and returns a boolean. If\nthe callable returns True, the tool will require confirmation from the\nuser. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.mcp_tool module\u00b6"], "text": "google.adk.tools.mcp_tool module \u00b6 class google.adk.tools.mcp_tool. MCPTool ( * args , ** kwargs ) \u00b6 Bases: McpTool Deprecated name, use McpTool instead. Initializes an MCPTool. This tool wraps an MCP Tool interface and uses a session manager to\ncommunicate with the MCP server. Parameters : mcp_tool \u2013 The MCP tool to wrap. mcp_session_manager \u2013 The MCP session manager to use for communication. auth_scheme \u2013 The authentication scheme to use. auth_credential \u2013 The authentication credential to use. require_confirmation \u2013 Whether this tool requires confirmation. A boolean\nor a callable that takes the function\u2019s arguments and returns a\nboolean. If the callable returns True, the tool will require\nconfirmation from the user. Raises : ValueError \u2013 If mcp_tool or mcp_session_manager is None. class google.adk.tools.mcp_tool. MCPToolset ( * args , ** kwargs ) \u00b6 Bases: McpToolset Deprecated name, use McpToolset instead. Initializes the MCPToolset. Parameters : connection_params \u2013 The connection parameters to the MCP server. Can be: StdioConnectionParams for using local mcp server (e.g. using npx or python3 ); or SseConnectionParams for a local/remote SSE server; or StreamableHTTPConnectionParams for local/remote Streamable http\nserver. Note, StdioServerParameters is also supported for using local\nmcp server (e.g. using npx or python3 ), but it does not support\ntimeout, and we recommend to use StdioConnectionParams instead when\ntimeout is needed. tool_filter \u2013 Optional filter to select specific tools. Can be either: - A\nlist of tool names to include - A ToolPredicate function for custom\nfiltering logic tool_name_prefix \u2013 A prefix to be added to the name of each tool in this\ntoolset. errlog \u2013 TextIO stream for error logging. auth_scheme \u2013 The auth scheme of the tool for tool calling auth_credential \u2013 The auth credential of the tool for tool calling require_confirmation \u2013 Whether tools in this toolset require\nconfirmation. Can be a single boolean or a callable to apply to all\ntools. header_provider \u2013 A callable that takes a ReadonlyContext and returns a\ndictionary of headers to be used for the MCP session. class google.adk.tools.mcp_tool. McpTool ( * , mcp_tool , mcp_session_manager , auth_scheme = None , auth_credential = None , require_confirmation = False , header_provider = None ) \u00b6 Bases: BaseAuthenticatedTool Turns an MCP Tool into an ADK Tool. Internally, the tool initializes from a MCP Tool, and uses the MCP Session to\ncall the tool. Note: For API key authentication, only header-based API keys are supported.\nQuery and cookie-based API keys will result in authentication errors. Initializes an MCPTool. This tool wraps an MCP Tool interface and uses a session manager to\ncommunicate with the MCP server. Parameters : mcp_tool \u2013 The MCP tool to wrap. mcp_session_manager \u2013 The MCP session manager to use for communication. auth_scheme \u2013 The authentication scheme to use. auth_credential \u2013 The authentication credential to use. require_confirmation \u2013 Whether this tool requires confirmation. A boolean\nor a callable that takes the function\u2019s arguments and returns a\nboolean. If the callable returns True, the tool will require\nconfirmation from the user. Raises : ValueError \u2013 If mcp_tool or mcp_session_manager is None. property raw_mcp_tool : Tool \u00b6 Returns the raw MCP tool. async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Any Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. class google.adk.tools.mcp_tool. McpToolset ( * , connection_params , tool_filter=None , tool_name_prefix=None , errlog=<_io.TextIOWrapper name='<stderr>' mode='w' encoding='utf-8'> , auth_scheme=None , auth_credential=None , require_confirmation=False , header_provider=None ) \u00b6 Bases: BaseToolset Connects to a MCP Server, and retrieves MCP Tools into ADK Tools. This toolset manages the connection to an MCP server and provides tools\nthat can be used by an agent. It properly implements the BaseToolset\ninterface for easy integration with the agent framework. Usage: toolset = MCPToolset ( connection_params = StdioServerParameters ( command = 'npx' , args = [ \"-y\" , \"@modelcontextprotocol/server-filesystem\" ], ), tool_filter = [ 'read_file' , 'list_directory' ] # Optional: filter specific tools ) # Use in an agent agent = LlmAgent ( model = 'gemini-2.0-flash' , name = 'enterprise_assistant' , instruction = 'Help user accessing their file systems' , tools = [ toolset ], ) # Cleanup is handled automatically by the agent framework # But you can also manually close if needed: # await toolset.close() Initializes the MCPToolset. Parameters : connection_params \u2013 The connection parameters to the MCP server. Can be: StdioConnectionParams for using local mcp server (e.g. using npx or python3 ); or SseConnectionParams for a local/remote SSE server; or StreamableHTTPConnectionParams for local/remote Streamable http\nserver. Note, StdioServerParameters is also supported for using local\nmcp server (e.g. using npx or python3 ), but it does not support\ntimeout, and we recommend to use StdioConnectionParams instead when\ntimeout is needed. tool_filter \u2013 Optional filter to select specific tools. Can be either: - A\nlist of tool names to include - A ToolPredicate function for custom\nfiltering logic tool_name_prefix \u2013 A prefix to be added to the name of each tool in this\ntoolset. errlog \u2013 TextIO stream for error logging. auth_scheme \u2013 The auth scheme of the tool for tool calling auth_credential \u2013 The auth credential of the tool for tool calling require_confirmation \u2013 Whether tools in this toolset require\nconfirmation. Can be a single boolean or a callable to apply to all\ntools. header_provider \u2013 A callable that takes a ReadonlyContext and returns a\ndictionary of headers to be used for the MCP session. async close ( ) \u00b6 Performs cleanup and releases resources held by the toolset. This method closes the MCP session and cleans up all associated resources.\nIt\u2019s designed to be safe to call multiple times and handles cleanup errors\ngracefully to avoid blocking application shutdown. Return type : None classmethod from_config ( config , config_abs_path ) \u00b6 Creates an MCPToolset from a configuration object. Return type : MCPToolset async get_tools ( readonly_context = None ) \u00b6 Return all tools in the toolset based on the provided context. Return type : List [ BaseTool ] Parameters : readonly_context \u2013 Context used to filter tools available to the agent.\nIf None, all tools in the toolset are returned. Returns : A list of tools available under the specified context. Return type : List[ BaseTool ] pydantic model google.adk.tools.mcp_tool. SseConnectionParams \u00b6 Bases: BaseModel Parameters for the MCP SSE connection. See MCP SSE Client documentation for more details. https://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/client/sse.py url \u00b6 URL for the MCP SSE server. headers \u00b6 Headers for the MCP SSE connection. timeout \u00b6 Timeout in seconds for establishing the connection to the MCP SSE\nserver. sse_read_timeout \u00b6 Timeout in seconds for reading data from the MCP SSE\nserver. Show JSON schema { \"title\" : \"SseConnectionParams\" , \"description\" : \"Parameters for the MCP SSE connection.\\n\\nSee MCP SSE Client documentation for more details.\\nhttps://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/client/sse.py\\n\\nAttributes:\\n    url: URL for the MCP SSE server.\\n    headers: Headers for the MCP SSE connection.\\n    timeout: Timeout in seconds for establishing the connection to the MCP SSE\\n      server.\\n    sse_read_timeout: Timeout in seconds for reading data from the MCP SSE\\n      server.\" , \"type\" : \"object\" , \"properties\" : { \"url\" : { \"title\" : \"Url\" , \"type\" : \"string\" }, \"headers\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Headers\" }, \"timeout\" : { \"default\" : 5.0 , \"title\" : \"Timeout\" , \"type\" : \"number\" }, \"sse_read_timeout\" : { \"default\" : 300.0 , \"title\" : \"Sse Read Timeout\" , \"type\" : \"number\" } }, \"required\" : [ \"url\" ] } Fields : headers (dict[str, Any] | None) sse_read_timeout (float) timeout (float) url (str) field headers : dict[str, Any] | None = None \u00b6 field sse_read_timeout : float = 300.0 \u00b6 field timeout : float = 5.0 \u00b6 field url : str [Required] \u00b6 pydantic model google.adk.tools.mcp_tool. StdioConnectionParams \u00b6 Bases: BaseModel Parameters for the MCP Stdio connection. server_params \u00b6 Parameters for the MCP Stdio server. timeout \u00b6 Timeout in seconds for establishing the connection to the MCP\nstdio server. Show JSON schema { \"title\" : \"StdioConnectionParams\" , \"description\" : \"Parameters for the MCP Stdio connection.\\n\\nAttributes:\\n    server_params: Parameters for the MCP Stdio server.\\n    timeout: Timeout in seconds for establishing the connection to the MCP\\n      stdio server.\" , \"type\" : \"object\" , \"properties\" : { \"server_params\" : { \"$ref\" : \"#/$defs/StdioServerParameters\" }, \"timeout\" : { \"default\" : 5.0 , \"title\" : \"Timeout\" , \"type\" : \"number\" } }, \"$defs\" : { \"StdioServerParameters\" : { \"properties\" : { \"command\" : { \"title\" : \"Command\" , \"type\" : \"string\" }, \"args\" : { \"items\" : { \"type\" : \"string\" }, \"title\" : \"Args\" , \"type\" : \"array\" }, \"env\" : { \"anyOf\" : [ { \"additionalProperties\" : { \"type\" : \"string\" }, \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Env\" }, \"cwd\" : { \"anyOf\" : [ { \"type\" : \"string\" }, { \"format\" : \"path\" , \"type\" : \"string\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Cwd\" }, \"encoding\" : { \"default\" : \"utf-8\" , \"title\" : \"Encoding\" , \"type\" : \"string\" }, \"encoding_error_handler\" : { \"default\" : \"strict\" , \"enum\" : [ \"strict\" , \"ignore\" , \"replace\" ], \"title\" : \"Encoding Error Handler\" , \"type\" : \"string\" } }, \"required\" : [ \"command\" ], \"title\" : \"StdioServerParameters\" , \"type\" : \"object\" } }, \"required\" : [ \"server_params\" ] } Fields : server_params (mcp.client.stdio.StdioServerParameters) timeout (float) field server_params : StdioServerParameters [Required] \u00b6 field timeout : float = 5.0 \u00b6 pydantic model google.adk.tools.mcp_tool. StreamableHTTPConnectionParams \u00b6 Bases: BaseModel Parameters for the MCP Streamable HTTP connection. See MCP Streamable HTTP Client documentation for more details. https://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/client/streamable_http.py url \u00b6 URL for the MCP Streamable HTTP server. headers \u00b6 Headers for the MCP Streamable HTTP connection. timeout \u00b6 Timeout in seconds for establishing the connection to the MCP\nStreamable HTTP server. sse_read_timeout \u00b6 Timeout in seconds for reading data from the MCP\nStreamable HTTP server. terminate_on_close \u00b6 Whether to terminate the MCP Streamable HTTP server\nwhen the connection is closed. Show JSON schema { \"title\" : \"StreamableHTTPConnectionParams\" , \"description\" : \"Parameters for the MCP Streamable HTTP connection.\\n\\nSee MCP Streamable HTTP Client documentation for more details.\\nhttps://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/client/streamable_http.py\\n\\nAttributes:\\n    url: URL for the MCP Streamable HTTP server.\\n    headers: Headers for the MCP Streamable HTTP connection.\\n    timeout: Timeout in seconds for establishing the connection to the MCP\\n      Streamable HTTP server.\\n    sse_read_timeout: Timeout in seconds for reading data from the MCP\\n      Streamable HTTP server.\\n    terminate_on_close: Whether to terminate the MCP Streamable HTTP server\\n      when the connection is closed.\" , \"type\" : \"object\" , \"properties\" : { \"url\" : { \"title\" : \"Url\" , \"type\" : \"string\" }, \"headers\" : { \"anyOf\" : [ { \"additionalProperties\" : true , \"type\" : \"object\" }, { \"type\" : \"null\" } ], \"default\" : null , \"title\" : \"Headers\" }, \"timeout\" : { \"default\" : 5.0 , \"title\" : \"Timeout\" , \"type\" : \"number\" }, \"sse_read_timeout\" : { \"default\" : 300.0 , \"title\" : \"Sse Read Timeout\" , \"type\" : \"number\" }, \"terminate_on_close\" : { \"default\" : true , \"title\" : \"Terminate On Close\" , \"type\" : \"boolean\" } }, \"required\" : [ \"url\" ] } Fields : headers (dict[str, Any] | None) sse_read_timeout (float) terminate_on_close (bool) timeout (float) url (str) field headers : dict[str, Any] | None = None \u00b6 field sse_read_timeout : float = 300.0 \u00b6 field terminate_on_close : bool = True \u00b6 field timeout : float = 5.0 \u00b6 field url : str [Required] \u00b6 google.adk.tools.mcp_tool. adk_to_mcp_tool_type ( tool ) \u00b6 Convert a Tool in ADK into MCP tool type. This function transforms an ADK tool definition into its equivalent\nrepresentation in the MCP (Model Context Protocol) system. Return type : Tool Parameters : tool \u2013 The ADK tool to convert. It should be an instance of a class derived\nfrom BaseTool . Returns : An object of MCP Tool type, representing the converted tool. Examples # Assuming \u2018my_tool\u2019 is an instance of a BaseTool derived class\nmcp_tool = adk_to_mcp_tool_type(my_tool)\nprint(mcp_tool) google.adk.tools.mcp_tool. gemini_to_json_schema ( gemini_schema ) \u00b6 Converts a Gemini Schema object into a JSON Schema dictionary. Return type : Dict [ str , Any ] Parameters : gemini_schema \u2013 An instance of the Gemini Schema class. Returns : A dictionary representing the equivalent JSON Schema. Raises : TypeError \u2013 If the input is not an instance of the expected Schema class. ValueError \u2013 If an invalid Gemini Type enum value is encountered. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.openapi_tool module\u00b6"], "text": "google.adk.tools.openapi_tool module \u00b6 class google.adk.tools.openapi_tool. OpenAPIToolset ( * , spec_dict = None , spec_str = None , spec_str_type = 'json' , auth_scheme = None , auth_credential = None , tool_filter = None ) \u00b6 Bases: BaseToolset Class for parsing OpenAPI spec into a list of RestApiTool. Usage: # Initialize OpenAPI toolset from a spec string. openapi_toolset = OpenAPIToolset ( spec_str = openapi_spec_str , spec_str_type = \"json\" ) # Or, initialize OpenAPI toolset from a spec dictionary. openapi_toolset = OpenAPIToolset ( spec_dict = openapi_spec_dict ) # Add all tools to an agent. agent = Agent ( tools = [ * openapi_toolset . get_tools ()] ) # Or, add a single tool to an agent. agent = Agent ( tools = [ openapi_toolset . get_tool ( 'tool_name' )] ) Initializes the OpenAPIToolset. Usage: # Initialize OpenAPI toolset from a spec string. openapi_toolset = OpenAPIToolset ( spec_str = openapi_spec_str , spec_str_type = \"json\" ) # Or, initialize OpenAPI toolset from a spec dictionary. openapi_toolset = OpenAPIToolset ( spec_dict = openapi_spec_dict ) # Add all tools to an agent. agent = Agent ( tools = [ * openapi_toolset . get_tools ()] ) # Or, add a single tool to an agent. agent = Agent ( tools = [ openapi_toolset . get_tool ( 'tool_name' )] ) Parameters : spec_dict \u2013 The OpenAPI spec dictionary. If provided, it will be used\ninstead of loading the spec from a string. spec_str \u2013 The OpenAPI spec string in JSON or YAML format. It will be used\nwhen spec_dict is not provided. spec_str_type \u2013 The type of the OpenAPI spec string. Can be \u201cjson\u201d or\n\u201cyaml\u201d. auth_scheme \u2013 The auth scheme to use for all tools. Use AuthScheme or use\nhelpers in google.adk.tools.openapi_tool.auth.auth_helpers auth_credential \u2013 The auth credential to use for all tools. Use\nAuthCredential or use helpers in google.adk.tools.openapi_tool.auth.auth_helpers tool_filter \u2013 The filter used to filter the tools in the toolset. It can be\neither a tool predicate or a list of tool names of the tools to expose. async close ( ) \u00b6 Performs cleanup and releases resources held by the toolset. Note This method is invoked, for example, at the end of an agent server\u2019s\nlifecycle or when the toolset is no longer needed. Implementations\nshould ensure that any open connections, files, or other managed\nresources are properly released to prevent leaks. get_tool ( tool_name ) \u00b6 Get a tool by name. Return type : Optional [ RestApiTool ] async get_tools ( readonly_context = None ) \u00b6 Get all tools in the toolset. Return type : List [ RestApiTool ] class google.adk.tools.openapi_tool. RestApiTool ( name , description , endpoint , operation , auth_scheme = None , auth_credential = None , should_parse_operation = True ) \u00b6 Bases: BaseTool A generic tool that interacts with a REST API. Generates request params and body Attaches auth credentials to API call. Example: # Each API operation in the spec will be turned into its own tool # Name of the tool is the operationId of that operation, in snake case operations = OperationGenerator () . parse ( openapi_spec_dict ) tool = [ RestApiTool . from_parsed_operation ( o ) for o in operations ] Initializes the RestApiTool with the given parameters. To generate RestApiTool from OpenAPI Specs, use OperationGenerator.\nExample: # Each API operation in the spec will be turned into its own tool # Name of the tool is the operationId of that operation, in snake case operations = OperationGenerator () . parse ( openapi_spec_dict ) tool = [ RestApiTool . from_parsed_operation ( o ) for o in operations ] Hint: Use google.adk.tools.openapi_tool.auth.auth_helpers to construct\nauth_scheme and auth_credential. Parameters : name \u2013 The name of the tool. description \u2013 The description of the tool. endpoint \u2013 Include the base_url, path, and method of the tool. operation \u2013 Pydantic object or a dict. Representing the OpenAPI Operation\nobject\n( https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md#operation-object ) auth_scheme \u2013 The auth scheme of the tool. Representing the OpenAPI\nSecurityScheme object\n( https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md#security-scheme-object ) auth_credential \u2013 The authentication credential of the tool. should_parse_operation \u2013 Whether to parse the operation. async call ( * , args , tool_context ) \u00b6 Executes the REST API call. Return type : Dict [ str , Any ] Parameters : args \u2013 Keyword arguments representing the operation parameters. tool_context \u2013 The tool context (not used here, but required by the\ninterface). Returns : The API response as a dictionary. configure_auth_credential ( auth_credential = None ) \u00b6 Configures the authentication credential for the API call. Parameters : auth_credential \u2013 AuthCredential|dict - The authentication credential.\nThe dict is converted to an AuthCredential object. configure_auth_scheme ( auth_scheme ) \u00b6 Configures the authentication scheme for the API call. Parameters : auth_scheme \u2013 AuthScheme|dict -: The authentication scheme. The dict is\nconverted to a AuthScheme object. description : str \u00b6 The description of the tool. classmethod from_parsed_operation ( parsed ) \u00b6 Initializes the RestApiTool from a ParsedOperation object. Return type : RestApiTool Parameters : parsed \u2013 A ParsedOperation object. Returns : A RestApiTool object. classmethod from_parsed_operation_str ( parsed_operation_str ) \u00b6 Initializes the RestApiTool from a dict. Return type : RestApiTool Parameters : parsed \u2013 A dict representation of a ParsedOperation object. Returns : A RestApiTool object. name : str \u00b6 The name of the tool. async run_async ( * , args , tool_context ) \u00b6 Runs the tool with the given arguments and context. Return type : Dict [ str , Any ] Note Required if this tool needs to run at the client side. Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\nGemini. Parameters : args \u2013 The LLM-filled arguments. tool_context \u2013 The context of the tool. Returns : The result of running the tool. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.preload_memory_tool module\u00b6"], "text": "google.adk.tools.preload_memory_tool module \u00b6 class google.adk.tools.preload_memory_tool. PreloadMemoryTool \u00b6 Bases: BaseTool A tool that preloads the memory for the current user. This tool will be automatically executed for each llm_request, and it won\u2019t be\ncalled by the model. NOTE: Currently this tool only uses text part from the memory. description : str \u00b6 The description of the tool. name : str \u00b6 The name of the tool. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.retrieval module\u00b6"], "text": "google.adk.tools.retrieval module \u00b6 class google.adk.tools.retrieval. BaseRetrievalTool ( * , name , description , is_long_running = False , custom_metadata = None ) \u00b6 Bases: BaseTool description : str \u00b6 The description of the tool. name : str \u00b6 The name of the tool. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.tool_context module\u00b6"], "text": "google.adk.tools.tool_context module \u00b6 class google.adk.tools.tool_context. ToolContext ( invocation_context , * , function_call_id = None , event_actions = None , tool_confirmation = None ) \u00b6 Bases: CallbackContext The context of the tool. This class provides the context for a tool invocation, including access to\nthe invocation context, function call ID, event actions, and authentication\nresponse. It also provides methods for requesting credentials, retrieving\nauthentication responses, listing artifacts, and searching memory. invocation_context \u00b6 The invocation context of the tool. function_call_id \u00b6 The function call id of the current tool call. This id was\nreturned in the function call event from LLM to identify a function call.\nIf LLM didn\u2019t return this id, ADK will assign one to it. This id is used\nto map function call response to the original function call. event_actions \u00b6 The event actions of the current tool call. tool_confirmation \u00b6 The tool confirmation of the current tool call. property actions : EventActions \u00b6 get_auth_response ( auth_config ) \u00b6 Return type : AuthCredential request_confirmation ( * , hint = None , payload = None ) \u00b6 Requests confirmation for the given function call. Return type : None Parameters : hint \u2013 A hint to the user on how to confirm the tool call. payload \u2013 The payload used to confirm the tool call. request_credential ( auth_config ) \u00b6 Return type : None async search_memory ( query ) \u00b6 Searches the memory of the current user. Return type : SearchMemoryResponse ", "code_blocks": []}, {"heading_path": ["google.adk.tools.toolbox_toolset module\u00b6"], "text": "google.adk.tools.toolbox_toolset module \u00b6 class google.adk.tools.toolbox_toolset. ToolboxToolset ( server_url , toolset_name = None , tool_names = None , auth_token_getters = None , bound_params = None ) \u00b6 Bases: BaseToolset A class that provides access to toolbox toolsets. Example: `python toolbox_toolset = ToolboxToolset(\"http://127.0.0.1:5000\", toolset_name=\"my-toolset\") ) ` Parameters : server_url \u2013 The URL of the toolbox server. toolset_name \u2013 The name of the toolbox toolset to load. tool_names \u2013 The names of the tools to load. auth_token_getters \u2013 A mapping of authentication service names to\ncallables that return the corresponding authentication token. see: https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core#authenticating-tools for details. bound_params \u2013 A mapping of parameter names to bind to specific values or\ncallables that are called to produce values as needed. see: https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core#binding-parameter-values for details. The resulting ToolboxToolset will contain both tools loaded by tool_names\nand toolset_name. async close ( ) \u00b6 Performs cleanup and releases resources held by the toolset. Note This method is invoked, for example, at the end of an agent server\u2019s\nlifecycle or when the toolset is no longer needed. Implementations\nshould ensure that any open connections, files, or other managed\nresources are properly released to prevent leaks. async get_tools ( readonly_context = None ) \u00b6 Return all tools in the toolset based on the provided context. Return type : list [ BaseTool ] Parameters : readonly_context ( ReadonlyContext , optional ) \u2013 Context used to filter tools\navailable to the agent. If None, all tools in the toolset are returned. Returns : A list of tools available under the specified context. Return type : list[ BaseTool ] ", "code_blocks": []}, {"heading_path": ["google.adk.tools.transfer_to_agent_tool module\u00b6"], "text": "google.adk.tools.transfer_to_agent_tool module \u00b6 google.adk.tools.transfer_to_agent_tool. transfer_to_agent ( agent_name , tool_context ) \u00b6 Transfer the question to another agent. This tool hands off control to another agent when it\u2019s more suitable to\nanswer the user\u2019s question according to the agent\u2019s description. Return type : None Parameters : agent_name \u2013 the agent name to transfer to. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.url_context_tool module\u00b6"], "text": "google.adk.tools.url_context_tool module \u00b6 class google.adk.tools.url_context_tool. UrlContextTool \u00b6 Bases: BaseTool A built-in tool that is automatically invoked by Gemini 2 models to retrieve content from the URLs and use that content to inform and shape its response. This tool operates internally within the model and does not require or perform\nlocal code execution. description : str \u00b6 The description of the tool. name : str \u00b6 The name of the tool. async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. ", "code_blocks": []}, {"heading_path": ["google.adk.tools.vertex_ai_search_tool module\u00b6"], "text": "google.adk.tools.vertex_ai_search_tool module \u00b6 class google.adk.tools.vertex_ai_search_tool. VertexAiSearchTool ( * , data_store_id = None , data_store_specs = None , search_engine_id = None , filter = None , max_results = None , bypass_multi_tools_limit = False ) \u00b6 Bases: BaseTool A built-in tool using Vertex AI Search. data_store_id \u00b6 The Vertex AI search data store resource ID. search_engine_id \u00b6 The Vertex AI search engine resource ID. Initializes the Vertex AI Search tool. Parameters : data_store_id \u2013 The Vertex AI search data store resource ID in the format\nof\n\u201cprojects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}\u201d. data_store_specs \u2013 Specifications that define the specific DataStores to be\nsearched. It should only be set if engine is used. search_engine_id \u2013 The Vertex AI search engine resource ID in the format of\n\u201cprojects/{project}/locations/{location}/collections/{collection}/engines/{engine}\u201d. filter \u2013 The filter to apply to the search results. max_results \u2013 The maximum number of results to return. bypass_multi_tools_limit \u2013 Whether to bypass the multi tools limitation,\nso that the tool can be used with other tools in the same agent. Raises : ValueError \u2013 If both data_store_id and search_engine_id are not specified or both are specified. \u2013 async process_llm_request ( * , tool_context , llm_request ) \u00b6 Processes the outgoing LLM request for this tool. Use cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it\u2019s sent out. Return type : None Parameters : tool_context \u2013 The context of the tool. llm_request \u2013 The outgoing LLM request, mutable this method. ", "code_blocks": []}, {"heading_path": ["google.adk.utils module\u00b6"], "text": "google.adk.utils module \u00b6 ", "code_blocks": []}, {"heading_path": ["google.adk.version module\u00b6"], "text": "google.adk.version module \u00b6 ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:39:30.249253", "source_type": "adk-docs"}
{"doc_id": "5f3d7932bb0ab6fdc9206511e5a37b576b9ec3f7df98ecf143d12414cbbb7626", "url": "https://google.github.io/adk-docs/tools/authentication", "title": "Redirecting...", "sections": [{"heading_path": [], "text": "You're being redirected to a new destination . ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:39:30.328863", "source_type": "adk-docs"}
{"doc_id": "bd589016989c0fa1e50fd4db99b59275a4f2e81ed6e8e9119c2a731c56d4472b", "url": "https://google.github.io/adk-docs/api-reference/cli/cli.html", "title": "CLI Reference \u2014 adk cli  documentation", "sections": [{"heading_path": ["CLI Reference\u00b6"], "text": "CLI Reference \u00b6 This page contains the auto-generated command-line reference for the adk tool. ", "code_blocks": []}, {"heading_path": ["adk\u00b6"], "text": "adk \u00b6 Agent Development Kit CLI tools. adk [ OPTIONS ] COMMAND [ ARGS ] ... Options --version \u00b6 Show the version and exit. ", "code_blocks": []}, {"heading_path": ["api_server\u00b6"], "text": "api_server \u00b6 Starts a FastAPI server for agents. AGENTS_DIR: The directory of agents, where each sub-directory is a single\nagent, containing at least __init__.py and agent.py files. Example: adk api_server \u2013port=[port] path/to/agents_dir adk api_server [ OPTIONS ] [ AGENTS_DIR ] Options --host <host> \u00b6 Optional. The binding host of the server Default : '127.0.0.1' --port <port> \u00b6 Optional. The port of the server --allow_origins <allow_origins> \u00b6 Optional. Any additional origins to allow for CORS. --log_level <log_level> \u00b6 Optional. Set the logging level Options : DEBUG | INFO | WARNING | ERROR | CRITICAL --trace_to_cloud \u00b6 Optional. Whether to enable cloud trace for telemetry. Default : False --reload , --no-reload \u00b6 Optional. Whether to enable auto reload for server. Not supported for Cloud Run. --a2a \u00b6 Optional. Whether to enable A2A endpoint. Default : False --reload_agents \u00b6 Optional. Whether to enable live reload for agents changes. Default : False --session_service_uri <session_service_uri> \u00b6 Optional. The URI of the session service.\n- Use \u2018agentengine://<agent_engine_resource_id>\u2019 to connect to Agent Engine sessions.\n- Use \u2018sqlite://<path_to_sqlite_file>\u2019 to connect to a SQLite DB.\n- See https://docs.sqlalchemy.org/en/20/core/engines.html#backend-specific-urls for more details on supported database URIs. --artifact_service_uri <artifact_service_uri> \u00b6 Optional. The URI of the artifact service, supported URIs: gs://<bucket name> for GCS artifact service. --eval_storage_uri <eval_storage_uri> \u00b6 Optional. The evals storage URI to store agent evals, supported URIs: gs://<bucket name>. --memory_service_uri <memory_service_uri> \u00b6 Optional. The URI of the memory service.\n- Use \u2018rag://<rag_corpus_id>\u2019 to connect to Vertex AI Rag Memory Service.\n- Use \u2018agentengine://<agent_engine_resource_id>\u2019 to connect to Vertex AI Memory Bank Service. e.g. agentengine://12345 --session_db_url <session_db_url> \u00b6 Deprecated. Use \u2013session_service_uri instead. --artifact_storage_uri <artifact_storage_uri> \u00b6 Deprecated. Use \u2013artifact_service_uri instead. Arguments AGENTS_DIR \u00b6 Optional argument ", "code_blocks": []}, {"heading_path": ["create\u00b6"], "text": "create \u00b6 Creates a new app in the current folder with prepopulated agent template. APP_NAME: required, the folder of the agent source code. Example: adk create path/to/my_app adk create [ OPTIONS ] APP_NAME Options --model <model> \u00b6 Optional. The model used for the root agent. --api_key <api_key> \u00b6 Optional. The API Key needed to access the model, e.g. Google AI API Key. --project <project> \u00b6 Optional. The Google Cloud Project for using VertexAI as backend. --region <region> \u00b6 Optional. The Google Cloud Region for using VertexAI as backend. Arguments APP_NAME \u00b6 Required argument ", "code_blocks": []}, {"heading_path": ["deploy\u00b6"], "text": "deploy \u00b6 Deploys agent to hosted environments. adk deploy [ OPTIONS ] COMMAND [ ARGS ] ... ", "code_blocks": []}, {"heading_path": ["agent_engine\u00b6"], "text": "agent_engine \u00b6 Deploys an agent to Agent Engine. AGENT: The path to the agent source code folder. Example: adk deploy agent_engine \u2013project=[project] \u2013region=[region] \u2013staging_bucket=[staging_bucket] \u2013display_name=[app_name] path/to/my_agent adk deploy agent_engine [ OPTIONS ] AGENT Options --project <project> \u00b6 Required. Google Cloud project to deploy the agent. It will override GOOGLE_CLOUD_PROJECT in the .env file (if it exists). --region <region> \u00b6 Required. Google Cloud region to deploy the agent. It will override GOOGLE_CLOUD_LOCATION in the .env file (if it exists). --staging_bucket <staging_bucket> \u00b6 Required. GCS bucket for staging the deployment artifacts. --trace_to_cloud \u00b6 Optional. Whether to enable Cloud Trace for Agent Engine. Default : False --display_name <display_name> \u00b6 Optional. Display name of the agent in Agent Engine. Default : '' --description <description> \u00b6 Optional. Description of the agent in Agent Engine. Default : '' --adk_app <adk_app> \u00b6 Optional. Python file for defining the ADK application (default: a file named agent_engine_app.py) --temp_folder <temp_folder> \u00b6 Optional. Temp folder for the generated Agent Engine source files. If the folder already exists, its contents will be removed. (default: a timestamped folder in the system temp directory). --env_file <env_file> \u00b6 Optional. The filepath to the .env file for environment variables. (default: the .env file in the agent directory, if any.) --requirements_file <requirements_file> \u00b6 Optional. The filepath to the requirements.txt file to use. (default: the requirements.txt file in the agent directory, if any.) Arguments AGENT \u00b6 Required argument ", "code_blocks": []}, {"heading_path": ["cloud_run\u00b6"], "text": "cloud_run \u00b6 Deploys an agent to Cloud Run. AGENT: The path to the agent source code folder. Example: adk deploy cloud_run \u2013project=[project] \u2013region=[region] path/to/my_agent adk deploy cloud_run [ OPTIONS ] AGENT Options --project <project> \u00b6 Required. Google Cloud project to deploy the agent. When absent, default project from gcloud config is used. --region <region> \u00b6 Required. Google Cloud region to deploy the agent. When absent, gcloud run deploy will prompt later. --service_name <service_name> \u00b6 Optional. The service name to use in Cloud Run (default: \u2018adk-default-service-name\u2019). --app_name <app_name> \u00b6 Optional. App name of the ADK API server (default: the folder name of the AGENT source code). --port <port> \u00b6 Optional. The port of the server --allow_origins <allow_origins> \u00b6 Optional. Any additional origins to allow for CORS. --log_level <log_level> \u00b6 Optional. Set the logging level Options : DEBUG | INFO | WARNING | ERROR | CRITICAL --trace_to_cloud \u00b6 Optional. Whether to enable cloud trace for telemetry. Default : False --reload , --no-reload \u00b6 Optional. Whether to enable auto reload for server. Not supported for Cloud Run. --a2a \u00b6 Optional. Whether to enable A2A endpoint. Default : False --reload_agents \u00b6 Optional. Whether to enable live reload for agents changes. Default : False --with_ui \u00b6 Optional. Deploy ADK Web UI if set. (default: deploy ADK API server only) Default : False --verbosity <verbosity> \u00b6 Deprecated. Use \u2013log_level instead. Options : DEBUG | INFO | WARNING | ERROR | CRITICAL --temp_folder <temp_folder> \u00b6 Optional. Temp folder for the generated Cloud Run source files (default: a timestamped folder in the system temp directory). --adk_version <adk_version> \u00b6 Optional. The ADK version used in Cloud Run deployment. (default: the version in the dev environment) Default : '1.7.0' --session_service_uri <session_service_uri> \u00b6 Optional. The URI of the session service.\n- Use \u2018agentengine://<agent_engine_resource_id>\u2019 to connect to Agent Engine sessions.\n- Use \u2018sqlite://<path_to_sqlite_file>\u2019 to connect to a SQLite DB.\n- See https://docs.sqlalchemy.org/en/20/core/engines.html#backend-specific-urls for more details on supported database URIs. --artifact_service_uri <artifact_service_uri> \u00b6 Optional. The URI of the artifact service, supported URIs: gs://<bucket name> for GCS artifact service. --eval_storage_uri <eval_storage_uri> \u00b6 Optional. The evals storage URI to store agent evals, supported URIs: gs://<bucket name>. --memory_service_uri <memory_service_uri> \u00b6 Optional. The URI of the memory service.\n- Use \u2018rag://<rag_corpus_id>\u2019 to connect to Vertex AI Rag Memory Service.\n- Use \u2018agentengine://<agent_engine_resource_id>\u2019 to connect to Vertex AI Memory Bank Service. e.g. agentengine://12345 --session_db_url <session_db_url> \u00b6 Deprecated. Use \u2013session_service_uri instead. --artifact_storage_uri <artifact_storage_uri> \u00b6 Deprecated. Use \u2013artifact_service_uri instead. Arguments AGENT \u00b6 Required argument ", "code_blocks": []}, {"heading_path": ["eval\u00b6"], "text": "eval \u00b6 Evaluates an agent given the eval sets. AGENT_MODULE_FILE_PATH: The path to the __init__.py file that contains a\nmodule by the name \u201cagent\u201d. \u201cagent\u201d module contains a root_agent. EVAL_SET_FILE_PATH: You can specify one or more eval set file paths. For each file, all evals will be run by default. If you want to run only specific evals from a eval set, first create a comma\nseparated list of eval names and then add that as a suffix to the eval set\nfile name, demarcated by a : . For example, sample_eval_set_file.json:eval_1,eval_2,eval_3 This will only run eval_1, eval_2 and eval_3 from sample_eval_set_file.json. CONFIG_FILE_PATH: The path to config file. PRINT_DETAILED_RESULTS: Prints detailed results on the console. adk eval [ OPTIONS ] AGENT_MODULE_FILE_PATH [ EVAL_SET_FILE_PATH ] ... Options --config_file_path <config_file_path> \u00b6 Optional. The path to config file. --print_detailed_results \u00b6 Optional. Whether to print detailed results on console or not. Default : False --eval_storage_uri <eval_storage_uri> \u00b6 Optional. The evals storage URI to store agent evals, supported URIs: gs://<bucket name>. Arguments AGENT_MODULE_FILE_PATH \u00b6 Required argument EVAL_SET_FILE_PATH \u00b6 Optional argument(s) ", "code_blocks": []}, {"heading_path": ["run\u00b6"], "text": "run \u00b6 Runs an interactive CLI for a certain agent. AGENT: The path to the agent source code folder. Example: adk run path/to/my_agent adk run [ OPTIONS ] AGENT Options --save_session \u00b6 Optional. Whether to save the session to a json file on exit. Default : False --session_id <session_id> \u00b6 Optional. The session ID to save the session to on exit when \u2013save_session is set to true. User will be prompted to enter a session ID if not set. --replay <replay> \u00b6 The json file that contains the initial state of the session and user queries. A new session will be created using this state. And user queries are run againt the newly created session. Users cannot continue to interact with the agent. --resume <resume> \u00b6 The json file that contains a previously saved session (by\u2013save_session option). The previous session will be re-displayed. And user can continue to interact with the agent. Arguments AGENT \u00b6 Required argument ", "code_blocks": []}, {"heading_path": ["web\u00b6"], "text": "web \u00b6 Starts a FastAPI server with Web UI for agents. AGENTS_DIR: The directory of agents, where each sub-directory is a single\nagent, containing at least __init__.py and agent.py files. Example: adk web \u2013port=[port] path/to/agents_dir adk web [ OPTIONS ] [ AGENTS_DIR ] Options --host <host> \u00b6 Optional. The binding host of the server Default : '127.0.0.1' --port <port> \u00b6 Optional. The port of the server --allow_origins <allow_origins> \u00b6 Optional. Any additional origins to allow for CORS. --log_level <log_level> \u00b6 Optional. Set the logging level Options : DEBUG | INFO | WARNING | ERROR | CRITICAL --trace_to_cloud \u00b6 Optional. Whether to enable cloud trace for telemetry. Default : False --reload , --no-reload \u00b6 Optional. Whether to enable auto reload for server. Not supported for Cloud Run. --a2a \u00b6 Optional. Whether to enable A2A endpoint. Default : False --reload_agents \u00b6 Optional. Whether to enable live reload for agents changes. Default : False --session_service_uri <session_service_uri> \u00b6 Optional. The URI of the session service.\n- Use \u2018agentengine://<agent_engine_resource_id>\u2019 to connect to Agent Engine sessions.\n- Use \u2018sqlite://<path_to_sqlite_file>\u2019 to connect to a SQLite DB.\n- See https://docs.sqlalchemy.org/en/20/core/engines.html#backend-specific-urls for more details on supported database URIs. --artifact_service_uri <artifact_service_uri> \u00b6 Optional. The URI of the artifact service, supported URIs: gs://<bucket name> for GCS artifact service. --eval_storage_uri <eval_storage_uri> \u00b6 Optional. The evals storage URI to store agent evals, supported URIs: gs://<bucket name>. --memory_service_uri <memory_service_uri> \u00b6 Optional. The URI of the memory service.\n- Use \u2018rag://<rag_corpus_id>\u2019 to connect to Vertex AI Rag Memory Service.\n- Use \u2018agentengine://<agent_engine_resource_id>\u2019 to connect to Vertex AI Memory Bank Service. e.g. agentengine://12345 --session_db_url <session_db_url> \u00b6 Deprecated. Use \u2013session_service_uri instead. --artifact_storage_uri <artifact_storage_uri> \u00b6 Deprecated. Use \u2013artifact_service_uri instead. Arguments AGENTS_DIR \u00b6 Optional argument ", "code_blocks": []}, {"heading_path": ["adk cli"], "text": "adk cli ", "code_blocks": []}, {"heading_path": ["Navigation"], "text": "Navigation Contents: CLI Reference adk ", "code_blocks": []}, {"heading_path": ["Related Topics"], "text": "Related Topics Documentation overview Previous: adk cli documentation \u00a92025, Google.\n      \n      |\n      Powered by Sphinx 8.2.3 & Alabaster 1.0.0 | Page source ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:39:33.835752", "source_type": "adk-docs"}
{"doc_id": "36ef94ae1fea819f4af9e97ffc176b2b14fa5e4a68f45a59b9ffc7b8d117ae06", "url": "https://google.github.io/adk-docs/api-reference/python/index.html", "title": "Agent Development Kit documentation", "sections": [{"heading_path": [], "text": "Contents Menu Expand Light mode Dark mode Auto light/dark, in light mode Auto light/dark, in dark mode Hide navigation sidebar Hide table of contents sidebar Skip to content Agent Development Kit  documentation Submodules google.adk.a2a module google.adk.agents module google.adk.artifacts module google.adk.apps package google.adk.auth module google.adk.cli module google.adk.code_executors module google.adk.errors module google.adk.evaluation module google.adk.events module google.adk.examples module google.adk.flows module google.adk.memory module google.adk.models module google.adk.planners module google.adk.platform module google.adk.plugins module google.adk.runners module google.adk.sessions module google.adk.telemetry module google.adk.tools package google.adk.tools.agent_tool module google.adk.tools.apihub_tool module google.adk.tools.application_integration_tool module google.adk.tools.authenticated_function_tool module google.adk.tools.base_authenticated_tool module google.adk.tools.base_tool module google.adk.tools.base_toolset module google.adk.tools.bigquery module google.adk.tools.crewai_tool module google.adk.tools.enterprise_search_tool module google.adk.tools.example_tool module google.adk.tools.exit_loop_tool module google.adk.tools.function_tool module google.adk.tools.get_user_choice_tool module google.adk.tools.google_api_tool module google.adk.tools.google_maps_grounding_tool module google.adk.tools.google_search_tool module google.adk.tools.langchain_tool module google.adk.tools.load_artifacts_tool module google.adk.tools.load_memory_tool module google.adk.tools.load_web_page module google.adk.tools.long_running_tool module google.adk.tools.mcp_tool module google.adk.tools.openapi_tool module google.adk.tools.preload_memory_tool module google.adk.tools.retrieval module google.adk.tools.tool_context module google.adk.tools.toolbox_toolset module google.adk.tools.transfer_to_agent_tool module google.adk.tools.url_context_tool module google.adk.tools.vertex_ai_search_tool module google.adk.utils module google.adk.version module Back to top View this page Toggle Light / Dark / Auto color theme Toggle table of contents sidebar ", "code_blocks": []}, {"heading_path": ["google\u00b6"], "text": "google \u00b6 Submodules google.adk.a2a module google.adk.agents module Agent BaseAgent BaseAgent.after_agent_callback BaseAgent.before_agent_callback BaseAgent.description BaseAgent.name BaseAgent.parent_agent BaseAgent.sub_agents BaseAgent.config_type BaseAgent.from_config() BaseAgent.validate_name BaseAgent.clone() BaseAgent.find_agent() BaseAgent.find_sub_agent() BaseAgent.model_post_init() BaseAgent.run_async() BaseAgent.run_live() BaseAgent.canonical_after_agent_callbacks BaseAgent.canonical_before_agent_callbacks BaseAgent.root_agent InvocationContext InvocationContext.active_streaming_tools InvocationContext.agent InvocationContext.agent_states InvocationContext.artifact_service InvocationContext.branch InvocationContext.context_cache_config InvocationContext.credential_service InvocationContext.end_invocation InvocationContext.end_of_agents InvocationContext.input_realtime_cache InvocationContext.invocation_id InvocationContext.live_request_queue InvocationContext.live_session_resumption_handle InvocationContext.memory_service InvocationContext.output_realtime_cache InvocationContext.plugin_manager InvocationContext.resumability_config InvocationContext.run_config InvocationContext.session InvocationContext.session_service InvocationContext.transcription_cache InvocationContext.user_content InvocationContext.increment_llm_call_count() InvocationContext.model_post_init() InvocationContext.populate_invocation_agent_states() InvocationContext.reset_sub_agent_states() InvocationContext.set_agent_state() InvocationContext.should_pause_invocation() InvocationContext.app_name InvocationContext.is_resumable InvocationContext.user_id LiveRequest LiveRequest.activity_end LiveRequest.activity_start LiveRequest.blob LiveRequest.close LiveRequest.content LiveRequestQueue LiveRequestQueue.close() LiveRequestQueue.get() LiveRequestQueue.send() LiveRequestQueue.send_activity_end() LiveRequestQueue.send_activity_start() LiveRequestQueue.send_content() LiveRequestQueue.send_realtime() LlmAgent LlmAgent.after_model_callback LlmAgent.after_tool_callback LlmAgent.before_model_callback LlmAgent.before_tool_callback LlmAgent.code_executor LlmAgent.disallow_transfer_to_parent LlmAgent.disallow_transfer_to_peers LlmAgent.generate_content_config LlmAgent.global_instruction LlmAgent.include_contents LlmAgent.input_schema LlmAgent.instruction LlmAgent.model LlmAgent.output_key LlmAgent.output_schema LlmAgent.planner LlmAgent.static_instruction LlmAgent.tools LlmAgent.config_type LlmAgent.validate_generate_content_config LlmAgent.canonical_global_instruction() LlmAgent.canonical_instruction() LlmAgent.canonical_tools() LlmAgent.canonical_after_model_callbacks LlmAgent.canonical_after_tool_callbacks LlmAgent.canonical_before_model_callbacks LlmAgent.canonical_before_tool_callbacks LlmAgent.canonical_model LoopAgent LoopAgent.max_iterations LoopAgent.config_type ParallelAgent ParallelAgent.config_type RunConfig RunConfig.context_window_compression RunConfig.enable_affective_dialog RunConfig.input_audio_transcription RunConfig.max_llm_calls RunConfig.output_audio_transcription RunConfig.proactivity RunConfig.realtime_input_config RunConfig.response_modalities RunConfig.save_live_audio RunConfig.session_resumption RunConfig.speech_config RunConfig.streaming_mode RunConfig.support_cfc RunConfig.validate_max_llm_calls RunConfig.save_input_blobs_as_artifacts RunConfig.msg RunConfig.wrapped_property RunConfig.field_name SequentialAgent SequentialAgent.config_type google.adk.artifacts module BaseArtifactService BaseArtifactService.delete_artifact() BaseArtifactService.get_artifact_version() BaseArtifactService.list_artifact_keys() BaseArtifactService.list_artifact_versions() BaseArtifactService.list_versions() BaseArtifactService.load_artifact() BaseArtifactService.save_artifact() GcsArtifactService GcsArtifactService.delete_artifact() GcsArtifactService.get_artifact_version() GcsArtifactService.list_artifact_keys() GcsArtifactService.list_artifact_versions() GcsArtifactService.list_versions() GcsArtifactService.load_artifact() GcsArtifactService.save_artifact() InMemoryArtifactService InMemoryArtifactService.artifacts InMemoryArtifactService.delete_artifact() InMemoryArtifactService.get_artifact_version() InMemoryArtifactService.list_artifact_keys() InMemoryArtifactService.list_artifact_versions() InMemoryArtifactService.list_versions() InMemoryArtifactService.load_artifact() InMemoryArtifactService.save_artifact() google.adk.apps package App App.context_cache_config App.events_compaction_config App.name App.plugins App.resumability_config App.root_agent ResumabilityConfig ResumabilityConfig.is_resumable google.adk.auth module google.adk.cli module google.adk.code_executors module BaseCodeExecutor BaseCodeExecutor.optimize_data_file BaseCodeExecutor.stateful BaseCodeExecutor.error_retry_attempts BaseCodeExecutor.code_block_delimiters BaseCodeExecutor.execution_result_delimiters BaseCodeExecutor.code_block_delimiters BaseCodeExecutor.error_retry_attempts BaseCodeExecutor.execution_result_delimiters BaseCodeExecutor.optimize_data_file BaseCodeExecutor.stateful BaseCodeExecutor.execute_code() BuiltInCodeExecutor BuiltInCodeExecutor.execute_code() BuiltInCodeExecutor.process_llm_request() CodeExecutorContext CodeExecutorContext.add_input_files() CodeExecutorContext.add_processed_file_names() CodeExecutorContext.clear_input_files() CodeExecutorContext.get_error_count() CodeExecutorContext.get_execution_id() CodeExecutorContext.get_input_files() CodeExecutorContext.get_processed_file_names() CodeExecutorContext.get_state_delta() CodeExecutorContext.increment_error_count() CodeExecutorContext.reset_error_count() CodeExecutorContext.set_execution_id() CodeExecutorContext.update_code_execution_result() UnsafeLocalCodeExecutor UnsafeLocalCodeExecutor.optimize_data_file UnsafeLocalCodeExecutor.stateful UnsafeLocalCodeExecutor.execute_code() google.adk.errors module google.adk.evaluation module AgentEvaluator AgentEvaluator.evaluate() AgentEvaluator.evaluate_eval_set() AgentEvaluator.find_config_for_test_file() AgentEvaluator.migrate_eval_data_to_new_schema() google.adk.events module Event Event.actions Event.author Event.branch Event.id Event.invocation_id Event.long_running_tool_ids Event.timestamp Event.new_id() Event.get_function_calls() Event.get_function_responses() Event.has_trailing_code_execution_result() Event.is_final_response() Event.model_post_init() EventActions EventActions.agent_state EventActions.artifact_delta EventActions.compaction EventActions.end_of_agent EventActions.escalate EventActions.requested_auth_configs EventActions.requested_tool_confirmations EventActions.rewind_before_invocation_id EventActions.skip_summarization EventActions.state_delta EventActions.transfer_to_agent google.adk.examples module BaseExampleProvider BaseExampleProvider.get_examples() Example Example.input Example.output Example.input Example.output VertexAiExampleStore VertexAiExampleStore.get_examples() google.adk.flows module google.adk.memory module BaseMemoryService BaseMemoryService.add_session_to_memory() BaseMemoryService.search_memory() InMemoryMemoryService InMemoryMemoryService.add_session_to_memory() InMemoryMemoryService.search_memory() VertexAiMemoryBankService VertexAiMemoryBankService.add_session_to_memory() VertexAiMemoryBankService.search_memory() VertexAiRagMemoryService VertexAiRagMemoryService.add_session_to_memory() VertexAiRagMemoryService.search_memory() google.adk.models module BaseLlm BaseLlm.model BaseLlm.supported_models() BaseLlm.connect() BaseLlm.generate_content_async() Gemini Gemini.model Gemini.model Gemini.retry_options Gemini.supported_models() Gemini.connect() Gemini.generate_content_async() Gemini.api_client Gemma Gemma.model Gemma.supported_models() Gemma.generate_content_async() LLMRegistry LLMRegistry.new_llm() LLMRegistry.register() LLMRegistry.resolve() google.adk.planners module BasePlanner BasePlanner.build_planning_instruction() BasePlanner.process_planning_response() BuiltInPlanner BuiltInPlanner.thinking_config BuiltInPlanner.apply_thinking_config() BuiltInPlanner.build_planning_instruction() BuiltInPlanner.process_planning_response() BuiltInPlanner.thinking_config PlanReActPlanner PlanReActPlanner.build_planning_instruction() PlanReActPlanner.process_planning_response() google.adk.platform module google.adk.plugins module BasePlugin BasePlugin.after_agent_callback() BasePlugin.after_model_callback() BasePlugin.after_run_callback() BasePlugin.after_tool_callback() BasePlugin.before_agent_callback() BasePlugin.before_model_callback() BasePlugin.before_run_callback() BasePlugin.before_tool_callback() BasePlugin.on_event_callback() BasePlugin.on_model_error_callback() BasePlugin.on_tool_error_callback() BasePlugin.on_user_message_callback() LoggingPlugin LoggingPlugin.after_agent_callback() LoggingPlugin.after_model_callback() LoggingPlugin.after_run_callback() LoggingPlugin.after_tool_callback() LoggingPlugin.before_agent_callback() LoggingPlugin.before_model_callback() LoggingPlugin.before_run_callback() LoggingPlugin.before_tool_callback() LoggingPlugin.on_event_callback() LoggingPlugin.on_model_error_callback() LoggingPlugin.on_tool_error_callback() LoggingPlugin.on_user_message_callback() PluginManager PluginManager.get_plugin() PluginManager.register_plugin() PluginManager.run_after_agent_callback() PluginManager.run_after_model_callback() PluginManager.run_after_run_callback() PluginManager.run_after_tool_callback() PluginManager.run_before_agent_callback() PluginManager.run_before_model_callback() PluginManager.run_before_run_callback() PluginManager.run_before_tool_callback() PluginManager.run_on_event_callback() PluginManager.run_on_model_error_callback() PluginManager.run_on_tool_error_callback() PluginManager.run_on_user_message_callback() ReflectAndRetryToolPlugin ReflectAndRetryToolPlugin.after_tool_callback() ReflectAndRetryToolPlugin.extract_error_from_result() ReflectAndRetryToolPlugin.on_tool_error_callback() google.adk.runners module InMemoryRunner InMemoryRunner.agent InMemoryRunner.app_name Runner Runner.app_name Runner.agent Runner.artifact_service Runner.plugin_manager Runner.session_service Runner.memory_service Runner.credential_service Runner.context_cache_config Runner.resumability_config Runner.agent Runner.app_name Runner.artifact_service Runner.close() Runner.context_cache_config Runner.credential_service Runner.memory_service Runner.plugin_manager Runner.resumability_config Runner.rewind_async() Runner.run() Runner.run_async() Runner.run_live() Runner.session_service google.adk.sessions module BaseSessionService BaseSessionService.append_event() BaseSessionService.create_session() BaseSessionService.delete_session() BaseSessionService.get_session() BaseSessionService.list_sessions() DatabaseSessionService DatabaseSessionService.append_event() DatabaseSessionService.create_session() DatabaseSessionService.delete_session() DatabaseSessionService.get_session() DatabaseSessionService.list_sessions() InMemorySessionService InMemorySessionService.append_event() InMemorySessionService.create_session() InMemorySessionService.create_session_sync() InMemorySessionService.delete_session() InMemorySessionService.delete_session_sync() InMemorySessionService.get_session() InMemorySessionService.get_session_sync() InMemorySessionService.list_sessions() InMemorySessionService.list_sessions_sync() Session Session.app_name Session.events Session.id Session.last_update_time Session.state Session.user_id State State.APP_PREFIX State.TEMP_PREFIX State.USER_PREFIX State.get() State.has_delta() State.setdefault() State.to_dict() State.update() VertexAiSessionService VertexAiSessionService.append_event() VertexAiSessionService.create_session() VertexAiSessionService.delete_session() VertexAiSessionService.get_session() VertexAiSessionService.list_sessions() google.adk.telemetry module trace_call_llm() trace_merged_tool_calls() trace_send_data() trace_tool_call() google.adk.tools package APIHubToolset APIHubToolset.close() APIHubToolset.get_tools() AgentTool AgentTool.agent AgentTool.skip_summarization AgentTool.from_config() AgentTool.populate_name() AgentTool.run_async() AuthToolArguments AuthToolArguments.auth_config AuthToolArguments.function_call_id BaseTool BaseTool.custom_metadata BaseTool.description BaseTool.from_config() BaseTool.is_long_running BaseTool.name BaseTool.process_llm_request() BaseTool.run_async() DiscoveryEngineSearchTool DiscoveryEngineSearchTool.discovery_engine_search() ExampleTool ExampleTool.examples ExampleTool.from_config() ExampleTool.process_llm_request() FunctionTool FunctionTool.func FunctionTool.run_async() LongRunningFunctionTool LongRunningFunctionTool.is_long_running MCPToolset ToolContext ToolContext.invocation_context ToolContext.function_call_id ToolContext.event_actions ToolContext.tool_confirmation ToolContext.actions ToolContext.get_auth_response() ToolContext.request_confirmation() ToolContext.request_credential() ToolContext.search_memory() VertexAiSearchTool VertexAiSearchTool.data_store_id VertexAiSearchTool.search_engine_id VertexAiSearchTool.process_llm_request() exit_loop() transfer_to_agent() google.adk.tools.agent_tool module AgentTool AgentTool.agent AgentTool.skip_summarization AgentTool.from_config() AgentTool.populate_name() AgentTool.run_async() AgentToolConfig AgentToolConfig.agent AgentToolConfig.skip_summarization google.adk.tools.apihub_tool module APIHubToolset APIHubToolset.close() APIHubToolset.get_tools() google.adk.tools.application_integration_tool module ApplicationIntegrationToolset ApplicationIntegrationToolset.close() ApplicationIntegrationToolset.get_tools() IntegrationConnectorTool IntegrationConnectorTool.EXCLUDE_FIELDS IntegrationConnectorTool.OPTIONAL_FIELDS IntegrationConnectorTool.run_async() google.adk.tools.authenticated_function_tool module AuthenticatedFunctionTool AuthenticatedFunctionTool.run_async() google.adk.tools.base_authenticated_tool module BaseAuthenticatedTool BaseAuthenticatedTool.run_async() google.adk.tools.base_tool module BaseTool BaseTool.custom_metadata BaseTool.description BaseTool.from_config() BaseTool.is_long_running BaseTool.name BaseTool.process_llm_request() BaseTool.run_async() google.adk.tools.base_toolset module BaseToolset BaseToolset.close() BaseToolset.from_config() BaseToolset.get_tools() BaseToolset.get_tools_with_prefix() BaseToolset.process_llm_request() ToolPredicate google.adk.tools.bigquery module BigQueryCredentialsConfig BigQueryCredentialsConfig.model_post_init() BigQueryToolset BigQueryToolset.close() BigQueryToolset.get_tools() google.adk.tools.crewai_tool module CrewaiTool CrewaiTool.from_config() CrewaiTool.tool CrewaiToolConfig CrewaiToolConfig.description CrewaiToolConfig.name CrewaiToolConfig.tool google.adk.tools.enterprise_search_tool module EnterpriseWebSearchTool EnterpriseWebSearchTool.description EnterpriseWebSearchTool.name EnterpriseWebSearchTool.process_llm_request() google.adk.tools.example_tool module ExampleTool ExampleTool.examples ExampleTool.from_config() ExampleTool.process_llm_request() ExampleToolConfig ExampleToolConfig.examples google.adk.tools.exit_loop_tool module exit_loop() google.adk.tools.function_tool module FunctionTool FunctionTool.func FunctionTool.run_async() google.adk.tools.get_user_choice_tool module get_user_choice() google.adk.tools.google_api_tool module BigQueryToolset CalendarToolset DocsToolset GmailToolset GoogleApiTool GoogleApiTool.configure_auth() GoogleApiTool.configure_sa_auth() GoogleApiTool.description GoogleApiTool.name GoogleApiTool.run_async() GoogleApiToolset GoogleApiToolset.close() GoogleApiToolset.configure_auth() GoogleApiToolset.configure_sa_auth() GoogleApiToolset.get_tools() GoogleApiToolset.set_tool_filter() SheetsToolset SlidesToolset YoutubeToolset google.adk.tools.google_maps_grounding_tool module GoogleMapsGroundingTool GoogleMapsGroundingTool.description GoogleMapsGroundingTool.name GoogleMapsGroundingTool.process_llm_request() google.adk.tools.google_search_tool module GoogleSearchTool GoogleSearchTool.description GoogleSearchTool.name GoogleSearchTool.process_llm_request() google.adk.tools.langchain_tool module LangchainTool LangchainTool.from_config() LangchainToolConfig LangchainToolConfig.description LangchainToolConfig.name LangchainToolConfig.tool google.adk.tools.load_artifacts_tool module LoadArtifactsTool LoadArtifactsTool.description LoadArtifactsTool.name LoadArtifactsTool.process_llm_request() LoadArtifactsTool.run_async() google.adk.tools.load_memory_tool module LoadMemoryResponse LoadMemoryResponse.memories LoadMemoryTool LoadMemoryTool.process_llm_request() load_memory() google.adk.tools.load_web_page module load_web_page() google.adk.tools.long_running_tool module LongRunningFunctionTool LongRunningFunctionTool.is_long_running google.adk.tools.mcp_tool module MCPTool MCPToolset McpTool McpTool.raw_mcp_tool McpTool.run_async() McpToolset McpToolset.close() McpToolset.from_config() McpToolset.get_tools() SseConnectionParams SseConnectionParams.url SseConnectionParams.headers SseConnectionParams.timeout SseConnectionParams.sse_read_timeout SseConnectionParams.headers SseConnectionParams.sse_read_timeout SseConnectionParams.timeout SseConnectionParams.url StdioConnectionParams StdioConnectionParams.server_params StdioConnectionParams.timeout StdioConnectionParams.server_params StdioConnectionParams.timeout StreamableHTTPConnectionParams StreamableHTTPConnectionParams.url StreamableHTTPConnectionParams.headers StreamableHTTPConnectionParams.timeout StreamableHTTPConnectionParams.sse_read_timeout StreamableHTTPConnectionParams.terminate_on_close StreamableHTTPConnectionParams.headers StreamableHTTPConnectionParams.sse_read_timeout StreamableHTTPConnectionParams.terminate_on_close StreamableHTTPConnectionParams.timeout StreamableHTTPConnectionParams.url adk_to_mcp_tool_type() gemini_to_json_schema() google.adk.tools.openapi_tool module OpenAPIToolset OpenAPIToolset.close() OpenAPIToolset.get_tool() OpenAPIToolset.get_tools() RestApiTool RestApiTool.call() RestApiTool.configure_auth_credential() RestApiTool.configure_auth_scheme() RestApiTool.description RestApiTool.from_parsed_operation() RestApiTool.from_parsed_operation_str() RestApiTool.name RestApiTool.run_async() google.adk.tools.preload_memory_tool module PreloadMemoryTool PreloadMemoryTool.description PreloadMemoryTool.name PreloadMemoryTool.process_llm_request() google.adk.tools.retrieval module BaseRetrievalTool BaseRetrievalTool.description BaseRetrievalTool.name google.adk.tools.tool_context module ToolContext ToolContext.invocation_context ToolContext.function_call_id ToolContext.event_actions ToolContext.tool_confirmation ToolContext.actions ToolContext.get_auth_response() ToolContext.request_confirmation() ToolContext.request_credential() ToolContext.search_memory() google.adk.tools.toolbox_toolset module ToolboxToolset ToolboxToolset.close() ToolboxToolset.get_tools() google.adk.tools.transfer_to_agent_tool module transfer_to_agent() google.adk.tools.url_context_tool module UrlContextTool UrlContextTool.description UrlContextTool.name UrlContextTool.process_llm_request() google.adk.tools.vertex_ai_search_tool module VertexAiSearchTool VertexAiSearchTool.data_store_id VertexAiSearchTool.search_engine_id VertexAiSearchTool.process_llm_request() google.adk.utils module google.adk.version module ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:40:06.488461", "source_type": "adk-docs"}
{"doc_id": "a14fb7f6472e54e228e2ec8aee59a7a4ac0f4c3cca607ccd50876b7b445da3f7", "url": "https://google.github.io/adk-docs/api-reference/cli/index.html", "title": "adk cli documentation \u2014 adk cli  documentation", "sections": [{"heading_path": ["adk cli documentation\u00b6"], "text": "adk cli documentation \u00b6 Add your content using reStructuredText syntax. See the reStructuredText documentation for details. Contents: CLI Reference adk ", "code_blocks": []}, {"heading_path": ["adk cli"], "text": "adk cli ", "code_blocks": []}, {"heading_path": ["Navigation"], "text": "Navigation Contents: CLI Reference ", "code_blocks": []}, {"heading_path": ["Related Topics"], "text": "Related Topics Documentation overview Next: CLI Reference \u00a92025, Google.\n      \n      |\n      Powered by Sphinx 8.2.3 & Alabaster 1.0.0 | Page source ", "code_blocks": []}], "last_crawled_at": "2025-11-19T22:40:07.382326", "source_type": "adk-docs"}
